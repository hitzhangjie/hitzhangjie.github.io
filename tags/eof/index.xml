<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>eof on</title><link>/tags/eof/</link><description>Recent content in eof on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Thu, 20 Dec 2018 23:11:29 +0800</lastBuildDate><atom:link href="/tags/eof/index.xml" rel="self" type="application/rss+xml"/><item><title>write closed tcpconn</title><link>/blog/2018-12-20-write-closed-tcpconn/</link><pubDate>Thu, 20 Dec 2018 23:11:29 +0800</pubDate><guid>/blog/2018-12-20-write-closed-tcpconn/</guid><description>问题背景 # tcp client: write to a half-closed tcp connection!
这里探讨一下这个问题，Write to a closed tcp connection的问题。在深入讨论这些问题之前，首先要了解tcp state diagram，为此文末特地附上了经典的tcp状态转换图。
我们的场景是这样的，tcp server已经启动，然后tcp client主动建立连接请求，连接成功建立后，tcp client并不立即发送数据而是等待一段时间之后才会发送数据（这种在client端的tcp连接池中非常常见），tcp server端为了防止连接被滥用，会每隔30s钟检查一下tcp连接是否空闲，如果两次检查都发现tcp连接空闲则主动将连接关闭。
原因分析 # 此时tcp server端会调用conn.Close()方法，该方法最终会导致传输层发送tcp FIN包给对端，tcp client这边的机器收到FIN包后会回一个ACK，然后呢？tcp client不会继续发FIN包给tcp server吗？不会！仅此而已。问题就是这么诞生的，什么问题呢，tcp client仍然可以发包，但是n, err := tcpconn.Write(...)这个时候并不会检测到err != nil，只有等到n, err := tcpconn.Read(...)的时候才会发现err为io.EOF，这个时候才能判断得知tcp server已经把连接销毁了。
从RPC框架角度而言，希望为client维护的tcp连接池是高效可用的，所以想对上述情况下的客户端连接进行检测，避免连接池中存在上述被tcp server关闭的连接。
再简单总结下tcp server、tcp client两端的不同处理逻辑：
从tcp server的视角来看，
tcp server调用的conn.Close()，对应的是系统调用close，tcp server端认为它已经彻底关闭这个连接了！
从tcp client的视角来看，
这个连接是我主动建立的，我还没有给你发送FIN包发起关闭序列呢，因此这个连接仍然是可以使用的。tcp client认为tcp server只是关闭了写端，没有关闭读端，因此tcp client仍然是可写的，并且socket被设置成了nonblocking，conn.Write()仍然是成功返回的，返回的err == nil。但是当真正传输层执行数据发送的时候，tcp server端认为这个连接已销毁，因此会返回RST！这个时候上层go代码因为已经返回已经感知不到写的时候存在错误，这个RST会将tcp client端的socket标记为已关闭。下次tcpconn.Read的时候就能感知到io.EOF错误了，如果再发起一次tcpconn.Write也可以立即返回错误。
关于close与shutdown # 假如tcp server调用的不是conn.</description></item></channel></rss>