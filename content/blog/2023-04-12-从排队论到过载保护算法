---
layout: post
title: 从排队论到过载保护算法
date: 2023-04-12 10:38:09 +0800
tags: ["排队论","little's law","latency","qps","load"]
toc: true
---



## 排队论简介

排队论的精髓是通过数学模型和分析方法来研究排队系统的性能和行为。排队系统是指由一些服务设施和一些顾客组成的系统，顾客需要排队等待服务。排队论的目标是研究如何优化排队系统的性能，以提高服务质量和效率。

排队论的核心是建立数学模型来描述排队系统的行为。这些模型通常基于随机过程和概率论，用于描述顾客到达的随机性、服务时间的随机性以及服务设施的数量和性能等因素。通过分析这些模型，可以得出排队系统的性能指标，如平均等待时间、平均逗留时间、系统利用率等等。

排队论的应用非常广泛，涉及到许多领域，如交通运输、通信网络、制造业、医疗保健等等。在这些领域中，排队论可以用来优化资源利用、提高服务质量、降低成本等等。

总之，排队论的精髓是通过数学模型和分析方法来研究排队系统的性能和行为，以优化系统的性能和效率。

## 理论公式及应用

排队论是一个非常广泛的领域，其中涉及到许多不同的理论公式和应用。以下是一些常见的排队论理论公式和计算机系统中的应用：

1. Little's Law：L = λW，其中L表示系统中平均顾客数，λ表示到达率，W表示平均逗留时间。这个公式表明，系统中平均顾客数等于到达率乘以平均逗留时间。在计算机系统中，这个公式可以用来计算系统中的平均并发请求数，以及系统的响应时间和吞吐量。
2. Kendall's Notation：A/B/C/K/N，其中A表示到达过程的类型，B表示服务时间的分布类型，C表示服务设施的数量，K表示服务设施的排队规则，N表示系统容量。这个符号表示了排队系统的基本特征，可以用来描述和比较不同的排队系统。
3. M/M/1队列：这是一个经典的排队模型，其中到达过程和服务时间都是指数分布，服务设施数量为1。这个模型可以用来计算系统的平均等待时间、平均逗留时间、系统利用率等指标。在计算机系统中，这个模型可以用来分析单个服务器的性能。
4. M/M/m队列：这是一个扩展的M/M/1队列模型，其中服务设施数量为m。这个模型可以用来计算系统的平均等待时间、平均逗留时间、系统利用率等指标。在计算机系统中，这个模型可以用来分析多个服务器的性能。
5. 网络队列模型：这是一个用于分析计算机网络性能的排队模型，其中网络节点被建模为队列，数据包被建模为顾客。这个模型可以用来计算网络的吞吐量、延迟、丢包率等指标。
6. 负载均衡算法：这是一种用于优化计算机系统性能的算法，通过将负载均衡地分配到多个服务器上，以提高系统的吞吐量和可靠性。排队论可以用来分析负载均衡算法的性能和效率。

这些理论公式和应用只是排队论中的一部分，排队论还涉及到许多其他的理论和应用，如排队网络、排队模拟、排队优化等等。

## 浅谈Little's Law

### 简要说明

Little's Law是一个基本的排队论原理，它描述了在一个**稳定的系统**中，平均顾客数、平均等待时间和平均服务率之间的关系。该原理最初由美国数学家John Little在1961年提出，被广泛应用于各种排队系统的性能分析和优化。

Little's Law的问题背景是排队系统，例如银行、超市、餐厅等等。在这些系统中，顾客到达、等待和离开的过程构成了一个排队模型。Little's Law的目的是通过分析这个模型，来解决如何优化排队系统的问题。

Little's Law的核心公式是：**L = λW**，其中L表示平均顾客数，λ表示平均到达率，W表示平均等待时间。这个公式告诉我们，如果我们知道了平均到达速率和平均等待时间，就可以计算出平均顾客数。反之亦然，如果我们知道了平均顾客数和平均等待时间，就可以计算出平均到达速率。这个公式可以帮助我们更好地理解排队系统的性能，并且指导我们如何优化排队系统。

### 应用案例

以下是一些应用Little's Law的案例：

1. 在一个银行分行，平均每小时有100名顾客到达，平均等待时间为10分钟，那么该分行的平均顾客数是多少？根据Little's Law，L = λW = 100 * 10 / 60 = 16.67，因此该分行的平均顾客数为16.67人。
2. 一家餐厅想要提高服务质量，他们决定增加服务员的数量。根据Little's Law，如果他们想要减少平均等待时间，他们需要增加服务员的数量，以提高服务率。如果他们想要减少平均顾客数，他们需要减少到达率，例如通过减少广告宣传或者提高价格等方式。

## 在线服务领域

### 理解little's law

将其应用到我们熟悉的在线服务领域的话，调整下相关参数：

 - 队列平均长度可视为同时被服务的请求个数，即服务并发度Concurrency，
 - 队列人数到达(速)率可视为服务吞吐Throughput，
 - 平均服务时间可视为服务平均处理延迟Latency（可细分为等待延迟+处理延迟），

 这样可以得到另一个版本的Little's Law，Concurrency=Throughput * Latency。

简单理解下这里的公示。假设请求都是单线程处理，每个请求只会占用一个cpu core，则服务并发度Concurrency就是cpu core的个数；每个请求的处理平均时间为Latency（单位为秒），则1秒内一个cpu core可以处理的请求数为 1/Latency；因此，1秒内可处理的总请求个数也就可以确定：Throughput = Concurrency * (1/ Latency)，进一步就可以得到公式：Concurrency = Throughput * Latency……所以，还是好理解的。

利用这个公式，我们可以进一步去分析计算机系统处理请求时的吞吐量、处理时延、并发处理能力之间的关系。

> 有时候我们队计算机进行系统性能优化，也会对某任务的某一部分进行改善，如何评估改善后任务的整体性能极限呢？可以通过Amdahl's Law来分析，详见 [Wikipedia Amdahl's Law](https://en.wikipedia.org/wiki/Amdahl%27s_law)，不展开了。

那我们如何具体来使用它来评估系统处理请求时的吞吐量、处理时延、并发处理能力之间的关系呢？有没有什么实际案例可供借鉴下。

### 工程应关注什么

首先，工程上我们往往会通过调整服务配置，对服务进行不同测试，比如性能测试、负载测试、压力测试、稳定性测试等。

- 性能测试，以系统设计初期规划的性能指标为预期目标，对系统不断施加压力，验证系 统在资源可接受范围内，是否能达到性能预期。 

- 负载测试，对系统不断地增加并发请求，以增加系统压力，直到系统的某项或多项性能 指标达到安全临界值。当并发请求数量超过安全临界值之后，系统吞吐量不升反 降。 

- 压力测试，超过安全负载的情况下，对系统继续施加压力，直到系统崩溃或不能再处理 任何请求，以此获得系统最大压力承受能力。 

- 稳定性测试，被测试系统在特定硬件、软件、网络环境条件下，给系统加载一定业务压力， 运行一段较长时间，以此检测系统是否稳定。

通过这些测试，来确定不同负载下（系统负载、cpu负载、内存负载等）服务能够支持的吞吐量Throughput（QPS）、处理延迟Latency（p90、p95、p99耗时、平均处理耗时）

### 过载保护算法

也就是说，我们通常会将负载作为一个相对固定的值，比如CPU单核85%作为一个参考点，测试期间压力源发送的请求系统负载稳定在这个值，然后观察Throughtput、Latency的关系变化。注意此时85%的负载下，响应时间Latency不一定是最好的，但是吞吐量可能是更大的，要注意根据SLA（承诺的响应时间、QPS等来为客户分配合理的资源）。或者我们将其压测到过载，然后取此时QPS的一个75%左右作为一个相对合理的QPS值，并在客户端通过漏桶、令牌桶等算法来强制执行这个最大频率上限。

但是对于大型分布式系统，这个配置值很快就会过期，QPS可能偏小导致后端服务不能充分利用资源，或者QPS过大导致后端服务过载。我们应该考虑并发请求，而不是考虑 RPS CPU、内存、磁盘或网络等限制。 Little's Law 很好地涵盖了这种关系，其中 `Limit = Average RPS * Average Latency`。





