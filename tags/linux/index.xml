<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>linux on</title><link>/tags/linux/</link><description>Recent content in linux on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Sun, 19 May 2024 09:10:25 +0800</lastBuildDate><atom:link href="/tags/linux/index.xml" rel="self" type="application/rss+xml"/><item><title>Bash常用命令</title><link>/blog/2016-01-07-bash%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</link><pubDate>Sun, 19 May 2024 09:10:25 +0800</pubDate><guid>/blog/2016-01-07-bash%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</guid><description>迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是一些日常高频使用的linux命令。
lp : submit files and print pwd : print current work directory match pattern in bash : ? * [] extension of '{}' : b{ed,olt,ar}s ls *.{c,h,o} i/o : cat : copy input to output grep: match lines from input sort: sort lines from input cut : extract columns from input how to set the delimiter to space? note: -d' ' only specify space as the delimiter,not including tab,so it's inconvenient when files contain both of space and tab.</description></item><item><title>Linux性能问题排查60s</title><link>/blog/2023-09-08-linux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A560s/</link><pubDate>Fri, 08 Sep 2023 16:30:30 +0800</pubDate><guid>/blog/2023-09-08-linux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A560s/</guid><description>简介 # 最近在阅读Gregg大佬著作《BPF Performance Tools》，其中一小节作者提到了其在Netflix工程团队中践行的一个性能排查checklist，当遇到Linux性能问题时，前60s往往是借助这个checklist来进行排查，如果有必要，缩小范围后再借助其他工具进行进一步排查。我觉得这个简短的checklist还挺实用的，特地摘录出来分享下。
问题背景 # 这个checklist可以用来指导排查任意Linux性能问题，当我们知道有台机器性能（疑似）有问题时，我们就可以登录这台机器，按照这个checklist来进行前60s的快速分析。这也是Gregg自己以及Netflix工程团队实践中总结出来的。
对于很多刚入行后台开发的同学而言，我觉得这个还是比较有价值的，应该在日常工作中不断实践、不断加深对性能影响因素的理解。有位技术扎实的同事曾经这样说，一切都是可计算的、可量化的，比如判断对特定工作负载瓶颈是什么，cpu、内存、网卡？链路长短，网络延迟，然后大致的系统吞吐量是什么样的？他大致就能推算出来。
其实，Jeff Dean曾经在论文里给出过一些开发人员应该知晓的latency数据：
L1 cache reference ......................... 0.5 ns Branch mispredict ............................ 5 ns L2 cache reference ........................... 7 ns Mutex lock/unlock ........................... 25 ns Main memory reference ...................... 100 ns Compress 1K bytes with Zippy ............. 3,000 ns = 3 µs Send 2K bytes over 1 Gbps network ....... 20,000 ns = 20 µs SSD random read ........................ 150,000 ns = 150 µs Read 1 MB sequentially from memory .</description></item><item><title>压测之接口lo的妙用</title><link>/blog/2023-04-14-%E5%8E%8B%E6%B5%8B%E4%B9%8B%E6%8E%A5%E5%8F%A3lo%E7%9A%84%E5%A6%99%E7%94%A8/</link><pubDate>Fri, 14 Apr 2023 03:10:08 +0000</pubDate><guid>/blog/2023-04-14-%E5%8E%8B%E6%B5%8B%E4%B9%8B%E6%8E%A5%E5%8F%A3lo%E7%9A%84%E5%A6%99%E7%94%A8/</guid><description>问题背景 # 前一篇文章介绍了本地开发机压测时如何为每个待压测分配CPU资源（其实是taskset进行绑核，由于没有其他负载可以近似为分配CPU资源），本文继续介绍下如何让压测变得更真实一点，那就是网络IO这块，在本地通信时往往使用的是loopback接口，但是loopback并不是一个真实的网卡设备，它基本没有什么硬件网卡设备的传输速率的限制，也没有网络传输过程中的传输延迟。
这样的话，我们在压测的时候，网络方面的开销就几乎体现不出来，比如说，你想看下在4g网络下客户端、服务器之间网络通信数据包多大时打开数据压缩更有价值……
在我的测试过程中我希望能尽可能简化测试工作的同时，也能保证该有的环境的真实性，于是就有了本文对loopback接口的一点探索。
认识本地lo # Linux中的Loopback接口是一个虚拟网络接口，允许在同一主机上运行的应用程序之间通信。它通常被称为“lo”接口，具有IP地址127.0.0.1。
Loopback接口在内核中使用Loopback驱动程序实现，创建一个虚拟网络接口，并将所有传入的数据转发到本地协议栈。当一个应用程序将数据发送到loopback接口时，数据会被回送到协议栈，并像从另一个网络接口到达一样转发。 在Linux中，Loopback接口的一个重要用例是用于测试和调试网络应用程序。通过通过Loopback接口发送和接收数据，应用程序可以模拟网络流量，而不实际发送或接收来自物理或虚拟网络接口的数据。
Loopback接口还由一些网络协议使用，例如Kubernetes kube-proxy IPVS，OSPF和其他需要在同一主机上的进程之间通信的网络相关软件。
总之，Linux中的Loopback接口是一个虚拟网络接口，为在同一主机上运行的应用程序提供了一种通信通道。它在内核中使用Loopback驱动程序实现，并且在测试、调试和网络相关软件中具有许多实际用例。
认识netem # 在 Linux 中，ip 命令中的 netem 是一个网络模拟工具。它允许您对网络连接进行各种修改，例如，添加延迟、丢包以及增加噪声等，以便在网络环境下测试应用程序的性能和稳定性。使用 netem 工具，您可以模拟各种不同的网络条件，包括高延迟、高带宽和低带宽等，以便更好地测试和优化应用程序在各种网络条件下的行为。
Netem 已经成为 Linux 网络模拟和测试工具的标准选择之一，同时也是在诸如交换机、路由器和 WAN 加速器等网络设备上进行隔离测试和仿真时的一个有用工具。通过使用 netem，您可以更好地了解您的应用程序在不同网络条件下的行为，并且能够更好地进行演示和培训。
利用本地lo # 如何使用netem让本地loopback接口更好地模拟真实网络情况呢？下面就来简单说一下。
启用netem # 首先，需要启用内核模块netem：
sudo yum install -y kmod sudo modprobe sch_netem 模拟网络延迟 # 然后，如果loopback接口的每次的收、发操作模拟一定的网络延迟：
sudo yum install iproute-tc or sudo yum install iproute sudo tc qdisc add dev lo root netem delay 1ms 这样的话就相当于一个rtt增加了2ms，为了验证这个，你可以在执行上述模拟前后，分别看下ping localhost的延迟。</description></item><item><title>压测之taskset的妙用</title><link>/blog/2023-04-13-%E5%8E%8B%E6%B5%8B%E4%B9%8Btaskset%E7%9A%84%E5%A6%99%E7%94%A8/</link><pubDate>Thu, 13 Apr 2023 03:22:15 +0800</pubDate><guid>/blog/2023-04-13-%E5%8E%8B%E6%B5%8B%E4%B9%8Btaskset%E7%9A%84%E5%A6%99%E7%94%A8/</guid><description>问题背景 # 想测试下gRPC框架的性能，设计了如下服务拓扑来对gRPC框架各组件、特性、参数配置下的性能进行探索。
压力源程序 perfclient ---请求-&amp;gt; perfserver1 ---请求-&amp;gt; perfserver2 压力源程序perfclient会并发发送请求给服务perfserver1，perfserver1则会继续请求perfserver2，然后perfserver2回包给perfserver1，perfserver1收到响应后内部完成处理逻辑后继续回包给perfclient。
perfclient每隔一段时间会打印下请求的请求量、成功量、失败量，以及qps、耗时信息。需要注意的事，这里再统计耗时信息的时候，除了avg、min、max耗时，还需要percentile(or quantile）百分位耗时，后者更具有说服力。
现在呢？遇到点问题，正常我需要将上述压力源程序、被压测服务perfserver1、perfserver2尽力部署到不同的机器上，让它们之间避免相互影响，同时部署的机器上也应该注意没有其他负载会干扰到我们的测试，但是问题来了：
可能有机器，但是部署起来太麻烦了，可能每调整下测试点就要要操作多台机器 可能有机器，但是云平台存在超卖的情况，母机负载大影响到了虚拟机负载稳定性 可能有机器，但是ci/cd流水线执行耗时太久了 可能没机器，只有一台本地开发机 有没有什么其他简单好用的办法呢？我觉得有，资源隔离下啊。
认识taskset # taskset，是linux下用来进行绑核设置的一个工具，我们可以借助它对上述不同的3个进程的cpu资源进行限定，如压力源程序perfclient需要能多生成些请求，我们给它分配7~10 4个cpu core，perfserver1负载会稍微比perfserver2高点，但如果是纯echo的话也多不了读少，给perfserver1分配2个cpu core，给perfserver2也分2个。
taskset -a -p 7,8,9,10 `pidof perfclient` taskset -a -p 3,4 `pidof perfserver1` taskset -a -p 5,6 `pidof perfserver2` 这样上述几个进程就被分别设置到了不同的cpu cores上执行，意味着当他们把cpu跑满时，他们能抗的负载大致就是这个比例。
解释下选项-a：
taskset如果不指定选项-a，则知会对当前进程名对应的主进程进行绑核设置，不会对进程中的其他线程进行设置，当然也不会对后续新创建的线程进行设置。
加了-a，taskset就会对执行命令时，该进程pid下的所有线程进行统一的绑核设置，但是如果后续创建了新线程，新线程不会被绑核。
那么如果一个程序是多线程程序，且线程数不是固定的，会在以后新创建、销毁动态变化的，这种该怎么解决呢？
go天然多线程 # go程序天然是多线程程序，那应该如何进行绑核设置呢？如果只是为了限制进程使用的cpu资源，直接使用runtime.GOMAXPROC(x)进行设置不行吗？不行！
该函数只是说限制同时在运行的线程数，并没有像taskset那样将线程绑到核上，这意味着这些go程序线程的执行有可能会在cpu core上迁移，这样的话通过top命令查看cpu core负载情况，就不好判断哪个core的负载是因为哪个进程引起的…对吧。
另一个问题，go程序的GMP调度模型会在必要时自动创建新的线程出来，用来执行goroutines，这里问题就来了，我需要动态感知当前进程下的所有线程。go语言或者标准库都没有提供线程层面的东西来获取，那我们怎么获取呢？
go如何绑核 # Linux下面每个进程都有一个pid，对应的虚拟文件系统/proc//tasks下面就是该进程pid下的所有线程信息。理论上可以定时获取里面的pid，然后再去taskset -p绑核，或者说go启动一个协程定时调用下taskset -a -p &amp;lt;pid&amp;gt;，可以简洁明了搞定。</description></item><item><title>Linux内核学习资料</title><link>/blog/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/</link><pubDate>Sat, 02 Jul 2022 14:39:04 +0800</pubDate><guid>/blog/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/</guid><description>现在学习Linux操作系统的人越来越多了，进一步学习Kernel的人也越来越多了，经常有人问起有没有质量好的、获得大家认可的学习资料论坛，尤其是对于学习内核的新手而言，能否获得这些好的学习资料还是很重要的。因为经常有人问起这个问题，所以在Linux源码随附的文档中，有专门一篇文档kernel-docs.rst专门整理罗列了适合大家学习Linux内核的文档、在线资源、出版书籍等，并逐一做了简要的描述。注意到其中有些资料是和具体内核模块相关的，如网络协议栈、中断子系统等，也适合有针对性地、深入地去学习。
本文剩余内容来自Linux内核文档 kernel-docs.rst，整理在此方便查阅参考。
Docs at the Linux Kernel tree # The Sphinx books should be built with make {htmldocs | pdfdocs | epubdocs}.
* Name: **linux/Documentation** :Author: Many. :Location: Documentation/ :Keywords: text files, Sphinx. :Description: Documentation that comes with the kernel sources, inside the Documentation directory. Some pages from this document (including this document itself) have been moved there, and might be more up to date than the web version. On-line docs # * Title: **Linux Kernel Mailing List Glossary** :Author: various :URL: https://kernelnewbies.</description></item><item><title>mac/win下linux c/c++开发</title><link>/blog/2022-06-28-linux-cc-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/</link><pubDate>Tue, 28 Jun 2022 23:08:51 +0800</pubDate><guid>/blog/2022-06-28-linux-cc-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/</guid><description>问题背景 # 我们很多人主力操作系统是macOS或者Windows，用Linux作为主力操作系统的少吧，不过之前确实有连续7年多是用Fedora作为主力操作系统 :)
现在很多人开发人员使用MacBook Pro作为自己的开发机，大厂标配，我们很多后台呢，开发的程序一般最后还是要跑在Linux系统上的，尤其是c/c++开发涉及到这里的跨平台开发的问题，很多开发人员用着非常原始的方式在开发，开发体验比较差。
借这个契机，我调研了下现在比较好的一些开发方式，总结分享下。
先定一个要实现的小目标：
能基于IDE进行开发，比如VSCode; 另外，编译构建必须能够 vscode: add dockerfile to workspace # 在vscode中cmd+p，输入add dockerfile to workspace并执行，此时会选择基础镜像，如面向c++开发的基础镜像，此时会生成默认的dockerfile。 然后在dockerfile选中后点击右键，选择build image，此时就完成镜像构建了，该默认dockerfile默认是一个编译镜像，里面包含了编译构建产物。 直接运行上述镜像默认就是运行程序，运行的方式可以在docker explorer里面找到镜像，右键菜单中选择Run，或者命令行执行。 这个镜像只是用来编译构建、测试运行的，还不能满足我们开发阶段的需求，因为开发阶段需要考虑头文件、库的搜索问题。
解决思路：
至少要构建一个支持开发的镜像，如c/c++镜像； 启动这个镜像，并将当前工程以volume的形式挂在到容器中，或者在容器中clone下来这个项目。提交代码要注意随时提交； 开发通过vscode remote连接到vscode server进行开发，其实是本地vscode通过ssh连接传输vscode server软件包到容器中并安装启动； 如果开发镜像支持类似WebIDE的方式进行开发，也可以代替3这种方式，只是一些本地vscode的快捷配置等可能不是很好同步。 docker desktop: New Dev environment # Docker Desktop的这种实现方式，就是上面提到的2\3这几步的组合，基本满足我们希望实现的目标了（支持开发容器Mount local directory或者容器中Clone git repository）。
这种方式也有不足，就是假设后续有人要接手这个项目，或者有人和你协作，你怎么办呢？ 我们可以直接提交一个镜像push到registry，他只要能拉代码，又能拉镜像就基本能还原之前的开发环境。
但是我为什么非要push一个镜像上去呢（包括自定义的基础镜像、开发阶段的分享镜像）？ 如果不push镜像而docker destop默认的开发镜像调整了或者我希望定制一个统一的怎么办？
Docker Desktop创建新的开发镜像的时候有一种方式，允许指定一个基础镜像，但是这个基础镜像要push到远程registry。代码会被clone到这个 容器内部，我们就通过vscode remote进行开发即可。
尽管vscode鼓励非Linux用户尽量通过这种方式，因为fs操作更快，但是还是有点不方便，因为这数据卷相当于额外浪费一份存储，考虑到之前已经克隆过的情况下。 有没有办法既能自定义基础镜像，又能挂载本地磁盘目录为数据卷的方式来解决呢？可以，请看方式3。
vscode: Remote-Containers # vscode中Command Pallete中Remote-Containers: Add Development Container Configuration Files，执行这个我们可以为工程指定一个配置文件.</description></item><item><title>Linux桌面发行版分享</title><link>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E5%88%86%E4%BA%AB/</link><pubDate>Sun, 26 Jun 2022 16:37:16 +0800</pubDate><guid>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E5%88%86%E4%BA%AB/</guid><description>Linux桌面发行版分享 # 这是一篇写在2016年的文章一直在我的个人笔记里，感觉当时很多想法今天依然成立，所以拿出来继续分享下。某些信息可能已经有过时，相关的部分我在备注里进行了标注，
0.体验Linux发行版 # 今天安装了Ubuntu 16.04 LTS，本来准备一直用Fedora的，但是我的笔记本上安装的还是 Fedora 21版本，但是当前最新的已经更新到了Fedora 24,今天刚刚发布了Beta版本。此 前我对Fedora 23 GA以及Fedora 24 Alpha版本进行了简单的测试，实在是不喜欢KDE 5！
怎么说呢，其实看上去KDE 5挺漂亮的，应该将来也会有不错的发展，但是考虑到KDE 5刚 出来的时间还不够长，其中很多在KDE 4里面方便实用的功能在KDE 5中还没有被开发出来 ，而我又是一个倾向于“工欲善其事，必先利其器”的同学，让我这样把一个未充分完善好 的桌面环境当做自己的主力系统，我实在难以接受！对于GNOME 3，我就不做任何评论了 ，我宁可用Ubuntu Unity也不用GNOME 3！
可能有人说，没必要一直跟着更新啊，继续实用Fedora 21也可以啊！？此话当然不假， 可是一个失去后续更新支持的版本，我想还是要继续跟进新版本要更好。其实我现在配置 的已经相当棒了，有的软件源里面的程序存在某些小问题，瑕不掩瑜的，我也对其源代码 进行了部分修改，以为自己所用，因为这部分工作还是相当多、相当细的，如果继续跟进 新的发行版，而软件源里面的软件包可能还没有修改过来，或者不符合我的需要，又要进 行重复性的工作，我觉得这个工作量还是蛮大的，至少现在我没有那么充足的时间。
Fedora发行版每6个月更新一次，CentOS 7可以支持10年，我本来也计划使用CentOS的， 但是CentOS对稳定性的追求，也使得很多软件包不能被加入其软件源，有些我很喜欢的工 具，安装、配置起来就会比较麻烦，dpkg、alien、rpmrebuild甚至修改源代码这些可能 都要用到，以配置出一个趁手的系统环境。半年前，我在另一台三星的笔记本安装了 CentOS 7，配置完成之后，堪称完美，那个时候时间多啊，折腾的时间也挺长的；现在时 间没有那么充裕了，我在这台thinkpad上安装了CentOS 7.2，前后也就折腾了一天，不打 算折腾了。
最后，我选择了Ubuntu 16.04 LTS版本，可以支持5年，而我本身也想重新比较一下 Ubuntu、Fedora这两大发行版，为什么呢？因为对这两款发行版，我都有向当长的使用时 间，现在也积累了很多的经验，前不久我碰巧又看到了一个各大发行版性能对比的文章， 其中Debian系列的性能要明显优于RHEL系列，原因我暂时也不是特别清楚，这也是激发我 重新选择Ubuntu的原因之一。我希望在使用过程中，重新比较一下Ubuntu和Fedora这两大发行版的差异，例如包管理工具的差异、软件包中的配置文件的差异、系统管理方面的差 异，此外呢，我也希望能够对其性能上的差异进行一下更深的认识。
1.系统安装过程 # 系统安装过程，应该说是驾轻就熟了，下载一个Ubuntu 16.04 LTS的ISO文件，然后使用 Unetbootin制作一个可以引导系统安装的U盘。U盘要格式化成FAT32格式，且要根据需要 预留一定的存储空间，以供安装过程中释放文件使用，如果预留空间不足，可能导致安装 失败。
制作完成安装U盘之后，插入电脑，关闭BIOS中的UEFI引导模式，然后从USB HDD启动安装即可。安装的时候手动分区，最好能够把那些第三方软件包给安装上，这样省的后续安装 ，省心。我是深有体会，之前安装音频、视频播放器的时候，安装解码库浪费了很多时间 。安装过程中有个别地方需要设置一下，例如用户名、密码、语言、地区、时间等等的。
注意，Ubuntu在安装过程中不会对root用户的密码进行设置，并且默认将新建的用户加入 wheel组中！但是在Fedora安装过程中，会对root密码进行设置，然后再创建一个新用户 ，并允许选择是否将该用户加入wheel组中，还可以指定uid、gid等。这是一个区别，需 要注意一下，安装完成之后，需要通过“passwd root”对密码进行重新设定。</description></item><item><title>聊聊伴我多年的老友，Linux</title><link>/blog/2017-03-13-%E8%81%8A%E8%81%8A%E4%BC%B4%E6%88%91%E5%A4%9A%E5%B9%B4%E7%9A%84%E8%80%81%E5%8F%8Blinux/</link><pubDate>Mon, 13 Mar 2017 21:00:00 +0800</pubDate><guid>/blog/2017-03-13-%E8%81%8A%E8%81%8A%E4%BC%B4%E6%88%91%E5%A4%9A%E5%B9%B4%E7%9A%84%E8%80%81%E5%8F%8Blinux/</guid><description>1 邂逅Linux # 初次接触Linux操作系统是在什么时候？想想～～
高三毕业后买了第一台电脑，一台清华同方的台式机，随机赠送的光盘里面有一张操作系 统光盘“家电下乡Linux适农版”……那是我第一次接触并运行Linux，但那时的我并没有意识 到，放在我面前的是一个即将深深地吸引我并要在多年的职业生涯中去不断锤炼的存在。
大一、大二这两年，我或多或少地接触到了Linux，但是并没有产生多大兴趣，直到有一 天我激怒了一个同学。当时他正在摆弄Ubuntu，错误地GRUB配置导致系统引导失败，着急 的他在QQ空间发了一条状态，意思就是大神求救之类的。当时我回了一个字“水”。他看后 很生气，系统都启动不了了能不着急吗？于是呢，就言辞激烈地“回敬”了我几句……
事后我想，Linux有这么复杂吗？于是我开始试图取了解Linux，当然这只是个引子，后面 陆陆续续看到有不少同学都在使用各种Linux的发行版，我才决定认真去了解、学习一下 Linux，没想到这竟是一条不归路……
LiveCD &amp;amp; RemasterSys &amp;amp; dump &amp;amp; restore GRUB 2 &amp;amp; Customize Boot Menu to bootstrap Multiple OS Plymouth Tweak KDE/GNOME/Unity Appearance (Colors &amp;amp; Themes) Linux Commandline Techs &amp;amp; Administration Unix/Linux Programming Linux Kernel 0.11 Linux Kernel 2.4 Keep going along the roadmap to Linux World! 上面大体上是我初识、折腾、学习、应用、研究Linux的过程，而且这个过程在相当长一 段事时间内还将一直向前延伸下去。与其说对Linux感兴趣，不如说是好奇心驱使，还有 很多疑问没有揭开，这里当然不只是Linux操作系统内核本身。
我这个博客所要描述的东西可能就比较杂了，这里面我会穿插着记录很多东西～与其说是 博客，不如说是我自己的一个学习笔记了，但是我这个人比较喜欢分享，但有不想那么刻 意，所以我就把它丢在这，谁看见了找到点自己感兴趣的东西，也算是种缘分。
2 LiveCD &amp;amp; RemasterSys &amp;amp; dump &amp;amp; restore # 2.</description></item><item><title>Linux桌面发行版分享</title><link>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E4%BD%93%E9%AA%8C/</link><pubDate>Sat, 07 May 2016 00:23:47 +0800</pubDate><guid>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E4%BD%93%E9%AA%8C/</guid><description>Linux桌面发行版分享 # 这是一篇写在2016年的文章一直在我的个人笔记里，感觉当时很多想法今天依然成立，所 以拿出来继续分享下。某些信息可能已经有过时，相关的部分我在备注里进行了标注，
0.体验Linux发行版 # 今天安装了Ubuntu 16.04 LTS，本来准备一直用Fedora的，但是我的笔记本上安装的还是 Fedora 21版本，但是当前最新的已经更新到了Fedora 24,今天刚刚发布了Beta版本。此 前我对Fedora 23 GA以及Fedora 24 Alpha版本进行了简单的测试，实在是不喜欢KDE 5！
怎么说呢，其实看上去KDE 5挺漂亮的，应该将来也会有不错的发展，但是考虑到KDE 5刚 出来的时间还不够长，其中很多在KDE 4里面方便实用的功能在KDE 5中还没有被开发出来 ，而我又是一个倾向于“工欲善其事，必先利其器”的同学，让我这样把一个未充分完善好 的桌面环境当做自己的主力系统，我实在难以接受！对于GNOME 3，我就不做任何评论了 ，我宁可用Ubuntu Unity也不用GNOME 3！
可能有人说，没必要一直跟着更新啊，继续实用Fedora 21也可以啊！？此话当然不假， 可是一个失去后续更新支持的版本，我想还是要继续跟进新版本要更好。其实我现在配置 的已经相当棒了，有的软件源里面的程序存在某些小问题，瑕不掩瑜的，我也对其源代码 进行了部分修改，以为自己所用，因为这部分工作还是相当多、相当细的，如果继续跟进 新的发行版，而软件源里面的软件包可能还没有修改过来，或者不符合我的需要，又要进 行重复性的工作，我觉得这个工作量还是蛮大的，至少现在我没有那么充足的时间。
Fedora发行版每6个月更新一次，CentOS 7可以支持10年，我本来也计划使用CentOS的， 但是CentOS对稳定性的追求，也使得很多软件包不能被加入其软件源，有些我很喜欢的工 具，安装、配置起来就会比较麻烦，dpkg、alien、rpmrebuild甚至修改源代码这些可能 都要用到，以配置出一个趁手的系统环境。半年前，我在另一台三星的笔记本安装了 CentOS 7，配置完成之后，堪称完美，那个时候时间多啊，折腾的时间也挺长的；现在时 间没有那么充裕了，我在这台thinkpad上安装了CentOS 7.2，前后也就折腾了一天，不打 算折腾了。
最后，我选择了Ubuntu 16.04 LTS版本，可以支持5年，而我本身也想重新比较一下 Ubuntu、Fedora这两大发行版，为什么呢？因为对这两款发行版，我都有向当长的使用时 间，现在也积累了很多的经验，前不久我碰巧又看到了一个各大发行版性能对比的文章， 其中Debian系列的性能要明显优于RHEL系列，原因我暂时也不是特别清楚，这也是激发我 重新选择Ubuntu的原因之一。我希望在使用过程中，重新比较一下Ubuntu和Fedora这两大 发行版的差异，例如包管理工具的差异、软件包中的配置文件的差异、系统管理方面的差 异，此外呢，我也希望能够对其性能上的差异进行一下更深的认识。
1.系统安装过程 # 系统安装过程，应该说是驾轻就熟了，下载一个Ubuntu 16.04 LTS的ISO文件，然后使用 Unetbootin制作一个可以引导系统安装的U盘。U盘要格式化成FAT32格式，且要根据需要 预留一定的存储空间，以供安装过程中释放文件使用，如果预留空间不足，可能导致安装 失败。
制作完成安装U盘之后，插入电脑，关闭BIOS中的UEFI引导模式，然后从USB HDD启动安装 即可。安装的时候手动分区，最好能够把那些第三方软件包给安装上，这样省的后续安装 ，省心。我是深有体会，之前安装音频、视频播放器的时候，安装解码库浪费了很多时间 。安装过程中有个别地方需要设置一下，例如用户名、密码、语言、地区、时间等等的。
注意，Ubuntu在安装过程中不会对root用户的密码进行设置，并且默认将新建的用户加入 wheel组中！但是在Fedora安装过程中，会对root密码进行设置，然后再创建一个新用户 ，并允许选择是否将该用户加入wheel组中，还可以指定uid、gid等。这是一个区别，需 要注意一下，安装完成之后，需要通过“passwd root”对密码进行重新设定。</description></item><item><title>Debian系使用笔记</title><link>/blog/2016-01-07-debian%E7%B3%BB%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</link><pubDate>Thu, 07 Jan 2016 09:43:00 +0800</pubDate><guid>/blog/2016-01-07-debian%E7%B3%BB%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0/</guid><description>迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是一些日常高频使用的linux命令。
1）linux 文件目录树与磁盘分区 一块硬盘最多有4个主分区，可以将其中的主分区设置为扩展分区，然后在扩展分区中再继续划分为多个逻辑分区，从而得道更多的分区。 linux中，磁盘分区的命名方式是hdcn（ide ata硬盘）或sdcn（scsi 硬盘/sata 硬盘/usb 硬盘等），其中的c表示编号，从a开始。比如hda和hdb分别代表ide0插口上的主盘和从盘，而n则是分区编号，1～4对应该磁盘的4个可能的主分区或者扩展分区，5之后的都是逻辑分区来。 比如我的电脑是划分来3个主分区，其中一个主分区被设置为扩展分区，它们的编号分别为sda1，sda2，sda3。sda3被设为扩展分区，然后将其划分成来6个逻辑分区，编号为sda5～sda10。 不管是linux还是windows系统，每个分区的文件系统都会组织成一个目录树，对于windows系统来讲，通常每棵目录树都是并列的，并且每一个分区都分配一个盘符，由此可以确定任意文件在整个系统中的确切位置。 而对于linux系统来说，所有分区都被组织在同一个目录树上，选取一个分区作为目录树的根，其余的分区上的文件系统都被挂载到这个根目录树上的某个节点上。 相比之下，可以看出linux系统这种组织方式的优点。windows系统中，如果盘符发生了变动，并且分区中如果有与系统盘中关联的程序，那么这些程序的运行将受到影响，因为他们的程序路径发生来变动，可能环境变量等等已经失效了。而在linux系统中，如果将改动了分区，那么只需要重新改动下对应分区在根分区上的挂载点就可以了。 2）内核/模块/基本库 概念 提到linux系统时，多半是指整个操作系统，但是实际上，linux仅仅是系统的内核部分。 linux不是微内核。 通常内核不直接与我们交互，他们工作在硬件和软件之间，主要完成两大类任务：帮助软件获取硬件资源的控制权，并操控硬件；协调各个软件，让他们和谐统一地工作。 内核得天独厚的优势是：拥有系统中的最高权限。 可以将程序运行状态分为：核心态和用户态。只有极少数的核心态程序才能操纵硬件。 作为核心态程序的内核提供给用户态程序的接口称为系统调用。 内核的具体工作包括内存管理/进程调度/文件系统管理/网络通信/进程间通信，这些工作都可一划分成多种工作方式，以适应不通的需求，此外还需要驱动大量的硬件工作，所以内核的工作量是非常大的。 对于内核的设计，采取如下策略，以减少内核工作量和错误发生率： 如果工作可以在用户空间完成，就不要放入内核中，这就是所谓的微内核技术，但是linux不是微内核，但是也在逐渐地将一些可以在用户空间中完成的任务放入用户空间中。 如果内核某项工作可以做成独立的模块，那么就允许将其设计为独立的模块，然后在需要该模块的时候，再将其加载运行。 3）文件与文件系统 文件在linux系统中，是个非常重要的概念，除了普通文件之外，对于所有的设备，linux也一并将其看作是文件，像对待文件一样对他们进行操作。 在linux系统中，除了一些普通文件之外，还有其他一些特殊类型的文件，这些文件在/dev目录下基本上都可以看到。 ls -l /dev： 根据开头的第一个字符判断文件类型： -:普通文件 d:文件目录 l:符号链接文件 c:字符设备文件，如键盘 b:块设备文件，如硬盘 f:fifo文件，队列 s:socket文件，linux中，socket既可以用来进行网络通信，也可以用于进程间通信 4）环境变量与shell 父进程的环境变量可以被子进程继承，子进程对环境变量的修改不会影响父进程。 5）网络与服务 这里主要理解daemon的意思吧，也就是daemon进程，守护进程的概念。 守护进程，就是一直处于运行状态，它监视某种事件的发生，比如有客户端请求，然后它就提供必要的服务，如果没有客户端请求，那么它就处于等待状态，等待客户端请求。 6）cat命令与tac命令 cat命令是“连接”一词的缩写形式，如果指定的参数为多个文件，它会将这几个文件衔接起来，如果通过重定向的形式将内容输出到一个新的文件，就可以实现将文件合并的功能。 tac命令，跟cat命令类似，但是它是反序的。 7）gzip与bizp2 gzip与bzip2这两个压缩程序，可以与tar实现无缝衔接，tar命令在使用的时候，常常使用选项-z或者-j，分别代表gzip和bzip2，当然对应的文件扩展名有所变化，分别为*.tar.gz和*.tar.bz2。 常用的选项-c表示compress，即压缩，-x表示解压。 -z表示使用gzip，-j表示使用bzip2。 -v表示输出压缩解压缩的文件列表。 -f表示对文件进行压缩解压。 apt-cache 强大的apt查询工具 9）dpkg apt的底层软件工具 dpkg一个比较实用的方法使用来备份系统已经安装的软件列表，以便重装系统之后，快速恢复系统中需要的软件，相当于对系统的一次克隆。 备份软件安装列表： dpkg --get-selections &amp;gt; installedApp 将安装列表中的软件安装到系统： dpkg --set-selections &amp;lt; installedApp sudo apt-get dselect-upgrade 也可以如下操作： dpkg --get-selections | grep -v deinstall &amp;gt; installedApp dpkg --set-selections &amp;lt; installedApp sudo dselect screen 可以实现在一个终端窗口中生成多个终端，方便实用，尤其是在非x-window工作状态下，screen的重要性就体现的更加明显。 ctrl+a,c to create a session ctrl+a,p go previous session ctrl+a,n go next session ctrl+a,N go to the session numbered 'N' ctrl+a,' go to the seesion named by 'ctrl+a,A' ctrl+a,&amp;quot; list all session and choose which to go ctrl+a,A rename current session ctrl+a,d detach current screen's display,leaving current session keeping on running mc 命令行下的文件管理器 除了对文件的相关操作之外，还可以登录ftp服务器。 12） w3m 命令行下的www浏览工具 使用上下左右箭头可以在网页中移动，当移到某个超链接上后，可以通过回车健进行跳转。如果是在页面中的输入框中输入信息，首先敲击回车键，然后就可以输入信息来。 13） wget与curl 命令行与后台下载工具 14） grub菜单举例 #default =0 # 0 is the default timeout =5 root (hda1,6) splashimage /boot/grub/debian-boot.</description></item></channel></rss>