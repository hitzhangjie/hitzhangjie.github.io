<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on</title><link>/blog/</link><description>Recent content in Blog on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 06 Oct 2020 08:49:55 +0000</lastBuildDate><atom:link href="/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>Linux任务调度(8): 任务越多调度就越频繁吗</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A68/</link><pubDate>Tue, 22 Apr 2025 12:36:00 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A68/</guid><description>Linux任务调度(7): 任务越多上下文切换就越频繁吗 # 本文将讲述一个曾经困扰在我们项目组心头的关于go进程混部时的担忧，以及由此引出的多进程混部时的隔离性问题。比如，个别程序不健壮创建大量进程，是否会推高上下文切换次数导致无谓的CPU开销的问题。我们将结合工具perf、bpftrace来深入观察并分析，以加深了对真实负载场景下任务调度的深层理解。
Go运行时引发的思考 # 一个线上问题 # 对CFS的深入思考，一个直接原因是因为go程序中GOMAXPROCS设置不合理，母机上有128个CPU核心，但是虚拟化技术下容器里分配的只有2个cpus。
此时go进程检测到GOMAXPROCS=128（go不会自动感知到实际上只分配了2个cpus），此时runtime会误认为最多可以创建128个P（GMP中的P，Processor），后果就是进程中最多会创建128个P。比如随着goroutines增多如果当前P处理不过来，就会激活更多的空闲P，对应的创建更多的线程M并轮询绑定的P上的的localrunq、全局的globalrunq以及定时器事件、网络IO事件就绪的goroutines并调度。这里的轮询操作就会导致较高的CPU开销，容易导致CPU throttling（节流）从而导致程序性能下降。
GMP调度是如何初始化的 # go运行时是这样创建GMP的
进程启动的时候会根据GOMAXPROCS先创建出对应数量的P，详见 schedinit()-&amp;gt;procresize()，但是还是没有创建M个这么多线程的； 上述创建出来的一堆P，除了当前g.m.p是在用状态，其他都是idle状态；M也不会预先创建出来，而是根据设计负载情况动态去创建、去激活P去执行的； 具体来说就是当创建一堆goroutines后，这些goroutine会先往 p.runq放，放不下了就会考虑 injectglist(...)，这个其实就是放到全局队列 sched.runq，放的时候： 如果当前M有关联一个P，就先放 npidle个G到 sched.runq，并且启动 npdile个M去激活 npdile个P，去尝试从goroutine抢G然后执行。然后剩下的放到 p.runq； 如果当前M没有关联一个P，这种情况下怎么会发生呢（有多种情况可能会发生，比如GC、系统调用阻塞、初始化阶段等）？这种情况下会全部放到 sched.runq，然后启动最多npidle个（即 min(goroutineQSize, npdile)）个M去激活P并执行； 简单总结就是：“如果短时间内创建大量goroutines，当前p.runq full（或者M解绑了P）就会往sched.runq放。然后会启动最多npidle个M去抢P激活，然后workstealing的方式从sched.runq抢goroutines执行。”
如果这种情况一旦出现了，这些大量创建出来的M，后续无goroutines执行时，也会不断地执行一些轮询 p.runq、sched.runq、netpoller、stealing、timer事件，这个无谓的轮询过程中就容易推高CPU占用。而实际的 --cpus 配额很少，就更容易达到CPU配额限制，进而被虚拟化管理软件给节流（CPU throttling），进而导致程序性能出现整体性的下降 (程序正常逻辑还没怎么执行，全被这些多出来的M轮询消耗掉了)。
一时负载高创建的M能退出吗 # 那有没有办法，让这些创建出来的大量M退出呢？创建出来的M退出只有一种办法，runtime.LockOSThread()，这种情况下，goroutine会和M绑定，goroutine执行完毕退出时，M也会被销毁。但是正常情况下是不会调用这个函数的（调试器tracer会调用该函数），所以多创建出来的M不会退出，进而就导致了这里的问题。
实际上，go程序中解决这个问题，很简单，读取下cgroups的cpu配额即可。可以直接 import _ &amp;quot;github.com/uber-go/automaxprocs&amp;quot; 来解决。
更多任务会导致更频繁上下文切换吗 # 上面go运行时错误设置GOMAXPROCS导致过多P、M创建出来导致了轮询的CPU开销，这个点我们已经明确了，并且了解到了对应的解决方案。
我们还有一个顾虑：
1）同一个机器上，有多个进程，其中一个go进程因为上述原因创建了大量的线程，CFS调度器任务切换频率会不会也被推高？我们都知道上下文切换有开销。 2）同一个机器上，如果有多个进程，如果我想避免某个进程对其他进程的影响，或者某个用户下的所有进程对其他用户下的进程的影响？该如何做。
这几个问题，其实就是我深入研究CFS调度器的根本原因，因为我像搞明白混部的影响及问题边界，这对保证服务乃至系统的可用性至关重要。当然你可以不混部来绕过这些弯弯绕绕的细节。
让我来尝试会大下上面两个问题，其中2）我们已经知道了，CFS可以通过组调度来解决这类问题，但是不会自动构建不同用户的任务组，一个进程包括多个线程也不会作为一个任务组进行限制，可以理解成系统默认有更多线程有更多处理能力，除非你们的系统管理员显示设置。
OK, 那现在，我们只需要搞清楚1），如果任务数增多会导致上下文切换更频率吗？
假设CFS的设计实现果真如此，那这就是个巨大的风险点。现代Linux系统可以创建非常多的任务出来。现代Linux系统不是早些年的时候由CS 13bits索引范围限制了GDT/LDT表长度了，2^13/2=4096个进程（每个进程占GDT表的2项），早期版本最多支持这么多个任务。但是后面Linux版本对此做了修改，解除了这里的限制。每个处理器核心只在GDT中记录它当前运行的任务的表项信息，而任务队列则交给每个处理器核心的cfs_rq，可以创建的任务数量不再受CS 13bits索引、GDT/LDT表长度限制了。Linux系统可以支持的任务数只受限于pid_max、内核配置项、系统资源了。
而如果随着任务数增多，上下文切换频率就变高，这样大量的CPU资源会被浪费在上下文切换上。所以调度器是绝对不会这样实现的，这种设计太蠢了。如果任务数很多，我们可以接受不饿死的前提下、允许一定的调度延时、允许降低一定的交互性，但是不能降低系统调度的吞吐量、不能导致CPU资源巨大浪费、完全不可用。
所以我们的判断应该是，No！更多任务不会导致更频繁的上下文切换！这里的更多任务是指的非常多任务，而不是说从1到2，从2到4，从4到8，从8到16，从16到32这种程度，我们讨论的是从128到256，从1024到2048，从2048到4096这种程度。
谨慎评估下上下文切换频率 # 根据前面的介绍，任务切换 __schedule(preempt)的时机有3个，任务阻塞主动让出CPU、任务抢占、任务唤醒被重新加入run-queue。结合我们下面的测试用例，任务阻塞到被唤醒，我们创建的线程不会主动阻塞，只会被抢占，所以我们只需要分析任务抢占这个路径即可，scheduler_tick()-&amp;gt;task_tick()-&amp;gt;check_preempt_tick()，这里面会检查当前任务是否应该被抢占，发生抢占才会发生上下文切换。</description></item><item><title>Linux任务调度(7): CFS调度器源码分析1</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A67v2/</link><pubDate>Thu, 27 Jun 2024 12:36:00 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A67v2/</guid><description>Linux任务调度(7): CFS调度器源码分析 # 前面几篇文章介绍了Linux下调度器的演进过程，也对CFS调度器的大致工作原理进行了介绍，本文在CFS源码层面进行深入分析，帮助大家更深刻地理解CFS调度器的实现细节。Linux从开始引入CFS调度器到现在，已经发展了近20年的时间。在这一段时间里，CFS调度器经历了多次演进，我们选择相对比较新的版本 v5.12 版本内核为例进行说明。现在主流云厂商提供的Linux发行版内核都还有这个版本，我们的分析仍然具有一定的时效性方面的价值。OK，我们开始。
核心概念及源码分析 # 对“公平”的理解 # CFS的目标是为所有任务提供公平的CPU时间分配，这里要先好好理解下 “公平” 的含义：
1）如果多个任务具有相同的优先级，那么它们理应获得相同的调度机会； 2）如果多个任务优先级有高低之分，那么它们在调度上要有对应的体现，优先级高的要获得更多的调度机会； 3）要防止高优先级任务始终霸占CPU，导致低优先级任务饿死（starvation）； 4）对于响应式任务、非响应式任务，要有必要的奖励和惩罚机制，以改善用户体验； 5）要有能力在用户层级、任务组层级、具体任务层级，建立这种“公平性”； 6）这种公平性在多CPU核心上，除了100%保证单CPU核心上的公平，也需要考虑负载均衡和任务迁移，尽力去做到多CPU核心上的整体调度的相对公平；
这是我对CFS中“公平性”的理解，接下来我们将结合CFS的源码来分析是如何做到的，让大家知其然知其所以然。
核心数据结构 # 被调度的具体任务，或者用户组、任务组，它们都用可调度实体来抽象表示，即 sched_entity； struct sched_entity { /* For load-balancing: */ struct load_weight load; struct rb_node run_node; struct list_head group_node; unsigned int on_rq; u64 exec_start; u64 sum_exec_runtime; u64 vruntime; u64 prev_sum_exec_runtime; u64 nr_migrations; struct sched_statistics exec_statistics; #ifdef CONFIG_FAIR_GROUP_SCHED int depth; struct sched_entity *parent; /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; /* rq &amp;quot;owned&amp;quot; by this entity/group: */ struct cfs_rq *my_q; /* cached value of my_q-&amp;gt;h_nr_running */ unsigned long runnable_weight; #endif #ifdef CONFIG_SMP /* * Per entity load average tracking.</description></item><item><title>vscode-常规配置以及同步说明</title><link>/blog/2024-04-14-%E5%B8%B8%E8%A7%84%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%90%8C%E6%AD%A5%E8%AF%B4%E6%98%8E/</link><pubDate>Sun, 14 Apr 2024 23:00:00 +0800</pubDate><guid>/blog/2024-04-14-%E5%B8%B8%E8%A7%84%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%90%8C%E6%AD%A5%E8%AF%B4%E6%98%8E/</guid><description>前言 # 我经常在项目开发过程中针对不同项目，甚至是相同项目的不同模块阶段，频繁调整配置以满足当时的需要，我觉得能够快速调整vscode配置满足开发人员需要，是一项必备技能。
这里就简单总结下vscode配置调整过程中，一些比较有价值的信息。
搜索配置项 # 搜索修改过的配置项，可以按照 &amp;ldquo;@modified&amp;quot;进行过滤， 搜索指定插件的话，可以按照&amp;rdquo;@ext:&amp;ldquo;进行过滤 设置优先级 # 配置项可以在不同的设置范围内进行覆盖。在下面的列表中，后面的范围会覆盖前面的范围：
默认设置 - 这个范围代表未配置的默认设置值。 用户设置 - 对所有的 VS Code 实例全局适用。 远程设置 - 适用于用户打开的远程机器。 工作区设置 - 适用于打开的文件夹或工作区。 工作区文件夹设置 - 适用于多根工作区的特定文件夹。 特定语言的默认设置 - 这些是由扩展提供的特定语言的默认值。 特定语言的用户设置 - 与用户设置相同，但特定于某种语言。 特定语言的远程设置 - 与远程设置相同，但特定于某种语言。 特定语言的工作区设置 - 与工作区设置相同，但特定于某种语言。 特定语言的工作区文件夹设置 - 与工作区文件夹设置相同，但特定于某种语言。 策略设置 - 由系统管理员设置，这些值始终会覆盖其他设置值。 跨设备同步 # Settings Sync功能，之前使用IDEA系列产品时，一来一个Settings Repository及插件来做这个事情，VSCode就方便多了，直接支持用户维度下的多份的同步，比如分别为macOS、Linux、Windows分别自定义一份配置。
同步的内容也很丰富：
常规设置项 view tasks snippets shortcuts 甚至是UI状态都可以 而且可以精确控制每一个配置项是否参与同步，这个就很有用，比如要读本地机器的文件，但是文件路径在参与同步的设备上不同，那么该配置项就可以“取消设置同步”。
重置配置 # 当该乱某个配置项时，可以选择齿轮按钮，点击弹出菜单然后选择“reset this setting”，或者从settings.</description></item><item><title>vscode-调整配置以保持专注</title><link>/blog/2024-04-14-%E8%B0%83%E6%95%B4%E9%85%8D%E7%BD%AE%E4%BB%A5%E4%BF%9D%E6%8C%81%E4%B8%93%E6%B3%A8/</link><pubDate>Sun, 14 Apr 2024 10:00:00 +0800</pubDate><guid>/blog/2024-04-14-%E8%B0%83%E6%95%B4%E9%85%8D%E7%BD%AE%E4%BB%A5%E4%BF%9D%E6%8C%81%E4%B8%93%E6%B3%A8/</guid><description>前言 # 保持专注、减少外界干扰，首要的是培养内在的专注力，而不是依赖工具。回想起我前几年的一些经历：
我的 MacBook Pro Touch Bar 经常闪烁，几乎刺痛了我的双眼。最终发现是硬件故障，我曾看到一个网友的解决方法，简直让我笑掉大牙。他直接用黑色胶带把 Touch Bar 给封住了。 后来我购买了一款防眩光、防窥的屏幕膜，但它稍微有些厚度，导致关闭屏幕时无法完全贴合。我开始寻找更轻薄、更便携的替代品，直到一个“老手”给了我建议：“简单点，直接将屏幕膜撕下来放在配套袋子里。” 为何提及这两个例子呢？其实是想说，现阶段虽然有很多创新产品，但未必完美。与其花大量时间寻找“完美”，不如早日认识到自己深处发展历程中的某个时刻、转而采用更经济更有效的解决方案。
但是，尽管产品成品不完美，但我们依然可以尽己所能让它接近我们期望的那样。就比如使用vscode进行开发时，我希望它能在不同规模的项目中能够帮助开发者保持专注。
问题背景 # 项目采用的微服务架构+monorepo进行代代码组织，每个微服务一个子目录，当然也有很多scripts、tools、ci/cd配置、配置文件管理、外部依赖等等。业务开发的时候，其实你很想只关心某些范围，而忽略掉不相关的范围，以让自己保持专注的同时提升检索、开发的效率。
为了保持专注，不同产品中有不同的设计，比如KDE中的activity，IDEA中的projectscope，Typora中有打字机模式……就不扯远了，我们只看看vscode中能做到什么程度，来让开发者保持更好的专注度。
配置方式 # 忽略掉不关心的文件: files.exclude # vscode中支持在explorer、代码搜索操作中忽略某些文件夹、文件，这个是通过配置一些忽略规则来实现的。
规则配置说明，详见：see: https://code.visualstudio.com/docs/editor/glob-patterns
如果代码库是monorepo管理的，使用git进行版本控制（没有针对大仓的权限控制、拉取等进行特殊优化），那拉取下来后文件数量会很多，但是在我们对全局进行了了解之后，以后大部分功能开发过程中，你很可能希望能聚焦于其中某些部分，而非全部。不管是explorer中查看，还是代码搜索时检索，还是提交日志检查，你都希望能尽可能聚焦。所以是有必要隐藏某些不紧密相干的内容的。
忽略gitignore中文件: explorer.excludeGitIgnore # gitignore中通常会忽略一些文件，大多数时候这些文件也是一些不需要在explorer中显示的，所以vscode也增加了这样一个配置项，允许忽略.gitignore中忽略的文件。
严格来说，是vscode会读取gitignore中的配置，但是对其中某些规则的解析上并不完全等同于git。
举个例子，下述配置项通常用来忽略linux上的编译构建生成的二进制程序，但是如果vscode读取后就会忽略所有内容，并不完全等价于git忽略的内容。
* !*.* !*/ 不要watch不关心的目录：files.watcherExclude # vscode会通过filesystem watch特性来监视某些文件内容的修改情况，以便及时reload最新内容，但是这也是由性能开销的，如果某些路径下的变更不是自己关心的，可以考虑忽略。至少在显示打开、强制reload window时还是会加载最新内容的。
通过 project scope # IDEA系列的IDE产品中，有一个非常有用的特性，project scope。
前面提到的两种方式，控制的事工程全局层面，哪些文件可显示、隐藏出来。而project scope则是概念上对工程的划分。
比如用户登录流程、用户匹配流程、对局结束流程、DS管理流程，这些不同关键链路上的服务列表，它们有重叠的，也有各自特有的。用project scope进行管理就非常方便了。
你可以创建不同的project scopes，然后每个scope控制好要显示、隐藏的文件，当希望从某个关键业务流程切换到另一个关键业务流程的开发时，只需要切换project scope就可以了。
很遗憾的是，vscode原生不支持project scope，但是有些作者通过vscode extension的方式来实现了project scope，实现方式就是在进行scope切换时，自动帮用户设置好files.exclude。
通过 workspace # vscode支持workspace，以及multi-root workspace，意思是你可以将多个独立的工程组织在一个workspace中，在一个workspace中也可以控制显示、隐藏的文件。
workspace是不同于project scope的另一种特性，可以针对同一个project配置多个workspace分别设置好隐藏、显示规则，可以近似实现project scope的功能。 multi-root workspace还可以将多个不相干的projects组合在一个workspace里面，比如我有些个人兴趣驱动的电子书，调试器相关的、RPC框架相关的、Go语言设计实现相关的，我就可以将这几个独立的工程编排为一个workspace。</description></item><item><title>解决c10k c100k c10m问题</title><link>/blog/2024-01-06-%E8%A7%A3%E5%86%B3c10kc100kc10m%E9%97%AE%E9%A2%98/</link><pubDate>Sat, 06 Jan 2024 20:30:24 +0800</pubDate><guid>/blog/2024-01-06-%E8%A7%A3%E5%86%B3c10kc100kc10m%E9%97%AE%E9%A2%98/</guid><description>问题背景 # c10k, c100k甚至c10m，这些问题大家已经不再陌生，聊起来可能显得有点枯燥？新技术层出不穷，至少我自己对这些问题有了些新的认识，需要更新沉淀下我的“小宇宙”。
c10k问题, 1999, 1Gbps Ethernet # The C10k problem is the problem of optimizing network sockets to handle a large number of clients at the same time.[1] The name C10k is a numeronym for concurrently handling ten thousand connections.[2] Handling many concurrent connections is a different problem from handling many requests per second: the latter requires high throughput (processing them quickly), while the former does not have to be fast, but requires efficient scheduling of connections.</description></item><item><title>观测Go函数调用：go-ftrace 设计实现</title><link>/blog/2023-12-12-%E8%A7%82%E6%B5%8Bgo%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8go-ftrace%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/</link><pubDate>Tue, 12 Dec 2023 12:42:47 +0800</pubDate><guid>/blog/2023-12-12-%E8%A7%82%E6%B5%8Bgo%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8go-ftrace%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/</guid><description>img { width: 680px; padding-bottom: 1rem; } 前言 # 不久前在团队内部做了点eBPF相关的技术分享，过程中介绍了下eBPF的诞生以及在安全、高性能网络、可观测性、tracing&amp;amp;profiling等领域的实践以及巨大潜力。另外，在我们项目开发测试过程中，也希望对go程序的性能有更好的把控，所以对“上帝视角”的追求是会上瘾的，所以我们也探索了下如何基于eBPF技术对go程序进行无侵入式地观测。
分享过程中也演示了下我现阶段开发的go函数调用可观测性工具。下面是我的分享PPT，感兴趣的话可以打开阅读：eBPF原理及应用分享，欢迎一起学习交流。
基础知识 # 本文重点不在于eBPF扫盲，但是如果有eBPF的基础的话，再看本文对go-ftrace的介绍会事半功倍。所以如果对eBPF没什么了解，可以先看看我的分享PPT，或者其他资料，知道个大概。
go-ftrace主要是对go程序中的函数调用进行跟踪并统计其耗时信息，也可以获取函数调用过程中的参数信息，这样结合起来，你可以看到不同输入下的处理耗时的差异。
我们在前一篇文章里介绍了如何使用go-ftrace来跟踪go程序中的某些函数，甚至获取其执行过程中的函数参数信息。本文来详细介绍下go-ftrace的设计实现。
内核视角 # 自打1993年bpf（berkeley packet filter）技术出现以来，这种CFG-based（control flow graph）的字节码指令集+虚拟机的方案就取代了当时的Tree-based cspf （cmu/standford packet filter）方案，而后几年在Linux内核中引入了bpf，定位是用来做些tcpdump之类的包过滤分析，在后来Linux内核中引入了kprobe技术，允许用户在内核模块中通过kprobe跟踪内核中的一些函数来进行观测、分析，此后的很多年，bpf技术一直在改进，逐渐演化成一个独立的eBPF子系统，kprobe、uprobe也可以直接回调eBPF程序，使得整个Linux内核变得可编程，而且是安全的。
从跟踪角度来看，有静态跟踪、动态跟踪两种方式，静态跟踪主要是Linux内核中的一些tracepoints，动态跟踪主要是借助kprobe、uprobe技术。如果你阅读过我之前写的调试器的书籍（还未100%完成），你肯定会对“指令patch”技术有所了解，其实kprobe、uprobe技术的工作原理也是借助指令patch。
当我们通过系统调用bpf通知内核在指令地址pc处添加一个kprobe或者uprobe时，内核会将对应地址处的指令（有可能是多个字节）用一个一字节指令Int 3 (0xcc)代替，并在内核数据结构中记录下原指令内容，以及这个地址处是否是一个kprobe、uprobe。 当内核执行到这个指令0xcc时，它会触发一个异常，进而会执行Linux内核中断服务程序对其进行处理，内核会检查这个地址pc处是否有相关的kprobe、uprobe，有的话就跳过去执行，每个kprobe、uprobe实际上包含了prehandler、原指令、posthandler。先执行prehandler，如果返回码ok则继续执行原指令，再执行posthandler；如果prehandler返回错误码，那就不往后执行了，通过这个办法也可以拦截某些系统调用，如seccomp-bpf技术。 大致就是这样的一个过程，仔细深究的话kprobe、uprobe工作起来稍微有点差异。
注册kprobe你只需要告诉内核一个符号即可，比如一个系统调用名，内核会自己计算出这个符号对应的指令地址； 而注册一个uprobe的话，举个例子，go main.main函数，内核是不认识这个符号的，它也不知道main.main的地址该如何计算出来，就需要我们自己先算出来它的地址（实际上是相对于ELF文件开头的偏移量），然后再传给内核； 调试知识 # 那么针对不同的编程语言写的程序，如何指定一个符号来计算出对应的指令地址呢？这就是挑战点之一，不过在调试领域这个问题早就已经解决了，我们可以借鉴下来解决计算指定函数名的指令地址的问题。
DWARF，是一种调试信息标准，目前是使用最广泛的调试信息格式。其实有多种调试信息格式，但是从对不同编程语言、不同特性、数据编解码效率的优势来看，它确实更胜一筹，所以现在主流编程语言生成的调试信息基本都是支持DWARF或者优先考虑DWARF。
以go语言为例，当我们执行go build编译一个可执行程序时，以ELF binary文件为例，编译器、链接器会生成一些.[z]debug_开头的sections，这些sections中的数据就是调试信息。
常见的ELF sections及其存储的内容如下:
.debug_abbrev, 存储.debug_info中使用的缩写信息；
.debug_arranges, 存储一个加速访问的查询表，通过内存地址查询对应编译单元信息；
.debug_frame, 存储调用栈帧信息；
.debug_info, 存储核心DWARF数据，包含了描述变量、代码等的DIEs；
.debug_line, 存储行号表程序 (程序指令由行号表状态机执行，执行后构建出完整的行号表)</description></item><item><title>eBPF开发环境搭建</title><link>/blog/2023-11-22-ebpf%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</link><pubDate>Wed, 22 Nov 2023 01:57:47 +0800</pubDate><guid>/blog/2023-11-22-ebpf%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/</guid><description>问题背景 # 如果读者朋友使用的是Linux机器，而且系统是Ubuntu这些社区比较活跃的发行版，那么你遇到问题的时候，一般可以比较快地解决，或者很少遇到这种被他人反复才坑已经修复的问题。所以本篇文章并不一定适合你，不过看看也说不定有其他方面收获。
我使用的开发环境如下：
处理器：i9 13900K (x86_64) 操作系统：Windows 11 WSL版本：v2 Linux发行版：RedHat 8.5 Linux内核版本：5.15.90.1-microsoft-standard-WSL2+ 2023年9月份已经在阅读lizrice的learning-ebpf一书了，并且自己还跑了下书中的用例，并对测试时遇到的环境设置问题进行了解决，但是隔了一段时间，因为执行了 yum update吧，clang、llvm、kernel-headers、bcc相关包，它们之间的依赖没有明显问题，但是整合到一起编译构建、运行ebpf程序的时候，开始报错。
于是2023.11.21日这天花费了大量时间来重新解决eBPF的开发环境设置问题，先记录下，供大家以及自己日后参考。
环境设置 # 内核配置 # 1、git clone https://github.com/kernel-newbies/WSL2-Linux-Kernel
2、cd WSL2-Linux-Kernel &amp;amp;&amp;amp; git checkout linux-msft-wsl-5.15.90.1
​ 选择版本5.15.90.1，与lizrice/learning-ebpf中推荐版本5.15.x.y尽可能对齐
3、执行 make config 配置编译构建选项
​ 直接使用这里的.config ，这个已经是配置好了必要的ebpf选项的配置了
4、执行 make -j8 进行内核构建，内核输出到了vmlinuz文件
5、执行 sudo make headers_install 进行内核头文件安装
工具链配置 # 1、sudo yum install clang clang-devel llvm llvm-devel
​ 注意llvm不同版本兼容性有些问题，可能在低版本上编译ok升级后反而失败了，
​ 我就是遇到的这样的坑，原本bcc 0.26可以在llvm 16上编过，升级到llvm 17失败
2、不使用yum源中的bcc 0.25.0，有bug未修复，直接从源码安装
​ git clone https://github.</description></item><item><title>Linux任务调度(6): CFS不是银弹</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A66/</link><pubDate>Mon, 20 Nov 2023 12:59:05 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A66/</guid><description>演进过程 # 首先，再次回顾下下Linux进程调度器的一个发展历史：
v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n)) 前一篇文章中我们介绍了完全公平调度器CFS（Completely Fair Scheduler)，我们介绍了它的核心思想，并结合我们之前的几个顾虑给出了在CFS调度器下如何来解决顾虑的问题。CFS自从诞生以来，一直是Linux内核的默认调度器实现。它也先后经历了多次演进，如前文提到的对sched_entity的抽象改进以实现对组调度（group scheduling)的支持。看上去CFS已经是非常好的调度器实现了，事实上CFS也不是银弹。
没有银弹 # 尽管Torvalds、Ingo等人坚持希望在内核中维护一个通用的调度器实现，来支撑不同的场景。这个理想很丰满，但是从实践上来看，确实在某些领域CFS的表现仍然并不是很令人满意。
比如在个人桌面场景下，也不需要NUMA、也不要求在4096个处理器上具有良好扩展性，有没有比CFS更合适的调度器实现方案呢？那么在移动设备中呢？在其他更广泛的应用场景下呢？我们真的需要一个以一当十的CFS scheduler吗？还是需要一个个更适应各自领域的专用的scheduler？
BFS调度器 # 2009年，Con Kolivas 又带着他的新版本调度器实现方案BFS回归了内核开发社区，BFS是Brain Fucker Scheduler的简称，挑衅意味浓厚，这与其主张的希望为Linux kernel在不同场景下允许提供多样化的scheduler方案相关，而Torvalds、Ingo等人主张用一个通用的scheduler统领各种场景。
有些开发者进行了测试，在桌面场景下，BFS比CFS的效果好很多，但是因为理念的问题，BFS当时也被认为不会被合入内核，但是确实引发了广泛的关于scheduler的讨论。如今已经是2023年，Linux kernel仍然是采用CFS作为调度器，内核主线代码并没有BFS的身影。
关于BFS scheduler的设计，您可以通过阅读这篇文章来了解：BFS cpu scheduler v0.304 stable release。
BFS设计实现的内容，感兴趣的读者可以自行搜索，本文就不展开了。这里只是想跟大家强调，调度场景的多样性，以及内核大佬们对于CFS的不满以及孜孜不倦的探索。
Con Kolivas的方向是对的，内核应该有这种机制来支持用户选择对应的调度器实现以适应不同场景。
在论文BFS vs. CFS - scheduler comparison的摘要部分，作者也清晰表达了这种看法：
Our results indicate that scheduler performance varies dramatically according to hardware and workload, and as a result we strongly encourage Linux distributions to take an increased level of responsibility for selecting appropriate default schedulers that best suit the intended usage of the system.</description></item><item><title>Linux任务调度(5): CFS调度器</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A65/</link><pubDate>Sun, 19 Nov 2023 21:59:05 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A65/</guid><description>演进过程 # 首先，再次回顾下下Linux进程调度器的一个发展历史：
v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n)) 前一篇文章中我们介绍了v0.01版本中的调度器实现，复杂度为O(n)，在v0.01内核实现中写死了最多可调度的任务数量，只能算作是一个toy！随着从v0.01~v2.4.x版本中的优化，能调度的任务数量也上来了，但是复杂度还是O(n)。O(1)调度器对其进行了优化，但是其启发式算法来识别、奖惩交互性的逻辑难以建模、理解、维护、优化。RSDL调度器相比O(1)调度器有了很大的改进，但是Con Kolivas和Torvalds、Ingo等人有不同看法，最终迟迟未能合入内核主线。最后，在此前探索优化基础上，CFS诞生了并成为了运行至今的调度器解决方案。
问题背景 # 对Linux调度器做过点了解的话，应该都听说过“完全公平调度器”这个术语吧。完全公平调度器(Complete Fair Scheduler, 简称CFS)。CFS从v2.6.23到现在v6.0.0+久经沙场考验，它一定是有些过人之处，才能在多用户多任务、服务器、桌面、虚拟机、容器化乃至云原生领域都表现还不错。
业务在项目部署上的实践，让我产生了对Linux scheduler设计实现的一些思考。事情是这样的，项目是采用的微服务架构，但是在初期项目部署时节约成本、减少机器管理、服务部署的复杂度，项目采用了1台机器混部多个微服务的形式。这就不得不思考，如果其中一个服务进程占用CPU过多的话，对其他进程会不会造成影响。肯定会，但是如何隔离这种影响。
混部的坑 # 对于采用了k8s容器化部署的项目而言，一般就不会遇到这样的困扰，因为容器运行时已经做了比较好的资源隔离，包括CPU、内存等等，混部的话就有一定的挑战，尤其是像go这种支持协程、本身也是多线程而且支持GC的程序。
go本身就是多线程程序，用来支持多处理器多核上的goroutine调度执行，支持GC，轮询网络IO事件、轮询定时器事件等； go本身支持协程，协程的调度、最终执行依赖于多线程，尽管可以限制GOMAXPROCS（P的数量，限制同时运行的M数量）； go支持GC，但是对于程序上限没有硬限制（有别于Java等），只有软限制，内存占用居高不下容易导致OOM； 其他； 内存分配控制 # 对于go程序混部，有一定的挑战，综合投入产出比，可以考虑根据服务的重要程度、吞吐量、响应时间等要求给与不同的设置。以内存为例，混部服务GOMEMLIMIT上限尽量不要高于总可用内存的70%，留一点buffer给系统服务、个别服务超额分配的情况。Go GC中的MarkAssit机制实际上会要求申请分配内存的goroutine在GC期间参与一定的扫描，既加速了垃圾的扫描进度，也延缓了内存的分配速度，通过这种手段来保持堆大小尽可能维持着平衡。如果打开了GOMEMLIMIT，请求负载超过预期时会导致堆内存占用超过软限制时，并且无法通过GC降到GOMEMLIMIT以下。此时会导致Go GC的death spirals，CPU会消耗在GC上高达50%，严重影响进程的处理性能。而且，如果多个进程都遇到类似问题，内存占用会超过预设的70%，有OOM的风险。
这是对内存进行的控制，那么对CPU呢？实际上在对请求负载、内存消耗、物理资源不具备充足的掌控的时候，不建议大范围混部Go服务，因为上述影响可能会导致影响面扩大。
CPU分配控制 # 对于计算密集型任务，如果涉及到混部，为了分配CPU资源可能会考虑通过taskset进行绑核，实际上对于IO密集型任务也未尝不可，但是收益有多少呢？作者此前曾经在压测中做过这方面的一点尝试，将不同服务绑定在不同核上，这是我的一个单机用于压测的探索，实际真正线上服务，这种方案不一定真的可取。资源分配要取决于真实的负载情况才合理，不能简单的cpu 1,2,3,4给服务1，cpu 5,6给服务2，cpu 7给3，cpu 8给4这样。这样的粒度太糙了，而且预期的资源配给可能跟真实的负载相差很多。
与其瞎琢磨，瞎测试，不如多了解下CFS调度器让内核自己来解决。CFS调度器其实可以比较好地解决这个问题，不同服务可能创建了不同数量的线程、协程来应对匹配的请求负载，CFS调度器尽可能保证每个线程调度的公平（CFS调度的目标实际上是更抽象的sched_entity，这里用“线程”先简化问题范畴），从而让服务获得应该和负载匹配的cpu执行时间。
调度实现顾虑 # 看似通过上述设置，即使是混部，也可以工作的很好，嗯，但是我还是有顾虑。俗话说“无规矩不成方圆”，如果大家都守规矩、不犯错，可能也没写这篇文章的必要了。或者说，写这篇文章主要是想探讨下，研发规范、平台能力如何避免让这些不守规矩、爱犯错的人犯错。《波斯王子》里老国王对儿子说，“一个伟大的人，不仅自己要尽量不犯错，也要阻止他人犯错”。
CFS调度器设计实现上能否彻底解决我的顾虑呢？
1、如果机器混部有不同用户1、用户2的服务，用户1的进程数（线程数）特别多，如果不加控制手段，用户1会挤占用户2的资源；
2、如果用户1混部了多个服务1、2、3，如果服务3实现有问题，创建了大量线程，服务3会挤占服务1、2的资源；
3、还有种情况，每个服务可能对应着一个进程组，如果某个服务创建大量进程、线程，从而挤占了其他服务的资源怎么办；
其实这些问题，都属于调度器层面对于“公平性”的考虑范畴，只是它们有不同的层次：线程级别，用户级别，组级别。
CFS调度器随着第一个patch以及后续的很多次优化，可以解决上述不同层级的“公平性”问题，这就是“组调度(CFS group scheduling)”，我们在后面介绍。
CFS调度器 # 在学习RSDL调度器中我们也了解了它是如何保证和体现调度的公平性的，那么CFS调度器又是如何做的呢？一起来看下。
公平性建模 # 抽象vruntime # 在我看来，抛开道德、协作争议等问题不谈，我认为CFS调度器比Con Kolivas提出的RSDL调度器对公平性的建模上更胜一筹，因为它非常容易理解、容易实现，能够比较简单地论证这个算法能否比较好的工作。</description></item><item><title>Linux任务调度(3): O(1)调度器</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A63/</link><pubDate>Thu, 16 Nov 2023 18:59:05 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A63/</guid><description>演进过程 # 首先，再次回顾下下Linux进程调度器的一个发展历史：
v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n)) 前一篇文章中我们介绍了v0.01版本中的调度器实现，复杂度为O(n)，在v0.01内核实现中写死了最多可调度的任务数量，只能算作是一个toy！随着从v0.01~v2.4.x版本中的优化，能调度的任务数量也上来了，但是复杂度还是O(n)。
O(1)调度器简介 # 为了解决此前调度器调度一个进程复杂度为O(n)的问题，O(1)调度器就这么来了。
O(1)调度器，也被称为“常数时间调度器”，是为了解决Linux中早期调度算法的局限性而引入的。其目标是提高调度器的效率和可扩展性，特别是对于具有大量进程的系统。
传统的调度算法，如轮转调度（roundrobin）或基于优先级的调度器，其时间复杂度随着进程数量的增加呈线性增长。这意味着随着进程数量的增加，调度开销也会增加，导致性能下降。
O(1)调度器旨在提供常数时间的调度，无论进程数量如何。O(1)调度器显著减少了调度开销，并提高了整体系统性能。它成为Linux内核的默认调度器多年，直到后续版本中被完全公平调度器（CFS）取代。
重点攻坚问题 # O(1)调度器并不只是解决从O(n)到O(1)这一个问题，它还涉及到其他一些很有价值和挑战的问题：
实现完全的O(1)调度：新调度器中的每个算法都能在常数时间内完成，无论运行的进程数量如何。 实现完美的SMP可扩展性：每个处理器都有自己的锁和独立的运行队列。 实现改进的SMP亲和性：尝试将任务分组到特定的CPU上，并继续在那里运行它们。只有在运行队列大小不平衡时才将任务从一个CPU迁移到另一个CPU。 提供良好的交互性能：即使在系统负载较大的情况下，系统也应立即响应并调度交互式任务。 提供公平性：任何进程都不应在合理的时间内被剥夺时间片。同样，任何进程都不应获得不公平的高时间片。 针对只有一个或两个可运行进程的常见情况进行优化，同时能够很好地适应具有多个处理器且每个处理器上有许多进程的情况。 The Big Picture # 下图简要展示了O(1)调度器的核心数据结构，以及调度一个任务执行时大致的工作过程。
1）本质上O(1)调度器也是一个支持多优先级的多级反馈队列，结构组织上也是从高优先级到低优先级，每个优先级都有一个队列，其中保存该优先级的任务。2）调度时从高优先级到低优先级队列逐个检查，优先调度高优先级进程来执行，保证公平性。3）同时通过优先级确定其时间片，时间片执行完后就继续调度其他低优先级进程继续执行，避免饿死。4）不同进程的交互性不一样，调度器会给予不同的奖励和惩罚，表现就是动态优先级的差异，根据动态优先级计算出的时间片长短的差异。
工作原理剖析 # 如何调度1个任务 # 1、O(1)调度器会为每个CPU创建一个运行队列（分active和expired）和单独的spinlock（尽量减少操作时锁竞争）。
2、每个运行队列都会根据优先级组织成多级队列的形式，每个优先级从高到低都有对应的一个保存任务的queue，保存属于该优先级级别的进程。
3、而进程启动时都有设置静态优先级（nice值），调度器将其放入对应优先级的队列中。在运行过程中调度器也会根据进程优先级、是否是交互程序、执行时间、睡眠时间等计算其动态优先级。调整优先级后将其放入对应优先级的任务队列中。
4、当一个进程的状态发生变化时，如开始执行IO操作从Task_RUNNING变为TASK_UNINTERRUPTIBLE状态时，或者说它的优先级发生变化时，调度器会根据其优先级将其放入相应的运行队列中。
5、调度器寻找下一个可执行的进程时，始终首先从高优先级队列开始检查是否有可运行的进程，从而体现公平性。为了高效地识别出可运行的最高优先级的可运行进程，O(1)调度器使用位图（bitmap）来跟踪每个优先级对应的任务队列的状态。位图 bitmap[priorityLevel]==true指示运行队列中某个特定优先级级别的任务列表中是否包含任何可运行的进程。这使得调度器能够快速识别出哪个高级别的队列中具有可运行的进程。
ps：对位图进行查找从而找到对应的最高优先级的队列的这个操作，可以通过一些特殊的指令来加速，比如：x86 bsfl, PPC cntlzw，其他架构下也有对应的指令。
6、确定了最高优先级运行队列后，调度器选择该运行队列中的第一个进程，并安排其执行。每个队列都有一个指向第一个进程的队首指针，可以迅速确定可运行的第一个进程。被调度的进程，会从运行队列中移除，并且调度器更新位图以反映运行队列状态的变化。
7、通过使用这种方法，O(1)调度器实现了常数时间的调度操作。无论系统中的进程或任务数量如何，找到最高优先级任务和调度任务的时间复杂度保持不变。这使得高效且可扩展的调度成为现实，使其适用于具有大量进程的系统。
任务在队列中移动 # O(1)调度器使用的runqueue是个支持优先级的多级任务队列，本质上还是个多级反馈队列。意味着其优先级会被调整，任务会在多个队列中移来移去，这也是为了解决公平性、交互性方面的问题。
1、如果一个进程P刚开始处于最高优先级队列中，它的时间片为T，如果P被调度了，其执行一段时间后，假设时钟中断来，调度器需要检查是否应该调度另一个进程时。
如果发现P仍然是当前最高优先级的进程，且其时间片没有用完，那么会继续执行P； 如果发现有更高优先级的进程等着被调度，且支持抢占的话，那么P可能会被抢占； 2、实际上P在执行的过程中，它的优先级是会被动态调整的，比如它做了些IO类的操作：
执行IO密集型操作，恢复后时间片T没耗光，内核会认为这是一个响应式任务，会奖励它，优先级会被调高； 执行IO密集型操作，恢复后时间片T耗光，会认为这不是一个响应式任务，会惩罚它，优先级被调低或者没变化； 执行CPU密集型操作，会认为这不是一个响应式任务，会惩罚它，优先级被调低或者没变化； 3、当其优先级调整后，它就会被移动到对应优先级的任务队列中，等待下一轮被调度。</description></item></channel></rss>