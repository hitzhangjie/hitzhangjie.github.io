var suggestions=document.getElementById('suggestions'),search=document.getElementById('search');search!==null&&document.addEventListener('keydown',inputFocus);function inputFocus(a){a.ctrlKey&&a.key==='/'&&(a.preventDefault(),search.focus()),a.key==='Escape'&&(search.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(c){const d=suggestions.classList.contains('d-none');if(d)return;const a=[...suggestions.querySelectorAll('a')];if(a.length===0)return;const b=a.indexOf(document.activeElement);if(c.key==="ArrowUp"){c.preventDefault();const d=b>0?b-1:0;a[d].focus()}else if(c.key==="ArrowDown"){c.preventDefault();const d=b+1<a.length?b+1:b;a[d].focus()}}(function(){var a=new FlexSearch.Document({tokenize:function(a){return a.split(/\W+/).concat(a.replace(/[\x00-\x7F]/g,'').split('')).filter(a=>!!a)},cache:100,document:{id:'id',store:["href","title","description"],index:["title","description","content"]}});a.add({id:0,href:"/journey/education/education/",title:"教育经历",description:'“教育经历"',content:"   时间段 阶段 学校 专业方向     2013.9~2016.7 研究生 四川大学 计算机应用技术,网络安全   2009.9~2013.7 本科 哈尔滨工业大学 计算机科学与技术,软件工程    求学历程是人生的一个阶段，是努力迈向下个阶段的新起点\n生活中处处有学问，工作中也不乏有价值的问题，多思考多实践 🎶\n"}),a.add({id:1,href:"/journey/education/hit/",title:"本科教育",description:"xxx.md # ",content:"xxx.md # "}),a.add({id:2,href:"/journey/introduction/",title:"本节介绍",description:"在这里记录下日常生活中的所思、所想。\n写什么呢？随便写，目的是和自己对话。",content:"在这里记录下日常生活中的所思、所想。\n写什么呢？随便写，目的是和自己对话。\n"}),a.add({id:3,href:"/journey/education/scu/",title:"研究生教育",description:"研究生教育",content:"我是怎么去读研的？ # 考研 or 华为 # 13年考研时，我心里其实没有很明确的目标，要读个什么方向，或者要去哪里工作。考研之前，很多同学都去参加秋招了，东奔西跑的，那时候华为来校园招聘，我也不想东跑西跑的，于是就近参加了华为的校招，一个下午过完几轮面试，当天晚上发了Offer。\n自己当时在软件、计算同学里面算是学的比较好的，尤其是专业课方面，好几个保研的同学平时做课设、实验都是我指导的，也没什么需要遮遮掩掩的不是。我那时候就是贪玩，心里还想着考研，但是准备的也不是特别认真，也没参加过考研辅导班培训，总之最后340+，但是有一门卡小线，不要我。\n那个时候真的是很单纯，跟面试官说我要考研，可能会违约，但是面试官还是给了我Offer，劝我考虑下去华为这样的平台锻炼，对我帮助可能更大。我选择南研所的时候，还劝我要不要优先考虑深圳。现在来了深圳工作几年之后，真的是有点后悔当年的选择啊！\n调剂 or 华为 # 13年考研成绩出来后，发现没过，我看了下考上的能报的方向，心里松了口气，我想学的安全方向早就被保研的占满了，考上了也是选其他方向，自己也不是很感兴趣，那就准备工作吧。后面安心做毕设了，直到有一天四川大学图像所老师给我电话，看到了我填过的一则调剂信息，问我要不要去试试。就去了四川成都，第一天面完图像所，图像所老师觉得我挺不错，想留我，带我看他们图像所实验室，确实很棒啊。第二天看到网络安全实验室也有调剂信息，我又去面了下，结果网络安全方向（有3个实验室）、数据挖掘方向的几个老师也想要我。\n选择其实挺重要的，我当时放弃了上面所有机会，选了另一个实验室的导师。导师出国做访问学者了，开学后才见到，导师是挺厉害，只是他回国后自立门户了，我也就基本没接触到安全相关的太多东西，有也是自己瞎琢磨。导师也挺负责，找项目给自己锻炼，找机会让自己带团队，也挺感谢老师的。自己也有时间学了点自己感兴趣的东西，但是，弯路的确没有少走，如果早点工作的话，可能对自己提升会更快。当然，我依旧对这段经历心怀感激，好的坏的，它都让我有所收获。\n那时候还是有点书生气吧，想在学校里多待几年，父母虽不懂但也支持我继续，最后就和华为办了违约。因为这事吧，我在心里一直是高看华为一眼，平时也关注华为的动态，如果可以希望以后有机会吧。\n研究生是怎么过的？ # 成都，真的是个挺不错的城市，我也很想写点自己当时在成都的生活体悟，就借着这个机会瞎写写吧。\n成都确实很安逸 # 第一次去成都就是考研调剂的时候，当时去一个小馆子里面吃饭，老板端上来一“桶”米饭，我可没那么多钱啊，北方一碗米饭要1￥吧。当即问老板，吃不了这么多啊……原来是随便吃的意思 :)\n四川大学是综合性大学，和我们哈工大这类工科院校不同，我最大的感受就是，校园里活动比较丰富，各专业交织碰撞的气息更浓厚一点，妹子也比较多。\n说到这里，想起一个真实的笑话，我一个哥们说他们班开学前，看名单有两个妹子，结果开学后一个妹子直接没来只剩一个妹子。就是男女比例极不协调，连我们计算机专业也算上吧，一个班3~4个妹子，每次一上大课的时候，男同学们挤在一起说哪个妹子好看，尼玛，连班主任都批我们班男生不给力，自己班妹子被追走了也看不住 :(\n在学校里面，大部分都是学生，川大不一样，开放式校园，各色年龄段的人进进出出，让自己感觉从威海环翠区海滨校园一下子到了一个开party的小乐园，一出太阳后就能看到七老八少的人在草坪上晒着太阳玩耍聊天喝茶，但是看到都会感觉很开心。在深圳苦逼的我，已经很久没有体会到这种感觉了。\n成都，吃的、玩的、喝的、蹦的，都挺多的。\n  这个火锅就不说了，什么串串之类的，我对吃没研究，但是看到别人吃（比如我老婆）我也是很开心的。我最喜欢的就是炸土豆，在成都养成的习惯，走到一个城市去玩，先要探索下这里有没有卖炸土豆的。以至于在深圳腾讯上班，去麦当劳我总是固定的点7号套餐，有薯条啊。\n  成都，给我感觉比较深的就是，它作为西部核心城市，既有它现代化的一面（能想象吗，18条地铁线覆盖的二线城市，互联网大厂基本都有分公司在成都），也有它散发着浓郁历史气息的一面。对历史人物、文物、自然遗产的保护比较好。就是你想浪有可以让你低头的现代化城市群，你想雅也有让你自知文化沉淀不足的文化遗产。\n  喝的，有啥，茶吧，小酒馆吧，九眼桥酒吧一条街吧。能代表成都人的，我也不敢说很了解，但我感觉应该是喝茶吧，一群人喝个茶，吹吹水皮，聊聊八卦，开心啊。当年我们导师就喜欢喝茶，和我们聊很久。\n  蹦的，酒吧还挺多的，喝多了也不好，不过成年人喝多了也可以理解当年九眼桥的事，自己的事自己负责就好了，没什么可以嚼的。但是像小酒馆这样的，倒是可以多一点，还挺好玩的。成都这几年的文化作品也是比较出彩，《成都成都》、《哪吒》等等吧。难道人真的安逸些更容易出好作品？\n  有的时候我会想，要是把成都地皮硬搬到东部沿海，就可以打完美了，主要是我比较喜欢看海。这是大学时养成的习惯，喜欢跑环海路，喜欢闻海水腥味，喜欢吹海风。虽然成都深处内陆，但是现在看来，依然是屈指可数的超高性价比的城市。\n享受学习过程 # 说起我这段时间的学习，是比较自由的，除了每个周末给老师发邮件、周一和老师开会以外，其他的时间基本可以自由支配。因为我导师也是单干嘛，没有实验室打开的一些硬性要求。想去图书馆也行，想帮其他老师打打杂也行，我们也有实验室，只不过在江安校区了。曾经有段时间老师问我们愿不愿意搬过去住，我们都觉得脱离自己的学生圈子不太好，于是作罢。\n基本上，我每天都是在图书馆度过，这种感觉超棒的。图书馆旁边也有一些小吃，所以午饭、晚饭基本可以就近解决，味道也不错，不用跑来跑去把时间浪费在路上，很多时候可以在图书馆一待待一天。\n我比较喜欢拿个电脑直接到计算机相关的书架旁边学习，有遇到一些什么问题的时候，在书架上走走就能找到相关的资料，可能一本书的作者描述的不容易懂，可能另一本书中描述的就清楚一点。有时候闲逛，看到些没接触过的或者眼前一亮的东西，也容易开阔下思路。\n当然了，除了学习，也还是要看论文、跟技术、做项目的，导师给我们定了一个书单，要求我们这些是基础，说实话，毛德操老师的《Linux内核源码情景分析》现在我都没完全看完，部头太大了，但是写的是真好。\n导师其实对我们挺好的，也会指点我们，也会找机会带我们出去锻炼、去企业参观（国家电网、华为之类的），也会指出我们的不足。应该是我们被社会捶打的少吧，有时候被导师批一下。\n总体而言，在川大学习感受还可以，坏的也有就不值得单独拎出来说了，其他学校也有。\n协作酸甜苦辣 # 跟着导师做项目的时候，有那么一个学校的项目，基本上算是我是负责人在推动，然后和几个师兄弟宝蓝了从设计、开发、人力、测试、文档、客服一条龙，导师也给了一些非常好的指导，特别是和需求方沟通、进度把控方面。\n回想起以前做一些大作业、课程设计、毕业设计之类的，基本上都是我带别人做，工程量也不是很大，实在不行我直接撸了给大伙讲一讲也可以了，顶多多讲两遍，顶多嗓子讲的不舒服了。\n这次不行，工程量有点大，从原型设计、web、app、后台、测试、bug跟踪都需要做，人力又不够，客观说当时有几个同学的工程能力要稍微欠缺点，后面锻炼了一段时间后能上手了。但是代码的可测试性、可读性都很差，我刚开始有段时间会找出他们的问题给他们解释清楚，他们陆陆续续明白后修改。后面有些说了也不明白，纯凭经验干活。有的时候赶进度，遇到bug，我会把他们的代码备份后直接重写。很粗暴。\n其实这样是不好的，慢慢我也体会到了，如果觉得自己能力比较强一点，或者强一些、强很多，这个前提下，如果不注意带动周围人提升，以后自己就会比较累。因为你总感觉别人干的不好，你要亲自撸袖子干，工程量小可以，工程量大了也是于事无补的。\n所以后面，自己经常写文档，分享给他们看。也搭建了buggenie，专门在上面贴自己挖出的bug、原因、解决方法，后面大家习惯了，也在上面贴bug、原因、解决方法，慢慢地就好了很多。\n有那么一段时间，我很郁闷，歇了几天，我的同学们和导师汇报的时候玩笑似的说我最近没提交代码，导师找我面谈，还批了我一顿，我的g，我一个周末可以撸完他们一周的工作量。休息几天而已，而且也存在功能上的依赖。导师其实是想让我们保证进度，帮另外几个同学的模块加快点进度，我当然是愿意，问题是别人代码写的不好但是现在动力很足的时候，我上去重写或者开始当老师也似乎不是很好。\n后面开始想怎么解决这个问题，就是开始关注代码review。那时的review也不是现在PreMerge阶段review，review通过再合入，也比较原始，就是大家写完了，trunk提交了，晚上我会统一和昨天的对比下，代码量可能会有点多，但是因为是单体服务，各个需求场景逻辑也清晰，很容易看清楚逻辑有没有问题。\n又这么坚持了一段时间，感觉师兄弟多少在工程能力方面有了点提升，刚开始磨合的时候很痛苦，后面大家在一起都很拼、互相帮助、共克时艰 :)\n有一次，第二天就是项目演示了，会议很重要，我们全部通宵加班联调，人力不够真的是赶进度，师兄弟们还有一个女同学哦，挤在一个出租屋里奋战一晚，其实也有很多次周六周日在毕加索度过的。\n后面我也很认可这几个同学了，可能工程能力和我有差距，但是在做事上还是很靠谱的。团队中不可能每个人都是一样的，比如都是爱钻研技术的，团队里面需要各种角色的人，大家各自发挥自己的长处，磨合好，团队就会获得一个方向一致的合力，而不是各自力量相互抵消。\n准备参加工作 # 准备毕业找工作的时候，开始没好好准备，在放假去老婆家玩的火车上、玩的路上完成了Alibaba的面试，拿了Offer，但是评级不太好。这种情况下，可能很多人会选择去阿里吧，我咨询过阿里出来的李智慧老师，他也建议我去。后面，我想了想，还是想看看自己到底学的怎么样，证明一下自己嘛，就准备了一段时间去参加其他公司校招。\n去哪儿、新浪、华为、腾讯，拿到腾讯Offer的时候，我就不打算面其他的了，去哪儿给的评级应该比较好，几个同拿到Offer的里面薪资最高的，新浪的面试官说我是那两天面过的里面最好的，直言说可以和hr谈薪水，不行他可以和hr商量。华为我就是陪同学去的，机试题我一看都要吐了，研究生了还在做我本科阶段做的算法题。腾讯的面试官，我感觉整个流程下来是效率最高的，哦，不对，去哪儿是最高的，当天就给了Offer，腾讯和其他几家比是效率最高的。\n 去哪儿，打算去的，后面不久就除了新闻，说去哪儿和谁合并，怎么怎么的，最后没去； 新浪，效率太低，可能跟他们965有关系？不知道，但是隔了好多天才最终发Offer； 但是，那天我已经准备寄三方给阿里； 腾讯，过了后，我想着要不不去阿里了，部门主管沟通后，还是来了腾讯；  工作这些年，说真的，企业、企业之间的不同点在哪里呢？真的仅仅是业务线吗？我认为从75分做到90分到100分，甚至更高，有一项东西一定是绕不过的，就是企业文化。\n企业文化，真的不是空口白话，一家企业做的好的话，它会把公司的价值观通过各个产品直达用户，用户从产品中能真切感受到这家企业的韧劲。\n 你比方说阿里的店小二 你比方说正直的腾讯鹅 你比方说狼性的华为 \u0026hellip;  没有店小二的卖力，哪里有那么多五湖四海的回头客？没有正直的腾讯鹅，你们谁敢qq、微信消息发不停？没有狼性的华为，哪里敢在通信领域那么有底气？\n工作好几年，工作中虽然也有不尽如人意的地方，但是总的来说是好的。也不用再去多想当初的选择对或者错，选择错误其实何尝不是一种成长，失去某些东西的时候，你也会在反思怎么从其他地方赢回来。\n"}),a.add({id:4,href:"/tags/bpf/",title:"bpf",description:"",content:""}),a.add({id:5,href:"/categories/",title:"Categories",description:"",content:""}),a.add({id:6,href:"/tags/ebpf/",title:"ebpf",description:"",content:""}),a.add({id:7,href:"/categories/ebpf%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5/",title:"ebpf原理及实践",description:"",content:""}),a.add({id:8,href:"/tags/ftrace/",title:"ftrace",description:"",content:""}),a.add({id:9,href:"/tags/gofuncgraph/",title:"gofuncgraph",description:"",content:""}),a.add({id:10,href:"/tags/",title:"Tags",description:"",content:""}),a.add({id:11,href:"/tags/trace/",title:"trace",description:"",content:""}),a.add({id:12,href:"/tags/uftrace/",title:"uftrace",description:"",content:""}),a.add({id:13,href:"/blog/2023-09-25-%E8%A7%82%E6%B5%8Bgo%E5%BA%94%E7%94%A8%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8go-ftrace/",title:"观测Go应用函数调用：go-ftrace",description:"go-ftrace 是一个基于Linux bpf(2) 的类似内核工具 ftrace(1) 的函数调用跟踪、耗时统计工具，它主要是面向go应用程序的。",content:"go-ftrace # go-ftrace 是一个基于Linux bpf(2) 的类似内核工具 ftrace(1) 的函数调用跟踪、耗时统计工具，它主要是面向go应用程序的。\n限制: 因为设计实现的原因，当前go-ftrace只支持满足如下限制条件的go程序跟踪、统计：\n Linux内核：支持 bpf(2) 和 uprobe 的Linux内核 处理器架构: x86-64架构（little-endian字节序） 二进制程序：只能是go ELF可执行程序（非PIE模式），未剔除符号表.symtab，未剔除调试信息.(z)debug_info，  使用方式 # 项目中提供了测试程序 examples/main.go ，可以执行如下几种测试来了解go-ftrace的使用:\n示例1: 跟踪一个自定义函数 main.add: ftrace -u main.add ./main 示例2: 跟踪所有的匹配函数 main.add*: ftrace -u 'main.add*' ./main 示例3: 跟踪多个模式匹配的函数 main.add* 或 main.minus*: ftrace -u 'main.add*' -u 'main.minus*' ./main 示例4: 跟踪一个自定义函数 \u0026quot;main.add 以及 内置函数 runtime.chan*: ftrace -u 'main.add' -u 'runtime.chan*' ./main 示例5: 跟踪一个自定义类型的方法: ftrace -u 'main.(*Student).String ./main 示例6: 跟踪一个自定义类型的方法，并试图提取关心的参数: ftrace -u 'main.(*Student).String' ./main \\ 'main.(*Student).String(s.name=(*+0(%ax)):c64, s.name.len=(+8(%ax)):s64, s.age=(+16(%ax)):s64)'  示例目录下同时提供了一个 examples/Makefile, 你也可以执行 make \u0026lt;target\u0026gt; 来快速执行对应的命令（对应上面示例）来进行测试.\nps: 你可以在启动被测试程序 ./main 之前或者之后启动 ftrace，两种方式都可以正常工作，这主要是跟ebpf程序的加载、触发机制有关。\n安装方法 # 方式1 # 首先编译安装到 $GOBIN 或者 $GOPATH/bin，注意将 $GOBIN，$GOPATH/bin 设置到程序搜索路径 PATH 中。\ngo install github.com/hitzhangjie/go-ftrace/cmd/ftrace@latest  bpf tool require special permission, so we need run ftrace as root, like sudo ftrace ..., and we must make sure ftrace is searchable by sudo, so link it to the searchpath by sudo\nbpf程序的加载、执行需要特殊的权限，为了方便测试，我们先使用 sudo 来执行 sudo ftrace ...，由于 sudo 对安全性有要求， 为了执行 sudo ftrace 时能正常搜索到 ftrace，现在还需要添加个软链到 /usr/sbin/。\nsudo ln -s ~/go/bin/ftrace /usr/sbin/  经过这些设置后，就可以通过 sudo ftrace ... 对程序进行跟踪了:\nsudo ftrace -u 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire' ./a.out  方式2 # 为了简化安装，项目根目录下也提供了一个 Makefile 文件，可以执行 make \u0026amp;\u0026amp; make install 来完成安装。\n使用案例 # 你可以将其用于go程序的函数调用关系的跟踪，以及耗时相关的统计观测。\n以下面的示例代码为例（详见 examples/main.go），说明下工具的使用、执行效果：\nfunc main() { for { doSomething() } } ... func doSomething() { add(1, 2) minus(1, 2) s := \u0026amp;Student{\u0026quot;zhang\u0026quot;, 100} fmt.Printf(\u0026quot;student: %s\\n\u0026quot;, s) time.Sleep(time.Second) }  如果我们要观察函数 doSomething 执行过程中的函数调用关系，以及耗时情况，我们可以这样做：\nsudo ftrace -u 'main.*' -u 'fmt.Print*' ./main \\ 'main.(*Student).String(s.name=(*+0(%ax)):c64, s.name.len=(+8(%ax)):s64, s.age=(+16(%ax)):s64)'  ftrace 将输出如下信息，从中可以看到：\n 函数启动、停止时的绝对时间 函数执行的耗时信息，单位“秒(s)” 函数定义所在的源码位置 函数被发起调用时的位置 函数指令数据末尾的偏移量 想获取的函数参数信息  $ sudo ftrace -u 'main.*' -u 'fmt.Print*' ./main 'main.(*Student).String(s.name=(*+0(%ax)):c64, s.name.len=(+8(%ax)):s64, s.age=(+16(%ax)):s64)' WARN[0000] skip main.main, failed to get ret offsets: no ret offsets found 14 uprobes, large number of uprobes (\u0026gt;1000) need long time for attaching and detaching, continue? [Y/n] \u0026gt;\u0026gt;\u0026gt; press `y` to continue y add arg rule at 47cc40: {Type:1 Reg:0 Size:8 Length:1 Offsets:[0 0 0 0 0 0 0 0] Deference:[1 0 0 0 0 0 0 0]} add arg rule at 47cc40: {Type:1 Reg:0 Size:8 Length:1 Offsets:[8 0 0 0 0 0 0 0] Deference:[0 0 0 0 0 0 0 0]} add arg rule at 47cc40: {Type:1 Reg:0 Size:8 Length:1 Offsets:[16 0 0 0 0 0 0 0] Deference:[0 0 0 0 0 0 0 0]} INFO[0002] start tracing ... 23 17:10:59.0888 main.doSomething() { main.main+15 /home/zhangjie/github/go-ftrace/examples/main.go:10 23 17:10:59.0888 main.add() { main.doSomething+37 /home/zhangjie/github/go-ftrace/examples/main.go:15 23 17:10:59.0888 main.add1() { main.add+149 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:10:59.0888 main.add3() { main.add1+149 /home/zhangjie/github/go-ftrace/examples/main.go:40 23 17:10:59.0888 000.0000 } main.add3+148 /home/zhangjie/github/go-ftrace/examples/main.go:46 23 17:10:59.0888 000.0000 } main.add1+154 /home/zhangjie/github/go-ftrace/examples/main.go:33 23 17:10:59.0888 000.0000 } main.add+154 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:10:59.0888 main.minus() { main.doSomething+52 /home/zhangjie/github/go-ftrace/examples/main.go:16 23 17:10:59.0888 000.0000 } main.minus+3 /home/zhangjie/github/go-ftrace/examples/main.go:51 23 17:10:59.0888 main.(*Student).String(s.name=zhang\u0026lt;ni, s.name.len=5, s.age=100) { fmt.(*pp).handleMethods+690 /opt/go/src/fmt/print.go:673 23 17:10:59.0888 000.0000 } main.(*Student).String+138 /home/zhangjie/github/go-ftrace/examples/main.go:64 23 17:11:00.0889 001.0002 } main.doSomething+180 /home/zhangjie/github/go-ftrace/examples/main.go:22 23 17:11:00.0890 main.doSomething() { main.main+15 /home/zhangjie/github/go-ftrace/examples/main.go:10 23 17:11:00.0890 main.add() { main.doSomething+37 /home/zhangjie/github/go-ftrace/examples/main.go:15 23 17:11:00.0890 main.add1() { main.add+149 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:11:00.0890 main.add3() { main.add1+149 /home/zhangjie/github/go-ftrace/examples/main.go:40 23 17:11:00.0890 000.0000 } main.add3+148 /home/zhangjie/github/go-ftrace/examples/main.go:46 23 17:11:00.0890 000.0000 } main.add1+154 /home/zhangjie/github/go-ftrace/examples/main.go:33 23 17:11:00.0890 000.0001 } main.add+154 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:11:00.0890 main.minus() { main.doSomething+52 /home/zhangjie/github/go-ftrace/examples/main.go:16 23 17:11:00.0890 000.0000 } main.minus+3 /home/zhangjie/github/go-ftrace/examples/main.go:51 23 17:11:00.0891 main.(*Student).String(s.name=zhang\u0026lt;ni, s.name.len=5, s.age=100) { fmt.(*pp).handleMethods+690 /opt/go/src/fmt/print.go:673 23 17:11:00.0891 000.0000 } main.(*Student).String+138 /home/zhangjie/github/go-ftrace/examples/main.go:64 23 17:11:01.0895 001.0005 } main.doSomething+180 /home/zhangjie/github/go-ftrace/examples/main.go:22 ... \u0026gt;\u0026gt;\u0026gt; press `Ctrl+C` to quit. INFO[0007] start detaching detaching 16/16  致谢 # 该项目fork自 jschwinger233/gofuncgraph, 在此基础上做了一些优化、bugfix相关的工作来改善工具的易用性、健壮性。\n感谢原作者的贡献!\nps：如果你对C/C++/Rust/Python相关的ftrace工具感兴趣的话，可以了解下 namhyung/uftrace，如果你对内核的ftrace工具感兴趣，可以了解下 kernel ftrace。\n"}),a.add({id:14,href:"/blog/2023-09-15-ebpf%E6%A1%88%E4%BE%8B%E5%8F%8A%E5%88%86%E6%9E%90gofuncgraph/",title:"eBPF案例及分析：gofuncgraph",description:"可观测性（observability）是这几年开始被频繁提及的一个词，特别是在微服务领域可观测性已经成为了微服务治理的一项关键的平台化技术手段，在CNCF孵化的项目中我们看到Opentelemetry如火如荼的发展背后也逐渐出现了一些成熟的解决方案。在腾讯内部也有类似天机阁、蓝鲸、wxg等不同的解决方案。这些往往配合框架解决了微服务RPC层面 的可观测性问题，实际上借助eBPF这项革命性技术，我们还可以做更多。",content:"前言 # 可观测性（observability）是这几年开始被频繁提及的一个词，特别是在微服务领域可观测性已经成为了微服务治理的一项关键的平台化技术手段，在CNCF孵化的项目中我们看到Opentelemetry如火如荼的发展背后也逐渐出现了一些成熟的解决方案。在腾讯内部也有类似天机阁、蓝鲸、wxg等不同的解决方案。这些往往配合框架解决了微服务RPC层面 的可观测性问题，实际上借助eBPF这项革命性技术，我们还可以做更多。\n背景 # 不久前，在做一个关于序列化方面的优化工作，先说下项目情况：项目中使用的go框架采用了pb+protoc-gen-gogofast来生成桩代码，RPC通信的时候使用pb序列化。另外呢，为了方便开发人员查看pb message对应的log信息，项目的日志库使用了pbjson将pb message格式化为json后输出到log，RPC interceptor也会使用相同的方式序列化req、rsp后将其上报到链路跟踪系统。\n大致就是这样一个问题，当时对比了pbjson序列化、stdlib encoding/json序列化，segmentio/encoding/json序列化，以及bytedance/sonic序列化。哈哈，这个顺序其实就是由慢到快的一个顺序，bytedance/sonic凭借优化反射、simd等技术“遥遥领先”其他集中方案。除了benchmark的手段，我还想看看上线前后的一些详细的优化效果，比如不同包大小（比如按1KB分桶）的序列化耗时（纳秒）分布。\n摆在我面前有两个办法：\n 改源码，统计下序列化前后的执行耗时，然后打log，写个工具分析下log； 改源码，统计下序列化前后的执行耗时，然后上报到监控，看看统计直方图；  其实都可以，但是我有点懒，我既不想去改源码（更不用说改很多）去写log、报监控，分析完了还需要再把这堆代码删掉。改完代码我还需要编译、发布，我们每次编译发布流程都要10min左右，我很不想去干这些事。\n总之我既想要灵活的分析工具（能灵活指定函数名称），又不侵入业务代码，调研之后发现有开发者实现了这样的工具，jschwinger233/gofuncgraph，它借鉴了内核函数图跟踪工具ftrace的设计，执行效果大致如下。借助funcgraph，很快解决了我的问题。\n工具介绍 # gofuncgraph是借鉴了Linux内核函数图工具ftrace（function tracer）的功能，然后为go程序开发的一个函数图工具，如上图所示，你可以指定要跟踪的函数的匹配模式，然后该工具会将程序中匹配的函数名全部作为uprobe去注册，并注册上对应的回调处理函数。\n处理函数中会根据是进入函数、退出函数来生成一些这样的events，每个event都有时间，这样就可以准确统计出函数的执行耗时了。然后利用调用栈信息，也可以绘制出函数调用图。最终输出上述函数图。\n 一个小插曲，help: how to use gofuncgraph，最开始我以为是要用这个工具去启动个程序才可以执行测试，是我理解有误。和作者沟通过程中，作者提到之前阅读过我写的调试器相关的电子书，并说质量很高。大家互相分享互相学习，挺好的。现在我也来学习作者的gofuncgraph，除了学习ebpf程序的写法外，我也想了解下为什么调试器的知识会用在这个程序里。\n 剖析实现 # 本节先介绍该工具的用户界面设计实现，然后再介绍其内部的工作逻辑，工作逻辑中会层层深入把必要的DWARF、eBPF、编译链接加载等相关的关键内容都逐一介绍下。\n为了后续方便自己学习、维护、定制，我fork了作者的项目并做了一些优化、重构，如使用spf13/cobra来代替了原先的命令行框架，spf13/cobra支持长、短选项，对用户更友好。另外也对项目代码进行了一些可读性方面的优化。后续介绍将继续我修改的这个版本介绍 hitzhangjie/gofuncgraph (dev)。\n命令行界面 # 执行 gofuncgraph help 查看帮助信息，简要介绍了它的用途，你可以执行gofuncgraph --help来查看更完整的帮助信息。\n简要帮助信息：\n$ ./gofuncgraph bpf(2)-based ftrace(1)-like function graph tracer for Go! for now, only support following cases: - OS: Linux (always little endian) - arch: x86-64 - binary: go ELF executable built with non-stripped non-PIE mode Usage: gofuncgraph [-u wildcards|-x|-d] \u0026lt;binary\u0026gt; [fetch] [flags] Flags: -d, --debug enable debug logging -x, --exclude-vendor exclude vendor (default true) -h, --help help for gofuncgraph -t, --toggle Help message for toggle -u, --uprobe-wildcards strings wildcards for code to add uprobes  详细帮助信息：\n$ ./gofuncgraph --help gofuncgraph is a bpf(2)-based ftrace(1)-like function graph tracer for Go! here're some tracing examples: 1 trace a specific function in etcd client \u0026quot;go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire\u0026quot; gofuncgraph --uprobe-wildcards 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire' ./binary 2 trace all functions in etcd client gofuncgraph --uprobe-wildcards 'go.etcd.io/etcd/client/v3/*' ./binary 3 trace a specific function and include runtime.chan* builtins gofuncgraph -u 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire' -u 'runtime.chan*' ./binary 4 trace a specific function with some arguemnts gofuncgraph -u 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire(pfx=+0(+8(%ax)):c512, n_pfx=+16(%ax):u64, m.s.id=16(0(%ax)):u64 )' ./binary Usage: gofuncgraph [-u wildcards|-x|-d] \u0026lt;binary\u0026gt; [fetch] [flags] Flags: -d, --debug enable debug logging -x, --exclude-vendor exclude vendor (default true) -h, --help help for gofuncgraph -t, --toggle Help message for toggle -u, --uprobe-wildcards strings wildcards for code to add uprobes  这里使用spf13/cobra来组织程序cmd、选项管理、帮助信息查看，说下参数设计吧：\n -d，主要是为了gofuncgraph执行时打印更多的调试信息 -x，主要是为了将vendor包中定义的函数给排除掉 -h，查看详细帮助信息 -u，指定要添加uprobe探针的用户态函数名的匹配模式，支持多个，支持同时获取函数参数信息，-u是必填选项。  如何自定义帮助信息，可以改写rootCmd.Short和rootCmd.Long，这样就可以了。\n如果提前熟悉spf13/cobra的话，要实现上述功能就很简单、敲一会键盘就搞定。\n查找待跟踪函数 #  加载elf文件构造elf.File对象 遍历elf.symtab中的每个symbol 检查sym中 ST_TYPE==函数类型的symbol 检查symbol.Name是否匹配 --uprobe-wildcards|-u来决定是否要跟踪 检查命令行参数中的fetch中的函数名。如果指定了函数名那么最终就只输出该函数的信息，反之就输出\u0026ndash;uprobe-wildcards匹配的所有的函数信息。  到这里，要跟踪的函数已经基本确定下来了。\n执行uprobe注册 #   检查命令行参数中的fetch中的函数参数读取规则（实际上是和上一步同时完成的）。生成参数值提取的规则，实际上寄存器操作、栈操作的序列，这个序列能得到一个内存有效地址。读取该地址处的、指定数据类型大小的数据，就相当于读取出了参数值。\n  将筛选出来的函数名、入口地址、返回地址等封装下交给uprobe去注册。咦，怎么没有像BCC+Python那样显示注册handler呢？作者是用Cilium来开发的，Cilium有自己的类似注解的宏，它是能知道添加uprobe时如何知道handler的。\n  执行uprobe回调 #  当对应的uprobe被触发就会执行注册的回调函数，也是用C语言实现的。 作者将其编译为ebpf后（格式为*.o）通过//go:embed嵌入到go中的[]byte全局变量中，然后再将其提交到ebpf子系统。 回调函数就是将收到的通知转换为一个处理事件event，里面包含了一些区分是进入函数、退出函数的标识，以及时间戳、goid、ip等寄存器信息，交给个chan去处理。  处理uprobe回调 #  有个eventmanager不断地poll其中的event并进行处理，也就是说去根据这个去计算每个函数的调用栈、每个函数的执行开始时间、结束时间信息。 最后再显示到命令行输出界面上。  本文小结 # 至此就介绍了gofuncgraph的工作原理。gofuncgraph输出的函数调用栈信息，要通过DWARF .debug_frame来确定调用栈信息，所以这里又是一个DWARF的使用场景。\n"}),a.add({id:15,href:"/tags/observability/",title:"observability",description:"",content:""}),a.add({id:16,href:"/tags/bcc/",title:"bcc",description:"",content:""}),a.add({id:17,href:"/blog/2023-09-15-ebpf-bcc%E6%A1%86%E6%9E%B6helloworld/",title:"eBPF BCC框架：helloworld",description:"目前写eBPF程序的话，一般要通过C语言来写，python、golang写的都是用户态的部分，涉及到内核部分的操作都是要借助C语言来写，然后通过编译器将C部分编译成字节码，用户态部分只是借助bpf()系统调用将字节码程序提交给了eBPF子系统去运行。本文就结合BCC框架+Python来写一个简单的helloworld，来熟悉下ebpf程序的写法。",content:"怎么写eBPF程序 # 目前写eBPF程序的话，一般要通过C语言来写，python、golang写的都是用户态的部分，涉及到内核部分的操作都是要借助C语言来写，然后通过编译器将C部分编译成字节码，用户态部分只是借助bpf()系统调用将字节码程序提交给了eBPF子系统去运行。\n实际上任何高级语言都可以写用户态部分，但是写内核态部分的eBPF程序需要写C语言，编译器会将C语言部分编译成target=ebpf的字节码，所以现在有很多框架比如BCC+python以及Cilium+golang等，都是对eBPF字节码操作、系统调用操作的一些封装。\nps：如果你是用Rust的话，那么确实可以直接写eBPF程序，不用依靠C，一般常用的是Rust aya这个框架。\n从0开始写eBPF程序 # 前面多次提到了eBPF程序编写、执行的大致过程，但是介绍的还是太粗略了，也不打算在这么几个简单的总结性文档中，把细节都介绍清楚。\n我们可以先看下，如果手把手从0开始写eBPF程序，大致需要经历哪些操作，看图：\n![Go](assets/2023-09-15-eBPF BCC框架：helloworld/go.png)\n需要被简化的一些操作：\n 用C语言先写eBPF程序，然后使用编译器（如clang）将其编译为target为bpf的字节码程序，然后通过系统调用将其提交给eBPF子系统执行。这一步如果没有BCC这样的框架封装下的话，那么操作起来就有一点啰嗦。 还有你编译eBPF程序时要用到的很多头文件之类的设置，可能就比较麻烦。 还有eBPF程序执行时，那些结果存储到不同的数据结构，和不同语言的类型系统如何对接，如何方便的读取，全部自己从0开始搞也很麻烦。 其他的；  所以现在有BCC、Cilium、Aya这样的一些eBPF框架来简化这一些工作，我们可以先从BCC开始，这个项目比较早、成熟，用的人也多，也被集成到了Linux YUM源中，可以直接安装bcc、bcc-tools包来尝鲜。\n从helloworld开始 # 现在就开始使用BCC来写几个helloworld，让大家了解下一个简单的eBPF程序大致是如何写的，熟悉下其结构，后面虽然不一定自己写，但是了解已有的这些工具的实现细节，以及如何调整来满足自己需要，还是有帮助的。\nfile: helloworld.py\n#!/usr/bin/python3 from bcc import BPF program = r\u0026quot;\u0026quot;\u0026quot; int hello(void *ctx) { bpf_trace_printk(\u0026quot;Hello World!\u0026quot;); return 0; } \u0026quot;\u0026quot;\u0026quot; b = BPF(text=program) syscall = b.get_syscall_fnname(\u0026quot;execve\u0026quot;) b.attach_kprobe(event=syscall, fn_name=\u0026quot;hello\u0026quot;) b.trace_print()  分析下其结构：\n 导入bcc中的bpf program是一段c语言程序，b = BPF(text=program)，我们执行这个脚本时bcc框架会自动将其编译为字节码 它定义了一个hello函数，bpf_trace_printk会向ebpf子系统中的一个临时文件或者什么数据结构中打印hello world字符串 syscall = b.get_syscall_fnname是获得exeve函数调用的一个hook point b.attach_kprobe是在execve这个系统调用入口处通过kprobe系统调用创建一个探针，当执行到这里时会触发trap，内核会回调函数hello去执行，这里的hello就是上面C语言中定义的函数 b.trace_print会从取出前面打印的hello world字符串取出来打印出来。  这就是一个极简的helloworld的示例，当我们执行它时，它就会跟踪所有的execve的系统调用，每次触发这个系统调用时，就会打印上述helloworld字符串信息。\nps：执行ebpf程序时，需要使用root权限。\n执行上述示例 # ebpf程序运行需要用到debugfs，这个需要先挂载下，然后再执行，会看到打印很多helloworld：\nroot $ sudo mount -t debugfs debugfs /sys/kernel/debug root $ ./helloworld.py b' \u0026lt;...\u0026gt;-14182 [004] d...1 89191.905245: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14184 [001] d...1 89191.913364: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14183 [005] d...1 89191.913975: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14185 [005] d...1 89193.942389: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14187 [002] d...1 89193.951579: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14186 [001] d...1 89193.952179: bpf_trace_printk: Hello World!'  系统中很多地方都会执行系统调用execve，比如执行shell命令ls，shell会先创建子shell然后execve替换text为ls的text（指令），所以这里也是会触发打印helloworld。\n本文小结 # 本文介绍了下ebpf程序开发的一个大致过程，以及结合BCC+Python给了一个简单的helloworld的实例，这个实例过于简单但是能让读者知道大致的过程。后面会结合一个具体的案例gofuncgraph来详细介绍ebpf程序开发。\n"}),a.add({id:18,href:"/blog/2023-09-15-ebpf%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5%E4%BB%80%E4%B9%88%E6%98%AFebpf/",title:"eBPF原理及实践：什么是eBPF",description:"eBPF是一项革命性的内核技术，它允许开发人员编写自定义的代码，然后被内核动态加载后执行，以此来改变内核的执行行为。它的这个特点能够帮助实现高性能网络、更好的可观测性、更细致的安全分析工具。本文先介绍下ebpf是什么，也是作者学习过程中的一点总结。",content:"eBPF是一项革命性的内核技术，它允许开发人员编写自定义的代码，然后被内核动态加载后执行，以此来改变内核的执行行为。它的这个特点能够帮助实现高性能网络、更好的可观测性、更细致的安全分析工具。\neBPF的前身：bpf # 1、eBPF的前身是bpf（BSD Packet Filter），最早它在1993年论文中有Lawrence Berkeley National Laboratory的Steven McCanne和Van Jacobson提出，它是一种类似字节码虚拟机的东西，有自己的指令集，你可以通过它来编写程序然后交给这个小的虚拟机去执行，这个指令集非常像汇编。比如你可以用它来写包过滤的逻辑（接受或者拒绝一个网络分组）。在这篇论文中可以找到其他一些更加复杂的示例程序，论文名：The BSD Packet Filter: A New Architecture for User-level Packet Capture。\n2、1997年，Linux内核版本2.1.75首次引入了BPF，BPF也就开始成为了Berkeley Packet Filter的简称，主要用在tcpdump这些工具中来实现高效的网络包的跟踪。\n3、时间快进到2012年，Linux内核版本3.5中引入了seccomp-bpf，它能够控制是否允许用户态应用程序执行系统调用，举个例子，我们启动一个docker容器，如果不添加特殊的选项控制，在docker容器内部去调试程序的时候是执行不了的，因为Linux系统中程序调试需要利用系统调用ptrace，但是ptrace往往都是被默认不允许的，发挥作用的就是seccomp-bpf，这里有一篇文章介绍了seccomp+ptrace调试原理的文章：https://zhuanlan.zhihu.com/p/606317619。seccomp-bpf是首次开始将bpf从包过滤这个范畴开始向其他范畴扩展。到今天发展到eBPF这个阶段，其实与最早的“包过滤”已经没有多大关系了。\n从BPF到eBPF # 随着BPF在Linux内核中的演进，到了2014年，从版本3.18开始可以使用eBPF将来称呼这项技术，全程就是extended BPF，这包含了几个比较明显的改变：\n BPF指令级对64位机器做了高度的优化，解释器也基本上重写了； eBPF中增加了maps，BPF程序执行时可以访问它记录一些数据，这些数据可以在BPF程序间共享，也可以允许用户态程序访问它获取结果； 增加了bpf()系统调用，用户态程序通过它可以和eBPF程序进行交互，比如加载到内核、从内核卸载、访问maps数据等； 增加了bpf_这样的一些helper函数； 增加了eBPF程序验证器，验证安全的程序才可以被执行；  这是eBPF首次正式放出，但是不是结束，此后就开始了它的快速发展之路。\neBPF到生产系统 # 这里介绍下eBPF技术演进过程中的一些关键事件：\n 2005年Linux中就引入了特性kprobe，它允许在任意指令地址处设置trap，当执行到此处时允许回调用户自定义的函数。开发人员可以编写内核模块，将其中的函数设置为kprobe的回调以执行调试。 ps: 调试器一般也是使用这种指令patch的方式，区别在于kprobe回调函数是内核处理的，而调试器tracee执行时触发断点是内核通过信号通知tracer由tracer来执行的。 2015年的时候允许将eBPF程序连接到kprobe，kprobe可以回调eBPF程序了，这使得在Linux中tracing变得简单，为了更好的追踪Linux内核网络栈的各类事件，Linux中开始增加各种hooks允许eBPF程序进行更细致的观测。 2016年，Netflix的工程师Gregg大佬公开了他和团队在eBPF基础上的大量性能观测工具及实践，让基础设施、运维领域认识到了eBPF在这方面的巨大潜力。 2017年，Facebook开源了Katran这个基于eBPF的高性能L4负载均衡器，也是这一年，Liz Rice这位女强人对此也产生了浓厚的兴趣，并开始研究。 ps: Liz Rice 经常做些技术方面的分享，目前是 the chief open source officer with eBPF specialists at Isovalent, 也是 the Cilium cloud native networking, security and observability project 的创建者. 2018年，Netflix、Meta的几个工程师为Linux eBPF做了大量贡献，使得eBPF成为了Linux内核的一个独立子系统，同年BTF（bpf type format）成为了ebpf的格式类型，使得ebpf程序更加兼容。 2020年，Linux内核支持了LSM BPF允许将eBPF程序和Linux安全模型LSM（Linux Security Model）连接起来，这意味着eBPF的用途又进一步清晰了、扩大了，就是安全工具、网络、可观测性。 近些年，更是有越来越多的项目诞生，cilium、aya等等，很多开发者都对此做出了贡献，业界的实践也越来越多、越来越成熟。  起名有点难 # 到现在的话，ebpf中的字母e已经没有太大意义了，它已经不仅仅是对bpf的扩展了，它成为了一个独立的子系统。现在提起ebpf的时候，有些人也会用bpf来称呼。但是在Linux内核中，包括操作ebpf程序的系统调用bpf()以及相关的helper函数bpf_xxx，都是直接以bpf来称呼的，这说明Linux内核开发人员已经认可了bpf来代指ebpf，它的含义已经变了，直接代指这个子系统了。但是在Linux内核社区外，还有些人会使用ebpf来称呼，比如ebpf.io这类站点。\neBPF诞生崛起的原因 # 前面的介绍，让大家知道了ebpf演进过程中的一些关键事件，不禁要问为什么它会诞生？或者说它有哪些优点？\n关心点：内核系统调用 # 大家对Linux内核可能比较陌生，但是对操作系统应该不陌生，毕竟大学都学过。用户程序在执行某些操作时，离不开操作系统的支持，操作系统充当的就是用户程序、硬件之间的一个服务人员，用户程序和服务人员之间传话的窗口就是syscall（系统调用）。\n通常用户程序，并不会直接使用系统调用，或者说直接调用的场景比较少，大家一般是通过标准库或者其他库函数的方式来间接使用系统调用。以golang为例，所有网络层面的系统调用都被封装到了标准库net中。\n系统调用，比大家的认识可能要复杂些，它包括阻塞性系统调用、非阻塞性系统调用，不同系统调用对程序执行的影响是不一样的，所以go为什么是一门工程化很好的语言，就是它在运行时层面屏蔽了这些，即使某个线程因为系统调用阻塞了，程序还可以继续跑。\n因为系统调用如此重要，开发人员会想知道程序中到底在执行哪些系统调用，此时就会借助strace之类的一些工具来跟踪、统计系统调用的执行情况，这样我们能更好了解程序的执行情况。\n困难点：内核增加功能 # Linux内核的代码规模已经达到了3kw+了，相当大的规模了，如果自己不是Linux内核开发人员或者说对感兴趣的模块不是不熟悉，你很难去修改它的。即使你修改了还要考虑另一个问题，你可能只解决了在你这个情景下、平台下的问题，但是Linux内核是一个通用操作系统，意味着我们的修改可能不一定能解决其他情景、平台下的问题。往往你修改个东西，要经过社区、Torvalds的同意才行，这个周期会非常常。根据统计，Linux内核社区贡献的所有patches也就只有1/3能够进入主线。\n即使进入了这个主线，可能已经过去一段时间了，你还要考虑发行版的问题，因为我们大部分开发人员、企业使用的都是某个发行版，发行版使用的内核版本又不一样了，什么时候主线代码被发行版使用了发布了，你才能考虑升级机器上的操作系统。这里就又过去一段时间了。\n也就是说，即使你发现内核代码有缺陷，或者想做功能扩展，即使你很有能力开发内核代码（大部分开发估计并不擅长还是需要多年沉淀才行），即使被合入主线、被发行版使用、机器也顺利升级了，但是时间不等人，这种方式满足不了需求方快速变化的需要。\n困难点：内核模块扩展 # 内核开发人员可以考虑通过内核模块的方式（但是开发内核模块也比较困难），来代替直接修改内核代码贡献到上游这个方式，这个路子更敏捷更快，时间成本大大缩短。\n内核模块也可以动态加载、卸载，不需要升级系统时停止机器。\n但是内核模块的安全性一直是大家比较担心的：\n 它运行在特权用户级别， 这个模块经过大家充分CR吗，有漏洞吗，会给攻击吗 这个作者值得信任吗 这个模块万一有bug会影响到整机稳定性吗  大家对于内核模块的使用慎之又慎，eBPF通过验证器来尽可能保证字节码程序的安全性，至少不会影响到内核本身的健壮性。又可以独立开发的方式来增强内核功能、快速响应需求变化，相比之下就有很大的吸引力。\n优势：eBPF程序动态加载 # ebpf程序支持动态加载、移除，不需要升级内核来获得要扩展的特性，也不需要重启机器来应用这些特性，这对于进行性能方面的观测、实现并应用安全工具就非常好。\n优势：eBPF程序的高性能 # ebpf程序（可能用c写、用rust写），写完的ebpf程序会被编译器编译为target为ebpf的字节码程序，被ebpf子系统加载后会被JIT（即时编译器）编译为机器指令，执行的是机器指令。\nebpf程序最终执行时，可以最小化用户态、内核态的频繁切换、减少上下文切换的开销，数据记录在ebpf maps，用户程序要获取数据就从ebpf maps中取。\n所以ebpf程序的性能是比较高的。\n优势：云原生领域 # 在云原生领域，ebpf这种对业务代码无侵入、无需编排配置的方式，使得它在可观测性等方面具有很大的优势。\n之前大伙也是一般通过sidecar（边车）模式来增强pod的功能，比如logging、trcacing等，servicemesh也会通过sidecar实现network的能力，sidecar有它的灵活性和优势，但是也有它的局限性：\n 添加sidecar时，要使其生效（如果一开始忘了加），pod必须整个重启； 需要修改k8s的编排配置的yaml来增加这个sidecar，尽管这个过程功过鼠标勾勾点点就可以、配置是自动化的，但是如果不小心勾选错误还是不会被织入这个sidecar； pod内如果有多个容器，有可能是需要指定启动顺序的，否则可能会发生竞态条件或者故障发生，这样的话也意味着pod启动更慢； servicemesh中通过sidecar来实现network的功能，所有的网络流量都需要经过一个pod中网络代理容器的中转，这增加了传输延迟，影响网络性能；  这些问题也确实是sidecar模式的一些问题，幸运的是ebpf作为一种平台能力，就可以比较好的解决这些问题。\n本文小结 # 这里介绍了什么是ebpf，包括它的前身、演进的一些关键过程，以及相对于传统的方式，当我们希望做些可观测性、内核功能增强、缺陷修复时相比修改主线内核、写内核模块所具有的一些优势。然后，如果能将ebpf作为一种平台能力进行建设，这将使得在可观测性、安全工具、网络性能优化方面做出一些比较大的效果，不管你的机器是裸金属机器、虚拟机，还是容器化应用，它都能统统搞定，而且不需要你侵入业务代码、部署配置也不需要重启机器、pod。\n"}),a.add({id:19,href:"/tags/checklist/",title:"checklist",description:"",content:""}),a.add({id:20,href:"/tags/linux/",title:"linux",description:"",content:""}),a.add({id:21,href:"/blog/2023-09-08-linux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A560s/",title:"Linux性能问题排查60s",description:"最近再阅读Gregg大佬著作《BPF Performance Tools》，其中一小节作者提到了其在Netflix工程团队中践行的一个性能排查checklist，当遇到Linux性能问题时，前60s往往是借助这个checklist来进行排查，如果有必要，缩小范围后再借助其他工具进行进一步排查。我觉得这个简短的checklist还挺实用的，特地摘录出来分享下。",content:"简介 # 最近在阅读Gregg大佬著作《BPF Performance Tools》，其中一小节作者提到了其在Netflix工程团队中践行的一个性能排查checklist，当遇到Linux性能问题时，前60s往往是借助这个checklist来进行排查，如果有必要，缩小范围后再借助其他工具进行进一步排查。我觉得这个简短的checklist还挺实用的，特地摘录出来分享下。\n问题背景 # 这个checklist可以用来指导排查任意Linux性能问题，当我们知道有台机器性能（疑似）有问题时，我们就可以登录这台机器，按照这个checklist来进行前60s的快速分析。这也是Gregg自己以及Netflix工程团队实践中总结出来的。\n对于很多刚入行后台开发的同学而言，我觉得这个还是比较有价值的，应该在日常工作中不断实践、不断加深对性能影响因素的理解。有位技术扎实的同事曾经这样说，一切都是可计算的、可量化的，比如判断对特定工作负载瓶颈是什么，cpu、内存、网卡？链路长短，网络延迟，然后大致的系统吞吐量是什么样的？他大致就能推算出来。\n其实，Jeff Dean曾经在论文里给出过一些开发人员应该知晓的latency数据：\nL1 cache reference ......................... 0.5 ns Branch mispredict ............................ 5 ns L2 cache reference ........................... 7 ns Mutex lock/unlock ........................... 25 ns Main memory reference ...................... 100 ns Compress 1K bytes with Zippy ............. 3,000 ns = 3 µs Send 2K bytes over 1 Gbps network ....... 20,000 ns = 20 µs SSD random read ........................ 150,000 ns = 150 µs Read 1 MB sequentially from memory ..... 250,000 ns = 250 µs Round trip within same datacenter ...... 500,000 ns = 0.5 ms Read 1 MB sequentially from SSD* ..... 1,000,000 ns = 1 ms Disk seek ........................... 10,000,000 ns = 10 ms Read 1 MB sequentially from disk .... 20,000,000 ns = 20 ms Send packet CA-\u0026gt;Netherlands-\u0026gt;CA .... 150,000,000 ns = 150 ms  有开发者将上述数据进行了可视化，以方便从视觉上更直观的感受差别：\n如果一直关注性能领域，实践一段时间后就大约能摸到门道了，还是很有帮助的。当我们遇到性能方面的问题后，经验会帮助我们更快速地认识到哪些地方可能出了问题，排查反而可能只是印证思路的过程。\n我们今天重点讨论对于任意Linux性能问题（可能也不是熟悉的系统），应该如何排查的问题，尤其是最开始的60s应该如何快速定位缩小问题域。\nLinux 60s分析 # 这个checklist不是一个大杂烩，不是列举一堆工具，它是工程团队沉淀的经验。\n uptime dmesg | tail vmstat 1 mpstat -P ALL 1 pidstat 1 iostat -xz 1 free -m sar -n DEV 1 sar -n TCP,ETCP 1 top  下面一个个解释下其输出的含义，以及可以帮助确定哪些问题。\nuptime # $ uptime 17:07:46 up 18:27, 0 users, load average: 0.08, 0.02, 0.01  uptime可以查看机器上线时间、平均负载的变化，看性能问题主要是看平均负载的变化。load average有3个值，从左到右分别表示最近1min、5min、10min的负载变化，因此可以看出最近一段时间的负载是上升、下降还是持平。\n如果看到15min负载是比较高的，但是最近1min负载比较低或者正常，说明负载已经降下来了，我们登录机器太晚了。一般企业会考虑容错，出问题的机器会被自动剔除掉。如果需要进一步分析，就需要借助其他办法来排查了，比如时光机atop或其他性能观测平台。\n 负载，指的是待调度执行的进程数（包括可运行和陷入不可中断睡眠的进程）。因此，如果数值超过cpu核数时就可能意味着cpu饱和了。\n dmesg | tail # 如果进程使用内存超过限制，或者机器整体内存紧张而oom killer选中了该进程被kill掉的话，其log信息会写入系统日志中，可以直接cat /var/log/messages查看，也可以通过dmesg来查看。\n对于一个拥有64GB机器的我来说，想要轻松复现一个oom kill的demo，还需要思考下。ulimit -v, ulimit -m, control group限定内存大小，不知道为何，这几个方法并不会直接导致oom killer介入并杀死进程，跟它们之间的工作机制有关系，暂不讨论。\n启动一个容器 docker run -it --rm -m 100m golang:latest /bin/bash，里面写一个go，通过选项-m 100m限定了容器中所有进程的最大内存上限。启动后写一个go程序，循环分配内存并提交，如：\nfunc main() { for { b := make([]byte, 1\u0026lt;\u0026lt;20) b[0] = 1 } }  编译并关闭GC运行：\n$ GOGC=off ./app` Killed  容器就是普通进程，只不过是通过Linux namespaces+controlgroup等进行了一些列的隔离、控制，在宿主机上运行dmesg | tail就可以看到进程被kill的信息。\n$ dmesg | tail [69826.948539] [ 23658] 0 23658 3594 754 69632 344 0 bash [69826.948799] [ 23882] 0 23882 1260354 22707 8851456 25101 0 main [69826.949060] [ 23908] 0 23908 14443 619 147456 134 0 top [69826.949335] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=93a579dd93754105f6650187e2ba12e40911e028bd01ce85e24277e59166e3c8,mems_allowed=0,oom_memcg=/docker/93a579dd93754105f6650187e2ba12e40911e028bd01ce85e24277e59166e3c8,task_memcg=/docker/93a579dd93754105f6650187e2ba12e40911e028bd01ce85e24277e59166e3c8,task=main,pid=23882,uid=0 [69826.950308] Memory cgroup out of memory: Killed process 23882 (main) total-vm:5041416kB, anon-rss:90828kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:8644kB oom_score_adj:0 [70504.061676] docker0: port 1(veth791efaa) entered disabled state [70504.062119] veth39cc165: renamed from eth0 [70504.195179] docker0: port 1(veth791efaa) entered disabled state [70504.197296] device veth791efaa left promiscuous mode [70504.197814] docker0: port 1(veth791efaa) entered disabled state  对于有些进程跑着跑着不见了，可以优先考虑是不是oom kill了，dmesg就是个好办法，它能输出进程被kill时的一些信息，如内存使用量之类的。\n Linux如何选定一个进程进行oom kill可以详细了解下这背后的决策过程，不完全不严谨的可借鉴的总结就是，整机内存紧张，如果某个进程运行时间不久但是占用内存高，其oom score分值就越大，越大的越容易被kill。时光机atop也可以看到进程被kill的信息。\n vmstat 1 # zhangjie@PC-GeniusStation gotest $ vmstat 1 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 2476 26154180 577756 4476564 0 0 2 9 3 11 0 0 100 0 0 0 0 2476 26154184 577756 4476564 0 0 0 0 28 766 0 0 100 0 0 0 0 2476 26154184 577756 4476564 0 0 0 52 21 738 0 0 100 0 0  vmstat表示虚拟内存统计细腻系，参数1表示1s钟打印一次统计信息。比较有参考价值的几列数据：\n  r：正在运行的进程数+可运行等待执行的进程数，不包含等待IO的进程数，这个值比top和uptime总的load average更能反映CPU的饱和情况，因为它不包含IO进程，这样如果这个值比真实CPU核数多的话，那就说明CPU饱和了。\n  free：空闲内存数量，单位KB，使用free -m可以以mb为单位显示。\n  si, so：swap-in、swap-out数量（换入、换出次数），如果这些值不是0，意味着内存不足了，因为换入、换出仅在内存不足时才会发生。注意这里的换入换出是虚拟内存层面的。以前RAM比较小，经常有交换区的概念，现在RAM更大更便宜了，用的就比较少了。比如以前4GB内存+320GB硬盘配置下经常建个4GB大小的swapfile，现在我机器光RAM就是64GB 😄\nps：磁盘数据加载到内存，先是触发pagefault，然后内存控制器捕获异常后交给内核进行pages加载，也有叫法叫换入。注意这些术语所指的区别。\n  us, sy, id, wa, st：这几个是将cpu时间进行了细化，分别表示用户态、内核态、空闲时间，以及io等待时间，被某些虚拟机或者Xen等虚拟化技术抢走的时间。\n  通过这里的数据可以看出大部分时间都是消耗在us（用户态），要进一步分析，就需要借助其他工具、方法，如go tool pprof对程序进行分析，可以通过cpu火焰图观察到不同代码时间占用情况。\nmpstat -P ALL 1 # $ mpstat -P ALL 1 Average: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle Average: all 3.14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 96.86 Average: 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 Average: 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 ... Average: 22 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ... Average: 30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 Average: 31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00  mpstat能够输出所有CPU核心的耗时，而且它当这个耗时在不同状态下的时间占比进行了区分，比如usr,sys,iowait,irq,soft,steal。\n在上图中，我们看到有个核心core-22的user占比为100%，说明很可能存在一个单线程程序存在cpu瓶颈。\n假设，iowait时间占比较高，就要考虑disk io是否存在瓶颈；如果sys时间占比过高，则可以借助syscall、kernel tracing、cpu profiling工具进行进一步分析。\npidstat 1 # Linux 5.15.90.1-microsoft-standard-WSL2+ (PC-GeniusStation) 09/08/2023 _x86_64_ (32 CPU) 06:45:10 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:11 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:12 PM 1000 11479 1.00 0.00 0.00 0.00 1.00 22 pidstat 06:45:12 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:13 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:14 PM 1000 11480 65.00 0.00 0.00 0.00 65.00 22 main 06:45:14 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:15 PM 1000 11480 100.00 0.00 0.00 0.00 100.00 22 main  pidstat能显示每个进程的cpu使用情况，也会将cpu使用时间细化成user,system,guest,wait，和top不同的是，它显示的是随着时间推移进程cpu使用率情况发生变化的信息，不变化的就不输出了。\n上面这个例子显示有个pid=11480的进程，它的cpu使用率逐渐从1%上升了65%，又上升到了100%。因为这里我写了一个死循环的程序来测试。\niostat -xz 1 # $ iostat -xz 1 Linux 5.15.90.1-microsoft-standard-WSL2+ (PC-GeniusStation) 09/08/2023 _x86_64_ (32 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.04 0.00 0.03 0.00 0.00 99.93 Device r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util loop0 0.04 0.00 3.30 0.00 0.00 0.00 0.00 0.00 0.79 0.00 0.00 92.27 0.00 0.29 0.00 loop1 0.02 0.00 1.60 0.00 0.00 0.00 0.00 0.00 0.21 0.00 0.00 70.95 0.00 0.42 0.00 loop2 0.06 0.00 4.02 0.00 0.00 0.00 0.00 0.00 0.23 0.00 0.00 71.93 0.00 0.37 0.00 sda 0.02 0.00 0.99 0.00 0.01 0.00 28.05 0.00 0.16 0.00 0.00 64.08 0.00 0.66 0.00 sdc 1.85 0.49 30.38 18.33 0.35 1.62 15.84 76.73 0.14 5.17 0.00 16.40 37.28 0.67 0.16 sdb 0.01 0.01 0.07 1.46 0.00 0.36 26.15 97.29 1.01 1.35 0.00 8.56 147.50 2.96 0.01 sdd 0.01 0.24 0.61 245.70 0.00 0.06 4.82 20.85 0.31 0.81 0.00 51.18 1010.66 4.47 0.11 sde 0.42 0.09 14.12 1.02 0.16 0.16 27.21 64.33 0.17 5.39 0.00 33.34 11.27 0.25 0.01 avg-cpu: %user %nice %system %iowait %steal %idle 3.12 0.00 0.00 0.00 0.00 96.88  这个工具显示的事存储设备的IO统计信息，输出的信息有点多、有换行的情况，其中值得关注的列：\n r/s, w/s, rkB/s, wkB/s：表示每s读请求数、写请求数、读数据量KB、写数据量KB。磁盘IO导致的性能问题，从这些很容易看出是读还是写导致的。 await：平均IO等待时间，包括请求IO排队时间+IO服务时间，总之就是程序感受到的IO等待时间。如果该值比平均时间大的话，那么可能就有可能是设备IO饱和、设备出问题的征兆。 avgqu-sz：发送给IO设备的平均请求数量，如果这个值明显大于1，就很可能表示是设备饱和的情况（但是有些设备，比如虚拟设备，它后面可能对应着多个磁盘，这个时候是因为并发请求多个磁盘，大于1是正常的）。 util：设备利用率，表示设备繁忙程度，1s内设备有多长时间在执行IO任务，不是表示设备容量使用百分比。如果这个值超过60%就要警惕可能会导致比较差的性能，100%则表示设备饱和。  free -m # $ free -m total used free shared buff/cache available Mem: 31964 1479 24351 5 6134 30030 Swap: 8192 2 8189  这个工具大家应该比较熟，它能显示内存总量、已使用量、空闲内存的情况，几个大家可能不熟悉的提一下。\n  shared表示tmpfs的内存占用量，通常比较小，一般/run, /sys, /tmp, /dev/shm虚拟文件系统会使用tmpfs。\n  buff/cache表示kernel使用的buffer、cache大小，这部分内存在需要时可以回收给应用程序使用的，内核使用它们主要是为了改善性能。\n ps：free命令输出中的buff/cache列显示的是被内核缓冲区和页面缓存所占用的内存量，它主要包括以下几类信息的缓存:\n  磁盘块缓存(disk cache):对磁盘IO进行缓存,避免每次从磁盘读取数据。这部分是文件系统对磁盘内容的缓存。\n  inode和dentry缓存:文件系统元数据的缓存,如文件名、索引节点数据等。避免查找元数据时总是访问磁盘。\n  目录缓存:目录文件内容。\n  进程执行代码的缓存:已执行的代码可以被缓存复用。\n  页面缓存:文件 mmap 到内存的页面缓存。\n  网络缓冲区:网络数据通过socket接收时的缓冲区。\n  键值对缓存:一些数据结构如散列表的缓存。\n  其他数据结构缓存:例如进程信息、文件描述符。\n  所以简单说,buff/cache列主要反映了内核对文件系统、磁盘内容、网络数据、元数据等各类数据的缓存占用内存量。这些缓存可以加速访问速度。\n   total=used+free+shared+buff/cache，available是一个估计值，表示当前有多少内存供应用程序使用。\n  sar -n DEV 1 # $ sar -n DEV 1 Linux 5.15.90.1-microsoft-standard-WSL2+ (PC-GeniusStation) 09/08/2023 _x86_64_ (32 CPU) 07:32:46 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 07:32:47 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:47 PM eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:47 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 07:32:48 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:48 PM eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:48 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 07:32:49 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:49 PM eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  sar工具有很多统计模式，网络、磁盘、cpu等等，这里是用来查看网络相关的数据。通过rxkB/s、txkB/s可以查看到网络收发速率，可以评估是否达到了网卡的瓶颈。\nsar -n TCP,ETCP 1 # $ sar -n TCP,ETCP 1 07:35:03 PM active/s passive/s iseg/s oseg/s 07:35:04 PM 0.00 0.00 0.00 0.00 07:35:03 PM atmptf/s estres/s retrans/s isegerr/s orsts/s 07:35:04 PM 0.00 0.00 0.00 0.00 0.00 07:35:04 PM active/s passive/s iseg/s oseg/s 07:35:05 PM 1.00 0.00 2.00 3.00 07:35:04 PM atmptf/s estres/s retrans/s isegerr/s orsts/s 07:35:05 PM 0.00 0.00 0.00 0.00 0.00  这里使用sar来查看TCP连接、TCP错误相关的数据，有这么几列：\n active/s：表示每s本地主动发起的tcp连接数量； passive/s：表示每s本地被动接受建立的tcp连接数量； retrans/s：表示每妙tcp重传次数；  主动连接数和被动连接数有助于对工作负载进行区分，重传表示存在网络问题或者远程主机问题。\ntop # $ top top - 19:42:37 up 21:02, 0 users, load average: 0.00, 0.03, 0.32 Tasks: 15 total, 1 running, 14 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.2 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 31964.6 total, 24348.5 free, 1479.7 used, 6136.4 buff/cache MiB Swap: 8192.0 total, 8189.6 free, 2.4 used. 30030.2 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 2324 1712 1600 S 0.0 0.0 0:00.01 init(OracleLinu 4 root 20 0 3392 456 68 S 0.0 0.0 0:19.65 init 960 root 20 0 2340 112 0 S 0.0 0.0 0:00.00 SessionLeader 961 root 20 0 2340 120 0 S 0.0 0.0 0:00.00 Relay(962) 962 root 20 0 732512 27996 15856 S 0.0 0.1 0:02.83 docker-desktop- 979 root 20 0 2340 120 0 S 0.0 0.0 0:00.00 Relay(980) 980 zhangjie 20 0 769360 44228 27924 S 0.0 0.1 0:05.90 docker 1066 root 20 0 2340 112 0 S 0.0 0.0 0:00.00 SessionLeader 1067 root 20 0 2340 120 0 S 0.0 0.0 0:00.03 Relay(1068) 1068 zhangjie 20 0 22736 8288 3376 S 0.0 0.0 0:00.07 bash 15621 root 20 0 2340 112 0 S 0.0 0.0 0:00.00 SessionLeader 15622 root 20 0 2340 120 0 S 0.0 0.0 0:00.00 Relay(15623) 15623 zhangjie 20 0 22604 8096 3288 S 0.0 0.0 0:00.02 bash 16263 zhangjie 20 0 55416 4216 3588 R 0.0 0.0 0:00.00 top 18683 root 20 0 2348 120 0 S 0.0 0.0 0:00.83 Relay(18684)  top可以一次性显示性能相关的负载情况、cpu、内存相关的数据。到这里，top显示的很多数据，在前面提及的工具中我们已经见过了，但是运行top来二次确认下系统、进程数据也是有用的。\ntop有几个比较实用的操作，可能大家不清楚的，也提一下：\n h，按下h唤出帮助菜单； c，显示完整的cmd，包含路径几参数信息 shift+m，按内存占用情况对进程列表进行排序 e，切换内存占用量的单位，kb、m、g O，自定义key=value进行过滤，如COMMAND=bash 1，显示每个处理器核心的负载信息 top -p  -H，可以显示每个进程下的线程信息  那，先执行top行不行呢，当然可以，实际上要定位到问题源头，你可能要把上述工具都跑一下，问题排查的过程就是一步步缩小问题范围的过程。\n在理解上，我们可以接受这样的一系列工具，去逐个执行下看看情况，但是在实践中，我们还是希望有更好用的工具，比如atop，它能在同一个程序中展示上述工具所能显示的所有数据（atop也会调用上述工具，比如sar）。\nLinux atop # atop被称作是Linux下的时光机，是因为它能定时借助sar等系列工具收集、统计、记录下系统的一些运行信息，比如某个时刻的负载情况、cpu、内存、网络、设备io等等的情况，甚至连oom kill这样的事件都会记录下来。\n至于它为什么被称为时光机，是因为它真的是时光机：\n atop -r path-to/hhmmss.log，每天的运行时数据都会记录在一个日志文件里，你可以加载当天、过去的日志数据，来查看当时发生了什么； t: 可以将时间往后拨，按t一次，就会快进1min； shift+t：可以将时间往前拨，按shift+t一次，就会倒退1min； b：seek到指定时间对应的数据，如b 20230908 12:00，那么就查看12点以后的数据； \u0026hellip; h：查看帮助菜单；  atop大而全，确实是一个让人喜欢的工具，但是它输出的信息太多，有可能让新手蒙圈，现在AI非常给力，可以直接让AI解释每个数据项的含义。\n 有了atop，你就不用担心“坏了，我没及时登机器，现场丢了”。\n 进一步分析排查 # 上述工具，并不是排查问题、解决问题的全部，是排查问题时的前60s的排查建议，我觉得这个checklist还是比较中肯的。\n当我们确定了问题大约在哪个范围之后，你就可以继续深入排查，以go开发为例：\n 比如是内存使用问题，就可以通过go tool pprof进行内存相关的采样、go tool trace查看内存GC MMU信息，进一步确定内存高占用的原因； 比如是cpu使用问题，就可以通过go tool pprof进行cpu采样，查看下热点代码路径； 如果是sys占用高问题，也可以查看是不是存在大量的syscall之类的； 如果是网络、磁盘IO、kernel……  当我们缩小问题范围后，就需要借助合适的工具进一步排查，这个过程可能是层层深入的过程，甚至于没有现成的工具供你使用。换言之，大佬们给我们传递的始终是方法学、解决问题的模式，具体到不同的问题本身还是要case by case的分析。\n有可能大佬们沉淀了一些工具给我们使用，比如本书《BPF Performance Tools》中介绍的BCC包中的大量基于ebpf的分析工具。但是仍然有可能你需要自己开发工具，现在基于ebpf你可以做的、探查的更深入、更多。\n本文总结 # 本文介绍了Gregg《BPF Performance Tools》中提及的Netflix工程团队Linux性能问题排查60s checklist，介绍了下其checklist中提及的工具及适用范围，也介绍了下作者本人工作期间常用的Linux时光机atop，最后引出了ebpf这个当前在可观测性领域大火的技术。\n后面有机会的话，也会就ebpf在可观测性领域的应用、开发实践进行介绍 😃\n"}),a.add({id:22,href:"/tags/perforamence/",title:"perforamence",description:"",content:""}),a.add({id:23,href:"/tags/tools/",title:"tools",description:"",content:""}),a.add({id:24,href:"/tags/littles-law/",title:"little's law",description:"",content:""}),a.add({id:25,href:"/blog/2023-04-18-netflix%E8%87%AA%E9%80%82%E5%BA%94%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4/",title:"Netflix自适应过载保护算法",description:"前面一篇文章介绍了排队论的知识，介绍了负载、RPS、Latency之间的关系，也介绍了传统的过载保护算法、分布式频控的过载保护算法，以及近些年Netflix、微信公开的基于Little's Law改进的过载保护算法。本文只讨论负载的评估，以及如何更好地实现scalable的过载保护算法，本文主要是基于Netflix公开的Netflix/concurrency-limits进行讨论。",content:"思路简介 # Netflix/concurrency-limits，基于Java实现的，star 2.9k+，也有go语言的第三方实现platinummonkey/go-concurrency-limits。\n平时大家评估服务负载、容量、最佳qps是如何做的，往往是先压测看服务能抗多少qps，然后请求方取个75%*qps作为一个阈值，然后请求方通过令牌桶、漏洞之类的来进行控制。但是对于很多个节点、需要动态扩缩容场景，这个固定值很快就会失效……当然有分布式频控的搞法……netflix的思路是与其将重点放在如何告知客户端设置qps，还不如让客户端能根据rtt自动算出下阶段的最大请求量来，这个是借鉴了little’s law以及tcp的拥塞控制。\n 它这里vegas算法估计的limit是这么算的 L * (1-minRTT/sampleRTT)， 然后还有个gradient2优化，来平滑下  详细设计 # 这个库提供了很多的limiter实现：\n  fixed，固定值，并发请求的时刻量不能超过这个fixedlimiter的值，这个值不变\n  aimd，基于loss的，请求成功就加性增，遇到失败就乘性减\n  windowed，基于滑动窗口实现的，每个窗口期内有一个limiter（成员delegate）,可以是前面提到的fixed、aimd等limiter\n  vegas，是基于测量的rtt的，另外也会考虑丢包。它实际上是确定了这么几个负载阶段：请求没有排队、请求有少量排队、请求有多一点排队、请求有很多排队。每次采样后会更新最新的limit，更新时会首先根据当前minRTT和sampleRTT以及当前limit来算一下接下里的queueSize，然后检查queueSize处于上面哪个阶段，然后使用对数操作进行平滑对当前的limit进行增大、缩小的调整。\n  gradient，它这里和vegas的实现思想上是一致的，只是对于inflight*2≥estimatedLimit时的处理逻辑不一样，vegas是将排队严重情况分成了几个阶段用不同的函数来调整limit，gradient是用了一个“梯度”的方法来调整，大致上是当前estimatedLimit * gradient + queueSize…这个算法的平滑处理能理解，但是不是那么“想象“象其效果。\n仔细看下，多揣摩几遍还是可以想象的出来的 😂\n  gradient2，它这里是对gradient的一个优化，什么优化呢？gradient是基于测量minRTT的，这会有个问题，minRTT还是比较敏感的，对于测量tcp的包（因为通常都会分片、分片大小往往都是确定的）没啥问题还挺好的。\n但是使用minRTT来测量RPC就不是特别好，因为RPC请求，不同接口的请求可能大小变化挺大的，即使是相同接口的请求可能变化也比较明显的。所以使用avgRTT要比minRTT更友好些，不至于limit的“抖动”，可能会导致过度的load shedding，造成不必要的请求被拦截。\n然后这里的avgRTT怎么算呢？从开始到现在的请求RTT的平均值？这里其实用的一个指数平均，一方面有平均值的作用能避免minRTT的上述问题；另一方面，使用的指数平均，0.8longtermRTT + 0.2sampleRTT，这样也能尽可能反映当前时刻的负载信息。\n另外这里的tolerance=2.0是说，如果遇到sampleRTT=tolerance*longtermRTT时，可以容忍这么长耗时的请求而不降低limit，仍然可以按照原速率发送，如果超了tolerance下的设置，那么梯度gradient就会小于1.0，此时limit就会被调低。limit调低时也会被smooth参数进一步平滑下。\n当从过载中恢复时，因为longtermRTT也被搞大了，如果不加处理，可能会有较长一段时间才能恢复到≤sampleRTT，这会有个问题，如果不能尽快恢复longtermRTT，则有可能持续增加发包速率再次导致过载。为了尽快恢复longtermRTT到正常值让发包速率处于steady状态，会判断longrtt / shortrtt\u0026gt;2时会给longrtt*0.95尽快调低longrtt。\n  调查总结 # 总结一下，vegas、gradient都是基于minRTT进行测量的，对于RPC场景而言可能并非最佳选择。相比之下gradient2是基于longtermRTT指数平均代替了minRTT，对RPC场景适应性可能更好。\n除了RTT，它们都考虑了负载steady、overload情况下的不同阶段以及调整策略（主要是increase limit、decrease limit时如何做到平滑）。可以测试下gradient2先有个直观认识。\n一点后话 # 当你的系统是一个大型的分布式系统，集群也需要动态扩缩容，系统中的负载类型不同，同一个服务的不同接口处理耗时不同，即便是相同接口不同请求处理耗时也有明显不同，这个时候常规的基于“请求配额”的传统过载保护机制是不怎么有效的。\n最初有这种想法，是在看点做内容处理链路的时候，注意到有些服务是计算密集型的（如OCR模块），有些是IO密集型的，有些图文发表请求里面只有一张图片，有的有多张图片，有的文章比较短，有的文章比较长，这都会影响你的系统负载、处理耗时，如何科学的评估负载进而确定合理的请求配额，是一件比较困难的事情。\n后面开始思考如何评估“负载”这样的问题，可能会想CPU使用率、内存使用率高、IO利用率高、网卡利用率高，实际上不同workload类型对资源的使用情况不同，这些指标高还真不一定就是负载高。如果涉及到具体语言，可能会去想Java、Go GC STW问题……\n预期纠结这些，不如更高屋建瓴地站在宏观角度看看，如果负载高了会发生什么？系统负载开始变高之后，是可以把其当做一个黑盒通过外部观测来观察出来的。Netflix的过载保护算法正是从这里触发，看似简单的实现，但是并不是不着边际。整个网络世界得以正常运转的TCP拥塞控制也是建立在RTT、Loss观测基础上的，Netflix也将其Vegas Limiter命名成了Vegas，正是因为它借鉴了TCP vegas拥塞控制算法（TCP Reno的替代算法）。\n"}),a.add({id:26,href:"/tags/overload-control/",title:"overload control",description:"",content:""}),a.add({id:27,href:"/tags/%E6%8E%92%E9%98%9F%E8%AE%BA/",title:"排队论",description:"",content:""}),a.add({id:28,href:"/tags/%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4/",title:"过载保护",description:"",content:""}),a.add({id:29,href:"/tags/ip-link/",title:"ip link",description:"",content:""}),a.add({id:30,href:"/tags/loopback/",title:"loopback",description:"",content:""}),a.add({id:31,href:"/tags/netem/",title:"netem",description:"",content:""}),a.add({id:32,href:"/blog/2023-04-14-%E5%8E%8B%E6%B5%8B%E4%B9%8B%E6%8E%A5%E5%8F%A3lo%E7%9A%84%E5%A6%99%E7%94%A8/",title:"压测之接口lo的妙用",description:"loopback接口大家都清楚，大致最初的认识就是可以通过localhost或者127.0.0.1来访问它，用来测试下网络协议栈是否能正常工作，如ping localhost，或者用来完成本地的服务器开发测试。但是由于它是一个虚拟接口，很多真实NIC存在的一些约束它是没有的，比如传输速率等，再比如网络中的传输时延等……本文结合笔者在日常开发中的一点实践，来进一步讨论下对loopback的妙用。",content:"问题背景 # 前一篇文章介绍了本地开发机压测时如何为每个待压测分配CPU资源（其实是taskset进行绑核，由于没有其他负载可以近似为分配CPU资源），本文继续介绍下如何让压测变得更真实一点，那就是网络IO这块，在本地通信时往往使用的是loopback接口，但是loopback并不是一个真实的网卡设备，它基本没有什么硬件网卡设备的传输速率的限制，也没有网络传输过程中的传输延迟。\n这样的话，我们在压测的时候，网络方面的开销就几乎体现不出来，比如说，你想看下在4g网络下客户端、服务器之间网络通信数据包多大时打开数据压缩更有价值……\n在我的测试过程中我希望能尽可能简化测试工作的同时，也能保证该有的环境的真实性，于是就有了本文对loopback接口的一点探索。\n认识本地lo # Linux中的Loopback接口是一个虚拟网络接口，允许在同一主机上运行的应用程序之间通信。它通常被称为“lo”接口，具有IP地址127.0.0.1。\nLoopback接口在内核中使用Loopback驱动程序实现，创建一个虚拟网络接口，并将所有传入的数据转发到本地协议栈。当一个应用程序将数据发送到loopback接口时，数据会被回送到协议栈，并像从另一个网络接口到达一样转发。 在Linux中，Loopback接口的一个重要用例是用于测试和调试网络应用程序。通过通过Loopback接口发送和接收数据，应用程序可以模拟网络流量，而不实际发送或接收来自物理或虚拟网络接口的数据。\nLoopback接口还由一些网络协议使用，例如Kubernetes kube-proxy IPVS，OSPF和其他需要在同一主机上的进程之间通信的网络相关软件。\n总之，Linux中的Loopback接口是一个虚拟网络接口，为在同一主机上运行的应用程序提供了一种通信通道。它在内核中使用Loopback驱动程序实现，并且在测试、调试和网络相关软件中具有许多实际用例。\n认识netem # 在 Linux 中，ip 命令中的 netem 是一个网络模拟工具。它允许您对网络连接进行各种修改，例如，添加延迟、丢包以及增加噪声等，以便在网络环境下测试应用程序的性能和稳定性。使用 netem 工具，您可以模拟各种不同的网络条件，包括高延迟、高带宽和低带宽等，以便更好地测试和优化应用程序在各种网络条件下的行为。\nNetem 已经成为 Linux 网络模拟和测试工具的标准选择之一，同时也是在诸如交换机、路由器和 WAN 加速器等网络设备上进行隔离测试和仿真时的一个有用工具。通过使用 netem，您可以更好地了解您的应用程序在不同网络条件下的行为，并且能够更好地进行演示和培训。\n利用本地lo # 如何使用netem让本地loopback接口更好地模拟真实网络情况呢？下面就来简单说一下。\n启用netem # 首先，需要启用内核模块netem：\nsudo yum install -y kmod sudo modprobe sch_netem  模拟网络延迟 # 然后，如果loopback接口的每次的收、发操作模拟一定的网络延迟：\nsudo yum install iproute-tc or sudo yum install iproute sudo tc qdisc add dev lo root netem delay 1ms  这样的话就相当于一个rtt增加了2ms，为了验证这个，你可以在执行上述模拟前后，分别看下ping localhost的延迟。\n模拟之前ping测试延迟：\nsh-4.2# ping localhost PING localhost (127.0.0.1) 56(84) bytes of data. 64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.033 ms 64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.090 ms 64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.047 ms ^C --- localhost ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2035ms rtt min/avg/max/mdev = 0.033/0.056/0.090/0.025 ms  模拟之后ping测试延迟：\nsh-4.2# sudo tc qdisc add dev lo root netem delay 1ms sh-4.2# ping localhost PING localhost (127.0.0.1) 56(84) bytes of data. 64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=2.04 ms 64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=2.04 ms 64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=2.17 ms ^C --- localhost ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2002ms rtt min/avg/max/mdev = 2.040/2.087/2.175/0.072 ms  ping包括数据发出去、收到回包两个动作，每个动作都引入了1ms的延迟，rtt增加2ms。\n模拟千兆网卡 # 然后，如果loopback接口传输数据时希望有一定的网卡传输速率限制：\nbash-4.2# sudo tc qdisc add dev lo root netem rate 1000mbit  然后你可以使用iperf来测试下是否真的是千兆网卡的传输速率，iperf起个server：\nbash-4.2# iperf -s  然后再iperf起个client，观察二者的输出统计：\nsh-4.2# iperf -c localhost ------------------------------------------------------------ Client connecting to localhost, TCP port 5001 TCP window size: 4.00 MByte (default) ------------------------------------------------------------ [ 3] local 127.0.0.1 port 37004 connected with 127.0.0.1 port 5001 [ ID] Interval Transfer Bandwidth [ 3] 0.0-10.0 sec 1.16 GBytes 999 Mbits/sec  可以看到是999Mbit/sec，非常接近千兆网卡的传输速率了，全双工发送接受都是千兆。\n模拟MTU # 对了，正常TCP发包考虑到链路层封帧限制，还需要考虑mtu。\n先看下lo默认的mtu设置是多少，65536，这个在真实网络中不会这么大的，比如eth0这个网卡对应的mtu只有1500：\nsh-4.2# ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc netem state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 ... 10: eth0@if11: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 0a:0b:0c:0d:0e:0f brd ff:ff:ff:ff:ff:ff link-netnsid 0  好，现在来模拟下mtu等于1500：\nsh-4.2# ip link set dev lo mtu 1500 sh-4.2# ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 1500 qdisc netem state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00  可以看到lo的mtu已经设置为1500了，这也会影响到后续的包的模拟发送接收。但是如果只是通过简单的ping localhost测试，是不会看出啥明显影响的。我们可能会预期mtu小了，难道帧多了上述增加的delay每个帧的延迟加起来不就变多了嘛？这跟delay工作的层次有关系，它是在网络层这层工作的。\n也就意味着如果网络层的包，因为mtu比较小拆了很多分片出来，到达网络层后增加的延迟会明显增加的。这里暂时不用做到这么细，只需要关注网络层的整体请求、响应延迟即可。\n同时模拟多种 # 当然，可以同时模拟多种行为，千兆网卡的传输速率限制+每次收发增加1ms传输延迟：\nsh-4.2# ip link set dev lo mtu 1500 sh-4.2# sudo tc qdisc add dev lo root netem delay 1ms rate 1000mbit  重置模拟状态 # 当我们想重置对lo的修改时，就一切恢复到正常的默认状态了：\nsh-4.2# sudo tc qdisc del dev lo root  本文小结 # 本文从个人开发角度、方便测试角度、还原网络“真实”情况角度出发，了解了下如何更好地利用lo网络模拟千兆网卡、网络传输延迟，实际测试下来比较符合预期，是一种本地开发过程中的有效手段。\n本文主要是针对开发测试期间来考虑，要了解线上环境的最终测试情况，就是要做上线前压测、容量评估等工作。\n两码事，都是应该做的，不过掌握了这个办法，本地1台开发机可以利用的有声有色。\n"}),a.add({id:33,href:"/tags/perftest/",title:"perftest",description:"",content:""}),a.add({id:34,href:"/tags/taskset/",title:"taskset",description:"",content:""}),a.add({id:35,href:"/blog/2023-04-13-%E5%8E%8B%E6%B5%8B%E4%B9%8Btaskset%E7%9A%84%E5%A6%99%E7%94%A8/",title:"压测之taskset的妙用",description:"执行压测，通常要尽量避免其他因素的干扰，有条件的话会搭建专门的压测集群。但是在开发阶段如果希望对现阶段实现进行快速压测，将相关服务部署到压测环境是没那么方便的，至少每次部署要花费的时间是会比较久的。但是在本地开发机压测，又会遇到资源竞争、相互影响的问题……taskset绑核可以解决这里的一部分问题。",content:"问题背景 # 想测试下gRPC框架的性能，设计了如下服务拓扑来对gRPC框架各组件、特性、参数配置下的性能进行探索。\n压力源程序 perfclient ---请求-\u0026gt; perfserver1 ---请求-\u0026gt; perfserver2  压力源程序perfclient会并发发送请求给服务perfserver1，perfserver1则会继续请求perfserver2，然后perfserver2回包给perfserver1，perfserver1收到响应后内部完成处理逻辑后继续回包给perfclient。\nperfclient每隔一段时间会打印下请求的请求量、成功量、失败量，以及qps、耗时信息。需要注意的事，这里再统计耗时信息的时候，除了avg、min、max耗时，还需要percentile(or quantile）百分位耗时，后者更具有说服力。\n现在呢？遇到点问题，正常我需要将上述压力源程序、被压测服务perfserver1、perfserver2尽力部署到不同的机器上，让它们之间避免相互影响，同时部署的机器上也应该注意没有其他负载会干扰到我们的测试，但是问题来了：\n 可能有机器，但是部署起来太麻烦了，可能每调整下测试点就要要操作多台机器 可能有机器，但是云平台存在超卖的情况，母机负载大影响到了虚拟机负载稳定性 可能有机器，但是ci/cd流水线执行耗时太久了 可能没机器，只有一台本地开发机  有没有什么其他简单好用的办法呢？我觉得有，资源隔离下啊。\n认识taskset # taskset，是linux下用来进行绑核设置的一个工具，我们可以借助它对上述不同的3个进程的cpu资源进行限定，如压力源程序perfclient需要能多生成些请求，我们给它分配7~10 4个cpu core，perfserver1负载会稍微比perfserver2高点，但如果是纯echo的话也多不了读少，给perfserver1分配2个cpu core，给perfserver2也分2个。\ntaskset -a -p 7,8,9,10 `pidof perfclient` taskset -a -p 3,4 `pidof perfserver1` taskset -a -p 5,6 `pidof perfserver2`  这样上述几个进程就被分别设置到了不同的cpu cores上执行，意味着当他们把cpu跑满时，他们能抗的负载大致就是这个比例。\n解释下选项-a：\n  taskset如果不指定选项-a，则知会对当前进程名对应的主进程进行绑核设置，不会对进程中的其他线程进行设置，当然也不会对后续新创建的线程进行设置。\n  加了-a，taskset就会对执行命令时，该进程pid下的所有线程进行统一的绑核设置，但是如果后续创建了新线程，新线程不会被绑核。\n  那么如果一个程序是多线程程序，且线程数不是固定的，会在以后新创建、销毁动态变化的，这种该怎么解决呢？\ngo天然多线程 # go程序天然是多线程程序，那应该如何进行绑核设置呢？如果只是为了限制进程使用的cpu资源，直接使用runtime.GOMAXPROC(x)进行设置不行吗？不行！\n该函数只是说限制同时在运行的线程数，并没有像taskset那样将线程绑到核上，这意味着这些go程序线程的执行有可能会在cpu core上迁移，这样的话通过top命令查看cpu core负载情况，就不好判断哪个core的负载是因为哪个进程引起的…对吧。\n另一个问题，go程序的GMP调度模型会在必要时自动创建新的线程出来，用来执行goroutines，这里问题就来了，我需要动态感知当前进程下的所有线程。go语言或者标准库都没有提供线程层面的东西来获取，那我们怎么获取呢？\ngo如何绑核 # Linux下面每个进程都有一个pid，对应的虚拟文件系统/proc//tasks下面就是该进程pid下的所有线程信息。理论上可以定时获取里面的pid，然后再去taskset -p绑核，或者说go启动一个协程定时调用下taskset -a -p \u0026lt;pid\u0026gt;，可以简洁明了搞定。\n这样就可以搞定绑核设置：\nfor { cmd := exec.Command(\u0026quot;taskset\u0026quot;, \u0026quot;-a\u0026quot;, \u0026quot;-p 1,2,3,4\u0026quot;, os.Getpid()) cmd.Run() time.Sleep(time.Second*5) }  测试结果 # 执行top命令后，可以press 1，然后可以看到具体每个cpu core上的负载。在压测的时候就简单多了，因为进程下线程被绑核到特定的几个cpu core了，所以可以看对应core的负载来归一化当前服务的负载信息。\n这里就不过多展开了，避免不必要的信息泄露。\n"}),a.add({id:36,href:"/tags/latency/",title:"latency",description:"",content:""}),a.add({id:37,href:"/tags/load/",title:"load",description:"",content:""}),a.add({id:38,href:"/tags/qps/",title:"qps",description:"",content:""}),a.add({id:39,href:"/blog/2023-04-12-%E4%BB%8E%E6%8E%92%E9%98%9F%E8%AE%BA%E5%88%B0%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4%E7%AE%97%E6%B3%95/",title:"从排队论到过载保护算法",description:"本文从排队论开始解释，详细介绍了Little's Law排队论模型以及如何将其迁移到在线服务领域，并就服务负载的评估、过载保护算法、适应大规模分布式系统的过载保护算法进行了思考和总结。",content:"排队论简介 # 排队论的精髓是通过数学模型和分析方法来研究排队系统的性能和行为。排队系统是指由一些服务设施和一些顾客组成的系统，顾客需要排队等待服务。排队论的目标是研究如何优化排队系统的性能，以提高服务质量和效率。\n排队论的核心是建立数学模型来描述排队系统的行为。这些模型通常基于随机过程和概率论，用于描述顾客到达的随机性、服务时间的随机性以及服务设施的数量和性能等因素。通过分析这些模型，可以得出排队系统的性能指标，如平均等待时间、平均逗留时间、系统利用率等等。\n排队论的应用非常广泛，涉及到许多领域，如交通运输、通信网络、制造业、医疗保健等等。在这些领域中，排队论可以用来优化资源利用、提高服务质量、降低成本等等。\n总之，排队论的精髓是通过数学模型和分析方法来研究排队系统的性能和行为，以优化系统的性能和效率。\n公式及应用 # 排队论是一个非常广泛的领域，其中涉及到许多不同的理论公式和应用。以下是一些常见的排队论理论公式和计算机系统中的应用：\n Little\u0026rsquo;s Law：L = λW，其中L表示系统中平均顾客数，λ表示到达率，W表示平均逗留时间。这个公式表明，系统中平均顾客数等于到达率乘以平均逗留时间。在计算机系统中，这个公式可以用来计算系统中的平均并发请求数，以及系统的响应时间和吞吐量。 Kendall\u0026rsquo;s Notation：A/B/C/K/N，其中A表示到达过程的类型，B表示服务时间的分布类型，C表示服务设施的数量，K表示服务设施的排队规则，N表示系统容量。这个符号表示了排队系统的基本特征，可以用来描述和比较不同的排队系统。 M/M/1队列：这是一个经典的排队模型，其中到达过程和服务时间都是指数分布，服务设施数量为1。这个模型可以用来计算系统的平均等待时间、平均逗留时间、系统利用率等指标。在计算机系统中，这个模型可以用来分析单个服务器的性能。 M/M/m队列：这是一个扩展的M/M/1队列模型，其中服务设施数量为m。这个模型可以用来计算系统的平均等待时间、平均逗留时间、系统利用率等指标。在计算机系统中，这个模型可以用来分析多个服务器的性能。 网络队列模型：这是一个用于分析计算机网络性能的排队模型，其中网络节点被建模为队列，数据包被建模为顾客。这个模型可以用来计算网络的吞吐量、延迟、丢包率等指标。 负载均衡算法：这是一种用于优化计算机系统性能的算法，通过将负载均衡地分配到多个服务器上，以提高系统的吞吐量和可靠性。排队论可以用来分析负载均衡算法的性能和效率。  这些理论公式和应用只是排队论中的一部分，排队论还涉及到许多其他的理论和应用，如排队网络、排队模拟、排队优化等等。\n浅谈Little\u0026rsquo;s Law # 简要说明 # Little\u0026rsquo;s Law是一个基本的排队论原理，它描述了在一个稳定的系统中，平均顾客数、平均等待时间和平均服务率之间的关系。该原理最初由美国数学家John Little在1961年提出，被广泛应用于各种排队系统的性能分析和优化。\nLittle\u0026rsquo;s Law的问题背景是排队系统，例如银行、超市、餐厅等等。在这些系统中，顾客到达、等待和离开的过程构成了一个排队模型。Little\u0026rsquo;s Law的目的是通过分析这个模型，来解决如何优化排队系统的问题。\nLittle\u0026rsquo;s Law的核心公式是：L = λW，其中L表示平均顾客数，λ表示平均到达率，W表示平均等待时间。这个公式告诉我们，如果我们知道了平均到达速率和平均等待时间，就可以计算出平均顾客数。反之亦然，如果我们知道了平均顾客数和平均等待时间，就可以计算出平均到达速率。这个公式可以帮助我们更好地理解排队系统的性能，并且指导我们如何优化排队系统。\n应用案例 # 以下是一些应用Little\u0026rsquo;s Law的案例：\n 在一个银行分行，平均每小时有100名顾客到达，平均等待时间为10分钟，那么该分行的平均顾客数是多少？根据Little\u0026rsquo;s Law，L = λW = 100 * 10 / 60 = 16.67，因此该分行的平均顾客数为16.67人。 一家餐厅想要提高服务质量，他们决定增加服务员的数量。根据Little\u0026rsquo;s Law，如果他们想要减少平均等待时间，他们需要增加服务员的数量，以提高服务率。如果他们想要减少平均顾客数，他们需要减少到达率，例如通过减少广告宣传或者提高价格等方式。  在线服务领域 # 理解little\u0026rsquo;s law # 将其应用到我们熟悉的在线服务领域的话，可以达到稳态的前提下，调整下相关参数：\n 队列平均长度可视为同时被服务的请求个数，即服务并发度Concurrency， 队列人数到达(速)率可视为服务吞吐Throughput， 平均服务时间可视为服务平均处理延迟Latency（可细分为等待延迟+处理延迟），  这样可以得到另一个版本的Little\u0026rsquo;s Law，Concurrency=Throughput * Latency。\n简单理解下这里的公式。假设请求都是单线程处理，每个请求只会占用一个cpu core，则服务并发度Concurrency就是cpu core的个数；每个请求的处理平均时间为Latency（单位为秒），则1秒内一个cpu core可以处理的请求数为 1/Latency；因此，1秒内可处理的总请求个数也就可以确定：Throughput = Concurrency * (1/ Latency)，进一步就可以得到公式：Concurrency = Throughput * Latency……所以，还是好理解的。\n利用这个公式，我们可以进一步去分析计算机系统处理请求时的吞吐量、处理时延、并发处理能力之间的关系。\n 有时候我们队计算机进行系统性能优化，也会对某任务的某一部分进行改善，如何评估改善后任务的整体性能极限呢？可以通过Amdahl\u0026rsquo;s Law来分析，详见 Wikipedia Amdahl\u0026rsquo;s Law，不展开了。\n 那我们如何具体来使用它来评估系统处理请求时的吞吐量、处理时延、并发处理能力之间的关系呢？有没有什么实际案例可供借鉴下。\n工程应关注什么 # 首先，工程上我们往往会通过调整服务配置，对服务进行不同测试，比如性能测试、负载测试、压力测试、稳定性测试等。\n  性能测试，以系统设计初期规划的性能指标为预期目标，对系统不断施加压力，验证系 统在资源可接受范围内，是否能达到性能预期。\n  负载测试，对系统不断地增加并发请求，以增加系统压力，直到系统的某项或多项性能 指标达到安全临界值。当并发请求数量超过安全临界值之后，系统吞吐量不升反降。\n  压力测试，超过安全负载的情况下，对系统继续施加压力，直到系统崩溃或不能再处理 任何请求，以此获得系统最大压力承受能力。\n  稳定性测试，被测试系统在特定硬件、软件、网络环境条件下，给系统加载一定业务压力， 运行一段较长时间，以此检测系统是否稳定。\n  通过这些测试，来确定不同负载下（cpu、内存、IO等）服务能够支持的吞吐量Throughput（QPS）、处理延迟Latency（p90、p95、p99耗时、平均处理耗时）。\n真实的测试场景下涉及到软硬件、网络、其他组件影响等等比较复杂的因素，用Little\u0026rsquo;s Law、Amdahl\u0026rsquo;s Law很难进行精准的分析，但是可以用来推断下理论值、极限值。\n尽管真实环境中，不能直接用它来直接预测服务的负载、吞吐量、平均耗时等指标值，但是仍然可以使用它来指导具体的过载保护算法的设计。\n负载的评估 # 这里思考下，负载与RPS、处理时长之间的关系。根据排队论模型：Little\u0026rsquo;s Law L = λW，类比到计算机系统，L表示系统中任意时刻需要处理的请求数，λ表示每秒到达的请求数量，W表示请求的平均处理时长。\n随着λ从0逐渐增大：\n 当λ较小时，平均处理时长不会随着每秒请求量的增长有明显增加； 随着λ继续增大，系统中资源竞争逐渐加剧，比如抢锁、内存分配、协程调度、GC等问题开始表现出来，平均处理时长会略有增加，系统中任意时刻的处理请求数也会增加；  这个很好理解，但是难以精确的建模，比如针对内存负载、cpu负载、调度开销、GC开销做一个复杂的公式，模型训练也存在过拟合的问题，我们设计的公式可能也会 可能设计出的公式对某种workload比较合适，但是换一种就不一定行，如果只考虑我们后台微服务场景，也可以设计一套这样的负载计算公式（类似trpc-overload-control） 或者我们把问题简化下，把服务本身当做一个黑盒，管你内部发生了什么呢，只从外部观测角度来衡量负载高还是低，那就是Little\u0026rsquo;s Law指导下的做法，比如：Netflix自适应限流过载保护、微信基于排队时延的过载保护   λ继续增大，导致L超过了系统规划的容量，这个时候，就处理不了了  请求可能会有请求队列放不下的问题，这个就会丢弃请求， 或者处理超时，排队时延+处理时延，排队明显更久了，竞争也会加剧处理时延    对于过载保护，更适合基于一些能反映系统负载、服务负载情况的指标来评估负载信息：\n 系统负载，  cpu利用率高往往会被认为是负载高，确实是；但举个极端case如计算型负载，只要请求量不超过cpu cores很多就不能认为是过载； ram利用率高往往会被认为是负载高，也确实是；但是ram利用率多高算高呢？实际观察系统可用内存+可用buff加起来确实不是很大，这个时候认为过载可能也不见得正确，而且GC的触发也依赖内存分配动作的触发（定时只是兜底）；   服务负载：  由于机器可能会混部多个服务，这里用服务负载来特指某个服务的负载，用来和系统负载区分下 服务负载准确说应该是服务资源的配额限制，如内存软限制，其负载信息也会通过GC导致的CPU开销反映到系统负载上 协程调度的间隔、GC Pause耗时可能受系统负载影响，但也受服务本身影响，这些指标通过观测系统负载不一定能观测到，但是通过服务自身的运行时监控能观测到   当做黑盒  观察系统的吞吐量变化、处理耗时变化（client端、server端），真实情况可能会受网络抖动影响，但是网络（拥塞等）也确实是需要考虑的    总的来说，为了更合理地评估服务的过载保护算法，我们不能单纯看系统负载，也不能单独看服务负载，也不能完全当做黑盒来看，需要综合来评估下。\n这里提的是负载的评估，还没有提及过载保护算法，过载保护可以在客户端做，也可以在服务器做，也可以两边都做各有侧重点。\n过载保护算法 # 传统做法 # 通常会将负载作为一个相对固定的值，比如CPU单核85%作为一个参考点，测试期间压力源发送的请求系统负载稳定在这个值，然后观察Throughtput、Latency的关系变化。注意此时85%的负载下，响应时间Latency不一定是最好的，但是吞吐量可能是更大的，要注意根据SLA（承诺的响应时间、QPS等）来为客户分配合理的资源。或者我们将其压测到过载，然后取此时QPS的一个75%左右作为一个相对合理的QPS值，并在客户端通过漏桶、令牌桶等算法来强制执行这个最大频率上限。\n但是对于大型分布式系统，这个配置值很快就会过期，QPS可能偏小导致后端服务不能充分利用资源，或者QPS过大导致后端服务过载。\n分布式限频 # 为了解决这个问题，我们也会引入分布式限频，后端节点定期上报负载、可承载请求给频控服务，客户端定期从频控服务获取最新的配额（一般客户端请求量大，会通过先消费后上报，与频控服务来完成同步）。\n但是这样需要额外引入一个频控服务，它设计实现的不好也容易成为系统瓶颈。\n自适应过载保护 # 我们应该考虑并发请求，而不是考虑RPS、CPU、内存、磁盘或网络等限制。Little\u0026rsquo;s Law 很好地涵盖了这种关系，其中 Limit = Average RPS * Average Latency。\nLittle\u0026rsquo;s Law，它其实可以指导我们简化过载保护算法的设计，我们可以不用围绕CPU、内存、磁盘或网络情况来设计华而不实、过度复杂、又不能充分覆盖不同负载场景的负载计算的算法，仅通过观察请求成功率、失败率、响应时间就可以预测出系统接下来大致能支持的一个负载。简单理解，latency增加还好，如果成功率下降了，适当调低rps，反之调高。\n不需要引入其他分布式频控服务，也不需要设计复杂的负载计算的算法，借鉴最具有说服力的服务成功率、失败率、响应时间就可以动态调整接下来的请求速率，实现起来简单，部署时伸缩性、不同负载适应性更好。\n 相关的尝试：\n1、netflix在自己的视频处理链路中引入了这种算法，我们在之前业务腾讯看点的内容处理链路中也有类似的实践，gRPC中也有类似tcp拥塞窗口控制的机制。netflix设计实现了一个基于Java的库 Netflix/concurrency-limits，2.9k stars，有开发者用go重写了一遍 platinummonkey/go-concurrency-limits, 91 stars。\n2、微信在过载保护算法dagor中，将请求排队时长作为重点参考指标，参考文献Overload Control for Scaling WeChat Microservices，中文翻译见 微信过载保护的实现原理。\n 这里的几种案例都是基于Little\u0026rsquo;s Law出发的实践，都是大型项目中的真实实践，对于大规模分布式系统、动态扩缩容、链路动态变化场景下的适应性效果比较好。\n本文总结 # 本文简单是在实践过程中，对排队论、little\u0026rsquo;s Law、服务负载评估、过载保护算法的一点思考和认识，将相关的理论、实践简单总结下。我认为Little\u0026rsquo;s Law模型，以及以及在此基础之上的netflix、微信的过载保护实践，恰恰是抓住了问题的重点，所以能以更简洁优雅的做法来妥善的解决这个由来已久又被广泛讨论的问题。\n"}),a.add({id:40,href:"/tags/fuzztest/",title:"fuzztest",description:"",content:""}),a.add({id:41,href:"/tags/go-test-fuzz/",title:"go test -fuzz",description:"",content:""}),a.add({id:42,href:"/tags/gofuzz/",title:"gofuzz",description:"",content:""}),a.add({id:43,href:"/tags/overflow/",title:"overflow",description:"",content:""}),a.add({id:44,href:"/blog/2023-03-03-%E6%A3%80%E6%B5%8B%E5%B9%B6%E8%A7%A3%E5%86%B3%E8%AE%A1%E7%AE%97%E6%BA%A2%E5%87%BA%E9%97%AE%E9%A2%98/",title:"检测并解决数值计算溢出问题",description:"数值计算溢出是一个很严重的问题，可能学习计算机组成原理时，或者做些活动类的与金币、钱、经验值等相关的项目时，会特别注意一下。在普通业务服务代码中比较少见到处理类似问题的实践，当然它不一定引发错误……近期项目中遇到了这类问题，也趁机总结一下。",content:"问题背景 # 数据类型是个好东西，类型定义了一种数据组成以及允许在其上进行的操作。 数据类型是个好东西，它定义了一种最基础的“安全”，类型安全。\n我们在进行数值运算时，有可能会“超出”类型本身的值域，但是受限于位宽限制，进而表现为“上溢出”。以a+b为例：\n 如果a、b都是有符号数，且其符号相同，有可能超过最大值、最小值而在值域空间中轮转； 两个正数相加，结果却是负数；两个负数相加，结果却是正数. 如果a、b都是无符号数，也有可能超过最大值而在值域空间中轮转。  这个很容易理解，今天我们想看下如何解决此类问题。\n如何解决溢出问题 # 升级32位到64位？ # 这通常是第一反应，它可能是有效的，也可能无效。\n 有效：如果输入int32 a、b是有明确约束保证的，比如任意一个都必须在[-1*1\u0026laquo;31,(1\u0026laquo;31)-1]， a+b可能对int32可能会溢出，但是如果提升成int64则可以解决问题，前提有这样的约束保证； 无效：没有任何输入约束做保证，只是简单提升成int64 a、b是没有用的，极端情况，a=b=1\u0026laquo;36-1， a+b很明显就溢出了，这种就需要其他方法做保证。  设计上应该有上限？ # 在设计上就要有这方面的“数据”上的“安全”的意识，比如：\n 玩家每赛季的经验应该是有上限的，满经验后就提示玩家满经验，后续就不给加了； 比如用uint32表示经验值，那么加之前先测一下是否发生了溢出(v=orig+delta, 如果v小于任意一个则溢出) 这很好理解，正常情况下，v应该大于orig、delta，就是逻辑反嘛。 ps：不好理解？把值域想象成一个转盘，delta不可能让v在值域范围内“环绕 (wraparound)”/“转到”orig，反之orig也不能让v转到delta。 如果发生了溢出，则直接将v=maxUint32完事，多出来的就扔掉，提示玩家满经验。 或者，这里的满经验不一定要maxUint32，可以是认为设计好的一个小值，比如99999； 如果输入有约束，比较小比如int8 a, int8 b，那么至少可以保证 if a+b \u0026gt; 99999 then v=999999 是ok的， 也不会触及累积量v达到uint32最大值的情况。可能这种情况比较理想化了。  检查是否发生溢出？ # 言归正传，还是要有办法来比较可靠地检查运算结果a+b是否发生了溢出？\n 可以用大数计算来避免溢出，比如golang里面的math/big包。 比如int32 a,b相加，按int c=a+b的方式，c有可能是个溢出后的错误结果。 但是如果用大数计算，位宽充足可以算出正确结果，只要将其和maxInt32比较下即可知道是否发生了溢出。 如果确实发生了溢出，应该如何处理，如fallback到满经验值不再加经验。 也可以不用大数计算，通过一些有趣的副作用也可以知道是否发生了溢出。 比如在x86汇编中，可以通过 test OF,OF 来判断是否发生了溢出。 高级语言中，就没那么直接，比如go，得借助一些其他办法来判断，这就是这个math_test.go要测试的东西。  代码测试：运算时检测溢出 # 测试代码，请移步：https://github.com/hitzhangjie/codemaster/blob/master/math/math_test.go。\nmath_test.go中定义了两个函数safeSignedAdd、safeUnsignedAdd来对有符号数、无符号数加法进行安全的计算：\n 如果发生了溢出则返回错误，方便调用方处理； 如果没发生错误则返回两数之和；  我们想检测下如何更好地发现一些造成溢出的边界条件，我们使用go fuzztest来帮助发现潜在的问题。 我们设置了边界附近的值作为seed scorpus，这样方便go fuzztest引擎使用mutator微调输入参数时能够覆盖到边界条件。\n其实也可以使用go fuzztest的随机构造输入的模式，但是这样往往需要执行更多的时间才有助于发现问题。 ps：改天再写篇文章详细介绍下go fuzztest内部是如何工作的。\n这里看起来我们是为了使用go fuzztest而使用fuzztest，比如你怎么精心构造这样的seed scorpus的？其实不是为了用而用。\n 当我们设计实现一个函数时，脑海中应该知道输入是啥、输出是啥，过程中的极端case是啥，那你就有了一个输入的值域范围， 或者说不同的参数组合有几种特殊的情况，可以多次调用 f.Seed(v1,v2,\u0026hellip;)，来将这些参数作为一个seed scorpus， 以方便后续模糊测试引擎微调这些参数来覆盖特殊分支。 你不一定要精心构造出一定能触发异常边界的seed scorpus，你可以设置个大概的值，然后交给模糊测试引擎去做剩下的工作， 假定一个参数是uint32类型，你设置的seed参数设置的是n，那么这个n最终会在[n-100,n+100]的范围内变化，当然下界、 上界要在uint32范围内，每个参数都会这样变化。所以你的seed scorpus不一定刚好触发边界。 模糊测试运行过程中，如果它发现某个输入发生了错误（t.Errorf标记的），或者此输入导致代码覆盖率提升了（给每条语句插桩）， 那么就会将当前输入作为一个新的seed scorpus存起来，在其基础上微调参数执行。 最终我们尽可能地覆盖了更多的代码，并尽力去发现可能存在的边界异常。但是确实不能保证一定能找到问题。  随机模式的话，输入参数随机意味着逼近边界异常处需要更多的测试用例，可能耗时很长才能发现，但是也不一定能发现。\n测试覆盖：模糊测试!=漫无目的的测试 # 在执行uint32上溢出模糊测试时，我专门设计了一个seed scorpus，如下所示：\nf.Add(uint32(0xffffffff-1000), uint32(0))  此输入下，mutator无能为力，执行了几分钟也发现不了问题，如果知道mutator原理的就很容易明白为什么。\n$ go test -v -count=1 -fuzz=Fuzz_overflow_uint32 -run=^$ === FUZZ Fuzz_overflow_uint32 fuzz: elapsed: 0s, gathering baseline coverage: 0/1 completed fuzz: elapsed: 0s, gathering baseline coverage: 1/1 completed, now fuzzing with 16 workers fuzz: elapsed: 3s, execs: 767120 (255688/sec), new interesting: 1 (total: 2) fuzz: elapsed: 6s, execs: 1551732 (261545/sec), new interesting: 1 (total: 2) fuzz: elapsed: 9s, execs: 2352907 (267067/sec), new interesting: 1 (total: 2) fuzz: elapsed: 12s, execs: 3148542 (265216/sec), new interesting: 1 (total: 2) fuzz: elapsed: 15s, execs: 3945075 (265509/sec), new interesting: 1 (total: 2) fuzz: elapsed: 18s, execs: 4751252 (268643/sec), new interesting: 1 (total: 2) fuzz: elapsed: 21s, execs: 5550572 (266165/sec), new interesting: 1 (total: 2) fuzz: elapsed: 24s, execs: 6352445 (267419/sec), new interesting: 1 (total: 2) ...................................................................... fuzz: elapsed: 2m33s, execs: 40082850 (257913/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m36s, execs: 40876146 (264475/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m39s, execs: 41660462 (261389/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m42s, execs: 42442111 (260618/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m45s, execs: 43234687 (264132/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m48s, execs: 43994959 (253473/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m51s, execs: 44772385 (258989/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m54s, execs: 45562731 (263543/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m57s, execs: 46340129 (259039/sec), new interesting: 1 (total: 2) ^C  然后，进一步可以纠正下错误的测试思想，模糊测试!=漫无目的的测试，seed scorpus matters!\n当我们设计上有章法，测试时关注边界，自然知道seed scorpus该如何设置，比如我们改成：\nf.Add(uint32(0xffffffff), uint32(0))  继续执行测试，很快就发现了边界case，代码中我们加了模糊测试的次数，发现第9轮它便发现了问题。\ngo test -v -count=1 -fuzz=Fuzz_overflow_uint32 -run=^$ === FUZZ Fuzz_overflow_uint32 fuzz: elapsed: 0s, gathering baseline coverage: 0/1 completed fuzz: elapsed: 0s, gathering baseline coverage: 1/1 completed, now fuzzing with 16 workers fuzz: elapsed: 0s, execs: 9 (383/sec), new interesting: 0 (total: 1) --- FAIL: Fuzz_overflow_uint32 (0.02s) --- FAIL: Fuzz_overflow_uint32 (0.00s) math_test.go:31: iter-9 4294967198 + 118 = 20, err: overflow Failing input written to testdata/fuzz/Fuzz_overflow_uint32/a6532fa5f002651bb1003d5aedbea9bb5716a6d2a8fe7afff0b5252599a6d59b To re-run: go test -run=Fuzz_overflow_uint32/a6532fa5f002651bb1003d5aedbea9bb5716a6d2a8fe7afff0b5252599a6d59b FAIL exit status 1 FAIL github.com/hitzhangjie/codemaster/math 0.026s  小结 # 总结了下如何解决数值计算时的溢出问题，从编码上、从策略上，以及介绍了如何使用go fuzztest来更好地发现潜在的问题。 关于模糊测试的一点想法，模糊测试 != 漫无目的的测试，seed scorpus的选择和设置很有价值。后面有时间会写下go模糊测试的工作原理。\nps：对于溢出问题、环绕问题，go的类型系统都存在。在编译时，如果发生溢出，编译器会直接抛出错误，比如“constant ??? overflows uint32”；如果是运行时溢出，则会出现环绕（wraparound），此时就需要显示检查并避免环绕了。\n"}),a.add({id:45,href:"/tags/lang/",title:"-lang",description:"",content:""}),a.add({id:46,href:"/tags/gcflags/",title:"gcflags",description:"",content:""}),a.add({id:47,href:"/tags/go/",title:"go",description:"",content:""}),a.add({id:48,href:"/blog/2022-11-24-how-go.mod-works/",title:"how go.mod works?",description:"go.mod里面的版本号是如何影响go编译器检查的？之前整理过，今天项目中有遇到个类似的问题，就顺便再整理记录下。",content:"go.mod/go.sum内容 # go.mod里面包含的信息包括：\n 当前module构建要求的最小go版本 依赖的module及校验和信息 为了方便本地开发测试的一些replace信息  这里不讨论vendor相关的modules.txt中的内容。\n最小go版本号 # 我们举个例子来描述下。\n  如果当前module的go.mod是go 1.16，等价于编译的时候go build -gcflags \u0026lsquo;-lang=1.16\u0026rsquo; / go tool compile -lang=1.16。\n  假设我们现在安装的go版本是go1.19。\n  这种情况下执行编译测试：\n  如果我们用了范型（go1.18开始支持），go编译器编译时会检查， 本来go1.19肯定能编译1.18的范型代码，但是它会报错出来，因为go.mod里声明的go版本，是当前项目支持的最小go版本，有可能别人不是1.19而是1.15,1.17，所以要报错提示下\n我们还没有用那些1.16.5以后的新特性非得要新版本的go来编，所以之前能正常编。\n  如果我们安装的go1.15，go.mod里面的1.16高了，也会先尝试编译，编过了就编过了，编不过就报错最小版本是1.16.5 比如机器上现在是1.19，可以go.mod改成1.20正常编过\n  如果因为-lang编译导致的编不过，如果go.mod里面的版本比当前安装的版本高，还会打印出来 module requires go 1.21，提示安装新版本\n  依赖信息 # 依赖的module，除了指明importPath，还要指明version，才能完整指明一个依赖。这个应该没什么疑问，所以大家都会提交go.mod文件。\n再说下校验和，有什么用呢？防止包内容被篡改。有些同学因为什么原因导致校验和经常冲突，需要解决冲突，所以直接不提交go.sum文件了，这是十分错误的。\n有同学可能会觉得这些繁琐的步骤很荒唐，其实并不是，可重复的制品构建，是一门非常重要的工程上的保证手段，为了达到此目的，甚至还有封闭构建、构建容器等其他方法来提供进一步的保证。\n本文小结 # 本文简单记录了下go.mod/go.sum相关的知识点，可能对刚接触这块的同学比较有价值 :)\n"}),a.add({id:49,href:"/tags/module/",title:"module",description:"",content:""}),a.add({id:50,href:"/tags/consmark/",title:"consMark",description:"",content:""}),a.add({id:51,href:"/tags/garbagecollector/",title:"GarbageCollector",description:"",content:""}),a.add({id:52,href:"/tags/gc/",title:"GC",description:"",content:""}),a.add({id:53,href:"/blog/2022-11-20-go%E5%A6%82%E4%BD%95%E8%A7%A6%E5%8F%91%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/",title:"go如何触发垃圾回收的",description:"go触发GC有这么几个时机，内存分配时触发mallogc，定时触发sysmon，手动触发runtime.GC、debug.FreeOSMemory，其中内存分配时触发是go是重中之重，go runtime以此来平衡好内存分配、内存回收的节奏以让内存占用维持在一个合适的水准。本文对内存分配过程中触发GC的一些设计考量进行了总结梳理。",content:"前言 # go触发GC有这么几个时机，内存分配时触发mallogc，定时触发sysmon，手动触发runtime.GC、debug.FreeOSMemory，其中内存分配时触发是go是重中之重，go runtime以此来平衡好内存分配、内存回收的节奏以让内存占用维持在一个合适的水准。本文对内存分配过程中触发GC的一些设计考量进行了总结梳理。\n应该听过“mark assist” # gc过程中mutator分配内存时可能会被搞去做assistg,去辅助扫描标记一些对象是否该回收的工作,当我的辅助标记内存数量减去要申请的内存数,如果为负数时,相当于我申请的比辅助标记的多,相当于欠债了,这个时候我就得去做些辅助标记的工作 gcAssistBytes:\n 然后根据当前内存使用情况\\扫描情况\\下次GC的heapgoal,计算出我应该辅助标记多少,才能保证达到堆大小时GC标记工作恰好能完成,让我去干活 这个时候干活之前会先检查下bgMarkWorker因为扫描工作贡献的信用分,然后我可以借用这个信用分来偿还债务,以减少扫描工作,或者完全避免扫描工作 如果依旧欠债,那就干活呗,后面会执行到gcDrainN,去执行一些标记类的工作  这些标记类的工作从何而来呢,比如写屏障记录下来的一些需要去扫描的对象 执行完了这个扫描之后,这个assistG.gcAssistBytes就会加上扫描的字节数,相当于攒的一点信用分   干完这些之后,才允许你申请内存\\分配对象,哈哈哈!  goroutine可以去做些mark assist之类的工作的前提是，GC已经进入了GCMark阶段，那内存分配期间GC是什么如何被触发的呢？\nGC什么情况下被触发的 # 关于什么时候触发GC，严谨一点，内存分配期间何时触发的GC，这里不考虑sysmon触发、手动runtime.GC()触发，ok。\nGOGC\\GOMEMLIMIT\\heapGoal # 我们应该都这样的认识阶段，通过GOGC、GOMEMLIMIT可以计算出下次GC时的heapGoal，等堆内存占用达到这个heapGoal时会触发GC。\n但是严格来讲，理解成接下来内存占用达到heapGoal才触发GC，是不正确的。\n引入GC Trigger #  为了触发GC，还有一个概念，叫GC trigger，它的值heapGoal要小些，在GCOff阶段，内存分配过程中会检查当前heapLive大小是否超过了这个trigger，是则启动gc（gcStart） 那个协程来负责检查是否启动gc，可以理解成所有的协程，协程如果是申请大内存（\u0026gt;32K）则一定会做上述检查，小内存为了效率则不一定每次检查，当如果申请小内存（tiny or small）如果过程中span不足发生了refill也会做上述检查（shouldhelpgc） 当启动了GC之后，接下来goroutines如果涉及到内存分配，就会转入markAssist阶段，要分配多少，先要干一定量的标记扫描的活才行（内存debt/assist设计） 那么heapGoal干嘛用的呢，前面提到的内存debt/assist设计，就是为了在当前堆大小达到heapGoal时尽量完成内存的标记扫描，将markbits改成allocbits，未使用的就可以复用或者等下个GC cycle阶段回收  所以从GC trigger到heapGoal，这中间是有一些考量的，如果只认为GC heapGoal控制GC的触发，其实是认识不到位的。ps：可能在这这个提案 GC pacer redesign 实现之前确实是根据heapGoal来触发的，但是这会导致内存的不受限制的增长。\nGC Trigger计算 # 那么这个GC trigger是如何计算的呢？\n 首先它不能比heapGoal小很多，那可能会导致GC启动过早，写屏障打开后程序latency会上升，而且如果内存分配比较快GC一直触发运行，期间分配的对象会一直标记为black，Rss会上升 也不能过晚触发，可能导致标记扫描阶段assistG的工作量过大，latency会比较明显，而且会堆大小增长会超出预期。  至于如何计算的，可以先看下上面这个提案中关于GC trigger的设计，然后翻下源码瞧瞧……额，还是简单总结下吧：\n 明确下目标，GC trigger是用来确定何时触发GC的一个值，当内存分配导致堆大小变化时会检查当前heapLive\u0026gt;trigger来决定是否触发GC（申请大内存必检查，申请小内存为了效率一般不检查，但在span不足refill后检查） GC trigger如何计算出来的：  首先根据GOGC、GOMEMLIMIT算出下次GC的heapGoal， 然后根据minTrigger=heapMarked+(heapGoal-heapMarked)*0.7， 然后maxTrigger=heapMarked+(heapGoal-heapMarked)*.0.95，如果堆比较小就用这里算出的值意味着总有一个buffer来赶在内存占用达到heapGoal之前启动GC。如果堆比较大但是有没有多少扫描工作，就用heapGoal-defaultHeapMinimum(4MB)来作为maxTrigger，这也是一种优化。 ps: 这里的heapMarked表示上轮GC标记结束时堆大小。这两个值，相当于确定了一个候选的触发GC的heapLive范围，最终trigger值一定要大于等于minTrigger，一定要小于等于maxTrigger。   确定trigger：  确定runway，根据上轮GC过程记录的consMark（程序分配内存、扫描内存量的比值）、实际的扫描内存的量（heap+stack+global）以及并发标记执行阶段mutator:collector的CPU执行时间的比值3:1，可以大致算出下一轮GC期间内存使用量能涨到多少，这个源码中选了个词叫runway，意思是我们内存使用量能走多远。 很明显如果这个值如果大于heapGoal说明我们很可能会让堆占用走高，此时需要更激进地触发GC，所以此时的trigger就选下界minTrigger。 如果这个值比比heapGoal小，那就用goal-runway作为trigger，但是这个值表示的时啥？如果这个值比minTrigger小就用minTrigger。 前面还算了个最大trigger，如果这里的trigger值比maxTrigger还大，那trigger要改成maxTrigger。    Put it together # OK，现在知道了trigger值是怎么详细计算的了，好，我们继续串一下：\n 如果当前没有触发GC，当前goroutine正在执行内存分配  根据当前内存分配的量来确定是否shouldhelpgc（\u0026gt;32K一定为true，反之则要根据是否有span不足refill）  如果否就分配完内存该干嘛干嘛去就完了 如果需要辅助gc，首先先计算下当前trigger（上面详细描述了如何计算的），然后比较下当前heapLive、trigger的大小  如果heapLive \u0026lt; trigger，不用触发GC，该干嘛干嘛 如果heapLive \u0026gt; trigger，发起GC，即调用gcStart()，这里其实是发起一轮完整的GC，等它完成后再返回来该干嘛干嘛       当有其他goroutine发起了GC，进入GCMark阶段后gcBlackenEnabled=1表示其他mutator要把新分配对象标记为黑，可以理解成当前进入GC阶段了  每一个goroutine都要维护一个账本，自己分配了多少内存，自己辅助标记了多少内存 如果自己分配的内存没有超过辅助标记的内存，gcAssistBytes\u0026gt;0，没欠债该干嘛干嘛去 如果自己分配的内存超过自己辅助标记的内存，表示自己欠债了，欠债了怎么办？就得还债，还债就得去辅助标记内存，这就是我们说的markAssist  如果我要分配npages的内存，那么要辅助扫描多少内存呢，这个运行时有个计算规则，总的目标是在GC发起后、内存占用达到heapGoal之前我能把所有的内存扫描完 确定了要扫描多少内存后，就可以去干活了？等等，当前goroutine欠的债，也可以先找大佬帮还一下，这就是bgMarkWorker攒的credit（bytes），如果一次还不完，欠多少就是多少，自己去扫描就完了 ps: 这样有个好处，当前goroutine可以不用引入扫描内存的开销就可以继续干自己该干的事情。   这个阶段会更新当前goroutine的这个账本，如果当前GC Cycle内它还有动作，就可以继续拿来秋后算账    当一轮GC Cycle结束时，go runtime会将当前的gcMarkBits作为gcAllocBits，意思就是这些没有被标记的内存都可以在后续分配内存对象时复用了，实在没用的就可以还给操作系统了。\n本文小结 # 实际上内存分配器和垃圾回收器，这两个之间并不是割裂的关系，而是互相协作的两个组件，这里就只是介绍了内存分配过程中的主要逻辑，忽略了垃圾回收中的部分，也忽略了内存多层级组织的内容（mheap-\u0026gt;arena-\u0026gt;pages, mheap-\u0026gt;mcentral-\u0026gt;mspan-\u0026gt;p.mcache）。\n这篇文章总结的就是mallogc期间go runtime的一些考量，有时间在总结分享下go垃圾回收的部分。\n"}),a.add({id:54,href:"/tags/heapgoal/",title:"heapGoal",description:"",content:""}),a.add({id:55,href:"/tags/markassist/",title:"markAssist",description:"",content:""}),a.add({id:56,href:"/tags/runway/",title:"runway",description:"",content:""}),a.add({id:57,href:"/tags/trigger/",title:"trigger",description:"",content:""}),a.add({id:58,href:"/tags/dictionary/",title:"dictionary",description:"",content:""}),a.add({id:59,href:"/tags/gcshape/",title:"gcshape",description:"",content:""}),a.add({id:60,href:"/tags/generics/",title:"generics",description:"",content:""}),a.add({id:61,href:"/blog/2022-11-10-go1.18%E6%B3%9B%E5%9E%8B%E6%94%AF%E6%8C%81/",title:"go1.18泛型支持",description:"go1.18支持了泛型编程，很久之前就研究过它的设计实现原理，但是对于其如何编写泛型代码及注意事项，并没有仔细去看过。借着项目升级go1.19的机会，公共库中有些代码可以通过泛型来优化下，这里就学习过程中认为比较重要的泛型知识点做个梳理、总结。",content:"go1.18 泛型支持 # 关于泛型编程 # 首先什么是泛型呢？ # Generic programming is a style of computer programming in which algorithms are written in terms of types to-be-specified-later that are then instantiated when needed for specific types provided as parameters.\n泛型编程有啥好处呢？ #  cleaner code and simpler API (not always) improve code exectution performance (not always)  没有泛型的日子 # 如何应付的 # go1.18之前苦于没有范型编程，开发人员一般会这么做：\n go编译器对内置类型有一定的范型支持，比如new、make、len、cap go支持reflection和interace，通过这两个一定程度上可以模拟范型的能力 go支持//go:generate，通过自定义工具可以生成一些“重复”代码  痛点依然在 # 即便是通过反射、interface来模拟也把风险从编译时类型安全推到了运行时检查部分，生成代码也会有大量重复性代码……所以痛点依然存在。\ngo1.18中终于解决了这个问题，虽然现在来看还没那么尽善尽美，但是总算在路上了。\ngo泛型知识点 # go1.19当前范型设计实现，也还没完全实现提案type parameters proposal，这个提案也并非未来go泛型实现的天花板，会一步步完善。尽管还不尽善尽美，但是将来go泛型编程应该有较大的应用场景。现在有些库已经在用泛型重写了。\n自定义泛型： # 1.18支持了自定义范型（customized generics），这个提法是为了与内置的泛型支持区分开。所说的内置泛型，指的是类似new、make、len、cap这样的一些函数，或者map[k]v这样的数据结构类型，这些有泛型的思想和支持。\n但是我们所说的泛型主要是指自定义的泛型类型、函数、方法。\n基础知识： #  泛型类型 type Lockable[T any] 泛型方法 func(l *Lockable[T]) Do(f func(*T)) {…} 泛型函数 func Equal[T comprable](a, b T) bool { return a == b} 如果类型参数列表中有多个，如[a any, b, c, _ comparable]，它们的顺序没有影响的  接口表示： #  tilde form：~T，波浪号+类型，表示类型集合，表示所有underlying type为T的类型 term form：T1 | T2 | …. | Tn，类型的联合  接口嵌套： #   1.18之前接口内可以嵌入任意数量函数、任意类型名（只要类型名为接口名即可）\n  1.18中放松了嵌入类型名的限制，可以是\n 任意类型的字面量，只要不是类型参数名即可，比如string、其他接口名 无名接口定义 tilde形式 term形式  而类型参数的constraint其实就是interaface，这里的增强大大增强了constraint描述的范畴，如所有的int、uint、float，或者string\n  下面是些合法的接口定义\ntype L interface { Run() error Stop() } type M interface { L Step() error } type N interface { M interface{ Resume() } ~map[int]bool ~[]byte | string } type O interface { Pause() N string int64 | ~chan int | any }  在一个接口A中嵌入另一个接口B，相当于把B递归的展开把方法全部作为A的方法，比如接口0相当于这样，其中的不是方法名的部分，~map[int]bool…int64|~chan int|any，可以看做不同的term union form。\n注意interface { int; uint } 表示底层类型同时是int和uint的，而interface{int | uint}表示底层类型或者是int或或uint的，是两种完全不同的概念。\ntype O interface { Run() error Stop() Step() error Pause() Resume() ~map[int]bool ~[]byte | string string int64 | ~chan int | any }    如果constraint中只包含一个元素，而且它是type element，那么可以省略外层的interface{}，比如[T interface{~int}]可以简化为[T ~int]\n  但是上述简化，有时也会遇到解析问题，比如[T *int]，这里表示的是啥意思呢？是underlying type为 int的范型类型？还是把int当做一个常量解释为一个Tint这么大的数组？现在确实是当做数组的。编译器当然可以解决这个问题，但是得做些额外的处理，后面可能会优化吧。\nweired，那现在如何化解这个问题？\n 可以用完整形式，用interface裹起来 在最后加一个逗号结尾[T *int,]，类型参数列表最后允许加逗号的，换行的话也要用逗号连接  我擦，就不要用这种破坏可读性的方式来写，直接用interface{}包起来！\n在看个奇葩的[A int, B *A]，我擦这里的A到底是啥？I don’t know！\n 尽管类型参数的constraint是一个接口，但是不代表类型参数就可以像普通接口变量那样可以有动态值、可以断言，我们把它理解成一个类型、把constraint理解成一种限制就可以了，不要总想着它是一个接口值的变量（实际上也不是）。    类型参数作用域： #  参考这里：http://localhost:55556/generics/555-type-constraints-and-parameters.html#:~:text=Go specification says,of the type. 举个例子：type G[S ~[]E, E int] struct{}，这里的E后面有作为了S的声明，对于函数、方法也是类似的。就是说一个类型参数（比如E）的作用域从这个类型、函数、方法定义开始就有效，直到定义结束。所以这里的E是有效的，对于S它自然要找E在哪定义的，怎么找，在当前scope里面找，因为specification这么定义的，它当然在这个scope里找定义了。跟从左往右、从右往左这种表面上的顺序无关。  类型参数实例化、类型推导： #  其实包括泛型类型中的类型参数实例化，和泛型函数、泛型方法中的类型参数实例化  实例化时参数列表省略问题： #  泛型类型中：省略类型参数列表不能省略，要写完整的 泛型函数、泛型方法：当可以推断时，可以部分省略或完全省略  实例化时传递的实参问题： #  基本接口类型any、error可以作为类型参数的实例化参数。 如果一个类型参数A的constraint满足另一个类型参数B的constraint，那么可以传递A的实例化作为B对应的类型参数的实例化参数  类型参数上的操作 #   看这里吧：http://localhost:55556/generics/777-operations-on-values-of-type-parameter-types.html，实在是费解，这么多特殊规则，谁能记得住怎么写\n  有些操作是有效的，有些则是无效的。通俗地说，某个操作是否有效，要看其对类型参数对constraint所表示的type set中每个类型是否都有效，都有效才算是有效的。\n  go自定义泛型不是通过c++模版那样重复生成代码实现的，这也是和代码生成的不同之处。有一条principle rule就是：在go里面，每个有类型的表达式计算都必须有一个指定的类型，这里的类型可以是普通类型，也可以是类型参数。这条原则很关键，比方说typeset包含多个候选类型参数值，函数体里对值的操作表达式对应的类型需要有一个核心类型来表示。比如下面这个：\n// 如果T是chan int，那么从c读到的是int，如果T是chan bool，那么从c读初的是bool， // 一个是int，一个是bool，不能统一到同一个类型，这就叫core type missing， // 此时定义一个类型参数作个衔接就可以了。 func read[T chan int|chan bool](c T) { _ = \u0026lt;-c } // 改成这样就可以了 func read[T chan E, E int|bool](c T) { _ = \u0026lt;-c }  这里的限制多写写可能会更好理解，多看多学吧，理解go泛型还真有点费解，哈哈哈 🙂\n  go泛型技术细节 # go1.18中的generics（范型）实现思路：\n stenciling（蜡印）这种方式会为范型函数的每种用到的类型参数实例化一个函数，这种好处是会减少函数调用开销，缺点是会导致binary尺寸过大，也可能会导致一些当前无法预见的问题。 dictionary（字典）这种方式不会像stenciling那样为每个类型参数实例化一个，而是就生成一个函数实例，但是多给它传入一个dictionary指针参数，这个指针参数里包含了实际用到的类型参数（parameterized type）对应的具体类型参数（concrete type），有了这个信息就能知道实参的size、alignment等信息，这样在安排内存、栈帧、函数参数、返回值的时候就知道该如何组织了，后续的就没什么复杂的了。这种方式的一个问题，是需要考虑如何优化调用的性能开销。 gcshape，它描述的是在内存allocator、garbage collector视角看起来描述信息长得类似的type，这种type相同的可以实例化一个，这样的话可能有多次实例化，就暗含了stenciling的思想，虽然还是多了传字典，但是省了因为底层type不一样时所要做的额外工作。  本文小结 # 本文简单总结了go泛型编程的一些知识点、注意事项，以及简要介绍了go泛型的设计实现原理。内容没有展开太多，感兴趣的可以参考文章末了列出的参考文献。\n参考内容 #   泛型编程：https://en.wikipedia.org/wiki/Generic_programming\n  初识go泛型：http://localhost:55556/generics/444-first-look-of-custom-generics.html\n  类型参数限制：http://localhost:55556/generics/555-type-constraints-and-parameters.html\n  类型参数实例化：http://localhost:55556/generics/666-generic-instantiations-and-type-argument-inferences.html\n  对类型参数值的操作：http://localhost:55556/generics/777-operations-on-values-of-type-parameter-types.html\n  go泛型目前的状态：http://localhost:55556/generics/888-the-status-quo-of-go-custom-generics.html\n  go1.18 generics设计实现:https://github.com/golang/proposal/blob/master/design/generics-implementation-dictionaries-go1.18.md\n  "}),a.add({id:62,href:"/tags/stenciling/",title:"stenciling",description:"",content:""}),a.add({id:63,href:"/tags/ballast/",title:"ballast",description:"",content:""}),a.add({id:64,href:"/tags/gc-tuner/",title:"GC tuner",description:"",content:""}),a.add({id:65,href:"/tags/gogc/",title:"GOGC",description:"",content:""}),a.add({id:66,href:"/tags/gomemlimit/",title:"GOMEMLIMIT",description:"",content:""}),a.add({id:67,href:"/blog/2022-11-10-go%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E8%B0%83%E4%BC%98/",title:"go垃圾回收调优",description:"go1.19支持了内存软限制，这个内存调优带来了一种新的解决方案。在项目实践中，我们也从压舱石方案切换成了GOMEMLIMIT的方案，过程中遇到的问题、思考，也梳理分享下吧。",content:"相关背景 # 在go1.19之前，go程序内存调优的方式主要是通过环境变量GOGC（或者debug.SetGCPercent(?)）来控制，\n它的效果是影响go runtime计算nextGC heapGoal的大小：\n 较早的版本计算方式为：heapGoal = heapMarked + (heapMarked) * GOGC / 100， 后续go迭代时发现非堆内存也是有影响的，于是go1.18完善了下 heapGoal = heapMarked + (heapMarked + GCROOTs) * GOGC/100，这里的GCROOTS=(gstacks+globals)  GC pacer的目的就是为了根据上述公式计算下次GC的heapGoal，然后在必要时（比如malloc时）决定是否要GC。\n默认初始heapGoal大小为4MB，如果靠GOGC来控制的话，会比较频繁触发GC，对绝大多数server程序而言频繁GC占比较多CPU，程序整体吞吐、响应延迟会受一定影响。\n所以业界一般会通过两种方式来调优：\n ballast，利用一块不用的大内存（比如1GB），来推高下次GC的heapGoal，通过这种方式来降低GC频率 GC tuner，动态设置GOGC，定义一个对象为其设置finalizer，每轮GC结束时触发它并检查当前进程当前的内存占用情况，并与允许的最大内存占用进行比较，并计算出达到最大内存占用才触发GC时GOGC应该设定的值（其思路和go1.19 GOMEMLIMIT类似）  项目以前的方案 # 项目以前使用的是go1.16.5，这个版本中也只有GOGC一个控制GC的选项，使用的是ballast的方案：\n 在服务初始化阶段去初始化一个大内存而推高下次GC时的heapGoal 不同程序可能对内存需求不同，配置文件中允许自定义ballast大小，默认为1GB  包括业界在内都是介绍了ballast如何使用：\n 全局变量声明，垃圾回收器会认为其在整个进程生命周期内reachable 局部变量声明，通过runtime.KeepAlive(\u0026hellip;)来欺骗垃圾回收器这之前对象reachable  但是，好像只看到了一派祥和，我们使用时却遇到了Rss占用问题。\n问题1：ballast占物理内存 # 在测试环境（很多套测试环境）都有比较大概率发现服务在几乎空闲时，物理内存占用竟然高达1.1g…这很不符合常理。\n  通过pprof跟踪内存分配，发现内存分配比较大的路径就是这个压舱石（pprof mem采样是看的虚拟内存）。\n  然后top、pmap等跟踪可疑进程发现其确实存在1GB左右的anon区域，且该区域为dirty**（其实gdb把内存dump一看全是0，就很容易联想到类似对象分配后memset的操作）**。\n  根据了解的go GC、内存分配器相关的知识，了解到go向操作系统申请内存时通过mmap的方式，释放内存是通过madvise+MADV_DONTNEED/MADV_FREE的方式。\n  go1.12的时候改成了FREE默认代替DONTNEED，这两个选项是有区别的，详细的可以看下man手册（man 2 madvise），FREE的效率更好一点，但是也有一些不好的副作用。\n  go1.16之后linux下又恢复成了DONTNEED，因为FREE不会立即让进程的RSS降下来，会误导很多监控、开发运维人员\n  内存分配器为了提高分配效率、GC效率会进行一定的组织，这些概念大家应该有听说过，mheap、spanClass、mcentral、mspan、markbits、allocbits，还有p.mcache。\n smallSize\u0026lt;=32K的分配，走p.mcache（tinySize的更特殊一点，略） largeSize\u0026gt;32K的分配，直接走mheap  这些对象不管是从p.mcache-\u0026gt;mcentral-\u0026gt;arena-\u0026gt;mheap路径来分配的，还是从mheap直接分配的，最终都是建立在从操作系统申请来的page里的，而这些page是由page allocator申请的。即使是很大的对象，最终也是以存在span描述的区域里的。\n一个span可以很多pages，而在里面分配一个对象时，这些page是可以复用的，如果之前其中一个page用过了，但是现在申请一个更大的对象，之前这个旧的page也是所需pages中的一个，那么分配器会先清零memclr\u0026hellip;这段内存区域，这样在操作系统看来就是要真正分配内存，并且因为写了0，那就是全为dirty。\nps：可能我们以为我mmap新申请的内存页面，不写不也是0，为什么不只写之前复用过的page呢？嗯，道理归道理，现在的分配器实现就是这么干的，详见allocNeedsZero(base, npages)这个函数。\n结论：就是通过ballast这种方案初始化有点tricky，在更大范围的应用中不是很可靠：\n 虽然通过一些尽早分配的办法可以避免上述问题，但是不太可靠。因为不确定哪天import了一个包，里面干了些内存分配比较多的操作，说不定影响到ballast占物理内存。 另外ballast这种方案不可移植，它是否占内存与特定平台也有一定关系，并不总是说mmap了一段内存过来不读写就不占内存，windows下的分配就是立即分配。  问题2：可能引发OOM问题 # 本来是想通过ballast来在程序内存负载低时尽量减少GC活动，但是当内存负载高了之后，还是希望它能多清理下GC的，如果清理不及时就容易OOM。特别是混部场景下，这种问题就更明显。\n我们可以在内存占用较高时，把GOGC设置的小一点来频繁的触发GC，来缓解这个问题。但是如果项目已经是使用的GOGC=100+ballast方案的话可能就不是很好调节，因为下次GC的heapGoal已经被推高了。\n如果一开始就采用动态设置GOGC的方式，就更容易实施，比如uber的GC Tuner。在内存占用离上限（uber容器部署时通常取可用物理资源的70%）比较大时就用更大的GOGC（大于100），随着内存占用变高，GOGC也越来越小，通过更频繁的GC来尽可能避免OOM。\n项目现在的方案 # 社区呼吁go能提供内存软限制，目标就是内存占用在达到限制前尽量减少GC活动，当内存占用高了（甚至超了）限制就更及时地GC，以让内存占用保持在一个合理的限制内。\n这个想法其实就和大家最初使用压舱石的初衷比较接近了，也可以用这个方案GOMEMLIMIT/GOGC组合来达到此效果（关掉GOGC=off，指定软限制GOMEMLIMIT）。\nuber的动态GC Tuner的思路和软限制大致类似，不过go1.19为了支持软限制还是做了不少工作的，包括内存使用较高时能够更加激进GC（gcStart）、更加激进地归还内存给操作系统（scavenge）。\n详细了解下GOMEMLIMIT # 和GOGC类似，我们也可以通过环境变量GOMEMLIMIT来指定软限制，也可以通过debug.SetMemoryLimit(?)来设置。\n背景部分我们提到了GOGC如何影响下次GC时heapGoal的计算，GOMEMLIMIT也是通过影响下次GC时的heapGoal计算来发挥作用的，并且是各自根据GOGC、GOMEMLIMIT计算。\ngoal = memoryLimit // p0 - (mappedReady - heapFree - heapAlloc) // p1 - max(mappedReady - memoryLimit, 0) // p2 - memoryLimitHeapGoalHeadroom // p3  解释下：\n  p0：memoryLimit：就是指定的软限制\n  p1：noheap overheads\n  p2：超出限制的部分\n  p3：1mb的headroom（留点buffer）\n  那这里的goal和GOGC算出的goal，以哪个为准呢？可以简单理解为以小的为准，真实情况是有一点点微调，可以不关注。这样当内存占用达到这个goal时，就会触发GC了。\n项目推荐的GC设置 # 首先，要理解GOMEMLIMIT的初衷，它是一个软限制，意思是允许的进程可用内存上限。当进程使用内存少时它可以减少GC来让mutator拥有更多的CPU时间来干活，当进程占用内存高时它可以更频繁GC来回收内存，避免OOM。\n虽然它可以在小内存占用时减少GC频率，但是开发者应该意识到它和ballast还是有差别的。ballast是啥，压舱石的初衷是小内存占用时减少GC频率，但是对内存使用上限并没有控制。\n因此参考ballast的大小为1GB来设置GOMEMLIMIT为1GB或者2GB是没有道理的，我们应该根据实际部署情况来界定各个进程允许的资源使用上限来确定GOMEMLIMIT的值：\n 比如没有混部，per container per service或per host per service，那么可以用70%的内存资源作为软限制值，这样GC频率控制比较好，又留了较多的buffer给系统中其他服务，这也是uber容器化部署的一个经验值。 再比如有混布，一台机器部署了10个服务，那每个进程允许的软限制值肯定不能继续用机器内存的70%这个值，应该划分的更小，比如平均下7%，或者针对不同进程的实际情况在服务配置文件中进行指定。  另外由于go支持通过读取环境变量GOGC、GOMEMLIMIT的方式来在一开始gcinit的时候进行设置，所以我们应该遵循这样的原则，这两个变量都应该独立遵守下面的原则：\n 环境变量配置优先级最高，这样符合go使用习惯 环境变量未指定时，读取配置文件中的自定义值 如果配置文件没指定，则使用默认值  软限制实践的过程 # 最开始确实是直接GOMEMLIMIT=1gb+GOGC=off这样来设置的，但是测试过程中发现，这个方案是有问题的。有经验的开发人员可能已经意识到问题在哪里了：\n  ballast方案中，我们并不会GOGC=off直接关闭GC，这样虽然ballast推高了下次GC的阈值，但是sysmon还是能做到每隔两分钟（2min）强制GC一次的（forced GC）。所以如测试环境下观察的那样，大多数进程实际占用物理内存并不多，因为GC回收内存了；\n  而在我们GOMEMLIMIT+GOGC=off组合情况下，因为GOGC被关闭了，此时sysmon即使过了2min这个间隔期，也不会去触发forced GC（这个从源码中一看便知）。这样问题就来了，当内存占用小于1GB时基本上不会触发GC，因为非堆内存占用很少，按照GOMEMLIMIT计算出的下次的heapGoal跟GOMEMLIMIT差不多，所以基本上不会触发GC，这就会导致各个进程占用物理内存接近软限制，而如果混部的go进程多的话，就很容易导致机器内存占用率过高。\nps：我们是一台物理机部署了70个微服务，内存缓慢增长到了1gb作用。\n  那我们应该如何进一步解决这个问题呢？解决问题前，首先要搞清楚我们追求什么。\n  在进程内存占用很少时，尽量不触发GC，或者不要频繁GC；\n这个问题可以归结于GOGC=off+GOMEMLIMIT设多大的问题\n  在进程内存占用较多时，要触发GC来回收内存，不要因为达到容器、虚拟机、物理机等分配的资源限制（cgroup来控制）被OS给OOM kill掉；\n这个问题可以归结于GOMEMLIMIT上限设多大合适的问题\n  进程steady状态时占用内存不要停留在GOMEMLIMIT附近，以避免频繁GC对服务性能产生不良影响、抖动；\n这个问题可以归结于服务负载均衡、监控问题，超过软限制即超出预期处理能力，需要告警并扩容\n  这就是我们一步步得出前面go1.19 GC推荐设置的过程和思考。\nps：在升级go1.19并调整GC设置后，项目压测发现这个性能提升也是比较明显的，提升了1.2~1.3倍，能提升多少其实和具体项目处理逻辑相关，就不多展开了。\n还有一个问题，加了软限制后是否内存占用一定小于软限制值？\n  首先，不一定。\n  其次，这要看在特定负载下的内存分配、标记清除速率。通常可以根据GC cycle结束时collector扫描的内存量、分配内存和标记内存的比率、mutator:collector的cpu时间占比75%:25%，key算出下个GC Cycle中大致能分配的内存量。这个值也是一个触发GC的参考值，通过这个能够让内存分配、回收保持一定的稳态。\n  当内存分配时，g可以被要求作为assistG去清理一定量的内存，然后再执行分配，清理和分配的内存量差不多，通过这个也能让进程内存占用保持一定的稳态。\n  scavenge清理内存时现在也会参考这个软限制值，去释放内存给OS，这也是一个可以保持内存占用处于稳态的方法。\n  感兴趣的可以读下这块的源码，太多细节的东西，已经不能随意找到博客、文章给解答了 :)\n关于GC Tuner # 关于动态GC调优，uber有一个实现方案，根据其公开的技术文章 Uber\u0026rsquo;s Engineering Manages to Cut 70k CPUs by Tuning GO GC，大致是一个动态设置GOGC来让进程占用物理内存尽量不要超过设定的内存占用百分比的一个东西，从这个意义上来说，它的作用和GOMEMLIMIT很类似。github上有个参考实现，详见 GC Tuner。\n但是如前面所说，go1.19在支持软限制方面，除了内存占用较高时更频繁地触发GC（gcStart），也会更频繁地进行内存释放归还给操作系统（scavenge），效果会更好。所以已经升级到go1.19的项目建议使用软限制代替GC Tuner。\n既然是动态调优，可能意味着更大的可定制型，也不排除大家后面能搞出更优秀的GC Tuner来，怎么调优就不是本文要讨论的了。\n相关的注意事项 # 其实不管是通过以前GOGC这个唯一控制项，还是现在GOGC+GOMEMLIMIT组合的方式，开发人员都应该对自身服务性能、资源占用有个清晰的认识。这就是说，在必要的部署机型下做压测应该常态化，这样才能在服务部署运维时有更清晰的认识，内存占用多少算是正常、不正常，负载多高应该选择扩容、缩容。\n现在很多都已经容器化部署了，但是对于扩缩容依赖的CPU、MEM阈值要有认识。容器化部署隔离性好一点，如果存在混部，那对这里GOMEMLIMIT=?+GOGC=off还会有更好的认识，因为GC不及时可能导致混部的其他服务申请不到内存资源。\n不管用那种GC调优，对服务自身的认识都是每一个开发人员所应该关注、提高的。\n"}),a.add({id:68,href:"/tags/%E5%B7%A5%E4%BD%9C/",title:"工作",description:"",content:""}),a.add({id:69,href:"/tags/%E6%84%9F%E6%82%9F/",title:"感悟",description:"",content:""}),a.add({id:70,href:"/tags/%E8%85%BE%E8%AE%AF/",title:"腾讯",description:"",content:""}),a.add({id:71,href:"/tags/%E8%A3%81%E5%91%98/",title:"裁员",description:"",content:""}),a.add({id:72,href:"/blog/2022-10-01-%E8%A3%81%E5%91%98%E5%B8%A6%E7%BB%99%E6%88%91%E7%9A%84%E6%80%9D%E8%80%83/",title:"裁员带给我的思考",description:"沸沸扬扬的大公司裁员事件沸沸扬扬，矜矜业业、努力工作的我怎能想到这事也会降到我头上，我也有过短暂的困惑期，但是思考之后也就释然了。事情已经过去快4个月了，最终也会渐渐淡忘那段不愉快的时间，但是教训、反思不应该忘记。趁此国庆假期有时间就整理一下。",content:"本文简介 # 今天是国庆节，没抢到合适的高铁票去武汉，今天索性在深圳休息一天再走。回头看今年各互联网大厂大范围裁员的事情，看法也更全面了许多，就不讨论那些企业家有没有责任感的事情，就从家庭、个体工作生活角度谈下自己的一点看法。\n裁员事件 # 听到一点风声 # 从2019.7之后，我一直在从事PCG微服务框架的支持工作，我们会每两周开一次PMC迭代例会同步下规划及进展，有一次会议上，我们评估各语言版本微服务框架今年可能新增的实例数的时候，大家按照过去21年的新增趋势评估，结果有个领导说我们太乐观了，说今年PCG有很多业务要面临下线。\n开始看到瞄头 # 这是我当时听到的最早的“小道消息”了，但是没有当回事。后面过了一阵子，突然听说各大厂开始裁员了，但是各种消息、公关消息夹杂在一起，事情没发生在自己身边，也没觉得有多大影响。后面就听说同“幸福线（信服线）”隔壁几个中心开始裁员了，后面还是开例会的时候，有个子项目trpc-dart负责人说他们那边人员变动比较大，暂时没人力支持需求开发了。我当时开始想这么严重么，后面陆续开始关注这方面消息，涉及到的人是比较多。\n我也难逃此劫 # 再后面，就直接裁到我们这边了，先是组里面的工作年限短的收到毕业通知，裁完一波后，据说裁了很多人没降什么成本，于是开始裁高T、裁组长…后面就到我头上了。\n其实，我们技术总监等其他同事有跟我通过气，意思就是说裁到后面实在没办法了，当时收到消息的时候，虽然有点难过，但是很快就释然了。难过是因为自己好歹也为业务技术支撑、为公司微服务框架做了不少贡献，结果因为业务不景气、为了降“成本”就把工资高（贡献也多啊）的老员工直接裁掉，虽然说赔偿比较良心，但是你懂得心理上还是不认同这种粗暴的裁员方式的，那时候真的准备离开腾讯了。\n我的看法 # 业务调整是迟早的事 # 业务不景气已经不是一天两天了，只不过以前公司在各方面压力比较小，像这些不挣钱的业务也就这样活下来了，还养活了一部分人。\n只是心理上难接受些 # 像我是一毕业就SP进入了腾讯，6年时间先后做了几个业务，也做了些公线支持的工作，框架、规范、工具、培训分享等，内心对公司的归属感是很强的，这次简单粗暴的大范围裁员，让人感觉这些年算是瞎了眼。公司确实是家好公司，但真的不见得每个人都优秀。行业可能竞争比较激烈，可能业务发展遇到了瓶颈，但是你能感觉到有些领导在犯错，光嘴说的好听，动作搞的很大，但是树立一个个山头、做的事实少、能有高价值产出的就更少，业务也没有好的起色。\n整体形势差换工作难 # 已经是山头、嫡系林立的丛林社会了，这种情况下即便是想留下有能力的员工也近乎不可能，谁来评判呢。而且这个时候，领导们只想留下自己的嫡系，而非有能力的员工。有能力的员工，自然不用担心找不到工作机会，理论上是这样，前提是得有这么多就业岗位。今年大形势不好，很多公司都在裁员，最后这被裁的一两万同事要到外面去找机会，大厂普遍裁员，没这么多机会，很多同事只能去第二梯队的企业（业务不一定不行哈）。\n我旁边的一些同事，从接到通知就开始准备找工作，等到lastday离职哪天，有的也还没有拿到offer，当然最后他们找到offer了，但是这确实能看出来就业形式比较差。\n对公司不再有归属感 # 这种事情发生之后，咱也不哭不闹，不过是看清了这个丛林社会中，谁也靠不住，公司再好它也不是家，自己首先要考虑的还是家庭、家人、自己，摆工作的重要性往后放放。工作上，没了你随便找个人就能代替，再说了，就算是没人代替你大不了短期内工作没法推进了，但是依旧还可以维持。说白了，自己对公司业务来说没那么重要。没必要掏心掏肺的，为了点鸡毛蒜皮的小事牺牲自己那么多精力去忠心耿耿地工作，影响到家人就更蠢了。\n现在对腾讯已经没有任何“家”的感觉了，也不在KM上讨论问题了，公司内发生的事情也不再关心了，公司外的形象也不想去维护了，努力做好自己分内的事，拿钱干活。但是努力做好本职工作、提升自己、提供更好的产品服务，这个目标不能打折，程序员的自我修养。\n要明白来工作是为啥 # 人活着，时间精力有限，心里能装的东西有限，归根结底，我们还是要多体验些美好的东西，少为这些乱七八糟的事情浪费心神。裁员就裁员，要么活水去好的业务团队，无论学习、沉淀、挣钱都还有保障，要么出去找更好的机会。我来腾讯不就是为了来锻炼长经验的吗，多挣点钱更好。\n还是要坚持自己的想法，提升技术的同时，多看看有哪些小成本的试错机会能致富的，比如羊了个羊这样的小游戏，搞一个成功了，说不定就财务自由了，即便是没这么成功，多几种收入来源也是不错的。\n本文小结 # 最后，祝愿所有一起奋斗过的小伙伴们保重身体，找到合适的工作机会。\n"}),a.add({id:73,href:"/tags/chubby/",title:"chubby",description:"",content:""}),a.add({id:74,href:"/tags/distributed-lock/",title:"distributed lock",description:"",content:""}),a.add({id:75,href:"/tags/redlock/",title:"redlock",description:"",content:""}),a.add({id:76,href:"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/",title:"分布式锁",description:"",content:""}),a.add({id:77,href:"/blog/2022-09-25-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%96%B9%E6%A1%88%E7%9A%84%E6%80%9D%E8%80%83/",title:"分布式锁方案的思考",description:"微服务架构中分布式锁是一项比较常用的技术，但是并不是每个用过分布式锁的开发都正确认识了分布式锁。本文对分布式锁要解决的问题、实现技术进行了讨论，并对可用性更高的场景对锁服务设计实现提供了两个思路。",content:"问题背景 # 在微服务架构下，经常面临一些事务性处理需要考虑一致性的场景，笔者工作过程中，很多场景最终都采取了可用性优先、数据最终一致的方案。最后我们可能也会结合一些对账之类的手段来发现异常并修复不一致的数据。\n归根结底，是因为微服务架构下上述事务性处理方案没有保证刚性事务的ACID原则，其弱化了对A、C的控制，OK，这种方案并非不可接受的，只要业务场景适用即可。这里还有一点就是I（Isolation）的原则，如何保证微服务架构下事务处理的隔离性呢？\n分布式锁，就是大家常用的方案，只不过关于对分布式锁的认识，可能大家认识的程度并没有自己认为的那么到位。\n常见方案分类 # 分布式锁，归根究底是为了保证任务的排他性执行。但是为了排他性执行的初衷却可能是不同的，所以我们接下来会先按照要解决问题进行分类。然后呢，考虑到可用性、正确性，实现分布式锁的具体方法也是不同的，然后我们也可以按照实现方式进行分类。\n按解决问题分类 #  解决效率类问题：为了避免资源浪费，如每天统计下业务下所有服务接口成功率数据，这类定时任务也是多机部署的避免单点问题，但是只要一台机器执行就行了，属于解决效率类问题。没有必要多台机器执行，但是即便都执行了也没啥影响，只是后面执行的覆盖掉前面的执行了，仅此而已。 解决正确性问题：任务必须排他性执行，如果并发执行则存在正确性问题。比如用户购买游戏道具时需要读取玩家金币数、扣金币、写回，这里涉及到典型的Read、Modify、Write的问题，如果这个操作时序不是排他性的，就掺杂着重置、送礼等各种可能修改金币的操作时序，则会导致正确性问题。  按实现方式分类 #  基于缓存实现：比如利用redis、memcache等实现，分布式缓存一般提供了get、set的能力，允许给key、value指定版本、排他性、过期时间属性，来实现分布式锁。 基于共识算法实现：比如etcd、zk这类底层有raft、zab共识算法支撑的组件，借助他们可以比较可靠的实现分布式锁，至少能保证分配锁时不会导致client错误持有锁。  在实际实现、使用分布式锁时，我们多数时候是冲着正确性去的，但是方案本身其实是不完备的，但是我们却将其当做了“正确的”。\n常见方案介绍 # 基于redis单机版 # 比较常见的就是单机版的redis实现版本，如下所示：\n# 加锁操作 SET resource_name my_random_value NX PX 30000 # 解锁操作 if redis.call(\u0026quot;get\u0026quot;,KEYS[1]) == ARGV[1] then return redis.call(\u0026quot;del\u0026quot;,KEYS[1]) else return 0 end  实际情况是单机版redis存在单点问题，为了解决这个问题，通常又会给redis master挂个slave来备份数据，但是redis的备份机制是异步的，所以仍然存在主备切换时丢失锁数据而导致的错误加锁情况，解决不了正确性。\n基于redis集群版 # 集群版的redis，用的比较多的是redlock算法。redlock算法主要是解决单点故障问题，它的主要思想是，假设集群中有N个（建议值5）master节点，这些master节点及其replicas各自维护一些不相干的keyslots。加锁时，client先获取本地时间，然后串行地向N个节点发起请求，是串行的。\n至于详细的实现，redis官网上有这些推荐实现的github repo链接，可以自己去找找看。\n其实这个算法也解决不了网络波动、分区极端场景下，依然会导致client错误持有锁的情况，比如1、2、3、4、5个节点，一开始网络正常client1持有了1、2、3上的锁，后面网络波动导致client只能访问3、4、5，并且3发生了主备切换而备份上缺少数据，client依然能在3、4、5上获得相同锁。\n 尽管redlock算法提出了一些可以缓解正确性被破坏的想法，但是仍然不能保证分配锁时的正确性。\n 基于etcd实现 # etcd本身是基于raft算法实现的副本的状态复制，是有可靠的共识理论支撑的工程实现，另外etcd号称其raft算法实现有着比paxos算法更好的性能（这个没求证，多数情况下paxos算法可能性能更优点，也不一定非得有master节点），感兴趣的可以自行了解。\n基于etcd的分布式锁实现，已经内置在etcd中了，直接使用即可。\n因为示例代码的篇幅原因、go.mod设置等，我们就不在这里占用太多篇幅了，感兴趣的可以直接查看这里的示例代码：https://github.com/hitzhangjie/codemaster/blob/master/distlock/main.go。\n思考下 # 我们从解决效率问题的分布式锁，到解决正确性问题的分布式锁，对锁分配正确性的要求提升了一档，关于其实现方案，也从基于redis、redis集群版的方案，也过渡到了基于raft算法的etcd实现（其他的基于paxos、zab共识算法的类似就不介绍了），我们解决了锁服务分配锁时的正确性问题，但是这样就能保证任务排他性执行了吗？\n不能！client在使用锁的时候，可能会出现如下情况：\n client出现了崩溃、逻辑bug，导致锁没有被正确地释放掉，如果锁没有过期时间，将导致其他client加锁时出现死锁； client加锁时设置过期时间，但是过期时间可能设置的过短，锁过期被etcd清理然后又重新分配给了其他client，然后旧client还以为自己别锁保护的临界区内还可以肆意妄为，导致并发执行错误； client加锁时设置了合理的过期时间，但是自身因为其他原因出现了一定时间阻塞，恢复后继续执行，但是锁实际已经过期被释放； client执行操作时锁确实是有效的，但是在其发起对下游的请求后，下游继续处理期间锁过期，其他client持有了锁并发继续执行操作；  看到没，即便是锁分配是正确的，client使用锁时依然无法100%保证正确性，这个问题能100%解决吗？不能，但是可以尽可能缓解，比如合理设置锁过期时间，比如请求方调用下游服务时，把锁信息带给下游让下游能够去锁服务校验锁有效性。\ngoogle chubby # chubby是谷歌内部的专用的锁服务，没有对外部开源，但是通过其发表的论文，开源社区实现了zookeeper。这里只简单介绍下chubby的核心思想。\n 易用性：以锁服务api的形式方便业务接入 容错设计：  副本机制：锁服务节点，加解锁操作通过 paxos复制到副本。避免节点故障数据丢失问题，同时paxos复制保证了数据的同步准确性； 锁过期机制：锁服务分配的锁都是有过期时间的，过期的锁会被清理掉。避免client锁持有者因为逻辑错误、崩溃、阻塞等导致锁长期未释放导致的死锁问题； 锁清理机制：client锁持有者有可能出现崩溃，锁服务和client之间维持着一个会话，当检测到对端不可用时，锁服务会主动清理该client申请添加成功的锁。避免相关的锁不能及时被释放（不必等到锁过期，chubby锁是粗粒度锁，可长达几个小时）； 锁序号机制：只有client、server、锁服务全部参与进来，才能尽可能保证任务执行的排他性，锁服务可以保证锁分配的正确性，但是毕竟是建议性锁，client应该尽可能在锁有效期内完成所有操作，而下游server应该在执行操作前校验client传递的持有锁信息的有效性，校验是在server和锁服务之间完成的，这里的锁信息主要指的就是锁的序号（类似版本号的玩意）； 持久化机制：每个节点挂掉后可能恢复，恢复后它的数据是全部丢失还是可以恢复回来？一般是要借助合适的存储手段对这些数据进行存储，然后节点后恢复可以快速恢复。chubby是如何做的，感兴趣的可以自己查下。    我们看到google chubby确实考虑的比较周全，但是它也有自身的局限性。它适合用来做粗粒度的锁服务，比如锁持有时间长达几十分钟、几个小时这种，对于细粒度锁，比如小于1s，这种就不太合适了，为什么这么说呢？\nchubby是基于paxos来做的，paxos能保证状态复制的正确性，是基于多轮rpc通信来保证的，而rpc有网络通信开销，对于延迟敏感的处理路径，业务不一定能接受这个开销。而且chubby是有主节点的（paxos本身支持无主节点，但是代价是更多的消息交换），有主节点瓶颈的。因此，google内部也是将其用作粗粒度锁的，比如一些分布式系统的选主。\n如何方案选型 # 业务中如果希望引入分布式锁，选型的时候可以思考下自己到底是解决哪类问题？\n 如果是为了解决效率类问题，直接用redis方案就挺不错的，考虑到单点问题可以挂个slave，也没啥问题； 如果是为了解决正确性问题，也可以用redis redlock方案，但是要明白其可能存在的风险，业务能否接受； 如果对正确性非常重视，对于并发写冲突的情况完全不可接受，反而可以接受一些可用性损失，那我建议直接用etcd、zk等方案更合适； 如果业务更追求可用性，同时尽最大可能保证正确性，那也不妨考虑redis redlock，如果也不想引入额外组件增加运维工作量，也不妨考虑自研一个分布式锁；  自研分布式锁 # 方案1：和业务紧密结合的经济使用方案 # 现在只想优先保证业务可用性前提下，尽最大程度保证正确性。可以考虑如下方案，结合下图进行一下简单说明：\nclient（上游服务）访问一个下游逻辑服务时，如果uid相同的话，为了尽可能并发对同一个用户的数据做并发RMW操作时出错，需要分布式锁进行排他性控制。\n分布式锁的分配，可以考虑etcd来分配保证锁分配的正确性，但是之前考虑到etcd也是基于共识算法的，其大概率也不适合做细粒度锁支持，另外其failover时间一般是要10~20s左右的，如果业务中请求量很大，这么长时间不可用是不可接受的。\n我们可以进行这样的优化：\n 锁分配还是由etcd来分配，但是我分配的是一把大锁，什么意思呢？ 当某个uid1请求到来，client1希望请求logicsvr集群做某种操作时，这里client1通过一致性hash的方式，将uid=uid1请求发到节点logicsvr1处理，logicsvr1现在要rmw uid1的数据，为了保证排他性执行的正确性，它向etcd申请加锁，这个锁有效期比较长，比如1h，以后所有uid1的请求都会通过一致性发送到logicsvr1来处理，因为这个锁一直被logicsvr1持有着，不会有其他logicsvr和它并发rmw，但是？ 当client1请求发生路由漂移，请求发到了不是logicsvr1而是logicsvr3之后，logicsvr3发现自己没有锁，怎么办，肯定是要先申请加锁，此时etcd告诉它锁已经存在了不能加锁，etcd主节点的读操作效率是可以的，所以这种路由漂移情境下量也不会很多，对etcd加锁请求的开销是不用太担心的。  此时logicsvr3知道锁当前是logicsvr1持有，它可以转发请求给logicsvr1去处理； 大多数情况下转发过去logicsvr1会处理成功，因为此时只是路由漂移导致的，并不是logicsvr1挂掉了； 如果logicsvr1挂掉了，etcd也会清理掉起持有的锁，此时logicsvr3加锁成功，自己做处理就可以了；    这个方法可以应对：\n  正常情况下的排他性执行问题，避免了每个操作都申请锁的开销；\n  异常情况之一，logicsvr扩缩容等其他原因导致的路由漂移时的排他性执行问题；\n  这个方法解决不了：\n 如果logicsvr内部发生了网络波动，导致内部节点间转发等出现问题，就会退化为全部向etcd申请加锁的情况，可能会导致链路处理latency上升，etcd负载加重。  方案2：稍微通用点的分布式锁方案 # 再一种方案，就更容易想到些，我们可以基于多数派投票的方式来完成复制，每当申请加锁时，我们直接在当前locksvr加完锁后，同步地复制到其他locksvr实例节点，多数成功才认为成功并返回给client（如果失败可以异步地发起清理）。\n这种缺点就是每个locksvr节点相当于复制了完整的锁数据，且集群中消息量会比较多。\n那我们可以用一致性hash复制的方法来完成复制，比如locksvr收到请求lock(uid1)之后，可以拿这几个做key：uid1:0、uid1:1、uid1:2，分别计算一致性hash对应的节点，假设为locksvr1、locksvr3、locksvr5，那么写入即可，多数成功就认为成功。\n当然考虑到并发写入时有助于减少latency，也可以把这个请求加锁、复制锁的操作全部由locksvr来发起，那最大延迟就取决于响应最慢的哪个locksvr节点。\n这个方法可以应付：\n 锁方案比较通用，不用在logicsvr内部写那些加锁后判断锁持有者、转发请求给锁持有者处理的特殊逻辑； 大部分正常场景可以应付； locksvr本身内部的扩缩容、故障导致的路由漂移，可以应付（除非uid1对应的所有写入节点全挂掉了）； 锁数据存储全部是内存内计算，性能应该是没问题的； 也不需要引入额外的什么组件；  总结 # 最终需要什么样的方案，还是取决于实际的业务场景，没有什么方案可以以不变应万变。\n参考内容 # [0] 如何实现分布式锁, https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\n[1] 分布式锁需要各参与者参与, https://hazelcast.com/blog/long-live-distributed-locks/\n[2] 谷歌锁服务chubby论文, https://github.com/hitzhangjie/distributed-system-series/blob/master/papers/distributed%20lock%20-%20chubby.pdf\n[3] 伸缩性更好的层级chubby, https://github.com/hitzhangjie/distributed-system-series/blob/master/papers/distributed%20lock%20-%20hierarchical%20chubby.pdf\n[4] etcd实现分布式锁, https://medium.com/@felipedutratine/distributed-lock-with-etcd-in-go-d21e7df145bc\n[5] redis分布式锁redlock, https://redis.io/docs/reference/patterns/distributed-locks/\n[6] 分布式锁jepsen验证框架, https://github.com/dist-sys-dev/jepsen\n[7] 根据论文实现的chubby, https://github.com/dist-sys-dev/chubby\n[8] 层级chubby实现, https://github.com/dist-sys-dev/Hierarchical-Chubby\n"}),a.add({id:78,href:"/tags/consistent-hash/",title:"consistent hash",description:"",content:""}),a.add({id:79,href:"/tags/consistent-hash-with-bounded-load/",title:"consistent hash with bounded load",description:"",content:""}),a.add({id:80,href:"/tags/hash/",title:"hash",description:"",content:""}),a.add({id:81,href:"/tags/jump-consistent-hash/",title:"jump consistent hash",description:"",content:""}),a.add({id:82,href:"/tags/loadbalance/",title:"loadbalance",description:"",content:""}),a.add({id:83,href:"/tags/multi-probe-consistent-hash/",title:"multi-probe consistent hash",description:"",content:""}),a.add({id:84,href:"/tags/rendezvous-hash/",title:"rendezvous hash",description:"",content:""}),a.add({id:85,href:"/blog/2022-08-06-%E4%B8%80%E8%87%B4%E6%80%A7hash%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%96%B9%E6%A1%88%E7%9A%84%E6%80%9D%E8%80%83/",title:"一致性hash负载均衡方案的思考",description:"本文从一致性hash负载均衡策略触发，深入了解了下不同的方案变体，最后针对普适应更好的一致性hash方案、go-zero实现、实践中的引用改进进行了探索介绍。",content:"常见的负载均衡策略 # 客户端完成被调服务的服务发现后，获得了一批实例节点列表，现在要借助合适的负载均衡算法来选择一个实例完成请求处理。\n常见的负载均衡算法包括：\n 轮询：每一次网络请求按照顺序发放给下节点列表中的下一个节点，这种情况适用于节点配置相同并且平均服务请求相对均衡的情况 加权轮询：考虑了不同节点的硬件配置情况，如节点a、b、c性能有低到高，权重设置为1、3、6，则按照权重分配10%、30%、60%的请求给到节点，这种可以避免高性能机器负载低、避免性能差机器过载 随机：随机选择一个节点来处理请求，这种在请求量比较大的情况下能达到相对均衡的分布，同样适用于机器配置相同的情况 加权随机：考虑了不同节点的硬件配置情况，类似加权轮询，只不过选择下一个节点时是基于随机选择，而非轮询的方式 余数hash：根据某个key对节点数做取模运算，比如节点数为n，根据请求中的m = uid % n，表示用节点列表中第m个节点来作为服务节点。当key分布范围比较广能达到相对均衡，选择key字段的时候要考虑下key分布情况。使用hash的场景，一般是因为后端节点有状态可复用（或者希望借此减少并发冲突），但真实环境中，节点故障是常态，尤其是在容器化部署场景下自动化扩缩容，hash会导致集群中所有节点状态无法被复用。一般会用一致性hash代替hash。 一致性hash：一致性hash是对hash的优化，一致性这里强调的就是节点加入、离开后尽量保证大多数请求仍然能路由到该路由的节点，而不是新加入的节点，同时为了避免新加入、离开节点导致的负载不均衡问题，引入了虚拟节点的概念，每个物理节点都对应着hash换上一定数量的虚拟节点，这些节点混在一起，能实现各个节点负载的相对均衡。节点数量该选择多少呢？一个比较直观的认识是可能虚拟节点越多越均衡，但是数量过多也会有开销，这与虚拟节点的hash计算、存储有关系，本文后面讨论。 按响应速度：有些负载均衡设备，会根据与后端服务节点间的ping延时来选择一个响应时间最短的。类似的也可以根据client、server之间的ping延时或者请求处理响应时间来选择。 按最少连接数：对于某些请求处理时间比较长的场景，如ftp传输等，一个tcp连接存在的时间可能比较长，连接数比较多的可能代表该节点负载比较重，因此会开率选择连接数比较少的来提供服务。 其他  负载均衡算法有很多，之所以这么多也是因为应用场景的差异，根据合适的场景选择适用的负载均衡算法。\n调研一致性hash策略及其可替代方案 # 对一致性hash方案及其可替代方案进行调研、对比。\n余数hash # 余数hash，简单讲就是那个key去算出hash值，然后对节点数量取模，m = hash(key) % n，用节点列表中的第m个节点去做请求处理。 如果节点数变化非常不频繁，或者说key remapping（rebalancing）过程中带来的开销不大、影响不大，那用余数hash也无所谓。\n但是现实场景中，比如一些有状态服务，如果remapp后映射到了与先前不同的节点，或者容器化部署时节点数经常变更，不满足适用余数hash的条件。\n比较常见的对策，就是采用一致性hash。\n一致性hash # 简要介绍 # 一致性hash能够缓解节点加入、离开时rebalancing导致的一些hash节点改变的问题，在以下场景中就更有优势：\n  服务是有状态的，这样大多数路由仍然能路由到原来的节点，状态可以复用；\n  即使服务不是有状态的，将原来路由到节点n的请求及其后续请求继续路由到该节点，也可能存在更好的局部性处理（locality），\n 举个例子（可能不很恰当哈）： 比如有个个人展示页要展示头像昵称、最近游戏记录，假设之前有个什么客户端请求uid=xxx的请求路由到了节点n拉取过了昵称头像并cache，后面该展示页也路由到该节点的话就可以复用该cache。\n   假设key空间中值数量为k，节点数为n，那么当发生remapping时，笼统估算有k/n不命中原来的节点。\n关于实现 # 关于一致性hash的实现：\n 构建一个一致性hash环，一个数组就可以实现 选定节点的key，如ip，hash(key)，然后再hash换上对应位置存储该节点信息，考虑到hash环大小需要适当取模 考虑到各节点的负载平衡，引入虚节点，每个物理节点对应为k各虚节点（k多大？），各个虚节点的hash值计算就分不同方法：  key多大？兼顾计算效率和负载均衡性，因为节点数提前无法预估，可能要选择一个更好的经验值 引入k个hash函数，hash1(key), hash2(key), hash3(key)\u0026hellip;.hashK(key)，分别设置到hash环上 针对key，构造key_1, key_2, key_3..，keyK，使用同一个hash函数分别计算上述key的hash，并在hash环上设置其节点信息 TODO 这里的计算方式的选择，虚节点数多大（过少还是会不均衡），过大计算效率慢（多次计算hash），另外多个hash还是构造多个key也可能会影响到负载的均衡性，需要针对性的测试。   现在有个请求，比如用玩家userid作key，hash(key)得到值之后，因为一致性hash环是个收尾相接的有序数组实现的，可通过二分查找（查找第一个大于等于该hash(key) )的节点，复杂度O(logn)  一致性hash，对于带权重的也能支持到：比如a机器比b机器性能高一倍，希望其处理两倍于b的请求，那么就可以让a机器的虚节点多一倍。但是如果管理的节点数量成千上万之后，hash环上存储这些虚节点的开销就不能忽略了。\n一致性hash替代方案：Rendezvous hashing # Rendezvous hashing，也叫Highest Random Weight hashing。它比一致性hash提出来早一年，用了一种不同的方式来解决余数hash中key remapping的问题，也能实现一致性hash中 “需要remmap的keys数量=k/n” 的这种效果。\n它是怎么做的呢？将请求key和机器节点的key（比如ip），合在一起做hash（不像一致性hash那样分开做hash），然后选择hash值最大的那个机器节点。\ntype router struct { endpoints []*Endpoint } func (r *router) Get(key string) *Endpoint { var ep *Endpoint hashVal := -INF for _, e := range r.endpoints { h = hash(key, e) if h \u0026gt; hashVal { ep = e hashVal = h } } return ep }  这种方案的最大问题是O(n)的计算复杂度，一致性hash是O(logn)查找复杂度，不过如果节点数不是很多的话，这个开销可以接受。\nps：测试了下，rendezvous hash到各个节点一次记load+1，那么100w请求时，各节点load负载标准差387，最大、最小节点负载占总负载（100w）比例为1/1000。\ngo-zero实现的经典的一致性hash算法，虚节点数量100个，默认的hash函数（不一致哈），100w请求时，各节点负载标准差1w+，最大、最小节点负载占总负载（100w）比例为5/100。\n一致性hash变体：jump consistent hash # 相比传统的环形一致性哈希，空间复杂度更低，根本无内存占用，而且算法非常简洁，C++的实现不到10行代码就可以搞定。\nint32_t JumpConsistentHash(uint64_t key, int32_t num_buckets) { int64_t b = -1, j = 0; while (j \u0026lt; num_buckets) { b = j; key = key * 2862933555777941757ULL + 1; j = (b + 1) * (double(1LL \u0026lt;\u0026lt; 31) / double(key \u0026gt;\u0026gt; 33) + 1); } return b; }  但是jump consistent hash存在它的局限性，使用场景受限：\n 服务器名不是任意的，而是按照数字递增，它更适合应用于数据存储场景，如随着时间增长、数据量变化有创建出更多的shards之类的场景。 jump consistent hash只能在节点列表末端增加、删除节点，不能从中间任意删除节点，所以才说它适合用于存储类场景，比如数据容量大了，我们增加一个shard，或者说一个中间的shard崩溃了我们通过replicas复制来应对等。  在rpc场景下，后面任意一个节点都可能故障，我们需要从节点列表中删除任意一个节点的灵活性，所以说jump consistent hash不适用。\n一致性hash变体：consistent hash with bounded load # 这里的bounded load是啥意思呢？也是为了保证集群中各个节点的负载相对均衡，怎么做到呢，一个简单的思路就是：返回一个可以处理这个key的负载还ok的节点。\n1. 返回一个能处理这个key的节点，怎么理解呢？\n还是根据经典一致性hash的思路，计算key的hash从一致性hash环上找到第一个\u0026gt;=这个hash的虚节点，然后找到对应的物理节点信息。按经典一致性hash算法，此时就准备返回了。但是这里的方案变体还有其他事情要考量。\nps：在这个方案变体，一致性是要考虑的，但是负载均匀也是要考虑的，而且重视程度更重。经典一致性hash算法中，无论我们怎么设置虚节点数量、选择hash函数，包括给性能高的物理节点分配更多看似合理的虚节点等等。总有可能会出现负载不均衡的情况，负载均衡是一个理想值。我们在跑测试的时候也可以看到节点的最大、最小负载（hash一次load+1）相差很明显。怎么针对负载做优化呢？\n2、如何做到负载相对均匀?\n假设我们规定，返回一个节点时更新这个节点的load（load+1）、同时更新总的totalload，这样我们就能计算各个节点的avg load。如果第一步中待返回的load超过了avg load，我们就不返回该节点，而是从当前hash环当前虚节点位置继续向下遍历，直到找到下一个负载小于avg load的节点。\n有没有两全其美的方案？\n简单对比下，经典的一致性hash 及 jump一致性hash：\n ring-based consistent hash，以较大内存为代价，提供了增删任意node的灵活性，但是呢它的负载不够均衡。经典的实现里各个节点的负载是有偏差的，这给我们进行系统容量评估带来了些挑战，除非我们把虚节点加大，比如1000、2000。 jump consistent hash，以极低的内存消耗，提供了高效的负载均衡，负载均衡均匀性也比较好，但是损失的是灵活增删节点的灵活性，这导致它在存储类shards路由场景中比较适用，其他场景则不适用。  那有没有两全其美的方案呢？（实际上没有）\n Multi-Probe Consistent Hash（简写为MPCH），就是为了解决这里的问题的，也是google提出的。  优点：它支持O(n)的空间复杂度（胜过ring-based一致性hash），支持O(1)的插入、删除时间复杂度（胜过jump一致性hash），支持增删任意节点（胜过jump一致性hash） 缺点：它的查询复杂度下降了，假设我们追求的均匀性，比方说负载的peak-to-mean为1.05%，那么需要做21轮hash（有公式可以算，略）， 达到相同负载偏差，ring-based一致性hash需要700*ln(n)，n为100个节点时hash环存储时就要1m内存。   Maglev Hash方案，Maglev是google的网络负载均衡器，内部也用了一致性hash方案，我们简称maglev hash方案。maglev在google类似我司tgw这层，通过vip转发外部数据包给内部服务器时，希望尽量复用以前的tcpconn并在后端节点变化时做最少机器迁移：  优点：和ring-based一致性hash和rendezvous hash方案比，有不错的低内存开销、查询速度 缺点：maglev hash依赖一张查询表，当后端节点出现失败时构建这个查询表开销比较大，这也限制了后端节点的最大数量。    我们期望的完美的hash方案应该是什么样的?\n调研了这些hash方案后，我们希望有这样的完美的hash方案：\n Only 1/n percent of the keys would be remapped on average where n is the number of nodes. A O(n) space complexity where n is the number of nodes. A O(1) time complexity per insertion/removal of a node and per key lookup. A minimal standard deviation to make sure that a node is not overloaded compared to another one. It would allow associating a weight to a node to cope with different node sizing. It would allow arbitrary nodes name (not numbered sequentially) to support both load balancing and sharding.  但是实际情况是，没有这样完美的hash方案!\n Rendezvous has a linear time complexity per lookup. Ring consistent hash has a poor minimal standard deviation without the concept of virtual nodes. With virtual nodes, is space complexity is O(n*v) with n the number of nodes and v the number of virtual nodes per node. Jump consistent hash does not have a constant time complexity and it does not support arbitrary nodes name. Multi-Probe Consistent Hash也存在问题，虽然空间、时间、灵活性不错，但是查询效率大大下降了  其实还有很多hash方案，它们都极力去平衡“一致性”和“均匀性”，但是实际情况就是没有完美的可以适用于所有场景的方案，下面是个hash方案的对比（展示了随着shards数增加查询的耗时 nanoseconds）：\n除了单次查询耗时，其实还需要考虑内存开销、构建开销、插入删除节点开销、最大支持节点数等，没有完美的方案。\n所以，我们只能结合实际场景进行各种“权衡”，这也是为什么一致性hash方案尽管负载偏差比较差，但是它目前仍然应用范围比较广的原因，因为它对大多数场景都还ok。\n## 负载均衡最大努力交付\n现在回到我们现在的mesh框架的负载均衡场景，我们再重新评估下我们关切的点：\n 节点选择的一致性 节点负载的均匀性 尽最大努力交付  现在只考虑ring-based一致性hash方案，它好理解、适用范围更广，而且可以结合ring值域、key值域、虚节点数、hash函数选择来做些优化来满足需要：\n 一致性：根据理论值如果节点数n，那么新加入一个节点最多迁移1/n 均匀性：通过增加虚节点数量，hash函数也比较好，那么也可以改善均匀性，且能在我们接受范围内，ring占用的内存空间在可接受范围内 尽最大努力交付：如果选中的一个节点，是一个失败的节点，我们可以借助重试（replication），使用hash环选择第2个或更多个节点出来供使用，howto?  ring-based一致性hash，最大努力交付howto？\n 比如，hash出的一个节点，是一个失败的节点，直接取hash环上这个节点的下一个节点（不能是相同的物理节点），这种好实现点，虚节点记录下在环上的位置即可 比如，借鉴一些存储系统replication的思路，允许取出多个节点  参考资料 # 参考文献： #  介绍一致性hash，https://itnext.io/introducing-consistent-hashing-9a289769052e redezvous hash，https://medium.com/i0exception/rendezvous-hashing-8c00e2fb58b0 经典一致性hash算法paper：Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web jump一致性hash算法paper：A Fast, Minimal Memory, Consistent Hash Algorithm jump一致性hash算法paper推导：https://zhuanlan.zhihu.com/p/104124045 一致性hash算法tradeoff：https://dgryski.medium.com/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8 Multi-Probe一致性hash算法：https://arxiv.org/abs/1505.00062 一致性hash方案tradeoffs：https://itnext.io/introducing-consistent-hashing-9a289769052e Maglev hash方案，https://blog.acolyer.org/2016/03/21/maglev-a-fast-and-reliable-software-network-load-balancer/  实际应用： #  dapr采用了google consistent hash with bounded load, https://cloud.tencent.com/developer/article/1799300?from=article.detail.1340095 go-zero rpc框架采用了经典的一致性hash算法 twitter eventbus采用了rendezvous hash (最大随机权重hash） memcache client采用了jump consistent hash, https://sourcegraph.com/github.com/grafana/loki/-/blob/pkg/storage/chunk/cache/memcached_client.go?L100 go-redis client默认采用了rendezvous hash，https://sourcegraph.com/github.com/go-redis/redis@v8/-/blob/ring.go?L39  影响一致性hash评估结果的因素 # 我们主要关注负载均衡算法的 ”一致性“、”均匀性“ 这两点，我们的测试也围绕着这两点展开。为了使得测试更有价值，更有可信度，需要说明下接下来的测试方案。\n影响各负载均衡算法测试结果的，可能有以下几点：\n  服务物理节点数，固定为10\n 涉及到一致性hash算法及其变体时，我们会分别对比虚节点数为5、10、20、50、100、1000时的数量（直观理解，虚节点越多越均匀，内存开销可能越大） jump一致性hash，虚节点数量对内存没影响，但是该算法使用场景受限于节点只add不减少的场景（如只增加shards的存储场景） rendezvous hash，非一致性hash，没有虚节点概念，但是时间复杂度从一致性hash的O(logn)下降到O(n)，当节点数很多时开销不可忽视    待测试的userid数量足够多（将userid mapping到物理节点上去处理），要远多于节点数，比如100w\n  待测试的userid生成算法是否均匀，go标准库rand.Int()默认的source是均匀的，我们用这个方法来生成userid\n  各基于hash的负载均衡算法采用的hash函数是否一致，在从key计算hash value时，不一致的hash函数可能会导致分布不均匀，这样会导致难以评估各类负载均衡算法本身的差异性 可以把常见实现的代码clone下来，统一调节下hash函数来验证下，控制变量下。\n  一致性hash算法中，虚节点对应的hash value的计算，为了平衡负载均匀和开销，通常虚节点数量n可调整，这种情况下就没法按照经典一致性hash算法中那样提供n个hash函数了 一般是对物理节点host做下处理，比如加前缀1、2、3或者后缀9、10、11后表示虚节点，然后再用同一个hash函数做计算。 这种做法是否能让各个虚节点在ring上分布均匀呢？这个跟hash函数有关，但是直观感受是不见得能均匀。\n  用户userid在采用与hash(host)时相同的hash函数，userid的值域与其hash值，是否能在hash环上均匀分布呢？直观感受是，不见得。\n  上述这些都是影响我们评估算法质量的影响因素，在进行测试对比时要多关注。\n另外，关于“一致性”方面，通过算法本身的理论描述是可以给出一个理论值的：\n 一致性hash，假设k个key，n个nodes，那么节点加入、离开后，需要remapping的key大约为k/n（均衡的前提下） 一致性hash with bounded load，这个虽然负载比较均衡，但是直观感受是“一致性”不如经典的“一致性hash”，因为它会在负载偏高时选择下一个节点 jump consistent hash，这个算法只考虑存储场景data shards增加的情况，我们可以先延迟测试这个 rendezvous hash，理论上来说，只要新加入的节点host不会导致hash(userid, host)最大，就对原来的userid没影响，但是有多少userid会受影响呢？待理解  但是实际使用时到底怎么样，就跟key本身以及hash函数选择的优劣很有关系了。\n一致性hash实际测试结果 #  选择一个一致性hash实现，比如采用go-zero的一致性hash实现 测试一致性，这个有算法理论支撑，我们其实可以不用测试 测试均匀性，这个有必要亲自测试下 修改以支持最大努力交付，比如失败之后该如何重试，以go-zero中定义的一致性hash环为例：  先计算key从consistenthash.keys找到下一个虚节点的hashvalue，然后从ring[hashvalue]得到nodes，遍历这些nodes看是否有可用节点 上面不成，直接索引值+1顺着consistenthash.keys找下一个索引位置的hashvalue，再从ring[hashvalue]得到nodes，遍历看是否有可用节点， 如果转了一圈了还没有合适的，就应该退出了，当然也可以限制最大重试次数 另外要注意，之前遍历到的失败的节点，下次从虚节点找到对应物理节点时，应检查物理节点是否是已经排除过的，是的话就没必要重试了。    go-zero中一致性hash实现源码阅读 # 定义 # type ConsistentHash struct { hashFunc Func replicas int keys []uint64 ring map[uint64][]interface{} nodes map[string]lang.PlaceholderType lock sync.RWMutex }   hashFunc是自定义的hash函数 replicas表示每个物理节点对应的虚节点数量 keys其实就是一致性hash环的表示，记录了虚节点对应的hash值，有序 ring其实是hash值到一组虚节点的映射，它其实是为了解决hash冲突来的  准确地说，keys+ring构成了一致性hash环，查找hash(key)对应的虚节点时，先在keys中找到\u0026gt;=hash(key)的虚节点对应的hash值， 然后，通过hash值到ring中找对应的虚节点 因为可能有冲突，所以map[k]v这里的v是一个slice   nodes中记录了当前添加了哪些物理节点，但是这里的map[k]v，k是节点描述信息，可以简单理解成node.String()，v是struct{}  这个一致性hash的设计还是不错的。\nAdd/AddWithReplicas/AddWithWeight # 添加新节点的时候，大致就是这几个函数，逻辑是什么呢？\n 先获取待添加节点的一个描述信息，如String()，然后记录到nodes中，表示记录了这个节点 然后呢，根据设置的虚节点数量，for循环，每次在描述信息后面添加数字后缀，计算hash，然后记录到keys、ring里面 前面提过了，keys+ring共同构成了一致性hash环  Get # 根据key获取节点的时候呢？\n 先计算key的hash，然后从keys中找第一个\u0026gt;=hash(key)的位置，这个位置对应的hash即为候选虚节点的hash， 然后通过虚节点的hash去ring里面找，ring里面是个slice，是为了解决散列冲突的， 怎么从这个slice中取呢，重新hash一次，从这个slice里面选一个  继续优化 # ring-based一致性hash的均匀性还可以继续优化，比如从hash函数的选择方面，虚节点数量的选择方面。\n以下是10个物理节点，均匀的100w userid，在不同虚节点数量、hash函数选择情况下的测试情况：\ncase: replicas:50+hash:murmur3.Sum64 标准方差: 14628.560790453721 max: 126737 min: 76395 (max-min)/times: 0.050342 peak/mean: 1.26737 case: replicas:100+hash:murmur3.Sum64 标准方差: 14555.295022774357 max: 127129 min: 76438 (max-min)/times: 0.050691 peak/mean: 1.27129 * case: replicas:200+hash:murmur3.Sum64 标准方差: 6902.00454940447 max: 110178 min: 85121 (max-min)/times: 0.025057 peak/mean: 1.10178 case: replicas:500+hash:murmur3.Sum64 标准方差: 2285.3205902017335 max: 105277 min: 97136 (max-min)/times: 0.008141 peak/mean: 1.05277 case: replicas:1000+hash:murmur3.Sum64 标准方差: 2069.765928794848 max: 104603 min: 97606 (max-min)/times: 0.006997 peak/mean: 1.04603 case: replicas:2000+hash:murmur3.Sum64 标准方差: 2618.900303562547 max: 104628 min: 94870 (max-min)/times: 0.009758 peak/mean: 1.04628 case: replicas:50+hash:xxhash.Sum64 标准方差: 8627.559643375409 max: 119229 min: 91110 (max-min)/times: 0.028119 peak/mean: 1.19229 case: replicas:100+hash:xxhash.Sum64 标准方差: 8918.29840272235 max: 120236 min: 90692 (max-min)/times: 0.029544 peak/mean: 1.20236 * case: replicas:200+hash:xxhash.Sum64 标准方差: 5913.828556865679 max: 111947 min: 89811 (max-min)/times: 0.022136 peak/mean: 1.11947 case: replicas:500+hash:xxhash.Sum64 标准方差: 4256.551350565384 max: 107631 min: 93326 (max-min)/times: 0.014305 peak/mean: 1.07631 case: replicas:1000+hash:xxhash.Sum64 标准方差: 3148.5766943176086 max: 106134 min: 95150 (max-min)/times: 0.010984 peak/mean: 1.06134 case: replicas:2000+hash:xxhash.Sum64 标准方差: 1664.1786562746202 max: 103375 min: 96885 (max-min)/times: 0.00649 peak/mean: 1.03375 case: replicas:100+hash:crc32.ChecksumIEEE 标准方差: 16188.201024202783 max: 121890 min: 69629 (max-min)/times: 0.052261 peak/mean: 1.2189 case: replicas:200+hash:crc32.ChecksumIEEE 标准方差: 11440.727826497754 max: 126050 min: 82970 (max-min)/times: 0.04308 peak/mean: 1.2605 * case: replicas:500+hash:crc32.ChecksumIEEE 标准方差: 17259.726985094523 max: 130659 min: 69507 (max-min)/times: 0.061152 peak/mean: 1.30659 case: replicas:1000+hash:crc32.ChecksumIEEE 标准方差: 21791.261533009052 max: 137256 min: 72892 (max-min)/times: 0.064364 peak/mean: 1.37256 case: replicas:2000+hash:crc32.ChecksumIEEE 标准方差: 12953.256825987819 max: 120299 min: 73664 (max-min)/times: 0.046635 peak/mean: 1.20299  不难看出： xxhash的均匀性首先比较好，在100个虚节点（这个一般是比较常用的经验值）时，最大最小负载偏差2.9%，peak/mean比为1.20\n总结 # 本文从一致性hash负载均衡策略触发，深入了解了下不同的方案变体，最后针对普适应更好的一致性hash方案、go-zero实现、实践中的引用改进进行了探索介绍。\n"}),a.add({id:86,href:"/tags/kmemcheck/",title:"kmemcheck",description:"",content:""}),a.add({id:87,href:"/tags/kmemleak/",title:"kmemleak",description:"",content:""}),a.add({id:88,href:"/blog/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%86%85%E5%AD%98%E9%97%AE%E9%A2%98%E6%A3%80%E6%9F%A5/",title:"内核中的内存检查工具",description:"kmemcheck.txt # kmemcheck用于内核的未初始化内存的动态检测，它工作在内核态，与工作在用户态的 memcheck实现机制不同。虽然kmemcheck不如memcheck精确，但是已经足够使用的了。此外，kmemcheck会使用更多的内存，增加系统负载，仅适合用于内核的调试。\nkmemleak.txt # kmemleak是一个工作在内核态，用于检测内核中内存泄漏的工具，与工作在用户态的内存泄漏检测工具memcheck加参数\u0026ndash;leak-check工作时效果类似。\n为了加深对内存管理的理解，应该查看下这两个工具的源代码。",content:"kmemcheck.txt # kmemcheck用于内核的未初始化内存的动态检测，它工作在内核态，与工作在用户态的 memcheck实现机制不同。虽然kmemcheck不如memcheck精确，但是已经足够使用的了。此外，kmemcheck会使用更多的内存，增加系统负载，仅适合用于内核的调试。\nkmemleak.txt # kmemleak是一个工作在内核态，用于检测内核中内存泄漏的工具，与工作在用户态的内存泄漏检测工具memcheck加参数\u0026ndash;leak-check工作时效果类似。\n为了加深对内存管理的理解，应该查看下这两个工具的源代码。\n"}),a.add({id:89,href:"/tags/jprobe/",title:"jprobe",description:"",content:""}),a.add({id:90,href:"/tags/kprobe/",title:"kprobe",description:"",content:""}),a.add({id:91,href:"/tags/rprobe/",title:"rprobe",description:"",content:""}),a.add({id:92,href:"/blog/%E5%86%85%E6%A0%B8%E6%8E%A2%E9%92%88/",title:"内核探针kprobe工作原理",description:"内核为方便调试引入了内核探针，主要有3种，kprobe/jprobe/rprobe，我们重点关注kprobe的工作原理，这个理解了，其他几种探针工作原理很容易就能脑补出来。",content:"内核探针 # 内核中用来方便调试的探针（probe）主要有以下几种：\n kprobe，可以对任意指令地址处安装探针 jprobe，可以对函数入口地址处安装探针，方便获取参数信息 rprobe，或者称为retprobe，顾名思义，主要用来观察retvalue  这几种探针的实现原理大同小异，详细的工作原理可以参考 kprobes.rst。\nkprobe工作原理 # 联想下调试器中断点的工作方式，kprobe可以通过断点的形式来实现：\n 记录目标地址addr处的原始一字节指令 将目标地址处的指令替换为0xcc（int3就是软件断点），并注册该地址处对应的kprobe，kprobe应该包含了pre_handler/post_handler int3对应的中断服务处理程序中，有一段代码是要执行对应的kprobe的pre_handler； 将原addr处的一字节指令恢复，然后改成singlestep执行完下条指令； 执行完这个函数中的所有指令，执行完返回后继续执行post_handler 然后直接continue  我说的这个过程不一定精确，但是大致可以这么实现。这种方法可能效率会有点低下，kprobes.rst中也有些优化的思路，我这里没有仔细去看。\n我感兴趣的就是，内核里面的kprobe和调试器中的大致跟踪tracee执行过程，很类似。\n相同点：都是通过指令patch的方式\n不同点：\n kprobe是利用了int3指令触发trap服务程序走到了kprobe的处理逻辑去执行pre_handler/post_handler， 而调试器是tracee执行到断点时触发trap服务程序走到了通知tracer继续控制tracee这个逻辑。  总结 # 简要总结了下kprobe这种内核探针的工作原理。\n"}),a.add({id:93,href:"/tags/destructor/",title:"destructor",description:"",content:""}),a.add({id:94,href:"/tags/kobject/",title:"kobject",description:"",content:""}),a.add({id:95,href:"/tags/kref/",title:"kref",description:"",content:""}),a.add({id:96,href:"/blog/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86kobject%E4%B8%8Ekref/",title:"kref引用计数与kobject对象管理",description:"看完kref/kobject这几篇文档，更深地明白了一个道理，“能工模型，巧匠窃意”、“无招胜有招”，编程思想和编程工具是相辅相成的，前者帮助完善后者，后者便于更简单地推广前者。纵使是c语言这样的过程式编程语言，在牛人手里也可以提炼面向对象的精髓来建构更复杂的软件世界。",content:"kref # kref可以为你自定义的结构体提供一个引用计数器，kobject也可以实 现该功能，但是kobject比较复杂，如果只是提供一个简单的引用计数器的话，应该使用 kref而不是kobject。\nkref可以嵌入在我们定义的结构体struct中，当我们初始化一个结构体时通过kref_init对其进行初始化（引用计数为1），当我们引用这个struct时需要通过kref_get来增加其引用计数，而当我们不再引用这个struct时，我们可以通过kref_put来减少引用计数，同时还可以提供一个data_release的函数，当引用计数为0时该函数就会执行。\nkref非常类似于c++中的智能指针的功能，gcc编译期对c语言也增加了一些类似的属性扩展，允许在变量作用域结束时执行注册的函数。可见，自定义类型中通过恰当地使用kref，我们就可以实现近似上述c++智能指针等高阶玩法。\nsee kref.rst\nkobject # kobject又是什么呢，在面向对象领域中，对象有继承关系，派生对象需要实现抽象基类的方法，对象在没有被引用时也应该被自动销毁（联想c++析构函数）等。面向对象的那些思想在内核里面又是怎么样一种表现形式。\n无招胜有招，c虽然是过程式编程语言，但是其依然可以写出面向对象的代码来对完成对大型软件项目的设计构建。\n我们一般将kobject嵌入自定义的类型struct中来使用，同时还有对应的一个ktype：\n kobject，具备了引用计数功能，通过kobject_init/get/put操作可以对引用计数进行操作，另外kobject还有parent指针用来构建对象间的层级关系； ktype，用来描述每个kobject对象引用计数减为0时应该对这个包含kobject成员的struct类型执行何种操作，比如如何清理、释放之类的；  ps：kset可以看做是一个集合，用来管理一系列的kobject，使用场景见kobject.rst。\nsee kobject.rst\n总结 # 看完这几篇文档，更深地明白了一个道理，“能工模型，巧匠窃意”、“无招胜有招”，编程思想和编程工具是相辅相成的，前者帮助完善后者，后者便于更简单地推广前者。纵使是c语言这样的过程式编程语言，在牛人手里也可以提炼面向对象的精髓来建构更复杂的软件世界。\n"}),a.add({id:97,href:"/categories/linux%E5%86%85%E6%A0%B8/",title:"linux内核",description:"",content:""}),a.add({id:98,href:"/tags/refcount/",title:"refcount",description:"",content:""}),a.add({id:99,href:"/tags/smartpointer/",title:"smartpointer",description:"",content:""}),a.add({id:100,href:"/tags/books/",title:"books",description:"",content:""}),a.add({id:101,href:"/tags/docs/",title:"docs",description:"",content:""}),a.add({id:102,href:"/blog/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/",title:"Linux内核学习资料",description:"现在学习Linux操作系统的人越来越多了，进一步学习Kernel的人也越来越多了，经常有人问起有没有质量好的、获得大家认可的学习资料论坛，尤其是对于学习内核的新手而言，能否获得这些好的学习资料还是很重要的。因为经常有人问起这个问题，所以在Linux源码随附的文档中，有专门一篇文档kernel-docs.rst专门整理罗列了适合大家学习Linux内核的文档、在线资源、出版书籍等，并逐一做了简要的描述。注意到其中有些资料是和具体内核模块相关的，如网络协议栈、中断子系统等，也适合有针对性地、深入地去学习。",content:"现在学习Linux操作系统的人越来越多了，进一步学习Kernel的人也越来越多了，经常有人问起有没有质量好的、获得大家认可的学习资料论坛，尤其是对于学习内核的新手而言，能否获得这些好的学习资料还是很重要的。因为经常有人问起这个问题，所以在Linux源码随附的文档中，有专门一篇文档kernel-docs.rst专门整理罗列了适合大家学习Linux内核的文档、在线资源、出版书籍等，并逐一做了简要的描述。注意到其中有些资料是和具体内核模块相关的，如网络协议栈、中断子系统等，也适合有针对性地、深入地去学习。\n本文剩余内容来自Linux内核文档 kernel-docs.rst，整理在此方便查阅参考。\nDocs at the Linux Kernel tree # The Sphinx books should be built with make {htmldocs | pdfdocs | epubdocs}.\n* Name: **linux/Documentation** :Author: Many. :Location: Documentation/ :Keywords: text files, Sphinx. :Description: Documentation that comes with the kernel sources, inside the Documentation directory. Some pages from this document (including this document itself) have been moved there, and might be more up to date than the web version.  On-line docs # * Title: **Linux Kernel Mailing List Glossary** :Author: various :URL: https://kernelnewbies.org/KernelGlossary :Date: rolling version :Keywords: glossary, terms, linux-kernel. :Description: From the introduction: \u0026quot;This glossary is intended as a brief description of some of the acronyms and terms you may hear during discussion of the Linux kernel\u0026quot;. * Title: **Tracing the Way of Data in a TCP Connection through the Linux Kernel** :Author: Richard Sailer :URL: https://archive.org/details/linux_kernel_data_flow_short_paper :Date: 2016 :Keywords: Linux Kernel Networking, TCP, tracing, ftrace :Description: A seminar paper explaining ftrace and how to use it for understanding linux kernel internals, illustrated at tracing the way of a TCP packet through the kernel. :Abstract: *This short paper outlines the usage of ftrace a tracing framework as a tool to understand a running Linux system. Having obtained a trace-log a kernel hacker can read and understand source code more determined and with context. In a detailed example this approach is demonstrated in tracing and the way of data in a TCP Connection through the kernel. Finally this trace-log is used as base for more a exact conceptual exploration and description of the Linux TCP/IP implementation.* * Title: **On submitting kernel Patches** :Author: Andi Kleen :URL: http://halobates.de/on-submitting-kernel-patches.pdf :Date: 2008 :Keywords: patches, review process, types of submissions, basic rules, case studies :Description: This paper gives several experience values on what types of patches there are and how likely they get merged. :Abstract: [...]. This paper examines some common problems for submitting larger changes and some strategies to avoid problems. * Title: **Linux Device Drivers, Third Edition** :Author: Jonathan Corbet, Alessandro Rubini, Greg Kroah-Hartman :URL: https://lwn.net/Kernel/LDD3/ :Date: 2005 :Description: A 600-page book covering the (2.6.10) driver programming API and kernel hacking in general. Available under the Creative Commons Attribution-ShareAlike 2.0 license. :note: You can also :ref:`purchase a copy from O'Reilly or elsewhere \u0026lt;ldd3_published\u0026gt;`. * Title: **Writing an ALSA Driver** :Author: Takashi Iwai \u0026lt;tiwai@suse.de\u0026gt; :URL: http://www.alsa-project.org/~iwai/writing-an-alsa-driver/index.html :Date: 2005 :Keywords: ALSA, sound, soundcard, driver, lowlevel, hardware. :Description: Advanced Linux Sound Architecture for developers, both at kernel and user-level sides. ALSA is the Linux kernel sound architecture in the 2.6 kernel version. * Title: **Linux PCMCIA Programmer's Guide** :Author: David Hinds. :URL: http://pcmcia-cs.sourceforge.net/ftp/doc/PCMCIA-PROG.html :Date: 2003 :Keywords: PCMCIA. :Description: \u0026quot;This document describes how to write kernel device drivers for the Linux PCMCIA Card Services interface. It also describes how to write user-mode utilities for communicating with Card Services. * Title: **The Linux Kernel Module Programming Guide** :Author: Peter Jay Salzman, Michael Burian, Ori Pomerantz, Bob Mottram, Jim Huang. :URL: https://sysprog21.github.io/lkmpg/ :Date: 2021 :Keywords: modules, GPL book, /proc, ioctls, system calls, interrupt handlers . :Description: A very nice GPL book on the topic of modules programming. Lots of examples. Currently the new version is being actively maintained at https://github.com/sysprog21/lkmpg. * Title: **Global spinlock list and usage** :Author: Rick Lindsley. :URL: http://lse.sourceforge.net/lockhier/global-spin-lock :Date: 2001 :Keywords: spinlock. :Description: This is an attempt to document both the existence and usage of the spinlocks in the Linux 2.4.5 kernel. Comprehensive list of spinlocks showing when they are used, which functions access them, how each lock is acquired, under what conditions it is held, whether interrupts can occur or not while it is held... * Title: **A Linux vm README** :Author: Kanoj Sarcar. :URL: http://kos.enix.org/pub/linux-vmm.html :Date: 2001 :Keywords: virtual memory, mm, pgd, vma, page, page flags, page cache, swap cache, kswapd. :Description: Telegraphic, short descriptions and definitions relating the Linux virtual memory implementation. * Title: **Video4linux Drivers, Part 1: Video-Capture Device** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/406 :Date: 2000 :Keywords: video4linux, driver, video capture, capture devices, camera driver. :Description: The title says it all. * Title: **Video4linux Drivers, Part 2: Video-capture Devices** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/429 :Date: 2000 :Keywords: video4linux, driver, video capture, capture devices, camera driver, control, query capabilities, capability, facility. :Description: The title says it all. * Title: **Linux IP Networking. A Guide to the Implementation and Modification of the Linux Protocol Stack.** :Author: Glenn Herrin. :URL: http://www.cs.unh.edu/cnrg/gherrin :Date: 2000 :Keywords: network, networking, protocol, IP, UDP, TCP, connection, socket, receiving, transmitting, forwarding, routing, packets, modules, /proc, sk_buff, FIB, tags. :Description: Excellent paper devoted to the Linux IP Networking, explaining anything from the kernel's to the user space configuration tools' code. Very good to get a general overview of the kernel networking implementation and understand all steps packets follow from the time they are received at the network device till they are delivered to applications. The studied kernel code is from 2.2.14 version. Provides code for a working packet dropper example. * Title: **How To Make Sure Your Driver Will Work On The Power Macintosh** :Author: Paul Mackerras. :URL: http://www.linux-mag.com/id/261 :Date: 1999 :Keywords: Mac, Power Macintosh, porting, drivers, compatibility. :Description: The title says it all. * Title: **An Introduction to SCSI Drivers** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/284 :Date: 1999 :Keywords: SCSI, device, driver. :Description: The title says it all. * Title: **Advanced SCSI Drivers And Other Tales** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/307 :Date: 1999 :Keywords: SCSI, device, driver, advanced. :Description: The title says it all. * Title: **Writing Linux Mouse Drivers** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/330 :Date: 1999 :Keywords: mouse, driver, gpm. :Description: The title says it all. * Title: **More on Mouse Drivers** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/356 :Date: 1999 :Keywords: mouse, driver, gpm, races, asynchronous I/O. :Description: The title still says it all. * Title: **Writing Video4linux Radio Driver** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/381 :Date: 1999 :Keywords: video4linux, driver, radio, radio devices. :Description: The title says it all. * Title: **I/O Event Handling Under Linux** :Author: Richard Gooch. :URL: https://web.mit.edu/~yandros/doc/io-events.html :Date: 1999 :Keywords: IO, I/O, select(2), poll(2), FDs, aio_read(2), readiness event queues. :Description: From the Introduction: \u0026quot;I/O Event handling is about how your Operating System allows you to manage a large number of open files (file descriptors in UNIX/POSIX, or FDs) in your application. You want the OS to notify you when FDs become active (have data ready to be read or are ready for writing). Ideally you want a mechanism that is scalable. This means a large number of inactive FDs cost very little in memory and CPU time to manage\u0026quot;. * Title: **(nearly) Complete Linux Loadable Kernel Modules. The definitive guide for hackers, virus coders and system administrators.** :Author: pragmatic/THC. :URL: http://packetstormsecurity.org/docs/hack/LKM_HACKING.html :Date: 1999 :Keywords: syscalls, intercept, hide, abuse, symbol table. :Description: Interesting paper on how to abuse the Linux kernel in order to intercept and modify syscalls, make files/directories/processes invisible, become root, hijack ttys, write kernel modules based virus... and solutions for admins to avoid all those abuses. :Notes: For 2.0.x kernels. Gives guidances to port it to 2.2.x kernels. * Name: **Linux Virtual File System** :Author: Peter J. Braam. :URL: http://www.coda.cs.cmu.edu/doc/talks/linuxvfs/ :Date: 1998 :Keywords: slides, VFS, inode, superblock, dentry, dcache. :Description: Set of slides, presumably from a presentation on the Linux VFS layer. Covers version 2.1.x, with dentries and the dcache. * Title: **The Venus kernel interface** :Author: Peter J. Braam. :URL: http://www.coda.cs.cmu.edu/doc/html/kernel-venus-protocol.html :Date: 1998 :Keywords: coda, filesystem, venus, cache manager. :Description: \u0026quot;This document describes the communication between Venus and kernel level file system code needed for the operation of the Coda filesystem. This version document is meant to describe the current interface (version 1.0) as well as improvements we envisage\u0026quot;. * Title: **Design and Implementation of the Second Extended Filesystem** :Author: Rémy Card, Theodore Ts'o, Stephen Tweedie. :URL: https://web.mit.edu/tytso/www/linux/ext2intro.html :Date: 1998 :Keywords: ext2, linux fs history, inode, directory, link, devices, VFS, physical structure, performance, benchmarks, ext2fs library, ext2fs tools, e2fsck. :Description: Paper written by three of the top ext2 hackers. Covers Linux filesystems history, ext2 motivation, ext2 features, design, physical structure on disk, performance, benchmarks, e2fsck's passes description... A must read! :Notes: This paper was first published in the Proceedings of the First Dutch International Symposium on Linux, ISBN 90-367-0385-9. * Title: **The Linux RAID-1, 4, 5 Code** :Author: Ingo Molnar, Gadi Oxman and Miguel de Icaza. :URL: http://www.linuxjournal.com/article.php?sid=2391 :Date: 1997 :Keywords: RAID, MD driver. :Description: Linux Journal Kernel Korner article. :Abstract: *A description of the implementation of the RAID-1, RAID-4 and RAID-5 personalities of the MD device driver in the Linux kernel, providing users with high performance and reliable, secondary-storage capability using software*. * Title: **Linux Kernel Hackers' Guide** :Author: Michael K. Johnson. :URL: https://www.tldp.org/LDP/khg/HyperNews/get/khg.html :Date: 1997 :Keywords: device drivers, files, VFS, kernel interface, character vs block devices, hardware interrupts, scsi, DMA, access to user memory, memory allocation, timers. :Description: A guide designed to help you get up to speed on the concepts that are not intuitively obvious, and to document the internal structures of Linux. * Title: **Dynamic Kernels: Modularized Device Drivers** :Author: Alessandro Rubini. :URL: http://www.linuxjournal.com/article.php?sid=1219 :Date: 1996 :Keywords: device driver, module, loading/unloading modules, allocating resources. :Description: Linux Journal Kernel Korner article. :Abstract: *This is the first of a series of four articles co-authored by Alessandro Rubini and Georg Zezchwitz which present a practical approach to writing Linux device drivers as kernel loadable modules. This installment presents an introduction to the topic, preparing the reader to understand next month's installment*. * Title: **Dynamic Kernels: Discovery** :Author: Alessandro Rubini. :URL: http://www.linuxjournal.com/article.php?sid=1220 :Date: 1996 :Keywords: character driver, init_module, clean_up module, autodetection, mayor number, minor number, file operations, open(), close(). :Description: Linux Journal Kernel Korner article. :Abstract: *This article, the second of four, introduces part of the actual code to create custom module implementing a character device driver. It describes the code for module initialization and cleanup, as well as the open() and close() system calls*. * Title: **The Devil's in the Details** :Author: Georg v. Zezschwitz and Alessandro Rubini. :URL: http://www.linuxjournal.com/article.php?sid=1221 :Date: 1996 :Keywords: read(), write(), select(), ioctl(), blocking/non blocking mode, interrupt handler. :Description: Linux Journal Kernel Korner article. :Abstract: *This article, the third of four on writing character device drivers, introduces concepts of reading, writing, and using ioctl-calls*. * Title: **Dissecting Interrupts and Browsing DMA** :Author: Alessandro Rubini and Georg v. Zezschwitz. :URL: https://www.linuxjournal.com/article.php?sid=1222 :Date: 1996 :Keywords: interrupts, irqs, DMA, bottom halves, task queues. :Description: Linux Journal Kernel Korner article. :Abstract: *This is the fourth in a series of articles about writing character device drivers as loadable kernel modules. This month, we further investigate the field of interrupt handling. Though it is conceptually simple, practical limitations and constraints make this an ''interesting'' part of device driver writing, and several different facilities have been provided for different situations. We also investigate the complex topic of DMA*. * Title: **Device Drivers Concluded** :Author: Georg v. Zezschwitz. :URL: https://www.linuxjournal.com/article.php?sid=1287 :Date: 1996 :Keywords: address spaces, pages, pagination, page management, demand loading, swapping, memory protection, memory mapping, mmap, virtual memory areas (VMAs), vremap, PCI. :Description: Finally, the above turned out into a five articles series. This latest one's introduction reads: \u0026quot;This is the last of five articles about character device drivers. In this final section, Georg deals with memory mapping devices, beginning with an overall description of the Linux memory management concepts\u0026quot;. * Title: **Network Buffers And Memory Management** :Author: Alan Cox. :URL: https://www.linuxjournal.com/article.php?sid=1312 :Date: 1996 :Keywords: sk_buffs, network devices, protocol/link layer variables, network devices flags, transmit, receive, configuration, multicast. :Description: Linux Journal Kernel Korner. :Abstract: *Writing a network device driver for Linux is fundamentally simple---most of the complexity (other than talking to the hardware) involves managing network packets in memory*. * Title: **Analysis of the Ext2fs structure** :Author: Louis-Dominique Dubeau. :URL: https://teaching.csse.uwa.edu.au/units/CITS2002/fs-ext2/ :Date: 1994 :Keywords: ext2, filesystem, ext2fs. :Description: Description of ext2's blocks, directories, inodes, bitmaps, invariants...  Published books # * Title: **Linux Treiber entwickeln** :Author: Jürgen Quade, Eva-Katharina Kunst :Publisher: dpunkt.verlag :Date: Oct 2015 (4th edition) :Pages: 688 :ISBN: 978-3-86490-288-8 :Note: German. The third edition from 2011 is much cheaper and still quite up-to-date. * Title: **Linux Kernel Networking: Implementation and Theory** :Author: Rami Rosen :Publisher: Apress :Date: December 22, 2013 :Pages: 648 :ISBN: 978-1430261964 * Title: **Embedded Linux Primer: A practical Real-World Approach, 2nd Edition** :Author: Christopher Hallinan :Publisher: Pearson :Date: November, 2010 :Pages: 656 :ISBN: 978-0137017836 * Title: **Linux Kernel Development, 3rd Edition** :Author: Robert Love :Publisher: Addison-Wesley :Date: July, 2010 :Pages: 440 :ISBN: 978-0672329463 * Title: **Essential Linux Device Drivers** :Author: Sreekrishnan Venkateswaran :Published: Prentice Hall :Date: April, 2008 :Pages: 744 :ISBN: 978-0132396554 * Title: **Linux Device Drivers, 3rd Edition** :Authors: Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman :Publisher: O'Reilly \u0026amp; Associates :Date: 2005 :Pages: 636 :ISBN: 0-596-00590-3 :Notes: Further information in http://www.oreilly.com/catalog/linuxdrive3/ PDF format, URL: https://lwn.net/Kernel/LDD3/ * Title: **Linux Kernel Internals** :Author: Michael Beck :Publisher: Addison-Wesley :Date: 1997 :ISBN: 0-201-33143-8 (second edition) * Title: **Programmation Linux 2.0 API systeme et fonctionnement du noyau** :Author: Remy Card, Eric Dumas, Franck Mevel :Publisher: Eyrolles :Date: 1997 :Pages: 520 :ISBN: 2-212-08932-5 :Notes: French * Title: **The Design and Implementation of the 4.4 BSD UNIX Operating System** :Author: Marshall Kirk McKusick, Keith Bostic, Michael J. Karels, John S. Quarterman :Publisher: Addison-Wesley :Date: 1996 :ISBN: 0-201-54979-4 * Title: **Unix internals -- the new frontiers** :Author: Uresh Vahalia :Publisher: Prentice Hall :Date: 1996 :Pages: 600 :ISBN: 0-13-101908-2 * Title: **Programming for the real world - POSIX.4** :Author: Bill O. Gallmeister :Publisher: O'Reilly \u0026amp; Associates, Inc :Date: 1995 :Pages: 552 :ISBN: I-56592-074-0 :Notes: Though not being directly about Linux, Linux aims to be POSIX. Good reference. * Title: **UNIX Systems for Modern Architectures: Symmetric Multiprocessing and Caching for Kernel Programmers** :Author: Curt Schimmel :Publisher: Addison Wesley :Date: June, 1994 :Pages: 432 :ISBN: 0-201-63338-8 * Title: **The Design and Implementation of the 4.3 BSD UNIX Operating System** :Author: Samuel J. Leffler, Marshall Kirk McKusick, Michael J Karels, John S. Quarterman :Publisher: Addison-Wesley :Date: 1989 (reprinted with corrections on October, 1990) :ISBN: 0-201-06196-1 * Title: **The Design of the UNIX Operating System** :Author: Maurice J. Bach :Publisher: Prentice Hall :Date: 1986 :Pages: 471 :ISBN: 0-13-201757-1  Miscellaneous # * Name: **Cross-Referencing Linux** :URL: https://elixir.bootlin.com/ :Keywords: Browsing source code. :Description: Another web-based Linux kernel source code browser. Lots of cross references to variables and functions. You can see where they are defined and where they are used. * Name: **Linux Weekly News** :URL: https://lwn.net :Keywords: latest kernel news. :Description: The title says it all. There's a fixed kernel section summarizing developers' work, bug fixes, new features and versions produced during the week. Published every Thursday. * Name: **The home page of Linux-MM** :Author: The Linux-MM team. :URL: https://linux-mm.org/ :Keywords: memory management, Linux-MM, mm patches, TODO, docs, mailing list. :Description: Site devoted to Linux Memory Management development. Memory related patches, HOWTOs, links, mm developers... Don't miss it if you are interested in memory management development! * Name: **Kernel Newbies IRC Channel and Website** :URL: https://www.kernelnewbies.org :Keywords: IRC, newbies, channel, asking doubts. :Description: #kernelnewbies on irc.oftc.net. #kernelnewbies is an IRC network dedicated to the 'newbie' kernel hacker. The audience mostly consists of people who are learning about the kernel, working on kernel projects or professional kernel hackers that want to help less seasoned kernel people. #kernelnewbies is on the OFTC IRC Network. Try irc.oftc.net as your server and then /join #kernelnewbies. The kernelnewbies website also hosts articles, documents, FAQs... * Name: **linux-kernel mailing list archives and search engines** :URL: http://vger.kernel.org/vger-lists.html :URL: http://www.uwsg.indiana.edu/hypermail/linux/kernel/index.html :URL: http://groups.google.com/group/mlist.linux.kernel :Keywords: linux-kernel, archives, search. :Description: Some of the linux-kernel mailing list archivers. If you have a better/another one, please let me know.   "}),a.add({id:103,href:"/tags/balancing/",title:"balancing",description:"",content:""}),a.add({id:104,href:"/tags/irq/",title:"irq",description:"",content:""}),a.add({id:105,href:"/tags/nic/",title:"nic",description:"",content:""}),a.add({id:106,href:"/blog/irq-balancing/",title:"中断请求负载均衡",description:"在多CPU系统上，如何对设备的中断请求进行负载均衡，以提升中断处理效率。本文以多队列、单队列网卡为例介绍了中断的负载均衡方法。",content:"如果网卡NIC支持多队列，可以直接设置NIC多个队列的irq affinity到不同的CPU来实现负载均衡； 如果网卡NIC是单队列的，也可以通过RFS或者RPS在soft interrupt层面进行模拟，来实现负载均衡； RPS、RFS这种方式主要是针对单队列NIC的优化。\n我们是以网卡中断作为示例，对其他不同的设备其实也可以做类似处理。 并不是说所有的设备中断都需要绑定到多个cpu来实现负载均衡，因为有的外设的中断请求数可能并不多，就没必要了。\n多队列网卡ethtool -l eth0可以看到combined字段，该字段表明NIC有几个队列，如果有多个队列，比如8个， 那么对应的cpu affinity可以直接设置成ff，表示CPU0-7都可以收NIC中断请求来实现负载均衡。\nlspci -vvv可以看到不同的设备对应的中断号，如网卡设别可能是：pin A routed to IRQ 10，我们就知道10是其中断号。\nTODO:\n irq affinity设定了情况下，OS和硬件是如何交互的？如何负载均衡的，是在硬件层面实现的？ RPS/RFS，这种软中断层面的处理，具体细节是怎样的？  下面以多队列网卡为例来说明怎么回事。\n多队列网卡实现原理 # 1.硬件实现原理 # 下图是Intel 82575硬件逻辑图，有四个硬件队列。当收到报文时，通过hash包头的SIP、Sport、DIP、Dport四元组，将一条流总是收到相同的队列。同时触发与该队列绑定的中断。\n2.单队列驱动原理 # kernel从2.6.21版本之前不支持多队列特性，一个网卡只能申请一个中断号，因此同一个时刻只有一个核在处理网卡收到的包。如图2.1，协议栈通过NAPI轮询收取各个硬件queue中的报文到图2.2的net_device数据结构中，通过QDisc队列将报文发送到网卡。\n2.多队列驱动原理 # 2.6.21开始支持多队列特性，当网卡驱动加载时，通过获取的网卡型号，得到网卡的硬件queue的数量，并结合CPU核的数量，最终通过Sum=Min（网卡queue，CPU core）得出所要激活的网卡queue数量（Sum），并申请Sum个中断号，分配给激活的各个queue。\n如图3.1，当某个queue收到报文时，触发相应的中断，收到中断的核，将该任务加入到协议栈负责收包的该核的NET_RX_SOFTIRQ队列中（NET_RX_SOFTIRQ在每个核上都有一个实例），在NET_RX_SOFTIRQ中，调用NAPI的收包接口，将报文收到CPU中如图3.2的有多个netdev_queue的net_device数据结构中。\n这样，CPU的各个核可以并发的收包，就不会因为一个核不能满足需求，导致网络IO性能下降。\nRSS（Receive Side Scaling，网卡的硬件特性，多队列网卡将不同的流分发到不同的CPU上实现负载均衡）需要硬件支持，在不支持RSS的环境中，RPS/RFS提供了软件的解决方案。\n RPS（Receive Packet Steering）是把一个rx队列的软中断分发到多个CPU核上，从而达到负载均衡的目的。 RFS（Receive Flow Steering）是RPS的扩展，RPS只依靠hash来控制数据包，提供负载平衡，但是没有考虑到应用程序的位置（指应用程序所在CPU）。RFS目标是通过指派应用线程正在运行的CPU处理中断，增加数据缓存的命中率。  参考内容：\n"}),a.add({id:107,href:"/tags/affinity/",title:"affinity",description:"",content:""}),a.add({id:108,href:"/tags/interrupt/",title:"interrupt",description:"",content:""}),a.add({id:109,href:"/blog/irq-affinity/",title:"中断请求亲和性",description:"计算机硬件设备，有些通过中断的方式通知CPU有数据到达进而可以对其进行处理。那么这里设备的中断请求是如何发送到各个处理器的呢，是发送到所有的处理器，还是选择一个发送，有没有可能指定响应中断的CPU列表，即本文提到的中断请求的亲和性问题。Linux内核文档中irq-affinity.rst对此进行了描述，本文参照着文档对irq affinity进行设置、测试，加深理解。",content:"SMP IRQ affinity，指的是对称多处理器中的中断请求绑定。\n/proc/irq/IRQ#/smp_affinity和/proc/irq/IRQ#/smp_affinity_list指明了允许接收某 个中断请求IRQ#的多个或某个cpu。它是一个位掩码smp_affinity或者一个cpu列表 smp_affinity_list，其中记录了允许接受该中断请求的cpu。不允许禁止所有cpu接收该 中断请求，如果一个中断控制器不支持中断请求绑定，那么只能采用默认值，即允许所有 cpu接收该中断请求，并且这个值不会被修改。\n/proc/irq/default_smp_affinity指明了默认的中断绑定掩码，这个默认值将应用于所有 的非活动的、未激活的中断号。一旦一个中断号被分配、激活，那么它的中断绑定掩码将 被设置为这个默认值。这个默认值可以通过前面提到过的方法进行修改。这个默认掩码的 值为0xffffffff，请注意，该掩码是32位的。\n这里举个例子，网卡eth1中断请求IRQ44限定发送到CPU0-3，而后再限定发送到CPU4-7。\n网卡向cpu发中断请求44，下面我们对这个中断请求与cpu的绑定关系进行设置，并通过 ping命令进行测试，网卡会将接收到的icmp请求，以中断44的形式发送到绑定的cpu，通 过查看cpu接收到的中断请求数量，我们可以判断，这个44这个中断请求与cpu的绑定关系 。\n[root@moon 44]# cd /proc/irq/44 [root@moon 44]# cat smp_affinity ffffffff  首先，查看到44这个中断请求的默认绑定掩码为0xffffffff，说明，所有的cpu都可以接 收该中断请求。\n[root@moon 44]# echo 0f \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 0000000f  然后我们设置smp_affinity的值为0x0000000f，即使得编号为0-3的cpu允许接收该44这个 中断请求，其他的cpu都不会接收44这个中断请求。\n[root@moon 44]# ping -f h PING hell (195.4.7.3): 56 data bytes ... --- hell ping statistics --- 6029 packets transmitted, 6027 packets received, 0% packet loss round-trip min/avg/max = 0.1/0.1/0.4 ms  然后，对主机进行ping测试，这里的-f表示洪泛，h表示主机，实际测试的时候，可以修 改为localhost。这个时候，应用程序ping向主机发送了icmp请求包，网卡设备捕获到之 后，会向cpu发送中断号为44的中断请求。现在该主机上有8个cpu，由于我们设置了编号 为0-3的cpu可以接收该中断，其他的则不可以，那么如果我们查看cpu对中断44的接收情 况时，只有编号为0-3的cpu才能接收到中断请求。\n[root@moon 44]# cat /proc/interrupts | grep 'CPU\\|44:' CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 44: 1068 1785 1785 1783 0 0 0 0 IO-APIC-level eth1  通过查看测试结果，我们发现cpu 4-7 确实没有接收到编号为44的中断请求，但是编号 为0-3的cpu接收到了该中断请求。\n现在将其限定到CPU4-7上去：\n[root@moon 44]# echo f0 \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 000000f0  进一步进行测试，我们将允许接收编号44的中断请求的cpu设定为编号4-7，即将 smp_affinity的值设定为0x000000f0，下面再次通过ping进行测试。\n[root@moon 44]# ping -f h PING hell (195.4.7.3): 56 data bytes .. --- hell ping statistics --- 2779 packets transmitted, 2777 packets received, 0% packet loss round-trip min/avg/max = 0.1/0.5/585.4 ms [root@moon 44]# cat /proc/interrupts | 'CPU\\|44:' CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 44: 1068 1785 1785 1783 1784 1069 1070 1069 IO-APIC-level eth1  将当前cpu接收到的中断请求44的数量，与前面一次ping测试时各个cpu接收到的中断请求 44的数量对比发现，只有编号为4-7的cpu接收到的中断请求44的数量发生了改变，说明我 们成功的设置了中断请求44的中断绑定到cpu 4-7。\n如果想将中断请求限定发送到CPU1024-1031上，可以这么操作：\n[root@moon 44]# echo 1024-1031 \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 1024-1031  上面的语法可以将中断绑定到编号范围为1024-1031的cpu上。\nsee: irq affinity\n"}),a.add({id:110,href:"/tags/devcontainer/",title:"devcontainer",description:"",content:""}),a.add({id:111,href:"/tags/docker/",title:"docker",description:"",content:""}),a.add({id:112,href:"/tags/ide/",title:"ide",description:"",content:""}),a.add({id:113,href:"/blog/2022-06-28-linux-cc-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/",title:"mac/win下linux c/c++开发",description:"Linux C/C++开发是很多后台开发同学必备的一项技能，虽然现在Java、Go等跨平台语言的崛起也吸引了很多开发者，在某些业务中得到了大量的实践，但是C/C++依然是被广泛使用的。据我观察，进行Linux C/C++开发时在工具支持上还是没有Java、Go等开发起来方便，比如这个跨平台开发Linux C/C++程序的问题，头文件、库等等地怎么配置着，编译测试怎么玩着，说真的，我看了有些同事的做法真的头大，特别原始。本文就这个问题进行一点调研、总结，也为日后可能的类似开发工作做一些准备。",content:"问题背景 # 我们很多人主力操作系统是macOS或者Windows，用Linux作为主力操作系统的少吧，不过之前确实有连续7年多是用Fedora作为主力操作系统 :)\n现在很多人开发人员使用MacBook Pro作为自己的开发机，大厂标配，我们很多后台呢，开发的程序一般最后还是要跑在Linux系统上的，尤其是c/c++开发涉及到这里的跨平台开发的问题，很多开发人员用着非常原始的方式在开发，开发体验比较差。\n借这个契机，我调研了下现在比较好的一些开发方式，总结分享下。\n先定一个要实现的小目标：\n 能基于IDE进行开发，比如VSCode; 另外，编译构建必须能够  vscode: add dockerfile to workspace #  在vscode中cmd+p，输入add dockerfile to workspace并执行，此时会选择基础镜像，如面向c++开发的基础镜像，此时会生成默认的dockerfile。 然后在dockerfile选中后点击右键，选择build image，此时就完成镜像构建了，该默认dockerfile默认是一个编译镜像，里面包含了编译构建产物。 直接运行上述镜像默认就是运行程序，运行的方式可以在docker explorer里面找到镜像，右键菜单中选择Run，或者命令行执行。  这个镜像只是用来编译构建、测试运行的，还不能满足我们开发阶段的需求，因为开发阶段需要考虑头文件、库的搜索问题。\n解决思路：\n 至少要构建一个支持开发的镜像，如c/c++镜像； 启动这个镜像，并将当前工程以volume的形式挂在到容器中，或者在容器中clone下来这个项目。提交代码要注意随时提交； 开发通过vscode remote连接到vscode server进行开发，其实是本地vscode通过ssh连接传输vscode server软件包到容器中并安装启动； 如果开发镜像支持类似WebIDE的方式进行开发，也可以代替3这种方式，只是一些本地vscode的快捷配置等可能不是很好同步。  docker desktop: New Dev environment # Docker Desktop的这种实现方式，就是上面提到的2\\3这几步的组合，基本满足我们希望实现的目标了（支持开发容器Mount local directory或者容器中Clone git repository）。\n这种方式也有不足，就是假设后续有人要接手这个项目，或者有人和你协作，你怎么办呢？ 我们可以直接提交一个镜像push到registry，他只要能拉代码，又能拉镜像就基本能还原之前的开发环境。\n但是我为什么非要push一个镜像上去呢（包括自定义的基础镜像、开发阶段的分享镜像）？ 如果不push镜像而docker destop默认的开发镜像调整了或者我希望定制一个统一的怎么办？\nDocker Desktop创建新的开发镜像的时候有一种方式，允许指定一个基础镜像，但是这个基础镜像要push到远程registry。代码会被clone到这个 容器内部，我们就通过vscode remote进行开发即可。\n尽管vscode鼓励非Linux用户尽量通过这种方式，因为fs操作更快，但是还是有点不方便，因为这数据卷相当于额外浪费一份存储，考虑到之前已经克隆过的情况下。 有没有办法既能自定义基础镜像，又能挂载本地磁盘目录为数据卷的方式来解决呢？可以，请看方式3。\nvscode: Remote-Containers # vscode中Command Pallete中Remote-Containers: Add Development Container Configuration Files，执行这个我们可以为工程指定一个配置文件.devcontainer(实际是个目录)，.devcontainer/devcontainer.json中指明了我们要使用哪个镜像作为开发容器的基础镜像。 这里的基础镜像可以用vscode官方提供的，也可以是自己自定义好push到registry的，也可以是Dockerfile需要vscode代为构建本地镜像的，这几种方式均可！\n这样不就方便了吗，既不需要额外存储这个基础镜像，还保留了维护基础镜像的必要配置信息，如Dockerfile等。当然了如果基础镜像维护得当，我们引用registry 中的基础镜像即可，没必要每个工程下都放一份镜像Dockerfile信息。\n我目前比较喜欢这种方式，因为可以使用自定义基础镜像的同时，没有了额外容器中克隆代码导致的占用磁盘空间问题……不过这样性能会差点。\nWebIDE: 基于WebIDE的开发环境 # 在开发容器中支持WebIDE，github的codespace，以及gitpod就是类似的解决方案，我自己也基于开源的theia WebIDE做过类似的demo。\n这种方式也是一个思路，但是这种WebIDE的方式一般和代码托管站点结合起来会比较好些，现在github与gitpod、codespace的结合，腾讯内部工蜂也有与WebIDE的结合。\n这种结合起来是比较方便地，也可以通过与本地vscode的联动，来触发类似方式1中的这种工作方式，ssh到开发容器中，通过vscode client链接到vscode server。\n我们这里主要侧重于本地开发这种更通用点的场景，基于WebIDE的这种方式就不细说了，大家可以了解下gitpod、codespace的工作原理。\nvscode: 更多玩法 # vscode中还有更多玩法，比如docker in docker、docker from docker…和前面集中方式要解决的问题不一样，比如将vscode extension安装也放到容器中管理，而不是和本地vscode混在一起。有需要的时候再细究吧，先这么大只了解下。\n总结 # 本文总结了比较好用的跨平台开发Linux C/C++程序的方法，其实也不仅限于C/C++了，这个方法的适用性很广，只不过对于Linux C/C++跨平台开发这个场景，就比较有价值，因为看到很多同事的做法实在太原始了。\n"}),a.add({id:114,href:"/tags/vscode/",title:"vscode",description:"",content:""}),a.add({id:115,href:"/tags/lock/",title:"lock",description:"",content:""}),a.add({id:116,href:"/tags/mmap/",title:"mmap",description:"",content:""}),a.add({id:117,href:"/tags/multiprocess/",title:"multiprocess",description:"",content:""}),a.add({id:118,href:"/tags/mutex/",title:"mutex",description:"",content:""}),a.add({id:119,href:"/blog/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E9%87%8A%E6%94%BE/",title:"从0细说如何管理内存的？",description:"介绍下从用户态申请内存如malloc开始库函数做了什么、操作系统做了什么、操作系统内存分配器怎么做的、用户态内存分配器怎么做的，为什么用户态又要单独做内存分配器。类似地，释放内存free的时候这一连串的又发生了什么。",content:""}),a.add({id:120,href:"/blog/%E5%B9%B6%E5%8F%91%E5%90%8C%E6%AD%A5/",title:"并发同步",description:"介绍下如何实现多线程、多进程间的并发同步控制，多线程场景并发控制比较常见，多进程的可能不少人都比较陌生一点吧。",content:"并发同步，在并发编程中是非常重要的。当我们讨论并发编程时，我们的程序可能是通过多线程来实现，也可能通过多进程来实现。\n 我们在OS理论中了解到进程是资源分配的最小单位，线程是调度的最小单位。在Linux里面，这么讲也是成立的。更细致地说，在Linux中，线程其实就是轻量级进程LWP来表示的。对Linux调度器而言，可调度实体既可以是进程、线程也可以是一个任务组，这个任务组中又可以有其他的可调度实体。\n 有两个问题：\n  当我们在单进程多线程中该如何通过？\n  当我们在多个进程间进行同步时该如何同步？\n  我们常用的同步的措施包括：\n mutex/rwmutex semaphore condition variable  我们处理最多的可能就是单进程多线程情况下的同步，使用上面这些来处理没啥好说的。现在思考下，如果要实现多个进程之间的同步，有没有办法呢？\n这些玩意的实现，本质上是基于处理器指令lock addr锁总线的这一基础控制，一步步实现了CAS、Spinlock、mutex/semaphore/condvar。所以其核心就是利用了锁一个内存地址总线来实现。\nok，那么假设我们在当前进程全局变量中初始化了一个mutex变量，然后fork下当前进程，然后**父子进程能通过这个mutex变量进行同步控制吗？**不能！因为父子进程中复制后mutex是两个不同的内存变量，这两个变量的内存地址是不同的，其实就是两个不同的锁，所以无法通过这个mutex进行正确的同步控制。\n那怎么办呢？我们只要在共享的内存空间里面来初始化这个mutex变量就可以了（关键的就是lock的底层的内存地址一样就可以了），比如通过：\nbuffer = (*buffer_t)mmap(NULL,4,devzeroFD,MAP_SHARED)，\n然后将buffer-\u0026gt;lock作为mutex变量进行初始化，因为mmap映射的时候指定了共享模式，此时初始化写内存时也是共享的，fork的子进程初始化时其实也是同一个锁（已经初始化过不会重复初始化吧？），然后后续加解锁都是在相同的地址上了，这个很好理解，映射的是同一段内存。就能正常完成多个进程之间的同步控制。\n其他的rwmutex/semaphore/condvar，理论上也可以通过相似的方法来实现。\nreference:\n1: 多进程并发同步控制, Synchronization Across Process Boundaries\n2: 支持优先级继承的锁, Priority Inheritance Mutex\n"}),a.add({id:121,href:"/tags/alignment/",title:"alignment",description:"",content:""}),a.add({id:122,href:"/tags/cache-consistency/",title:"cache consistency",description:"",content:""}),a.add({id:123,href:"/tags/mesi/",title:"mesi",description:"",content:""}),a.add({id:124,href:"/tags/mesif/",title:"MESIF",description:"",content:""}),a.add({id:125,href:"/tags/packed/",title:"packed",description:"",content:""}),a.add({id:126,href:"/tags/padding/",title:"padding",description:"",content:""}),a.add({id:127,href:"/tags/thread-visibility/",title:"thread visibility",description:"",content:""}),a.add({id:128,href:"/tags/volatile/",title:"volatile",description:"",content:""}),a.add({id:129,href:"/blog/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/",title:"为什么需要内存对齐，以及如何控制对齐",description:"介绍下内存对齐访问（aligned access）的重要性，以及不对齐访问的情况下不同处理器的不同的行为，以及如何规避这些问题，比如编译期层面可能有哪些措施。也描述了下如何通过GCC扩展来控制aligned boundary或者packed。",content:"什么是内存对齐？ # 所谓的内存对齐，指的是我们的一些数据在内存中组织的时候，为了后续访问时效率更高，需要将其起始地址进行一定的对齐处理，最常见的就是将结构体各个成员起始地址分别对齐，非结构体比如一个普通的int数也会对齐处理的。\n举个int数的例子：\nint n = 100; printf(\u0026quot;n: %d\\n\u0026quot;, n); printf(\u0026quot;sizeof(int): %lu, address: %p\\n\u0026quot;, sizeof(n), \u0026amp;n);  运行后发现n的大小是4字节，地址是0x16d216c4c，hex \u0026lsquo;c\u0026rsquo;对应二进制数为1100，低位是00，00表示是4字节对齐的，那这个int数在内存中组织就是4字节对齐的。\n再看个struct结构体：\ntypedef struct { char sex; int age; } Person; Person p; printf(\u0026quot;sizeof(person): %lu\\n\u0026quot;, sizeof(p)); printf(\u0026quot;person.sex address: %p\\n\u0026quot;, \u0026amp;p.sex); printf(\u0026quot;person.age address: %p\\n\u0026quot;, \u0026amp;p.age);  运行后发现p的大小是8个字节，我们书本上学习过，sex放在地址0，age放在地址4处，sex后有3个padding char，这样整个是8个字节。然后我们继续看下地址:\nperson address: 0x16fdbac44 person.sex address: 0x16fdbac44 person.age address: 0x16fdbac48  struct的首地址跟第一个成员的首地址是相同的，低位的44表示01000100，说明这个结构体本身以及内部成员sex都是4字节对齐的，然后age地址低位是01001000，在0x16fdbac44+4=0x16fdbac48，其实是4字节对齐的。这么看下来这个结构体中各个字段都是4字节对齐的。在sex和age之间padding了3个char。\n这就是内存对齐了，至少直观地知道是什么了。\n 简单地说，当我们希望读取的数据字节数是N，该数据起始地址是addr，假设 addr % N == 0 就是aligned access，反之就是unaligned access。\n即便是基本类型也会对齐，对于结构体各个field都会对齐，当我们说一个struct是多少字节对齐时，指的是struct中field对齐用的字节数最大的一个。 不妨了解下go语言中的内存对齐规则，see: https://go.dev/ref/spec#:~:text=The%20following%20minimal,array%27s%20element%20type.\n 为什么需要对齐？ # 那么为什么要填充些padding数据呢？这就涉及到处理器访存的工作过程了，我们怎么控制处理器访问内存数据的？一般就是通过mov指令来将内存数据搬迁到内存后者寄存器中。mov指令，指令译码、指令执行，其实就是把一个内存地址放到地址总线上通过内存总线控制对应地址可读，然后通过数据总线从指定起始地址处连续读取数据总线位宽的数据到MDR（存储器数据寄存器）然后进一步加载到指定寄存器或者内存中。\n这里有什么要关注的吗？有，比如8086 20位的地址线可以寻址1MB的内存，内存以字节编址，那么20位地址线可以寻址内存空间为2^20=1MB，一次读取的数据量取决于数据总线位宽，比如8086位 16位数据线，一次也就读取2个字节。\n假设我们一个int数吧存放在地址0处，那么我1条汇编指令mov ax, 0x0就可以完成，为啥呢，数据总线是16位的，一次就能读取出来放到ax里。\n那么如果这个int数不在地址0处，而是在0x1处呢？此时一条mov ax, 0x0就不够了，只读了8个字节，还有8个字节在0x2处，最后就只能movb al, 0x1, movb ah, 0x2。和内存对齐的相比，这种就多了一次访存操作，执行效率自然就慢了啊。\n上面这个例子基本总结了内存对齐的原因，就是为了尽量通过内存对齐充分发挥硬件访问内存的效率，避免因为未合理对齐导致的编译器需要安插一些其他更多的内存访问指令，每条指令执行都需要经过取指、译码、执行等过程，而且还是访存，访存和处理器计算的效率是不在一个数量级的。所以要内存对齐。\n 准确地说，unaligned access的坏处主要包含这些，跟平台有关系：\n 有的平台会透明处理这些问题，只不过是性能上会有些下降； 有的平台可能会抛异常，异常处理函数来解决，性能开销更大； 有的平台可能会抛异常，异常信息不明确，无法修复； 有的平台可能不能正常处理，请求了错误的内存地址的数据，导致bug；  一般编译器会考虑不同平台的差异性，尽量生成aligned access的指令。\nsee：linux unaligned memory access。\n 内存对齐基本规则？ # 内存对齐规则，大面上的大家都清楚，就是算呗，按那几条对齐规则来。\n举个例子：\ntypedef struct { char sex; int age; } Student;  sex占1个字节，放在地址p处1字节对齐；age是4个字节的话应该4字节对齐，这样sex后应该填充3个padding char，age放在地址p+0x4处，本身为4字节。这样整个struct大小为8字节，各字段也合理对齐了。\n读者可以自行找些网上的相关资料了解更多对齐的信息。\n如何人为控制对齐？ # 对于编译期默认是如何控制对齐的，我们可以写程序轻松验证出来。其实gcc编译期扩展可以通过attribute进行修饰，对结构体对齐、结构体字段的对齐规则进行精细控制。\n这部分我们就通过程序来验证学习下，不做过多解释了，注释可以说明一切。\n#include \u0026lt;stdio.h\u0026gt; typedef struct { char sex; int age; } Person; // because it's packed, so sizeof is 5 bytes // 1 + 4 = 5 bytes typedef struct __attribute__ ((packed)) { char sex; int age; } Student; // this way: 1 + 4 + 3padding + 4 = 12 bytes struct StudentX { char sex __attribute__ ((aligned (1))); int age __attribute__ ((packed)); int xxx __attribute__ ((aligned(4))); }; // this way, the sizeof StudentY will be 16 bytes // 8 + 8 = 16 bytes struct StudentY { char sex __attribute__ ((aligned (8))); int age __attribute__ ((aligned (8))); }; // this way, add attributes to the struct means this struct: // - aligned(4) : sizeof is 8 // - aligned(8) : sizeof is 8 // - aligned(16) : sizeof is 16 // - aligned(32) : sizeof is 32 // // i don't know how aligned affects struct members, it looks like // telling the compiler to try to align the struct members in this way: // - if aligned (n) is too small, use default value, like char:1 int:4 // - if aligned (n) is bigger than default values, try to align to bigger boundary. typedef struct __attribute__ ((aligned (4))) { char sex ; int age ; } StudentZ; int main(int argc, char **argv) { int n = 100; printf(\u0026quot;n: %d\\n\u0026quot;, n); printf(\u0026quot;sizeof(int): %lu, address: %p\\n\u0026quot;, sizeof(n), \u0026amp;n); Person p; printf(\u0026quot;sizeof(person): %lu\\n\u0026quot;, sizeof(p)); printf(\u0026quot;person address: %p\\n\u0026quot;, \u0026amp;p); printf(\u0026quot;person.sex address: %p\\n\u0026quot;, \u0026amp;p.sex); printf(\u0026quot;person.age address: %p\\n\u0026quot;, \u0026amp;p.age); Student s; printf(\u0026quot;sizeof(student): %lu\\n\u0026quot;, sizeof(s)); struct StudentX x; printf(\u0026quot;sizeof(studentx): %lu\\n\u0026quot;, sizeof(x)); struct StudentY y; printf(\u0026quot;sizeof(studenty): %lu\\n\u0026quot;, sizeof(y)); StudentZ z; printf(\u0026quot;sizeof(studentz): %lu\\n\u0026quot;, sizeof(z)); printf(\u0026quot;address of z: %p\\n\u0026quot;, \u0026amp;z); return 0; }  运行程序进行测试：\nn: 100 sizeof(int): 4, address: 0x16b356c4c sizeof(person): 8 person address: 0x16b356c44 person.sex address: 0x16b356c44 person.age address: 0x16b356c48 sizeof(student): 5 sizeof(studentx): 12 sizeof(studenty): 16 sizeof(studentz): 8 address of z: 0x16b356c18  通过这里的测试程序，以及输出的结果，我们应该能推断出编译期扩展 __attribute__ ((aligned (n))) 与 __attribute__((packed))的差异。packed表示不再对其进行padding，aligned表示了按照多少字节控制对齐，如果不超过指定的n就不能完成对对齐，就用默认可行的值，如果n超过了最小阈值则安n进行。\n总结 # 本文小结了数据、结构体及其字段在内存中的对齐，并通过实例解释了gcc扩展对对齐的控制。之前天美J3面试时有问及计算sizeof时又没有例外情况，当时也没想起来。除了平台原因（比如int数大小不是4字节），再或者如果是采用的gcc attributes对其进行了扩展，比如padding或者比较大的aligned value也会导致计算结果不一样的问题。\n"}),a.add({id:130,href:"/tags/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/",title:"内存对齐",description:"",content:""}),a.add({id:131,href:"/blog/volatile/",title:"对volatile的认识",description:"介绍了为什么c/c++需要volatile，关于volatile不能保证线程可见性的说明，以及为什么在x86上似乎可以做到线程可见性的释疑，最后简单提了下mesif来说明线程可见性是要依附于cache一致性协议的。",content:"关于这个我有一篇非常不错的总结，估计是全网最好的总结：你不认识的c/c++ volatile，虽然标题有点“博眼球”，但是内容绝对是很多高T都可能不知道的。\n今天翻之前整理的Linux内核文档笔记时，又看到了当时volatile相关的笔记，也是因为这个事情几年前听中心的高T分享时觉得他搞错了，才写的这篇总结。\n这里也放个简单的文档，系统性的强调下，认识正确了对于并发编程还是很重要的。\nsee also linux volatile considered harmful，linus torvalds大佬亲笔。\n简单总结下的话就是：\n volatile，需要volatile，尤其是对于涉及到外设访问的情况，有些外设的设备端口是通过统一编址来的，使用某些访存指令而非专用的in/out指令的话，有可能读的数据会做优化，比如放到寄存器中，硬件cpu还可能放到cache中。对于这些设备的读操作，需要避免优化才能正常工作，所以需要volatile。这在c/c++设备驱动中应该比较有用。 volatile，在c/c++语言设计层面，没有保证线程可见性的任何保证，切记！它只是告知编译器不要做软件级别的寄存器优化而已，对于硬件级别的cache缓存没有任何控制。 volatile，不能保证线程可见性，但是在不同的处理器平台上却是会有不同的表现，比如在x86平台上，加了volatile修饰的变量就能够保证线程可见性。为什么呢？首先加了volatile修饰后避免了寄存器优化，现在还有cache的顾虑对吧，但是x86平台比较特殊，它使用了一种称作 tso的memory model，x86多核能够看到其他核对某个cacheline的修改，因此能感知到最新写的数据，能做到线程可见性。 volatile在其他平台内存模型不同，不一定能和x86一样实现线程可见性。 要想实现线程可见性，编译器一般是结合语言本身的特性，为止生成一些内存屏障指令，这些屏障指令最终会触发cache的MESIF协议来使得当前核上的修改对其他核可见。  "}),a.add({id:132,href:"/tags/distro/",title:"distro",description:"",content:""}),a.add({id:133,href:"/tags/fedora/",title:"fedora",description:"",content:""}),a.add({id:134,href:"/tags/gnome/",title:"gnome",description:"",content:""}),a.add({id:135,href:"/tags/kde/",title:"kde",description:"",content:""}),a.add({id:136,href:"/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E5%88%86%E4%BA%AB/",title:"Linux桌面发行版分享",description:"这是我很久之前2016.5.7写的一篇关于linux桌面发行版的文章，但是一直停在我的笔记里。ubuntu 16.04 lts是2016年4月21日发布的，到现在也要6年多了，因为最近在整理之前的一些笔记，发现当初的一些想法还挺好的，拿出来继续分享下。",content:"Linux桌面发行版分享 # 这是一篇写在2016年的文章一直在我的个人笔记里，感觉当时很多想法今天依然成立，所以拿出来继续分享下。某些信息可能已经有过时，相关的部分我在备注里进行了标注，\n0.体验Linux发行版 # 今天安装了Ubuntu 16.04 LTS，本来准备一直用Fedora的，但是我的笔记本上安装的还是 Fedora 21版本，但是当前最新的已经更新到了Fedora 24,今天刚刚发布了Beta版本。此 前我对Fedora 23 GA以及Fedora 24 Alpha版本进行了简单的测试，实在是不喜欢KDE 5！\n怎么说呢，其实看上去KDE 5挺漂亮的，应该将来也会有不错的发展，但是考虑到KDE 5刚 出来的时间还不够长，其中很多在KDE 4里面方便实用的功能在KDE 5中还没有被开发出来 ，而我又是一个倾向于“工欲善其事，必先利其器”的同学，让我这样把一个未充分完善好 的桌面环境当做自己的主力系统，我实在难以接受！对于GNOME 3，我就不做任何评论了 ，我宁可用Ubuntu Unity也不用GNOME 3！\n可能有人说，没必要一直跟着更新啊，继续实用Fedora 21也可以啊！？此话当然不假， 可是一个失去后续更新支持的版本，我想还是要继续跟进新版本要更好。其实我现在配置 的已经相当棒了，有的软件源里面的程序存在某些小问题，瑕不掩瑜的，我也对其源代码 进行了部分修改，以为自己所用，因为这部分工作还是相当多、相当细的，如果继续跟进 新的发行版，而软件源里面的软件包可能还没有修改过来，或者不符合我的需要，又要进 行重复性的工作，我觉得这个工作量还是蛮大的，至少现在我没有那么充足的时间。\nFedora发行版每6个月更新一次，CentOS 7可以支持10年，我本来也计划使用CentOS的， 但是CentOS对稳定性的追求，也使得很多软件包不能被加入其软件源，有些我很喜欢的工 具，安装、配置起来就会比较麻烦，dpkg、alien、rpmrebuild甚至修改源代码这些可能 都要用到，以配置出一个趁手的系统环境。半年前，我在另一台三星的笔记本安装了 CentOS 7，配置完成之后，堪称完美，那个时候时间多啊，折腾的时间也挺长的；现在时 间没有那么充裕了，我在这台thinkpad上安装了CentOS 7.2，前后也就折腾了一天，不打 算折腾了。\n最后，我选择了Ubuntu 16.04 LTS版本，可以支持5年，而我本身也想重新比较一下 Ubuntu、Fedora这两大发行版，为什么呢？因为对这两款发行版，我都有向当长的使用时 间，现在也积累了很多的经验，前不久我碰巧又看到了一个各大发行版性能对比的文章， 其中Debian系列的性能要明显优于RHEL系列，原因我暂时也不是特别清楚，这也是激发我 重新选择Ubuntu的原因之一。我希望在使用过程中，重新比较一下Ubuntu和Fedora这两大发行版的差异，例如包管理工具的差异、软件包中的配置文件的差异、系统管理方面的差 异，此外呢，我也希望能够对其性能上的差异进行一下更深的认识。\n1.系统安装过程 # 系统安装过程，应该说是驾轻就熟了，下载一个Ubuntu 16.04 LTS的ISO文件，然后使用 Unetbootin制作一个可以引导系统安装的U盘。U盘要格式化成FAT32格式，且要根据需要 预留一定的存储空间，以供安装过程中释放文件使用，如果预留空间不足，可能导致安装 失败。\n制作完成安装U盘之后，插入电脑，关闭BIOS中的UEFI引导模式，然后从USB HDD启动安装即可。安装的时候手动分区，最好能够把那些第三方软件包给安装上，这样省的后续安装 ，省心。我是深有体会，之前安装音频、视频播放器的时候，安装解码库浪费了很多时间 。安装过程中有个别地方需要设置一下，例如用户名、密码、语言、地区、时间等等的。\n注意，Ubuntu在安装过程中不会对root用户的密码进行设置，并且默认将新建的用户加入 wheel组中！但是在Fedora安装过程中，会对root密码进行设置，然后再创建一个新用户 ，并允许选择是否将该用户加入wheel组中，还可以指定uid、gid等。这是一个区别，需 要注意一下，安装完成之后，需要通过“passwd root”对密码进行重新设定。\n相对来说，安装过程还是比较顺利的，但是需要注意的是，前面提到过Unetbootin需要预 留一定的空间，例如100m，或者200m，甚至500m，如果设置的比较小的话，可能就会遇到“磁盘空间不足，安装失败”，这是由于系统安装过程中，有些压缩文件需要释放，释放的目的地不是在我们要安装到的目标硬盘上，而是在我们的U盘上，剩余空间不足的话，肯 定文件释放就会失败，就不能成功安装到我们的目标硬盘上。例如Ubuntu Kylin设置100m 的话，就会安装失败，设为500m就可以安装成功。用U盘安装与用光盘安装还是有区别的 ，用光盘安装的话，一般释放文件的目的地在目标硬盘上。\n安装完成之后，赶紧试用一下吧。\n2.软件安装配置 # 软件安装完成之后，应该养成一个好习惯，先把软件中的所有配置选项查看一遍，这样的 话就可以对软件整体有个更全面的认识。很多用户在安装了软件之后，就不管不顾了，这 怎么行呢？比如有些人手机上安装了在线视频播放软件，但是从来不关心相关设置，时间 久了，缓存占用空间越来越多，但是却不知道清理这些垃圾；又或者买了IPhone以为手机 有指纹安全了，但是却不知道该在设置里面对Siri进行相关的设置，以阻止未解锁情况下 的绕过安全检查的问题……像这样的类似的问题有很多。\n安装完成一个软件之后尚需如此，安装完成一个操作系统之后，就更需要这样了。对于系 统中的绝大部分配置，例如启动设置、登陆设置、界面设置、环境变量设置、别名设置、 常用软件包设置、安全设置、tricks等等，这些都是一个熟练的计算机用户安装完系统之 后应该考虑的。对于Linux用户，这一点显得尤为重要，一个配置良好的系统，可以让 Linux充分发挥出其优势，成为我们的趁手的兵器！\n3.系统引导设置 # 3.1.设定GRUB引导界面 # 设定GRUB是很重要的，GRUB可以帮助引导多个安装的系统，支持windows、unix、linux等，我之前曾经有专门的笔记对GRUB相关的配置进行了详细地说明，这里就不再阐述了，感兴趣的话，可以参考我之前的说明加以了解。\n这里仅仅对GRUB的工作原理进行一下简单的说明。当我们按下开机按钮的时候，系统BIOS 被启动，并执行加电自检任务，任务完成之后，将引导操作系统启动。BIOS会将系统控制 权交由另一个程序进行处理，这个程序被安装在硬盘的启动扇区中，通常是第一个扇区。 但是一个扇区只有512个字节，不可能装下足够多的代码来完成系统的启动任务。因此在 这个第一扇区中往往存放了一些简单的代码，这段代码接收BIOS转交的系统控制权，去执 行后续的更加复杂的系统启动任务。\n以GRUB2为例，通常将GRUB安装在硬盘的第一扇区中，并且将系统内核映像安装在/boot分区中，并且/boot/grub2中也保留了其他的大量的GRUB2程序、配置文件等。这样硬盘第一扇区中的grub引导代码会加载相应的程序，并最终完成内核的装载任务。当内核装载完成之后，GRUB再将系统控制权交由内核，这时操作系统才算是真正的接管了整个系统。\n3.2.设定Plymouth动画，并开启帧缓冲 # 3.2.1.开启Plymouth # GRUB装载内核、引导内核、内核启动过程中，需要执行很多任务，这个任务耗时可能还比 较长，为了让用户在等待系统启动的过程中，不至于等待地又闷又烦，可以在这段时间里 ，显示一个比较友好的启动界面，例如进度条、启动动画等等。\nplymouth就是这样的一个程序！它通常包括了3个主要部分，一个plymouthd程序，这个相当于一项服务，在系统启动的时候会决定什么时候开启动画、结束动画，开启和结束动画 是通过另一个程序plymouth来完成的。另一个部分也就是这里的动画了，我们称之为 plymouth主题。\n用户可能在同一个系统中安装多个plymouth主题，这就存在一个“系统显示哪个主题”的选择问题！在Fedora里面，是通过plymouth-set-default-theme来选择主题，然后通过 dracut重建initramfs实现的。但是在Ubuntu里面采用了一种更加简便的方式，即通过 update-alternatives来实现。在Fedora里面，其实也存在update-alternatives工具，但 是却采用的重新建立initramfs的方式，相比之下，稍微有点繁琐，但是这种方式可能在 系统启动速度方面更胜一筹。因为plymouth主题所需的资源被直接加入到了了 initramfs中，加载后解压缩的速度可能比通过update-alternatives生成的符号链接再次 访问文件系统更加节省时间。各有优缺点！\n3.2.2.开启帧缓冲 # /etc/initramfs-tools/conf.d/splash中增加一行FRAMEBUFFER=y，没有该文件就创建该 文件。开启帧缓冲之后，可以加速plymouth启动，以使得plymouth动画能够尽量铺满系统启动的整个过程，以使得启动界面更加友好。\n修改完成后，需要重新建立initramfs，执行命令update-initramfs -u命令即可完成。对 于Fedora系统需要通过dracut来完成，其实Ubuntu里面也是通过dracut来完成的， update-initramfs命令只不过是一个shell脚本而已，其只不过是对dracut命令的封装。\n3.3.指定关键内核参数 # 系统中有些参数是在系统启动的过程中指定的，虽然在系统运行期间仍然可以对其进行修 改，但是如果通过配置文件或者其他方式能够指定好相关的参数信息，运行期间就无需再干预、调整了。\n3.3.1.设定虚拟内存换出比率vm.swappiness # 现在的物理内存越来越大了，在一般使用情况下，交换区是很少会被使用到的。虚拟内存 频繁的换入换出会影响系统的响应速度，就算是现在使用SSD，也比内存慢很多，因此合 理地设置内存页面换入换出率是非常重要的，而且我们要使用的是桌面版操作系统，合理 地设置可以减少图形界面的响应延迟时间。\n/etc/sysctl.conf中增加vm.swappiness=16，通过sysctl vm.swappiness命令可以看出默 认设置是60，我们通过修改配置文件将其设置为16。\n3.3.2.设定udev的网卡命名规则 # 对于系统中的网卡，我们更加熟悉eth0、wlan0这样的命名方式，但是如果我们不加配置 ，系统中很可能显示的是enp0s25、wlp3s0这样的名字，为什么呢？这与udev命名规则有 关系。\n如何看到我们熟悉的名字呢？当然业余udev命名规则有关系，这里可以通过grub传递内核 参数“net.ifnames=0 biosdevname=0”来解决，修改/etc/default/grub之后，需要重新更新/boot/grub2/grub.cfg，这个可以通过update-grub2来完成。\n但是，我的情况比较特别，我这个笔记本有两个硬盘，分别记为/dev/sda和/dev/sdb。其中/dev/sdb上安装了Fedora，并且在/dev/sdb上安装了grub；/dev/sda上安装了Ubuntu，并且在/dev/sda上安装了grub。然后将/dev/sdb作为第一启动设备，为啥这么做？因为sdb是一个SSD，速度快，而且Fedora是我的主力系统，就是这么个情况。由于引导Ubuntu启动的grub配置文件是在/dev/sdb上的Fedora中生成的，与Ubuntu上面的grub配置文件没有关系。\n因此如果要正确改过网卡的名字来，还是需要修改/dev/sdb上的 /boot/grub2/grub.cfg中的相关配置。其实也就是将上述提到的内盒参数加入到 menuentry的linux命令后的选项中而已。\n3.3.3.关闭启动时fsck对文件系统的检查 # /etc/fstab中将每个分区的最后的一列数字全部修改为0，这样可以避免系统启动时对文 件系统进行检查，加快系统启动速度。\n3.3.4.激活所有的系统魔法键vm.sysrq # 修改/etc/sysctl.conf，增加一行vm.sysrq=1，这样就可以激活Linux系统内所有的魔法 键，例如比较常用的Ctrl+Alt+Print+K，表示杀死当前会话，包括当前会话中启动的所有 的进程；Ctrl+Alt+Print+B，表示立即重新启动系统。\n这两个魔法键是我经常使用的，非常有用，特别是希望快速检查配置更改是否有效或者图 形界面失去响应的时候。\n4.系统优化及系统工具 # 4.1.系统配置优化 # 4.1.1.Ubuntu greeter配置 # 要创建、修改的文件主要包括：\n /usr/share/glib-2.0/schemas/com.canonical.unity-greeter.gschema.xml  修改该文件，可以禁用greeter界面的系统已就绪的声音提醒、是否绘制网格、是否要加 载一个图像作为背景，加载图像前的界面颜色等。对于要加载的图片最好能够与用户之前 设定的桌面壁纸一致，这样可以加快系统登陆系统的时间（避免了再次加载图片嘛，减少 了访问文件系统的时间）；另外，加载图片之前的颜色，也应尽量与壁纸、plymouth动画 背景色相一致，这样显得系统启动更加流畅，界面更友好。\n修改该xml文件后，需要执行如下命令使其生效：\n sudo glib-compile-schemas /usr/share/glib-2.0/schemas\n 执行改行命令的目的，是将修改后的xml文件与未修改的xml文件重新编译成一个完整的二 进制文件，gsettings读取这个二进制文件并对图形界面进行相关的设置。\n关于如何在用户设定新的壁纸之后，让系统启动到greeter界面的时候可以自动装载的问 题，我们可以在上述xml里面将待加载的图片设为一个符号链接.background-uri。然后当 用户修改背景图片后，可以通过命令update-background来更新该链接，使其指向新的背 景图片；或者在.bashrc里面写入一些脚本来完成链接的更新。总之目的就是保证用户再 次登陆时，能够加载正确的图片，实现平滑地界面过渡。\n /home/username/.bashrc  关于如何在用户设定新的壁纸之后，让系统启动到greeter界面的时候可以自动装载的问 题，我们可以在上述xml里面将待加载的图片设为一个符号链接.background-uri。然后当 用户修改背景图片后，可以通过命令update-background来更新该链接，使其指向新的背 景图片；或者在.bashrc里面写入一些脚本来完成链接的更新。总之目的就是保证用户再 次登陆时，尅加载正确的图片，实现平滑地界面过渡。\n在我以前使用Ubuntu 12.04 LTS的时候，gconf可以在用户选择新的桌面壁纸后执行一些 操作，比如更新%gconf.xml文件，其中保存了用户选择的壁纸的绝对路径，可以利用它来 更新符号链接.background-uri。但是在Ubuntu 16.04 LTS里面，我发现系统中默认没有 使用生成%gconf.xml文件，但是通过gsettings可以获取到壁纸路径信息，并且格式与 %gconf.xml中是一致的。\n在.bashrc中，增加如下三行脚本就够了：\n BACKGROUND_CONFIG=gsettings get org.gnome.desktop.background picture-uri\nBACKGROUND_CONFIG=echo ${BACKGROUND_CONFIG#*//}\nln -sf $BACKGROUND_CONFIG ~/.background-uri\n  /usr/bin/update-background  当然了，也可以把上述三行脚本写入一个bash脚本中，放入搜索路径/usr/bin中：\n #!/bin/bash\nBACKGROUND_CONFIG=gsettings get org.gnome.desktop.background picture-uri\nBACKGROUND_CONFIG=echo ${BACKGROUND_CONFIG#*//}\nln -sf $BACKGROUND_CONFIG ~/.background-uri\necho \u0026ldquo;update background-uri link \u0026hellip; done\u0026rdquo;\n  /home/username/.background-uri  这只是一个符号链接，通过它指向正确的桌面壁纸。由于不希望在后续使用过程中看到这 个文件，或者对其进行直接修改，所以将其设置为隐藏文件。\n4.1.2.bash配置 #   /etc/passwd\n  /etc/bash.bashrc \u0026amp; /etc/profile\n  .bashrc \u0026amp; .profile\n 环境变量   Java相关\nAnt相关\nMaven相关\n\u0026hellip;\n其他\n  别名   alias bb=\u0026ldquo;byobu\u0026rdquo;\nalias clean=\u0026ldquo;dpkg -l | grep ^rc | awk \u0026lsquo;{print $2}\u0026rsquo; | xargs sudo dpkg -P\u0026rdquo; alias cls=\u0026ldquo;reset\u0026rdquo;\nalias duu=\u0026ldquo;du -h -a -d 1\u0026rdquo; alias ee=\u0026ldquo;exit\u0026rdquo;\nalias g++=\u0026ldquo;g++ \u0026ndash;std=c++0x\u0026rdquo;\nalias gentags=\u0026ldquo;sudo /usr/bin/ctags \u0026ndash;c-kinds=+dfglm \u0026ndash;language-force=C -R .\u0026rdquo;\nalias gg=\u0026ldquo;cd /home/user/Github/Study\u0026rdquo;\nalias grep=\u0026ldquo;grep \u0026ndash;color=auto\u0026rdquo;\nalias gvim=\u0026ldquo;gvim -f\u0026rdquo;\nalias indent=\u0026ldquo;indent -kr\u0026rdquo;\nalias l=\u0026ldquo;ls -CF\u0026rdquo;\nalias la=\u0026ldquo;ls -A\u0026rdquo;\nalias ll=\u0026ldquo;ls -al\u0026rdquo;\nalias ls=\u0026ldquo;ls \u0026ndash;color=auto\u0026rdquo;\nalias lg-ce=\u0026ldquo;sdcv -u\u0026rsquo;朗道汉英字典5.0'\u0026rdquo;\nalias lg-ec=\u0026ldquo;sdcv -u\u0026rsquo;朗道英汉字典5.0'\u0026rdquo;\nalias mirror=\u0026ldquo;wget -r -p -np -k\u0026rdquo;\nalias mmatlab=\u0026ldquo;matlab -nojvm\u0026rdquo;\nalias pp=\u0026quot;/usr/bin/proxychains4\u0026quot;\nalias ss=\u0026ldquo;ssh -qtfnN -D 7070 ZhangJie@192.168.56.254\u0026rdquo;\nalias vvim=\u0026ldquo;vim -u ~/.vvimrc\u0026rdquo;\nalias nvim=\u0026ldquo;vim -u NONE\u0026rdquo;\n  函数   hostlist\n\u0026hellip;\n其他\n   4.1.3.gnome-terminal或Konsole配置 # 4.1.4.Vim配置 #  vim.tiny-\u0026gt;vim-\u0026gt;vim.nox-\u0026gt;vim.athena-\u0026gt;vim.gtk/vim.gnome  vim的不同二进制版本，其中内置的功能特性有所差异，在上述箭头所示顺序中，各版本 包含的特征依次增加。系统中可以安装多个vim版本，然后通过update-alternatives来控 制使用那个版本。\n .viminfo  /etc/vim/vimrc中，保存着vim的全局配置。奇葩的是，在Ubuntu里面默认没有开启 viminfo支持，这个只要对/etc/vim/vimrc文件进行修改，取消相应的配置前面的注释就 可以了。\n .vimrc  vimrc这个是vim的主要配置文件，关于vim这一个编辑器，涉及到很多方面的配置，包括 颜色配置、快捷键配置、颜色配置、命令配置、插件配置等等，建议没事多翻翻vim相关 的论坛，总能学到点东西，加快文本编辑效率。vim不愧是编辑器之神！\n如果实在是对vim的相关配置感兴趣，不妨查看一下我的相关配置说明，可以从如下repo 进行获取：https://github.com/hitzhangjie/Conf.git。\n4.1.5.按键延时、按键速率配置，更快速地输入 # 降低按键延时、提高按键速率，这样可以更加快速地进行输入操作，在Vim中进行移动效 率也会更快。可以根据需要、个人习惯进行适当地调整。\n有些情况下，我们进行输入操作时，如果一边思考一边输入的时候，可能输入操作会比较 慢一些，但是如果思考任务不是很重的情况下，输入的速度就会很快，但是呢，系统的默 认按键设置有一个按键延时和输入速率限制，这个限制在某些情况下会严重干扰输入速度 。对于这一点我是深有体会，何况自己还是一个专业级码农，一个不折不扣的输入快手， 一个命令行、vim重度用户，对于按键输入速度有着较高的要求。\n对于OS X用户，其shell中存在较为严重的按键延时问题，我是在体验OS X的虚拟机的时 候发现这个问题的，之后就在Linux上对相应的设置进行了完善，输入体验有了较大提升 。建议朋友们优化一下相应的配置，相信会有更好的输入体验。\n4.2.系统常用工具 # 系统中包括了大量的工具，包括官方的以及第三方提供的，甚至有些个人提供的工具，能 够从众多的工具中遴选出那些高价值的、实用的工具，对于后续的高效工作是非常有利的 。在多年的Linux使用过程中，我将自己觉得非常好的工具介绍给大家，当然了这里的工 具可能不仅仅是一些软件包，也可能是系统中提供的一些不错的功能、组件等等。\n4.2.1.byobu、tmux、screen # 对于Linux而言，命令行是体现其强大之处的一个窗口。有些刚开始学习Linux的用户，很 难以理解为什么命令行这种极其不方便的操作方式会有比GUI更好的体验、效率。其实这 个问题很容易理解，一个命令通常可以灵活指定几个、多个、很多个选项，在GUI中能够 对其进行有效组织不是一项简单的工作，不是说不能，只是说可能会附带很多的工作量。\n举个简单的例子，以windows资源管理器为例吧。windows资源管理器看似已经非常强大了，在里面我们可以将文件以列表、图标等多种视图形式进行展示，并且支持复制、粘贴、 移动、搜索等操作。对于普通桌面用户而言，这个确实已经足够强大了。下面我试着题几 个功能需求，你们看看windows资源管理器是否能够做到。\n 列出最近1分钟内修改过的文件？   Linux下可以通过命令“find -mmin 1”来完成。\n  列出最近10分钟内访问过的文件？   Linux下可以通过命令“find -amin 10\u0026quot;来完成。\n  列出文件内容中包括“xxxx”字样的文件？   Linux下可以通过命令\u0026rsquo;find -iname \u0026ldquo;*\u0026rdquo; | grep \u0026ldquo;xxxx\u0026rdquo; | cut -d':' -f1 | sort | uniq\u0026rsquo;来完成。\n  列出所有的目录文件，或者列出所有的普通文件？   Linux下可以通过shell脚本来完成，如：\n#!/bin/bash\nfor f in find . -iname \u0026quot;*\u0026quot; do\nif [ -d $f ]; then echo $f; fi\ndone\n  显示出指定目录的树形结构，并可以指定深度？   Linux下可以通过命令”tree -L n“来完成。\n   ……\n  其他\n   用户的需求是灵活多样的，是变化的，GUI界面相对比较固定，正所谓众口难调，有的用户希望功能多点，哪怕界面看上去很复杂，但是有的用户却希望界面尽可能简单，仅仅保留刚需的功能就可以。\n 对于windows资源管理器而言，无法完成上述任务，实际上Linux中的某些类似的GUI工具 也难以完整地提供上述功能，而Linux命令行却可以通过某种形式的组合，来快速地满足 各种灵活多变的功能需求，GUI工具相比较之下，显得非常不灵活。这还只是谈到一个简 单的资源管理方面的工作，我们的工作实际上比这个要复杂很多很多，Linux中的命令行 可以通过不同程度地组合来满足解决复杂任务，但是要提供一个GUI来胜任所有的灵 活多变的任务，就太不现实了。\n上面提到了命令行的强大之处，相信大家能够对命令产生一点新的认识，对于重度Linux 用户来说，命令行是不可缺少的，一个不能够熟练使用命令行的用户，很难说他是一个水 平较高的用户，哪怕他有再长的使用经历也是白搭，时间并不能保证用户积累了充足的经 验和知识。重度Linux用户可能会开启很多的命令行窗口，并在不同的窗口中执行不同的 任务，但是如果能够通过一个程序对开启的多个命令行窗口进行更加有组织的管理，操作 起来就会更加方便，tmux、screen就是基于这样的目的诞生的。而byobu是建立在tmux或者screen之上的一个更加界面友好的工具程序，通过它可以更加方便的对打开的多个命令行窗口进行管理。byobu中的常用操作包括F2切换、F8重命名等等。\n4.2.2.lantern、switchomega+chrome、vpn # 在国内，有堵墙阻碍了我们正常上网，就是GFW嘛，不说你们也知道对不对，但是有些人 确实是不知道的，我刚上大学的时候就不知道。09年高中毕业之后，我买了自己的电脑， 才算是真正地用起了互联网。大一的时候，那个时候比较菜，很多计算机技术方面的问题 ，在百度上搜索一下基本就可以得到解决，但是后来慢慢地发现自己提出的问题，百度基 本上搜索不到正确的结果，而且也对百度的搜索质量越来越不满意。后面是一个同学介绍 我使用Google，也确实让自己受益匪浅。\n用Google，需要翻墙，翻墙的手段也是多种多样，翻墙工具更是五花八门。但是说来说去 ，把那些陈年废弃的老古董搬出来没有多大实用价值，当然了它们非常具有历史意义，对 于那些曾经奋斗在翻墙一线的前辈们我们应表示感谢。现在比较好用的翻墙工具，要么就 是直接用vpn，要么就是用开源的lantern。lantern支持Windows、Linux、OS X多种操作 系统，也支持Android手机，目前不支持iOS。感兴趣的话，可以直接从如下链接进行下载 ：https://github.com/getlantern。\n对于lantern的配置，在windows下面，只要运行lantern，IE浏览器、Chrome浏览器等就 会自动进入代理模式，在不同的Linux发行版中可能要进行不同的设置。Ubuntu 16.04 LTS中可以启动lantern后让浏览器自动进入代理模式；Fedora 21中在启动Lantern之后， Firefox浏览器自动进入代理模式，但是对于Chrome浏览器需要通过SwitchyOmega进行相应的代理设置，其实就是创建一个代理代理规则，即使用pac.profile来实现自动代理， pac.profile获取url为: http://localhost:16823/proxy_on.pac。造成这种问题的原因 可能是lantern设置页面没有勾选“管理系统代理”，可能也是lantern在不同系统上的”行为“差异。\nlantern提供了一个http代理端口8787（支持http、https协议），可以通过proxychains 进行设置，对其他http程序进行代理，也可以在其他使用http代理的软件提供代理服务， 例如android studio、eclipse、mendeley desktop等等。\n 写在2022年6月：再见lantern，lantern此时已经退出历史舞台很多年了 :(\n 4.2.3.vim+markdown、cherrytree、wiznote # 不管是在学习Linux的过程中，还是在其他学习过程中，都需要对相关知识进行收藏、整 理、总结，养成一个良好的记笔记的习惯是非常重要的，当然了，拥有一个跟得上思维的 记笔记的工具也是必不可少的，这类工具有很多，也看到很多朋友都选择了了自己的编辑 器。我本人也在长期的学习过程中试用了大量的记笔记工具，但是有的工具提供的功能并 不是我所需要的，或者没有我想要的功能，经过大量尝试之后，我也找到了适合我使用的 记笔记的工具，在这里也简单介绍一下。\n正所谓工具要趁手，趁手的意思也就是说，工具好不好，关键要看是否适合用户自己，因 此不太可能说，我喜欢的工具你也一定喜欢，或者一定能够满足你的需要，请辩证看待。\n vim+markdown  vim作为编辑器之神，已经赢得了很多人的青睐，特别是程序员，我也是程序员，我也喜 欢写东西，比如写总结、写博客、写体会等等吧，但是我讨厌把大量的时间花在排版上。 将vim与markdown结合起来可以说是一个非常好的选择。并且通过配合 vim-instant-markdown插件，可以实现在文字编辑过程中的实时预览。我非常喜欢现在的这种编辑体验。下图是我现在编辑状态下的一个截图。\n对于集成了markdown语法支持的编辑器，也有很多，但是由于我钟情于vim，即便有编辑 器集成了对vim操作方式的模拟，但是毕竟还是模拟，也不是一个完整的vim，编辑效率仍 然大大受限，所以我没有选择像markdown、atom这样的编辑工具。如果朋友们不喜欢vim，可以试用下atom。\n ps：2022年6月更新，我也是instant-markdown-d的贡献者。\n  cherrytree  cherrytree中可以通过树形结构对多个学习不同的学习内容进行阻止，例如为编程、内核 、算法单独创建一棵树进行管理，简单直观；\n树形结构可以任意扩展，支持多级子树的创建，灵活方便；\n编辑器中支持不同编程语言的语法高亮，而且能方便地调节代码窗口的大小，实用；\ncherrytree是我最常用的记笔记工具了，并且其文件支持加密操作，避免信息泄露，也可 以非常方便地将其加入github中，永不丢失，多好啊！\n ps: 2022.6更新，在我后面工作后逐渐将工作迁移到了mac设备下，主要原因是苹果生态下设备之间文件同步非常方便，但是cherrytree的作者表示自己没有mac设备，所以cherrytree短期内兼容mac是不大可能的。有点遗憾，我对mac下的图形化编程一知半解，不然还可以帮助贡献下。\n  wiznote  我们都经常上网，不管是用手机还是用电脑，很多时候，看到非常好的帖子，都是希望将 其收藏一下，收单到浏览器收藏夹或者某些app客户端里面，但是我们也常注意到这种情 况，有的帖子经过很长一段时间之后，不能正常访问了，可能是被删除了，也可能是被和 谐了，或者是被重新编辑过了，与之前相比发生了变化……我们当然是希望收藏的内容日后 查看的时候仍然与收藏时内容保持一致，当然更不希望进行收藏的网页日后居然无法访问 了，这岂不是很糟糕。\n为知笔记很好地解决了这一点，当我们收藏一个网页的时候，并不只是简单地保存一下网 页的链接，而是可以在本地中离线一份完整的网页，将内容保存起来。而且为知笔记还做 到了浏览器页面收藏、微信朋友圈文章收藏、公众号文章收藏，还能够将其他地方看到的 网页分享到为知笔记的公众号，只要分享了就自动保存。非常地方便！现在很多人都在使 用为知笔记了！\n现在为知笔记也可以支持markdown语法了，但是，编辑工作我还是希望使用vim来完成， 为知笔记更多时候被我用来收藏网页、朋友圈、公众号中的文章，过一段时间再对其进行 整理，收入cherrytree中。但是对于一般的笔记，我更强相遇使用vim+markdown来完成。\n ps：2022.6更新，为知笔记也是一个很不错的笔记，但是在我后续使用中遇到了同步错乱的问题，最后放弃使用类似云笔记的东西了，直接用简单靠谱的github来托管数据，用最好用的编辑器typora等来写文档。\n 4.2.4.gthumb、gimp、shotwell # 查看图片工具，gnome、unity里面最好的我认为要数gthumb了，在kde里面gthumb界面比较丑，但是其功能绝对是最强大的。gimp是类似于ps的图像处理工具，小巧也很使用。 shotwell是照片管理软件，平心而论软件做的是不错，但是使用的确实不多。\n4.2.5.virtualbox、vmware workstation # 虚拟机管理软件virtualbox在Linux下是非常赞的，vmware workstation也可以，但是 vmware workstation有些bug，我在Fedora 21上进行安装是遇到了问题，当然通过修改源代码，重新编译也成功进行安装了，但是有的问题还是无法解决。在Linux下面使用 virtualbox要更加省心一些，virtualbox已经做的非常出错了，支持的操作系统类型比 vmware workstation要多，而且性能方面也一点不输vmware workstation，对Linux支持的也比较好。\n在Linux下面，建议使用virtualbox，我现在安装了多个虚拟机，包括windows xp、 openSUSE 13、Mac OS X 10.7是用的非常好，当然其他的系统也都安装后测试过，上面提 到的三个要不同程度地用到。\n以前在windows下面的时候，我确实是用vmware workstation比较多，因为virtualbox在 windows下面跑起来真心慢的要命，vmware workstation要好很多，但是在Linux里面， virtualbox运行速度非常快，而且是自由软件，当然使用virtualbox了。\nvirtualbox提供的几种网络模式，也很简洁明了，nat、host only等模式，可以基本满足 的需要，我倾向于选择virtualbox。\n4.2.6.smplayer、clementine、mixxx、mpg123、openshot # Linux下面的视频播放软件，我认为最方便的应该是smplayer，跟vlc、dragon player、 totem、mpv等等比起来简直是神器，不仅功能多，而且操作也方便，某种程度上归功于其丰富的快捷键配置操作。\n音频播放器，我觉得clementine比较好，听音乐嘛，也不需要非常复杂的操作，界面简单 清爽就好了，clementine满足了我的需要，我不喜欢rhymbox、banshee等其他流行的音频播放器。喜欢dj、电子音等劲爆音乐的，可以使用下mixxx。mpg123是命令行下的一个非常简单的音频播放工具。\nopenshot是一个矢量视频编辑工具，其功能非常多，我经常用它来合成视频、剪辑视频、 视频转码等等，openshot工作过程中，因为计算量较大，cpu使用率较高。\n4.2.7.openssh-server、openssh-client # ssh，secure shell，这个是很有用的代替ftp、telnet的工具，在自己的电脑上搭建一个 sshd服务还是非常有必要的，说不定啥时候就需要从其他电脑链接到自己的电脑，比如 host与guest进行通信的时候，或者在本地搭建git服务器的时候……有很多场景都会用到。 当然了，更多的时候，我们是通过ssh去链接外面的某个主机。\n ps：因为网络的原因访问github不方便，所以我是搞了个二级的git托管，第一级是在本地电脑上开了个专门的账户git，这个账号home目录下用来托管git数据，但是这个账号禁止登录。然后白天我在图书馆或者网络不好的地方干活，就会从本地工作空间提交到这里来，等有网络了我再提交到github，其实有些我也没有提交到github。我主要是担心误删除rm -rf之类的不小心把仓库给删了，所以才搞个独立账号来充当git服务器。\n 总之，sshd、ssh是经常用到的工具，可以通过安装openssh-server将本地主机配置成 sshd服务器，安装openssh-client来获取相应的ssh等众多实用客户端工具。\n4.2.8.git、svn # 版本控制工具的两个代表是git和svn，其中svn是集中式的版本控制工具，而git是分布式 的版本控制工具。相比较而言，git比svn要优秀很多，当然其学习成本要高很多。\n建议学习一下《Pro Git》这本书，深入认识下git的工作原理，并在以后的的学习工作中 养成版本控制的意识，并切实将git应用起来。\n4.2.9.gnome-terminal、Konsole # 一个好用的终端模拟软件，绝对是非常重要的，比较好用的两个，kde下面使用konsole， ubuntu unity、gnome下面使用gnome-terminal。\n在里面可以对字体、颜色、输入指示器等等进行较为丰富的设置，一切为了效率。\n4.2.10.Ubuntu Unity、KDE、GNOME # 当前流行的三大桌面环境，是ubuntu unity、kde、gnome，任何一个Linux发行版都可以 对上述桌面环境进行整合，我对目前主流的桌面环境都使用过，上述三个使用的时间比较 长，根据我多年的使用体会，我自己更加倾向于选择kde和ubuntu unity。如果我使用的 是RHEL系列的，我就使用kde，如果我使用的是Ubuntu，那就使用ubuntu unity。gnome3实在不敢恭维，有很多人比较推崇gnome3，但是我确实不喜欢这种方式，自己感觉操作效率是上述三个中最差劲的。\n ubuntu unity  从使用ubuntu 12.04 lts开始，就开始使用ubuntu unity了，刚开始的时候确实觉得还不 错，但是永久了，就发现有些东西并不实用，我想回归精简了，仍旧是善变，并不就是人 家unity做的不好。后面你们猜我用上了什么，我用上gnome-shell-fallback，没错，我 觉得gnome2时候的界面真是清爽多了，为此，我后面还使用了相当长时间的rhel 6.5，直 到后面我用上了Fedora并开始使用kde作为主要的桌面环境。\n现在发现ubuntu unity确实做的不错，稳定性、速度等各方面都相当不错，所以我要先给 个赞！可以说之前一直都在折腾GUI方面的东西了，越折腾越心累，现在能够平心静气地 来对待这些问题了，自己也有实力对不合心意的地方进行修改了，改配置文件、改源代码 、替换必要的组件等等，随心所欲不逾矩！这种感觉还是非常爽的！当我看到有某个同学 在使用“丑陋”的Ubuntu时，心里面就有种不一样的感觉，很多新手不会配置却总是抱怨，Linux这么灵活，就是让你去探索的，不喜欢探索、折腾，自认为这是浪费时间的可以去买个Mac，不过说真的，Mac OS X的GUI就是一个gnome2的级别，操作效率渣的要命！\n ps：2022.6更新，现在mac使用了马上6年了，和我当年使用Linux发行版的时间差不多久了，说实话mac系统整体而言整合的比较好，但是要想提效，还是有很多东西要配置的，see 你的mac有哪些趁手的工具。\n 现在回头来看，我喜欢Ubuntu Unity哪些地方呢，没有特别推崇的地方，就是一种感觉， 优化的确实不错了，比以前强多了，而且操作起来确实也是很方便。\n kde  自从我使用Fedora 21以来，就一直使用kde作为桌面环境，kde4相当成熟、稳定，我很喜 欢，而且灵活性好，可以进行丰富的配置，这一点我非常喜欢，可以让其变得相当简约不 简单，也可以让其变得相当华丽而优雅。\n但是最新的Fedora里面增加了dnf，怎么说呢，我非常依赖yum，但是目前dnf还没有完全 实现某些功能，而且kde5里面很多地方还不完善。今年6月份才会出Fedora 24的GA版本， 我也等不了那么长时间了，于是提前体验了一下Alpha版本，发现kde5并没有达到我希望 的程度，dnf也没有实现我依赖的功能，所以我暂时先放弃了使用Fedora 24的年头，转而 投奔了Ubuntu，也没有继续采用kde桌面环境，而是使用了自带的unity。\n其实kde4是一个非常高效的桌面环境，简约的界面，丰富的快捷键，简直双到爆。\n gnome  gnome2比较简约，实用性比较好，但是对于追求高效操作的用户来讲，未免又显得过于寒 酸了些，值得一提的是，Mac OS X也就是相当于gnome2的级别，虽然苹果重新设计了很多东西，但是仍然就是这么个水平，操作鸡肋，难以满足我的需要。\ngnome3是比较高级了一点，但是有点哗众取宠，鄙人不喜欢，谁爱谁用，反正我是不用。其实gnome3很早之前就被无数人喷过了，比如Linus Torvalds。\n ps：2022.6更新，anyway，gnome3目前似乎称为了主流桌面环境，特别是服务器为中心的发行版。\n 4.2.11.workspaces、pager、activity #  虚拟桌面  Ubuntu Unity、GNOME里面使用的是workspaces的概念来表达多个虚拟桌面的意思，在KDE里面其实也是用的这个概念，但是它提供的工具却叫pager，表达的意思是一样的，都是表示的虚拟桌面的意思。\n虚拟桌面，其实就是在一个桌面上虚拟出多个桌面，例如一个笔记本就只有一个屏幕，只 能显示一个桌面啊，但是现在我虚拟出4个桌面，可以在其中进行切换。现在主流操作系 统windows、osx、linux中都提供了虚拟桌面支持。而linux中的几乎所有的桌面环境都支 持虚拟桌面。\n ps：2022.6更新，windows是从win10开始支持的吧，叫任务视图。osx下叫桌面1、桌面2……都是类似的东西。\n 虚拟桌面的作用是非常明显的，我们可以在不同的虚拟桌面中做不同的工作，这使得工作 更加井井有条、效率更高。\n 活动  KDE Plasma里面，提供了activity的概念，在同一个用户会话中，可以有多个不同的 activity，比如音乐activity、编程activity等，我们可以在当前会话中的不同activity 中进行切换，使得自己能够在不同的任务之间进行切换。\nactivity看起来也是非常有应用价值的，但是我任务比较明确，并且我认为在不同的任务 之间进行切换，并不需要付出较多的额外的工作，比如在游戏、工作、娱乐之间进行切换 ，我认为是一个很自然的过程，所以我几乎不使用activity。\n ps：2022.6更新，activity其实是在虚拟桌面上的能力升级，它允许你在不同的模式之间进行快速切换，其实这就是一种通过虚拟环境来实现任务隔离并保持专注的能力。\n现在智能手机中一般也会有类似的功能，比如工作、家庭两个不同的虚拟环境，当然了我们确实也可以通过多用户切换的方式来达到类似效果，但是activity可能要更优雅些，你可以复用这个用户下的应用、数据，只是在不同的高强度任务之间做个隔离，比如从工作状态一下子切到休闲模式，一键打开需要休闲的程序之类的。\n现在osx里面提出了一种捷径的软件，你可以自定义一些操作，通过捷径来做一些操作，但是初衷可能不一样，但可以模拟相同的功能。\n 4.2.12.自定义快捷键shortcuts # Ubuntu Unity、KDE Plasma中都提供了非常丰富的快捷键配置，非常棒！快捷键可以极大地提升操作效率。\n4.2.13.tracking mouse # 这个应该算是一个小小的技巧把，一般在animation effect中进行配置。有的时候，鼠标 颜色难免会难以与其所处的区域进行区分，移动一下鼠标还不容易发现鼠标的位置，怎么 办？开启tracking mouse效果之后，按一下快捷键，就可以发现鼠标的位置了。\n ps：2022.6更新，osx下拼命移动鼠标指针，鼠标指针会变大，也比较容易发现。\n 4.2.14.quick tile windows # 快速地将窗口移动到某一区域（上下左右以及屏幕4个角落）并且使其在该范围内最大化 ，是一个很常用的、有效的操作。很多时候，我们都是同时执行多项任务，并且希望能够 看到多个任务的执行情况，因此，该功能就非常有应用价值了。\nwindows环境中一般有quick tile to left\\right操作，Ubuntu Unity和KDE中一般支持上 下左右以及4个角落的quick tile操作，GNOME3中不清楚，GNOME2中倒是有quick tile to left\\right操作。\n ps：2022.6更新，osx下这点没有linux桌面环境支持的好，基本上要借助工具才能解决。我目前是使用hammerspoon+lua脚本的方式来对这些功能进行管理。hs的好处是提供了lua的接口，如果你能看懂文档，懂点变成，就可以写出自己想要的桌面管理软件来。感兴趣的话可以参考我写的：https://github.com/hitzhangjie/conf/tree/master/macOS-hammerspoon。\n 4.2.15.fcitx+sogou输入法 # 配置一个好用的输入法是至关重要的，特别是在需要中英文混输的情况下，能够快速地在 中英文之间进行切换，并能高效地输入中英文，对于提高输入效率、提高输入体验非常重 要。\n目前在Linux中，最主要的输入法框架主要是给予ibus或者fcitx，其他的都不是很流行。 ibus的话，添加中文输入法之后，可以增加搜狗输入法的词库，但是依然比较鸡肋；最好 的办法就是安装fcitx，然后安装搜狗输入法。\n在Ubuntu 12.04 LTS的时候，由于官方软件源中的fcitx版本较低，不能正常启动搜狗输 入法，因此需要手动添加第三方软件源对fcitx进行更新。现在的Ubuntu 16.04 LTS中 fcitx已经足够新了，直接从搜狗官网上下载deb包进行安装就可以了，比较省事。\n关于搜狗输入法的设置问题，搜狗输入法提供了专门的设置面板，可以修改皮肤、模糊音 等等，提高输入体验。对于输入法切换ctrl+space激活输入法，ctrl+shift在输入法之间 进行切换。\n与windows相比，这里的ctrl+shift在输入法之间进行切换有点差别。在windows中是在所 有的输入法之间进行切换，但是在fcitx中是将所有的输入法分成了两组：Active Group 和Inactive Group，当按下ctrl+shift之后，实际上是在当前group中进行切换，而不是 在所有的输入法之间进行切换。如果要想在所有的输入法之间进行切换，需要进行特别的 设置，如下图所示，勾选上“include inactive input methods when scrolling”。\n ps：2022.6更新，抱歉图片失效了，当初没注意是localhost的链接。\n Ubuntu 16.04 LTS里面有点奇葩，不知道为什么，在.xprofile里面增加export GTK_IM_MODULE=fcitx、export QT_IM_MODULE=fcitx、export XMODIFIERS=\u0026quot;@im=fcitx\u0026quot; 会导致fcitx无法启动。以前在Ubuntu 12.04 LTSu以及Fedora里面都是可以的啊，不晓得 这次是因为什么。wpp（wps里面的演示文稿）需要在启动脚本/usr/bin/wpp中增加上述环 境变量，才能正常输入中文。不然可能运行wpp创建新文件的时候可以输入中文，但是打 开一个已有的ppt文档时就不能够正常输入了。而且更加奇葩的是，wpp里面如果对某一页 演示文稿添加了备注，当切换到这一页的时候，会慢成狗。\n ps：2022.6更新，没想到搜狗被腾讯收购了，变成了一家人，不过现在又要裁员。\n 4.2.16.software-center vs gnome-software # 在ubuntu上面，现在有两款软件安装工具，一个是software-center，ubuntu专属的，另 一个是gnome-software，这个在运行gnome环境的系统上都可以安装，比如在fedora上也可以使用。\n但是gnome-software现在非常不稳定，安装、卸载过程中经常出错，而且对于一些软件组 件（不是一个大型的程序），这种软件包很可能在gnome-software安装列表中就不会出现 。但是ubuntu software-center就可以。怎么说呢，感觉gnome-software不如 software-center实用、健壮，把dpkg数据库搞崩溃了可不是什么好玩的事情。\n ps：使用Linux的一个最大感受就是，free software真香，绝大部分都是免费的，最主要的还是开放源代码，你可以修改啊，也可以学习。现在用了mac后只能从应用商店买，有时候还要找破解版的。鼓励支持正版软件，只是说在Linux下的时候真的感觉很自由、很放松。从社区中来，到社区中去，从社区中学习，也回馈到社区。给当年自由软件先驱们个赞！\n 4.2.17.DevHelp # 可以查看glibc的相关手册，极大帮助自己更加深入地学习C语言编程。我下面就要对 glibc中提供的一些特殊的高级数据类型进行学习，例如链表、树、图、map等等。glibc 参考手册如下所示。\n4.2.18.ctags、cscope # 看源代码的，当然了，自己写代码的时候也是用的到的。归根究底，还是要结合vim使用 ，在vim里面可以根据ctags生成的索引进行跳转，例如跳转到函数定义的位置，查看完成 之后再跳转回来。能实现这种功能的原因是ctags生成的索引信息，能够被vim正确解析， vim再执行相应的跳转操作，实现jump to和jump back操作。再将上述跳转操作绑定到其 他快捷键例如[[和]]上将可以极大地提高代码阅读的效率。\n ps：说实话感觉不是很好用。\n 4.2.19.lxr (linux cross reference) # 看源代码，开阔眼界的。lxr也是给予ctags建立索引信息，此外还能够给予swish-e或者 glimpse进行全文检索，因此在阅读代码时检索一个关键词、函数定义、宏定义等方面是 非常方便的。而且lxr支持点击一个函数调用时跳转到相应的函数定义的位置，相当于 jump to的功能，因为lxr是基于浏览器进行访问的，因此可以通过浏览器的历史执行回退 操作，返回到之前的函数调用页面，相当于jump back的操作。\n因为lxr是基于浏览器的、只读的源代码阅读工具，因此在阅读的时候，可以有效避免对 源代码的误修改操作，但是另一方面，我们也不能对源代码添加注释、修改等。\n选择ctags还是lxr关键还是看个人喜好了，我觉得看大型项目的源代码，如果只是本着学 习的目的进行一下阅读的话，那么用lxr好；如果有修改源代码并进行编译、测试等学习 任务的话，最好用ctags。再或者，直接使用某些其他的IDE也是个不错的选择。关键还是 看个人喜好。\n ps：2022.6更新，这个阅读大型项目源码非常赞，不过添加源码比较啰嗦。现在有了比较好的替代品，sourcegraph。之前学习java jdk的时候用的是在线的grepcode，前几年倒闭了。现在比较好的就是sourcegraph了。\n 4.2.20.其他 # 肯定还有一些很好的工具，不能一一列举，上面这些事用的比较多的。先分享这些把。\n5.哪里学习Linux # 首先得搞明白要学习linux哪方面？是linux桌面发行版的使用，还是linux系统管理，还是linux应用开发，还是linux内核开发的知识……幸好，有很多的社区邮件组、讨论组、问答社区可供我们学习。\nStackExchange \u0026amp; CodeProject \u0026amp; Sourceforge，是极好地学习计算机技术的地方，特别是这个StackExchange，它真的是包罗万象，而且里面的管理员很有水平，当你的问题描述不是很准确时，他们还会帮你润色。通常在上面都能得到大佬们的迅速且有效地解答。我自己是从中受益匪浅。\n学习开发的话，c/c++ primer、glibc学习（常用数据结构等支持很好）、gtk/qt/gnome开发（图形界面）、make、cmake的使用（项目构建）等等。\n在Linux下面感觉做什么都简单，你想想啊，全世界那么多服务器都是跑在Linux上的，基于Linux的开发包、经验分享肯定多如牛毛，就是一个字爽。\n"}),a.add({id:137,href:"/tags/ubuntu/",title:"ubuntu",description:"",content:""}),a.add({id:138,href:"/tags/emacs/",title:"emacs",description:"",content:""}),a.add({id:139,href:"/tags/vim/",title:"vim",description:"",content:""}),a.add({id:140,href:"/blog/2016-01-07-vim%E8%BF%9B%E9%98%B6%E7%AE%80%E6%98%93%E6%89%8B%E5%86%8C/",title:"vim使用进阶常用操作",description:"从开始接触Linux开始就开始接触vim，从刚开始地抵触到现在都离不开（这篇文章写在2016年1月，实际上补充到博客是在2022年6月），10年老用户发现日常的浏览器、IDE编辑器等等都改成了vim操作风格，为什么呢？vim的简约不简单的设计让它成为编辑器之神，一点都不为过，这里仅罗列些一些常见的操作吧，其实还有些常用功能，后续陆续补充或者写一个vim系列，以免一篇万字长文把vim新手吓到。不吹不黑，作为编辑器vim确实有它的过人之处。",content:"vim使用进阶常用操作 # 文件打开退出 #   open and edit files has several modes as following:\n vim filename: open this file vim +n filename: open file and position cursor at line n, `n is a number vim + filename: open this file and position your cursor at last line vim +/pattern filename: open file and position at the first match of pattern vim -r filename: open file and recover from swapfile, swapfile on big RAM is unnecessary, so we can disabled it vim -R filename: open file in mode read-only    providing you have edited the file,if you press:\n :q: to exit and you\u0026rsquo;ll be warned because you have edited file :q!: force to quit and won\u0026rsquo;t get warning message :w: to store the current modification into current file :wq: to store current modification into current file and quit :w fname: store current buffer content into another file fname,save as :ZZ: store current modification and quit    :{n}cq[!] : quit and returns an errcode n, default value of n is 1. you\u0026rsquo;ll need this when you want to abort a git rebase operation :)\n  内容插入内容 #  insert modes,if you press:  i:	insert at current position I:	insert at the beginning of current line a:	append after current position A: append at the end of line o:	insert a new line below current line O:	insert a new line above current line    在文件中移动 #   move your cursor in vim:\n j:	to next line k:	to previous line l:	to right h:	to left    go to specified line:\n \u0026lsquo;line number\u0026rsquo;+\u0026lsquo;G\u0026rsquo;    to the beginning of previous line\n shift +: to the beginning of next line 0:	to the beginning of current line $:	to the end of current line w:	to the beginning of next word,use \u0026lsquo;biaodianfuhao\u0026rsquo; as delimiter W:	like \u0026lsquo;w\u0026rsquo;, but use space as delimiter b:	to the beginning of previous word, \u0026lsquo;biaodianfuhao\u0026rsquo; as delimiter B: to the beginning of previous word, use space as delimiter e:	to the end of next word,\u0026lsquo;biaodianfuhao\u0026rsquo; E:	to the end of next word,space (:	to the beginning of current paragraph ):	to the end of current paragraph {:	to the beginning of previous paragraph }: to the end of next paragraph H:	to the beginning of current screen,not the file M:	to the middle of current screen,not the file L:	to the end of current screen,not the file G:	to the end of file gg:	to the beginning of file    move current line to top/center/bottom\n   z+enter: move current line to top of window z-: move current line to bottom of window zz: move current line to center of window  内容删除操作 #  delete content in vim:   x	:	delete character of current position X	:	delete left character of current position d1	:	like \u0026lsquo;x\u0026rsquo; d0	:	delete characters from the beginning of line to current position d$	:	delete characters from current position to end of line D	:	like \u0026rsquo;d$' d^	:	like \u0026lsquo;d0\u0026rsquo; but characters to delete doesn\u0026rsquo;t include space and tab dw	:	delete chars from current pos to end of word d5w	:	delete chars from current pos to end of next 5 words dtc	:	delete chars from current pos to next \u0026lsquo;c\u0026rsquo; (\u0026lsquo;c\u0026rsquo; not included) dfc	: delete chars from current pos to next \u0026lsquo;c\u0026rsquo; (\u0026lsquo;c\u0026rsquo; included) d/word	:	delete chars from current pos to the first match of \u0026lsquo;word\u0026rsquo; d3{	:	delete from previous 3 paragraphs to current pos d{	:	delete from beginning of current paragraph to current pos db	:	delete from beginning of current to current pos dW	:	delete from current pos to end of word,use \u0026lsquo;space\u0026rsquo; as delimiter dB	:	delete from beginning of current word to current pos,\u0026lsquo;space\u0026rsquo; d5B	:	from previous 5 words to current pos d)	:	from current pos to the end of current line d4)	:	from current pos to the end of next 5 lines d}	:	from current pos to the end of current paragraph d4}	:	from current pos to the end of next 4 paragraphs dd	: delete current line 3dd	:	delete 3 lines from current line dL	: delete from current pos to end of current screen dH	:	delete from beginning of current screen to current pos  读写外部文件 #   read file\u0026rsquo;s content into buffer: :[address] r [filename] read content of \u0026lsquo;filename\u0026rsquo;,then insert the content into the \u0026lsquo;address\u0026rsquo; position of buffer. if address is 0,then insert content into the beginning of buffer. if address is 100,then insert content after line number 100. if address is default,then insert content after current cursor position.\n  write buffer content into file on disk :[address] w [!] [filename] because it is rarely used,we neglect it.we usually use command \u0026lsquo;w\u0026rsquo; to store.\n  文件内容搜索 #   search string /pattern : press / then input the pattern to search\n  search string1 and substitute by string2 :[g] [address] s /searchString/substitueString [/option] usually,we use the command as following format: %s /string1/string2/g\nhere is an example:\n%s /string1/string2 /g || | | | ab c d e  a: we can search string1 in all lines in current buffer b: substitue commmand c: the string we want to search d: use string2 to replace string1 e: /g allows us to substitue every match in the same line.if we neglected \u0026lsquo;/g\u0026rsquo; option,and if multiple matches of string1 occurs,we can only substitue the first match.\n  advanced search and substitute by regexp\nProviding there\u0026rsquo;re many strings monitor_\u0026ldquo;desc\u0026rdquo; in code, we want to replace it with cmd_\u0026ldquo;desc\u0026rdquo;_succ，in which the string $desc is composed of characters like abc……xyz. So how to do that? In vim command mode, we can press: :%s/monitor_\\([a-z]\\{1,}\\)/cmd_\\1_succ。Here [a-z]{1,+} is used to match $desc，the outerscope () is used to capture the first matched group, （notice we do some escaping by \\{1,+}），the group \\1 will let us reuse the first captured group (that is $desc) . In vim, the captured group number is numbered by the order ( appears。 If you think the escape logic is complex, then we can use vim magic or very magic search mode, set magic, then we can use :%s/\\v/monitor_([a-z]{1,})/cmd_\\1_succ instead. Please refer to help magic to read more.\n  分屏切换操作 #   split the vim window:\n horizontally split, :split or :split filename vertically split, :vsplit or :vsplit filename    change window focus in vim: ctrl+w+w\n  ​	we can also use shortcuts to change focus but it\u0026rsquo;s inconvenient,so neglect it.\n​	but we can define key maps to use ctrl+hjkl to move between vim buffers.\nclose windows in vim: providing there\u0026rsquo;re several windows splitted existing:  :q :	to close current window :qall	:	to close all windows :only	: to close the other windows    执行shell操作 #   start a shell in vim: :sh this is the first method to execute shell commands in vim. after you start a shell and execute all commands,you can press \u0026lsquo;exit\u0026rsquo; to quit and go back to vim.\n  execute shell cmd this is another method to execute shell commands. by this method,you can execute only one shell command.\n  ​	suggest we use the first method.\n execute shell cmd and insert the result into buffer\n  :.!command if we\u0026rsquo;re in last line mode,we can use \u0026lsquo;.!command\u0026rsquo; instead of \u0026lsquo;!command\u0026rsquo;,like \u0026lsquo;.!ls -al\u0026rsquo;.\n  :!!command if we\u0026rsquo;re in command mode,we can use \u0026lsquo;!!command\u0026rsquo; instead of \u0026lsquo;command\u0026rsquo;. please note,when we type \u0026lsquo;!!command\u0026rsquo;, actually it is \u0026lsquo;.!command\u0026rsquo;.\n    标记跳转操作 #   marks\n ma : create a mark \u0026lsquo;a\u0026rsquo; at current position \u0026lsquo;a : jump to mark \u0026lsquo;a\u0026rsquo; mb : create a mark \u0026lsquo;b\u0026rsquo; at current position \u0026lsquo;b : jump to mark \u0026lsquo;b\u0026rsquo; ma : following mark created with the same name will override the ones create before    视图类操作 #  mkview/loadview we can create a view for current session, like we can fold/unfold some codes, the state will be saved in the view, which is saved under ~/.vim/views/. even we save/quit, later we reopen the same file, the view created before will be loaded automatically. It\u0026rsquo;s convienient if you\u0026rsquo;re writing some code specially the project is big.  tags搜索跳转 #   ctags/etags we can generate tags for your file content, no matter it is normal text file or source code, it just generate tags for your files, then we can search by tags to quickly find the position where it is defined, then we can jump there.\nwhen generating tags, we need install binary tool like ctags/etags, run ctags -R . is OK for most cases, it will generate tags in your current folder for all files recursively.\n  tags search\nby default, it will search tags file under current directory or the same directory which your editing file resides. sometimes we want vim to search other directories, for example, we write linux programs and we need some linux system headers, we want to jump to the system headers by looking up the tags.\nthen we need to generate tags file for system headers, and we should let vim to search through it. we should add the path to that tags file into vim tags search paths.\nset tags=./tags;tags/;~，it first find tags file in the same directory which the editing file resides, if not found, then it keep searching in current working directory; if not found it searched the user homedir. if still not found, it stopped.\nwe can add system headers path into the search paths.\nPlease read more abount vim tags by :help tags.\n其他 #   you can read my .vimrc to learn more about vim settings:\n  plugins\n plugin manager like vundle autocomplete minibuffers guidelines code snippets syntastic file tree comments vim editor statusbar, like vim-airline vim markdown renderer, like vim-instant-markdown vim markdown toc generator file encoding fix    encoding\n encoding/fileencoding/termencoding    backspace/delete\n  line wrapping\n  autoread file when file outer changed\n  key mappings\n  highlight search, cursorline, cursorcolumn, foreground, background\n  autowrap for specified types\n  split window and move btw them\n  syntax highlight\n  colors theme\n  format paragraph\n  tab and spaces\n  fold and unfold, autofold text block\n  insert text effiently, like time, heading, horziontal\n  create helpfile and generate tags for them, jump btw files by tags\n  settings for coding, like vim-go, etc\n  etc.\n  总结 # vim被IT界赞誉为编辑器之神，与emacs这个被称为神之编辑器的都有很多支持者。\n我是vim的支持者，我喜欢能用一个按键搞定的就不用同时按组合键。有人会质疑，这么多的按键你记得住吗？不是在装x吧？\n真不是，vim优秀的地方，一个是奉行极简主义，这个很符合我的习惯或者说性格；再就是它有非常强大的定制功能，你可以把自己想要的配置以dotfiles的形式维护起来，就像我一样，换个地方换个机器把配置拖下来，就可以用起来。\n前期虽然学习成本高，一旦上手很容易爱不释手，萝卜青菜各有所爱 :) 当时是怎么决定要修炼vim的呢？是为了装x看能不能在完全脱离鼠标的情况下对计算机进行各种操作，比如通过命令、配置等等，虽然初衷不纯，但是最后还是上车了 :)\n"}),a.add({id:141,href:"/blog/2022-05-08-%E5%86%99%E5%9C%A8%E6%AF%8D%E4%BA%B2%E8%8A%82/",title:"写在2022.5.8母亲节：无题",description:"今天是母亲节，在这个特殊的日子，默默地写点东西表达下对妈妈、老婆的感谢，写着写着就跑偏了，都感谢下吧，希望今年一切顺利。",content:" img { width: 680px; padding-bottom: 1rem; }  写在前面\n过去很多个时间节点，本来应该写下点什么，好让它显得更丰满些、有仪式感些，显得自己没有虚度这段时光。这样那样的原因，一次次作罢。今天有点手指酸疼，也不是很想去写的，但我担心错过这个特殊的日子，以后找不到这样的好时机来倾诉这些沉积很久的想法，所以还是矫情一回吧。\n竟也用上了“无题”做题目，可能是因为多重角色的变化，萦绕在心头的思绪更多了些、复杂了些吧，不过本文也确实没预设主题。\n感恩老婆：你的第一个母亲节\n对农历我总是搞不清楚，即便偶尔发现个特殊的节气、节日也是无意中听说，由于从小过生日都是按照农历，所以我的生日也基本是父母、姨妈、姥姥他们提及的时候我才会知道，哦，生日那天可以加餐意思下。\n也经常有这样的文章，孩子生日那天，却也是母亲最痛的那天，孩子也应该在生日那天表达下对母亲的感恩。也明白这个道理，但是却没法感同身受。\n宝贝闺女出生，我从深圳赶到武汉后，只能在产房外等待，没能陪伴在老婆旁边，也没感受到她有多撕心裂肺的疼痛，当我怀揣着惊喜去看她娘俩时，看到老婆脸色那么憔悴，加上晚上陪床时临近产房的年轻妈妈疼的直喊，我也看到了医护清理出来的胎盘……一下子内心揪了一下，生个娃做母亲的真的太不容易了。\n联想到老婆产前从体型微胖到长个大肚子行动不便，产后的各种恢复，带娃的辛苦，在我这个“奋斗B”在深圳几乎缺席了一切相关事项的情况下，老婆几乎自己一个人扛下了所有劳累和委屈。\n感谢老婆，送给我一个小天使，感谢老婆的辛苦付出，今天也是你的第一个节日。虽然小宝贝还不会叫妈妈，但现在已经知道了去找妈妈，以后她也会慢慢变成你的跟屁虫，母亲节也会给你送来束康乃馨，就先憧憬下吧。\n感恩母亲：今天才体会到那份不易\n如果没有亲自看到老婆经历的那些不易，我可能永远也不会感受到做母亲的那份不易，而且是在30年前那样的生活、医疗条件下。\n从我记事起，妈妈就是我心灵的港湾，省吃俭用，给我做好吃的，给我做衣服，做鞋子，教我识拼音、写字、算术，刚去上学时该会的也都会差不多了。那时候，家里条件也不好，爸爸妈妈辛辛苦苦地劳动，家里再难的时候，也不让我因此而受伤分毫。\n念了那么多年书，终于毕业了，我急不可耐地要去试试，可是爸爸却先走了，那段时间虽然妈妈和我来了深圳，但是我能感受到，她很压抑，早出晚归的儿子、不熟悉的环境、不熟悉的网络购物、不熟悉的医院就诊流程，等等。我开始想，有可能妈妈是为了维护儿子在他人眼中的孝心选择性地放弃了熟悉的家、人、环境，难为妈妈了。\n老婆怀孕后，妈妈也尽己所能赶来照顾，人生地不熟的武汉，我也担心这婆媳矛盾会不会也让我束手无策，不过妈妈和老婆都是通情达理之人，也没出现过矛盾，真的很让人欣慰，但这背后她们也各自牺牲了很多。\n母亲节快乐，再过些天，你也会多个跟屁虫，被喊“奶奶”也很开心吧。\n感谢警察：对我的批评教育\n爸爸刚走那一两年，我常觉得这个没有他的世界几乎不可接受。爸爸身上那种正直、坚毅、豁达的品质，在家族中也比较受长辈同辈小辈的信任。我虽本性不坏，但是做的就没爸爸好，原本打算多跟爸爸聊聊，让自己做的更好。可谁能想到，我的良师益友就这么走了。\n那段时间眼里容不得沙子了，几乎自我封闭了和其他人的接触和交流。工作上也因此或多或少遇到些不快，这段时间也没少和老婆、妈妈抱怨。\n有段时间我也经常看些“针砭时弊”的内容，好的坏的、对的错的，我只相信自己的眼睛、思考，唠叨个不停，老婆也听的烦，妈妈再听估计也听出了老茧。后面我发现也改变不了她们，她们也不关心这些，我就更郁闷了。当我看Youtube一些相关内容时，老婆就会主动播放金灿荣等人的视频。\n深圳的快节奏也是出了名的，当你双脚落地深圳开始，你就开始走路带风了。大多数年轻人都脚步如飞，他们也很拼，惜时如金。有时是城市规划的问题，有时是平台调度策略的问题，有时是人自己的问题，谁都想快一点，你快就需要有人配合你慢一点，不然就容易出冲突。\n总有些漠视规则的人会来挑动你的神经，差点割喉的电动车遮阳棚、看手机频繁踩你脚后跟的行人、斑马线和行人抢路的司机、和行人抢路闯红灯的外卖小哥、不避让自行车的司机，等等。\n这些因素叠加到一起，最终让我变成一个火药桶。终于后面发生了一次冲突，调节中，一个差不多爸爸这个年纪的警察，和我聊了聊，“你就说大哥你厉害”，“你可以骂他吐口水”，“他不对在先，但你犯不着把他……”，“年轻人年轻气盛可以理解”，“不值得”，道理是很简单的道理……但是我有多久没有听到来自长辈的“疏导”了。我忽然感觉到豁然开朗，前所未有的轻松，感谢深圳警察的批评教育，让我以一个小错误及时“迷途知返”。\n去年年底，对一家假冒的苹果售后服务中心的维权过程，算是我把警察的话听进去了，这个社会上有很多资源能协助你惩罚犯错误的人，只要你利用好它们，没必要剑走偏锋。\n感谢亲朋：谢谢你们一直在\n工作后也没什么机会和亲朋常聚聚，再加上这几年疫情防控，机会就更少了，21年底因为小宝宝太小也没有回老家。20年底办婚礼的时候，那个时候在婚礼现场心血来潮拍照怎么能少的了和发小、朋友们呢？拍了几张合照。\n不过没几天老婆就有喜了，后面就忙着各种相关的事情，竟然忘记了把这些照片给导出来。过些天抽个周末，把这些照片整理一下，给家人朋友们发一下。\n感谢你们一直在，虽然也常常很久不联系。虽然我们身处不同的城市，做着不同的工作，每天操心着不同的话题，但是总有些东西是我们共同关注的，比如生活、带娃。\n时间、空间，会让人与人产生距离感，像山东、深圳距离1700公里，也不过是2小时的距离，友谊之上的时空距离，我认为只是一句微信“嘿，在吗”的距离。\n感谢伤疤：认识并爱惜身体\n这个世界离了谁都会转，哪怕人类灭绝，几百亿年后也可能诞生其他物种，所以，这个世界不是为谁而存在，我们才是这个世界的游客。当我们在旅途中遇到些不快，也尽量怀揣着乐观的心态去观察它吧。\n“伤疤，是美好生活的刺青”，20年吧，骑着自行车重重从车把前摔了出去（车轮卡在砖缝里），晚上太黑来不及反应，手掌被擦掉3~4平方厘米左右的皮，火辣辣地疼，一只手骑到小区门口发了这条朋友圈， “Scars are just tattoos of better stories”。\n因为我坚持骑行十几年，这是我喜欢的事情，所以在因它而受伤后才会这么乐观，如果是工作生活上的糟糕的其他事，我可能就没这么好心情了。\n21年，因为意外伤到了一只手指，住院。病房里有位大哥类似的伤，因为想省钱选择截去了手指。我的费用，报销前总计1w多，报销完后2600。这个社会并不是那么其乐融融的，有很多群体收入并不高，在出现身体上的问题时，还是会有些人迫于经济压力被动地、无奈地放弃。这件事对我触动还是很大，我也开始关注治疗的局限性，有些东西能修但修不彻底。\n以前我听过两种不同的声音，“留得青山在，不怕没柴烧”，“为了革命，你还怕流血牺牲吗”。很明显，断章取义只会曲解我们的认识。\n我想说的是，任何时候我们选择爱惜自己的身体，都不能算作是错误。从自己这个个体而言，这个世界上除了你甘愿为之献身的目标以外，几乎不存在任何比你的身体更有价值、高级的东西。\n21年读了一本书《人体的秘密》，我很喜欢里面一段话，和大家分享下，大意是说：“就在我们迷茫、不知所措的当下，你的身体里无数的细胞、各种组织、器官正在为你的正常运行以最大地效率工作……”。闭上眼睛体会下，就在我们不知所措的当下，有无数的细胞正在为我们拼命地运转。人体、生命，是多么奇妙啊！事实上，除去健康人体中的“精神”，单看组建人体的化学元素，造价就要上百万元（或者百万美元），更不用说这些物质组件起来的复杂的组织、器官了，而且还没有考虑人类最伟大的“大脑的思维”。\n身体有些东西，坏了就是修不好的，比如伤疤、牙齿、脱发、肌腱，等等这些显而易见的。更值得深思的是，我们挣得的收入，并不一定够用来垫付身体损害的修复费用。\n希望大家能坚持查体，多关注身体异常，用正确的方法爱惜自己的身体总没有错的，除非你愿意为之做出牺牲。\n拥抱多元：不同正是存在的价值\n慢慢地发现很多人对很多事务的看法都是不同的，我们常以这句话自驱，“君子和而不同，小人同而不合”，说直白点，不同才是我们存在的价值，我思故我在，尽管我的认知不一定全面、正确，但是我相信一定有比我更聪明、有见识的人，只要他能把我反映的因素考虑进去，在更高层次的抽象、设计层面予以解决掉，那这就是有价值的。\n因为做计算机相关工作的原因，我加入了一些Slack群组、Twitter关注了一些比较牛的技术人员，几年之后，我可以很舒心的说，showoff一下没事，这很正常。\n以前我的QQ空间、朋友圈、微博夹杂着各种技术文章，后来我看大家都不怎么发，那算了吧，我感觉我也打扰到大家了，就不发了吧。遗憾的是，我认为这是一种圈子里的交流。我们真的要对好友列表打上各种标签，发条朋友圈之前斟酌一番吗？\n我关注的这些大佬还都挺平易近人的，他们也会晒娃，晒codesnippet，晒自己新买的宝马，晒自己刚还完房贷，晒自己书写到哪里了，晒自己敲键盘手速有多快（有次跟大佬pk过，略逊一筹），晒自己接下来要去哪里分享，晒今天和女友的约会很开心…这样的生活多简单！\n另外，近几年出现了不少App想打破熟人社交的模式，soul等等的，主要原因还是一些现实原因导致上述问题似乎无法不好解决，年轻人甚至也包括一些像我这样的“老人”也开始去尝试一些打破熟人社交的方式，showoff是多么重要，目的还是为了给社交注入一些有活力的元素，才更有可玩性。\n人，真的没必要把自己隐藏起来，我还是希望我的朋友圈里面能有些晒这个晒那个的，虽然我不一定看的懂，但如果你能炫一下，那对我而言应该也确实开拓了下眼界。也不用担心自己的意见是否不同，是否会被赞同，如果你抱着更加积极开放的心态去互动，也会不断修正自己的观点。\n现实中，有很多人不分享，有的是担心被认为是炫耀，但是他明明只是为了分享体验，如果后续XR技术的加成，一位身处德国骑着s1000rr的骑友可以让处于禁摩地带的我感受一波300km/h的癫狂速度，那你说我会以为他在炫耀他有跑车吗？不会。\n技术，归根结底还是服务于人类的现实生活，只不过它可能通过了虚拟的途径，这里的“虚拟”也只是一种媒介而已，又有什么区别呢？我和异国他乡的朋友通电话，他听到的声音也是虚拟的，并不是我的声音340m/s传播过去的，可这又有什么关系呢？\n虚拟，并不是为了把大家架设在虚拟中，恰恰它是建立在现实基础上的进一步抽象，通过它可以丰富我们连接的媒介。比如深圳夜晚加班的我可以触摸到武汉婴儿床上的宝贝，感受到她q弹的皮肤、宁静的喘息声。\n现在元宇宙概念火热，如果你联想不到更多的场景，不要急，不妨让子弹再飞一会儿，也许那时候会有还不错的场景落地实现。\n收尾吧\n好像说了很多，这大致就是我近段时间的想法，感谢老婆、感谢母亲、感谢亲朋、感谢警察同志、拥抱不同的声音。2022变化颇多，做当下最正确的决定吧，剩下的交给运气，相信大家运气都不会太差。\n"}),a.add({id:142,href:"/tags/%E6%AF%8D%E4%BA%B2%E8%8A%82/",title:"母亲节",description:"",content:""}),a.add({id:143,href:"/tags/%E7%88%B6%E4%BA%B2%E8%8A%82/",title:"父亲节",description:"",content:""}),a.add({id:144,href:"/tags/ha/",title:"HA",description:"",content:""}),a.add({id:145,href:"/tags/sla/",title:"SLA",description:"",content:""}),a.add({id:146,href:"/blog/2022-06-21-%E5%AE%9E%E8%B7%B5%E4%B8%AD%E9%AB%98%E5%8F%AF%E7%94%A8%E5%A6%82%E4%BD%95%E5%81%9A/",title:"实践中高可用如何做",description:"大家经常提及高可用，但是什么情况下要去考虑高可用，哪些服务应该做高可用，有状态、无状态服务实现高可用的方法又有什么不同？本文对此做了一些思考，也提供了一些比较常用的低成本的解决思路。",content:"高可用 # 提升服务可用性当然是一件好事，但是实现高可用也是有成本的。提升可用性的常用做法是通过靠设备冗余来实现，当然还有其他的办法，但是不管是哪种办法，做这些工作是有成本的。实践中，一般要权衡投入产出比，来决定需不需要做HA，做的话对哪些服务做HA。\n提升可用性的手段 # 所谓高可用，可以从以下几个方面来考虑：\n 进程内模块的开闭（特性开关）：对异常代码分支进行打开、关闭控制，有问题时可以关闭 特定用户的影响：特定用户本地数据问题可能触发某种异常，可以暂时对用户屏蔽特定逻辑 子系统级的影响：大系统小做，轻重分离，将关键服务和一般服务拆分开，避免互相影响 进程级的影响：多进程模型，避免单个进程挂掉产生影响，常用的共享内存队列+多进程 节点级的影响：单个节点挂掉，可以通过冗余、屏蔽故障节点的方式来解决，主备、集群等 组件级的影响：对组件的性能边界要有清晰的认识 大流量冲击：消息队列削峰 地震火灾导致的区域性故障：部署时考虑跨机房、跨区域部署，异地多活 等等  有状态、无状态服务 # 服务也分为有状态服务、无状态服务，对这两种情景的处理方式一般也不同的。\n 无状态服务，一般通过屏蔽故障节点、负载均衡的方式来解决即可； 有状态服务，则相对更复杂一些。总而言之节点级的可用性的提升，一般要借助设备冗余来实现，但是对游戏业务而言，这个成本会比较高。而且有些游戏后台服务是有状态服务，对这类服务做HA会明显增加整体方案的复杂度（比如主备方案，或者分片+副本的集群方案），而且设备成本也会增加很多。设备成本过高，还不如让玩家重开一局。  游戏业务的特点和普通的业务可能不太一样，其战斗服务器一般都是有状态服务，所以主流无状态服务采用的HA方案、主备或者集群方案，不一定总适用于游戏场景的，因为考虑到机器挂掉后恢复的收益，这个实现成本、方案复杂度就太高了。\n游戏业务中对有状态服务的HA一般这样做，可能会通过：\n 分区分服 分set 多进程 大系统小做+轻重分离 特性开关 用户数据异常屏蔽 等等  通过这些方式的来降低问题影响面，也算是提升可用性的办法吧。\n"}),a.add({id:147,href:"/tags/%E6%97%A0%E7%8A%B6%E6%80%81/",title:"无状态",description:"",content:""}),a.add({id:148,href:"/tags/%E6%9C%89%E7%8A%B6%E6%80%81/",title:"有状态",description:"",content:""}),a.add({id:149,href:"/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/",title:"高可用",description:"",content:""}),a.add({id:150,href:"/tags/algorithm/",title:"algorithm",description:"",content:""}),a.add({id:151,href:"/tags/data-structure/",title:"data structure",description:"",content:""}),a.add({id:152,href:"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/",title:"数据结构与算法",description:"",content:""}),a.add({id:153,href:"/blog/2022-05-24-%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/",title:"浅谈数据结构与算法",description:"本科学数据结构与算法时，自己也比较注意理论实践想结合，对课本上讲授的内容也算是掌握的比较好，到考研复习时甚至能直接拿出草稿纸把课本中所有线性表、树、图等相关的算法直接给手写出来，至今我还保留着当时的一份草稿 :)\n数据结构与算法是比较重要的，当对计算性能、存储空间提出明确要求时，就需要考虑计算复杂度、空间复杂度的问题，只不过实际工作中要求没有那么高，大家也没有那么重视而已。但是当涉及到一些复用范围比较广的代码，一般都会做benchmark来验证其是否ok。\n如果一个同学脑海里有成体系的数据结构与算法的训练，在设计方案时也会同时考虑几种方案并平衡各自优缺点，这其实就是一个非常好的工程素养。当然了数据结构与算法的训练，也会逐渐培养大家一种能力，就是化繁为简、把特殊问题一般化，这种能力在编码、设计解决方案时也会具备更好的维护性。\n我自认为自己具备这种能力了，但是实际情况是，在我接触了分布式领域的相关知识后，我发现数据结构与算法真的是博大精深，数据结构可以小到一个数组，也可以大到一个B+树，而对他们的运用更能彰显掌握的精炼程度，数组记录的可能是一系列普通数值，也可能是一个分布式领域冲突检测的时钟向量。\n在数据结构与算法的课本上，可能接触不到这么广泛的领域，某种程度上会让人觉得课本知识有点死板、枯燥，不知道前Google工程师王争的极客时间课程《数据结构与算法》之美，是否会有另一番味道？另外，自己从未参加过ACM竞赛之类的，也看过一些参与竞赛的同学的分享、编程模板，内容覆盖面之广也让我汗颜，自觉能力不能及。\n所以我准备试读下王争的课程《数据结构与算法》，go go go。",content:"本科学数据结构与算法时，自己也比较注意理论实践想结合，对课本上讲授的内容也算是掌握的比较好，到考研复习时甚至能直接拿出草稿纸把课本中所有线性表、树、图等相关的算法直接给手写出来，至今我还保留着当时的一份草稿 :)\n数据结构与算法是比较重要的，当对计算性能、存储空间提出明确要求时，就需要考虑计算复杂度、空间复杂度的问题，只不过实际工作中要求没有那么高，大家也没有那么重视而已。但是当涉及到一些复用范围比较广的代码，一般都会做benchmark来验证其是否ok。\n如果一个同学脑海里有成体系的数据结构与算法的训练，在设计方案时也会同时考虑几种方案并平衡各自优缺点，这其实就是一个非常好的工程素养。当然了数据结构与算法的训练，也会逐渐培养大家一种能力，就是化繁为简、把特殊问题一般化，这种能力在编码、设计解决方案时也会具备更好的维护性。\n我自认为自己具备这种能力了，但是实际情况是，在我接触了分布式领域的相关知识后，我发现数据结构与算法真的是博大精深，数据结构可以小到一个数组，也可以大到一个B+树，而对他们的运用更能彰显掌握的精炼程度，数组记录的可能是一系列普通数值，也可能是一个分布式领域冲突检测的时钟向量。\n在数据结构与算法的课本上，可能接触不到这么广泛的领域，某种程度上会让人觉得课本知识有点死板、枯燥，不知道前Google工程师王争的极客时间课程《数据结构与算法》之美，是否会有另一番味道？另外，自己从未参加过ACM竞赛之类的，也看过一些参与竞赛的同学的分享、编程模板，内容覆盖面之广也让我汗颜，自觉能力不能及。\n所以我准备试读下王争的课程《数据结构与算法》，go go go。\n"}),a.add({id:154,href:"/tags/pattern/",title:"pattern",description:"",content:""}),a.add({id:155,href:"/blog/2022-04-24-understanding-design-patterns/",title:"Understanding the Design Patterns",description:"The design patterns is a blueprint about how to solve a commonly-reoccuring prolem in specific occasions.According to scale and complexity, the patterns could be categorized as Architecture Patterns, Design Patterns and Idioms.",content:"The design patterns is a blueprint about how to solve a commonly-reoccuring prolem in specific occasions.According to scale and complexity, the patterns could be categorized as Architecture Patterns, Design Patterns and Idioms.\nIntroduction # go-patterns actually is short for design patterns in go, which shows list of demos behind the concepts.\nWe must think about the following questions before we dive into the demos, it is really important.\n What\u0026rsquo;s a pattern? What\u0026rsquo;s a design pattern? History of patterns? Why should I learn patterns? Criticism of patterns? Classification of patterns? etc.  What\u0026rsquo;s a pattern? # Pattern is a solution, which works well in practices, to a commonly reoccurring problems. Patterns could be created and shared in every area, like building body, improving representation skills, architecture skills, or software design.\nI\u0026rsquo;m a developer, when I talk about patterns, I mean the software design pattern. Learning patterns can help us build software on the collective experience of skilled software engineers. Then when we work on a particular problem, we could recall a similar problem which had already been solved and reuse the essense of its solution to solve this new problem. That\u0026rsquo;s 举一反三 in Chinese.\nWith the help of patterns, novices will work better as if they were (or almost as if they were) experts on modest-sized projects, without having to gain many years of experience.\nWhat makes a pattern? # A pattern for software architecture describes a particular recurring design problem that arises in specific design contexts, and presents a well-proven generic scheme for its solution. The solution scheme is specified by describing its consitituent components, their responsibilities and relationships, and the ways in which they collaborate.\nSee: Pattern-Oriented Software Architecture, Volume 1, Page 8~11.\n Context: a situation giving rise to a problem. Problem: the recurring problem arising in that context. Solution: a proven resolution of the problem.  Pattern Categories # In software design area, patterns could be split into different layers.\nA closer look at existing patterns reveals that they cover various ranges of scale and abstraction.\n Some patterns help in structuring a software system into subsystems. Other patterns support the refinement of subsystems and components, or of the relationships between them. Further patterns help in implementing particular design aspects in a specific programming language.  Patterns also range from domain-independent ones, such as those for decoupling interacting components, to patterns addressing domain-specific aspects such as transaction policies in business applications, or call routing in telecommunication.\nTo refine our classification, we group patterns into three categories:\n  Architecture Patterns\nViable software architectures are built according to some overall structuring principle. We describe these principles with architectural patterns.\n A architectural pattern expresses a fundamental structural organization schema for software systems. It provides a set of predefined subsystems, specifies their responsibilities, and includes rules and guidelines for organizing the relationships between them.\n Architectural patterns are templates for concrete software architectures. They specify the system-wide structual properties of an application, and have an impact on the architecture of its subsystems. The selection of an architecture pattern is therefore a fundamental design decision when developing a software system.\n  Design Patterns The subsystems of a software architecture, as well as the relationships between them, usually consist of several smaller architectural units. We describe these using design patterns.\n A design pattern provides a scheme for refining the subsystems or components of a software system, or the relationships between them. It describes a commonly-recurring structure of communicating components that solves a general design problem within a particular context.\n Design patterns are medium-scale patterns. They are smaller in scale than architectural patterns, but tend to be independent of a particular programming language or programming paradigm. The application of a design pattern has no effect on the fundamental structure of a software system, but may have a strong influence on the architecture of a subsystem.\nMany design patterns provides structures for decomposing more complex services or components. Others address the effective cooperation between them, such as the following pattern: Observer or Publisher-Subscriber.\n  Idioms Idioms deal with the implemention of particular design issues.\n An idiom is a low-level pattern specific to a programming language. An idiom describes how to implement particular aspects of components or the relationships between them using the features of the given language.\n Idiom represent the lowest-level patterns. They address aspects of both design and implemention.\nMost idioms are language-specific, they capture existing programming experience. Often the same idiom looks different for different languages, and sometimes an idiom that is useful for one programming language doesn\u0026rsquo;t make sense in another.\n  Relationships between Patterns # A pattern solves a particular problem, but its application may raise new problems. Some of these can be solved by other patterns.\nMost patterns for software architecture raise problems that can be solved by smaller patterns. Patterns do not usually exist in isolation. Each pattern depends on the smaller patterns it contains and on the larger patterns in which it is contained.\nAnd a pattern may also be a variant of another.\nPatterns can also combine in more complex structures at the same level of abstraction. Each pattern resolves a particular subset of the forces to balance the forces when solving the problem.\nPattern Description # Patterns must be presented in an appropriate form if we are to understand and discuss them. A good description helps us grasp the essense of a pattern immediately:\n what\u0026rsquo;s the problem the pattern addresses? what\u0026rsquo;s the proposed solution?\nA good description also provides us with all the details necessary to implement a pattern, and to consider the consequences of its application. describe the solution uniformly!\nThis helps us to compare one pattern with another, especially when we are looking for alternative solutions to a problem.  The basic Context-Prolem-Solution structure provides a good starting point for a description format, but it is not enough.\nA pattern must be named - preferably with an intuitive name - if we are to share it and discuss it.\nOK, a good pattern template is showed below, please use it as a starting point:\n Name The name and a short Summary of the pattern. Also Known As Other names for the pattern, if any are known. Example A real-world example demonstrating the existence of the problem and the need for the pattern. Throughout the description we refer to the example to illustrate solution and implementation aspects, where this is necessary for useful. Context The situations in which the pattern may apply. Problem the problem the pattern addresses, including a discussion of its associated forces. Solution The fundamental solution principle underlying the pattern. Structure A detailed specification of the structural aspects of the pattern, including CRC-cards and OMT class diagram. Dynamics Typical scenarios describing the runtime behavior of the pattern. We further illustrate the scenarios with Object Message Sequences Charts. Implementation Guidelines for implementing the pattern. ...... ....... Variants A brief description of variants or specializations of a pattern. Known Uses Examples of the use of this pattern, taken from existing systems. Consequences The benefits the pattern provides, and any potiential liabilities. See Also References to patterns that solve similar problems, and to patterns that help us refine the pattern we are describing.  Will you learn patterns? # Now I think your answer will be definitely 100% Yes.\nRepository hitzhangjie/go-patterns will aim to provide demos for design patterns and idioms in golang. Hope we could follow the design details of design patterns to quickly solve the recurring problems.\n"}),a.add({id:156,href:"/tags/gdb/",title:"gdb",description:"",content:""}),a.add({id:157,href:"/blog/2022-04-10-macos-10.15.7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEgdb/",title:"macOS 10.15.7安装配置gdb",description:"macOS darwin内核的调整导致gdb无法正常工作，本文总结了权限问题、调试卡死问题的一种解决办法，亲测可用。但是该办法只是绕过了某些异常，并没有彻底修复gdb的bug",content:"问题简介 # gdb作为一款符号级调试器，是广大开发人员排查问题的神兵利器，但是因为macOS darwin内核的一些调整，gdb出现了各种神奇的bug行为，如权限问题导致的无法启动调试、启动调试后调试会话卡死等等。\n作者此前也曾经因为此类问题而苦恼，甚至不得不放弃了使用gdb调试器而使用其他办法来排查。最近在通过homebrew安装jupyterlab的时候发现gdb被升级了，就突然想起了之前被搁置的这个问题，测试后发现gdb还是不可正常使用。因此google一圈加不断测试，最终终于成功了。\n这里总结下方便日后查阅，也供遇到类似问题的朋友参考，这确实是一个老大难的问题了。google能发现很多针对该问题的讨论，难兄难弟们，let\u0026rsquo;s go。\n如何解决 #   download the source code zip file from https://github.com/bminor/binutils-gdb.git, unzip the zipfile to ./binutils-gdb-master\n  then try to build from master HEAD\nmkdir build cd build ../binutils-gdb-master/configure \\ --disable-unit-tests \\ --disable-binutils \\ --without-guile make -j8  the built gdb binary is put here: ./gdb/gdb. Because I want to make package management simpler, so I don\u0026rsquo;t want to run make install to install the gdb and other files.\n ps: there\u0026rsquo;s no make uninstall target in the Makefile, if you want to remove all installed files, try this:\n make install DESTDIR=/tmp/gccinst find /tmp/gccinst | sed -e s,/tmp/gccinst,, | \\ (while read F; do rm \u0026quot;$F\u0026quot;; done)    I then run brew install gdb to install the homebrew latest version, then I replace the gdb binary by:\ncp ./gdb/gdb /usr/local/Cellar/gdb/11.2/bin/gdb -f    Then codesign mentioned above, OK, I put it here for convenience: write a gdb-entitlement.xml:\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026quot;-//Apple//DTD PLIST 1.0//EN\u0026quot; \u0026quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026quot;\u0026gt; \u0026lt;plist version=\u0026quot;1.0\u0026quot;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.allow-jit\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.allow-unsigned-executable-memory\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.allow-dyld-environment-variables\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.disable-library-validation\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.disable-executable-page-protection\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.debugger\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.get-task-allow\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt;  then run following command to codesign:\nsudo codesign --entitlements gdb-entitlement.xml -fs gdb-cert $(which gdb)  If you haven\u0026rsquo;t created gdb-cert before, run following command to create:\n# download the script, or create one with the content in Appendix https://github.com/conda-forge/gdb-feedstock/blob/main/recipe/macos-codesign/macos-setup-codesign.sh # replace the certificate name sed -i 's/gdb-codesign/gdb-cert/g' macos-setup-codesign.sh # run the script to create the certificate and trust it ./macos-setup-codesign.sh # check the certificate is create or not security find-certificate -p -c gdb-cert | openssl x509 -checkend 0 or security find-certificate -p -c gdb-cert |openssl x509 -noout -text\\    then you can start your debugging, it works.\n  小节 # 本文总结了解决macOS平台上gdb无法正常调试的问题，这个办法只是解决了我和部分开发人员遇到的问题，但是并没有从根本上修复问题，不排除在您的环境下依然存在问题，请自己尝试是否有效，不行就继续寻找其他解决方案。\n附录 #   macos-setup-codesign.sh\n#!/bin/bash # This script is copied from https://github.com/llvm/llvm-project/blob/master/lldb/scripts/macos-setup-codesign.sh CERT=\u0026quot;gdb_codesign\u0026quot; function error() { echo error: \u0026quot;$@\u0026quot; 1\u0026gt;\u0026amp;2 exit 1 } function cleanup { # Remove generated files rm -f \u0026quot;$TMPDIR/$CERT.tmpl\u0026quot; \u0026quot;$TMPDIR/$CERT.cer\u0026quot; \u0026quot;$TMPDIR/$CERT.key\u0026quot; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 } trap cleanup EXIT # Check if the certificate is already present in the system keychain security find-certificate -Z -p -c \u0026quot;$CERT\u0026quot; /Library/Keychains/System.keychain \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 if [ $? -eq 0 ]; then echo Certificate has already been generated and installed exit 0 fi # Create the certificate template cat \u0026lt;\u0026lt;EOF \u0026gt;$TMPDIR/$CERT.tmpl [ req ] default_bits = 2048 # RSA key size encrypt_key = no # Protect private key default_md = sha512 # MD to use prompt = no # Prompt for DN distinguished_name = codesign_dn # DN template [ codesign_dn ] commonName = \u0026quot;$CERT\u0026quot; [ codesign_reqext ] keyUsage = critical,digitalSignature extendedKeyUsage = critical,codeSigning EOF echo Generating and installing gdb_codesign certificate # Generate a new certificate openssl req -new -newkey rsa:2048 -x509 -days 3650 -nodes -config \u0026quot;$TMPDIR/$CERT.tmpl\u0026quot; -extensions codesign_reqext -batch -out \u0026quot;$TMPDIR/$CERT.cer\u0026quot; -keyout \u0026quot;$TMPDIR/$CERT.key\u0026quot; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 [ $? -eq 0 ] || error Something went wrong when generating the certificate # Install the certificate in the system keychain sudo security add-trusted-cert -d -r trustRoot -p codeSign -k /Library/Keychains/System.keychain \u0026quot;$TMPDIR/$CERT.cer\u0026quot; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 [ $? -eq 0 ] || error Something went wrong when installing the certificate # Install the key for the certificate in the system keychain sudo security import \u0026quot;$TMPDIR/$CERT.key\u0026quot; -A -k /Library/Keychains/System.keychain \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 [ $? -eq 0 ] || error Something went wrong when installing the key # Kill task_for_pid access control daemon sudo pkill -f /usr/libexec/taskgated \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 # Exit indicating the certificate is now generated and installed exit 0    "}),a.add({id:158,href:"/tags/debugging/",title:"debugging",description:"",content:""}),a.add({id:159,href:"/tags/delve/",title:"delve",description:"",content:""}),a.add({id:160,href:"/tags/dlv/",title:"dlv",description:"",content:""}),a.add({id:161,href:"/tags/k8s/",title:"k8s",description:"",content:""}),a.add({id:162,href:"/tags/kubernetes/",title:"kubernetes",description:"",content:""}),a.add({id:163,href:"/blog/2022-04-08-%E5%AE%9E%E7%8E%B0k8s%E5%BA%94%E7%94%A8%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/",title:"实现k8s应用远程调试",description:"最近在支持团队测试左移、测试规范、CI/CD流水线方面的一些工作，针对开发人员发现问题、定位问题、修复问题这个过程产生了一点新的想法，尤其是在整体上云后的大背景下，我认为值得和大家一起探讨下，如何借助远程调试更快速地定位k8s应用问题。",content:"最近在支持团队测试左移、测试规范、CI/CD流水线方面的一些工作，针对开发人员发现问题、定位问题、修复问题这个过程产生了一点新的想法，尤其是在整体上云后的大背景下，我认为值得和大家一起探讨下，如何借助远程调试更快速地定位k8s应用问题。\n1 问题背景 # 现在公司大部分业务都上云了，服务部署基本上也k8s容器化了，解决了一些老大难的问题，本文不讨论k8s的好处，我们讨论下开发k8s应用（比如微服务）时开发侧可能碰到的一些问题。前段时间我开发了一个统计模调接口成功率的服务，部署在123平台，因为服务代码有些隐晦的bug排查修复花了些时间，这个过程中就开始思考为什么我对go、trpc很熟的情况下定位问题还这么麻烦呢？于是就有了接下来的探索以及这篇总结。\n2 经常遇到的问题 # 如果一件事情，短时间内需要人肉重复很多遍，就很容易让人抓狂，比如这次开发体验很快就让我抓狂了：\n 测试服务发现服务表现不正常，准备定位bug 查看错误日志初步锁定问题范围，重新走读代码进一步缩小问题范围 修改代码、提交代码，构建镜像、发布，然后重新测试  排查问题不只是这么轻描淡写，简单3步就搞定了：\n 可能是bug不容易定位，在外部数据满足某种条件下或者遇到某种事件时才会触发bug； 可能是测试用例覆盖不够，通过上述方法定位并解决了问题1，但是后面发现了问题2； 可能是日志信息不够，错误异常分支没有日志，或者日志信息不全； 微服务架构事务处理会跨越多个服务，可能要结合tracing、logging、metrics多个系统联合排查； 修改代码后提交并构建发布，可能涉及到CI/CD环节，流水线耗时较长； 123平台提供了dtools来快速构建、patch，但是破坏了测试环境稳定性（缺少镜像） TKE有同学基于七彩石配置下发实现的替换工具，存在dtools类似的问题； ……  总之，这个排查过程可能要涉及到多轮人肉操作，作为一个VIM党连上下移动都觉得用滑动鼠标、按上下左右是种低效的操作，更不用说让我在各个系统中间（而且系统衔接当前也还有较大空间）切来切去了。做了这么多“额外”的操作，才能渐渐去逼近真相、解决真正的问题。\n3 降低问题复杂度 # 这里先声明下，并不是说通过日志这种方式排查问题不好，主要还是要看待解决问题的复杂度，如果加几行日志就可以轻松缩小问题域并解决，那自然是好的。但是实际情况是，并不是所有问题都这么容易解决，而且也确实需要多考虑一些其他影响，比如dtools对测试环境的破坏（覆盖了镜像、忘了打镜像怎么办），频繁测试严格走CI/CD的耗时，等等。\n包括现在提倡的测试左移，单测覆盖、接口测试、集成测试等等，测试是门艺术，远比我之前肤浅的认识要重要，除了质量也要关注效率，做这么多其实也是像在投入时间、迭代效率、软件质量、团队构成等因素之间寻求一种平衡，降低整体复杂度。现在有些团队已经不再将单测覆盖率当做硬指标了，而是通过结合多种测试手段来寻求这种平衡。\n很多人对TDD有认识，但是在实际开发过程中并不会真的去做，代码语句覆盖、分支覆盖情况可能并不高，而且对某些corner cases可能靠正常思路也很难构造出来，可能要结合fuzz testing来协助。\n说这么多，只是为了说明一点，发现问题、走查日志、走查代码、修复提交、构建发布、重新测试，可能是我们每个开发同学解决定位解决bug时高频出现的操作流程，没有好的问题定位工具支持，对宝贵的开发资源就是种浪费。\n我看了下外部的很多团队在k8s开发方面的一些实践，这个过程感觉是可以优化的，那就是让开发k8s应用的我们获得本地调试能力，让远程的一些“不确定性的因素”变成本地“肉眼可见”的观测，问题解决起来就方便多了。尤其是对某些testcase，可能需要反复往前、往后翻代码才能定位到问题，这种在将mozilla rr（record and replay）作为调试器backend的加成下优势会非常明显。\n4 远程调试k8s应用 # 前面我们说了开发定位bug时大致的手段，并且强调了在问题比较复杂时，我们可能会通过多次“修改代码、构建发布、测试”这样的流程来逼近bug，这种场景下，如果能用调试器来跟踪下应用的执行过程，观测下执行流程、变量信息等是否符合预期，缩小问题域的过程会快很多，扩展阅读部分给出了一些业界团队的实践，供参考。\n调试器基础 # 对于一般的应用程序调试器大致可以分为两种类型：指令级调试器、符号级调试器，大家平时调试用的gdb、delve等就是符号级调试器，当然他们也具备一定的指令级调试能力。现代符号级调试器架构一般分为frontend、backend，二者通过service层进行通信（如借助rpc或者pipe），frontend主要是完成与用户的交互、展示，backend完成对tracee（被调试线程）的实际控制。\n以go语言的符号级调试器go-delve/delve为例，其分为frontend、backend，frontend可以是命令行、gdlv图形界面、vscode、goland等，backend针对不同的平台有多种实现，如借助平台的delve native实现、借助其他调试器能力gdbserver、mozilla rr等。本地调试frontend和backend之间通信通过net.pipe，远程通信通过json-rpc，如果是考虑到与vscode、goland集成的话则需要考虑类似DAP（debugger adapter protocol）的方式。\nps: 这里不过多展开了，对调试器设计实现感兴趣的朋友，可以参考我的电子书（最后一章待完成）：https://www.hitzhangjie.pro/debugger101.io/\n大家用的vscode插件、go-delve/delve调试器，其实就是先起个dlv backend以server的形式监听，协议就是DAP，通过vscode调试的时候，会通过DAP协议与dlv backend交互，dlv backend对被调试进程进行控制（如控制单步执行、读写内存等），大致就是这样的，对于远程调试k8s应用，也是这样的过程。\n远程调试演示 # 首先给大家简单实操演示下远程调试k8s应用，最后大家会意识到这个是完全可以实现的，而且可以做的更方便易用。\n示例工程说明 # 下面以一个简单的工程作为示例，实操下如何远程调试k8s应用，这个工程只有这么几个文件：\n/Volumes/kubernetes/debugging-go-app-in-k8s $ tree . . ├── Dockerfile ├── Makefile ├── app └── main.go 0 directories, 4 files  这里的main.go，是一个http服务，模拟我们的微服务，可以长期运行并接受用户请求。\npackage main import ( \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; ) // DefaultPort is the default port to use if once is not specified by the SERVER_PORT environment variable const DefaultPort = \u0026quot;8080\u0026quot; func getServerPort() string { port := os.Getenv(\u0026quot;SERVER_PORT\u0026quot;) if port != \u0026quot;\u0026quot; { return port } return DefaultPort } // EchoHandler echos back the request as a response func EchoHandler(writer http.ResponseWriter, request *http.Request) { log.Println(\u0026quot;Echoing back request made to \u0026quot; + request.URL.Path + \u0026quot; to client (\u0026quot; + request.RemoteAddr + \u0026quot;)\u0026quot;) writer.Header().Set(\u0026quot;Access-Control-Allow-Origin\u0026quot;, \u0026quot;*\u0026quot;) // allow pre-flight headers writer.Header().Set(\u0026quot;Access-Control-Allow-Headers\u0026quot;, \u0026quot;Content-Range, Content-Disposition, Content-Type, ETag\u0026quot;) request.Write(writer) } func main() { log.Println(\u0026quot;starting server, listening on port \u0026quot; + getServerPort()) http.HandleFunc(\u0026quot;/\u0026quot;, EchoHandler) http.ListenAndServe(\u0026quot;:\u0026quot;+getServerPort(), nil) }  Makefile完成应用程序的构建：\nall: GOOS=linux GOARCH=amd64 go build -gcflags 'all=-N -l' -o ./app ./main.go  Dockerfile完成镜像构建：\nFROM golang:1.16.3 ENV GO111MODULE=on RUN go get github.com/go-delve/delve/cmd/dlv@v1.8.2 RUN mkdir app WORKDIR /app COPY app . EXPOSE 10000 EXPOSE 8080 ENTRYPOINT [\u0026quot;/go/bin/dlv\u0026quot;, \u0026quot;--listen=:10000\u0026quot;, \u0026quot;--headless=true\u0026quot;, \u0026quot;--api-version=2\u0026quot;, \u0026quot;exec\u0026quot;, \u0026quot;./app\u0026quot;]  注意这里我们直接dlv、app加到了镜像里，并且应用程序直接是以被调试模式运行的。实际真的考虑到便利性的话，dlv以sidecar的形式提供，并且接收dlv connect请求后attach到running process的方式更合适，现在是完全可以做到这点的，dlv作者Derek Parker曾经做过一期分享，专门介绍k8s cluster应用调试，感兴趣的可以从文末参考链接中找到。\n示例工程部署 # 后续内容假定大家已经安装了docker、minikube，如果没有请自行了解下如何安装，然后启动docker、minikube start启动本地k8s cluster。\n构建镜像前先将docker registry指向minikube默认的registry：\neval $(minikube -p minikube docker-env)  然后再构建这个镜像，这样kubectl就能引用到本地镜像：\ndocker build -t debugging-go-app-in-k8s:latest .  k8s部署并运行这个镜像：\nkubectl run --rm -i debugging-go-app-in-k8s:latest --image-pull-policy=Never  运行并查看容器是否起来：\nkubectl get pods  应该能看到debugging-go-app-in-k8s，起来就ok了。\nminikube有点特殊，正常来说可以通过minikube service来创建个tunnel以与容器中的程序通信，比如测试http接口。\n也可以通过kubectl port-forward来实现：\nkubectl port-forward debugging-go-app-in-k8s 10000:10000 // 这个是dlv backend端口 kubectl port-forward debugging-go-app-in-k8s 8080:8080 // 这个是http服务端口  一个支持调试的k8s应用已经准备好了，然后可以通过dlv或者IDE进行调试了。\n远程调试测试 # 以dlv命令行调试为例：\n// 先连接到远程k8s pod中的debugger backend dlv connect localhost:10000 dlv\u0026gt; _ // 准备个断点，比如接口处理函数 dlv\u0026gt; break EchoHandler dlv\u0026gt; _  然后给http服务发个请求 curl http://localhost:8080，此时就会发现dlv frontend已经停在EchoHandler这个位置了，此时我们可以正常进行调试了。当然也可以通过vscode里面的Run\u0026gt;Connect and Debug来设置remote address为localhost:8080后在vscode中进行调试。\n与容器平台结合 # 开发同学如果觉得有用的话，不妨主动贡献一下，腾讯内部的主流容器平台是TKE（Tencent Kubernetes Engine），PCG 123平台也是在TKE基础上构建。理论上我们围绕容器平台提供些调试器插件即可实现远程调试能力。最终远程调试能力支持的话，可能最终形态应该是这样的。\n在同一个pod中部署一个delve，delve对同一个pod中的go-app进行调试，然后开发人员通过debugger frontend通过json-rpc或者DAP与pod中的delve（debugger backend）进行交互，完成对服务go-app的调试。\n由于源代码存放路径差异的问题，dlv提供了一种解决思路substitute-path，这样在涉及到源码相关的转换时（比如基于file lineno添加断点等）依然可以顺利调试。\n5 本文小结 # 开发过程中对问题定位的一点思考，了解了下业界一些实践，对于k8s、微服务这种情况，还是很值得建设远程调试能力的。业界很多头部企业都有这方面的实践，比如Google、RHEL等，以Google Cloud的Cloud Code为例，支持watch本地代码更新并自动发布、重新启动调试，其他的可以通过下面的扩展阅读了解。\n研发效率、工具建设是一项长跑，我们要倾听一线用户的真实诉求，也要多去探索优秀团队的实践来反哺自身。\n6 扩展阅读 #  Google Cloud: Cloud Code调试k8s应用，https://cloud.google.com/code/docs/vscode/debug solo-io/Squash: The debuggers for microservices，https://github.com/solo-io/squash vscode-kubernetes-tools/debug，https://github.com/vscode-kubernetes-tools/vscode-kubernetes-tools/blob/master/debug-on-kubernetes.md setlog/debug-k8s: how to debug a go-service in k8s, https://github.com/setlog/debug-k8s remote debugging on k8s using vscode, https://www.youtube.com/watch?v=nMm-vaFcG9c\u0026amp;list=LL\u0026amp;index=2 bug on a cluster by derek parker - 20220317, https://www.youtube.com/watch?v=TKPmvy6xGlQ\u0026amp;t=340s bug on a cluster by derek parker - 20220406，https://www.meetup.com/ChicagoGo/events/284436038 debugging go applications inside k8s，https://hackernoon.com/debugging-go-application-inside-kubernetes-from-ide-h5683xeb telepresence: making the remote local: faster feedback, collaboration and debugging，https://www.telepresence.io/docs/latest/concepts/faster/ Debugging Go Microservices in Kubernetes with VScode，https://blog.getambassador.io/debugging-go-microservices-in-kubernetes-with-vscode-a36beb48ef1  "}),a.add({id:164,href:"/tags/ast/",title:"AST",description:"",content:""}),a.add({id:165,href:"/tags/highlight/",title:"highlight",description:"",content:""}),a.add({id:166,href:"/tags/ident/",title:"ident",description:"",content:""}),a.add({id:167,href:"/tags/keyword/",title:"keyword",description:"",content:""}),a.add({id:168,href:"/blog/2022-02-09-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%BA%90%E4%BB%A3%E7%A0%81%E8%AF%AD%E6%B3%95%E9%AB%98%E4%BA%AE/",title:"如何实现源代码语法高亮",description:"大家对源代码语法高亮并不陌生，不管是功能强大的IDE，还是常规的一些编辑器vim、sublime、markdown codefences等都支持不同编程语言的语法高亮，大家知道具体是如何实现的吗？本文就以go语言语法高亮为例简单做个介绍。",content:"语法高亮 # 软件开发过程中对源代码进行语法高亮是非常有必要的，通过这种方式可以将程序中不同的要素进行有效地区分，如关键字、保留字、标识符、括号匹配、注释、字符串等等。开发人员使用的IDE一般都支持语法高亮，像vim、sublime等的编辑器也可以通过插件对不同编程语言的源代码进行语法高亮支持。\n如何实现 # 要实现语法高亮，需要做哪些工作呢？如果学习过编译原理，其实应该很容易想到，我们只需要实现一个词法分析器能够提取程序中的token序列，并通过语法分析器进行分析识别这些token具体为何物、它们之间具体是什么联系，是构成一个函数，还是构成一个表达式，还是简单到定义了一个变量、一个分支控制语句，等等。只要识别出来了，将这些不同的程序构造进行高亮显示自然不再困难。\n动手实践 # 我们就以go语言为例，来具体讨论下如何对源码进行高亮显示。自然我们不希望重新实现一遍词法分析器、语法分析器之类的琐碎工作，我们也没有精力去重新实现一遍这类工作。尽管flex、yacc可以帮助我们简化这类工作，但是go标准库其实已经提供了package ast来帮助我们做一些语法分析相关的工作。本文我们就基于package ast来演示下如何对go源码进行语法高亮。\n设计一个package colorize来提供一个colorize.Print(\u0026hellip;)方法，来将指定的源码文件进行高亮展示，并且允许指定源文件的行号范围、io.Writer、高亮颜色风格。只用编写如下几个源文件即可：\n line_writer.go，负责按行输出，输出的时候允许指定token、高亮颜色风格，token包含了起始位置信息，所以配合颜色，即可完成对特定关键字、标识符、注释等不同程序构造的高亮显示； colorize.go，负责读取源文件并对其进行AST分析，将其中我们要高亮的一些程序构造提取出来，如关键字package、var、func等作为token提取出来，并构造一个colorTok（包含了token本身位置信息、属于哪一类别，这里的类别决定了最终的颜色风格）； style.go，即高亮显示风格，不同类别对应着不同的终端颜色；  下面就是具体的源码实现了，其实这里的源码源自go-delve/delve，我在编写debugger101相关的demo时发现了go-delve/delve中存在的bug，并对其进行了修复，这里也算是简单记录分享一下吧。同学们真正有机会去尝试这个的也不多。\nfile: colorize.go # // Package colorize use AST analysis to analyze the source and colorize the different kinds // of literals, like keywords, imported packages, etc. // // If you want to highlight source parts, for example, the identifiers. // - firstly, colorTok must be generated by `emit(token.IDENT, n.Pos(), n.End())` in colorize.go // - secondly, we should map the token.IDENT to some style in style.go // - thirdly, we should define the color escape in terminal.go package colorize import ( \u0026quot;go/ast\u0026quot; \u0026quot;go/parser\u0026quot; \u0026quot;go/token\u0026quot; \u0026quot;io\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;path/filepath\u0026quot; \u0026quot;reflect\u0026quot; \u0026quot;sort\u0026quot; ) // Print prints to out a syntax highlighted version of the text read from // path, between lines startLine and endLine. func Print(out io.Writer, path string, startLine, endLine, arrowLine int, colorEscapes map[Style]string) error { buf, err := ioutil.ReadFile(path) if err != nil { return err } w := \u0026amp;lineWriter{w: out, lineRange: [2]int{startLine, endLine}, arrowLine: arrowLine, colorEscapes: colorEscapes} var fset token.FileSet f, err := parser.ParseFile(\u0026amp;fset, path, buf, parser.ParseComments) if err != nil { w.Write(NormalStyle, buf, true) return nil } var base int fset.Iterate(func(file *token.File) bool { base = file.Base() return false }) type colorTok struct { tok token.Token // the token type or ILLEGAL for keywords start, end int // start and end positions of the token } toks := []colorTok{} emit := func(tok token.Token, start, end token.Pos) { if _, ok := tokenToStyle[tok]; !ok { return } start -= token.Pos(base) if end == token.NoPos { // end == token.NoPos it's a keyword and we have to find where it ends by looking at the file for end = start; end \u0026lt; token.Pos(len(buf)); end++ { if buf[end] \u0026lt; 'a' || buf[end] \u0026gt; 'z' { break } } } else { end -= token.Pos(base) } if start \u0026lt; 0 || start \u0026gt;= end || end \u0026gt; token.Pos(len(buf)) { // invalid token? return } toks = append(toks, colorTok{tok, int(start), int(end)}) } for _, cgrp := range f.Comments { for _, cmnt := range cgrp.List { emit(token.COMMENT, cmnt.Pos(), cmnt.End()) } } ast.Inspect(f, func(n ast.Node) bool { if n == nil { return true } switch n := n.(type) { case *ast.File: emit(token.PACKAGE, f.Package, token.NoPos) return true case *ast.BasicLit: emit(n.Kind, n.Pos(), n.End()) return true case *ast.Ident: // TODO(aarzilli): builtin functions? basic types? return true case *ast.IfStmt: emit(token.IF, n.If, token.NoPos) if n.Else != nil { for elsepos := int(n.Body.End()) - base; elsepos \u0026lt; len(buf)-4; elsepos++ { if string(buf[elsepos:][:4]) == \u0026quot;else\u0026quot; { emit(token.ELSE, token.Pos(elsepos+base), token.Pos(elsepos+base+4)) break } } } return true } nval := reflect.ValueOf(n) if nval.Kind() != reflect.Ptr { return true } nval = nval.Elem() if nval.Kind() != reflect.Struct { return true } tokposval := nval.FieldByName(\u0026quot;TokPos\u0026quot;) tokval := nval.FieldByName(\u0026quot;Tok\u0026quot;) if tokposval != (reflect.Value{}) \u0026amp;\u0026amp; tokval != (reflect.Value{}) { emit(tokval.Interface().(token.Token), tokposval.Interface().(token.Pos), token.NoPos) } for _, kwname := range []string{\u0026quot;Case\u0026quot;, \u0026quot;Begin\u0026quot;, \u0026quot;Defer\u0026quot;, \u0026quot;Package\u0026quot;, \u0026quot;For\u0026quot;, \u0026quot;Func\u0026quot;, \u0026quot;Go\u0026quot;, \u0026quot;Interface\u0026quot;, \u0026quot;Map\u0026quot;, \u0026quot;Return\u0026quot;, \u0026quot;Select\u0026quot;, \u0026quot;Struct\u0026quot;, \u0026quot;Switch\u0026quot;} { kwposval := nval.FieldByName(kwname) if kwposval != (reflect.Value{}) { kwpos, ok := kwposval.Interface().(token.Pos) if ok \u0026amp;\u0026amp; kwpos != token.NoPos { emit(token.ILLEGAL, kwpos, token.NoPos) } } } return true }) sort.Slice(toks, func(i, j int) bool { return toks[i].start \u0026lt; toks[j].start }) flush := func(start, end int, style Style) { if start \u0026lt; end { w.Write(style, buf[start:end], end == len(buf)) } } cur := 0 for _, tok := range toks { flush(cur, tok.start, NormalStyle) flush(tok.start, tok.end, tokenToStyle[tok.tok]) cur = tok.end } if cur != len(buf) { flush(cur, len(buf), NormalStyle) } return nil }  file: style.go # package colorize import \u0026quot;go/token\u0026quot; // Style describes the style of a chunk of text. type Style uint8 const ( NormalStyle Style = iota KeywordStyle StringStyle NumberStyle CommentStyle LineNoStyle ArrowStyle ) var tokenToStyle = map[token.Token]Style{ token.ILLEGAL: KeywordStyle, token.COMMENT: CommentStyle, token.INT: NumberStyle, token.FLOAT: NumberStyle, token.IMAG: NumberStyle, token.CHAR: StringStyle, token.STRING: StringStyle, token.BREAK: KeywordStyle, token.CASE: KeywordStyle, token.CHAN: KeywordStyle, token.CONST: KeywordStyle, token.CONTINUE: KeywordStyle, token.DEFAULT: KeywordStyle, token.DEFER: KeywordStyle, token.ELSE: KeywordStyle, token.FALLTHROUGH: KeywordStyle, token.FOR: KeywordStyle, token.FUNC: KeywordStyle, token.GO: KeywordStyle, token.GOTO: KeywordStyle, token.IF: KeywordStyle, token.IMPORT: KeywordStyle, token.INTERFACE: KeywordStyle, token.MAP: KeywordStyle, token.PACKAGE: KeywordStyle, token.RANGE: KeywordStyle, token.RETURN: KeywordStyle, token.SELECT: KeywordStyle, token.STRUCT: KeywordStyle, token.SWITCH: KeywordStyle, token.TYPE: KeywordStyle, token.VAR: KeywordStyle, }  file: line_writer.go # package colorize import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; ) type lineWriter struct { w io.Writer lineRange [2]int arrowLine int curStyle Style started bool lineno int colorEscapes map[Style]string } func (w *lineWriter) style(style Style) { if w.colorEscapes == nil { return } esc := w.colorEscapes[style] if esc == \u0026quot;\u0026quot; { esc = w.colorEscapes[NormalStyle] } fmt.Fprintf(w.w, \u0026quot;%s\u0026quot;, esc) } func (w *lineWriter) inrange() bool { lno := w.lineno if !w.started { lno = w.lineno + 1 } return lno \u0026gt;= w.lineRange[0] \u0026amp;\u0026amp; lno \u0026lt; w.lineRange[1] } func (w *lineWriter) nl() { w.lineno++ if !w.inrange() || !w.started { return } w.style(ArrowStyle) if w.lineno == w.arrowLine { fmt.Fprintf(w.w, \u0026quot;=\u0026gt;\u0026quot;) } else { fmt.Fprintf(w.w, \u0026quot; \u0026quot;) } w.style(LineNoStyle) fmt.Fprintf(w.w, \u0026quot;%4d:\\t\u0026quot;, w.lineno) w.style(w.curStyle) } func (w *lineWriter) writeInternal(style Style, data []byte) { if !w.inrange() { return } if !w.started { w.started = true w.curStyle = style w.nl() } else if w.curStyle != style { w.curStyle = style w.style(w.curStyle) } w.w.Write(data) } func (w *lineWriter) Write(style Style, data []byte, last bool) { cur := 0 for i := range data { if data[i] == '\\n' { if last \u0026amp;\u0026amp; i == len(data)-1 { w.writeInternal(style, data[cur:i]) if w.curStyle != NormalStyle { w.style(NormalStyle) } if w.inrange() { w.w.Write([]byte{'\\n'}) } last = false } else { w.writeInternal(style, data[cur:i+1]) w.nl() } cur = i + 1 } } if cur \u0026lt; len(data) { w.writeInternal(style, data[cur:]) } if last { if w.curStyle != NormalStyle { w.style(NormalStyle) } if w.inrange() { w.w.Write([]byte{'\\n'}) } } }  运行测试 # 下面是测试文件，我们定义了一个表示源码内容的字符串，并通过gomonkey mock掉了ioutil.ReadFile(\u0026hellip;)的操作让其返回定义的源码字符串，然后执行colorize.Print(\u0026hellip;)对其进行高亮显示。\nfile: colorize_test.go\npackage colorize_test import ( \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;reflect\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;github.com/agiledragon/gomonkey/v2\u0026quot; \u0026quot;github.com/hitzhangjie/dlv/pkg/terminal/colorize\u0026quot; ) var src = `package main // Vehicle defines the vehicle behavior type Vehicle interface{ // Run vehicle can run in a speed Run() } // BMWS1000RR defines the motocycle bmw s1000rr type BMWS1000RR struct { } // Run bwm s1000rr run func (a *BMWS1000RR) Run() { println(\u0026quot;I can run at 300km/h\u0026quot;) } func main() { var vehicle = \u0026amp;BMWS1000RR{} vehicle.Run() } ` const terminalHighlightEscapeCode string = \u0026quot;\\033[%2dm\u0026quot; const ( ansiBlack = 30 ansiRed = 31 ansiGreen = 32 ansiYellow = 33 ansiBlue = 34 ansiMagenta = 35 ansiCyan = 36 ansiWhite = 37 ansiBrBlack = 90 ansiBrRed = 91 ansiBrGreen = 92 ansiBrYellow = 93 ansiBrBlue = 94 ansiBrMagenta = 95 ansiBrCyan = 96 ansiBrWhite = 97 ) func colorizeCode(code int) string { return fmt.Sprintf(terminalHighlightEscapeCode, code) } var colors = map[colorize.Style]string{ colorize.KeywordStyle: colorizeCode(ansiYellow), colorize.ArrowStyle: colorizeCode(ansiBlue), colorize.CommentStyle: colorizeCode(ansiGreen), colorize.LineNoStyle: colorizeCode(ansiBrWhite), colorize.NormalStyle: colorizeCode(ansiBrWhite), colorize.NumberStyle: colorizeCode(ansiBrCyan), colorize.StringStyle: colorizeCode(ansiBrBlue), } func TestPrint(t *testing.T) { p := gomonkey.ApplyFunc(ioutil.ReadFile, func(name string) ([]byte, error) { return []byte(src), nil }) defer p.Reset() buf := \u0026amp;bytes.Buffer{} colorize.Print(buf, \u0026quot;main.go\u0026quot;, bytes.NewBufferString(src), 1, 30, 10, colors) colorize.Print(os.Stdout, \u0026quot;main.go\u0026quot;, bytes.NewBufferString(src), 1, 30, 10, colors) }  现在运行这个测试用例go test -run TestPrint，程序运行结果如下：\n我们看到程序中的部分程序元素被高亮显示了，当然我们只识别了简单的一小部分，关键字、字符串、注释，实际IDE中会分析的更加的细致，大家在使用IDE的时候应该也都有这方面的体会。\n本文小结 # 本文简单总结了如何基于go ast对源代码进行语法分析并进行高亮显示，希望读者能了解到这里的知识点，并能认识到编译原理的相关知识真的是可以用来做些有价值、有意思的东西的。再比如，我们实现一些linters对源码进行检查（如golangci-linter），作者之前还写过一篇文章是讲述如何对go程序进行可视化，有些IDE还支持自动生成classgram、callgraph等等，这些也是对go ast的另一种应用。\n新的一年与大家共勉，做有追求的工程师，知其然知其所以然 :)\n"}),a.add({id:169,href:"/tags/b+tree/",title:"B+Tree",description:"",content:""}),a.add({id:170,href:"/tags/btree/",title:"BTree",description:"",content:""}),a.add({id:171,href:"/tags/explain/",title:"explain",description:"",content:""}),a.add({id:172,href:"/tags/index/",title:"index",description:"",content:""}),a.add({id:173,href:"/tags/mysql/",title:"mysql",description:"",content:""}),a.add({id:174,href:"/blog/2022-01-06-mysql%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/",title:"MySQL查询性能优化",description:"【转】MySQL优化原理，https://www.cnblogs.com/zhangyinhua/p/7620964.html\n说起MySQL的查询优化，相信大家积累一堆技巧：不能使用SELECT *、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？\n我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。\n  img { width: 680px; padding-bottom: 1rem; }  MySQL逻辑架构 # 如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。\nMySQL逻辑架构，来自：高性能MySQL\nMySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。\nMySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。\n最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。\n MySQL查询过程 # 我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。\n当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？\nMySQL查询过程\n客户端/服务端通信协议 # MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。\n客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。\n与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。\n查询缓存 # 在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。\nMySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。\n如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。\n既然是缓存，就会失效，那查询缓存何时失效呢？　MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：\n 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗  基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：\n 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存  最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。\n当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等，读者可以自行阅读相关资料，这里权当抛砖引玉吧。\n语法解析和预处理 # MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。\n查询优化 # 经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。\nMySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。\nMysql代码\nmysql\u0026gt; select * from t_message limit 10; ...省略结果集 mysql\u0026gt; show status like 'last_query_cost'; +-----------------+-------------+ | Variable_name | Value | +-----------------+-------------+ | Last_query_cost | 6391.",content:"【转】MySQL优化原理，https://www.cnblogs.com/zhangyinhua/p/7620964.html\n说起MySQL的查询优化，相信大家积累一堆技巧：不能使用SELECT *、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？\n我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。\n  img { width: 680px; padding-bottom: 1rem; }  MySQL逻辑架构 # 如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。\nMySQL逻辑架构，来自：高性能MySQL\nMySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。\nMySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。\n最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。\n MySQL查询过程 # 我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。\n当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？\nMySQL查询过程\n客户端/服务端通信协议 # MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。\n客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。\n与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。\n查询缓存 # 在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。\nMySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。\n如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。\n既然是缓存，就会失效，那查询缓存何时失效呢？　MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：\n 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗  基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：\n 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存  最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。\n当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等，读者可以自行阅读相关资料，这里权当抛砖引玉吧。\n语法解析和预处理 # MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。\n查询优化 # 经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。\nMySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。\nMysql代码\nmysql\u0026gt; select * from t_message limit 10; ...省略结果集 mysql\u0026gt; show status like 'last_query_cost'; +-----------------+-------------+ | Variable_name | Value | +-----------------+-------------+ | Last_query_cost | 6391.799000 | +-----------------+-------------+  示例中的结果表示优化器认为大概需要做6391个数据页的随机查找才能完成上面的查询。这个结果是根据一些列的统计信息计算得来的，这些统计信息包括：每张表或者索引的页面个数、索引的基数、索引和数据行的长度、索引的分布情况等等。\n有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL只选择它认为成本小的，但成本小并不意味着执行时间短）等等。\nMySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：\n 重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序） 优化MIN()和MAX()函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值，具体原理见下文） 提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询） 优化排序（在老版本MySQL会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多）  随着MySQL的不断发展，优化器使用的优化策略也在不断的进化，这里仅仅介绍几个非常常用且容易理解的优化策略，其他的优化策略，大家自行查阅吧。\n查询执行引擎 # 在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为handlerAPI。查询过程中的每一张表由一个handler实例表示。\n实际上，MySQL在查询优化阶段就为每一张表创建了一个handler实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。\n返回结果给客户端 # 查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如改查询影响到的行数以及执行时间等等。\n如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。\n结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。\n回头总结一下MySQL整个查询执行过程，总的来说分为5个步骤：\n 客户端向MySQL服务器发送一条查询请求 服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段 服务器进行SQL解析、预处理、再由优化器生成对应的执行计划 MySQL根据执行计划，调用存储引擎的API来执行查询 将结果返回给客户端，同时缓存查询结果   性能优化建议 # 看了这么多，你可能会期待给出一些优化手段，是的，下面会从3个不同方面给出一些优化建议。但请等等，还有一句忠告要先送给你：不要听信你看到的关于优化的“绝对真理”，包括本文所讨论的内容，而应该是在实际的业务场景下通过测试来验证你关于执行计划以及响应时间的假设。\nScheme设计与数据类型优化 # 选择数据类型只要遵循小而简单的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。越简单的数据类型在计算时需要更少的CPU周期，比如，整型就比字符操作代价低，因而会使用整型来存储ip地址，使用DATETIME来存储时间，而不是使用字符串。\n这里总结几个可能容易理解错误的技巧：\n 通常来说把可为NULL的列改为NOT NULL不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为NOT NULL。 对整数类型指定宽度，比如INT(11)，没有任何卵用。INT使用16为存储空间，那么它的表示范围已经确定，所以INT(1)和INT(20)对于存储和计算是相同的。 UNSIGNED表示不允许负值，大致可以使正数的上限提高一倍。比如TINYINT存储范围是通常来讲，没有太大的必要使用DECIMAL数据类型。即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用TIMESTAMP使用4个字节存储空间，DATETIME使用8个字节存储空间。因而，TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同。 大多数情况下没有使用枚举类型的必要，其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用ALTER TABLE（如果只只是在列表末尾追加元素，不需要重建表）。 schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。 大表ALTER TABLE非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇淫技巧可以解决这个问题，有兴趣可自行查阅。  创建高性能索引 # 索引是提高MySQL查询性能的一个重要途径，但过多的索引可能会导致过高的磁盘使用率以及过高的内存占用，从而影响应用程序的整体性能。应当尽量避免事后才想起添加索引，因为事后可能需要监控大量的SQL才能定位到问题所在，而且添加索引的时间肯定是远大于初始添加索引所需要的时间，可见索引的添加也是非常有技术含量的。\n接下来将向你展示一系列创建高性能索引的策略，以及每条策略其背后的工作原理。但在此之前，先了解与索引相关的一些算法和数据结构，将有助于更好的理解后文的内容。推荐：带你从头到尾捋一遍MySQL索引结构！\n索引相关的数据结构和算法 # 通常我们所说的索引是指B-Tree索引，它是目前关系型数据库中查找数据最为常用和有效的索引，大多数存储引擎都支持这种索引。使用B-Tree这个术语，是因为MySQL在CREATE TABLE或其它语句中使用了这个关键字，但实际上不同的存储引擎可能使用不同的数据结构，比如InnoDB就是使用的B+Tree。\nB+Tree中的B是指balance，意为平衡。需要注意的是，B+树索引并不能找到一个给定键值的具体行，它找到的只是被查找数据行所在的页，接着数据库会把页读入到内存，再在内存中进行查找，最后得到要查找的数据。\n在介绍B+Tree前，先了解一下二叉查找树，它是一种经典的数据结构，其左子树的值总是小于根的值，右子树的值总是大于根的值，如下图①。如果要在这课树中查找值为5的记录，其大致流程：先找到根，其值为6，大于5，所以查找左子树，找到3，而5大于3，接着找3的右子树，总共找了3次。同样的方法，如果查找值为8的记录，也需要查找3次。所以二叉查找树的平均查找次数为(3 + 3 + 3 + 2 + 2 + 1) / 6 = 2.3次，而顺序查找的话，查找值为2的记录，仅需要1次，但查找值为8的记录则需要6次，所以顺序查找的平均查找次数为：(1 + 2 + 3 + 4 + 5 + 6) / 6 = 3.3次，因为大多数情况下二叉查找树的平均查找速度比顺序查找要快。\n二叉查找树和平衡二叉树\n由于二叉查找树可以任意构造，同样的值，可以构造出如图②的二叉查找树，显然这棵二叉树的查询效率和顺序查找差不多。若想二叉查找数的查询性能最高，需要这棵二叉查找树是平衡的，也即平衡二叉树（AVL树）。\n平衡二叉树首先需要符合二叉查找树的定义，其次必须满足任何节点的两个子树的高度差不能大于1。显然图②不满足平衡二叉树的定义，而图①是一课平衡二叉树。平衡二叉树的查找性能是比较高的（性能最好的是最优二叉树），查询性能越好，维护的成本就越大。比如图①的平衡二叉树，当用户需要插入一个新的值9的节点时，就需要做出如下变动。\n平衡二叉树旋转\n通过一次左旋操作就将插入后的树重新变为平衡二叉树是最简单的情况了，实际应用场景中可能需要旋转多次。至此我们可以考虑一个问题，平衡二叉树的查找效率还不错，实现也非常简单，相应的维护成本还能接受，为什么MySQL索引不直接使用平衡二叉树？\n随着数据库中数据的增加，索引本身大小随之增加，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级。可以想象一下一棵几百万节点的二叉树的深度是多少？如果将这么大深度的一颗二叉树放磁盘上，每读取一个节点，需要一次磁盘的I/O读取，整个查找的耗时显然是不能够接受的。那么如何减少查找过程中的I/O存取次数？\n一种行之有效的解决方法是减少树的深度，将二叉树变为m叉树（多路搜索树），而B+Tree就是一种多路搜索树。理解B+Tree时，只需要理解其最重要的两个特征即可：第一，所有的关键字（可以理解为数据）都存储在叶子节点（Leaf Page），非叶子节点（Index Page）并不存储真正的数据，所有记录节点都是按键值大小顺序存放在同一层叶子节点上。其次，所有的叶子节点由指针连接。如下图为高度为2的简化了的B+Tree。\n简化B+Tree\n怎么理解这两个特征？MySQL将每个节点的大小设置为一个页的整数倍（原因下文会介绍），也就是在节点空间大小一定的情况下，每个节点可以存储更多的内结点，这样每个结点能索引的范围更大更精确。所有的叶子节点使用指针链接的好处是可以进行区间访问，比如上图中，如果查找大于20而小于30的记录，只需要找到节点20，就可以遍历指针依次找到25、30。如果没有链接指针的话，就无法进行区间查找。这也是MySQL使用B+Tree作为索引存储结构的重要原因。\nMySQL为何将节点大小设置为页的整数倍，这就需要理解磁盘的存储原理。磁盘本身存取就比主存慢很多，在加上机械运动损耗（特别是普通的机械硬盘），磁盘的存取速度往往是主存的几百万分之一，为了尽量减少磁盘I/O，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，预读的长度一般为页的整数倍。\n 页是计算机管理存储器的逻辑块，硬件及OS往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（许多OS中，页的大小通常为4K）。主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。\n MySQL巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了读取一个节点只需一次I/O。假设B+Tree的高度为h，一次检索最多需要h-1I/O（根节点常驻内存），复杂度O(h)=O(logMN)。实际应用场景中，M通常较大，常常超过100，因此树的高度一般都比较小，通常不超过3。\n最后简单了解下B+Tree节点的操作，在整体上对索引的维护有一个大概的了解，虽然索引可以大大提高查询效率，但维护索引仍要花费很大的代价，因此合理的创建索引也就尤为重要。\n仍以上面的树为例，我们假设每个节点只能存储4个内节点。首先要插入第一个节点28，如下图所示。\nleaf page和index page都没有满\n接着插入下一个节点70，在Index Page中查询后得知应该插入到50 - 70之间的叶子节点，但叶子节点已满，这时候就需要进行也分裂的操作，当前的叶子节点起点为50，所以根据中间值来拆分叶子节点，如下图所示。\nLeaf Page拆分\n最后插入一个节点95，这时候Index Page和Leaf Page都满了，就需要做两次拆分，如下图所示。\nLeaf Page与Index Page拆分\n拆分后最终形成了这样一颗树。\n最终树\nB+Tree为了保持平衡，对于新插入的值需要做大量的拆分页操作，而页的拆分需要I/O操作，为了尽可能的减少页的拆分操作，B+Tree也提供了类似于平衡二叉树的旋转功能。当LeafPage已满但其左右兄弟节点没有满的情况下，B+Tree并不急于去做拆分操作，而是将记录移到当前所在页的兄弟节点上。通常情况下，左兄弟会被先检查用来做旋转操作。就比如上面第二个示例，当插入70的时候，并不会去做页拆分，而是左旋操作。\n左旋操作\n通过旋转操作可以最大限度的减少页分裂，从而减少索引维护过程中的磁盘的I/O操作，也提高索引维护效率。需要注意的是，删除节点跟插入节点类型，仍然需要旋转和拆分操作，这里就不再说明。\n高性能策略 # 通过上文，相信你对B+Tree的数据结构已经有了大致的了解，但MySQL中索引是如何组织数据的存储呢？以一个简单的示例来说明，假如有如下数据表：\nMysql代码\nCREATE TABLE People( last_name varchar(50) not null, first_name varchar(50) not null, dob date not null, gender enum(`m`,`f`) not null, key(last_name,first_name,dob) );  对于表中每一行数据，索引中包含了last_name、first_name、dob列的值，下图展示了索引是如何组织数据存储的。\n索引如何组织数据存储，来自：高性能MySQL\n可以看到，索引首先根据第一个字段来排列顺序，当名字相同时，则根据第三个字段，即出生日期来排序，正是因为这个原因，才有了索引的“最左原则”。\n1、MySQL不会使用索引的情况：非独立的列 # “独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数。比如：\nselect * from where id + 1 = 5  我们很容易看出其等价于 id = 4，但是MySQL无法自动解析这个表达式，使用函数是同样的道理。\n2、前缀索引 # 如果列很长，通常可以索引开始的部分字符，这样可以有效节约索引空间，从而提高索引效率。\n3、多列索引和索引顺序 # 在多数情况下，在多个列上建立独立的索引并不能提高查询性能。理由非常简单，MySQL不知道选择哪个索引的查询效率更好，所以在老版本，比如MySQL5.0之前就会随便选择一个列的索引，而新的版本会采用合并索引的策略。举个简单的例子，在一张电影演员表中，在actor_id和film_id两个列上都建立了独立的索引，然后有如下查询：\nselect film_id,actor_id from film_actor where actor_id = 1 or film_id = 1  老版本的MySQL会随机选择一个索引，但新版本做如下的优化：\nselect film_id,actor_id from film_actor where actor_id = 1 union all select film_id,actor_id from film_actor where film_id = 1 and actor_id \u0026lt;\u0026gt; 1   当出现多个索引做相交操作时（多个AND条件），通常来说一个包含所有相关列的索引要优于多个独立索引。 当出现多个索引做联合操作时（多个OR条件），对结果集的合并、排序等操作需要耗费大量的CPU和内存资源，特别是当其中的某些索引的选择性不高，需要返回合并大量数据时，查询成本更高。所以这种情况下还不如走全表扫描。  因此explain时如果发现有索引合并（Extra字段出现Using union），应该好好检查一下查询和表结构是不是已经是最优的，如果查询和表都没有问题，那只能说明索引建的非常糟糕，应当慎重考虑索引是否合适，有可能一个包含所有相关列的多列索引更适合。\n前面我们提到过索引如何组织数据存储的，从图中可以看到多列索引时，索引的顺序对于查询是至关重要的，很明显应该把选择性更高的字段放到索引的前面，这样通过第一个字段就可以过滤掉大多数不符合条件的数据。\n索引选择性是指不重复的索引值和数据表的总记录数的比值，选择性越高查询效率越高，因为选择性越高的索引可以让MySQL在查询时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。\n理解索引选择性的概念后，就不难确定哪个字段的选择性较高了，查一下就知道了，比如：\nSELECT * FROM payment where staff_id = 2 and customer_id = 584  是应该创建(staff_id,customer_id)的索引还是应该颠倒一下顺序？执行下面的查询，哪个字段的选择性更接近1就把哪个字段索引前面就好。\nselect count(distinct staff_id)/count(*) as staff_id_selectivity, count(distinct customer_id)/count(*) as customer_id_selectivity, count(*) from payment  多数情况下使用这个原则没有任何问题，但仍然注意你的数据中是否存在一些特殊情况。举个简单的例子，比如要查询某个用户组下有过交易的用户信息：\nselect user_id from trade where user_group_id = 1 and trade_amount \u0026gt; 0  MySQL为这个查询选择了索引(user_group_id,trade_amount)，如果不考虑特殊情况，这看起来没有任何问题，但实际情况是这张表的大多数数据都是从老系统中迁移过来的，由于新老系统的数据不兼容，所以就给老系统迁移过来的数据赋予了一个默认的用户组。这种情况下，通过索引扫描的行数跟全表扫描基本没什么区别，索引也就起不到任何作用。\n推广开来说，经验法则和推论在多数情况下是有用的，可以指导我们开发和设计，但实际情况往往会更复杂，实际业务场景下的某些特殊情况可能会摧毁你的整个设计。\n4、避免多个范围条件 # 实际开发中，我们会经常使用多个范围条件，比如想查询某个时间段内登录过的用户：\nselect user.* from user where login_time \u0026gt; '2017-04-01' and age between 18 and 30;  这个查询有一个问题：它有两个范围条件，login_time列和age列，MySQL可以使用login_time列的索引或者age列的索引，但无法同时使用它们。\n5、覆盖索引 # 如果一个索引包含或者说覆盖所有需要查询的字段的值，那么就没有必要再回表查询，这就称为覆盖索引。覆盖索引是非常有用的工具，可以极大的提高性能，因为查询只需要扫描索引会带来许多好处：\n 索引条目远小于数据行大小，如果只读取索引，极大减少数据访问量 索引是有按照列值顺序存储的，对于I/O密集型的范围查询要比随机从磁盘读取每一行数据的IO要少的多  6、使用索引扫描来排序 # MySQL有两种方式可以生产有序的结果集，其一是对结果集进行排序的操作，其二是按照索引顺序扫描得出的结果自然是有序的。如果explain的结果中type列的值为index表示使用了索引扫描来做排序。\n扫描索引本身很快，因为只需要从一条索引记录移动到相邻的下一条记录。但如果索引本身不能覆盖所有需要查询的列，那么就不得不每扫描一条索引记录就回表查询一次对应的行。这个读取操作基本上是随机I/O，因此按照索引顺序读取数据的速度通常要比顺序地全表扫描要慢。\n在设计索引时，如果一个索引既能够满足排序，又满足查询，是最好的。\n只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向也一样时，才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有ORDER BY子句引用的字段全部为第一张表时，才能使用索引做排序。ORDER BY子句和查询的限制是一样的，都要满足最左前缀的要求（有一种情况例外，就是最左的列被指定为常数，下面是一个简单的示例），其他情况下都需要执行排序操作，而无法利用索引排序。\n-- 最左列为常数，索引：(date,staff_id,customer_id) select staff_id,customer_id from demo where date = '2015-06-01' ``order by staff_id,customer_id  7、冗余和重复索引 # 冗余索引是指在相同的列上按照相同的顺序创建的相同类型的索引，应当尽量避免这种索引，发现后立即删除。比如有一个索引(A,B)，再创建索引(A)就是冗余索引。冗余索引经常发生在为表添加新索引时，比如有人新建了索引(A,B)，但这个索引不是扩展已有的索引(A)。\n大多数情况下都应该尽量扩展已有的索引而不是创建新索引。但有极少情况下出现性能方面的考虑需要冗余索引，比如扩展已有索引而导致其变得过大，从而影响到其他使用该索引的查询。\n8、删除长期未使用的索引 # 定期删除一些长时间未使用过的索引是一个非常好的习惯。\n关于索引这个话题打算就此打住，最后要说一句，索引并不总是最好的工具，只有当索引帮助提高查询速度带来的好处大于其带来的额外工作时，索引才是有效的。对于非常小的表，简单的全表扫描更高效。对于中到大型的表，索引就非常有效。对于超大型的表，建立和维护索引的代价随之增长，这时候其他技术也许更有效，比如分区表。最后的最后，explain后再提测是一种美德。\n特定类型查询优化 # 优化COUNT()查询 # COUNT()可能是被大家误解最多的函数了，它有两种不同的作用，其一是统计某个列值的数量，其二是统计行数。统计列值时，要求列值是非空的，它不会统计NULL。如果确认括号中的表达式不可能为空时，实际上就是在统计行数。最简单的就是当使用COUNT(*)时，并不是我们所想象的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计行数。\n我们最常见的误解也就在这儿，在括号内指定了一列却希望统计结果是行数，而且还常常误以为前者的性能会更好。但实际并非这样，如果要统计行数，直接使用COUNT(*)，意义清晰，且性能更好。\n有时候某些业务场景并不需要完全精确的COUNT值，可以用近似值来代替，EXPLAIN出来的行数就是一个不错的近似值，而且执行EXPLAIN并不需要真正地去执行查询，所以成本非常低。通常来说，执行COUNT()都需要扫描大量的行才能获取到精确的数据，因此很难优化，MySQL层面还能做得也就只有覆盖索引了。如果不还能解决问题，只有从架构层面解决了，比如添加汇总表，或者使用redis这样的外部缓存系统。\n优化关联查询 # 在大数据场景下，表与表之间通过一个冗余字段来关联，要比直接使用JOIN有更好的性能。如果确实需要使用关联查询的情况下，需要特别注意的是：\n 确保ON和USING字句中的列上有索引。在创建索引的时候就要考虑到关联的顺序。当表A和表B用列c关联的时候，如果优化器关联的顺序是A、B，那么就不需要在A表的对应列上创建索引。没有用到的索引会带来额外的负担，一般来说，除非有其他理由，只需要在关联顺序中的第二张表的相应列上创建索引（具体原因下文分析）。 确保任何的GROUP BY和ORDER BY中的表达式只涉及到一个表中的列，这样MySQL才有可能使用索引来优化。  要理解优化关联查询的第一个技巧，就需要理解MySQL是如何执行关联查询的。当前MySQL关联执行的策略非常简单，它对任何的关联都执行嵌套循环关联操作，即先在一个表中循环取出单条数据，然后在嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为为止。然后根据各个表匹配的行，返回查询中需要的各个列。\n太抽象了？以上面的示例来说明，比如有这样的一个查询：\nSELECT A.xx,B.yy FROM A INNER JOIN B USING(c) WHERE A.xx IN (5,6)  假设MySQL按照查询中的关联顺序A、B来进行关联操作，那么可以用下面的伪代码表示MySQL如何完成这个查询：\nouter_iterator = SELECT A.xx,A.c FROM A WHERE A.xx IN (5,6); outer_row = outer_iterator.next; while(outer_row) { inner_iterator = SELECT B.yy FROM B WHERE B.c = outer_row.c; inner_row = inner_iterator.next; while(inner_row) { output[inner_row.yy,outer_row.xx]; inner_row = inner_iterator.next; } outer_row = outer_iterator.next; }  可以看到，最外层的查询是根据A.xx列来查询的，A.c上如果有索引的话，整个关联查询也不会使用。再看内层的查询，很明显B.c上如果有索引的话，能够加速查询，因此只需要在关联顺序中的第二张表的相应列上创建索引即可。\n优化LIMIT分页 # 当需要分页操作时，通常会使用LIMIT加上偏移量的办法实现，同时加上合适的ORDER BY字句。如果有对应的索引，通常效率会不错，否则，MySQL需要做大量的文件排序操作。\n一个常见的问题是当偏移量非常大的时候，比如：LIMIT 10000 20这样的查询，MySQL需要查询10020条记录然后只返回20条记录，前面的10000条都将被抛弃，这样的代价非常高。\n优化这种查询一个最简单的办法就是尽可能的使用覆盖索引扫描，而不是查询所有的列。然后根据需要做一次关联查询再返回所有的列。对于偏移量很大时，这样做的效率会提升非常大。考虑下面的查询：\nSELECT film_id,description FROM film ORDER BY title LIMIT 50,5;  如果这张表非常大，那么这个查询最好改成下面的样子：\nSELECT film.film_id,film.description FROM film INNER JOIN ( SELECT film_id FROM film ORDER BY title LIMIT 50,5 ) AS tmp USING(film_id);  这里的延迟关联将大大提升查询效率，让MySQL扫描尽可能少的页面，获取需要访问的记录后在根据关联列回原表查询所需要的列。\n有时候如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET，比如下面的查询：\nSELECT id FROM t LIMIT 10000, 10;  改为：\nSELECT id FROM t WHERE id \u0026gt; 10000 LIMIT 10;  其他优化的办法还包括使用预先计算的汇总表，或者关联到一个冗余表，冗余表中只包含主键列和需要做排序的列。\n优化UNION # MySQL处理UNION的策略是先创建临时表，然后再把各个查询结果插入到临时表中，最后再来做查询。因此很多优化策略在UNION查询中都没有办法很好的时候。经常需要手动将WHERE、LIMIT、ORDER BY等字句“下推”到各个子查询中，以便优化器可以充分利用这些条件先优化。\n除非确实需要服务器去重，否则就一定要使用UNION ALL，如果没有ALL关键字，MySQL会给临时表加上DISTINCT选项，这会导致整个临时表的数据做唯一性检查，这样做的代价非常高。当然即使使用ALL关键字，MySQL总是将结果放入临时表，然后再读出，再返回给客户端。虽然很多时候没有这个必要，比如有时候可以直接把每个子查询的结果返回给客户端。\n结语 # 理解查询是如何执行以及时间都消耗在哪些地方，再加上一些优化过程的知识，可以帮助大家更好的理解MySQL，理解常见优化技巧背后的原理。希望本文中的原理、示例能够帮助大家更好的将理论和实践联系起来，更多的将理论知识运用到实践中。\n其他也没啥说的了，给大家留两个思考题吧，可以在脑袋里想想答案，这也是大家经常挂在嘴边的，但很少有人会思考为什么？\n 有非常多的程序员在分享时都会抛出这样一个观点：尽可能不要使用存储过程，存储过程非常不容易维护，也会增加使用成本，应该把业务逻辑放到客户端。既然客户端都能干这些事，那为什么还要存储过程？ JOIN本身也挺方便的，直接查询就好了，为什么还需要视图呢？  参考资料 #  [1] 姜承尧 著；MySQL技术内幕-InnoDB存储引擎；机械工业出版社，2013 [2] Baron Scbwartz 等著；宁海元 周振兴等译；高性能MySQL（第三版）; 电子工业出版社， 2013 [3] 由 B-/B+树看 MySQL索引结构\n "}),a.add({id:175,href:"/tags/bazelbuild/",title:"bazelbuild",description:"",content:""}),a.add({id:176,href:"/blog/2021-10-21-bazelbuild%E6%9E%84%E5%BB%BAgo%E5%BE%AE%E6%9C%8D%E5%8A%A1/",title:"bazelbuild：构建go微服务",description:"关于monorepo、multirepo的争论不绝于耳，至于采用哪种方式进行管理，要因地制宜地选择最合适的方案，要看到其优势，也要看到工具建设和迁移的成本。这里重点谈下各自的优势及什么时候适用Bazel构建。",content:" img { width: 680px; padding-bottom: 1rem; }  1 前言 # 关于monorepo、multirepo的争论不绝于耳，至于采用哪种方式进行管理，要因地制宜地选择最合适的方案，要看到其优势，也要看到工具建设和迁移的成本。这里重点谈下各自的优势及什么时候适用Bazel构建。\n1.1 monorepo # 如果团队采用的是希望改善代码复用、希望让烂代码无处遁形、希望构建一致的CI/CD标准并落地、希望更好地沉淀经验、希望更好地促进团队成员成长等等，考虑到这些，似乎monorepo是更好的代码管理方式。\n但是也要考虑代码管理的规模、是否多语言技术栈、如何保证高效、封闭、可重复的构建。\n虽然google、uber、twitter等很多国内外大厂都采用了monorepo方式进行管理，但是也要看到这背后投入的大量的基础工具、平台的建设，这些并不是每个公司、团队所能予以支持的。目前开源的技术方案也并非完整的解决方案。\n谷歌为什么采用单仓：Why Google Stores Billions of Lines of Code in a Single Repository\n1.2 multirepo # multirepo每个仓库代码规模小，灵活易管理，做什么调整也很方便，也不需要特别重的基础工具、平台的支持，当然如果有大规模代码检索等之类的工具加成，也算锦上添花。\n对于小仓模式、大仓模式之争，微信同事曾经有专门做过一个具体的小仓模式实践分享。\n1.3 构建系统 # 这个世界就没有所谓的银弹，当我们企图用一种看似不错的方案解决问题时，这种方案本身也会重新引入一些新的问题。所以量体裁衣、因地制宜很重要，希望我们能结合自身情况（基础平台、工程素养现状、业务场景、业务迭代效率、产品定位等等）选择合适的方案。\nps：我认为，monorepo的规模至少要做到部门及以上级别，否则真的就是费力不讨好。\n关于monorepo、multirepo的异同、优缺点这里就暂不讨论了，这里准备讨论下monorepo下的构建系统支持。\ngo一般用go module构建，java一般用gradle或者maven构建，c++一般用cmake或makefile构建…总之有很多类似的构建方式，现在是多语言同一个repo管理，如果依然各个语言各自一套构建系统的话，随着代码规模上升，会变得很难管理。\n一个好的构建系统必须需要解决如下几个问题：\n- 如何建模待构建目标的依赖清单；\n- 如何实现高效地构建；\n- 如何保证可重复地构建；\n- 如何解决多语言构建问题；\n目前来看，从互联网大厂及开源社区的反馈来看，谷歌开源的bazel应该是当前的主流方案。\n2 Bazel基础 # 本文后续讨论建立在开发团队基于“monorepo+multi-language”的背景下，应该如何使用bazel对trpc-go项目进行构建。与此无关的内容不予以讨论。\n2.1 为什么用Bazel # - 代码管理方式：monorepo\n- repo中包含多种编程语言开发的projects；\n- 自定义rules、target来生成文件，如通过pb生成pb.go（不提交代码版本控制）；\n- 通过封闭构建，来保证可重复构建；\n- 希望能实现更细粒度的增量构建；\n- 希望能实现分布式构建；\n- 希望能利用构建缓存避免不必要地重复构建；\n- etc；\nps：if using multirepo \u0026amp;\u0026amp; go build, forget bazel. it overkills your project.\n2.2 Bazel核心概念 # bazel的上手成本相对熟悉go module的同学来说，还是有一定的学习成本的，学习bazel并不轻松，但是随着实践并陆续体会到monorepo+bazel带来的好处之后，会发现bazel是非常好的一个构建系统。当然，也可能体会不到 :(。\n要想熟练使用bazel，理解其工作原理不可缺少的，我们先来了解下bazel构建的核心概念。\n2.2.1 WORKSPACE # WORKSPACE，是一个文本文件，位于repo根目录下，这样的repo也称bazel工作区。\nWORKSPACE文件，定义了工作区下项目依赖的构建规则、外部依赖等，bazel构建targets时需要的输入、BUILD文件都在工作区下搜索，构建targets的输出也是存储在工作区中。\nbazel运行过程中会在工作区根目录下生成名如“bazel-*”的多个目录，构建依赖、输出等就是存储在这些目录下。\n2.2.2 BUILD # BUILD，是一个文本文件，位于工作区根目录以及子目录下，用于定义package。BUILD文件用于描述待构建的targets，以及构建每个target的输入、输出。\n2.2.3 TARGET # TARGET，是构建目标的意思，它位于BUILD文件中，每个BUILD文件中可以有多个targets。\ntargets的类型是多种多样的，如cc_binary、cc_library、cc_test分别表示构建c++可执行程序、库、单元测试，java_binary、java_library、java_test分别表示构建java可执行程序、库、单元测试。\nbazel内置支持的语言数量是有限的，只支持c++、java、python，其他语言要通过扩展rules来支持，比如rules_go提供了对go语言的构建支持，rules_go中定义了go_binary、go_library、go_test分别构建go可执行程序、库、单元测试。\n同样地，我们也可以扩展rules来调用一些代码生成工具自动生成一些桩代码文件，比如根据pb文件自动生成pb.go、grpc.go，或针对trpc框架的pb.go、trpc.go、validate.pb.go、_mock.go文件等等。\n2.2.4 RULES # RULES，简言之就是一系列扩展规则，它允许我们扩展新的target类型。RULES的编写，是通过Starlark语言来完成的，Starlark是一门配置语言，特别适用于bazel rules的编写。后面我们会通过扩展rules来扩展trpc相关的target，以通过pb生成trpc框架需要的桩代码。\n2.2.5 可见性 # 编程语言提供了某些语言级别的可见性保证，如C语言可以利用static/extern来声明变量的链接属性（对编译单元内可见还是全局可见），C++、Java类提供了一些修饰符，Go提供了导出、非导出的支持。\nBazel内部定义了一些可见性的声明方式，允许在语言之上提供更进一步的控制。可能有些语言没有提供可见性保证，即便是语言提供了类似的保证，Bazel的这个能力也能使得我们对代码施加更进一步的控制。如Go package A导出了一个类型给package B使用（跨包，不得不导出，这是语言级别的限制），但是出于某种原因（如不打算长期维护）并不希望这个类型给更大范围的团队使用，就可以通过Bazel可见性来进行精细化约束。\n2.2.6 封闭构建 # 当开发人员写完代码本地编译成功了，代码提交后，其他人在自己的构建环境下却构建失败，可能原因有多种：\n- go版本不一致，如go1.13才引入了errors.Is/As/Unwrap等，他人构建环境可能是go1.12；\n- protoc及插件版本不一致，如protoc-gen-go旧版本不支持paths=source_relative选项可能导致生成的桩代码路径位置错误，编译时引用失败；\n- mockgen版本不一致，如新版本要求go.mod已初始化，反之则会mock桩代码生成失败，go test因为缺少必要mock代码而构建失败；\n- etc；\n类似的原因还有很多，无法一一列举，我们应花功夫消除这些破坏可重复构建的因素。封闭构建，简言之就是保证构建环境的一致，并保证制品的可重复构建。\n要实现封闭构建，就要识别当前构建中的这些破坏性行为，并予以消除，如将分散在各开发同学机器上的构建工具锁定一个稳定的版本并打包成构建依赖，在WORKSPACE中定义该依赖及版本，构建时自动拉取该依赖并用其进行构建。\n2.3 Bazel构建实践 # 理解了上述的一些Bazel核心概念之后，看几个使用Bazel来进行构建的工程实例，加深理解。\n2.3.1 Bazel构建demo # - Building a C++ Project: https://docs.bazel.build/versions/4.2.1/tutorial/cpp.html\n- Building a Java Project: https://docs.bazel.build/versions/4.2.1/tutorial/java.html\n- Building a Android Project: https://docs.bazel.build/versions/4.2.1/tutorial/android-app.html\n- Building a iOS Project: https://docs.bazel.build/versions/4.2.1/tutorial/ios-app.html\n把上述4个构建实例全部看完，应该已经大致掌握了Bazel的使用了。\n有可能读者并不熟悉C++、Java、Android、iOS，有可能只熟悉Go呢？即便熟悉，要想直接从go module迁移到bazel构建也还是有相当大的成本的。所以我们还是要单独介绍下如何一步步从go module迁移到bazel构建，然后我们再介绍最终沉淀下来的trpc-go项目构建方案。\n2.3.2 Bazel构建Go # Go语言支持 # 不同于使用Bazel构建C++、Java，Bazel支持的内置语言不支持Go，需要引入扩展的rules来支持Go构建，即：https://github.com/bazelbuild/rules_go，参考bazelbuild/rules_go readme在WORKSPACE中增加相应的starlark脚本即可支持到。\nBUILD文件中，也要从bazelbuild/rules_go中加载target定义，如go_binary、go_library、go_test，此时我们便可以在BUILD文件定义go相关的targets了。\nGo依赖管理 # go工具链有支持go的依赖管理，开发人员在写代码的时候，go工具链能够自动地协助开发人员更新go.mod、go.sum，是非常易用的。ps 当然关于go module的不足我们就不讨论了。\n以go1.16为例，当我们代码中import了某个外部依赖，当我们编译的时候，为了保证可重复构建，go1.16要求我们显示地通过“go get $dependency”的方式将依赖添加到go.mod、go.sum中。这个过程比较严谨，开发人员在确认没有什么风险的时候，也会通过“go mod tidy”来批量将依赖更新到go.mod、go.sum中（只是为了方便）。\n要知道，go mod对依赖的管理是基于源代码中的importpath分析来实现的，bazel中如果要描述go packages之间的依赖关系，也是要采取类似的方式的，但是谁来做这个工作呢？rules_go这个扩展的规则集。\n一般来说，我们是要通过go_repository来定义外部依赖的（包括别名、importpath、版本、hash），然后在go_binary、go_library的deps属性中引用这些外部依赖，但是联想go get逐个添加的情况，逐个手写也bazel go依赖是会很啰嗦的。\n能否像执行“go mod tidy”一样自动更新所有的依赖呢？gazelle！\ngazelle，即：https://github.com/bazelbuild/bazel-gazelle。它能分析go源码中的importpath来自动更新deps.bzl（外部依赖）并自动生成go_binary、go_library、go_test，同时还能自动填充这些targets的deps属性。如果项目中同时支持go module、bazel构建，gazelle也可以通过go.mod、go.sum来更新deps.bzl以及targets的依赖。\nGo桩代码 # 在微服务开发中，RPC通信模式是当下主流方式，通信双方基于同一份IDL生成rpcstub文件，如grpc框架需要基于pb文件生成pb.go、grpc.go。pb也不属于bazel官方支持的语言，也是需要通过引入额外的rules扩展来支持对pb相关的桩代码的生成。\nrules_proto，即：https://github.com/bazelbuild/rules_proto，是对pb的扩展支持。\nps：大家可能会困惑，需要引入这么多扩展的rules？其实，这个只需要在WORKSPACE的根目录中配置一次就可以了，后续在工作区中开发，大家只关心BUILD文件编写就可以了。而且我们也会在工作区下放置一些shell脚本，运行脚本就能快速生成一个模板BUILD文件。这样使用起来就会方便多了。\nGRPC构建 # bazelbuild/codelabs，即：https://github.com/bazelbuild/codelabs，提供了一个比较完整的bazel构建demo，同一个WORKSPACE下包括了go、java、typescript、android、proto多个targets的构建，这也算个极简的monorepo了。\n2.3.3 构建trpc服务 # 我们将在第3节构建trpc服务中详细展开，我们推荐的目录组织方式、当前要做的工作，将来要进一步完善的工作。\n这里我们先简单梳理下，使用bazel构建trpc服务（先考虑trpc-go），我们需要考虑哪些：\ngo语言构建支持 # 前面我们介绍了基于rules_go扩展了对go的支持，以及基于go_binary、go_library、go_test来定义不同类型targets的方式。这部分内容对我们不再是挑战。\ngo module依赖管理 # 前面我们介绍了基于rules_go扩展了对go的支持，以及基于go_repository定义外部依赖并通过targets的deps对依赖进行显示声明，也介绍了基于gazelle进行辅助依赖管理。这部分内容对我们不再是挑战。\npb桩代码支持 # 前面我们提到了rules_proto对pb桩代码进行支持，通过rules_proto扩展的target类型，我们能生成pb.go文件，通过proto grpc扩展规则，我们也能生成grpc.go文件。但是trpc有点不同的是，trpc相关的桩代码生成逻辑，是通过统一的一个trpc命令行工具来生成的，包括：\n- $pb.pb.go：trpc调用protoc-gen-go生成；\n- $pb.pb.validate.go：trpc调用protoc-gen-secv生成；\n- $pb.trpc.go：trpc生成的适配trpc框架的rpcstub，作用等同于grpc.go；\n- $pb_mock.go：trpc调用mockgen生成；\n我们需要自定义新的规则集来支持trpc相关的代码生成逻辑，包括要定义对应的target类型，比如trpc_proto，其输入为pb文件，输出为对应的上述桩代码。trpc_proto该target应该作为trpc服务中go_binary、go_library、go_test的输入，准确地说是其trpc_proto的输出作为这几个target的输入。\nps：当然我们可以在将trpc_proto作为go_library的输入，让go_binary、go_test依赖go_library来完成与pb桩代码的链接，最终成功构建。\n现实比想象复杂 # bazel构建的掌握还是有一定学习成本的，当前公司里面，大范围采用monorepo+多语言开发的团队，采用bazel进行构建的实践并不多，借鉴加改进是必须的。\n依赖管理，并不如前文介绍那么简单，实际工程中依赖管理要复杂一些，要求对bazel的工作原理、扩展的rules的实现有更加清晰、完整的认识，否则构建失败将是家常便饭。\ntrpc工具的工作方式，安装加载配置文件、模板依赖$USER、$HOME，违背了bazel的封闭构建原则，需要进行定制化改造，以在bazel中正常使用。\nbazel构建，如果一不小心执行了bazel clean，那么后续再次构建将非常耗时，要拉取并构建大量的依赖工具，如protoc等等。大仓模式下，分布式增量构建、缓存是必须要开启的，否则与multirepo+go build相比构建效率严重下降。\n接触bazel时间不长、实践经验偏少，折腾两周，现仍存在一些未知事项。bazel的掌握，可能需要在推行monorepo+bazelbuild的团队进行适当的培训，加以指导。\n3 Bazel构建trpc # 这里介绍bazel构建trpc服务（如无特殊提及，这里的trpc服务均代指trpc-go服务），包括独立的trpc服务的构建、后续工程目录的组织方式、后续协议的托管方式，以及其他保证封闭构建、提高构建效率所需要做的工作。\n3.1 构建trpc服务 # 3.1.1 快速体验 # 为演示如何使用bazel构建一个trpc服务，准备了一个demo，以截图的形式提供。\n项目目录结构如下图所示：\n和trpc命令生成的模板工程有何不同？\n- 根目录下多了两个文件：WORKSPACE、BUILD文件；\n- stub目录下多了BUILD文件；\n- stub目录下少了hello.proto相关的go文件、go.mod文件、go.sum文件；\n确保已经安装bazel（macOS可以brew install bazel），cd到项目根目录：\n- 执行“bazel build //:helloworld”，即完成服务二进制程序的构建；\n- 执行“bazel run //:helloworld \u0026ndash; -conf=trpc_go.yaml”来启动程序；\n- 执行“bazel test //:helloworld_test”，将构建失败，现在还没有支持mock代码的生成；\nFIXME mockgen执行失败\n3.1.2 配置WORKSPACE # 如下图所示，通过注释部分可以看到做了哪些工作：支持go语言、通过gazelle辅助go依赖管理、支持protobuf、支持我们自定义的trpc。需要注意的是自定义的trpc是放置到该示例工程的trpc目录下的，将来推行大仓时，我们可以将其放在monorepo的根目录下。\n3.1.3 配置BUILD # 项目根目录下的BUILD中定义了该trpc服务的几个构建目标：\n- gazelle是为了辅助从go.mod文件自动更新依赖、targets中的deps属性的；\n- go_binary定义了要构建的可执行程序，它依赖helloworld_lib这个target，这个target由go_library定义，这里的这个定义实际上是所有源代码构建而成的一个库；\n- go_library定义了一个库，它被go_binary引用，它里面包含了一系列要构建的源文件，有工程内部的main.go、hello_service.go，也有外部依赖@repo//path-to:target，也有版本控制系统中未纳入的一些文件编译出的库，便是//stub/\u0026hellip;./helloworld:helloworld-stub-lib，这个依赖在stub/\u0026hellip;./helloworld/BUILD中定义，其实它把pb文件对应的pb.go、trpc.go编译成了可链接的库；\n- go_test定义了单测测试相关的构建，这里先不细看；\nok，现在我们先大致了解这几个target是怎么回事即可。\n继续看下stub/\u0026hellip;./helloworld/BUILD文件中的配置信息：\n- 加载了工作区根目录下的trpc/defs.bzl，其中定义了一个函数trpc_proto，这其实描述了一个新target类型的定义；\n- 使用trpc_proto定义了一个新的target，其输入为stub目录下的hello.proto文件，其输出当前由trpc_proto的生成文件列表决定，当前只生成pb.go、trpc.go；\n- 加载rules_go并通过go_library定义了一个新的target，这个target将trpc_proto的输出作为作为，同时该target也声明了一些外部依赖，该target编译出的库最终其导入路径为：脱敏处理，${importPath}/trpcprotocol/helloworld，通过这个importpath来帮助go编译器进行链接；\n到这里，我们了解了WORKSPACE、BUILD文件的大致配置，应该能理解bazel编译过程中的大致工作方式了。\n接下来我们再来看下我们自定义的trpc_proto target类型是如何定义的。\n3.1.4 扩展RULES # load(\u0026quot;//trpc:defs.bzl\u0026quot;, \u0026ldquo;trpc_proto\u0026rdquo;), trpc_proto实际上只是一个starlark编写的函数，就放在工作区根路径下的trpc/defs.bzl文件中。\n可能读者对starlark不熟悉，但是阅读应该能知晓其含义的。trpc_proto这个函数就是将定义的target中的属性作为参数传入，然后执行。该函数确定了要输出的文件列表，然后调用trpc_create函数对pb文件进行处理。trpc_create函数内部调用了trpc命令完成对pb文件桩代码的生成逻辑。\n但是这些工具从哪里来呢？通过trpc_create函数中引用的$$TRPC的值，可以确定trpc命令行即为//trpc:trpc，通过trpc/BUILD文件可以确定，//trpc:trpc指的就是//@trpc//:trpc。\n那@trpc这个外部依赖是从哪里来的呢？@trpc这个外部依赖又包含了哪些内容呢？\n外部依赖都是在WORKSPACE中定义的（或者由starlark函数从其他文件中加载而来），我们看下WORKSPACE文件中对该外部依赖trpc的定义，其实@trpc是引用的腾讯软件源上的一个压缩包，http_archive会下载该压缩包放到bazel-*临时目录中，并解压。\n这个压缩包中包含的内容都有哪些呢？可以下载下来看看，包含了trpc、protoc等常用命令以及pb文件。这个压缩包的内容，实际上是由 https://{脱敏处理}/go-kits/bazelbuild下的publish.sh脚本构建并推送到腾讯软件源的。\n上述http_archive中还有个配置项build_file，它表示将//trpc:BUILD.trpc.bazel作为该外部依赖@trpc的BUILD文件，这个文件干了什么呢？它定义了该package（BUILD对应package）的可见性，这样我们才能引用其下的一些trpc、protoc等二进制工具以及include/**下的pb文件。\n3.2 沉淀构建脚本 # 为方便编写WORKSPACE、BUILD文件，需定义几个shell脚本，帮助快速生成该类文件：\n- 沉淀常用的WORKSPACE配置到生成脚本generate_workspace.sh，放到公共库目录下；\n- 沉淀常用的BUILD配置到生成脚本generate_build.sh，放到公共库目录下；\n开发人员不管是定义新的WORKSPACE，还是在现有WORKSPACE中编写BUILD，借助上述脚本可以快速生成对应的文件模板，稍加修改便是。\n3.2 目录组织方式 # 如果后续推行大仓，大致的目录组织方式是这样的（红色部分与trpc构建相关）：\n- monorepo根目录下放置上述WORKSPACE；\n- monorepo根目录下放置上述自定义的trpc相关的bazel定义；\n- monorepo根目录下组织子文件夹，如大仓是BG级规模，子文件夹可用来区分部门、业务；\n- 部门、子业务下的项目按projects维度进一步组织子文件夹；\n- project维度就可以对应到我们的trpc微服务了；\n- project下的文件夹（go package)对应bazel package，需编写BUILD文件；\n- project下的go.mod、go.sum其实都可以删除了，保留应该也可以；\n- project下的stub下仅保留pb文件；\n- project下不保留stub目录，协议托管在rick，通过go_repository下载，project下BUILD中增加原stub/\u0026hellip;./helloworld/BUILD中target定义即可；\n- project下的go.mod、go.sum其实都可以删除了，保留应该也可以，辅助gazelle生成依赖；\n- @trpc常用工具，不再依赖开发个人、公共构建机上安装的资源，统一在软件源维护；\n- 其他；\n3.3 协议托管方式 # 3.3.1 随项目stub子目录 # 这种方式前文已经演示过了，可以支持到。\n3.3.2 协议管理平台托管 # 协议管理平台也是托管到工蜂，可以通过go_repository下载，也可以支持到。\n这两种协议托管方式都是可以支持到的。\n3.4 保证封闭构建 # 通过封闭构建来保证可重复构建，我们需要识别可能破坏封闭构建的一些行为，将其移除。\n目前观察，trpc命令及其依赖的工具的一些工作方式，可能有违背封闭构建的行为，如强依赖$USER、$HOME来安装加载配置、模板信息。工具侧可能需要进行对应的改造。\n3.5 改善构建效率 # 如果推行大仓+bazelbuild，需要把bazel的分布式构建、增量构建、缓存优势发挥出来，bazel cluster需要提前做相应的规划。\n掌握bazel构建和简单的go build管理起来，还是有一定的上手成本的 :)，想让大家使用monorepo+bazel build而非monorepo+go build，还是需要尽快做准备、优化bazel构建体验。说一千道一万，不如美好的初体验。\n4 总结 # 本文总结了Bazel构建的优势、核心概念、示例demo，以及使用Bazel构建trpc服务的一点实践总结，以及后续可行的目录组织、协议托管方式、其他相关工作。\n对Bazel相关的最佳实践还需要进一步去学习、探索，以充分发挥Bazel构建的优势。\n最后也感谢小伙伴等给予的反馈、提供的可供参考的bazelbuild工程。\n5 参考内容 # 1、官方bazelbuild文档\n2、bazelbuild/codelabs\n3、book: beginning bazel\n4、PCG个别团队的go bazelbuild实践，go项目bazel迁移\n​ TEG个别团队的bazelbuild实践：https://脱敏处理/yak/yak2\n5、其他km文章及外部分享\n6、Bazel学习笔记\n"}),a.add({id:177,href:"/tags/hermetic/",title:"hermetic",description:"",content:""}),a.add({id:178,href:"/tags/monorepo/",title:"monorepo",description:"",content:""}),a.add({id:179,href:"/tags/multirepo/",title:"multirepo",description:"",content:""}),a.add({id:180,href:"/tags/dma/",title:"dma",description:"",content:""}),a.add({id:181,href:"/tags/io/",title:"io",description:"",content:""}),a.add({id:182,href:"/tags/sendfile/",title:"sendfile",description:"",content:""}),a.add({id:183,href:"/tags/splice/",title:"splice",description:"",content:""}),a.add({id:184,href:"/tags/zero-copy/",title:"zero copy",description:"",content:""}),a.add({id:185,href:"/blog/2021-09-09-%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9B%B6%E6%8B%B7%E8%B4%9D%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/",title:"常见的零拷贝优化技术",description:"本文介绍了零拷贝是什么、零拷贝优化的目的以及常见的零拷贝手段。",content:"在关注IO性能时我们经常听到零拷贝，那么零拷贝到底是什么呢？为什么要做零拷贝？又有哪些方案？本文就一起来看下。\n零拷贝技术一般可以分为两类 #  devices（disk、nic）和kernel buffer之间的数据拷贝，一般可以通过DMA（直接存储器访问）来优化掉，既能够避免中断CPU减轻CPU负载，也能够直接读写内存减少数据从nic到cpu再到kernel buffer的拷贝动作； kernel buffer和application buffer之间的数据拷贝；  说优化拷贝一般是去优化cpu拷贝，DMA拷贝是无法避免的。零拷贝则强调的是kernel buffer和application buffer之间的拷贝，零拷贝并不是说整个过程中完全有没有数据拷贝，在kernel space还是发生拷贝，当然下面提到的sendfile+DMA硬件支持分散读/聚集写情况下能优化掉kernel buffer之间的拷贝。\n然后明确下优化拷贝的原因 #  使用系统调用的次数影响到上下文切换次数，上下文切换会带来一定的开销，如read、write组合起来完成磁盘数据读取、网络发送，就要切换4次，而且read、write要重复很多次，上下文切换开销就不能完全忽视； 数据拷贝，主要是说利用cpu来拷贝，cpu势必要中断原来的任务去做拷贝的事情，move来move去，干了些杂活，理想情况下是希望尽可能做更多的事，当然不一定能完全避免cpu拷贝，但是能让拷贝的数据量减少点还是值得的；  零拷贝优化一方面是要优化掉kernel buffer和application buffer的数据拷贝问题，一方面也要考虑下如何尽可能减少cpu拷贝对程序停顿的影响。\n常见的拷贝优化方案 # 这里解决kernel buffer和application buffer之间数据拷贝的常用办法有以下几种，以读取磁盘数据发送到socket为例说明：\nmemory mapping # mmap系统调用，read的时候，dma从磁盘发送数据到kernel buffer，mmap根据fd映射对应的kernel buffer和application buffer，省掉一次考拷贝。write的时候，数据从kernel buffer直接拷贝到socket buffer再到nic buffer;\nshared buffers in kernel memory space # 这里希望能再次优化掉mmap方案中write时从kernel buffer到nic buffer的拷贝，在kernel space中建立一个共享内存区域buf，dma传送数据到这个buf的b_data指针指向的位置，write的时候使用dma从这个buf的m_data位置开始写，其实b_data、m_data共享了底层内存区域。相当于一个写指针、一个读指针。通过这种方式优化掉了kernel space到nic space的拷贝；\nshared buffers between user and kernel space # linux sk_buffers结构，其中有个指针记录着要发送的数据（application buffer中）的地址，避免了从application buffer到kernel buffer的拷贝；\ndifferent system calls, sendfile, splice, etc # 先说sendfile，sendfile允许在fd之间直接传送数据，进出sendfile上下文切换只需两次，数据直接从源fd对应的kernel buffer（dma从设备上拷贝过去）到目的socketfd的socket buffer拷贝，完全绕过了应用程序buffer及其拷贝；\nsendfile with DMA Scatter/Gather copy # 上面sendfile存在一个从kernel buffer到socket buffer的cpu拷贝，如何优化掉？在硬件支持下，kernel buffer可以只把这个buffer的fd信息发送给socket，这里就避免了数据拷贝，这里的kernel buffer可以是多个，那就发送多个buffer的fd信息给socket，然后DMA借助分散读聚集写直接从上述kernel buffers拷贝到nic buffer。这样完全消除了cpu拷贝动作，避免了对cpu的中断；\nsplice # 从一个fd到另一个fd拷贝数据，先要在两个fd之间通过pipe系统调用构建一个管道，管道在内核中就是一个buffer只不过返回读端、写端在userspace中供读写。splice就是从源fd的kernel buffer写到pipe buffer的写端，然后再从这个pipe buffer的读端拷贝数据到目的fd的kernel buffer。和前面最牛对技术方案相比，这种方案和前面这种sendfile+DMA分散读聚集写相比，kernel space中多了两次cpu copy，好处是可以不需要硬件的支持；\nhardware support # 前面已经提到过了DMA相关的加成，可能还有其他方案；\n总结 # 本文总结了零拷贝是什么、目的是什么以及有哪些常见的优化手段，除了软件层面的方案，在硬件加成下还可以做更好的方案。其实不同零拷贝技术对安全加密、过滤也有不同的影响，这部分内容如果有机会再总结分享。\n参考内容 #  https://www.uidaho.edu/-/media/UIdaho-Responsive/Files/engr/research/csds/publications/2012/Performance-Review-of-Zero-Copy-Techniques-2012.pdf mmap：https://man7.org/linux/man-pages/man2/mmap.2.html splice/tee：https://www.kernelhcy.info/?p=202 splice: https://man7.org/linux/man-pages/man2/splice.2.html  "}),a.add({id:186,href:"/tags/etcd/",title:"etcd",description:"",content:""}),a.add({id:187,href:"/tags/kvstore/",title:"kvstore",description:"",content:""}),a.add({id:188,href:"/tags/raft/",title:"Raft",description:"",content:""}),a.add({id:189,href:"/tags/wal/",title:"wal",description:"",content:""}),a.add({id:190,href:"/blog/2021-09-04-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8raft%E5%BC%80%E5%8F%91%E5%BC%BA%E4%B8%80%E8%87%B4kv%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/",title:"如何使用raft算法开发强一致kv存储系统",description:"...",content:"本文内容 # 本文结合etcd源码来进行介绍，etcd/contrib/raftexample提供了一个基于etcd/raft实现的kv存储系统。从该示例出发，我们来看一看如何基于raft算法开发一个强一致的kv存储系统。\n看完本文的源码分析后，上手一个raft强一致系统开发就不是什么难事了。\nps：假定读者已经阅读并理解了raft论文，这里有我的批注版的In Search of an Understandable Consensus Algorithm.pdf，读起来可能会好理解点。\netcd/raft # etcd服务端程序入口：see 源码\n 启动过程中区分当前节点类型：根据data-dir目录下的目录名member/proxy/empty来区分，然后启动etcd实例或者proxy； 启动etcd服务节点：startEtcd这个函数，逻辑主要包括启动供集群节点间通信的rafthttp服务，以及供客户端请求的服务； 启动etcd proxy：startProxy这个函数，逻辑主要是启动etcd代理；  etcd哪些部分值得学习：\n etcd proxy从项目功能上来说虽然很重要，但是从学习角度来说没那么有价值，不看这个； etcd server从项目功能上来说是核心，但是我们也没有必要学习所有的请求处理逻辑，重点是关注读写操作时如何基于raft实现强一致； raft：这部分是raft算法的核心实现，从理解raft论文到算法工程化需要额外做出巨大的优化，这些知识点往往是通用的，重点掌握；  raft部分：\n pb协议：  raft peers的通信协议，see 源码； raft算法中提到核心的几个rpc就是Vote、AppendEntries，但是工程中需要考虑更多，详见上述pb中的enum MessageType； 上述pb中的message Message类型定义了rpc通信过程中的请求/响应，不同rpc通过MessageType type字段区分；   状态机：  raft实现数据一致性是通过replicated log（复制日志）实现的，这里的replicated log有时也称为WAL（write ahead log）； raft算法中，每个节点raftnode可能处于以下状态中的一种：follower、candidate、precandidate、leader； raft算法中，每个节点的状态可以通过一个状态机来建模；    了解了这些基础知识之后，我们结合etcd/contrib/raftexample来解释下raft如何选举，以及leader遇到写操作如何保证数据强一致。\netcd/raft如何进行leader选举 # newRaftNode newRaftNode，see 源码，这个函数包括创建一个var rc raftNode，然后rc.startRaft()，这个函数包含非常重要的几个部分：\n startNode，see 源码，这个主要是建立好raftnode启动时的一些初始状态转换，有一个for事件循环处理，如改变raftnode的状态：tick函数、step函数，以及一些message的处理等等； serveRaft： serveChannels：see 源码  startNode:\n 如何查看这部分源码呢，首先从启动一个raftnode开始吧：see 源码； StartNode函数启动一个raftnode，节点刚启动的时候state都是follower：see 源码； StartNode→Bootstrap(peers)通过配置告诉当前raftnode有多少个raftpeers，然后这些raftpeers加入与当前节点所在的集群属于变更配置，也要记录到raftlog中； raftnode真正跑起来是在这里：see 源码，这里有个大的for循环，node的主要逻辑都在这里了；  tickElection：for/switch-case n.tickC，选举逻辑，此时如果当前raftnode为follower或者candidate吧，此时的tick函数为tickElection，如果选举超时时间过了并且没收到leader的heartbeat来重置选举超时时间，此时会将MsgHup消息类型传入step函数中，将当前follower变为candidate发起选举：see 源码。这里的选举在raft论文中是直接就是选举动作，但是工程上做了优化，引入了一个可选的两阶段选举prevote。虽然可以tick是触发了tickElection，但是这个后续执行中会检查当前节点是否有资格成为leader，不一定有资格（比如自身的WAL不满足条件）。 假如有资格发起选举，则会调用becomeCandidate，会将当前raftnode的term+1，并且step函数变为stepCandidate。然后会调用r.poll来判断是否胜选：see 源码，其实这里是判断的自己给自己投票的话能否胜选，对于single raftnode的集群有用，假如是多节点集群那么这里无法胜选，继续看。ps：如果胜选就becomeLeader成为leader了。如果不是单节点，就要通过r.send发送投票给各个peers：see 源码。这里的r.send并不是真的网络发送，而是记录到r.msgs里面等下处理这里的r.msgs。注意这里r.send的时候已经编程了MsgVote类型了，表示投票请求，后续也应该收到MsgVoteResp。 r.msgs什么时候处理呢？还是前面我们提到的这个大循环体，每轮循环都会检查r.msgs中有没有message要处理：see 源码，这里的函数n.rn.HasReady()方法检查到len(r.msgs)\u0026gt;0，则认为有消息要处理，这个消息最终会被包装到一个Ready{}事件中，这个事件会被丢到n.readyc这个chan中，什么时候处理在下面serveChannels中介绍。 becomeLeader：see 源码，step函数变为stepLeader，tick函数则变成tickHeartbeat，意味着当前为leader需要给followers定时发送heartbeat来重置它们的选举超时时间，那么heartbeat是什么形式的呢？其实就是通过appendEntry，只不过entry为空，用这种空的entry来表示心跳。leader就要担负起write请求的重任了。 但是如果没胜选的话，raftnode的状态就是candidate，step函数未stepCandidate，下面会继续用到。    serveChannels： 前面关于r.msgs的消息没跟踪到在哪里处理的，我们看下是不是在serveChannels里面？ serveChannels: see 源码\n 这个函数里面也有一个for事件循环，当它发现rc.node.Ready()有var rd Ready{}事件可处理时，如果rd上有非空的snapshot，就写入storage，然后将rd.Entries也记录到rd.HardState，然后将rd.Entries也写入storage，最后将rd.Messages发送到peers。我们感觉voteMsg是在这个时候发送给peers的，到底是不是呢：see 源码。是的，这里的rd事件就是从raftnode.Ready()从发从其raftnode.readyc这个channel中取出来的。取出来后通过transport发送出去，这样voteMsg就发送出去了，那么投票的响应又是什么时候收到、什么时候处理的呢？ startRaft/AddPeer的时候会调用startPeer，内部会开始循环收包，收peer发来的raftmessage放入一个recvc chan中，startPeer中专门开启了一个goroutine来检查recvc中有没有peer发送来的消息，比如peer发送给我们的voteMsg的响应包：see 源码。这里通过raft.Process(ctx,m)对raftmessage进行处理。如何处理是在这个示例代码中定义的：see 源码，即调用step函数进行处理。我们再往回看下，发送这个消息前已经把节点的step函数修改为了stepCandidate，那我们再看下这个函数里面干了啥，猜测应该有判断是否收到多数投票确认的逻辑； stepCandidate：see 源码，我们不考虑可选的prevote阶段，很显然这个消息MsgVote的响应类型应该是MsgVoteResp，如果是的话，就继续r.poll检查下是否胜选吧，如果胜选了，则自己becomeLeader，然后广播appendEntries，这里append是干啥，是为了通治其他peers更新commit index吧。  这样leader选举就完成了！！！\netcd/raft leader执行put操作如何保证强一致 # 用etcd/raft实现强一致的系统示例：https://github.com/etcd-io/etcd/tree/main/contrib/raftexample。我们不妨从这个项目入手来看下到底是怎么工作的。上述项目是一个暴露http接口的kv强一致存储系统。\n接下来重点看一个leader负责执行命令put \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;时的执行逻辑，是怎样的，领略下这个过程中raft扮演的角色。 put命令是通过http put method实现的，see 源码。\n这里的处理逻辑也很简单，它直接调用了h.store.Propose(key, string(v))，h.store是一个kvstore，这里的Propose是干嘛呢？这里就可以跟raft算法中的MsgProp关联起来了，还记得吗？MsgProp这种消息类型是用来appendEntries的。这里的思想就是WAL（write ahead log）的思想，先把动作记录到日志中，后面在通过日志来更新状态机。状态机的状态都包含什么呢，我们前面已经知道有各种状态的流转，那么这个日志中记录的数据存储在哪呢？\n就是这里的kvstore啊！一个raftnode启动后要把快照、日志中记录的事件还原到一个特定的存储中，这个示例中就是一个内存中的kv数据结构。h.store.Propose(key,string(v))首先异步地调用kvstore.Propose(key,val)将数据写入到proposeC这个chan中：see 源码，然后再异步地从中取出来：see 源码，通过rc.node.Propose(ctx, prop)，转入raft.node.Propose实现：see 源码，这里的n.stepWait方法将MsgProp消息类型以及要写入的日志数据传给stepWait，这里面将消息写入到raftnode.propc就完事返回了。\nstartPeer从这个propc chan中取出消息m，然后r.Process(ctx, m)去处理，r.Process方法是在示例代码中自定义的，see 源码，通过r.Process进入step函数又来到r.Step(m)，此时raftnode.Step函数是什么呢？赶紧看看发送MsgProp消息时又没有更改raftnode.Step，没有，那这个Step应该是stepLeader\u0026hellip;没错，沿着stepLeader一路看下来：see 源码，这里果然是leader让peers appendEntries的动作，干了什么呢？\n首先当前raftnode.appendEntries，把MsgProp消息里的日志项（可能有多条）先追加到自己的log entries里面，然后bcastAppend发送给所有的peers让它们去append entries，它们追加成功后肯定回回包MsgPropResp消息类型的消息。我们看看这个消息是在哪里处理的？感觉应该也是在startPeer函数中的收包逻辑里面。那应该也是从recvc chan中取出回包处理。\n哈哈，看半天竟然没搜索到MsgPropResp消息类型，前面读源码时有个细节漏掉了。sendAppend的时候实际上会把消息类型改成MsgApp（MessageAppend）去追加日志，followers处理完成后响应一个MsgAppResp消息类型。对于leader raftnode，收到消息后触发状态转换，又要执行其step函数，此时step函数还是stepLeader，发现消息是MsgAppResp，准备处理：see 源码。\n我们先考虑正常情况，leader收到响应发现follower在WAL中记录了发送的log entries，leader收到此响应后就会决定是否要更新该follower的next index（下次要发送的log entries开始索引）。然后判断是否可以更新leader的commit index了，更新了之后对client的读请求就可见了。leader更新了commit index之后也要通过bcastAppend通知followers更新commit index。\n这些已提交索引之前的log entries会被发布到示例代码中的commitsC chan中，然后有一个goroutine专门读取这上面的commitC并把其中的entries读取出来，应用到我们的kvstore中，这样存储的一些数据就从WAL日志转化为了内存数据结构中的真实数据，可以对外提供查询服务了。\n小结 # 大致就是这些内容吧！感兴趣的继续深挖下raftexample+raft实现吧。感觉自己已经理解了raft的核心思想以及如何使用raft来开发强一致存储系统了，读者是不是也有同感呢:)\n"}),a.add({id:191,href:"/tags/techlead/",title:"techlead",description:"",content:""}),a.add({id:192,href:"/tags/technical-leadership/",title:"technical leadership",description:"",content:""}),a.add({id:193,href:"/blog/2021-08-17-%E5%9F%B9%E5%85%BB%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/",title:"培养技术领导力",description:"技术领导力的3个层次：leading self, leading others, leading organizations，你准备好了吗？",content:"关于如何培养自己的技术领导力，文章technical leadership: getting started 中作者分享了自己的心得。\n读后深有感触，现在做一个简单的总结。总结不拘泥于原文结构，根据个人感悟重新整理下。\n塑造领导力的3个层次：leading self，leading others，leading organizations。没有人天生就是专家，在成为专家的路线上，我们就要沿着这3个层次慢慢锻炼提升自己。\n成为专家 # 想起10000小时定律，要成为领域专家是需要付出大量的实践的，过程中要不断提升自己的实践能力、技术视野、对公司业务价值及目标的理解。能否成为真正的专家，靠的不是运气，而是稳定持续地有力输出，again and again and again…consistently！这里就要求自己先做到leading self，把自己做到最好，起到表率的作用。然后再尝试靠技术领导力去leading others，leading organizations。\n善于分享 # 提高这里的输出，也不能总是依靠个人能力。如果你想走得够快，你可能选择自己走；如果你想走得更远，那必须依靠团队的力量。对于掌握的知识、技能，藏着掖着并不是在帮你，因为你没有正向激励到身边的人，没有在恰当的时候塑造有力的技术影响力，更没有帮助大家提升到更接近的段位来一场更漂亮的团战。是时候地分享自己掌握的知识、技能，也减少他人对自己的依赖，侧面上可以赢取更多的时间放在更有价值的事情上。知识是没有穷尽的，总会有更值得钻研的领域等着去探索。\n有效沟通 # 有效沟通，并不是说要如何快速地结束沟通，而是如何高效率地达成共识。当然有些沟通不能达成共识，但是也要有效地同步双方掌握的问题背景、信息，完成意见的交换，仍应当放在沟通目的的第一位。看待问题要避免掺杂过多主观成分，客观看待问题，以目标为导向，更有助于促成有效沟通。有效沟通是表达自己、了解他人的前提，也是能团战的必要条件。\n加油！加油！加油！\n"}),a.add({id:194,href:"/tags/%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/",title:"技术领导力",description:"",content:""}),a.add({id:195,href:"/books/golang/",title:"Go语言设计实现内幕",description:"作为一名Go语言开发展，很庆幸见证了Go语言的逐渐发展壮大，现在也赢得了很多开发者的青睐。作为一名Gopher，很难不被Go语言的设计实现所着迷，或者说，了解这里的设计实现细节，可以让我们学到更多，也可以写出更好的代码。",content:"作为一名Go语言开发展，很庆幸见证了Go语言的逐渐发展壮大，现在也赢得了很多开发者的青睐。作为一名Gopher，很难不被Go语言的设计实现所着迷，或者说，了解这里的设计实现细节，可以让我们学到更多，也可以写出更好的代码。\n 在我学习Go语言的过程中，也阅读了不少其他开发者写的文章，也做了很多源码分析、跟踪调试，怎么说呢？了解这些细节其实并不是最重要的，了解背后的设计方案、设计思想才是最有价值的。细节总是在变化中的，但是设计方案、思想的大方向是更加明确些的。我逐渐将之前收集、书写的内容进行分类整理，就变成了当前的电子书。\n本内容涉及大量的Go语言设计实现方面的内容，包括编译器、链接器、运行时调度、内存分配器、垃圾回收器、标准库等等，尽量保证知识点的系统性，《Go语言设计实现内幕》。\n欢迎阅读，如果您在阅读过程中发现有错误、疏漏、建议，不要犹豫，请给我提issue。\n"}),a.add({id:196,href:"/tags/8%E6%9D%A1%E8%B0%AC%E8%AE%BA/",title:"8条谬论",description:"",content:""}),a.add({id:197,href:"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/",title:"分布式",description:"",content:""}),a.add({id:198,href:"/blog/2021-07-05-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%978%E6%9D%A1%E8%B0%AC%E8%AE%BA/",title:"分布式计算的8条谬论",description:"分布式计算的谬论，是由L Peter Deutsch以及其他Sun Microsystems的同行总结的几条分布式计算初学者经常误以为成立的判断。",content:"分布式计算的谬论，是由L Peter Deutsch以及其他Sun Microsystems的同行总结的几条分布式计算初学者经常误以为成立的判断。\n这8条谬论分别是：\n 网络是可靠的； 通信时延为0； 带宽是无限的； 网络是安全的； 拓扑不会改变； 只有一个管理者； 传输成本为0； 网络是同构的；  陷入这8条谬论会导致如下后果：\n 开发的软件程序中针对网络的错误处理不够健壮，遇到网络错误时程序会stall或者无限等待响应，即便是网络恢复了，程序也不能自行恢复或需要手动重启； 忽视通信时延以及可能导致的丢包问题，应用层、传输层开发人员开发的程序对于传输流量大小没有任何限制，会导致严重的的丢包或者带宽浪费； 流量的发送方，忽视带宽本身的限制，会导致一些瓶颈； 忽视网络安全容易被恶意用户和不断演进的能绕过安全软件的恶意程序蒙蔽双眼； 网络拓扑的改变也会对网络带宽和通信时延产生影响，因此会产生相似的问题； 可能会出现多个管理员，它们可能会制定出相互冲突的策略，流量的发送方需要知道这里的“策略”才能按预期路径传输，但是策略出现冲突，会对传输造成影响。 构建、维护一个网络或者子网的隐藏成本不能被忽略，在预算中必须清晰地列出来，而不能出现突然地削减； 如果假定一个系统是同构网络，那么可能会导致这里列出的前3个谬论；  这8条谬论的诞生：\n这8个谬论大部分由来自Sun Microsystems公司的L. Peter Deutsch提出，1994年它提出了前7个。不过Bill Joy和Tom Lyon在那时就早已经将前4条作为网络计算的谬论了。在1997年，James Gosling（Sun员工，也是Java之父）添加了第8条谬论。\n"}),a.add({id:199,href:"/tags/2pc/",title:"2PC",description:"",content:""}),a.add({id:200,href:"/tags/3pc/",title:"3PC",description:"",content:""}),a.add({id:201,href:"/tags/base/",title:"BASE",description:"",content:""}),a.add({id:202,href:"/tags/cap/",title:"CAP",description:"",content:""}),a.add({id:203,href:"/tags/concenus/",title:"Concenus",description:"",content:""}),a.add({id:204,href:"/tags/flp/",title:"FLP",description:"",content:""}),a.add({id:205,href:"/tags/paxos/",title:"Paxos",description:"",content:""}),a.add({id:206,href:"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/",title:"分布式系统",description:"",content:""}),a.add({id:207,href:"/blog/2021-07-01-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B%E5%B8%88roadmap/",title:"分布式系统工程师roadmap",description:"广大后台开发同僚们，想必都经历了这样那样的分布式系统实战，可能遇到过数据一致性问题，可能遇到过事务一致性问题，可能遇到过集群变更问题……似乎大家没有深厚的分布式系统理论，也在实践中渐渐成长为了有经验的分布式系统工程师。但是，“有经验”也可能是只是经验主义，并不是真的知道了“真理”。这里并不是要做个老学究，而是说深入理解了分布式系统理论后，实践中会更加得心应手。本文整理汇总了一些比较重要的分布式系统教程，以及工程参考范例，理论与实践相结合想必会有更大收获。",content:"如何成为一名资深的分布式系统工程师，需要补齐哪些理论基础，又需要哪些工程方面的锻炼？本文原文见 Henry Robinson 的文章 distributed systems theory for the distributed systems engineer，我觉得是一个很不错的roadmap，沿着这个脉络半年下来，还是很有收获的……继续:)\n1 掌握分布式背后的相关理论 # 可能会有人甩出很多论文，FLP论文、Paxos论文、Raft论文、拜占庭将军相关的论文\u0026hellip;相关的论文可以摆出很多，但是论文是有一定深度的，是非常严谨的论述，对于攻读PhD的同学有帮助，但是对于一名从事分布式系统工程的同学真的有必要全部掌握吗？应该看多少论文，毕竟经过了那么多年的发展、沉淀呢？ 作为一名分布式系统工程师，搞明白需要掌握哪些理论，比单纯了解有哪些论文更重要。\n2 First Steps # 下面的4个文集很好地介绍了构建一个分布式系统要面临的挑战，它们共同概述了分布式系统工程师必须克服的一些技术上的困难，并为后面章节中更详细的说明奠定了基础。\n Distributed Systems for Fun and Profit，介绍了分布式系统的基础知识，包括时间在分布式系统中扮演的角色、不同的复制策略等； Notes on distributed systems for young bloods，不是纯理论介绍，在理论和实践中做到了一个不错的平衡，为后续更深入学习打好基础； A Note on Distributed Systems，一篇很经典的论文，解释了分布式系统中为什么不能总把远程交互对象当做本地的对象，让读者理解分布式场景中的问题和挑战； The fallacies of distributed computing，分布式计算的8个谬论，为分布式系统设计人员设计系统打下基础；  我们需要了解两个重要属性的含义，“safety”和“liveness”：\n safety，该属性表示不会有坏的事情发生，如API不会返回不一致的value、集群中不会同时选出两个leader等； liveness，该属性表示好的事情最终会发生，如API最终会返回一个结果、磁盘写操作最终会完成等；  3 Failure and Time # 分布式系统工程师面对的一些困难，其实可以归结为下面2个原因：\n Processes may fail There\u0026rsquo;s no good way to tell that they have done so  即，分布式系统中的任意进程可能会出现故障，但是其他进程又没有可靠的方式来感知这个进程出现了故障。\n进程掌握并共享给其他进程的时间方面的信息、可能检测到的故障场景以及可以正确实现的算法和原语之间存在非常紧密的关系。大多数情况下，我们假设两个不同的节点对于现在是什么时间或时间流逝的速度完全没有共享的信息。\n我们需要认识到：\n 故障模式（failure modes）也是分层次的，大致分成：crash stop（崩溃停止） → omission（遗漏） → Byzantine（拜占庭）。我们要知道在层次结构顶部可能发生的在较低级别必须是可能的，在较低层不可能发生的在更高级别也必须是不可能的； 在缺少任何共享时钟的情况下，如何判断一个事件和另外一个事件发生的先后顺序。我们需要掌握Lamport clocks，以及它的泛化Vector clocks，也参考下Dynamo的这篇论文吧； 发生单个故障的可能性，对我们实现一个正确的分布式系统的影响有多大（可以参考下面给出的FLP result的笔记）； 不同的时间模型（models of time），同步（synchronous）、部分同步（partially synchronous）、异步（asynchronous）； 检测故障是一个基本问题，它在准确性和完整性之间进行权衡——这是另一个safety与liveness（安全与活跃）的冲突。 真正将故障检测作为理论问题提出的论文是 Chandra 和 Toueg 的“Unreliable Failure Detectors for Reliable Distributed Systems（可靠分布式系统的不可靠故障检测器）”。但是也有几个较短的摘要总结 - 我非常喜欢斯坦福大学的这个随机摘要总结Survey on Scalable Failure Detectors。  4 The basic tension of fault tolerance # 一个可以容忍某些故障（fault tolerance）而不降级（downgrade）的系统必须能够像这些故障没有发生一样运行。 这通常意味着系统的某些部分必须冗余地工作（work redundantly），但做比绝对必要的工作更多的工作（do more work than is absolutely necessary）通常会带来性能和资源消耗的成本。 这是为系统添加容错（fault tolerance）的基本冲突。\n我们需要了解：\n 确保单副本可串行化（single-copy serialisability）的仲裁技术（quorum technique）。 请参阅 Skeen 的原始论文 a quorum-based commit protocol，但也许更好的是 Wikipedia 的条目。 关于2阶段提交（2-phase-commit，简称2PC）、3阶段提交（3PC）、Paxos，等等，它们为什么会拥有不同的容错属性； 最终一致性（eventual consistency）及其他技术，如何以对系统行为的较弱保证为代价，来避免一致性、性能之间的冲突。Dynamo论文（Dynamo: Amazon\u0026rsquo;s Highly Available Key-Value Store）是一个了解这些内容不错的起点吧，Pat Helland的经典论文 Life Beyond Transactions（Life beyond Distributed Transactions: an Apostate\u0026rsquo;s Opinion） 也值得一读。  5 Basic Primitives # 分布式系统中几乎没有达成一致的基本构建块（building blocks），但更多的开始出现。 我们需要知道以下问题是什么，以及在哪里可以找到对应的解决方案：\n 领导者选举（leader election），Bully算法等； 一致性快照（consistent snapshotting），Chandy和Lamport的经典论文 Distributed Snapshots: Determining Global States of a Distributed System 等； 共识问题（consensus），参考上面提及的2PC、Paxos论文； 分布式状态机复制（distributed state machine replication），wikipedia的介绍就不错，Lampson的论文 How to build a highly available system using consensus 比较正式但是有点枯燥； 广播（broadcast），同时传递消息给不止一个节点，这里又有几种不同的技术：1）原子广播（atomic broadcast），要么广播一个消息给分组（group）内的所有节点，要么不广播给任何一个节点；2）gossip，参考经典论文；3）因果多播（causal multicast），也考虑下Birman和Cheriton之间令人愉快的来回。 链式复制（chain replication），通过将节点组织成虚拟链表来确保写入的一致性和顺序性的一种巧妙方法。1）最早的论文 Chain Replication for Supporting High Throughput and Availability；2）对读多写少场景的一系列改进 Object Storage on CRAQ: High-throughput chain replication for read-mostly workloads；3）@slfritchie做的一个实验报告 Chain Replication In Theory and in Practice Working Title, rough draft。  6 Fundamental Results # 关于分布式理论的几个事实要牢记在心，先列几个帮助比较大的。\n 如果在不同进程之间有消息丢失（网络分区），我们将不能实现强一致性存储（C）的同时还能对所有请求进行正确响应（A）。这就是大家熟知的CAP理论； 共识（concensus）是不可能通过如下方式实现的：1）总是正确的；2）总能终止，即使当（异步）系统中某台机器出现“崩溃-停止（crash-stop）”时（FLP result）。在论文“We Love SF Talk”第一页解释了FLP result，后面是证明，没有必要去搞明白证明过程（反证，琢磨下也好理解）。 一般而言，在少于2轮消息交互的情况下不可能解决共识问题； 原子广播（atomic broadcast）和共识问题一样困难——准确地说，如果我们解决了原子广播，也就解决了共识问题；反之亦然。Chandra和Toueg证明了这一点（Unreliable Failure Detectors for Reliable Distributed Systems），我们了解这是对的就好了。  7 Real Systems # 掌握、精通分布式的最重要的方式就是不断实践，不断阅读、了解、跟进、评价业界的真实系统、新出现系统的设计决策。 一遍又一遍地这样做。\n下面是一些推荐阅读信息：\nGoogle：\n GFS Spanner F1 Chubby BigTable MillWheel Omega Dapper Paxos Made Live The Tail At Scale  Not Google：\n Dryad Cassandra Ceph RAMCloud HyperDex PNUTS Azure Data Lake Store  8 Postscript # 本文作者是 Henry Robinson ，原文见 distributed systems theory for the distributed systems engineer。作者在文末留了个招聘广告，这里就保留了（既然干货满满如此有诚意）。\n 如果你掌握了这个列表中的所有概念和技术，可以联系我，我想和你谈谈我们在Cloudera Slack的分布式系统工程师开发职位。—— Henry Robinson\n ps：作者功力有限，翻译中如有疏漏错误之处，请指出来避免我误导他人。\n"}),a.add({id:208,href:"/tags/design/",title:"design",description:"",content:""}),a.add({id:209,href:"/blog/2021-06-23-go%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97%E6%96%87%E9%9B%86/",title:"go设计实现系列文集",description:"陆续看过一些go语言设计实现的文章，编译器、运行时调度、内存管理、垃圾回收、race检测、AST、locks等等吧，相对来说比较系统。收藏的这些文章，描述都比较形象、简单易懂，和动辄分析大篇幅的源码来说，对初学者或者希望利用碎片化时间学习的同学来说，会比较友好一点……就分享一下吧。",content:"陆续看过一些go语言设计实现的文章，编译器、运行时调度、内存管理、垃圾回收、race检测、AST、locks等等吧，相对来说比较系统。收藏的这些文章，描述都比较形象、简单易懂，和动辄分析大篇幅的源码来说，对初学者或者希望利用碎片化时间学习的同学来说，会比较友好一点……就分享一下吧。\n"}),a.add({id:210,href:"/tags/internals/",title:"internals",description:"",content:""}),a.add({id:211,href:"/tags/%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"设计实现",description:"",content:""}),a.add({id:212,href:"/tags/l4/",title:"L4",description:"",content:""}),a.add({id:213,href:"/tags/l4ka/",title:"L4Ka",description:"",content:""}),a.add({id:214,href:"/tags/microkernel/",title:"microkernel",description:"",content:""}),a.add({id:215,href:"/blog/2021-06-19-the-l4-microkernel/",title:"The L4 MicroKernel",description:"L4简介 # L4是在L3基础上开发的，改进了IO和IPC等，L4致力于打造一个通用的微内核，以便允许在其基础上进一步定制化来满足场景需求，L4衍生了不少微内核实现。\n现在也有些工作组致力于将Linux在L4上运行起来（L4Linux），将Windows在L4上运行起来（L4Windows），著名的GNU Hurd已经从老的Mach微内核迁移到了L4微内核。\n内核划分依据 # 微内核相比于宏内核，主要是微内核提供的核心更小，区别二者的依据并非源码多少，而是内核中提供功能的多寡。GNU Hurd中有提供宏内核、微内核、混合内核的对比示意图，点击查看。注意，宏内核有时记作monolithic kernel，也记作macro kernel。\nps：通常微内核源码会比宏内核少很多，如L4::Pistachio/ia32只有1w+左右的代码，但是Linux有几百万行。\n微内核通常将内核功能限定在下面几个方面：\n 进程管理； 虚拟内存管理； 进程通信、同步机制；  其他宏内核中常见的文件系统、设备驱动、网络功能在微内核中都是在用户态实现，这些功能可能在single-server中全部实现，也可能在multi-server中实现，进程通过内核IPC机制与server之间进行通信来。\n因为微内核中用户程序请求一些用户态的server（如文件系统、网络等服务）都需要借助IPC来完成，IPC用的非常多，改进其性能就显得尤为重要。早期的微内核实现IPC性能比较差，L4及以后的微内核设计都将提升IPC性能作为一个重要方向，L4中已经做的不错了，一起来了解下是如何实现的。\n微内核优缺点 # 优点 #   robustness：微内核中将很多功能在用户态实现，比如以multi-server的方式实现，假如文件系统服务出故障了，直接重启该服务即可，无需重启整个内核。而且这些服务是在用户态运行的，无权访问核心态数据，对整个内核无破坏性。微内核体积小也更方便维护、调试、定位、修复。\n  security：安全是系统很重要的方面，root用户可以访问一切资源，宏内核中root的权限、可支配范围相当大，root权限被滥用会导致严重问题，如Linux 2.4以前版本ptrace可以加载任意模块包括恶意模块。微内核中这样对权限收的更紧，没那么多系统调用，自然获得root权限的入口更少，更容易约束。\n  memory usage：内核的代码、数据需要常驻内存，宏内核中即便某些部分不常用到也不能够换出到交换区，会浪费内存空间，也影响用户程序执行效率。在微内核中，微内核本身体积小，宏内核中的一些核心服务被放到用户态中实现了，使用不频繁的内存区可以换出到交换区。\n  performance：当想在微内核核心态执行操作时，通常要关闭中断，以避免一些重要的处理过程被中断，这么做顶多会导致当前的一些程序、服务没有处理中断请求。如果考虑实时处理的话，则需要考虑这点。\n  缺点 # 微内核的缺点就是程序之间、程序和某些系统服务之间的通信都需要通过IPC来完成，如果IPC性能差则会导致整体性能差，所以有很多研究如何提高IPC性能的研究。L4Ka的研究人员可以证明，能够将IPC的开销从100ms降低到5ms及以下。\nsee: https://www.youtube.com/watch?v=wCoLTnHUwEY.\nL4Ka的设计 # L4表示第二代微内核，它吸收了第一代微内核设计上的一些经验教训，第一代微内核中Mach是最有名的实现之一。Mach和当时的其他微内核实现类似，没有自底向上地思考到底哪些功能应该在内核中实现，哪些不应该在内核中实现。其实它们看上去更像是拿到一个宏内核，然后再尝试将一些内核中的系统服务搞到用户层去。\nL4考虑了这些问题，比如哪些服务在用户态运行并且不损失安全性和功能。比如L4内核甚至都没必要引入threads或scheduler的概念，只提供实现进程抢占的系统调用就可以（尽管实际情况是L4支持用户级线程）。微内核就是这样，提供最基础的功能，在不同场景中用户可以执行特定的策略来实现更加复杂的功能。\n看L4Ka的详细设计之前，先来了解几个概念。\nL4Ka基本概念 #   threads：线程是最基本的调度实体，只有线程可以被调度。线程之间的同学是通过IPC来完成的，每个线程都有一个寄存器集合（IP、SP、user-visible registers、processor table）、一个关联的task、进程地址空间、pagefault handler（页式管理器，通过IPC接收pagefault请求）、exception handler、preempters和一些其他的调度参数（优先级、时间片等）。\n  tasks：task提供了进程执行需要的环境，它包括了一个虚地址空间、通信端口，一个task至少包括了一个thread，最新的L4实现不限制线程数量。task中创建的所有线程（除了主线程）创建后都需要显示启动，通过系统调用lthread_ex_regs()来启动。一个clan可以包括一个或多个tasks，其中只有一个是chief task，一个task创建另一个task，前者成为后者的chief task。task只可以被chief task kill掉，或者因为chief task被kill掉而间接被kill掉。\n  ps：这里clan、task、chief task的关系，可以联系下Linux下的会话session、会话首进程、进程组、组长进程、父进程之类的来理解。",content:"L4简介 # L4是在L3基础上开发的，改进了IO和IPC等，L4致力于打造一个通用的微内核，以便允许在其基础上进一步定制化来满足场景需求，L4衍生了不少微内核实现。\n现在也有些工作组致力于将Linux在L4上运行起来（L4Linux），将Windows在L4上运行起来（L4Windows），著名的GNU Hurd已经从老的Mach微内核迁移到了L4微内核。\n内核划分依据 # 微内核相比于宏内核，主要是微内核提供的核心更小，区别二者的依据并非源码多少，而是内核中提供功能的多寡。GNU Hurd中有提供宏内核、微内核、混合内核的对比示意图，点击查看。注意，宏内核有时记作monolithic kernel，也记作macro kernel。\nps：通常微内核源码会比宏内核少很多，如L4::Pistachio/ia32只有1w+左右的代码，但是Linux有几百万行。\n微内核通常将内核功能限定在下面几个方面：\n 进程管理； 虚拟内存管理； 进程通信、同步机制；  其他宏内核中常见的文件系统、设备驱动、网络功能在微内核中都是在用户态实现，这些功能可能在single-server中全部实现，也可能在multi-server中实现，进程通过内核IPC机制与server之间进行通信来。\n因为微内核中用户程序请求一些用户态的server（如文件系统、网络等服务）都需要借助IPC来完成，IPC用的非常多，改进其性能就显得尤为重要。早期的微内核实现IPC性能比较差，L4及以后的微内核设计都将提升IPC性能作为一个重要方向，L4中已经做的不错了，一起来了解下是如何实现的。\n微内核优缺点 # 优点 #   robustness：微内核中将很多功能在用户态实现，比如以multi-server的方式实现，假如文件系统服务出故障了，直接重启该服务即可，无需重启整个内核。而且这些服务是在用户态运行的，无权访问核心态数据，对整个内核无破坏性。微内核体积小也更方便维护、调试、定位、修复。\n  security：安全是系统很重要的方面，root用户可以访问一切资源，宏内核中root的权限、可支配范围相当大，root权限被滥用会导致严重问题，如Linux 2.4以前版本ptrace可以加载任意模块包括恶意模块。微内核中这样对权限收的更紧，没那么多系统调用，自然获得root权限的入口更少，更容易约束。\n  memory usage：内核的代码、数据需要常驻内存，宏内核中即便某些部分不常用到也不能够换出到交换区，会浪费内存空间，也影响用户程序执行效率。在微内核中，微内核本身体积小，宏内核中的一些核心服务被放到用户态中实现了，使用不频繁的内存区可以换出到交换区。\n  performance：当想在微内核核心态执行操作时，通常要关闭中断，以避免一些重要的处理过程被中断，这么做顶多会导致当前的一些程序、服务没有处理中断请求。如果考虑实时处理的话，则需要考虑这点。\n  缺点 # 微内核的缺点就是程序之间、程序和某些系统服务之间的通信都需要通过IPC来完成，如果IPC性能差则会导致整体性能差，所以有很多研究如何提高IPC性能的研究。L4Ka的研究人员可以证明，能够将IPC的开销从100ms降低到5ms及以下。\nsee: https://www.youtube.com/watch?v=wCoLTnHUwEY.\nL4Ka的设计 # L4表示第二代微内核，它吸收了第一代微内核设计上的一些经验教训，第一代微内核中Mach是最有名的实现之一。Mach和当时的其他微内核实现类似，没有自底向上地思考到底哪些功能应该在内核中实现，哪些不应该在内核中实现。其实它们看上去更像是拿到一个宏内核，然后再尝试将一些内核中的系统服务搞到用户层去。\nL4考虑了这些问题，比如哪些服务在用户态运行并且不损失安全性和功能。比如L4内核甚至都没必要引入threads或scheduler的概念，只提供实现进程抢占的系统调用就可以（尽管实际情况是L4支持用户级线程）。微内核就是这样，提供最基础的功能，在不同场景中用户可以执行特定的策略来实现更加复杂的功能。\n看L4Ka的详细设计之前，先来了解几个概念。\nL4Ka基本概念 #   threads：线程是最基本的调度实体，只有线程可以被调度。线程之间的同学是通过IPC来完成的，每个线程都有一个寄存器集合（IP、SP、user-visible registers、processor table）、一个关联的task、进程地址空间、pagefault handler（页式管理器，通过IPC接收pagefault请求）、exception handler、preempters和一些其他的调度参数（优先级、时间片等）。\n  tasks：task提供了进程执行需要的环境，它包括了一个虚地址空间、通信端口，一个task至少包括了一个thread，最新的L4实现不限制线程数量。task中创建的所有线程（除了主线程）创建后都需要显示启动，通过系统调用lthread_ex_regs()来启动。一个clan可以包括一个或多个tasks，其中只有一个是chief task，一个task创建另一个task，前者成为后者的chief task。task只可以被chief task kill掉，或者因为chief task被kill掉而间接被kill掉。\n  ps：这里clan、task、chief task的关系，可以联系下Linux下的会话session、会话首进程、进程组、组长进程、父进程之类的来理解。\n flexpages and Virtual Address Space：flexpages指的是flexible large memory pages，L4通过这些内存来访问主存和设备IO内存。进程虚地址空间也是由flexpages构成的，提供了两个系统调用来管理flexpages：grant、map、flush。grant将内存页从一个user交给另一个user，前者失去访问权限；map将内存页共享给另一个task，二者均可以访问；如果一个内存页已经映射给其他用户使用了，flush将清空对应地址空间。  IO实现 # L4并没有在内核中实现IO，而是将其放到了内核外的用户层去实现。内核只是接受IO相关的中断请求（IPC请求的形式），然后将其转发给对应的设备驱动来完成处理。访问外设IO都是以这种方式进行的。\nIPC实现 # 假如task A的线程发送给task B中的线程一个消息M，需要经历这么几步：\n A: load B的id A: load data of M A: call kernel kernel: read IPC request，load B的id kernel：switch rsp to B\u0026rsquo;s rsp kernel：switch VMA to B\u0026rsquo;s VMA kernel: load A的id并设置 kernel：return to userspace（B\u0026rsquo;s VMA) B: receive A发送的M（来自kernel load A的id并设置这步）  ps：这里的设计实现see：https://www.youtube.com/watch?v=mRr1lCJse_I。据说现在宏内核之所以还能活的好好的，主要是之前的微内核IPC性能实在太差。\n如果是发送小消息，拷贝数据到用户态深圳可以用寄存器来搞定，速度快；如果是发送大消息，则需要减少这里的两次拷贝到一次拷贝，怎么搞呢？让B先设置一个共享内存区，然后A将M写入后call kernel，内核直接切换到B，从共享内存区中recieve数据。\nLinux中的IPC涉及很多操作：数据copy、syscall、ctxt switch、blocking、waking，但是微内核L4设计中可以去掉scheduler导致的blocking、waking开销，数据拷贝也可以分为寄存区、共享内存区方式来减少往内核缓冲区的一次拷贝，系统调用中做的工作也简单，整体可以去掉不少开销。\n本分析中测试给出的数据（不确定一次通信传输了多少数据）：\n Linux IPC开销~4500 cycles，约2微秒 L4 IPC开销~900 cycles，约0.33微秒  L4 IPC性能大致是Linux的5倍，之前有个L4 fast inter-process communication的分享提到L4是L3 IPC性能的20倍。\n微内核IPC设计及优化，不止上面这点，详细地可以参考：GW AdvOS: Microkernel IPC Design and Optimizationm。\n安全性实现 # L4安全性机制是基于secure domains来实现的，即tasks、clans、chiefs。之前有提到过L4中进程通信不是基于channel的而是基于IPC请求的。如果是同一个clans中的task通信，那么直接用普通的IPC通信即可，但是如果是不同clans中的task通信，IPC消息必须转到发送方的clans的chief task处理后（chief可以对消息做些操作），才能发送给请求方所在clans的chief task，然后chief task转发给目标task。\n如果是跨越机器的通信，可以把IPC换成协议TCP/IP。\nps: 至于为什么不用channels来通信的方式，简单提一下，channels通信势必要引入chan sender、receiver，sender、receiver要根据chan状态进行同步，还要考虑阻塞、唤醒问题，也不得不考虑scheduler的问题，这里的开销就上来了，会导致IPC性能很差。前面也提过了，微内核IPC设计中优化掉了部分操作来减少开销。\n总结 # 本文介绍了微内核、宏内核的划分方法，介绍了L4的一些背景，以及L4中IO、IPC、安全性的实现方法。\n微内核相对于宏内核来说也具有一定的优势，并且第一代微内核IPC性能差的问题已经得到了明显改善。在如今万物互联的趋势下，微内核对资源占用小的优势应该也更适合资源有限的IoT设备。现在华为也在大力推动自己鸿蒙微内核liteos_a的开源协同，微内核将来还是有很大的市场空间的。\n本文就算是，我迈出了认真学习微内核设计、开发的第一步吧。\n参考内容 #  L4 and Fast Interprocess Communication, https://www.youtube.com/watch?v=mRr1lCJse_I GW AdvOS: Microkernel IPC Design and Optimizationm, https://www.youtube.com/watch?v=wCoLTnHUwEY  "}),a.add({id:216,href:"/blog/2021-06-15-go-map%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8%E9%80%89%E5%9E%8B/",title:"go map设计实现及应用选型",description:"map大致实现 # buckets \u0026amp; overflow # 本文介绍了map的内部数据结构，每个桶8个kvpairs，超过了可以用溢出桶，但是溢出桶会降低map性能，所以会创建新的bucket将数据迁到新bucket里面。\nhash \u0026amp; top hash table # 一个kvpairs存储在哪个bucket里面呢，首先根据key计算hash，然后对buckets数量取余，再放到对应桶里面，如果有空位置就放入，没有就需要走前面提到的溢出桶的逻辑。\n根据key计算出的hash除了计算key分布在哪个桶，还有其他用途，每个桶里都有一个top hash构成的数组，是为了map访问时加快查询key所在的数组索引的，通过减少比较key的耗时来加速访问。\nmapaccess_faststr, mapaccess_fast64\u0026hellip;访问map中元素时，根据key类型不同编译器插入不同的函数调用，函数名后缀表示key的类型，为什么有不同的函数呢？这是为了提高key的hash计算效率和比较效率。\nload factor # 装填因子，是用来控制map装填的元素数量，即元素数量除以桶数量。装填因子过小容易浪费内存空间，过大容易引发更多的碰撞冲突导致性能下降。\ninitialization \u0026amp;\u0026amp; lazy initialization # map提前初始化再赋值，比lazy初始化后再赋值效率高，为什么呢？lazy初始化桶是后面创建的更花时间。但是lazy初始化相比较而言容易节省内存。\nkvpairs padding # map中kvpairs的存储有考虑内存占用方面的优化，key的类型和value的类型可能不同，所以在数据对齐过程中padding会浪费不少内存，所以go map中的keys和values是分开存储的，先存储keys再存储values。\n并发安全检测 # map中的并发读写问题，go提供了如下方式进行检查：\n  data race detection：通过选项-race来检测是否存在data race，关于data race检测的问题，kavya joshi的分享里有介绍；\n  concurrent map writes：map对应的数据结构hmap中有个字段flags来记录当前的map操作，比如当前执行m[1]=1，是一个kv的赋值，对应的函数是mapassign_fast64，如果执行的是delete(m, 1)，对应的函数是mapdelete_fast64，这里的map修改操作对应的函数内部会将hmap.flags^=hashWriting，如果已经有一个写操作在执行，后面又有一个写操作执行，后面的写操作就有很大概率检测到flags的hashWriting位被设置了，此时就会抛出错误“concurrent map writes”错误；\n  关于map为什么不直接提供并发安全的版本，原因也简单。并发安全的版本是有同步开销的，但是很多时候并不需要并发安全的版本，如果默认实现是并发安全的，性能上就要大打折扣了。不考虑并发安全问题的话，map比sync.Map要快7~10倍。\n并发安全实现 # sync.Map是并发安全的实现，它对某些场景下的并发读写做了性能方面的优化：\n \u0026ldquo;The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, (2) when multiple goroutines read, write and overwrite entries for disjoint sets of keys.",content:"map大致实现 # buckets \u0026amp; overflow # 本文介绍了map的内部数据结构，每个桶8个kvpairs，超过了可以用溢出桶，但是溢出桶会降低map性能，所以会创建新的bucket将数据迁到新bucket里面。\nhash \u0026amp; top hash table # 一个kvpairs存储在哪个bucket里面呢，首先根据key计算hash，然后对buckets数量取余，再放到对应桶里面，如果有空位置就放入，没有就需要走前面提到的溢出桶的逻辑。\n根据key计算出的hash除了计算key分布在哪个桶，还有其他用途，每个桶里都有一个top hash构成的数组，是为了map访问时加快查询key所在的数组索引的，通过减少比较key的耗时来加速访问。\nmapaccess_faststr, mapaccess_fast64\u0026hellip;访问map中元素时，根据key类型不同编译器插入不同的函数调用，函数名后缀表示key的类型，为什么有不同的函数呢？这是为了提高key的hash计算效率和比较效率。\nload factor # 装填因子，是用来控制map装填的元素数量，即元素数量除以桶数量。装填因子过小容易浪费内存空间，过大容易引发更多的碰撞冲突导致性能下降。\ninitialization \u0026amp;\u0026amp; lazy initialization # map提前初始化再赋值，比lazy初始化后再赋值效率高，为什么呢？lazy初始化桶是后面创建的更花时间。但是lazy初始化相比较而言容易节省内存。\nkvpairs padding # map中kvpairs的存储有考虑内存占用方面的优化，key的类型和value的类型可能不同，所以在数据对齐过程中padding会浪费不少内存，所以go map中的keys和values是分开存储的，先存储keys再存储values。\n并发安全检测 # map中的并发读写问题，go提供了如下方式进行检查：\n  data race detection：通过选项-race来检测是否存在data race，关于data race检测的问题，kavya joshi的分享里有介绍；\n  concurrent map writes：map对应的数据结构hmap中有个字段flags来记录当前的map操作，比如当前执行m[1]=1，是一个kv的赋值，对应的函数是mapassign_fast64，如果执行的是delete(m, 1)，对应的函数是mapdelete_fast64，这里的map修改操作对应的函数内部会将hmap.flags^=hashWriting，如果已经有一个写操作在执行，后面又有一个写操作执行，后面的写操作就有很大概率检测到flags的hashWriting位被设置了，此时就会抛出错误“concurrent map writes”错误；\n  关于map为什么不直接提供并发安全的版本，原因也简单。并发安全的版本是有同步开销的，但是很多时候并不需要并发安全的版本，如果默认实现是并发安全的，性能上就要大打折扣了。不考虑并发安全问题的话，map比sync.Map要快7~10倍。\n并发安全实现 # sync.Map是并发安全的实现，它对某些场景下的并发读写做了性能方面的优化：\n \u0026ldquo;The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, (2) when multiple goroutines read, write and overwrite entries for disjoint sets of keys. In these two cases, use of a Map may significantly reduce lock contention compared to a Go map paired with a separate Mutex or RWMutex.\u0026rdquo;\n 意思就是说，sync.Map对于像缓存（caches）这种写一次（或次数很少）但是读取次数多的场景就很适用，或者存在多个goroutines并发读写，但是读写的keys集合是不相交的。\n第三方实现：ShardedMap # sync.Map对于需要频繁执行删除的场景、更广泛的写场景，没有对其进行足够的优化，这两个场景可以参考shardedmap实现。\nBenchmark及选型 # 对map、sync.Map、concurrent_map（shardedmap）进行了benchmark，结果如下：\nBenchmarkDeleteEmptyMap-8 20000000 86.9 ns/op BenchmarkDeleteEmptySyncMap-8 300000000 5.16 ns/op BenchmarkDeleteEmptyCMap-8 50000000 34.8 ns/op BenchmarkDeleteMap-8 10000000 131 ns/op BenchmarkDeleteSyncMap-8 10000000 135 ns/op BenchmarkDeleteCMap-8 30000000 37.0 ns/op BenchmarkLoadEmptyMap-8 20000000 87.9 ns/op BenchmarkLoadEmptySyncMap-8 300000000 5.03 ns/op BenchmarkLoadEmptyCMap-8 100000000 17.1 ns/op BenchmarkLoadMap-8 20000000 111 ns/op BenchmarkLoadSyncMap-8 100000000 12.8 ns/op BenchmarkLoadCMap-8 100000000 22.5 ns/op BenchmarkSetMap-8 10000000 187 ns/op BenchmarkSetSyncMap-8 5000000 396 ns/op BenchmarkSetCMap-8 20000000 84.9 ns/op  benchmark结果表明：\n map+rwmutex这种方式，锁粒度比加大，增删该查操作耗时相对来说都是比较明显的； sync.Map这种方式，写少读多的情况是非常合适的，效率比较明显，优于map、concurrent_map； concurrent_map，考虑了并发写比较频繁的情况，特别是删除，多shard执行删除操作时效率非常明显；  举个应用选型的例子：连接池明明显属于读多写少的场景，建议用sync.Map代替（key为ip:port，value为connection），后面transport如果要实现双工模式的时候，需要维护req.seqno\\req的映射关系，增删频繁，可以考虑用concurrent_map（key为req.seqno，value为req）。\n参考内容 #  https://medium.com/a-journey-with-go/go-map-design-by-example-part-i-3f78a064a352?source=\u0026mdash;\u0026mdash;\u0026mdash;45\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; https://medium.com/a-journey-with-go/go-map-design-by-code-part-ii-50d111557c08 https://medium.com/a-journey-with-go/go-concurrency-access-with-maps-part-iii-8c0a0e4eb27e https://github.com/orcaman/concurrent-map/blob/master/concurrent_map.go https://golangexample.com/a-simple-and-efficient-thread-safe-sharded-hashmap-for-go/  "}),a.add({id:217,href:"/tags/map/",title:"map",description:"",content:""}),a.add({id:218,href:"/tags/shardedmap/",title:"ShardedMap",description:"",content:""}),a.add({id:219,href:"/tags/sync.map/",title:"sync.Map",description:"",content:""}),a.add({id:220,href:"/tags/runtime/",title:"runtime",description:"",content:""}),a.add({id:221,href:"/tags/syscall/",title:"syscall",description:"",content:""}),a.add({id:222,href:"/blog/2021-06-06-how-go-handles-syscall/",title:"syscall：how does go runtime handles syscall",description:"1 How go runtime handle syscall ? # 最近遇到个线上服务频繁陷入系统调用导致go运行时创建了大量线程，影响到了服务质量，定位、解决问题之后，希望能进一步探究go运行时处理系统调用的过程，以便加深理解。参考了不少网友的分享，特别是知乎Golang Inernal专栏，结合个人的学习理解在此整理记录一下，与大家分享。\n1.1 前言 # 在开始结合源码进行分析之前，先做下简单的介绍，方便先从整体上把握go对系统调用的处理过程，然后从第二部分开始，再结合源码介绍具体的细节。\n系统调用分为阻塞系统调用、非阻塞系统调用，go里面对这些系统调用有归类整理，详见源文件：/src/syscall/syscall_linux_amd64.go。\n如下图所示，sys开头的表示的是阻塞系统调用，会调用Syscall，以sysnb开头的是非阻塞系统调用，会调用RawSyscall，关于Syscall和RawSyscall的区别下面整理。阻塞型的系统调用本身会阻塞线程，为了避免线程阻塞导致协程不可调度，golang运行时要感知这样的系统调用并做特殊处理，非阻塞的系统调用直接调即可，不需要golang运行时参与。 Syscall定义在asm_linux_amd64.s里面，代码中有runtime.entersyscall(SB)和runtime.exitsyscall(SB)函数调用，这个是与golang运行时进行交互的，用于通知golang运行时我即将发起或者退出一个系统调用。\n对于会导致阻塞的系统调用，都要通过Syscall来调用来通知golang运行时，以便golang运行时做处理，如创建新的物理线程调度器其它的goroutine，避免整个进程无线程可调度而最终被sysmon杀死进程。 对于某些非阻塞的系统调用，就不必再与golang运行时交互了，直接调用就可以，这样可以减少两次与golang运行时交互的函数调用开销，这里就掉的是RawSyscall： 网络io操作本来也是阻塞的，但是因为socket fd会被设置为non-blocking，系统调用虽然还是阻塞的系统调用，但是已经不会阻塞调用线程了，所以也无所谓了。\n有个脚本mksyscall.pl根据syscall_linux_amd64.go里面定义的系通调用列表，就是第一张图那些带注释的部分，这个pl脚本会负责生成与之相关的系统调用函数，生成在syscall/zsyscall_linux_amd64.go里面。可以找几个有代表性的来看下生成的系统调用函数：\n比如sendfile是阻塞的系统调用： 比如settimeofday是非阻塞的系统调用： epoll相关的epollwait也是阻塞的，但是网络socket fd在go里面都统一设置为了nonblocking fd处理了，因此并不会阻塞。 1.2 开始分析源码 # 在讲述系统调用发生的协程调度之前，让我们看看go是如何进入系统调用的，理解了这个让我们不会对后面所说的一些东西感到很陌生。\ngolang对操作系统的系统调用作了封装，提供了syscall这样的库让我们执行系统调用。例如，Read系统调用实现如下：\nfunc Read(fd int, p []byte) (n int, err error) { n, err = read(fd, p) if raceenabled { if n \u0026gt; 0 { ...... } ...... } return } // 最终封装了Syscall func read(fd int, p []byte) (n int, err error) { var _p0 unsafe.",content:"1 How go runtime handle syscall ? # 最近遇到个线上服务频繁陷入系统调用导致go运行时创建了大量线程，影响到了服务质量，定位、解决问题之后，希望能进一步探究go运行时处理系统调用的过程，以便加深理解。参考了不少网友的分享，特别是知乎Golang Inernal专栏，结合个人的学习理解在此整理记录一下，与大家分享。\n1.1 前言 # 在开始结合源码进行分析之前，先做下简单的介绍，方便先从整体上把握go对系统调用的处理过程，然后从第二部分开始，再结合源码介绍具体的细节。\n系统调用分为阻塞系统调用、非阻塞系统调用，go里面对这些系统调用有归类整理，详见源文件：/src/syscall/syscall_linux_amd64.go。\n如下图所示，sys开头的表示的是阻塞系统调用，会调用Syscall，以sysnb开头的是非阻塞系统调用，会调用RawSyscall，关于Syscall和RawSyscall的区别下面整理。阻塞型的系统调用本身会阻塞线程，为了避免线程阻塞导致协程不可调度，golang运行时要感知这样的系统调用并做特殊处理，非阻塞的系统调用直接调即可，不需要golang运行时参与。 Syscall定义在asm_linux_amd64.s里面，代码中有runtime.entersyscall(SB)和runtime.exitsyscall(SB)函数调用，这个是与golang运行时进行交互的，用于通知golang运行时我即将发起或者退出一个系统调用。\n对于会导致阻塞的系统调用，都要通过Syscall来调用来通知golang运行时，以便golang运行时做处理，如创建新的物理线程调度器其它的goroutine，避免整个进程无线程可调度而最终被sysmon杀死进程。 对于某些非阻塞的系统调用，就不必再与golang运行时交互了，直接调用就可以，这样可以减少两次与golang运行时交互的函数调用开销，这里就掉的是RawSyscall： 网络io操作本来也是阻塞的，但是因为socket fd会被设置为non-blocking，系统调用虽然还是阻塞的系统调用，但是已经不会阻塞调用线程了，所以也无所谓了。\n有个脚本mksyscall.pl根据syscall_linux_amd64.go里面定义的系通调用列表，就是第一张图那些带注释的部分，这个pl脚本会负责生成与之相关的系统调用函数，生成在syscall/zsyscall_linux_amd64.go里面。可以找几个有代表性的来看下生成的系统调用函数：\n比如sendfile是阻塞的系统调用： 比如settimeofday是非阻塞的系统调用： epoll相关的epollwait也是阻塞的，但是网络socket fd在go里面都统一设置为了nonblocking fd处理了，因此并不会阻塞。 1.2 开始分析源码 # 在讲述系统调用发生的协程调度之前，让我们看看go是如何进入系统调用的，理解了这个让我们不会对后面所说的一些东西感到很陌生。\ngolang对操作系统的系统调用作了封装，提供了syscall这样的库让我们执行系统调用。例如，Read系统调用实现如下：\nfunc Read(fd int, p []byte) (n int, err error) { n, err = read(fd, p) if raceenabled { if n \u0026gt; 0 { ...... } ...... } return } // 最终封装了Syscall func read(fd int, p []byte) (n int, err error) { var _p0 unsafe.Pointer if len(p) \u0026gt; 0 { _p0 = unsafe.Pointer(\u0026amp;p[0]) } else { _p0 = unsafe.Pointer(\u0026amp;_zero) } r0, _, e1 := Syscall(SYS_READ, uintptr(fd), uintptr(_p0), uintptr(len(p))) n = int(r0) if e1 != 0 { err = e1 } return } // 我们只关心进入系统调用时调用的runtime·entersyscall // 和退出时调用的runtime·exitsyscall TEXT ·Syscall(SB),NOSPLIT,$0-56 CALL runtime·entersyscall(SB) MOVQ 16(SP), DI MOVQ 24(SP), SI MOVQ 32(SP), DX MOVQ $0, R10 s MOVQ $0, R8 MOVQ $0, R9 MOVQ 8(SP), AX // syscall entry SYSCALL CMPQ AX, $0xfffffffffffff001 JLS ok MOVQ $-1, 40(SP) // r1 MOVQ $0, 48(SP) // r2 NEGQ AX MOVQ AX, 56(SP) // errno CALL runtime·exitsyscall(SB) RET  我们并不关心系统调用到底怎么实现。我们只关心系统调用过程与调度器相关内容，因为Golang自己接管系统调用，调度器便可以在进出系统调用时做一些你所不明白的优化，这里我要带你弄清楚调度器怎么做优化的。\n1.3 进入系统调用前 # 我们前面说过，系统调用是一个相对耗时的过程。一旦P中的某个G进入系统调用状态而阻塞了该P内的其他协程。此时调度器必须得做点什么吧，这就是调度器在进入系统调用前call runtime·entersyscall目的所在。\n 关于调度粘性（亲和性）问题，这里提一嘴：\n下文描述的时候有点偏故事性，关于GMP三者之间的关系，请务必注意goroutine、thread调度亲和性问题，这样就比较容易理解为什么G想再原来的M上执行，而M又想在原来的P上执行。\np上有mcache、gFree，m上有tls，m运行g申请小于32K的内存是从p.mcache中分配，维持g、m、p之间的关系有助于复用之前p上建立的mcache，也有助于m创建新的g时复用p上之前维护的空闲g列表。\n当然可能还有一些其他的原因，这里暂时先不展开了 see：https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/runtime2.go#L613。\n OK，我们继续讲运行时对系统调用的处理。\nvoid ·entersyscall(int32 dummy) { runtime·reentersyscall((uintptr)runtime·getcallerpc(\u0026amp;dummy), runtime·getcallersp(\u0026amp;dummy)); } void runtime·reentersyscall(uintptr pc, uintptr sp) { void (*fn)(void); // 为什么g-\u0026gt;m-\u0026gt;locks++? g-\u0026gt;m-\u0026gt;locks++; g-\u0026gt;stackguard0 = StackPreempt; g-\u0026gt;throwsplit = 1; // Leave SP around for GC and traceback. // save()到底在save什么？ save(pc, sp); g-\u0026gt;syscallsp = sp; g-\u0026gt;syscallpc = pc; runtime·casgstatus(g, Grunning, Gsyscall); // 这些堆栈之间到底是什么关系？ if(g-\u0026gt;syscallsp \u0026lt; g-\u0026gt;stack.lo || g-\u0026gt;stack.hi \u0026lt; g-\u0026gt;syscallsp) { fn = entersyscall_bad; runtime·onM(\u0026amp;fn); } // 这个还不知道是啥意思 if(runtime·atomicload(\u0026amp;runtime·sched.sysmonwait)) { fn = entersyscall_sysmon; runtime·onM(\u0026amp;fn); save(pc, sp); } // 这里很关键：P的M已经陷入系统调用，于是P忍痛放弃该M // 但是请注意：此时M还指向P，在M从系统调用返回后还能找到P g-\u0026gt;m-\u0026gt;mcache = nil; g-\u0026gt;m-\u0026gt;p-\u0026gt;m = nil; // P的状态变为Psyscall runtime·atomicstore(\u0026amp;g-\u0026gt;m-\u0026gt;p-\u0026gt;status, Psyscall); if(runtime·sched.gcwaiting) { fn = entersyscall_gcwait; runtime·onM(\u0026amp;fn); save(pc, sp); } g-\u0026gt;stackguard0 = StackPreempt; g-\u0026gt;m-\u0026gt;locks--; }  上面与调度器相关的内容其实就是将M从P剥离出去，告诉调度器，我已经放弃M了，我不能饿着我的孩子们（G）。但是M内心还是记着P的，在系统调用返回后，M还尽量找回原来的P，至于P是不是另结新欢就得看情况了。\n注意这时候P放弃了前妻M，但是还没有给孩子们找后妈（M），只是将P的状态标记为PSyscall，那么什么时候以及怎么样给孩子们找后妈呢？我们在后面详细阐述。\n1.4 从系统调用返回后 # 从系统调用返回后，也要告诉调度器，因为需要调度器做一些事情，根据前面系统调用的实现，具体实现是：\nvoid ·exitsyscall(int32 dummy) { void (*fn)(G*); // 这个g到底是什么？ g-\u0026gt;m-\u0026gt;locks++; // see comment in entersyscall if(runtime·getcallersp(\u0026amp;dummy) \u0026gt; g-\u0026gt;syscallsp) runtime·throw(\u0026quot;exitsyscall: syscall frame is no longer valid\u0026quot;); g-\u0026gt;waitsince = 0; // 判断能否快速找到归属 if(exitsyscallfast()) { g-\u0026gt;m-\u0026gt;p-\u0026gt;syscalltick++; // g的状态从syscall变成running，继续欢快地跑着 runtime·casgstatus(g, Gsyscall, Grunning); g-\u0026gt;syscallsp = (uintptr)nil; g-\u0026gt;m-\u0026gt;locks--; if(g-\u0026gt;preempt) { g-\u0026gt;stackguard0 = StackPreempt; } else { g-\u0026gt;stackguard0 = g-\u0026gt;stack.lo + StackGuard; } g-\u0026gt;throwsplit = 0; return; } g-\u0026gt;m-\u0026gt;locks--; // Call the scheduler. // 如果M回来发现P已经有别人服务了，那只能将自己挂起 // 等着服务别人。 fn = exitsyscall0; runtime·mcall(\u0026amp;fn); ...... } static bool exitsyscallfast(void) { void (*fn)(void); if(runtime·sched.stopwait) { g-\u0026gt;m-\u0026gt;p = nil; return false; } // 如果之前附属的P尚未被其他M,尝试绑定该P if(g-\u0026gt;m-\u0026gt;p \u0026amp;\u0026amp; g-\u0026gt;m-\u0026gt;p-\u0026gt;status == Psyscall \u0026amp;\u0026amp; runtime·cas(\u0026amp;g-\u0026gt;m-\u0026gt;p-\u0026gt;status, Psyscall, Prunning)) { g-\u0026gt;m-\u0026gt;mcache = g-\u0026gt;m-\u0026gt;p-\u0026gt;mcache; g-\u0026gt;m-\u0026gt;p-\u0026gt;m = g-\u0026gt;m; return true; } // Try to get any other idle P. // 否则从空闲P列表中随便捞一个出来 g-\u0026gt;m-\u0026gt;p = nil; if(runtime·sched.pidle) { fn = exitsyscallfast_pidle; runtime·onM(\u0026amp;fn); if(g-\u0026gt;m-\u0026gt;scalararg[0]) { g-\u0026gt;m-\u0026gt;scalararg[0] = 0; return true; } } return false; }  G从系统调用返回的过程，其实就是失足妇女找男人的逻辑：\n 首先看看能否回到当初爱人(P)的怀抱：找到当初被我抛弃的男人，我这里还存着它的名片(m-\u0026gt;p)，家庭住址什么的我都还知道； 如果爱人受不了寂寞和抚养孩子的压力已经变节（P的状态不再是Psyscall），那我就随便找个单身待解救男人从了也行； 如果上面的1、2都找不到，那也没办法，男人都死绝了，老娘只好另想他法。  以上过程1和2其实就是exitsyscallfast()的主要流程，用怀孕了的失足妇女找男人再合适不过。 一个女人由于年轻不懂事失足，抛家弃子（家是P，子是P的G）。当浪子回头后，意欲寻回从前的夫君，只能有两种可能：\n 等了很久已然心灰意冷的夫君在家人的安排下另娶他人； 痴情的夫君已然和嗷嗷待哺的孩子们依然在等待她的归回。  当然第二种的结局比较圆满，这个女人从此死心塌地守着这个家，于是p-\u0026gt;m又回来了，孩子们(g)又可以继续活下去了。 第一种就比较难办了，女人（m）心灰意冷，将产下的儿子（陷入系统调用的g）交于他人（全局g的运行队列）抚养，远走他乡，从此接收命运的安排（参与调度，以后可能服务于别的p）。 对于第二种可能性，只能说女人的命运比较悲惨了：\nstatic void exitsyscall0(G *gp) { P *p; runtime·casgstatus(gp, Gsyscall, Grunnable); dropg(); runtime·lock(\u0026amp;runtime·sched.lock); // 这里M再次尝试为自己找个归宿P p = pidleget(); // 如果没找到P，M讲自己放入全局的运行队列中 // 同时将它的g放置到全局的P queue中进去，自己不管了 if(p == nil) globrunqput(gp); else if(runtime·atomicload(\u0026amp;runtime·sched.sysmonwait)) { runtime·atomicstore(\u0026amp;runtime·sched.sysmonwait, 0); runtime·notewakeup(\u0026amp;runtime·sched.sysmonnote); } runtime·unlock(\u0026amp;runtime·sched.lock); // 如果找到了P，占有P并且开始执行P内的g，永不回头 if(p) { acquirep(p); execute(gp); // Never returns. } if(g-\u0026gt;m-\u0026gt;lockedg) { // Wait until another thread schedules gp and so m again. stoplockedm(); execute(gp); // Never returns. } // 找了一圈还是没找到，释放掉M当前执行环境，M不再做事 // stopm会暂停当前M直到其找到了可运行的P为止 // 找到以后进入schedule，执行P内的g stopm(); // m从stopm()中返回以后，说明该m被绑定至某个P,可以开始 // 继续欢快地跑了,此时就需要调度找到一个g去执行 // 这就是调用schedule的目的所在 schedule(); // Never returns. }  话说到这里，其实这个M当前没有运行的价值了（无法找到p运行它），那么我们就将她挂起，直到被其他人唤醒。 m被挂起调用的函数是stopm()\n// Stops execution of the current m until new work is available. // Returns with acquired P. static void stopm(void) { if(g-\u0026gt;m-\u0026gt;locks) runtime·throw(\u0026quot;stopm holding locks\u0026quot;); if(g-\u0026gt;m-\u0026gt;p) runtime·throw(\u0026quot;stopm holding p\u0026quot;); if(g-\u0026gt;m-\u0026gt;spinning) { g-\u0026gt;m-\u0026gt;spinning = false; runtime·xadd(\u0026amp;runtime·sched.nmspinning, -1); } retry: runtime·lock(\u0026amp;runtime·sched.lock); // 将m插入到空闲m队列中，统一管理 mput(g-\u0026gt;m); runtime·unlock(\u0026amp;runtime·sched.lock); // 在这里被挂起，阻塞在m-\u0026gt;park上，位于lock_futex.go runtime·notesleep(\u0026amp;g-\u0026gt;m-\u0026gt;park); // 从挂起被唤醒后开始执行 runtime·noteclear(\u0026amp;g-\u0026gt;m-\u0026gt;park); if(g-\u0026gt;m-\u0026gt;helpgc) { runtime·gchelper(); g-\u0026gt;m-\u0026gt;helpgc = 0; g-\u0026gt;m-\u0026gt;mcache = nil; goto retry; } // m-\u0026gt;nextp是什么？ acquirep(g-\u0026gt;m-\u0026gt;nextp); g-\u0026gt;m-\u0026gt;nextp = nil; }  那么说到这里，其实很多事情都一目了然，当一个M从系统调用返回后，通过各种方式想找到可以托付的P(找前夫—\u0026gt;找闲汉)，求之不得最终只能将自己挂起，等待下次系统中有空闲的P的时候被唤醒。\n1.5 sysmon # 前面我们重点讲了一个m是如何陷入系统调用和如何返回的心酸之路。我们忽略了p的感情，因为他才是真正的受害者，它被剥夺了m，从此无人理会它嗷嗷待哺的孩子们(g)，并且状态还被变成了Psyscall，相当于贴上了屌丝标签，别无他法，只能等待陷入系统调用的m返回，再续前缘。 当然，这样做是不合理的，因为如果m进入系统调用后乐不思蜀，那P的孩子们都得饿死，这在现实社会中可以发生，但在数字世界里是决不允许的。 OK，组织绝对不会忽略这种情况的，于是，保姆（管家）出现了，它就是sysmon线程，这是一个特殊的m，专门监控系统状态。 sysmon周期性醒来，并且遍历所有的p，如果发现有Psyscall状态的p并且已经处于该状态超过一定时间了，那就不管那个负心的前妻，再次p安排一个m，这样p内的任务又可以得到处理了。\nfunc sysmon() { ...... retake(now); ...... } // 我们只摘取了sysmon中与P处理相关的代码分析： static uint32 retake(int64 now) { uint32 i, s, n; int64 t; P *p; Pdesc *pd; n = 0; // 遍历所有的P，根据其状态作相应处理，我们只关注Psyscall for(i = 0; i \u0026lt; runtime·gomaxprocs; i++) { p = runtime·allp[i]; if(p==nil) continue; pd = \u0026amp;pdesc[i]; s = p-\u0026gt;status; if(s == Psyscall) { t = p-\u0026gt;syscalltick; if(pd-\u0026gt;syscalltick != t) { pd-\u0026gt;syscalltick = t; pd-\u0026gt;syscallwhen = now; continue; } if(p-\u0026gt;runqhead == p-\u0026gt;runqtail \u0026amp;\u0026amp; runtime·atomicload(\u0026amp;runtime·sched.nmspinning) + runtime·atomicload(\u0026amp;runtime·sched.npidle) \u0026gt; 0 \u0026amp;\u0026amp; pd-\u0026gt;syscallwhen + 10*1000*1000 \u0026gt; now) continue; incidlelocked(-1); // 因为需要将P重新安排m，所以状态转化为Pidle if(runtime·cas(\u0026amp;p-\u0026gt;status, s, Pidle)) { n++; handoffp(p); } incidlelocked(1); ...... }  找到了处于Psyscall状态的P后，继续判断它等待的时间是否已经太长，如果是这样，就准备抛弃原来的还陷入syscall的m，调用handoff(p)，开始为p准备新生活。\n我们接下来仔细分析下p是怎么过上新生活的，handoffp无非就是找一个新的m，将m与该p绑定，接下来将由m继续执行该p内的g。\nhandoffp()找到的新的m可能是别人以前的m(私生活好混乱)。由于这里获得的m是处于idle状态，处于wait状态（在stopm()中被sleep的），在这里，handoffp中会通过startm()来唤醒它，一个常见逻辑就是这个p里面还有g要执行那么就直接startm，这里的startm会通过mget获取一个空闲的m（如stopm暂停的m），获取不到就通过newm()创建一个m。\n这里的startm以被唤醒的m为例继续说明，关于新创建的m被唤醒的m继续执行它被阻塞的下一条语句：\nstopm() { ...... // 从挂起被唤醒后开始执行 runtime·noteclear(\u0026amp;g-\u0026gt;m-\u0026gt;park); if(g-\u0026gt;m-\u0026gt;helpgc) { runtime·gchelper(); g-\u0026gt;m-\u0026gt;helpgc = 0; g-\u0026gt;m-\u0026gt;mcache = nil; goto retry; } // 将M和P绑定 acquirep(g-\u0026gt;m-\u0026gt;nextp); g-\u0026gt;m-\u0026gt;nextp = nil; } // 由于m在sleep前的调用路径是exitsyscall0() –\u0026gt; stopm()，从stopm()中返回至exitsyscall0后，执行接下来的语句 func exitsyscall0(gp *g) { _g_ := getg() ...... stopm() // m继续run起来后，执行一次schedule // 找到m-\u0026gt;p里面可运行的g并执行 schedule() // Never returns. } // One round of scheduler: find a runnable goroutine and execute it. // Never returns. func schedule() { _g_ := getg() ...... if gp == nil { gp, inheritTime = runqget(_g_.m.p.ptr()) if gp != nil \u0026amp;\u0026amp; _g_.m.spinning { throw(\u0026quot;schedule: spinning with local work\u0026quot;) } } if gp == nil { gp, inheritTime = findrunnable() resetspinning() } if gp.lockedm != nil { // Hands off own p to the locked m, // then blocks waiting for a new p. startlockedm(gp) goto top } // 执行该gp execute(gp, inheritTime) }  1.6 总结 # 本文介绍了go对系统调用的大致处理过程，感谢知乎网友丁凯在知乎的分享，结合个人理解，略作整理也分享给大家。\n"}),a.add({id:223,href:"/blog/2021-05-25-go%E6%8A%A2%E5%8D%A0%E5%BC%8F%E8%B0%83%E5%BA%A6/",title:"go抢占式调度",description:"SIGURG，在信号处理函数runtime/signal_unix.go:sighandler(\u0026hellip;)函数中又看到对sigPreempt的处理。\nSIGURG实现抢占式调度： 对应这个函数doSigPreempt，检查当前g是不是wantAsyncPreempt，ok的话检查是不是isAsyncSafePoint，ok的话，sigctxt.pushCall(funcPC(asyncPreempt), newpc)，这个函数调整PC并注入一个对asyncPreempt的调用。\nTODO wantAsyncPreempt对应的判断参数是谁去设置的，什么时候设置的？\nTODO isAsyncSafePoint，safepoint的含义？这个函数的注释以及代码中的if-else已经足够结实清楚什么是safepoint了，以及safepoint的意义了。\n看下asyncPreempt的逻辑，该函数是在汇编中实现的，首先保存寄存器的值，然后调用asyncPreempt2执行其他处理。\ng.preemptStop决定是挂起g还是重新调度g：\n 如果被抢占的g的g.preemptStop为true，则执行mcall(preemptPark)挂起该g，g的状态被改为preempted，后面什么时机会重新调度它吧。然后执行schedule调度其他goroutine执行； 如果g.preemptStop为false，则mcall(gopreempt_m)将g从running改为runnable重新调度一次。  大致的抢占式调度逻辑就是这样的。\nps: func mcall(fn func(*g))，mcall switches from the g to the g0 stack and invokes fn(g), where g is the goroutine that made the call.",content:"SIGURG，在信号处理函数runtime/signal_unix.go:sighandler(\u0026hellip;)函数中又看到对sigPreempt的处理。\nSIGURG实现抢占式调度： 对应这个函数doSigPreempt，检查当前g是不是wantAsyncPreempt，ok的话检查是不是isAsyncSafePoint，ok的话，sigctxt.pushCall(funcPC(asyncPreempt), newpc)，这个函数调整PC并注入一个对asyncPreempt的调用。\nTODO wantAsyncPreempt对应的判断参数是谁去设置的，什么时候设置的？\nTODO isAsyncSafePoint，safepoint的含义？这个函数的注释以及代码中的if-else已经足够结实清楚什么是safepoint了，以及safepoint的意义了。\n看下asyncPreempt的逻辑，该函数是在汇编中实现的，首先保存寄存器的值，然后调用asyncPreempt2执行其他处理。\ng.preemptStop决定是挂起g还是重新调度g：\n 如果被抢占的g的g.preemptStop为true，则执行mcall(preemptPark)挂起该g，g的状态被改为preempted，后面什么时机会重新调度它吧。然后执行schedule调度其他goroutine执行； 如果g.preemptStop为false，则mcall(gopreempt_m)将g从running改为runnable重新调度一次。  大致的抢占式调度逻辑就是这样的。\nps: func mcall(fn func(*g))，mcall switches from the g to the g0 stack and invokes fn(g), where g is the goroutine that made the call.\n"}),a.add({id:224,href:"/tags/preemption/",title:"preemption",description:"",content:""}),a.add({id:225,href:"/tags/schedule/",title:"schedule",description:"",content:""}),a.add({id:226,href:"/blog/2021-05-25-go%E7%A8%8B%E5%BA%8F%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B/",title:"go程序信号处理过程",description:"go信号处理基础 # go os.signal package对信号处理做了封装，其中信号SIGKILL、SIGSTOP是操作系统规定的不允许捕获的信号，是不受os.signal这个package影响的\ngo中将信号分为两类：同步信号和异步信号。\n  同步信号：指的是go程序运行时程序内部错误触发的一些问题，如SIGBUS、SIGFPE、SIGSEGV，这些信号会被转换成运行时panic信息；\n  异步信号：除了上述提及的信号之外的信号，就是异步信号了。异步信号不是程序内部错误导致的，而是由操作系统或者外部其他程序发送给它的。\n  有哪些异步信号？ #  当程序失去对控制终端的控制时，会收到SIGHUP信号； 在控制终端中输入Ctrl+C时会收到SIGINT信号； 在控制终端中输入Ctrl+\\时会受到SIGQUIT信号；  ps：通常想让程序退出的话，Ctrl+C就可以了，如果想让程序退出同时打印栈转储信息，那就用Ctrl+\\。\n默认的信号处理方式？ # 接收到信号之后，肯定有默认的处理方式，这个在学习linux信号处理时肯定有了解过的，在go程序中可能只是默认处理方式有点不同，这个有需要的时候去了解就可以了。这里不展开了。\n值得一提的是信号SIGPROF，这个信号用于实现runtime.CPUProfile。\n自定义信号处理方式？ # 自定义信号处理方式，在linux signal函数中可以指定信号及对应对应的处理函数，go中类似，它允许通过os.Notify指定一个或多个信号chan，里面可以注册感兴趣的信号，当收到这些信号时，就可以执行用户自定义的信号处理逻辑。\nSIGPIPE信号处理 # 当程序write broken pipe时，会收到SIGPIPE信号，比如写网络连接失败，如果不做处理默认崩溃掉那就完蛋了。go程序中对这个做了优化处理。\nwrite broken pipe的行为与write的file descriptor的fd有关系：\n 如果fd是stdout、stderr，那么程序收到SIGPIPE信号，默认行为是程序会退出； 如果是其他fd，程序收到SIGPIPE信号，默认行为是不采取任何动作，对应的write操作返回一个EPIPE错误；  ps：后者很重要，写网络连接失败是常有的事情，linux c程序如果不显示处理SIGPIPE信号，默认行为将是程序直接crash，go程序对此作了优化，让write返回error而非crash，对于go将构建高性能、稳定健壮的网络程序的初衷来说是有必要的。\ncgo程序信号处理？ # 涉及到cgo就要分几种情况来讨论，这里会有点麻烦了，涉及到信号处理函数的重复注册、信号掩码设置、信号处理函数的栈等问题，在os/signal/doc.go里面有这方面的描述，这里不赘述。\ngo信号处理过程 # 介绍了go程序内部的信号处理过程。GMP调度模型里面，每个M都有一个独立的gsignal goroutine，系统投递信号给进程时实际上是有gsignal goroutine来接受这个信号，然后检查下是否可处理。如果可处理就将其push到一个信号队列中，然后有一个专门的goroutine执行signal.loop，这个函数从上述信号队列中取信号，并转移到用户自定义的chan os.Signal中，再由我们自己写的chan read代码消费，并执行处理。\n对应到源码中主要有几个函数：\n对应到源码中主要有几个函数：\n  os/signal/signal.go：这个函数里面在func init()的时候有启动一个loop函数，这个函数内调用runtime.signal_recv来不停地接收信号，然后检查程序通过os.Notify为哪些chan os.Signal订阅了该信号，就将该信号push到对应的chan中，后面应用程序就可以自行处理了；\n  runtime/sigqueue.go：runtime.sigsend、runtime.signal_recv这两个函数很重要，前者是程序收到系统发送来的信号时将信号写入outgoing sigqueue中，其实就是sig结构体的mask字段，后面signal_recv的时候也是从该mask字段读取，并写入recv字段中，recv中非0的应该就是表示收到了信号（信号编号为索引值）；\n  runtime/signal_unix.go：有个函数sighandler，这个函数负责对不同的信号执行不同的处理，比如抢占式调度SIGURG的处理，比如SIGPROF的处理，比如我们这里讨论的一些异步信号的处理sigsend。在go程序中不管是什么信号，这些信号是在sighandler做不同处理。sighandler虽然名字是信号处理函数，我们也看到了通过setsig将所有信号全部设置sighandler为信号处理函数，但是其实这只是表现。setsig函数内部又做了一个转换，将信号的信号处理函数设置为了sigtramp活着cgosigtramp，这些函数内部又调用sighandler。下面会提到sigtramp的逻辑；\n  runtime/runtime2.",content:"go信号处理基础 # go os.signal package对信号处理做了封装，其中信号SIGKILL、SIGSTOP是操作系统规定的不允许捕获的信号，是不受os.signal这个package影响的\ngo中将信号分为两类：同步信号和异步信号。\n  同步信号：指的是go程序运行时程序内部错误触发的一些问题，如SIGBUS、SIGFPE、SIGSEGV，这些信号会被转换成运行时panic信息；\n  异步信号：除了上述提及的信号之外的信号，就是异步信号了。异步信号不是程序内部错误导致的，而是由操作系统或者外部其他程序发送给它的。\n  有哪些异步信号？ #  当程序失去对控制终端的控制时，会收到SIGHUP信号； 在控制终端中输入Ctrl+C时会收到SIGINT信号； 在控制终端中输入Ctrl+\\时会受到SIGQUIT信号；  ps：通常想让程序退出的话，Ctrl+C就可以了，如果想让程序退出同时打印栈转储信息，那就用Ctrl+\\。\n默认的信号处理方式？ # 接收到信号之后，肯定有默认的处理方式，这个在学习linux信号处理时肯定有了解过的，在go程序中可能只是默认处理方式有点不同，这个有需要的时候去了解就可以了。这里不展开了。\n值得一提的是信号SIGPROF，这个信号用于实现runtime.CPUProfile。\n自定义信号处理方式？ # 自定义信号处理方式，在linux signal函数中可以指定信号及对应对应的处理函数，go中类似，它允许通过os.Notify指定一个或多个信号chan，里面可以注册感兴趣的信号，当收到这些信号时，就可以执行用户自定义的信号处理逻辑。\nSIGPIPE信号处理 # 当程序write broken pipe时，会收到SIGPIPE信号，比如写网络连接失败，如果不做处理默认崩溃掉那就完蛋了。go程序中对这个做了优化处理。\nwrite broken pipe的行为与write的file descriptor的fd有关系：\n 如果fd是stdout、stderr，那么程序收到SIGPIPE信号，默认行为是程序会退出； 如果是其他fd，程序收到SIGPIPE信号，默认行为是不采取任何动作，对应的write操作返回一个EPIPE错误；  ps：后者很重要，写网络连接失败是常有的事情，linux c程序如果不显示处理SIGPIPE信号，默认行为将是程序直接crash，go程序对此作了优化，让write返回error而非crash，对于go将构建高性能、稳定健壮的网络程序的初衷来说是有必要的。\ncgo程序信号处理？ # 涉及到cgo就要分几种情况来讨论，这里会有点麻烦了，涉及到信号处理函数的重复注册、信号掩码设置、信号处理函数的栈等问题，在os/signal/doc.go里面有这方面的描述，这里不赘述。\ngo信号处理过程 # 介绍了go程序内部的信号处理过程。GMP调度模型里面，每个M都有一个独立的gsignal goroutine，系统投递信号给进程时实际上是有gsignal goroutine来接受这个信号，然后检查下是否可处理。如果可处理就将其push到一个信号队列中，然后有一个专门的goroutine执行signal.loop，这个函数从上述信号队列中取信号，并转移到用户自定义的chan os.Signal中，再由我们自己写的chan read代码消费，并执行处理。\n对应到源码中主要有几个函数：\n对应到源码中主要有几个函数：\n  os/signal/signal.go：这个函数里面在func init()的时候有启动一个loop函数，这个函数内调用runtime.signal_recv来不停地接收信号，然后检查程序通过os.Notify为哪些chan os.Signal订阅了该信号，就将该信号push到对应的chan中，后面应用程序就可以自行处理了；\n  runtime/sigqueue.go：runtime.sigsend、runtime.signal_recv这两个函数很重要，前者是程序收到系统发送来的信号时将信号写入outgoing sigqueue中，其实就是sig结构体的mask字段，后面signal_recv的时候也是从该mask字段读取，并写入recv字段中，recv中非0的应该就是表示收到了信号（信号编号为索引值）；\n  runtime/signal_unix.go：有个函数sighandler，这个函数负责对不同的信号执行不同的处理，比如抢占式调度SIGURG的处理，比如SIGPROF的处理，比如我们这里讨论的一些异步信号的处理sigsend。在go程序中不管是什么信号，这些信号是在sighandler做不同处理。sighandler虽然名字是信号处理函数，我们也看到了通过setsig将所有信号全部设置sighandler为信号处理函数，但是其实这只是表现。setsig函数内部又做了一个转换，将信号的信号处理函数设置为了sigtramp活着cgosigtramp，这些函数内部又调用sighandler。下面会提到sigtramp的逻辑；\n  runtime/runtime2.go：这里定义了GMP调度模型中的m，m包含一个成员gsignal，它表示信号处理用的goroutine。os_linux.go中mpreinit会为创建一个goroutine，协程栈被初始化一个32KB大小的信号处理栈，很大这是为了兼容不同操作系统的一些问题，linux要≥2KB，OSX要≥8KB\u0026hellip;\n  sigtramp是注册到操作系统的信号处理函数，当操作系统执行系统调用返回时检查进程有没有信号到达，有并且没有屏蔽信号则执行对应的信号处理函数，这个时候是切到了用户态去执行信号处理函数。在执行信号处理函数的时候比较特殊，go需要为信号处理函数准备一个不同的栈帧，即信号处理栈，这个前面提过了是一个32KB大小的栈，然后将当前m.g设置为gsignal（栈大小为32KB），栈准备好之后，执行前面提过的sighandler执行信号处理，处理完成返回后，再将m.g设置为原来的g恢复正常执行。其实signhandler执行过程中，sigsend发送到outgoing sigqueue，然后signal_recv收信号发送到os.Notify订阅的chan，就完事了，后面就是我们熟悉的chan read并处理逻辑了。\n  算是介绍的比较详细了吧，篇幅、时间原因就不贴源码了，感兴趣的可以对着提及的源码仔细看看、求证一下。\n"}),a.add({id:227,href:"/tags/signal/",title:"signal",description:"",content:""}),a.add({id:228,href:"/tags/goroutine/",title:"goroutine",description:"",content:""}),a.add({id:229,href:"/blog/2021-05-24-how-goroutine-created-and-started/",title:"how goroutine created and started",description:"goroutine创建：runtime.newproc(siz int32, fn *funcval)\n go fn()，传递给fn的参数实际上是紧跟着存在fn压栈后的地址后面，在newproc1的栈帧里面，但是不出现在签名参数列表中，因为这些参数类型、数量不一样，也无法出现在签名参数列表中； newproc1创建g； getg().m.p.ptr()拿到当前p； runqput将当前g放入p的local queue中，如果满则放到global queue中； g等待被调度器调度执行；  大致创建执行goroutine的逻辑是这样的，下面的逻辑都是切到系统栈上去执行的。\n1 newproc1逻辑\n查看源码发现，goroutine初始创建时对函数参数大小是有限制的，如果参数占内存空间很大，比如超过初始栈帧大小2KB，那么goroutine创建会失败：\u0026ldquo;fatal error: newproc: function arguments too large for new goroutine\u0026rdquo;，比如，go func(a [1024]int) {}([1024]int{})。\n每个p内部都有一个空闲goroutine队列gFree，这个就是用来执行fn的goroutine，是可以复用的，不用的时候可以丢给调度器schedt.gFree供其他p复用。这里空闲的goroutines，一部分存在于p.gFree，如果gfput(p, gp)时发现p.gFree队列太长说明过剩了，就转移一部分到调度器schedt.gFree中供其他p复用。\ngoroutine执行完毕后运行时并不急于将其销毁，而是会考虑goroutine的复用，gfput，前面提过了。希望go func()通过协程执行时，也不必每次创建新的goroutine，gfget，可以复用p.gFree中的goroutine，如果p.gFree空或者过少（32）且调度器schedt.gFree中有空闲，则转移一部分过来给p复用。但是goroutine的栈有可能会被销毁，如果复用到栈被销毁的goroutine就需要stackalloc重新为其分配新栈帧。\n如果没有空闲的g可供复用，那就只能malg从头新建一个goroutine了。\ngoroutine创建成功、栈空间也ok了之后，就要把goroutine要执行的函数对应的函数参数给拷贝到这个栈空间里面来，通过memmove(spArg, argp, uintptr(narg))来完成。完成后调整newg的调度上下文相关的寄存器值，等调度器调度它时，还原其中的上下文信息，pc就指向其对应的函数地址了，对应的数据也会指向其对应的栈空间。\n然后，通过gostartcallfn→gostartcall(buf, fn, ctxt)，之前已经拷贝了函数fn的参数到goroutine栈空间了，这里面再继续在栈内设置fn返回地址、gobuf.sp+gobuf.pc信息。\n上述调整完成之后，将goroutine的状态从_Gdead调整为_Grunnable，等待调度器调度。新创建的时候其状态是_Gidle，一定会将其调整为_Gdead然后再进行上述准备工作，一切就绪后才调整为_Grunnable让其参与调度。\n2 runqput(p, gp, next) 这里的逻辑是，希望将gp放到p的local queue中，但是也有头插、尾插两种方式。\n 如果next为true，可以认为是头插，其实是放到p.runnext中，比p.queue中的得到优先调度。如果之前p.runnext有值，还要该值对应的g放入p.queue中； 如果next为false，则尝试将其放置到p.queue中，这里也有快慢两种情况，快的情况就是，因为p.queue这个本地队列长度最大为256，如果有空余位置放入就返回，这是快的情况。慢的情况就是如果p.queue满了就要先转移1/2到调度器全局队列schedt.queue中，然后再放入，这个过程就慢一些。  放置过程中，如果p.runqueue满了怎么办，将其放置到调度器schedt.queue这个全局队列中。\n3 wakeup()逻辑\n这个函数内部执行startm(p, spinning)，来找一个m来执行goroutine，具体是怎么做的呢？\n  如果没有指定p，比如新建goroutine时，此时会尝试检查有没有空闲的p，没有的话就直接返回了，相当于当前一次没有执行成功，那么只能下次调度的时候再执行这个新建的goroutine了；\n  现在有空闲的p，我们还缺什么，m！然后mget找一个空闲的m，如果没有空闲的，就newm创建一个新的，本质上是通过clone系统调用创建的新的线程。然后将这个m和这个p关联起来，m.nextp = p。值得一提的是clone出来的线程对应的线程处理函数是mstart，mstart使用汇编写的，内部实际调用的是mstart0，它内部又请求mstart1，获取当前g：\n  如果g.m==\u0026amp;m0，则执行mstartm0完成信号处理注册，继续执行其他；\n  获取当前m.",content:"goroutine创建：runtime.newproc(siz int32, fn *funcval)\n go fn()，传递给fn的参数实际上是紧跟着存在fn压栈后的地址后面，在newproc1的栈帧里面，但是不出现在签名参数列表中，因为这些参数类型、数量不一样，也无法出现在签名参数列表中； newproc1创建g； getg().m.p.ptr()拿到当前p； runqput将当前g放入p的local queue中，如果满则放到global queue中； g等待被调度器调度执行；  大致创建执行goroutine的逻辑是这样的，下面的逻辑都是切到系统栈上去执行的。\n1 newproc1逻辑\n查看源码发现，goroutine初始创建时对函数参数大小是有限制的，如果参数占内存空间很大，比如超过初始栈帧大小2KB，那么goroutine创建会失败：\u0026ldquo;fatal error: newproc: function arguments too large for new goroutine\u0026rdquo;，比如，go func(a [1024]int) {}([1024]int{})。\n每个p内部都有一个空闲goroutine队列gFree，这个就是用来执行fn的goroutine，是可以复用的，不用的时候可以丢给调度器schedt.gFree供其他p复用。这里空闲的goroutines，一部分存在于p.gFree，如果gfput(p, gp)时发现p.gFree队列太长说明过剩了，就转移一部分到调度器schedt.gFree中供其他p复用。\ngoroutine执行完毕后运行时并不急于将其销毁，而是会考虑goroutine的复用，gfput，前面提过了。希望go func()通过协程执行时，也不必每次创建新的goroutine，gfget，可以复用p.gFree中的goroutine，如果p.gFree空或者过少（32）且调度器schedt.gFree中有空闲，则转移一部分过来给p复用。但是goroutine的栈有可能会被销毁，如果复用到栈被销毁的goroutine就需要stackalloc重新为其分配新栈帧。\n如果没有空闲的g可供复用，那就只能malg从头新建一个goroutine了。\ngoroutine创建成功、栈空间也ok了之后，就要把goroutine要执行的函数对应的函数参数给拷贝到这个栈空间里面来，通过memmove(spArg, argp, uintptr(narg))来完成。完成后调整newg的调度上下文相关的寄存器值，等调度器调度它时，还原其中的上下文信息，pc就指向其对应的函数地址了，对应的数据也会指向其对应的栈空间。\n然后，通过gostartcallfn→gostartcall(buf, fn, ctxt)，之前已经拷贝了函数fn的参数到goroutine栈空间了，这里面再继续在栈内设置fn返回地址、gobuf.sp+gobuf.pc信息。\n上述调整完成之后，将goroutine的状态从_Gdead调整为_Grunnable，等待调度器调度。新创建的时候其状态是_Gidle，一定会将其调整为_Gdead然后再进行上述准备工作，一切就绪后才调整为_Grunnable让其参与调度。\n2 runqput(p, gp, next) 这里的逻辑是，希望将gp放到p的local queue中，但是也有头插、尾插两种方式。\n 如果next为true，可以认为是头插，其实是放到p.runnext中，比p.queue中的得到优先调度。如果之前p.runnext有值，还要该值对应的g放入p.queue中； 如果next为false，则尝试将其放置到p.queue中，这里也有快慢两种情况，快的情况就是，因为p.queue这个本地队列长度最大为256，如果有空余位置放入就返回，这是快的情况。慢的情况就是如果p.queue满了就要先转移1/2到调度器全局队列schedt.queue中，然后再放入，这个过程就慢一些。  放置过程中，如果p.runqueue满了怎么办，将其放置到调度器schedt.queue这个全局队列中。\n3 wakeup()逻辑\n这个函数内部执行startm(p, spinning)，来找一个m来执行goroutine，具体是怎么做的呢？\n  如果没有指定p，比如新建goroutine时，此时会尝试检查有没有空闲的p，没有的话就直接返回了，相当于当前一次没有执行成功，那么只能下次调度的时候再执行这个新建的goroutine了；\n  现在有空闲的p，我们还缺什么，m！然后mget找一个空闲的m，如果没有空闲的，就newm创建一个新的，本质上是通过clone系统调用创建的新的线程。然后将这个m和这个p关联起来，m.nextp = p。值得一提的是clone出来的线程对应的线程处理函数是mstart，mstart使用汇编写的，内部实际调用的是mstart0，它内部又请求mstart1，获取当前g：\n  如果g.m==\u0026amp;m0，则执行mstartm0完成信号处理注册，继续执行其他；\n  获取当前m.mstartfn，即线程处理函数，执行该函数，如果该函数会执行结束那还要继续执行；\n  如果当前g.m不是m0，那么要将g.m.nextp与当前m关联起来，为什么呢？m执行调度时用这个p呗，执行它的queue中的goroutine呗；\n  执行调度schedule()逻辑，这个函数调用一次就是执行一轮调度，逻辑就是寻找一个可运行的goroutine然后执行。这个函数比较有意思了，有些goroutine是通过lockOSThread绑定了执行它的线程的，这样的goroutine只能用那个绑定的m来执行，未绑定的则无此限制。 lockedg：这个schedule函数先获取当前g，如果发现当前g.m.lockedg不为0，表示有一个g通过lockOSThread绑定到了g.m，这个时候先停掉当前m，让其把p交出来，等下次有线程schedule里面调度执行lockedg时再唤醒该m，此时m被parked，p被空出来了。再调用execute(lockedg, inheritTime)，将该lockedg设置为当前g.m.curg，并修改装改为_Grunning，然后下面gogo(\u0026amp;gp.sched)恢复该待执行goroutine的上下文，执行之，execute函数never returns。可以想象下，如果一个m有g locked，那么每次调度都会先优先执行该goroutine？ 剩下的逻辑：获取当前g.m.p，\u0026hellip;..一堆有的没的逻辑，会通过findRunnable找一个可以运行的g来执行，最后也是调用execute来执行gp。 netpoller：值得一提的是这个函数里面会通过findRunnable来查找一个可执行的g，除了从p.queue、schedt.queue、其他p.queue中找可运行的goroutine外，也包括从netpoller中获取等待网络IO事件就绪的g。\n  到这里就可以算是结束了，到这里基本就了解了整个goroutine从创建到执行的完整逻辑了。当然这个后面还有点逻辑，目前也没搞懂写来干嘛的，先不管后面这个逻辑吧。\n 然后notewakeup唤醒阻塞在\u0026amp;m.park上的一个proc，这个是做什么呢？意思是说，如果之前m执行（执行某个goroutine的代码）时，因为某个原因阻塞了（这个原因通常用目标对象的事件地址来表示，如\u0026amp;m.park），现在这个条件满足了，现在将其唤醒继续执行。我们不禁想问，这里的\u0026amp;m.park表示的是什么呢？  ps：这里用到了futex来实现轻量级地锁获取+获取失败阻塞、锁释放+唤醒阻塞线程操作，see https://lwn.net/Articles/360699/。\n"}),a.add({id:230,href:"/tags/garbage-collector/",title:"garbage collector",description:"",content:""}),a.add({id:231,href:"/blog/2021-05-01-gogc-prioritizing-low-latency-and-simplicity/",title:"GC: prioritizing low latency and simplicity",description:"go GC 如何实现一个面向未来10年的低延迟、简洁的垃圾回收器，本文摘自golang官方blog，介绍了go团队针对GC所做的系列优化",content:"原文地址：https://blog.golang.org/go15gc\n介绍了当前软硬件大规模发展的趋势以及go GC需要优先解决的问题：低延迟和简单性（通过一个参数就可以控制，而非像JVM调参那样）。\ngo团队的目标是设计一个面向未来十年的垃圾回收器，借鉴了十几年前发明的算法。go GC使用的是并发三色标记清除算法（concurrent, tri-color, mark-sweep collector），由Dijkstra在1978年提出。该算法与现在大多数企业级的GC实现不同，但是go团队认为该算法更适合于现代硬件的发展，也更有助于实现现代软件的GC低延迟目标。\n该GC算法中，每个对象只能是white、grey、black中的其中一种，heap可以看做是互相连接的对象构成的一个graph。GC算法流程是：\n GC开始时，所有对象都是white； GC遍历所有的roots对象（比如全局变量、栈变量）将其标记为灰色； 然后GC选择一个grey对象，将其标记为black，并扫描（scan）该对象检查它内部的指向其他对象的指针。如果发现有指针指向其他white对象，将white对象标记为grey； 该过程重复执行，直到没有任何的灰色对象； 最后，剩下的白色对象即认为是不可达对象，可以被回收再利用；  GC过程和应用程序执行是并发进行的，应用程序也称为mutator，它会在GC运行期间修改一些指针的值。mutator必须遵循这样一条规则，就是不允许出现一个黑色对象指向一个白色对象，这样会导致对象被错误地回收。为了保证该规则成立，就需要引入写屏障（write barrier），它是编译阶段由编译器对mutator指针操作安插的一些特殊指令，用来跟踪对指针的修改，write barrier如果发现当前黑色对象的内部指针字段指向了外部的一个白色对象，则会将白色对象染色为grey，避免其被错误地GC掉，也保证其可以被继续扫描。\n有些GC相关的问题：\n 什么时候启动GC？ 通过哪些指标来判断要启动GC？ GC应该如何与scheduler进行交互？ 如何暂停一个mutator线程足够长时间，以扫描器stack？ 如何表示white、grey和black三种颜色来实现高效地查找、扫描grey对象？ 如何知道roots对象在哪里？ 如何知道一个指向对象的指针的位置？ 如何最小化内存碎片？ 如何解决cache性能问题？ heap应该设置为多大？ 等等。  上述问题有些与内存分配有关，有些与可达对象分析有关，有些与goroutine调度有关，有些与性能有关，关于这些内容的讨论远远超出本文篇幅，可以自己参考相关的材料。\n为了解决GC性能问题，可以考虑为每一种优化加个参数来控制，开发人员可以自己调整这里的参数来达到想要的优化效果。但是这种做法时间久了之后会发现有非常多的参数，调优就会变得非常困难，比如JVM调优。go团队不想走这样的老路，力求简单高效。\ngo通过GOGC这个环境变量来控制整个堆大小相对于现阶段可达对象大小的比例。GOGC默认值是100%，意味着当堆大小增长了当前可达对象大小的1倍时（2倍大小），就会触发GC；200%则意味着继续增长了当前可达对象的2倍时触发GC（3倍大小）。\n 如果想降低GC花费的时间，就把这个值设置的大一点，因为这样不容易频繁触发GC； 如果愿意花费更多的GC时间来换取更少的内存占用，就把这个值设置的小一点，因为这样能够更加频繁地GC；  前面提到go团队要设计一个面向未来十年的垃圾回收器，未来十年机器内存容量可能会翻倍或者成倍增长，简单地将GOGC设置为一定倍率也可以很好地工作，也不用像JVM调优那样重新设置一堆地参数，调参大军好惨。go团队也可以倾听用户真正地诉求在运行时方面做更多的优化。\n"}),a.add({id:232,href:"/blog/09%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9/",title:"09普通索引和唯一索引：如何选择",description:"对比两种类型的索引 #  普通索引，允许多条记录中组成索引的字段值出现重复的情况； 唯一索引，不允许……  两种类型索引实现 # 肯定都是一样的啊\n两种类型索引效率 # 我们以表user为例：\ncreate table `user` ( id int auto_increment, id_card varchar(64), name varchar(32), primary key(id), [uique|index] (id_card) -- 创建索引：唯一索引或者普通索引 )  其中id_card可能是唯一索引，也可能是普通索引。\n查询效率 # 以这条查询语句为例：select name from user where id_card=?\n  普通索引的查询\n顺着B+树根据id_card查询，查询到第一条记录之后，回表查询对应的name，加入结果集。继续遍历向右的指针对应的记录，直到找到第一条id_card不匹配的记录为止。因为id_card肯定是不重复的，所以这里向右的匹配开销顶多也就是多比较一次。\n当然如果匹配到的这条记录如果是page的最后一条记录的话，那么可能向右的查找需要加载另一个page，这是最坏的情况了。\n实际情况是B+树种一个节点可以存储非常多的key和指针，真的出现匹配记录出现在最后一个的情况非常少。\n  唯一索引的查询\n查找过程也是顺着B+树根据id_card查询，然后再回表。区别是它找到第一个匹配的节点之后就停止向右的查找了，因为它知道是唯一索引，不可能有重复的记录存在。\n  性能对比\n看上去唯一索引查询性能会高一点，但是前面也分析了id_card本身具备唯一性，普通查询中这种继续向右查找的操作对性能影响开销并不大，微乎其微。所以对于这两种索引，建议使用普通索引来代替唯一索引。\n  更新效率 # 更新语句以这个为例：update user set name=\u0026quot;xxxx\u0026quot; where id_card=?\n  change buffer\n在mysql执行数据更新时，会先写redo log，然后收到ok后准备更新数据。这个要更新的行对应的页数据如果在内存中，则直接更新内内存中的相应字段就可以了。",content:"对比两种类型的索引 #  普通索引，允许多条记录中组成索引的字段值出现重复的情况； 唯一索引，不允许……  两种类型索引实现 # 肯定都是一样的啊\n两种类型索引效率 # 我们以表user为例：\ncreate table `user` ( id int auto_increment, id_card varchar(64), name varchar(32), primary key(id), [uique|index] (id_card) -- 创建索引：唯一索引或者普通索引 )  其中id_card可能是唯一索引，也可能是普通索引。\n查询效率 # 以这条查询语句为例：select name from user where id_card=?\n  普通索引的查询\n顺着B+树根据id_card查询，查询到第一条记录之后，回表查询对应的name，加入结果集。继续遍历向右的指针对应的记录，直到找到第一条id_card不匹配的记录为止。因为id_card肯定是不重复的，所以这里向右的匹配开销顶多也就是多比较一次。\n当然如果匹配到的这条记录如果是page的最后一条记录的话，那么可能向右的查找需要加载另一个page，这是最坏的情况了。\n实际情况是B+树种一个节点可以存储非常多的key和指针，真的出现匹配记录出现在最后一个的情况非常少。\n  唯一索引的查询\n查找过程也是顺着B+树根据id_card查询，然后再回表。区别是它找到第一个匹配的节点之后就停止向右的查找了，因为它知道是唯一索引，不可能有重复的记录存在。\n  性能对比\n看上去唯一索引查询性能会高一点，但是前面也分析了id_card本身具备唯一性，普通查询中这种继续向右查找的操作对性能影响开销并不大，微乎其微。所以对于这两种索引，建议使用普通索引来代替唯一索引。\n  更新效率 # 更新语句以这个为例：update user set name=\u0026quot;xxxx\u0026quot; where id_card=?\n  change buffer\n在mysql执行数据更新时，会先写redo log，然后收到ok后准备更新数据。这个要更新的行对应的页数据如果在内存中，则直接更新内内存中的相应字段就可以了。\n如果这个数据没有在binlog中，也不会立即写入磁盘，而是从从磁盘加载速度比较慢，所以可以将一些更新操作，记录到change buffer中。后面有读数据请求等等时，会触发从磁盘加载文件，加载成功后再应用change buffer中的数据。\n  普通索引更新\n普通索引更新的时候，基本上就是上述说的过程，它是可以使用change buffer的。\n  唯一索引更新\n唯一索引，这里的唯一意味着每次操作都要判断是否会违反唯一性这个约束。比如要插入一行数据(1,\u0026lsquo;id_card\u0026rsquo;,100)，就要判断是否已经有将“id_card”写入的记录。\n类似地，要对id_card=\u0026lsquo;xxx\u0026rsquo;的记录做更新，就要能够找到id_card对应的行数据，这个时候目标行数肯定是要加载到内存中的，所以对应的页一定在内存中。\n这种情况下直接更新内存肯定比更新change buffer要快了，change buffer还受限于buffer pool大小机器设定的可占buffer pool的比例呢，所以这种情况下就没必要使用change buffer了。\n所以唯一索引不使用change buffer。\n  对比\n实际情况是，唯一索引的更新效率会比普通索引低。因为它必须要将行数据加载到内存中判断并更新，不能向普通索引那样直接写完change buffer就完事了。change buffer中的一些操作，会在后续读取的时候加载完原始数据之后，然后应用change buffer中的操作到原始数据，这个过程称为merge。\n  changebuffer应用场景 # 也不是说所有的场景都适合使用changebuffer，如果写多读少的话，就很适用了。反过来的话，读多写少，这种就不适合使用change buffer了，可以考虑禁用。\nchangebuffer是通过buffer pool分配的，可以设定一个变量来控制change buffer的大小。\n"}),a.add({id:233,href:"/tags/isolation/",title:"isolation",description:"",content:""}),a.add({id:234,href:"/tags/mvcc/",title:"mvcc",description:"",content:""}),a.add({id:235,href:"/categories/mysql%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"MySQL设计实现",description:"",content:""}),a.add({id:236,href:"/tags/transaction/",title:"transaction",description:"",content:""}),a.add({id:237,href:"/blog/07%E9%87%8D%E8%A6%81%E7%9A%84%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E4%B8%8A/",title:"07重要的集群参数配置",description:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101171",content:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101171\n"}),a.add({id:238,href:"/tags/kafka/",title:"kafka",description:"",content:""}),a.add({id:239,href:"/categories/kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/",title:"kafka核心技术与实战",description:"",content:""}),a.add({id:240,href:"/blog/06kafka%E7%BA%BF%E4%B8%8A%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88%E6%80%8E%E4%B9%88%E5%81%9A/",title:"06kafka线上集群部署方案怎么做",description:"kafka线上集群部署，该怎么做呢？可以从下面几个大的方向入手。\n操作系统选型 # kafka是基于Java、Scala实现的跨平台的消息引擎系统，虽然是跨平台的，但是线上部署kafka用的最多的操作系统还是Linux，Window、macOS应该都非常少，可能只适合用来学习测试用，线上还是要尽量用Linux。\nLinux操作系统的一些亮点：\n IO多路复用技术，实现更加高效的网络IO操作； 零拷贝技术，数据网络传输效率； 应用部署广泛，社区支持度比较好；  关于零拷贝技术，公司同事allanpan写过一篇非常好的文章，可供参考：\n Linux I/O 原理和 Zero-copy 技术全面揭秘  磁盘选型 # 选机械硬盘呢，还是选固态硬盘呢？Kafka工作过程中比较多的方式是“顺序读写”操作，普通机械硬盘顺序读写效率已经比较高了，因此使用机械硬盘就可以了。\nkafka使用机械硬盘，一个是性能上有也不会比使用固态硬盘差多少（应该是说固态硬盘也没什么优势），再一个是便宜，能降低成本。\n另外要注意冗余，倒不是说就要用RAID，可以多加几个硬盘做冗余就行了。\n磁盘容量 # 磁盘容量要根据业务当前现状，及未来发展情况，合理地规划存储容量。\n可以从以下几个方面入手：\n 写入的消息格式是怎样的，存储一条消息需要多少字节？ 当前业务一天需要写入多少消息，10w条，100w条，未来呢？ 消息希望保留多长时间，2周，1个月？ 磁盘冗余备份数是多少，2？3？ 使用启用压缩？用哪种压缩算法？压缩率多少？  小心评估上述每一个问题，最后就能给出一个相对比较合理地预估了，当然要留些buffer，以应对预料之外的情况。\n网络带宽 # 当我们说带宽的时候，我们真正关心的是什么？我们要处理一批数据，比如kafka中的数据，每台机器都是千兆网卡，我们需要多少台机器的合力，才能保证对消息的高效处理。\nSo，每台机器的网卡带宽是固定的，我们关心的其实是处理一批数据我们需要多少台机器的问题。\n根据消息生产速率，以及单条消息大小，可以很容易计算出每秒大约能生成多少数据，现在我们要处理这些数据，消息队列中的消息不能一直处于积压状态，那意味着处理速度跟不上生产，后面会处理地越来越不及时。\n怎么办？就需要根据接受消息处理的速率，来评估大约需要机器来处理。而接收消息的速率，单机受限于网卡，用总的生产数据量（通常等于消费数据量）除以网卡带宽，就可以拿到一个比较粗糙的机器数量。\n真实情况是，要为每台机器预留一定的贷款，比如每台机器70%的带宽用于处理数据，其他 的留给一些系统、网络服务等。",content:"kafka线上集群部署，该怎么做呢？可以从下面几个大的方向入手。\n操作系统选型 # kafka是基于Java、Scala实现的跨平台的消息引擎系统，虽然是跨平台的，但是线上部署kafka用的最多的操作系统还是Linux，Window、macOS应该都非常少，可能只适合用来学习测试用，线上还是要尽量用Linux。\nLinux操作系统的一些亮点：\n IO多路复用技术，实现更加高效的网络IO操作； 零拷贝技术，数据网络传输效率； 应用部署广泛，社区支持度比较好；  关于零拷贝技术，公司同事allanpan写过一篇非常好的文章，可供参考：\n Linux I/O 原理和 Zero-copy 技术全面揭秘  磁盘选型 # 选机械硬盘呢，还是选固态硬盘呢？Kafka工作过程中比较多的方式是“顺序读写”操作，普通机械硬盘顺序读写效率已经比较高了，因此使用机械硬盘就可以了。\nkafka使用机械硬盘，一个是性能上有也不会比使用固态硬盘差多少（应该是说固态硬盘也没什么优势），再一个是便宜，能降低成本。\n另外要注意冗余，倒不是说就要用RAID，可以多加几个硬盘做冗余就行了。\n磁盘容量 # 磁盘容量要根据业务当前现状，及未来发展情况，合理地规划存储容量。\n可以从以下几个方面入手：\n 写入的消息格式是怎样的，存储一条消息需要多少字节？ 当前业务一天需要写入多少消息，10w条，100w条，未来呢？ 消息希望保留多长时间，2周，1个月？ 磁盘冗余备份数是多少，2？3？ 使用启用压缩？用哪种压缩算法？压缩率多少？  小心评估上述每一个问题，最后就能给出一个相对比较合理地预估了，当然要留些buffer，以应对预料之外的情况。\n网络带宽 # 当我们说带宽的时候，我们真正关心的是什么？我们要处理一批数据，比如kafka中的数据，每台机器都是千兆网卡，我们需要多少台机器的合力，才能保证对消息的高效处理。\nSo，每台机器的网卡带宽是固定的，我们关心的其实是处理一批数据我们需要多少台机器的问题。\n根据消息生产速率，以及单条消息大小，可以很容易计算出每秒大约能生成多少数据，现在我们要处理这些数据，消息队列中的消息不能一直处于积压状态，那意味着处理速度跟不上生产，后面会处理地越来越不及时。\n怎么办？就需要根据接受消息处理的速率，来评估大约需要机器来处理。而接收消息的速率，单机受限于网卡，用总的生产数据量（通常等于消费数据量）除以网卡带宽，就可以拿到一个比较粗糙的机器数量。\n真实情况是，要为每台机器预留一定的贷款，比如每台机器70%的带宽用于处理数据，其他 的留给一些系统、网络服务等。\n"}),a.add({id:241,href:"/blog/05%E8%81%8A%E8%81%8Akafka%E7%9A%84%E7%89%88%E6%9C%AC%E5%8F%B7/",title:"05聊聊kafka的版本号",description:"了解kafka的版本演进，及各个版本的特性，更方便确定自己的业务选择合适的版本。\nkafka版本号说明：kafka-2.11-2.2.1.tgz\nkafka的服务端是用scala编写的，其中2.11表示的是scala编译器实现的，其中2.2.1才是kafka的版本号，主版本2、副版本2、修订版本1。\n了解各个版本的演进\nKafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0，其中的小版本和 Patch 版本很多。哪些版本引入了哪些重大的功能改进？关于这个问题，我建议你最好能做到如数家珍。\n额，历史版本暂时先不深究了。\n最后还有个建议，不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多 Kafka 为你提供的性能优化收益。",content:"了解kafka的版本演进，及各个版本的特性，更方便确定自己的业务选择合适的版本。\nkafka版本号说明：kafka-2.11-2.2.1.tgz\nkafka的服务端是用scala编写的，其中2.11表示的是scala编译器实现的，其中2.2.1才是kafka的版本号，主版本2、副版本2、修订版本1。\n了解各个版本的演进\nKafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0，其中的小版本和 Patch 版本很多。哪些版本引入了哪些重大的功能改进？关于这个问题，我建议你最好能做到如数家珍。\n额，历史版本暂时先不深究了。\n最后还有个建议，不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多 Kafka 为你提供的性能优化收益。\n"}),a.add({id:242,href:"/blog/04%E6%88%91%E4%BB%AC%E5%BA%94%E8%AF%A5%E9%80%89%E6%8B%A9%E5%93%AA%E7%A7%8Dkafka/",title:"04我们应该选择哪种kafka",description:"pk其他流处理平台 # Apache Storm、Apache Spark Streaming 亦或是 Apache Flink，它们在大规模流处理领域可都是响当当的名字。\n令人高兴的是，Kafka 经过这么长时间不断的迭代，现在已经能够稍稍比肩这些框架了。我在这里使用了“稍稍”这个字眼，一方面想表达 Kafka 社区对于这些框架心存敬意；另一方面也想表达目前国内鲜有大厂将 Kafka 用于流处理的尴尬境地，毕竟 Kafka 是从消息引擎“半路出家”转型成流处理平台的，它在流处理方面的表现还需要经过时间的检验。\n kafka connect，扩展了kafka的流式处理生态\n 你知道几种kafka？ #  apache kafka，社区版，是后续所有版本的基础 confluent kafka，提供了一些其他功能，如跨数据中心备份、集群监控工具等 cloudera/hortonworks kafka，提供的CDH和HDP是非常有名的大数据平台，里面集成了目前主流的大数据框架，现在两个公司已经合并，都集成了apache kafka。  apache kafka的优缺点 # 优点：\n 开发人数多、活跃，版本迭代快  缺点：\n 仅仅提供最基础的组件 kafka connect，仅提供一种读写文件的连接器，其他的要自己实现 没有任何监控框架或者工具，要借助第三方监控框架来监控（如kafka manager）  confluent kafka、cdh/hdp kafka的优缺点就不多说了，国内大公司很少有使用的。",content:"pk其他流处理平台 # Apache Storm、Apache Spark Streaming 亦或是 Apache Flink，它们在大规模流处理领域可都是响当当的名字。\n令人高兴的是，Kafka 经过这么长时间不断的迭代，现在已经能够稍稍比肩这些框架了。我在这里使用了“稍稍”这个字眼，一方面想表达 Kafka 社区对于这些框架心存敬意；另一方面也想表达目前国内鲜有大厂将 Kafka 用于流处理的尴尬境地，毕竟 Kafka 是从消息引擎“半路出家”转型成流处理平台的，它在流处理方面的表现还需要经过时间的检验。\n kafka connect，扩展了kafka的流式处理生态\n 你知道几种kafka？ #  apache kafka，社区版，是后续所有版本的基础 confluent kafka，提供了一些其他功能，如跨数据中心备份、集群监控工具等 cloudera/hortonworks kafka，提供的CDH和HDP是非常有名的大数据平台，里面集成了目前主流的大数据框架，现在两个公司已经合并，都集成了apache kafka。  apache kafka的优缺点 # 优点：\n 开发人数多、活跃，版本迭代快  缺点：\n 仅仅提供最基础的组件 kafka connect，仅提供一种读写文件的连接器，其他的要自己实现 没有任何监控框架或者工具，要借助第三方监控框架来监控（如kafka manager）  confluent kafka、cdh/hdp kafka的优缺点就不多说了，国内大公司很少有使用的。\n"}),a.add({id:243,href:"/blog/03kafka%E5%8F%AA%E6%98%AF%E6%B6%88%E6%81%AF%E5%BC%95%E6%93%8E%E7%B3%BB%E7%BB%9F%E5%90%97/",title:"03kafka只是消息引擎系统吗",description:"如果一个点一个点的学习，虽然了解了一个个点的作用，但是不能快速建立起全局的认识，也比较容易丧失学习兴趣，还是先了解全貌再深入细节，学习效果会更好一点。\napache kafka只是一个消息引擎系统吗 #  apache kafka是消息引擎系统； apache kafka也是一个分布式流式处理平台（distributed streaming platform）；  kafka出自linkedin，kafka 社区将其清晰地定位为一个分布式、分区化且带备份功能的提交日志（Commit Log）服务。\nKafka 在设计之初就旨在提供三个方面的特性 #  提供一套 API 实现生产者和消费者； 降低网络传输和磁盘存储开销； 实现高伸缩性架构。  kafka的华丽变身 # 所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？Kafka Streams诞生了！\nkafka与其他主流大数据流式计算框架相比，优势在哪里呢？\n  更容易实现端到端的正确性，能够实现端到端的精确一次性处理语义。\n  自己对于流式计算的定位，和其他的一些流失计算框架不同，它更轻量，不涉及集群调度等等比较重的东西，比较适合中小企业；\n   ps：kafka不适合当做最终存储。\n ",content:"如果一个点一个点的学习，虽然了解了一个个点的作用，但是不能快速建立起全局的认识，也比较容易丧失学习兴趣，还是先了解全貌再深入细节，学习效果会更好一点。\napache kafka只是一个消息引擎系统吗 #  apache kafka是消息引擎系统； apache kafka也是一个分布式流式处理平台（distributed streaming platform）；  kafka出自linkedin，kafka 社区将其清晰地定位为一个分布式、分区化且带备份功能的提交日志（Commit Log）服务。\nKafka 在设计之初就旨在提供三个方面的特性 #  提供一套 API 实现生产者和消费者； 降低网络传输和磁盘存储开销； 实现高伸缩性架构。  kafka的华丽变身 # 所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？Kafka Streams诞生了！\nkafka与其他主流大数据流式计算框架相比，优势在哪里呢？\n  更容易实现端到端的正确性，能够实现端到端的精确一次性处理语义。\n  自己对于流式计算的定位，和其他的一些流失计算框架不同，它更轻量，不涉及集群调度等等比较重的东西，比较适合中小企业；\n   ps：kafka不适合当做最终存储。\n "}),a.add({id:244,href:"/blog/02%E5%BF%AB%E9%80%9F%E6%90%9E%E5%AE%9Akafka%E6%9C%AF%E8%AF%AD/",title:"02快速搞定kafka术语",description:"kafka属于分布式的消息引擎系统，主要功能是提供一套完备的消息发布与订阅解决方案：\n  发布的订阅的对象是主题，topic；\n  client端\n 消息的生产者，producer； 消息的消费者，consumer；    server端\n broker 一个broker集群有多个broker，将多个broker部署在多台机器上，当其中一个挂了，另一个broker也依然能对外提供服务，这就是kafka实现高可用的手段之一。    备份机制，replication\n  副本，replica，相同的数据在被存储到多台机器上\n  领导者副本（leader replica），对外提供服务（与客户端交互）\n  追随者副本（follower replica），只能被动地跟随领导者副本，不与外界交互\n追随者副本请求领导者副本，把最新的更新操作发送给它，以完成同步\n    可伸缩性\n 将每个topic，划分成多个分区（partition），分区编号从0开始； 副本是在分区这个层级定义的，即每个分区可以定义副本的数量；    topic ：每个主题可以包含多个分区\n​	\\\npartition：每个分区可以配置多个副本\n​	\\\n​	replica (leader/follower)：每个分区的多个副本中只能有一个为leader，对外服务\n​	\\\n​	offset：消息曾，分区中包含若干条消息，每条消息的位移从0开始，依次递增\nclient只能与分区的leader replica进行通信。\n消费组里面可以订阅\nkafka broker通过追加写，来实现持久化，来避免缓慢的随机IO操，利用了比较好的顺序写操作。\n再来回顾下这里的常见术语：\n消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。\n主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\n分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。",content:"kafka属于分布式的消息引擎系统，主要功能是提供一套完备的消息发布与订阅解决方案：\n  发布的订阅的对象是主题，topic；\n  client端\n 消息的生产者，producer； 消息的消费者，consumer；    server端\n broker 一个broker集群有多个broker，将多个broker部署在多台机器上，当其中一个挂了，另一个broker也依然能对外提供服务，这就是kafka实现高可用的手段之一。    备份机制，replication\n  副本，replica，相同的数据在被存储到多台机器上\n  领导者副本（leader replica），对外提供服务（与客户端交互）\n  追随者副本（follower replica），只能被动地跟随领导者副本，不与外界交互\n追随者副本请求领导者副本，把最新的更新操作发送给它，以完成同步\n    可伸缩性\n 将每个topic，划分成多个分区（partition），分区编号从0开始； 副本是在分区这个层级定义的，即每个分区可以定义副本的数量；    topic ：每个主题可以包含多个分区\n​	\\\npartition：每个分区可以配置多个副本\n​	\\\n​	replica (leader/follower)：每个分区的多个副本中只能有一个为leader，对外服务\n​	\\\n​	offset：消息曾，分区中包含若干条消息，每条消息的位移从0开始，依次递增\nclient只能与分区的leader replica进行通信。\n消费组里面可以订阅\nkafka broker通过追加写，来实现持久化，来避免缓慢的随机IO操，利用了比较好的顺序写操作。\n再来回顾下这里的常见术语：\n消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。\n主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\n分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。\n消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。\n副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。\n生产者：Producer。向主题发布新消息的应用程序。\n消费者：Consumer。从主题订阅新消息的应用程序。\n消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。\n消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。\n重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。\n"}),a.add({id:245,href:"/blog/01%E6%B6%88%E6%81%AF%E5%BC%95%E6%93%8E%E7%B3%BB%E7%BB%9Fabc/",title:"01消息引擎系统",description:"apache kafka是什么呢？\n 消息引擎系统（messaging systems）🆗 这种描述更加准确！ 消息队列（是用队列实现的？not accurately) 消息中间件（messaging middleware）   类似地，比如consensus algorithm，翻译成共识算法，比一致性算法更合适，一致性已经被用的泛滥了。\n 消息编码方式： #  消息编码格式，csv、xml、json、pb、thrift； kafka使用的是纯二进制的字节序列；  消息传输方式： #  点对点，系统a发送的消息只能被b接受，其他人都不能接收； 发布订阅，可以有多个发送方（发布者，可能有多个），接收方（订阅方，可能有多个），这种能够实现非常灵活的系统扩展；  JMS：严格来说，是一种规范，而不是一种实现。\n消息引擎的作用： #   削峰填谷，避免生产者发送过量消息冲垮下游，使得下游能够平滑处理大量请求；\n为什么不对上游进行限速？限制后影响到用户体验怎么办？不现实！\n  解耦，解耦生产者和消费者，容易实现灵活的扩展；\n比如量大了之后，加更多的消费者来提高处理效率就行了嘛，加的慢也没影响，不会直接对用户体验造成影响。\n  ",content:"apache kafka是什么呢？\n 消息引擎系统（messaging systems）🆗 这种描述更加准确！ 消息队列（是用队列实现的？not accurately) 消息中间件（messaging middleware）   类似地，比如consensus algorithm，翻译成共识算法，比一致性算法更合适，一致性已经被用的泛滥了。\n 消息编码方式： #  消息编码格式，csv、xml、json、pb、thrift； kafka使用的是纯二进制的字节序列；  消息传输方式： #  点对点，系统a发送的消息只能被b接受，其他人都不能接收； 发布订阅，可以有多个发送方（发布者，可能有多个），接收方（订阅方，可能有多个），这种能够实现非常灵活的系统扩展；  JMS：严格来说，是一种规范，而不是一种实现。\n消息引擎的作用： #   削峰填谷，避免生产者发送过量消息冲垮下游，使得下游能够平滑处理大量请求；\n为什么不对上游进行限速？限制后影响到用户体验怎么办？不现实！\n  解耦，解耦生产者和消费者，容易实现灵活的扩展；\n比如量大了之后，加更多的消费者来提高处理效率就行了嘛，加的慢也没影响，不会直接对用户体验造成影响。\n  "}),a.add({id:246,href:"/blog/08%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84/",title:"08事务隔离：事务到底是隔离的还是不隔离的",description:"启动事务 # 启动事务的方式有哪些：\n autocommit=1，每条语句是一个独立的事务，比如select、update、delete； 通过begin/start transaction来启动一个事务，但是该语句并不是事务的起点，起点是在后面的第一条sql语句执行的时候； start transaction with consistent snapshot，立即启动一个新的事务，和begin/start transaction不同，该语句是一个事务的起点；  视图的概念 # 在mysql里，视图，有两种意思：\n  一个是“view”，它是一个用查询语句定义的虚拟表，如执行create view select * from table，该语句执行的时候执行查询语句获得结果并创建视图，可以在视图上执行查询操作，查询语法与在表上的查询方式类似；\n  另一个是InnoDB在实现MVCC时用到的“一致性读视图”，即consistent read view，用于支持RC（read commited，读提交）和RR（repeatable read，可重复读）隔离级别的实现；\n它没有物理结构，作用是事务执行期间用来定义“当前事务能看到什么数据”。\n  “快照”在MVCC里是怎么工作的 # 在可重复读隔离级别下，事务在启动的时候就“创建了个快照”，这个快照是基于整库的。\n但是这里的创建快照，并不是复制一份完整的数据作为只读，肯定不能这样实现，想想一下一个数据库如果数量很大，复制的存储开销也太大了。\nmysql MVCC里实现的这个快照非常聪明：\n  InnoDB里每个事务都有一个唯一的事务ID，叫transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。\n  每行数据也是有多个版本的，这里的版本就用transaction id来表示。哪个数据版本更加新一点旧一点，还是根据生成该版本时的顺序来决定的，每行数据的transaction id则用来维护一个一致性读视图；\n  当对某行数据进行更新操作时，会申请一个新的事务id，并插入新行数据，并更新字段trx_id为事务id，此时，插入了新的数据并不会删除旧的，旧的还是保存着的。但是新版的行数据有办法能找到旧版本的数据；\n注意新生成一个版本数据时，也会插入一行undo log，一个事务可以借助其事务id，从当前数据版本开始读，然后结合每行数据的trx_id和undo log，来读取到当前事务可见的数据版本，来实现一致性读视图，也就实现了可重复读；\n就是当前事务id可能是100，现在对应行的数据当前版本是102，100这个事务就顺着数据行的当前版本开始找，直到发现一个版本\u0026lt;=100时才行，也就保证了一致性读，这里就是根据数据行102版本的undo log找到前一条数据行，重复这个过程，直到发现一个版本\u0026lt;=100。\n  通过这种方式，实现了秒级快照的能力！\n当前读（current read） # 如果事务中涉及到一些更新类的操作的话，这里的更新是在数据“最新版本”上进行的更新，也就是说在“当前读”的版本上进行更新。后续的读，看上去读取到的就是最新值。\n这可能会让我们觉得，与我们之前MVCC里面一致性读时说的一些有矛盾。其实没有矛盾的，只是更新操作的时候是在当前读的最新数据上进行更新。而后续读取的时候依然是按照MVCC里一致性读的方式来的。\n如果更新时不是按照当前读来更新，那么就会造成以前已经提交的事务更新操作丢失了。\n有几种办法可以实现当前读：\n 更新操作肯定是当前读了； select + lock in share mod，也是当前读； select + for update，也是当前读；  ",content:"启动事务 # 启动事务的方式有哪些：\n autocommit=1，每条语句是一个独立的事务，比如select、update、delete； 通过begin/start transaction来启动一个事务，但是该语句并不是事务的起点，起点是在后面的第一条sql语句执行的时候； start transaction with consistent snapshot，立即启动一个新的事务，和begin/start transaction不同，该语句是一个事务的起点；  视图的概念 # 在mysql里，视图，有两种意思：\n  一个是“view”，它是一个用查询语句定义的虚拟表，如执行create view select * from table，该语句执行的时候执行查询语句获得结果并创建视图，可以在视图上执行查询操作，查询语法与在表上的查询方式类似；\n  另一个是InnoDB在实现MVCC时用到的“一致性读视图”，即consistent read view，用于支持RC（read commited，读提交）和RR（repeatable read，可重复读）隔离级别的实现；\n它没有物理结构，作用是事务执行期间用来定义“当前事务能看到什么数据”。\n  “快照”在MVCC里是怎么工作的 # 在可重复读隔离级别下，事务在启动的时候就“创建了个快照”，这个快照是基于整库的。\n但是这里的创建快照，并不是复制一份完整的数据作为只读，肯定不能这样实现，想想一下一个数据库如果数量很大，复制的存储开销也太大了。\nmysql MVCC里实现的这个快照非常聪明：\n  InnoDB里每个事务都有一个唯一的事务ID，叫transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。\n  每行数据也是有多个版本的，这里的版本就用transaction id来表示。哪个数据版本更加新一点旧一点，还是根据生成该版本时的顺序来决定的，每行数据的transaction id则用来维护一个一致性读视图；\n  当对某行数据进行更新操作时，会申请一个新的事务id，并插入新行数据，并更新字段trx_id为事务id，此时，插入了新的数据并不会删除旧的，旧的还是保存着的。但是新版的行数据有办法能找到旧版本的数据；\n注意新生成一个版本数据时，也会插入一行undo log，一个事务可以借助其事务id，从当前数据版本开始读，然后结合每行数据的trx_id和undo log，来读取到当前事务可见的数据版本，来实现一致性读视图，也就实现了可重复读；\n就是当前事务id可能是100，现在对应行的数据当前版本是102，100这个事务就顺着数据行的当前版本开始找，直到发现一个版本\u0026lt;=100时才行，也就保证了一致性读，这里就是根据数据行102版本的undo log找到前一条数据行，重复这个过程，直到发现一个版本\u0026lt;=100。\n  通过这种方式，实现了秒级快照的能力！\n当前读（current read） # 如果事务中涉及到一些更新类的操作的话，这里的更新是在数据“最新版本”上进行的更新，也就是说在“当前读”的版本上进行更新。后续的读，看上去读取到的就是最新值。\n这可能会让我们觉得，与我们之前MVCC里面一致性读时说的一些有矛盾。其实没有矛盾的，只是更新操作的时候是在当前读的最新数据上进行更新。而后续读取的时候依然是按照MVCC里一致性读的方式来的。\n如果更新时不是按照当前读来更新，那么就会造成以前已经提交的事务更新操作丢失了。\n有几种办法可以实现当前读：\n 更新操作肯定是当前读了； select + lock in share mod，也是当前读； select + for update，也是当前读；  "}),a.add({id:247,href:"/blog/07%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E8%A1%8C%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D/",title:"07行锁功过：怎么减少行锁对性能的影响",description:"行锁 # 行锁，顾名思义就是对表的行进行加锁，是存储引擎层来设计实现的：\n MyISAM没有行锁，对表执行更新时只能加表锁，并发度就比较低 InnoDB支持行锁，并发度就比MyISAM高，所以一般用InnoDB代替MyISAM   ps: 减少行锁的冲突，有助于进一步提高并发处理能力。\n 两阶段封锁协议 # 在一个事务中：\n 加锁，是在需要的时候按需加锁； 释放锁，是在事务提交的时候释放锁；  知道这个后，我们可以在编码时进行一点优化。\n如果事务涉及到锁定多个行的情况，尽量将可能导致锁冲突的行操作往后放，这样减少了锁持有时间，从而降低锁冲突。\n举个例子，现在有个顾客A从电影院B买电影票，需要执行：\n  1：扣账户A余额的操作；\n  2：需要给电影院B增加余额的操作；\n  3：记录一条交易日志；\n  那这几个操作该如何排序呢？因为会有很多人买电影票，所以操作2的冲突概率是比较大的，所以将2排在最后，而操作3是在额外的表中追加记录，基本不存在行冲突，所以不如放在最前面，A可能除了买电影票还可能买其他，冲突概率次之。\n所以排序为3、1、2比较合理。\n死锁和死锁检测 # 调整上面的操作顺序，只能尽量减少锁冲突，提高并发度，但是不能完全保证避免死锁。\n死锁原因 # 造成死锁的原因，就是多个事务中加锁顺序不一致，造成了循环依赖：比如事务t1已经持有了锁a，现在申请锁b，但是锁b呢已经被事务t2持有，事务t2还在申请锁a，但是a已经被t持有。这样事务t1、t2相互等待对方，都拿不到锁，就造成了死锁。\n死锁检测 # 解决死锁问题，有这么几种方法，一种是死锁避免，一种是死锁检测。\n  死锁避免，可以让获取锁的操作有一个最大超时时间，超过这个时间就返回获取锁失败，让事务退出，事务退出的时候释放掉已经持有的锁，这样就避免了死锁。\nmysql中可以通过设置变量innodb_lock_wait_timeout的值来设定这个超时时间，默认值是50s，这个时间还是很长的，一旦真的发生了死锁，对业务不可用时间也比较长，50s啊！\n如果把这个变量设为1s呢，也不行，可能会有很多的锁获取失败的情况，但是可能是正常获取锁操作，非死锁，会造成很多误伤，也不好！\n  死锁检测，通过死锁检测算法来检测是否会出现死锁操作，比如获取一个锁之前，先检查这个锁被哪个线程持有，没有也就正常拿到锁了，如果被线程t2持有，继续检查这个线程t2有没有要申请的锁被当前线程持有，如果有，那么当前线程发起的加锁请求将会导致一个循环依赖，会发生死锁。\n这个时候，可以直接让当前事务失败，释放锁，或者干掉另一个事务t2让它释放锁，也就避免了死锁。\n死锁检测默认是开启的，innodb_deadlock_detect，通过这个变量来设置。\n  相关开销 # 死锁避免虽然效果不怎么令人满意，一般还是会开启死锁检测的，但是死锁检测的过程前面也简单描述了，实际上这个死锁检测的过程会更复杂，假如有1000个线程，当前线程t1可能希望获得线程t2上的锁，t2可能希望获得t3上的锁，\u0026hellip;.，t1000可能希望获得当前线程t1的锁……就是要分析做很多分析才能判断出会不会导致死锁。\n有的时候线程数多了之后，死锁检测开销也会比较高，表现就是CPU占用率很高，比如100%，但是每秒并没有执行几个事务。\n热点记录 # 对于某些热点记录，更新频繁的记录，这样的锁冲突的情况会比较多，而且线程数也比较多的情况下，问题更明显，CPU占用很高，但是执行不了几个事务，尽管没有真的发生死锁。\n对于热点记录如何解决呢？\n 方法一：将对一条记录的操作拆分成对多个记录，每次更新时随机选一条，降低锁冲突的概率，比如改为随机更新10条记录中的一条，冲突概率就下降为原来的1/10； 方法二：改成用写增量流水日志的方式，定期地取合并日志中的操作更新到原来的那一条记录；  这里的思想，很分布式缓存热key的处理方式也是类似的，要么就是通过写多个key来解决，要么就是记录流水异步更新来解决。",content:"行锁 # 行锁，顾名思义就是对表的行进行加锁，是存储引擎层来设计实现的：\n MyISAM没有行锁，对表执行更新时只能加表锁，并发度就比较低 InnoDB支持行锁，并发度就比MyISAM高，所以一般用InnoDB代替MyISAM   ps: 减少行锁的冲突，有助于进一步提高并发处理能力。\n 两阶段封锁协议 # 在一个事务中：\n 加锁，是在需要的时候按需加锁； 释放锁，是在事务提交的时候释放锁；  知道这个后，我们可以在编码时进行一点优化。\n如果事务涉及到锁定多个行的情况，尽量将可能导致锁冲突的行操作往后放，这样减少了锁持有时间，从而降低锁冲突。\n举个例子，现在有个顾客A从电影院B买电影票，需要执行：\n  1：扣账户A余额的操作；\n  2：需要给电影院B增加余额的操作；\n  3：记录一条交易日志；\n  那这几个操作该如何排序呢？因为会有很多人买电影票，所以操作2的冲突概率是比较大的，所以将2排在最后，而操作3是在额外的表中追加记录，基本不存在行冲突，所以不如放在最前面，A可能除了买电影票还可能买其他，冲突概率次之。\n所以排序为3、1、2比较合理。\n死锁和死锁检测 # 调整上面的操作顺序，只能尽量减少锁冲突，提高并发度，但是不能完全保证避免死锁。\n死锁原因 # 造成死锁的原因，就是多个事务中加锁顺序不一致，造成了循环依赖：比如事务t1已经持有了锁a，现在申请锁b，但是锁b呢已经被事务t2持有，事务t2还在申请锁a，但是a已经被t持有。这样事务t1、t2相互等待对方，都拿不到锁，就造成了死锁。\n死锁检测 # 解决死锁问题，有这么几种方法，一种是死锁避免，一种是死锁检测。\n  死锁避免，可以让获取锁的操作有一个最大超时时间，超过这个时间就返回获取锁失败，让事务退出，事务退出的时候释放掉已经持有的锁，这样就避免了死锁。\nmysql中可以通过设置变量innodb_lock_wait_timeout的值来设定这个超时时间，默认值是50s，这个时间还是很长的，一旦真的发生了死锁，对业务不可用时间也比较长，50s啊！\n如果把这个变量设为1s呢，也不行，可能会有很多的锁获取失败的情况，但是可能是正常获取锁操作，非死锁，会造成很多误伤，也不好！\n  死锁检测，通过死锁检测算法来检测是否会出现死锁操作，比如获取一个锁之前，先检查这个锁被哪个线程持有，没有也就正常拿到锁了，如果被线程t2持有，继续检查这个线程t2有没有要申请的锁被当前线程持有，如果有，那么当前线程发起的加锁请求将会导致一个循环依赖，会发生死锁。\n这个时候，可以直接让当前事务失败，释放锁，或者干掉另一个事务t2让它释放锁，也就避免了死锁。\n死锁检测默认是开启的，innodb_deadlock_detect，通过这个变量来设置。\n  相关开销 # 死锁避免虽然效果不怎么令人满意，一般还是会开启死锁检测的，但是死锁检测的过程前面也简单描述了，实际上这个死锁检测的过程会更复杂，假如有1000个线程，当前线程t1可能希望获得线程t2上的锁，t2可能希望获得t3上的锁，\u0026hellip;.，t1000可能希望获得当前线程t1的锁……就是要分析做很多分析才能判断出会不会导致死锁。\n有的时候线程数多了之后，死锁检测开销也会比较高，表现就是CPU占用率很高，比如100%，但是每秒并没有执行几个事务。\n热点记录 # 对于某些热点记录，更新频繁的记录，这样的锁冲突的情况会比较多，而且线程数也比较多的情况下，问题更明显，CPU占用很高，但是执行不了几个事务，尽管没有真的发生死锁。\n对于热点记录如何解决呢？\n 方法一：将对一条记录的操作拆分成对多个记录，每次更新时随机选一条，降低锁冲突的概率，比如改为随机更新10条记录中的一条，冲突概率就下降为原来的1/10； 方法二：改成用写增量流水日志的方式，定期地取合并日志中的操作更新到原来的那一条记录；  这里的思想，很分布式缓存热key的处理方式也是类似的，要么就是通过写多个key来解决，要么就是记录流水异步更新来解决。\n"}),a.add({id:248,href:"/tags/locks/",title:"locks",description:"",content:""}),a.add({id:249,href:"/tags/row-lock/",title:"row lock",description:"",content:""}),a.add({id:250,href:"/blog/06%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E8%BF%99%E4%B9%88%E9%9A%BE/",title:"06全局锁和表锁：给表加个字段怎么这么难",description:"根据加锁的范围，mysql中的锁可以分为：全局锁、表锁、行锁 3类。\n全局锁 # 全局锁，是对整个数据库实例进行加锁，如通过命令Flush tables with read lock (FTWRL)加全局读锁，锁定后，数据更新（增删改）、数据定义（建表、修改表等）都会被阻塞。\n其作用，主要是做全库逻辑备份，也就是把全表select出来存成文本。\n加全局读锁之后，再开始备份，但是有风险：\n 如果是对主库备份，开了全局读锁之后，库不能写入，意味着业务基本不可用； 如果是对从库备份，开了全局读锁之后，从库新同步过来的binlog假如有表结构修改的操作，会导致因为拿不到MDL（metadata lock）而阻塞，无法修改表结构这一个阻塞还好，更严重的是会导致后续所有的拿MDL读锁的操作失败，包括正常的更新数据。因此这种方法容易造成主从同步延迟；  **备份数据，为什么要加锁，能不能不加锁？**不能！数据一致性，这个很好理解，不解释！\n有没有不加全局锁的方法，有，但是要看引擎是否支持事务：\n  MyISAM引擎，不支持事务，只能用加全局读锁的方式锁定之后再开始备份\n  InnoDB引擎，支持事务，主库备份的时候通过\u0026ndash;single-transaction，开启独立的事务进行备份：\n 因为备份时候设定的事务隔离级别是RR（可重复读），一致性问题不用担心了； 备份过程中也会拿MDL lock读锁，如果备份过程中有表结构更新操作，也可能会因为拿不到MDL写锁而阻塞，也会阻塞后续的所有数据更新动作； 针对上面问题，AliSQL提了个PR已经合入MariaDB，即尝试修改表的时候加个超时时间，如果过了超时时间还没有拿到MDL锁，则失败，等后续重试，这样至少不会阻塞正常的数据更新操作；   这里涉及了表锁中的一种：MDL锁\n   加全局读锁，可以将数据库设置为只读，还有一种办法，设置全局变量set global readonly=true，但是这种方式，风险更高：\n 通常这个属性还用来区分一个数据库是主库还是从从库，如果贸然修改这个变量，可能会造成一些其他应用的误判； 假如客户端申请了加全局锁且成功之后，如果客户端崩溃了，这个全局锁还是可以自动被释放掉的，库还是可以写入的。但是，如果客户端通过全局变量将库设置为了只读，那么客户端崩溃后，库也是只读的，不可写入的；  表锁 # 加表锁，主要有两种形式，lock tables\u0026hellip; 和 MDL lock。\nlock tables \u0026hellip; with read/write #   这种加锁方式，对应的解锁方式是 unlock tables\n  这种加锁方式，对其他线程能否读写、当前线程能否读写都做了明确的限制。假定当前线程p读表t1加读锁、对表t2加写锁，那么：\n 其他线程q是不能对t1执行写操作的，对t2也不能执行读操作，这个好理解； 当前线程p也是不能对t1执行写操作的，也不能对t2执行读操作；   可以理解成没有考虑锁的重入、读写排他性；",content:"根据加锁的范围，mysql中的锁可以分为：全局锁、表锁、行锁 3类。\n全局锁 # 全局锁，是对整个数据库实例进行加锁，如通过命令Flush tables with read lock (FTWRL)加全局读锁，锁定后，数据更新（增删改）、数据定义（建表、修改表等）都会被阻塞。\n其作用，主要是做全库逻辑备份，也就是把全表select出来存成文本。\n加全局读锁之后，再开始备份，但是有风险：\n 如果是对主库备份，开了全局读锁之后，库不能写入，意味着业务基本不可用； 如果是对从库备份，开了全局读锁之后，从库新同步过来的binlog假如有表结构修改的操作，会导致因为拿不到MDL（metadata lock）而阻塞，无法修改表结构这一个阻塞还好，更严重的是会导致后续所有的拿MDL读锁的操作失败，包括正常的更新数据。因此这种方法容易造成主从同步延迟；  **备份数据，为什么要加锁，能不能不加锁？**不能！数据一致性，这个很好理解，不解释！\n有没有不加全局锁的方法，有，但是要看引擎是否支持事务：\n  MyISAM引擎，不支持事务，只能用加全局读锁的方式锁定之后再开始备份\n  InnoDB引擎，支持事务，主库备份的时候通过\u0026ndash;single-transaction，开启独立的事务进行备份：\n 因为备份时候设定的事务隔离级别是RR（可重复读），一致性问题不用担心了； 备份过程中也会拿MDL lock读锁，如果备份过程中有表结构更新操作，也可能会因为拿不到MDL写锁而阻塞，也会阻塞后续的所有数据更新动作； 针对上面问题，AliSQL提了个PR已经合入MariaDB，即尝试修改表的时候加个超时时间，如果过了超时时间还没有拿到MDL锁，则失败，等后续重试，这样至少不会阻塞正常的数据更新操作；   这里涉及了表锁中的一种：MDL锁\n   加全局读锁，可以将数据库设置为只读，还有一种办法，设置全局变量set global readonly=true，但是这种方式，风险更高：\n 通常这个属性还用来区分一个数据库是主库还是从从库，如果贸然修改这个变量，可能会造成一些其他应用的误判； 假如客户端申请了加全局锁且成功之后，如果客户端崩溃了，这个全局锁还是可以自动被释放掉的，库还是可以写入的。但是，如果客户端通过全局变量将库设置为了只读，那么客户端崩溃后，库也是只读的，不可写入的；  表锁 # 加表锁，主要有两种形式，lock tables\u0026hellip; 和 MDL lock。\nlock tables \u0026hellip; with read/write #   这种加锁方式，对应的解锁方式是 unlock tables\n  这种加锁方式，对其他线程能否读写、当前线程能否读写都做了明确的限制。假定当前线程p读表t1加读锁、对表t2加写锁，那么：\n 其他线程q是不能对t1执行写操作的，对t2也不能执行读操作，这个好理解； 当前线程p也是不能对t1执行写操作的，也不能对t2执行读操作；   可以理解成没有考虑锁的重入、读写排他性；\n   MDL lock # 表的定义都记录在表的元信息里，要对表执行增删改查等DML操作，或者对表执行表结构修改等DDL操作时，都需要现获取表的MDL锁。增删改查就是MDL读锁，修改表结构就是拿MDL写锁。\nMDL锁也是是有可能导致数据库操作阻塞的。在前面描述数据库备份操作时，我们介绍了InnoDB通过\u0026ndash;single-transaction来进行备份的方法，其中描述了MDL读写锁排他性对备份过程、binlog主备同步延迟的影响。\n也介绍了如何尽量规避这个问题：尝试修改表结构（MDL写锁）时加个超时时间，避免长时间阻塞进而导致后续的数据更新操作失败（或者，导致主备同步延迟过大）。\n行锁 # 行锁，InnoDB执行引擎支持对加行锁，以前不支持行锁的时候，就要通过表锁来解决，先锁表，再修改、再解锁表，这种效率比较低。\n 执行引擎：推荐现在没有使用InnoDB执行引擎的更换数据库引擎为InnoDB； 代码写法：有些虽然更换了引擎，但是代码中还是用的lock tables、unlock tables，这种一般替换成begin、commit就可以了；  "}),a.add({id:251,href:"/tags/global-lock/",title:"global lock",description:"",content:""}),a.add({id:252,href:"/tags/lock-tables/",title:"lock tables",description:"",content:""}),a.add({id:253,href:"/tags/mdl-lock/",title:"mdl lock",description:"",content:""}),a.add({id:254,href:"/tags/table-lock/",title:"table lock",description:"",content:""}),a.add({id:255,href:"/blog/05%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8B/",title:"05索引原理：深入浅出索引（下）",description:"前面介绍了常见的查询类型，支持查询的常用数据结构和算法，然后介绍了InnoDB执行引擎B+树的优势，主要是和机械硬盘的特性结合起来实现高性能的读写，也描述了B+树层高与可存储的数据量的计算方式，等等吧。\n这里重点介绍下索引的设计、使用方面的一些知识点，下面讨论的都是InnoDB B+树。\nuser(id,name,age), pk(id),index(name)\n  主键索引\nb+树中索引节点存储的是关键字以及指针，指向指向索引节点或者数据节点的page。索引中的关键字，可以是一个列字段，也可以是多个列字段，如果是多个列字段的话，它们出现的顺序就是定义索引时写的顺序。\ninnodb主键索引是聚集索引，叶子节点中的数据直接包含了记录行的数据。\n  普通索引\n其他普通索引，比如id为主键，在name上创建索引，这种索引的叶子节点中记录的主键的id，如果要通过name去查age之类的其他字段信息，要先通过这里的name索引查到id，然后回表，也就是通过主键索引查找到对应的记录后（实际上是主键索引查找到指针对应的page，然后遍历page里面的各个记录找到的），再去拿到age等其他信息。\n所以普通索引这样查起来会多一次回表的操作。\n  覆盖索引\n假如说现在我想通过name，直接查找到对应的age行不行啊，不想先查到id，再回表查。不回表的话，就可以考虑索引覆盖，比如创建个索引index(name,age)，这样就会先通过这个组合索引中的name找到对应的叶子节点，叶子节点中也包含了age这个关键字，就可以直接返回age。\n当然name有可能重复，所以可能查询结果不是单条记录，那还得沿着这个第一次找到的节点，向右遍历叶子节点列表，知道name不满足为止。\n由于索引中包含了age，也就不需要回表了。\n  最左前缀原则\n创建组合（联合）索引之后，查询的时候一定要注意，要用最左匹配原则才能应用索引，否则用不上索引，为什么呢？比如我们定义索引的时候是index(name,age)，那么你查询到时候where age=xxx and name=yyy，这种就没有优先用name，查询比较的时候就用不上索引，但是where name=yyy and age=xxx就能用上索引。\n为什么会这样呢？b+数索引节点中关键字，是按照定义索引时字段的顺序设置的，比较的时候也是按照这个顺序来比较。\n 如何安排组合索引内的字段顺序？将更容易用到的放前面，这样可以提高复用的程度。 由于建立了索引index(a,b)，最左前缀可以在a上引用索引，也就不需要再单独为a建立索引index(a)了。 另外就是要考虑空间原则，是不是一定要(name，age)建联合索引，那就得考虑用的频率了，如果这种查询场景不多，查询效率要求也不高，那么确实不适合建立联合索引，浪费存储空间啊。但是也不能全表扫描那么慢吧，这个时候为name建个索引，回表查age，还是可以接受的。    索引下推\n对于组合索引index(a,b,c)，我们建议使用最左前缀匹配的方式来应用索引，那么如果查询的时候第一列是匹配的，第二列不配的，这种情况下会怎么处理呢？\n5.6以前的话，会直接根据匹配到的a回表，查出记录后再对比b是否匹配，不匹配再过滤掉，很明显这种效率是比较低的。\n5.6以后的话，引入了索引下推，什么意思呢，就是在组合索引上遍历的时候就直接比较其他几个索引列字段是否匹配，不匹配直接过滤掉，也不用回表了，减少了回表次数，效率自然也就高了。\n范围查询：说下范围查询大致是怎么工作的？\n最后说下范围查询，比如 user表上的索引有pk(id), age(name)，现在查询select name,age from user where age\u0026gt;25 and age\u0026lt;30 ，这个时候会现在index(age)这个索引上找到age\u0026gt;25的一个叶子节点，然后从这个节点开始，沿着叶子节点链表，直接向右遍历，因为都是按照age有序的嘛，每遍历一个叶子节点，回表查询name假如结果集，直到发现age\u0026lt;30不成立结束。\n  g",content:"前面介绍了常见的查询类型，支持查询的常用数据结构和算法，然后介绍了InnoDB执行引擎B+树的优势，主要是和机械硬盘的特性结合起来实现高性能的读写，也描述了B+树层高与可存储的数据量的计算方式，等等吧。\n这里重点介绍下索引的设计、使用方面的一些知识点，下面讨论的都是InnoDB B+树。\nuser(id,name,age), pk(id),index(name)\n  主键索引\nb+树中索引节点存储的是关键字以及指针，指向指向索引节点或者数据节点的page。索引中的关键字，可以是一个列字段，也可以是多个列字段，如果是多个列字段的话，它们出现的顺序就是定义索引时写的顺序。\ninnodb主键索引是聚集索引，叶子节点中的数据直接包含了记录行的数据。\n  普通索引\n其他普通索引，比如id为主键，在name上创建索引，这种索引的叶子节点中记录的主键的id，如果要通过name去查age之类的其他字段信息，要先通过这里的name索引查到id，然后回表，也就是通过主键索引查找到对应的记录后（实际上是主键索引查找到指针对应的page，然后遍历page里面的各个记录找到的），再去拿到age等其他信息。\n所以普通索引这样查起来会多一次回表的操作。\n  覆盖索引\n假如说现在我想通过name，直接查找到对应的age行不行啊，不想先查到id，再回表查。不回表的话，就可以考虑索引覆盖，比如创建个索引index(name,age)，这样就会先通过这个组合索引中的name找到对应的叶子节点，叶子节点中也包含了age这个关键字，就可以直接返回age。\n当然name有可能重复，所以可能查询结果不是单条记录，那还得沿着这个第一次找到的节点，向右遍历叶子节点列表，知道name不满足为止。\n由于索引中包含了age，也就不需要回表了。\n  最左前缀原则\n创建组合（联合）索引之后，查询的时候一定要注意，要用最左匹配原则才能应用索引，否则用不上索引，为什么呢？比如我们定义索引的时候是index(name,age)，那么你查询到时候where age=xxx and name=yyy，这种就没有优先用name，查询比较的时候就用不上索引，但是where name=yyy and age=xxx就能用上索引。\n为什么会这样呢？b+数索引节点中关键字，是按照定义索引时字段的顺序设置的，比较的时候也是按照这个顺序来比较。\n 如何安排组合索引内的字段顺序？将更容易用到的放前面，这样可以提高复用的程度。 由于建立了索引index(a,b)，最左前缀可以在a上引用索引，也就不需要再单独为a建立索引index(a)了。 另外就是要考虑空间原则，是不是一定要(name，age)建联合索引，那就得考虑用的频率了，如果这种查询场景不多，查询效率要求也不高，那么确实不适合建立联合索引，浪费存储空间啊。但是也不能全表扫描那么慢吧，这个时候为name建个索引，回表查age，还是可以接受的。    索引下推\n对于组合索引index(a,b,c)，我们建议使用最左前缀匹配的方式来应用索引，那么如果查询的时候第一列是匹配的，第二列不配的，这种情况下会怎么处理呢？\n5.6以前的话，会直接根据匹配到的a回表，查出记录后再对比b是否匹配，不匹配再过滤掉，很明显这种效率是比较低的。\n5.6以后的话，引入了索引下推，什么意思呢，就是在组合索引上遍历的时候就直接比较其他几个索引列字段是否匹配，不匹配直接过滤掉，也不用回表了，减少了回表次数，效率自然也就高了。\n范围查询：说下范围查询大致是怎么工作的？\n最后说下范围查询，比如 user表上的索引有pk(id), age(name)，现在查询select name,age from user where age\u0026gt;25 and age\u0026lt;30 ，这个时候会现在index(age)这个索引上找到age\u0026gt;25的一个叶子节点，然后从这个节点开始，沿着叶子节点链表，直接向右遍历，因为都是按照age有序的嘛，每遍历一个叶子节点，回表查询name假如结果集，直到发现age\u0026lt;30不成立结束。\n  g\n"}),a.add({id:256,href:"/blog/04%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8A/",title:"04索引原理：深入浅出索引（上）",description:"索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。直接在几百页的书找一个关键词可能要找很久，但是通过附录中先通过首字母找到对应的关键词，再通过关键词对应页码找到书中对应页、对应内容，就会比较快。查词典、查电话本，都是类似的思想。\n查询类型：\n 等值查询； 区间查询；  几种索引模型：\n  hash\n这种只适合等值查询，接近O(1)的时间复杂度，不适合范围查询（比如key介于[k1,k2]之间的就得全量扫描了）。这类存储，主要有memcached及其他一些nosql存储；\n  有序数组\n在等值查询、范围查询场景中，性能都比较好，基本可以在O(log(n))时间复杂度内搞定。当然数据有序、没有重复等情况下，平均复杂度要坏一点。但是考虑到插入的场景，插入点位置及以后的数据要移动的，代价比较高。\n有序数组，只适用于静态存储引擎，不怎么变化的那种存储。\n  搜索树\n根据对树中索引节点key的数量以及对树的高度的不同，可以分为好几种，比较常见的有二叉搜索树、二叉平衡树、红黑树，这些都是二叉的，时间复杂度基本都是O(log(n))，但是考虑到平均时间复杂度二叉平衡树是最好的，但是它的插入操作涉及到大量的树调整步骤，开销较大，普通二叉搜索树的话又有可能退化为一个单支的链表，查询性能退化为O(n)。红黑树是一个比较好的选择，使用也比较广，它通过施加一些约束限制了左、右子树高度不会成为另一个的两倍，这比二叉平衡树左右子树高度差最多为1可松多了，减轻了树调整的开销。红黑树是用的比较多的。\n树的搜索效率取决于树的高度，如果树高度很高，那么查询效率自然就会比较低。考虑到机械硬盘随机访问慢的特性，每个索引节点都要取机械硬盘里面去加载的，这个很慢的。数据库设计出来是要存储大量数据的，索引关键字区分度再高，二叉树出度太低，树还是会很高的，这对存储大量数据（几千万上亿）的数据库系统来说，二叉树有点吃不消，所以B树、B+树出现了。\n试想下，二叉树的情况下，节点多了之后，树高度会很高的，每个索引节点都可能存储在机械硬盘上离散的位置，读取每个索引节点会很耗时的。\nB树是m叉树，但是B树中的非叶子节点既可能是索引节点，也可能是数据节点，数据节点之间没有形成一个有序链表，没有充分考虑到机械硬盘顺序读取效率高的特点，B+树考虑到了，所有非叶子节点都是索引节点，所有，叶子节点均为数据节点，且构成了一个有序的链表，正好能解决机械硬盘随机访问慢的问题，也能利用硬盘顺序读取快的优势。\n  m叉树中的这个m应该多大呢？这个取决于数据块的大小，以InnoDB的一个整数字段索引为例，这个N差不多是1200。树高4层的时候，就差不多可以存储17亿条数据了。\nps：类似的怎么计算呢？\n学习下怎么计算的：https://www.programmersought.com/article/65874297377/\n现代机械硬盘最大不知道多少，innodb里面定义的是索引中指针大小是6个字节，意味着2^(6*8)/2^40=256TB，这里的指针大小表示的是数据在表空间中的偏移量，可以理解成可以寻址256TB的硬盘空间？\ninnodb默认的pagesize是16KB，ok！\n 先算一个索引可以存多少指针：假定我们用bigint作为主键，8个字节，指针6字节，那一个索引节点可以存储16KB/14B=1170个关键字和指针。 再算一个叶子节点可以存多少记录：聚集索引里面叶子节点中，索引关键字是数据记录的一部分，至少大于8个字节了，我们就假定一行记录大约么为1KB吧。那么一个叶子节点可以存储记录数量为16KB/1KB=16。  现在我们笼统算法下：\n  假如树最大高度为2，那么就是根节点指针数量*每个叶子节点记录数量，可以存储1170x16=18720\n  假如数最大高度为3，那么就是1170^2*16=21902400=2190w\n  假如数最大高度为4，那么就是1170^3*16=25625808000=256亿\n  实际情况一般3层就可以满足绝大部分场景使用了，数据量大的话，也极少有业务会超过4层。所以存储很多的数据，查询效率也基本上是有保证的。\n每次查询索引节点，都代表了一次磁盘IO，所以通过主键索引查询，会比借助其他辅助索引查询、再回表的方式要快一些。\n指针6个字节，意味着可以寻址的索引地址空间很大的，256TB，哪有这么大的内存，这个东西也可以理解成磁盘上索引的偏移量，256TB的硬盘。\n但是看得出来，索引可能也很大，不一定能完全在硬盘中存储的下，也是按需加载的！\nps：为什么要用自增id作为主键，有什么好处，主要是为了避免插入时页分裂，b+树调整导致的效率低下：https://zhuanlan.zhihu.com/p/71022670\nps：innodb b+tree索引结构：https://www.programmersought.com/article/1411118316/",content:"索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。直接在几百页的书找一个关键词可能要找很久，但是通过附录中先通过首字母找到对应的关键词，再通过关键词对应页码找到书中对应页、对应内容，就会比较快。查词典、查电话本，都是类似的思想。\n查询类型：\n 等值查询； 区间查询；  几种索引模型：\n  hash\n这种只适合等值查询，接近O(1)的时间复杂度，不适合范围查询（比如key介于[k1,k2]之间的就得全量扫描了）。这类存储，主要有memcached及其他一些nosql存储；\n  有序数组\n在等值查询、范围查询场景中，性能都比较好，基本可以在O(log(n))时间复杂度内搞定。当然数据有序、没有重复等情况下，平均复杂度要坏一点。但是考虑到插入的场景，插入点位置及以后的数据要移动的，代价比较高。\n有序数组，只适用于静态存储引擎，不怎么变化的那种存储。\n  搜索树\n根据对树中索引节点key的数量以及对树的高度的不同，可以分为好几种，比较常见的有二叉搜索树、二叉平衡树、红黑树，这些都是二叉的，时间复杂度基本都是O(log(n))，但是考虑到平均时间复杂度二叉平衡树是最好的，但是它的插入操作涉及到大量的树调整步骤，开销较大，普通二叉搜索树的话又有可能退化为一个单支的链表，查询性能退化为O(n)。红黑树是一个比较好的选择，使用也比较广，它通过施加一些约束限制了左、右子树高度不会成为另一个的两倍，这比二叉平衡树左右子树高度差最多为1可松多了，减轻了树调整的开销。红黑树是用的比较多的。\n树的搜索效率取决于树的高度，如果树高度很高，那么查询效率自然就会比较低。考虑到机械硬盘随机访问慢的特性，每个索引节点都要取机械硬盘里面去加载的，这个很慢的。数据库设计出来是要存储大量数据的，索引关键字区分度再高，二叉树出度太低，树还是会很高的，这对存储大量数据（几千万上亿）的数据库系统来说，二叉树有点吃不消，所以B树、B+树出现了。\n试想下，二叉树的情况下，节点多了之后，树高度会很高的，每个索引节点都可能存储在机械硬盘上离散的位置，读取每个索引节点会很耗时的。\nB树是m叉树，但是B树中的非叶子节点既可能是索引节点，也可能是数据节点，数据节点之间没有形成一个有序链表，没有充分考虑到机械硬盘顺序读取效率高的特点，B+树考虑到了，所有非叶子节点都是索引节点，所有，叶子节点均为数据节点，且构成了一个有序的链表，正好能解决机械硬盘随机访问慢的问题，也能利用硬盘顺序读取快的优势。\n  m叉树中的这个m应该多大呢？这个取决于数据块的大小，以InnoDB的一个整数字段索引为例，这个N差不多是1200。树高4层的时候，就差不多可以存储17亿条数据了。\nps：类似的怎么计算呢？\n学习下怎么计算的：https://www.programmersought.com/article/65874297377/\n现代机械硬盘最大不知道多少，innodb里面定义的是索引中指针大小是6个字节，意味着2^(6*8)/2^40=256TB，这里的指针大小表示的是数据在表空间中的偏移量，可以理解成可以寻址256TB的硬盘空间？\ninnodb默认的pagesize是16KB，ok！\n 先算一个索引可以存多少指针：假定我们用bigint作为主键，8个字节，指针6字节，那一个索引节点可以存储16KB/14B=1170个关键字和指针。 再算一个叶子节点可以存多少记录：聚集索引里面叶子节点中，索引关键字是数据记录的一部分，至少大于8个字节了，我们就假定一行记录大约么为1KB吧。那么一个叶子节点可以存储记录数量为16KB/1KB=16。  现在我们笼统算法下：\n  假如树最大高度为2，那么就是根节点指针数量*每个叶子节点记录数量，可以存储1170x16=18720\n  假如数最大高度为3，那么就是1170^2*16=21902400=2190w\n  假如数最大高度为4，那么就是1170^3*16=25625808000=256亿\n  实际情况一般3层就可以满足绝大部分场景使用了，数据量大的话，也极少有业务会超过4层。所以存储很多的数据，查询效率也基本上是有保证的。\n每次查询索引节点，都代表了一次磁盘IO，所以通过主键索引查询，会比借助其他辅助索引查询、再回表的方式要快一些。\n指针6个字节，意味着可以寻址的索引地址空间很大的，256TB，哪有这么大的内存，这个东西也可以理解成磁盘上索引的偏移量，256TB的硬盘。\n但是看得出来，索引可能也很大，不一定能完全在硬盘中存储的下，也是按需加载的！\nps：为什么要用自增id作为主键，有什么好处，主要是为了避免插入时页分裂，b+树调整导致的效率低下：https://zhuanlan.zhihu.com/p/71022670\nps：innodb b+tree索引结构：https://www.programmersought.com/article/1411118316/\n"}),a.add({id:257,href:"/blog/03%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81/",title:"03事务隔离：为什么你改了我还看不见",description:"数据库事务（刚性事务）\n事务特性：ACID\n Atomic Consistency Isolation Durability  事务隔离性及事务隔离级别：\n read uncommited read committed repeatable read serializable  在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念； 而“串行化”隔离级别下直接用加锁（读写冲突、写写冲突）的方式来避免并行访问。  事务隔离性级别通过变量 transaction_isolation 来设置。\nMVCC：\n在执行更新操作的时候，也会对应的插入一行“回滚记录”，用于MVCC（多版本并发控制）中构建不同时间启动的事务的视图，这主要是为了维持一个可重复读的视图。\n比如现在执行操作假如现在c=1，执行update c=2, c=3, c=4的操作，那么对应的就会插入四行回滚记录，将2回滚为1，将3回滚为2，将4回滚为3。\n三个更新操作的时刻t1、t2、t3，相当于确立了三个边界，边界时间点前后可能会有不同的事务启动、结束。那些依然还未结束的事务，通过他们的启动时间与回滚记录插入时的时间做对比，就可以找到应该依次执行哪些回滚记录来恢复到启动事务时的数据库状态，通过这种方式来重建一个可重复读的视图。\n这就是MVCC的要义。\n这些回滚日志，多了之后也会占用存储空间，浪费资源，需要清除？但是假如有个事务是时刻t启动的，那么时刻t之后的回滚日志都是要保留的，如果这个事务执行时间很长，就会导致回滚日志积累很多，浪费资源。因此不建议使用长事务。\n查找执行时间超过60s的长事务：\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60  了解下这个事务统计表几个比较有用的字段：\nmysql\u0026gt; desc innodb_trx; +----------------------------+-----------------+------+-----+---------+-------+ | Field | Type | Null | | +----------------------------+-----------------+------+-----+---------+-------+ | trx_id | bigint unsigned | NO | 事务id | | trx_state | varchar(13) | NO | 事务状态，如RUNNING | | trx_started | datetime | NO | 事务启动时间 | .",content:"数据库事务（刚性事务）\n事务特性：ACID\n Atomic Consistency Isolation Durability  事务隔离性及事务隔离级别：\n read uncommited read committed repeatable read serializable  在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念； 而“串行化”隔离级别下直接用加锁（读写冲突、写写冲突）的方式来避免并行访问。  事务隔离性级别通过变量 transaction_isolation 来设置。\nMVCC：\n在执行更新操作的时候，也会对应的插入一行“回滚记录”，用于MVCC（多版本并发控制）中构建不同时间启动的事务的视图，这主要是为了维持一个可重复读的视图。\n比如现在执行操作假如现在c=1，执行update c=2, c=3, c=4的操作，那么对应的就会插入四行回滚记录，将2回滚为1，将3回滚为2，将4回滚为3。\n三个更新操作的时刻t1、t2、t3，相当于确立了三个边界，边界时间点前后可能会有不同的事务启动、结束。那些依然还未结束的事务，通过他们的启动时间与回滚记录插入时的时间做对比，就可以找到应该依次执行哪些回滚记录来恢复到启动事务时的数据库状态，通过这种方式来重建一个可重复读的视图。\n这就是MVCC的要义。\n这些回滚日志，多了之后也会占用存储空间，浪费资源，需要清除？但是假如有个事务是时刻t启动的，那么时刻t之后的回滚日志都是要保留的，如果这个事务执行时间很长，就会导致回滚日志积累很多，浪费资源。因此不建议使用长事务。\n查找执行时间超过60s的长事务：\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60  了解下这个事务统计表几个比较有用的字段：\nmysql\u0026gt; desc innodb_trx; +----------------------------+-----------------+------+-----+---------+-------+ | Field | Type | Null | | +----------------------------+-----------------+------+-----+---------+-------+ | trx_id | bigint unsigned | NO | 事务id | | trx_state | varchar(13) | NO | 事务状态，如RUNNING | | trx_started | datetime | NO | 事务启动时间 | ... | trx_tables_locked | bigint unsigned | NO | 增删记录会锁表的 | ... | trx_rows_locked | bigint unsigned | NO | 更新记录会锁行的 | | trx_rows_modified | bigint unsigned | NO | 修改的行数量 | ... | trx_isolation_level | varchar(16) | NO | 当前事务隔离级别 | ... +----------------------------+-----------------+------+-----+---------+-------+  "}),a.add({id:258,href:"/blog/02%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/",title:"02一条SQL更新语句是如何执行的",description:"这里涉及的日志类型：\n  执行引擎层：innodb redolog\n  mysql服务层：mysql binlog\n  买东西赊账为例，老板通常有个账本，上面记录了所有人总的赊账情况，但是忙的时候是来不及查、计算的，可能就会在一个粉板上记录当前次的赊账情况，等打烊之后再去算，算完更新到账本上。\nmysql的设计者，采用了类似老板记账的方式，来提高更新效率。\nWAL：write ahead log，关键点就是：\n 先写日志，再写磁盘 也就是先写粉板，不忙的时候再写账本；   WAL log写操作基本只是追加，磁盘顺序写，效率高；写记录到磁盘还要考虑B+树特性、磁盘特性，要找到在哪里插入，涉及到多次随机读，效率是比较差的。\n所以说先写WAL这里是提高更新效率是没有问题的，当然了，也提供了崩溃后恢复的一种保证。\n 具体说，就是innodb引擎会：\n 先把记录写到redo log里面； 再更新内存，（这个时候就算更新完成了）； 然后比较空闲的时候再写回磁盘。  但是如果粉板写满了怎么办呢？老板只能停下手中的活，先把粉板上的赊账记录算完腾到账本上，然后擦掉粉板腾出新的空间，然后再继续赊账。\n类似地，innodb的redo log也是固定大小的（和粉板类似），从头到尾写满了，就得再从头写。redolog维护了两个指针：\n write pos，写最新赊账记录的位置，++，到头后再开始； checkpoint，表示已经将对应操作同步到磁盘数据文件的位置，相当于腾空的粉板位置，可以继续记录赊账位置。  当writepos追上checkpoint的时候，表示写满了，这时候mysql就得和老板一样停下来算账，不能接受新的更新请求，这样把checkpoint推进以下之后，再继续接受更新请求。\n这样即使数据库运行期间崩溃了，但是有了这个redolog，就可以将之前的操作全部恢复，不会丢失，这个能力称之为crash-safe。\n这里的write pos、checkpoint的作用，是为了提高更新效率，延时写入磁盘用的。\n一个更新操作是如何执行的？\n  当执行一个更新操作时，执行器找到记录对应的行，请求执行引擎返回行数据，如果行数据在内存中，执行引擎就从内存直接返回，反之还需要从磁盘上读回来返回。执行器拿到行数据之后完成更新，比如某列N=N+1，并请求执行引擎更新行数据。\n  执行引擎将数据更新到内存中，然后写redo log，然后返回给执行引擎成功，表示进入prepare状态，随时可提交。\n 为什么不先写redolog，再写内存？\n没有实质区别吧，不都写了内存嘛。是担心数据不一致问题吗？别担心，mysql用了MVCC的，（可重复读级别）不会出现不可重复读的。\n   执行器收到正常响应后，生成binlog并写入磁盘binlog文件，然后对刚才的操作继续请求置引擎发起commit操作。\n 如果写binlog失败会怎样？mysql中有个选项binlog_error_action，用来控制如果binlog写失败：\n  上述变量，其默认值是ABORT_SERVER，即mysqld退出。需要排除binlog写失败原因（如磁盘满、inode耗光等）后再启动起来。\n  还可以将上述变量设置为IGNORE_ERROR，就是写binlog失败就失败，继续执行，此时就会导致没有生成binlog，无法同步给slave，master-slave数据就会变得不一致。而且也会影响到数据备份。一般是不太能接受的。\n  重启后，innodb中有prepare阶段的redo log（未commited），这个时候binlog中又没有对应的binlog，此时就会rollback掉。",content:"这里涉及的日志类型：\n  执行引擎层：innodb redolog\n  mysql服务层：mysql binlog\n  买东西赊账为例，老板通常有个账本，上面记录了所有人总的赊账情况，但是忙的时候是来不及查、计算的，可能就会在一个粉板上记录当前次的赊账情况，等打烊之后再去算，算完更新到账本上。\nmysql的设计者，采用了类似老板记账的方式，来提高更新效率。\nWAL：write ahead log，关键点就是：\n 先写日志，再写磁盘 也就是先写粉板，不忙的时候再写账本；   WAL log写操作基本只是追加，磁盘顺序写，效率高；写记录到磁盘还要考虑B+树特性、磁盘特性，要找到在哪里插入，涉及到多次随机读，效率是比较差的。\n所以说先写WAL这里是提高更新效率是没有问题的，当然了，也提供了崩溃后恢复的一种保证。\n 具体说，就是innodb引擎会：\n 先把记录写到redo log里面； 再更新内存，（这个时候就算更新完成了）； 然后比较空闲的时候再写回磁盘。  但是如果粉板写满了怎么办呢？老板只能停下手中的活，先把粉板上的赊账记录算完腾到账本上，然后擦掉粉板腾出新的空间，然后再继续赊账。\n类似地，innodb的redo log也是固定大小的（和粉板类似），从头到尾写满了，就得再从头写。redolog维护了两个指针：\n write pos，写最新赊账记录的位置，++，到头后再开始； checkpoint，表示已经将对应操作同步到磁盘数据文件的位置，相当于腾空的粉板位置，可以继续记录赊账位置。  当writepos追上checkpoint的时候，表示写满了，这时候mysql就得和老板一样停下来算账，不能接受新的更新请求，这样把checkpoint推进以下之后，再继续接受更新请求。\n这样即使数据库运行期间崩溃了，但是有了这个redolog，就可以将之前的操作全部恢复，不会丢失，这个能力称之为crash-safe。\n这里的write pos、checkpoint的作用，是为了提高更新效率，延时写入磁盘用的。\n一个更新操作是如何执行的？\n  当执行一个更新操作时，执行器找到记录对应的行，请求执行引擎返回行数据，如果行数据在内存中，执行引擎就从内存直接返回，反之还需要从磁盘上读回来返回。执行器拿到行数据之后完成更新，比如某列N=N+1，并请求执行引擎更新行数据。\n  执行引擎将数据更新到内存中，然后写redo log，然后返回给执行引擎成功，表示进入prepare状态，随时可提交。\n 为什么不先写redolog，再写内存？\n没有实质区别吧，不都写了内存嘛。是担心数据不一致问题吗？别担心，mysql用了MVCC的，（可重复读级别）不会出现不可重复读的。\n   执行器收到正常响应后，生成binlog并写入磁盘binlog文件，然后对刚才的操作继续请求置引擎发起commit操作。\n 如果写binlog失败会怎样？mysql中有个选项binlog_error_action，用来控制如果binlog写失败：\n  上述变量，其默认值是ABORT_SERVER，即mysqld退出。需要排除binlog写失败原因（如磁盘满、inode耗光等）后再启动起来。\n  还可以将上述变量设置为IGNORE_ERROR，就是写binlog失败就失败，继续执行，此时就会导致没有生成binlog，无法同步给slave，master-slave数据就会变得不一致。而且也会影响到数据备份。一般是不太能接受的。\n  重启后，innodb中有prepare阶段的redo log（未commited），这个时候binlog中又没有对应的binlog，此时就会rollback掉。\n   执行引擎把刚才写入的redolog的状态修改为commit状态，更新完成。\n 万一这一步执行的时候，服务crash了怎么办？这个时候innodb也写了redo log了，服务层也写了binlog了，怎么办呢？\n  如果redo log里面已经修改成commited了，重启后，crash recover的时候innodb是可以恢复这个数据的；\n  如果redo log里面没有改成commited呢？以为都是两阶段提交，因为binlog里面有记录，但是redo log没有改成commited，所以可能要服务层发起commit操作？\nfixme 以后再确定下这个问题吧！\n     执行引擎在合适的（通常是空闲的）时候将redolog中数据同步到磁盘数据文件。\n  注意这里将 redolog 拆成两部分prepare+commit，这就是典型的两阶段提交。为什么要两阶段提交，是为了保持两份日志文件的完整性，让两份日志文件之间的逻辑一致。\n不妨从恢复数据库到半个月内任意一秒t的状态，从这个角度来思考这个问题？\n 如何恢复？首先t之前的最近的一次全量备份，先恢复到临时数据库中，然后找这次全量备份之后t之前的binlog，并恢复到临时数据库中。然后将临时数据库中的数据恢复到线上。 再看为什么用两阶段提交？不用就不能保证两个日志文件的完整性（c=c+1）：  假如先写完redolog再写binlog，redolog将c=0改成了1，但是binlog写成功前挂掉了，这样本地数据是c=1，但是归档日志同步给别人后丢了一个事务操作，或者自己重启后恢复的时候也丢了一个操作c变成了0。 假如先写完binlog后再写redolog，binlog中记录了c=c+1=1，但是redolog写失败了，此时库中数据其实是0，如果binlog同步给别人，按binlog恢复出的数据是1，而不是0，也不一致。如果是挂掉之后恢复，能一致都是1。    可见如果不适用prepare-commit两阶段提交的话，日志中记录的状态和真实的存储情况就会出现不一致。\n不只是数据库误删表之类的才会有恢复的需要，其实mysql集群扩容，比如多加几个读副本，也是需要这里的全量备份+binlog同步来完成“数据恢复”的。\nbinlog是mysql服务层面记录的原始操作日志，比如给某列+1，innodb的redolog是物理日志，记录的是在哪个物理页上写什么数据，binlog才是master-slave同步用的，这个在功能上是和raft中的wal log功能定位一致的。\nrelog的初衷，只是为了提高更新的效率，而非实现master-slave的数据一致性。binlog才是为了追求数据一致性的。wal只是一种操作上的描述，raft中的也是叫wal，但是也应该看到都叫wal，但是这只是一种策略，实现出来的实际功能、定位可能是完全不同的。\nredolog空间是有限的，毕竟它是为了提高更新效率用的，mysql是追加写的，写完一个binlog文件继续写下一个binlog文件，不会覆盖以前的，它的定位是要实现主从节点的数据同步，所以binlog日志也称为归档日志，是归档用的，用来实现主从间数据同步的。\n举一反三：\n联想到了raft算法中，为了保证数据强一致的效果，也采取了WAL的方式。比如master收到一个更新请求的时候，它会写本地log，并维护了几个索引值nextIndex、commitIndex，nextIndex是下次准备同步给slave节点的日志的索引位置，但是同步给很多slave节点的过程是并发的，可能有的日志索引项在某些节点上有冲突，没有收到多数投票，或者master更新比较快，这都会导致master这边的commitIndex\u0026lt;nextIndex。commitIndex表示收到了多数的投票master已经提交到状态机的日志项的索引位置。commitIndex也会同步给其他的节点，其他节点可以把commitIndex当做为一个可以可靠的对本地log进行持久化的参考值，commitIndex之前的日志项都可以提交到状态机，写入到磁盘数据文件，完成持久化。而commitIndex之后的日志条目，都是有可能会被作为的，这通常和分布式系统中出现分区有关系。\n我们可以看到，这里的wal日志，write ahead log，其本质就是在真正的完成一项操作之前，先日志记录成功，后续就可以有个保证，即出现失败后也可以进行可靠地重试，不至于数据出现丢失。\n两个比较关键的参数：\n  redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。\n  sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。\n  另外，“两阶段提交”也是分布式系统中保证“数据逻辑”一致性的常用方案。\n另外备份的频率怎么决定呢？一周一次全量备份，还是一天一次。这个要根据“业务重要性”、“成本”、以及“可允许的最长恢复时间”来决定。\n 业务重要，预算客观，那就尽量减少恢复时间，一天一次备份； 如果不是那么重要，预算吃紧，也对较长的数据恢复时间有一定的容忍度，那么就一会走一次备份。  "}),a.add({id:259,href:"/tags/update/",title:"update",description:"",content:""}),a.add({id:260,href:"/blog/01%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/",title:"01一条SQL查询语句是如何执行的",description:"MySQL基础架构\nmysql基础架构示意图，及主要流程介绍\nmysql 连接及内存管理\nmysql 8.0删除了查询缓存，为什么：https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/\n优化器：存在多个索引，应该用哪一个？\nmysql select语句中不存在的列，是在哪个阶段分析出来的呢？分析器\nmysqld程序入口:\n main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/main.cc#L23:12 mysqld_main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/mysqld.cc#L7680:5  ",content:"MySQL基础架构\nmysql基础架构示意图，及主要流程介绍\nmysql 连接及内存管理\nmysql 8.0删除了查询缓存，为什么：https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/\n优化器：存在多个索引，应该用哪一个？\nmysql select语句中不存在的列，是在哪个阶段分析出来的呢？分析器\nmysqld程序入口:\n main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/main.cc#L23:12 mysqld_main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/mysqld.cc#L7680:5  "}),a.add({id:261,href:"/tags/select/",title:"select",description:"",content:""}),a.add({id:262,href:"/tags/cas/",title:"cas",description:"",content:""}),a.add({id:263,href:"/tags/cmpxchg/",title:"cmpxchg",description:"",content:""}),a.add({id:264,href:"/tags/futex/",title:"futex",description:"",content:""}),a.add({id:265,href:"/categories/go%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"go设计实现",description:"",content:""}),a.add({id:266,href:"/blog/2021-04-17-locks%E5%AE%9E%E7%8E%B0%E9%82%A3%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%95%85%E4%BA%8B/",title:"Locks实现:背后不为人知的故事",description:"从事软件开发多年的你，真的了解locks背后的那些故事吗？锁是如何实现的，无锁真的是没有任何同步吗，为什么总是谈锁色变，锁究竟有哪些开销。本文将结合go sync.Mutex讨论下这些问题。",content:"从事软件开发多年的你，真的理解locks背后的那些故事吗？锁是如何实现的，无锁指的又是什么，无锁真的移除了任何同步操作吗？为什么大家总是谈锁色变，锁的开销真的有那么大吗，平时编码中又该注意些什么呢？本文将结合go sync.Mutex对这些问题进行讨论。\n并发：我们关心什么 # 并发编程，开发人员应该对原子性、指令重排有深刻的认识。\n原子性 # 大家都了解过数据库事务的原子性，类似地，程序中也经常有些操作也需要达到类似的效果——被某种类似事务的机制“保护”起来，要么全部执行要么全部不执行。通常我们将这样需要保护的代码段称为临界区。我们希望临界区内的代码要么全部执行要么全部不执行，达到这种原子性的效果。\n其实不只是代码段，给一个int变量赋值，也需要考虑原子性，因为在不同的操作系统、处理器平台上，可能一个简单的int变量赋值需要涉及多条机器指令，而在多条指令执行期间，则可能发生各种事件，比如被其他CPU核的赋值指令写乱了同一变量的数据。设想下一个int变量4字节，但是处理器平台只有16位mov指令。再或者执行i++（i为int类型）操作，实际上是包含了read-modify-write三个操作，这几个操作中间也可能插入其他指令执行。当然一条机器指令也可能不是原子的，比如add src, dst，src和dst都是内存地址，这里就涉及到读取src和dst、计算、写回dst的多个操作……更不用说一个包含了多个字段的struct结构体的赋值了。\n这类原子性问题，可以通过一些相当低级的原子操作来保证，如int变量i++，可以考虑lock add指令（假定操作数位宽和int变量相同），稍复杂的数据结构（如struct）也可以使用一些“高级锁”来做同步保证，如go中的sync.Mutex。\n指令重排 # 指令重排的根源在于CPU的设计，古老的CPU只有一条取指、译码、执行、访存、写回的功能电路。联想下假如一个单线程程序执行阻塞网络IO的时候会发生什么，整个程序全阻塞在这里干不了其他的。CPU也存在类似问题，假如一条指令执行过程中因为数据没ready的问题不能执行，或者碰到多CPU多核间cache一致性同步，那CPU会stall，后续的指令都无法执行。\n所以CPU为了提高指令吞吐，增加了多条流水线设计，可以同时执行多条指令的取指、译码、执行、访存、写回，当然这其中有些指令是有数据依赖的，现代处理器支持寄存器重命名、指令乱序执行、重排序缓冲等功能，都是保证CPU执行效率的常用手段。如果想了解这方面的内容，see Computer Architecture: Dynamic Execution Core及系列课程Computer Architecture。这里贴一张超标量处理器的简图，方便大家理解这些优化手段所在的位置：\n 为什么要指令重排：\n为什么要指令重排呢？\n因为希望提高cpu指令吞吐，就要并行执行指令，要并行执行指令，就要分析出哪些指令之间有数据依赖的，表面上一个架构寄存器RAX可能被相邻多条指令使用，但是可能是一个伪数据依赖，就需要通过分析、寄存器重命名（如RAX重命名为物理寄存器R11）来消除伪数据依赖，从而允许其在执行阶段并行执行（out-of-order）。\n一条指令的执行过程，会分为多个阶段，有些阶段是按序执行的（in-order），有些则是乱序执行的（out-of-order）。在指令乱序执行之后，可能会对程序正确性造成影响？影响究竟有多大，就需要参考硬件内存一致性模型，比如Intel x86处理器采用的是TSO模型（Total Store Order）, see x86-TSO: A Rigorous and Usable Programmer\u0026rsquo;s Model for x86 Multiprocessors。\n指令重排带来的问题：\n指令在CPU乱序执行，在某些并发场景下，可能会带来一些微妙的问题。比如：\ntype num struct { a int b int } n := \u0026amp;num{} go func() { n.a = 1; n.b = 2; }() // g1 go func() { n.a = 2; n.b = 1; }() // g2  你们说最终n.a，n.b的结果是多少呢？不确定的，虽然go现在支持64位系统，现在处理器基本也都有64位mov指令，对a、b单独赋值都是原子的，但是对n整体的赋值不是。由于没有对n做保护，g1、g2中的赋值指令也没有什么数据一来，到时候乱序执行，g1 g2执行完成后，\u0026lt;n.a,n.b\u0026gt;的可能结果是：\u0026lt;1, 2\u0026gt; \u0026lt;1, 1\u0026gt; \u0026lt;2,1\u0026gt; \u0026lt;2,2\u0026gt;，这几种都有可能，而不只是有\u0026lt;1,2\u0026gt; \u0026lt;2,1\u0026gt;两种可能。\n这就是指令重排造成的影响，如果我们在出现了指令重排的情况下，去做一些关键的判断逻辑，可能就会带来严重的bug。\n这里重新回顾了下原子性、指令重排的含义，以及对程序正确性可能带来的影响，下面我们将尝试进一步考虑如何解决这些问题。\n内存屏障：阻止指令重排 # 首先，我们看如何解决指令重排序问题，解铃还须系铃人，CPU流水线乱序执行带来的问题，还需要CPU自己提供解决方案。CPU如何阻止指令重排序呢？\n内存屏障，可以用来阻止屏障前后的指令共同参与重排序，保证屏障后的指令不会出现在屏障前执行，保证屏障前的指令不会在屏障后执行。相当于屏障之前和之后确立了happens-before关系，保证了屏障之前的操作对屏障之后的操作都是可见的。\nCPU中通常提供了如下几条指令，用以建立内存屏障：\n lock：指令前缀，修饰指令保证指令执行时的排他性、原子性和完全内存屏障 lock cmpxchg：cmpxchg比较并交换，配合lock前缀实现CAS mfence：完全内存屏障（load+store） lfence：读内存屏障（load） sfence：写内存屏障（store）  一些库函数或者编程语言提供的标准库，可以选择上述某汇编指令来实现内存屏障，或者实现CAS（基本是包装下lock cmpxchg），并进一步实现各种高级锁，如spinlock、sync.Mutex。\n在继续介绍内存屏障的内容之前，先说明下lock prefix的工作原理。lock prefix的使用，顾名思义，就是在一些涉及访存的指令时，编码时在指令前面添加一个前缀lock。\n这个前缀有什么用呢？处理器碰到lock前缀的指令时会生成一个lock信号，这个信号会发送到总线上对要访问的操作数地址进行锁定，意思就是在当前这条指令结束之前，其操作数所在的内存区域不允许被其他指令访问。\n通过这种方式保证了当前这条指令操作的原子性。\n ps: 前面提到了lock指令修饰、mfence指令都可以构建完全内存屏障，都涉及到cache invalidation的操作，自然能够保证多核多线程下的可见性问题。\n 内存屏障：到底是什么 # 写并发程序，Happens-Before关系经常挂嘴边，Happens-Before关系是很容易理解的，因为它是一个编程语言的内存模型明确定义的，像Java、Go都有对内存模型的清晰定义，但是有的语言没有。举几个例子：go中包级别变量的初始化操作与包内func init()之间存在Happens-Before关系，一个锁的Unlock和下次的Lock之间也存在HB关系，chan的send、recv之间也存在HB关系……\n我们想要理解的是Happens-Before定义好之后，是如何实现的？当然是借助内存屏障了。那内存屏障怎么实现的，通过处理器提供的上述几条指令。那我想再问下这几条指令干了啥，为什么这几条指令就可以实现内存屏障。\n计算机中包含了太多分层的设计思想，硬件对大多数软件开发人员来说是个黑盒，似乎管好分内的事，永远将它当做一个黑盒就好了。\nWell，处理器到底怎么实现内存屏障的还是比较吸引我，上面的所有回答，对我没有什么实质的帮助，那就来看看硬件层面是怎么实现的。如果不了解硬件设计、工作原理，只站在软件角度，是很难搞明白的，这个是很现实的问题，尽管了解了之后会发现很简单，但是钻到这里也确实需要时间。\n内存屏障类型 #  全内存屏障（mfence）：barrier之前的load/store操作均比之后的先完成，且前后的指令不能共同参与指令重排序； 读屏障（lfence）：barrier之前的load比之后的load先完成； 写屏障（sfence）：barrier之前的store比之后的store先完成；  不同的处理器，均提供了自己的屏障指令，但是这些指令不管有什么异同，最终都与硬件设计相关，所以来看下现代处理器的一个大致设计。\n处理器架构 # 下面是一个用来解释内存屏障的精简的处理器架构示意图，大约包含如下几部分。\n  多个CPU或CPU Core之间通过总线连接； CPU通过总线与主存（memory）连接； 每个CPU都有自己的本地cache，通过cache一致性协议（如MESI/MESIF）与其他CPU Core维护一个一致的数据视图；  说起这里的一致性视图，我建议读者尝试了解下，会更好：\n 硬件内存一致性模型 编程语言内存模型  下面结合上图，我们介绍下一此数据更新操作涉及的过程。\n引入store buffer # CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销（执行cache一致性协议），CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。\n数据更新不直接写cacheline而是先写到store buffer，后面需要时再落cache并通知其他cache失效（执行cache一致性协议），这样CPU就可以减少stall继续执行指令。\n 引入invalidate queue # CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI/MESIF消息invalidate。\n正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。\n必要性及引入的问题 # 这么设计的必要性：\n 减少CPU更新本地cacheline、响应一致性协议invalidate通知导致的CPU stall问题，提高CPU整体利用率。 另外storebuffer、invalidate queue使我们有了指令重排的契机。  这么设计引入的问题：\n store buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见； invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据； cache一致性协议：它就是用来解决多个CPU共享一致性视图而设计的，但它只是一个协议，具体不同硬件设计的时候，某些屏障指令实现的时候要通过这里的cache一致性协议来保证多CPU、多核数据视图的一致性（可以参考硬件内存一致性模型、cache一致性协议相关的知识，加深理解）；  处理器执行操作变化 # 如果没有store buffer、invalidate queue，MESI和cache如何工作？\n 当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate； 当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据； CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。  如果引入了store buffer、invalidate queue之后，又该如何工作呢？\n 必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate； 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据；  处理器屏障指令 # 总结一下：\n 这里的读写屏障要依赖处理器提供的屏障指令 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 lock; addl来实现读写屏障 smp_mb/smp_rmb/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令lock;addl同时实现全屏障/读屏障/写屏障足矣。 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了。  gc屏障 isn\u0026rsquo;t 内存屏障 # ps：有些人还把GC Barrier和Memory Barrier搞混了，碰到不止一个同学了：\n GC Barrier，是编译器插入的一些代码片段，用来跟踪mutator对heap做的修改； Memory Barrier，则就是本文讨论涉及的内容，是处理器提供的一种低级的并发同步操作；  Lock prefix VS Locks # CAS，一般都是基于处理器指令 lock cmpxchg来实现的，这里一定要搞明白，这里虽然指令修饰前缀的字面含义也是lock，翻译过来也是锁，但这并非我们通俗意义上的锁。\n我们平时说的轻量级锁、重量级锁，比如spinlock、futex等，或者sync.Mutex, sync.RWMutex，这些锁都是“高级锁”，而处理器指令的lock prefix只是对单条指令执行的排他性进行控制。\n后者为前者实现提供了基础支持，但是不是一回事。比如，lock+cmpxchg基础上可以包装常用的cas操作，如golang中的atomic.CompareAndSwap(\u0026hellip;)，或者可以包装解决ABA问题的CAS操作。\n来看一下golang中CAS操作实现：\n# filename: atomic_amd64.go //go:noescape func Cas64(ptr *uint64, old, new uint64) bool # filename: atomic/doc.go func CompareAndSwapInt64(ptr *uint64, old, new uint64) bool # filename: atomic_amd64.s // bool	·Cas64(uint64 *val, uint64 old, uint64 new) // Atomically: //	if(*val == *old){ //	*val = new; //	return 1; //	} else { //	return 0; //	} TEXT ·Cas64(SB), NOSPLIT, $0-25 MOVQ	ptr+0(FP), BX MOVQ	old+8(FP), AX MOVQ	new+16(FP), CX LOCK # LOCK CMPXCHGQ, 排他性比较并交换 CMPXCHGQ	CX, 0(BX) SETEQ	ret+24(FP) RET TEXT ·CompareAndSwapInt64(SB),NOSPLIT,$0 JMP	runtime∕internal∕atomic·Cas64(SB) # 调用的是上面的Cas64  可以看到，它就是用lock cmpxchg来实现的，常用的atomic.CompareAndSwap也差不多了多少，还是调用的Cas64。\n然后我们再来看几个atomic包下的操作，来强化下对lock指令前缀的理解，这里直接对ADDQ操作进行了lock实现了原子的加操作。\nTEXT ·AddInt64(SB),NOSPLIT,$0 JMP	runtime∕internal∕atomic·Xadd64(SB) // uint64 Xadd64(uint64 volatile *val, int64 delta) // Atomically: //	*val += delta; //	return *val; TEXT ·Xadd64(SB), NOSPLIT, $0-24 MOVQ	ptr+0(FP), BX MOVQ	delta+8(FP), AX MOVQ	AX, CX LOCK # LOCK XADDQ，排他性的add操作 XADDQ	AX, 0(BX) ADDQ	CX, AX MOVQ	AX, ret+16(FP) RET  通常我们自己要应用cas的话，比如实现一个metrics gauge，可能会这么写：\n// Gauge 时刻量 type Gauge struct { v uint64 } // IncrBy 时刻量+v func (g *gauge) IncrBy(v float64) { for { oldBits := atomic.LoadUint64(\u0026amp;g.valBits) fv := math.Float64frombits(oldBits) + v newBits := math.Float64bits(fv) if atomic.CompareAndSwapUint64(\u0026amp;g.valBits, oldBits, newBits) { atomic.StoreUint32(\u0026amp;g.dirty, 1) return } } } ...  先读取原始值，计算，然后准备写回，写回的时候用了CAS，一次CAS操作不一定成功，因为可能其他协程也在尝试更新，所以我们这里要结合一个循环（自旋，spin）来保证重试成功。基于CAS的玩法一般都是这么实现的。\nLocks VS Lock-free # 这里读者也应该意识到了，前面CAS也是基于底层处理器的lock cmpxchg实现的，所以并不是说CAS操作就没有任何的同步措施。\n有些lockfree的数据结构+算法，也是基于CAS实现的，也并不是就真的没有任何同步措施。只是没有用那些通俗意义上的“锁”（如没有用可能导致线程阻塞的互斥量、信号量）。\n多线程编程时，对locks和lock-free对比，一种比较好理解的说法是：\n locks，contention managed by 3rd party (OS Kernel) lock-free, contention managed by the users (threads)  CAS和通俗意义的锁，相比之下，它的临界区非常小（单条指令），且不存在“锁”那样导致进程、线程、协程的挂起、恢复操作，没有上下文切换所引入的开销、调度延迟，所以开销更小一点。\n能用CAS代替mutex之类锁的地方，还是用CAS，因为mutex之类的会把进程线程给挂起，即便是sync.Mutex只挂起协程，但是涉及到go runtime scheduler的介入，开销也是比单纯的CAS要大很多的。在锁竞争比较严重的情况下，sync.Mutex也会经历一个锁膨胀的过程，CAS-\u0026gt;Spin-\u0026gt;Semaphore-\u0026gt;futex (spin+block threads)。\n上面提了基于CAS实现一些lock-free算法，其实lock-free算法的思路有很多：\n State Machines CAS operations - However contention lurks here! @Contended Annotation - JEP 142 Wait-Free in addition to Lock-Free Algorithms Thread Affinity x86 and busy spinning and back-off TSX (Transactional Synchronization Extensions)  see https://youtu.be/_uUkApe_yIk?t=2451\n实现一个锁 # 理解了CPU lock+cmpxchg的作用以及应用之后，就可以在此基础上实现一个简单的锁。\n自旋：spinlock # type SpinLock struct{ v int64 } func (s *SpinLock) Lock() bool { for { if atomic.CompareAndSwap(\u0026amp;s.v, 0, 1) { return true } } } func (s *SpinLock) UnLock() { atomic.StoreInt64(\u0026amp;s.v, 0) }  现在就可以拿这个锁去当做一个简单的锁去用了，但是，这种忙轮询的方式对CPU是一个比较严重的浪费，可以考虑一下如果长时间持有不了锁，是不是可以让出CPU给其他协程执行呢？可以，为了利用好CPU干有价值的事情，就应该让出去。\nCAS ABA问题 # 在这里提一嘴吧，在使用CAS的时候，应该关注ABA问题。什么是ABA问题。假定有个volatile变量v（初始值5），现在我们并发地对其进行修改，假如出现了这样对v的一个操作序列：-1 +1，现在v的值还是5。\n 有些场景不能接受ABA问题  有些场景是不能接受ABA问题的，比如你要通过这个值的变化来判断是否有发生过什么+1 -1的操作，因为这里的值v的变化是非单调的，有增有减，这样肯定区分不了是否发生过什么，就得想其他办法。\n比如你的值v用32位足够，那你可以考虑用个64位的int64，其中多出来的32位用来记录数据版本，然后用Cas64操作来代替之前的Cas32操作。\n 有些场景可以接受ABA问题  你比如前面抢到的那个自旋锁实现，SpinLock.v的值一直在0 1 0 1的变化，但是无所谓，我们仅用它来做一个当前状态的判断，而不是用它的当前值来判断以前的操作历史，如现在为0，表示没有人持有锁，但我们并不会去关心以前有没有人持有过锁。\n剥夺CPU：futex？ # 现在我们想把不干活的任务挂起，这里的任务可能是进程、线程，也可能是协程。进程线程挂起可不是我们想要的，挂起、恢复的开销太重了。\n上图是一个上下文切换开销测评对比，感兴趣的话可以参考这篇文章，see measuring context switching and memory overheads for linux threads。\n一般的锁实现，拿不到锁最后要么自旋，要么将当前任务给挂起，比如把进程、线程挂起，等后续锁被释放了才可以唤起等待队列中的某个进程、线程，恢复调度执行让其继续抢锁。上图中也看到了进程、线程、CPU亲和性不同场景下的上下文切换的开销，还是很明显的。\n所以比较聪明的锁，都不会一下子就挂起任务。\n混合锁实现 # 结合spin和futex的特点，实现一个混合锁：\n spinlock，自旋耗cpu，还不干活（无法推进程序执行）。自旋可以理解成为了不让出cpu让cpu一直干些杂活，比如将一个数从1加到100，加完了从头再加到100，多来几遍……纯粹是为了等锁被持有者释放。自旋锁就是自旋之后再CAS抢锁试下。但是锁竞争不严重的情况下，spinlock一般会成功，效率也高。 futex，阻塞线程，它是Linux内核为用户代码实现同步提供的一种支持，内部维护了一个waiters队列，支持等待、唤醒、定时唤醒，为实现锁提供了方便。开发自己写代码时一般不用这玩意，而是引用在运行时或者标准库在futex基础上封装的方法。 hybrid approach，先cas，不行再spinlock，再不行futex，分别适应没有锁竞争、少量锁竞争、严重锁竞争场景。  go语言中会怎么做呢，比如sync.Mutex？go中会做类似的处理吗？对锁的优化上大致思路差不多。只不过，go要支持轻量级协程，为了追求效率，会比常见的锁实现更细腻一点，不会在不该阻塞的时候把线程给阻塞了。\nsync.Mutex # 终于来到了go语言相关的设计实现，go中sync.Mutex的设计有些比较细腻的考量，本来我尝试解读下源码，发现源码mutex.Lock()/mutex.Unlock() slowpath篇幅比较长，很容易迷失在代码中抓不住主线。\n所以我把解释过的源码部分删除了，我们这里只总结下一些关键的点，感兴趣的读者可以自己读源码：see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L72\n首先，看下sync.Mutex定义：\ntype Mutex struct { state int32	// 锁状态，0:unlocked,1:locked,2:woken,4:starvation,高位 sema uint32	// 为什么是uint32? see 'man 2 futex' }  锁膨胀过程 # 对照着这个结构描述下mutex.Lock()过程中可能发生的一些事情：\n  这里的state就是表示锁的状态，unlocked, locked, starvation等，首先会看CAS(old=unlocked,new=locked)是否成功。没有锁竞争时，这里大概率就枷锁成功了。反之，则会进入下面的lockSlow流程。\n  lockSlow流程中，首先也会先通过判断state是否可以通过CAS+Spin (runtime.procyield) 来加锁成功，这里不会挂起协程，更不会挂起线程。一般少量锁竞争时，这里大概率也能成功。反之，则会进入下面的sema处理流程。\n  sema是一道锁膨胀处理，这里的信号量(0 or 1)其效果就是一个互斥量，如果信号量acquire成功就是获得了锁，反之就是失败（semacquire函数来获得信号量）。为了避免不必要的协程挂起，一开始也是通过cansemacquire来通过cas+spin来获得信号量，成功了就等于sync.Mutex.Lock()成功，锁竞争严重些可能就会有些协程加锁失败，它们就需要继续走锁膨胀处理逻辑。此时它们将尝试加锁（更底层的一把锁runtime.mutex, lockWithRank(semaRoot.lock) ），这把锁在加锁时是遵循这样的膨胀过程：goroutine active spin (runtime.procyield) -\u0026gt; thread passive spin (runtime.osyield) -\u0026gt; linux syscall futex， 总的原则就是自旋有效的话就没必要挂起协程、线程。加锁(runtime.mutex)成功后，只是说明goroutine有资格继续抢信号量（抢到信号量就是抢到sync.Mutex）了，抢到的自然好，抢不到的怎么办呢？semaRoot上维护了一个waiters队列，抢不到的就semaRoot.queue去排队，goparkunlock会把当前协程挂起并释放掉持有的锁runtime.mutex，直到有人释放了锁并将其唤醒(sync.Mutex.UnLock-\u0026gt;unlockSlow-\u0026gt;semarelease-\u0026gt;lockWithRank...semaRoot.dequeue-\u0026gt;goready(gp))。sema这里用到的futex是一个linux系统调用（fast user-space mutex），如果你不了解futex，see https://eli.thegreenplace.net/2018/basics-of-futexes/，锁实现中常用的futex操作就是futex_wait将当前线程挂起，futex_wake将线程唤醒，涉及到线程的上下文切换，开销较大。sema虽然也是用了futex，但是其也细致考虑了不同锁竞争情况下的加锁优化，尽可能避免不必要的开销。\nps: sync.Mutex.sema这个信号量一开始时为0，假设g1是第一个申请加锁的，sema==0根本对其没影响，g1通过CAS直接可以加锁成功。假设g1释放锁前g2也申请加锁，g2将走到lockSlow，假设其在前期cas+spin阶段g1未释放锁，g2只能走到sema信号量处理这里的锁膨胀逻辑，其在cansemacquire通过cas+spin抢信号量时希望sema\u0026gt;0，在sync.Mutex场景下，sema要么是0要么是1，现在sema==0所以g2不可能成功，只能等到sema==1的时候，那么何时sema==1？只能等到g1调用sync.Mutex.Unlock的时候，如果没有其他协程申请加锁，g1能通过CAS直接完成，但是因为g2在申请加锁，锁的state已经被写入了一些标志信息，比如waiters!=0或者starvation，g1检测到state变化后感知到有人在等待这把锁，有可能这个waiter已经goroutine parked甚至thread挂起，所以g1要通过unlockSlow去做些额外的通知工作。unlockSlow-\u0026gt;semarelease-\u0026gt;semaRoot.dequeue会将等待这把锁的g2给出队并通过goready(g2)去唤醒它，之后g2就可以开始继续尝试获取信号量（again，取到信号量就是取到sync.Mutex，但是前提是它得先拿到runtime.mutex）。假设此时除了g2还有g3也在等待这把锁呢，而且g3可能已经通过futex让线程挂起了，怎么搞？g1执行semarelease过程中，也会执行unlock，这个就会通过futexwakeup唤醒阻塞的线程，被暂停的g3也就可以继续执行抢锁(runtime.mutex)的动作了，抢到runtime.mutex，再去抢信号量，抢到就ok了，抢不到就在信号量上排队。\nsema里面也是优先尝试走CAS、Spin路线，尽可能避免挂起协程，协程切换的开销也不能忽略。\nsee: https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/sema.go\ntype semaRoot struct{	lock mutex treap *sudog nwait uint32 } func (root *semaRoot) queue(addr *uint32, s *sudog, lifo bool) { ... } func (root *semaRoot) dequeue(addr *uint32) (found *sudog, now int64) { ... }    在没有锁竞争的时候，大概率一次CAS能成功；锁竞争不严重的时候，可能自旋几次也能成功，再不行挂起协程、唤醒后再去抢锁也说不定能成功。但是锁竞争很严重的时候，你就是抢不到，那线程抢什么呢？睡觉去吧，这个时候就会用上futex让线程睡眠。\n#include \u0026lt;linux/futex.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; int futex(int *uaddr, int futex_op, int val, const struct timespec *timeout, /* or: uint32_t val2 */ int *uaddr2, int val3); futex_op: - FUTEX_WAIT 保持挂起线程，除非 *uaddr != val，或者定时器超时 - FUTEX_WAKE 唤起阻塞在uaddr上的线程 - ...    这就是sync.Mutex锁膨胀的一个过程，sync.Mutex -\u0026gt; sema -\u0026gt; futex，其实每个阶段都是优先考虑cas+spin的逻辑来尽量避免挂起（协程or线程）。\n注意下图中最后，uses futexes -\u0026gt; uses spin-locks这里，这里是说，linux futex在实现的时候也是使用了spinlock的……都是在考虑不同锁竞争情况下哪种方案更高效。\nps: linux futex根据地址做hash后找到hash bucket，bucket里面有个spinlock_t，拿到这把锁后就可以修改上面的waiters链表，比如将当前线程放入waiters后将当前线程挂起。至于这里为什么用spinlock呢？对内核锁的理解不是很全面，猜测一下，首先这里调整waiters也不怎么花时间，lock很快就释放了，线程spin一下就能等到有人释放，可能没必要用mutex休眠唤醒后再试，而且mutex阻塞上下文切换开销可能更大，所以使用spinlock。对用户态应用程序出现阻塞挂起协程让出cpu可能是件好事，但是在内核里面阻塞线程可不是件好事。linux kernel里面的锁可以参考：http://retis.sssup.it/luca/KernelProgramming/Slides/kernel_locking.pdf(p12-13)。关于futex的使用的话，看着片就够了:http://www.rkoucha.fr/tech_corner/the_futex.html#Principle_futex。\n协程调度优化 # 另外，go sync.Mutex也做了些协程调度相关的优化，大致总结一下。sync.Mutex有两种工作模式：normal mode 和 starvation mode，两种模式对执行Lock、Unlock的goroutine会产生不同的影响。\n  normal mode\n该模式下，waiters（goroutines）会按照申请加锁的顺序进入一个FIFO的队列，一个被唤醒的waiter不一定能够立即持有锁，它要和所有新的发起加锁请求的goroutines竞争。新到达的goroutines通常有一个优势——它们已经在CPU上运行了，并且有很多，所以一个刚被唤醒的waiter大概率会竞争锁失败。\n这种情况下，这个失败的waiter会被加入到这个FIFO队列的队首，当有goroutine释放锁并尝试唤醒一个waiter时，就会优先唤醒队首的waiter，但是也只是将其标记为runnable之后丢到p.localqueue runnext里，如果放不进去会尝试放到global queue，什么时候被调度到还未可知。\n而如果一个waiter竞争锁超过1ms还没有成功，就会将mutex从normal mode切换为startvation mode，下次有goroutine释放锁时，会采取更激进的方法以便让队首的waiter快速得到执行。\n  starvation mode\n该模式下，当一个goroutine释放锁时，锁的拥有者立即从该goroutine转交给队首的waiter。新到达的goroutines不会尝试获得锁，尽管它能观察到锁好像被释放掉了。这种模式下，新到达的goroutines会追加到FIFO的队列的末尾。并且，这个拿到锁的队首的waiter，会被标记为runnable然后放入当前g.P的runnext中，并且把当前g的时间片也一并传给它使用，当前g执行goyield让出P、M之后，M将立即执行p.runnext。简言之，饥饿模式下释放锁的g直接将锁handleoff给队首的waiter，并让其更快地得到执行。\n  当一个waiter收到一个mutex的拥有者权限时，它会检查，如果：1）它是这个锁竞争等待队列中的最后一个waiter；或者 2）它的加锁等待时间小于1ms，此时将把mutex从starvation mode切换为normal mode。\n与饥饿模式相比，正常模式下的互斥锁能够提供更好的性能，饥饿模式则能缩减goroutine 由于等待获取锁过久造成的延时。\n总结 # 本文介绍了并发中重要的原子性、指令重排问题，以及带来的安全编码风险，然后介绍了处理器提供的一些屏障指令，以及从硬件角度介绍了屏障的工作原理，然后介绍了CAS及其使用，引出了进一步的锁、无锁、CAS的异同点，然后我们简单提了下futex重量级锁导致的进程线程挂起、恢复开销大家，最后引出了go sync.Mutex的设计实现及一系列针对协程调度延迟的优化。\n希望本文对加深大家对锁的认识有帮助！\n参考内容 #  Memory Barriers: a Hardware View for Software Hackers,http://www.puppetmastertrading.com/images/hwViewForSwHackers.pdf how cpu lock cmpxchg works: http://heather.cs.ucdavis.edu/~matloff/50/PLN/lock.pdf don\u0026rsquo;t mix high-level locks with low-level CPU feature that happened to be renamed LOCK,https://stackoverflow.com/a/27856649/3817040 cpu-memory, https://akkadia.org/drepper/cpumemory.pdf src/runtime/internal/atomic/atomic_386.s, https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/internal/atomic/atomic_386.s#L23 sync.Mutex, https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L81:4 Let\u0026rsquo;s talk locks, Kavya Joshi, https://www.youtube.com/watch?v=tjpncm3xTTc Atomic Operations in Hardware, https://courses.cs.washington.edu/courses/cse378/07au/lectures/L25-Atomic-Operations.pdf Atomic Operation, https://wiki.osdev.org/Atomic_operation Lock-free Algorithms for Ultimate Performance, https://www.youtube.com/watch?v=_uUkApe_yIk Fear and Loathing in Lock-Free Programming, https://medium.com/@tylerneely/fear-and-loathing-in-lock-free-programming-7158b1cdd50c measuring context switching and memory overheads for linux threads, https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/ basis of futexes, https://eli.thegreenplace.net/2018/basics-of-futexes/ Computer Architecture: Dynamic Execution Core, https://youtu.be/XuCu9EEHBtk?t=1087 x86-TSO: A Rigorous and Usable Programmer\u0026rsquo;s Model for x86 Multiprocessors, https://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf Memory Consistency Models: A Tutorial, https://www.cs.utexas.edu/~bornholt/post/memory-models.html Detailed approach of the futex: http://www.rkoucha.fr/tech_corner/the_futex.html#Principle_futex Kernel and Locking, http://retis.sssup.it/luca/KernelProgramming/Slides/kernel_locking.pdf  "}),a.add({id:267,href:"/tags/sync.mutex/",title:"sync.Mutex",description:"",content:""}),a.add({id:268,href:"/tags/exception/",title:"exception",description:"",content:""}),a.add({id:269,href:"/tags/panic/",title:"panic",description:"",content:""}),a.add({id:270,href:"/tags/try-catch/",title:"try-catch",description:"",content:""}),a.add({id:271,href:"/blog/2021-04-16-%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85gopanic%E5%8F%8A%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/",title:"如何看待gopanic及异常处理",description:"最近发现有些同学对于go panic的理解有误，分不清什么时候用panic，什么时候用error，甚至是一些go老手也会出现不加选择乱用的情况，go panic有其明确的使用定位，但是不同于其他语言中的异常处理。",content:"Background # 最近有同学提问，大意是：“go中什么时候用panic、什么时候用error，能不能像其他语言中的try-catch一样用panic-recover来代替层层return err，或者应不应该recover一个panic之后转换为error？”\n这个问题引起了广泛的讨论，在对这几个问题的理解上，我本以为大家应该会认识到位的，没想到很多人认识很模糊。当然，好的地方就是总有有见识的同学站出来指出大家的问题。\n对于那些有灵性的同学，勤实践勤思考的同学，他会自然而然意识到哪种error handling pattern更好，也会有意识地去区分不同pattern的定位和应用场景。这类同学虽然没有什么理论术语支撑，但是他们的“经验”是贴近更好的设计思想、最佳实践的。如果更进一步，能愿意接受一些设计思想的洗礼，则可以将“经验”上升到“模式”，以指导更多人。\npanic != exception # go panic不同于其他语言中的exception，在设计、定位上是有明确的区别的，see: https://dave.cheney.net/2012/01/18/why-go-gets-exceptions-right。\n panics are always fatal to your program. In panicing you never assume that your caller can solve the problem. Hence panic is only used in exceptional circumstances, ones where it is not possible for your code, or anyone integrating your code to continue.\n go panic是用来表示程序出现了十分致命的错误，并且你不能假定这个错误能被解决。所以panic只在很少的场景下才会被用到，并且出现panic时，你的代码解决不了，引用这部分代码的其他代码也解决不了。\n所以，panic并非一般意义上的error，更不能用panic-recover代替层层向上传递error！\n对于，为了自身程序的健壮性，而在启动新的goroutine时，或者调用外部依赖的导出函数、方法时，可能选择recover一些预料之外的panic，并转换为error处理。\n有追求的开发人员，在panic的使用上应该始终遵循go设计理念，同时在程序的健壮性上也会采用些防御性编程的手段。\npanic vs exception # 我们很多开发人员都接触过多门语言，比如Java、C++，等等，这类语言都有异常处理机制，遇到一些意外事件时可以抛出一个异常，异常通常由try-catch block捕获并处理。\n初学者阶段，很多同学会努力去学习异常处理的正确编码方式，甚至是异常处理的实现原理，对性能的影响，等等，但是由于实际缺乏实际的大规模工程供锻炼实践，也很少有人会去思考一些问题，比如：\n  QA：我们为什么需要异常？\n 层层返回error，编码不方便，希望有统一的错误处理逻辑，保证主逻辑更清晰。    QA：异常解决了什么问题？\n 避免了层层传递error，异常在统一位置处理。    QA：异常引入了什么问题？\n  区分异常发生的位置，就要每个位置定义一个异常类型，这个数量应该挺大的。\n  而且由于实际编码中同一个异常会在多处被抛出，实际上看到代码中捕获一个异常类型时，你很难断定它是哪个操作抛出的。\n  而且每个可能捕获这个异常的地方，都需要拷贝异常处理代码。\n  如果没有捕获异常，通常进程会挂掉，能否识别一个函数是否会抛出异常，Java中有checked exception、unchecked exception，前者可以在编译时帮助确定是否有遗漏的try-catch，但是仍然有unchecked exception。\n    QA：异常真的解决了问题么？\n 异常表面解决了老问题，但是却有引入了新问题，而且新问题似乎更严重。    异常+try-catch，本质上将当前操作的错误处理逻辑转换为了caller要解决的问题，并没有少写多少错误处理代码，反而，同一异常处理代码在多个try-catch中被拷贝，而且可读性更差了。错误发生地、错误处理地分散在不同地方，能说是可读性好吗？我不这么认为。\ndon\u0026rsquo;t need exception? # 异常处理，真的是个好东西么？它真的解决了问题么？\n之前同困惑c++异常是解决了问题还是引入了新问题，为此也多方了解，直到后来看到zmq之父Martin Sustrik的文章，Why should I have written ZeroMQ in C, not C++。Martin详细介绍了在错误处理过程中，如果采用C++异常处理会带来怎样的麻烦，而如果直接使用error处理会有哪些好处。最终Martin在实现zmq时采用了 c++ minus exception的技术路线，即使用C++但是不适用C++异常处理。\n基于以前的沉思，Martin后面使用C有重新写了一个zmq的进化版本nanomsg ，C没有异常处理 :)\n这里不想引战，也不想做二元的判定，强烈推荐读者朋友们阅读下Dave、Martin Sustrik的文章，相信会对panic、error、exception的设计理解更透彻。\nReferences #  Why go gets exceptions right, https://dave.cheney.net/2012/01/18/why-go-gets-exceptions-right Why should I have written ZeroMQ in C, not C++, https://250bpm.com/blog:4/  "}),a.add({id:272,href:"/tags/cgo/",title:"cgo",description:"",content:""}),a.add({id:273,href:"/blog/2021-04-14-go%E7%A8%8B%E5%BA%8F%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D/",title:"Go程序内存泄露问题快速定位",description:".myimg { width: 680px; padding-bottom: 1rem; }  前几天有同学反馈了cgo内存泄露问题，自己也针对这个问题探索了一番，算是为以后解决类似问题提前攒点经验吧。也趁机整理了一下go开发过程中内存泄露问题的一些常用排查方法，也希望对新接触go的同学有所帮助。整理之余，bcc工具之丰富也让我有点惊讶，也希望对自己日后的工作有所帮助吧。\n内存泄漏 # 内存泄露，一个老生常谈的问题，但即便是老手也会犯一些低级错误。如果没有可靠的研发流程保证在测试阶段发现问题，问题就容易被带到线上。计算资源始终是有限的，问题也不会因为资源充裕就消失不见，产生影响只是时间问题。影响有多大，就要结合场景来说了。\n内存泄漏，最可能的影响就是内存申请失败。但实际上操作系统更聪明，结合系统整体负载情况，它会为每个进程计算一个oom_score，并在内存资源紧张时选择一个合适的进程杀死并回收内存资源，see how does the oom killer decide which process to kill first。\n所以，内存泄露的最终结果，大概率会被操作系统kill，通常进程挂掉后，确认其是否是因为oom问题被kill，可以通过查看 /proc/messages 来确认是否有对应日志。有的话，那就坐实了oom killed（但是被oom killed的进程不一定意味着存在内存泄露）。\n服务质量 # 结合运维手段的变化，来看看是否内存泄漏问题对服务质量造成的影响。\n 传统人工方式，通过感知告警、人为介入这种方式，效率低，要十几分钟； 通过虚拟机自动化部署的方式，感知异常自动重启虚拟机，耗时大约要分钟级； 通过docker容器化部署的方式，感知异常自动重启容器，耗时大约在秒级；  看上去现代运维方式一定程度上可以缓解这个问题，是，这也要分情况：\n 如果内存泄露的代码路径不容易被触发，那可能要跑很久才能触发oom kill，如一周；但是如果代码路径在关键代码路径上，且请求量大，频繁触发内存泄露，那可能跑个几分钟就会挂掉； 跟每次内存泄露的内存大小也有关系，如果泄露的少，多苟活一阵子，反之容易暴毙； 进程一旦挂掉，这段时间就不能响应了，服务的健康监测、名字服务、负载均衡等措施需要一段时间才能感知到，如果请求量大，服务不可用依然会带来比较大的影响。  服务质量保证是不变的，所以别管用了什么运维手段，问题终究是问题，也是要解决的。\nGo内存泄漏 # 垃圾回收 # 自动内存管理减轻了开发人员管理内存的复杂性，不需要像C\\C++开发者那样显示malloc、free，或者new、delete。垃圾回收借助于一些垃圾回收算法完成对无用内存的清理，垃圾回收算法有很多，比如：引用计数、标记清除、拷贝、分代等等。\nGo中垃圾回收器采用的是“并发三色标记清除”算法，see:\n Garbage Collection In Go : Part I - Semantics Garbage Collection In Go : Part II - GC Traces Garbage Collection In Go : Part III - GC Pacing  Go语言支持自动内存管理，那还存在内存泄漏问题吗？",content:" .myimg { width: 680px; padding-bottom: 1rem; }  前几天有同学反馈了cgo内存泄露问题，自己也针对这个问题探索了一番，算是为以后解决类似问题提前攒点经验吧。也趁机整理了一下go开发过程中内存泄露问题的一些常用排查方法，也希望对新接触go的同学有所帮助。整理之余，bcc工具之丰富也让我有点惊讶，也希望对自己日后的工作有所帮助吧。\n内存泄漏 # 内存泄露，一个老生常谈的问题，但即便是老手也会犯一些低级错误。如果没有可靠的研发流程保证在测试阶段发现问题，问题就容易被带到线上。计算资源始终是有限的，问题也不会因为资源充裕就消失不见，产生影响只是时间问题。影响有多大，就要结合场景来说了。\n内存泄漏，最可能的影响就是内存申请失败。但实际上操作系统更聪明，结合系统整体负载情况，它会为每个进程计算一个oom_score，并在内存资源紧张时选择一个合适的进程杀死并回收内存资源，see how does the oom killer decide which process to kill first。\n所以，内存泄露的最终结果，大概率会被操作系统kill，通常进程挂掉后，确认其是否是因为oom问题被kill，可以通过查看 /proc/messages 来确认是否有对应日志。有的话，那就坐实了oom killed（但是被oom killed的进程不一定意味着存在内存泄露）。\n服务质量 # 结合运维手段的变化，来看看是否内存泄漏问题对服务质量造成的影响。\n 传统人工方式，通过感知告警、人为介入这种方式，效率低，要十几分钟； 通过虚拟机自动化部署的方式，感知异常自动重启虚拟机，耗时大约要分钟级； 通过docker容器化部署的方式，感知异常自动重启容器，耗时大约在秒级；  看上去现代运维方式一定程度上可以缓解这个问题，是，这也要分情况：\n 如果内存泄露的代码路径不容易被触发，那可能要跑很久才能触发oom kill，如一周；但是如果代码路径在关键代码路径上，且请求量大，频繁触发内存泄露，那可能跑个几分钟就会挂掉； 跟每次内存泄露的内存大小也有关系，如果泄露的少，多苟活一阵子，反之容易暴毙； 进程一旦挂掉，这段时间就不能响应了，服务的健康监测、名字服务、负载均衡等措施需要一段时间才能感知到，如果请求量大，服务不可用依然会带来比较大的影响。  服务质量保证是不变的，所以别管用了什么运维手段，问题终究是问题，也是要解决的。\nGo内存泄漏 # 垃圾回收 # 自动内存管理减轻了开发人员管理内存的复杂性，不需要像C\\C++开发者那样显示malloc、free，或者new、delete。垃圾回收借助于一些垃圾回收算法完成对无用内存的清理，垃圾回收算法有很多，比如：引用计数、标记清除、拷贝、分代等等。\nGo中垃圾回收器采用的是“并发三色标记清除”算法，see:\n Garbage Collection In Go : Part I - Semantics Garbage Collection In Go : Part II - GC Traces Garbage Collection In Go : Part III - GC Pacing  Go语言支持自动内存管理，那还存在内存泄漏问题吗？\n理论上，垃圾回收（gc）算法能够对堆内存进行有效的清理，这个是没什么可质疑的。但是要理解，垃圾回收能够正常运行的前提是，程序中必须解除对内存的引用，这样垃圾回收才会将其判定为可回收内存并回收。\n内存泄漏场景 # 实际情况是，编码中确实存在一些场景，会造成“临时性”或者“永久性”内存泄露，是需要开发人员加深对编程语言设计实现、编译器特性的理解之后才能优化掉的，see：go memory leaking scenarios。\n即便是临时性内存泄漏，考虑到有限的内存资源、内存申请大小、申请频率、释放频率因素，也会造成进程oom killed的结果。所以，开发人员对待每一行代码还是要心存敬畏，对待内存资源也还是要慎重。\n常见的内存泄露场景，go101进行了讨论，总结了如下几种：\n Kind of memory leaking caused by substrings Kind of memory leaking caused by subslices Kind of memory leaking caused by not resetting pointers in lost slice elements Real memory leaking caused by hanging goroutines real memory leadking caused by not stopping time.Ticker values which are not used any more Real memory leaking caused by using finalizers improperly Kind of resource leaking by deferring function calls  简单归纳一下，还是“临时性”内存泄露和“永久性”内存泄露：\n 临时性泄露，指的是该释放的内存资源没有及时释放，对应的内存资源仍然有机会在更晚些时候被释放，即便如此在内存资源紧张情况下，也会是个问题。这类主要是string、slice底层buffer的错误共享，导致无用数据对象无法及时释放，或者defer函数导致的资源没有及时释放。 永久性泄露，指的是在进程后续生命周期内，泄露的内存都没有机会回收，如goroutine内部预期之外的for-loop或者chan select-case导致的无法退出的情况，导致协程栈及引用内存永久泄露问题。  内存泄露排查 # 初步怀疑程序存在内存泄露问题，可能是因为进程oom killed，或者是因为top显示内存占用持续增加无法稳定在一个合理值。不管如何发现的，明确存在这一问题之后，就需要及时选择合适的方法定位到问题的根源，并及时修复。\n借助pprof排查 # pprof类型 # go提供了pprof工具方便对运行中的go程序进行采样分析，支持对多种类型的采样分析：\n goroutine - stack traces of all current goroutines heap - a sampling of all heap allocations threadcreate - stack traces that led to the creation of new OS threads block - stack traces that led to blocking on synchronization primitives mutex - stack traces of holders of contended mutexes profile - cpu profile trace - allows collecting all the profiles for a certain duration  pprof操作 # 现在很多rpc框架有内置管理模块，允许访问管理端口通过/debug/pprof对服务进行采样分析（pprof会有一定的性能开销，最好分析前将负载均衡权重调低）。\n集成pprof非常简单，只需要在工程中引入如下代码即可：\nimport _ \u0026quot;net/http/pprof\u0026quot; go func() { log.Println(http.ListenAndServe(\u0026quot;localhost:6060\u0026quot;, nil)) }()  然后运行go tool pprof进行采样：\ngo tool pprof -seconds=10 -http=:9999 http://localhost:6060/debug/pprof/heap  有时可能存在网络隔离问题，不能直接从开发机访问测试机、线上机器，或者测试机、线上机器没有安装go，那也可以这么做：\ncurl http://localhost:6060/debug/pprof/heap?seconds=30 \u0026gt; heap.out # sz下载heap.out到本地 go tool pprof heap.out  go tool pprof可以收集两类采样数据：\n  in_use，收集进程当前仍在使用中的内存；   alloc，收集自进程启动后的总的内存分配情况，包括已经释放掉的内存；   go tool pprof展示采样信息时，申请内存以“红色”显示，释放内存以“绿色”显示。\n允许采样完成后打开一个浏览器页面（通过ip:port访问），交互式地查看采样结果信息，例如callgraph、flamegraph、top信息。\npprof示例：协程泄露 # 其中有2条红色的很醒目的路径，这是造成内存占用升高的主要路径，需要重点分析。以右边这条红色路径为例，最终走到了runtime.malg，碰到这个函数，联想前面总结的常见内存泄露场景，要有这样的意识：“这里可能涉及到goroutine泄露”，即goroutine创建了很多，但是goroutine没有正常执行结束，对应的协程使用的内存没有释放。\n此时根据上述callgraph中的线索检查程序中启动goroutine的地方，以及goroutine是否有正常退出的逻辑保证，就能比较方便地定位到泄露原因了。\n上述callgraph中展示了两条导致内存分配占用高的路径，但是其中左边一条可能是正常情况下的内存使用情况，而右边这条可能是异常情况。在分析阶段，我们需要有能力区分哪些内存分配是正常情况，哪些情况是异常情况。pprof提供了另外一个有用的选项-diff_base，我们可以在没有服务没有请求时采样30s生成一个采样文件，然后有请求时，我们再采样30s生成另一个采样文件，并将两个采样文件进行对比。这样就容易分析出请求出现时，到底发生了什么。\ngo tool pprof -http=':8081' \\ -diff_base heap-new-16:22:04:N.out \\ heap-new-17:32:38:N.out  这样问题看起来就更非常明确了，请求出现时处理请求的过程中启动了新协程执行处理。runtime.malg就是创建新协程，其内部会分配协程栈，这个栈在使用过程中会动态伸缩，并在协程退出时才会被销毁。\n由pprof heap确定了存在goroutine泄露问题，但我们还不知道此goroutine在何处启动的，为此，我们继续pprof goroutine。\ngo tool pprof -seconds=10 \\ -http=:8081 \\ http://localhost:6060/debug/pprof/goroutines  现在通过上述callgraph我们很容易定位到goroutine是在哪里启动的了，回到源码中进一步确认：\nvar ticker = time.NewTicker(time.Second) go func() { for { select { case \u0026lt;-ticker.C: // doSomething } } }() func somefunc(...) { ticker.Stop() }  原来当前协程因为ticker.C这个chan read操作阻塞了，需要注意的是time.Ticker.Stop()之后，ticker.C这个chan不会被关闭，最好在执行ticker.Stop()的时候，同时设置一个通知chan，close该chan来表示ticker停止。\nvar ticker = time.NewTicker(time.Second) var chdone = make(chan int, 1) go func() { for { select { case \u0026lt;-ticker.C: sa.read() case \u0026lt;- chdone: return } } }() func somefunc(...) { ticker.Stop() close(chdone) }  这里介绍了pprof的使用方法，pprof是每个go开发人员都应该掌握的。希望读者借助这里的示例能帮助读者了解pprof的操作、分析过程，达到灵活运用的程度还需要日常开发工作中多实践。\n借助bcc排查 # pprof：这个我干不了 # pprof对于分析纯go程序是非常有帮助的，但是对于cgo有点无能为力，cgo部分的代码已经跳出了go内存分配器的范围，采样也没用，那cgo部分出现内存泄露该如何排查呢？\n 要确定进程是否出现了内存泄露，可以观察进程运行期间的内存占用情况，如借助top、free -m，或者其他运维平台的监控系统，一般k8s都集成了prometheus对容器运行情况进行了监视。如果内存占用随着时间延长一直增长，没有在合理的内存占用值附近稳定下来，或者已经出现了oom killed、容器重启的问题出现，则可以初步判定进程存在内存泄露； 继续借助pprof工具排查go程序，如果pprof可以排查出明显的内存泄露问题，则内存泄漏问题可能是纯go部分代码引起，采用前面描述的分析、定位方法来解决； 如果pprof工具采样之后，没有发现明显的内存泄露的端倪，且程序中存在cgo部分的代码，怀疑cgo部分的代码存在内存泄露，此时则需借助其他手段（pprof无能为力了）来进一步分析cgo部分的可能异常；  库函数：hook库函数 # 要分析内存是否存在泄漏，也可以考虑自己hook一下库函数，自己实现这种我们就不展开讨论了。还是看看有没有趁手的好工具，能实实在在地、靠谱地帮我们解决实际问题（尽管趁手的工具也可能也是基于某种hook的能力实现的）。\nKernel：谁能逃脱我的法眼 # 内存分配操作，一般会借助一些库函数来完成，内存分配器也会做一些分配算法的优化，这里不关心这些，最终的内存申请操作还是要由操作系统来代劳，而请求内核服务的操作则是通过系统调用。\n操作系统提供了一些服务，允许对运行中的进程进行观测，以Linux为例，借助ptrace系统调用+PTRACE_SYSCALL，允许我们对一个运行中的进程执行的所有系统调用进行观测，ltrace、strace就是在此基础上实现的。\neBPF（extended BPF）的前辈是BPF（Berkeley Packet Filtering），BPF是一个ByteCode VM，它的数据模型限制于packet，经常用来做一些包分析，经典的如tcpdump。eBPF相比BPF，其数据模型不再受限于单一的packet，也不再只是用来分析packet的单一功能，可以利用它将eBPF program挂到任意的tracepoint或者kprobe去执行分析处理。这一下子打开了eBPF的万花筒，使得能够对内核各个子系统做观测、做性能分析，等等。\n各种测量、性能分析工具，真是亮瞎我的眼睛。\nBCC (eBPF toolkit)：测量、性能分析 # 如何基于eBPF写eBPF program来完成希望的测量、分析呢，see iovisor/bcc：\n BCC is a toolkit for creating efficient kernel tracing and manipulation programs, and includes several useful tools and examples. It makes use of extended BPF (Berkeley Packet Filters), formally known as eBPF, a new feature that was first added to Linux 3.15.\neBPF was described by Ingo Molnár as:\n One of the more interesting features in this cycle is the ability to attach eBPF programs (user-defined, sandboxed bytecode executed by the kernel) to kprobes. This allows user-defined instrumentation on a live kernel image that can never crash, hang or interfere with the kernel negatively.\n BCC makes BPF programs easier to write, with kernel instrumentation in C (and includes a C wrapper around LLVM), and front-ends in Python and lua. It is suited for many tasks, including performance analysis and network traffic control.\n BCC算是一个开发套件，在它基础上开发eBPF program会更简单，该仓库内当前已经拥有了非常丰富的测量、分析工具，工具之丰富，只差我能不能全部掌握了，也想成为像Brendan Gregg一样的性能分析专家。\n Brendan Gregg: Understanding all the Linux tracers to make a rational decision between them a huge undertaking. (I may be the only person who has come close to doing this.)\n 至于如何实现一个BCC工具，则非常简单，实际上就是写一个python文件，内部一个字符串包含一个c程序，c程序内调用封装的eBPF API，看一个简单的demo：\n#file: hello-open-world-1.py from bcc import BPF program = \u0026quot;\u0026quot;\u0026quot; #include \u0026lt;asm/ptrace.h\u0026gt; // for struct pt_regs #include \u0026lt;linux/types.h\u0026gt; // for mode_t int kprobe__sys_open(struct pt_regs *ctx, char __user* pathname, int flags, mode_t mode) { bpf_trace_printk(\u0026quot;sys_open called.\\\\n\u0026quot;); return 0; } \u0026quot;\u0026quot;\u0026quot; b = BPF(text=program) b.trace_print()  运行它：\n$ sudo python hello-open-world-1.py  OK，BCC套件里面提供了工具memleak，用来对内存泄露进行分析，下面结合一个cgo内存泄露的示例分析，来了解下如何是使用。\n建议能花点时间了解下linux tracing systems，see linux tracing systems \u0026amp; how they fit together ，理清下kprobe/uprobe/dtrace probes/kernel tracepoints的含义及工作原理，进而才能认识到eBPF的强大之处，不再展开了，看个示例。\nBCC：内存泄露示例 # 下面先看一个cgo示例工程是如何组织的，示例项目取自https://github.com/2Dou/cgo-example，您可以直接从这里下载。\nc-so/ ├── Makefile ├── add │ ├── Makefile │ ├── add.go │ └── src │ ├── add.c │ └── add.h └── main.go  上述工程中，add/src/下add.h/add.c实现了一个add函数，add/add.go中定义了可导出的函数Add(a, b int) int，内部通过cgo调用src下定义的int add(int, int)，add/Makefile将把add下的源文件整个编译构建打包成一个共享库文件libadd.so，供c-so/main.go调用。\nc-so/main.go引用目录add下定义的package add中的Add函数，c-so/Makefile只是简单的go build编译动作，编译完成后./c-so运行会提示库文件libadd.so不存在，这是因为库路径加载问题，执行LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(pwd -p) ./c-so即可，程序正常运行。\nOK，现在简单地篡改下src/add.c，将其内容修改如下，插入了一段不停申请内存的代码：\n#include \u0026quot;add.h\u0026quot; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int add(int a, int b) { /******* insert memory leakage start ********/ int i = 0; int max = 0x7fffffff; for (; i\u0026lt;max; i++) { int *p = (int *)malloc(sizeof(int) * 8); sleep(1); if (i % 2 == 0) { free(p) } } /******* insert memory leakage end ********/ return a+b; }  现在重新执行make编译之后，再次运行，程序不断地malloc但是从来不free，内存一点点被泄露，现在我们看看如何借助memleak分析内存泄露的位置：\n$ /usr/share/bcc/tools/memleak -p $(pid of c-so)  运行一段时间以后，memleak报告了内存分配的情况，显示的是“top10的还没有释放的内存分配”的位置信息：\n Trace outstanding memory allocations that weren\u0026rsquo;t freed.\nSupports both user-mode allocations made with libc functions and kernel-mode allocations made with kmalloc/kmem_cache_alloc/get_free_pages and corresponding memory release functions.\n 从memleak报告的最后一条信息来看：\n c-so这个程序运行过程中，调用了共享库libadd.so中的add函数； 这个add函数执行了345+次内存分配操作，每次申请sizeof(int)*8 bytes，总共分配了11048次内存； 内存分配malloc操作的位置大约就是add函数起始处+0x28的指令位置，可以通过objdump -dS libadd.so求证。  现在我们可以看到内存分配的位置、次数、内存数量，但是这个报告中报道的并非实际泄露的内存数量，比如我们也有free，怎么没有统计到呢？运行memleak -h查看下有哪些选项吧！\n$ /usr/share/bcc/tools/memleak -p $(pid of c-so) -t  现在可以看到报告信息中包含了alloc entered/exited，free entered/exited，可以断定memleak也跟踪了内存释放，但是这里的报告还是不够直观，能否直接显示泄露的内存信息呢？可以但是要稍微修改下，下面看下实现，你会发现现有的报告信息也不妨碍分析。\nbcc/memleak实现 # 不看下源码，总感觉心里有点虚，看下memleak这个eBPF program中的部分逻辑：\n跟踪malloc：\nint malloc_enter(struct pt_regs *ctx, size_t size) \\-\u0026gt; static inline int gen_alloc_enter(struct pt_regs *ctx, size_t size) : 内部会更新被观测进程已分配的内存数量（sizes记录） int malloc_exit(struct pt_regs *ctx) \\-\u0026gt; static inline int gen_alloc_exit(struct pt_regs *ctx) \\-\u0026gt; static inline int gen_alloc_exit2(struct pt_regs *ctx, u64 address) ：内部会记录当前申请的内存地址（allocs记录） \\-\u0026gt; stack_traces.get_stackid(ctx, STACK_FLAGS) ：记录当前内存分配动作的调用栈信息（allocs中记录）  跟踪free：\nint free_enter(struct pt_regs *ctx, void *address) \\-\u0026gt; static inline int gen_free_enter(struct pt_regs *ctx, void *address) ：从allocs中删除已经释放的内存地址  memleak周期性地对allocs进行排序，并按照sizes分配内存多少降序排列打印出来，因为memleak同时跟踪了malloc、free，所以一段时间后，周期性打印的内存分配调用栈位置，即可以认为是没有释放掉（泄露掉）的内存分配位置。\n借助pmap/gdb排查 # 这也是一种比较通用的排查方式，在排查内存泄露问题时，根据实际情况（比如环境问题无法安装go，bcc之类分析工具等等）甚至可考虑先通过pmap这种方式来分析一下。总之，灵活选择合适的方式吧。\n内存及pmap基础 # 进程中的内存区域分类可以按下面几个维度来划分，如果对这个不熟，建议参考以下文章，see:\n Memory Types Understanding Process Memory Managing Memory      Private Shared     Anonymous stack\nmalloc\nmmap(anon+private)\nbrk/sbrk mmap(anon+shared)   File-backed mmap(fd, private)\nbinary/shared libraries mmap(fd, shared)    借助pmap可以查看进程内存空间分布情况，包括地址范围、大小、内存映射情况，如：\n$ pmap -p \u0026lt;pid\u0026gt; # /proc/\u0026lt;pid\u0026gt;/maps 3009: ./blah 0000000000400000 4K r-x-- /home/fruneau/blah 0000000000401000 4K rw--- /home/fruneau/blah 00007fbb5da87000 51200K rw-s- /dev/zero (deleted) 00007fbb60c87000 1536K r-x-- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb60e07000 2048K ----- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb61007000 16K r---- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb6100b000 4K rw--- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb6100c000 20K rw--- [ anon ] 00007fbb61011000 128K r-x-- /lib/x86_64-linux-gnu/ld-2.13.so 00007fbb61221000 12K rw--- [ anon ] 00007fbb6122e000 8K rw--- [ anon ] 00007fbb61230000 4K r---- /lib/x86_64-linux-gnu/ld-2.13.so 00007fbb61231000 4K rw--- /lib/x86_64-linux-gnu/ld-2.13.so 00007fbb61232000 4K rw--- [ anon ] 00007fff9350f000 132K rw--- [ stack ] 00007fff9356e000 4K r-x-- [ anon ] ffffffffff600000 4K r-x-- [ anon ] total 55132K  $ pmap -x -p \u0026lt;pid\u0026gt; # /proc/\u0026lt;pid\u0026gt;/smaps Address Kbytes RSS Dirty Mode Mapping 0000000000400000 4 4 4 r-x-- blah 0000000000401000 4 4 4 rw--- blah 00007fc3b50df000 51200 51200 51200 rw-s- zero (deleted) 00007fc3b82df000 1536 188 0 r-x-- libc-2.13.so 00007fc3b845f000 2048 0 0 ----- libc-2.13.so 00007fc3b865f000 16 16 16 r---- libc-2.13.so 00007fc3b8663000 4 4 4 rw--- libc-2.13.so 00007fc3b8664000 20 12 12 rw--- [ anon ] 00007fc3b8669000 128 108 0 r-x-- ld-2.13.so 00007fc3b8879000 12 12 12 rw--- [ anon ] 00007fc3b8886000 8 8 8 rw--- [ anon ] 00007fc3b8888000 4 4 4 r---- ld-2.13.so 00007fc3b8889000 4 4 4 rw--- ld-2.13.so 00007fc3b888a000 4 4 4 rw--- [ anon ] 00007fff7e6ef000 132 12 12 rw--- [ stack ] 00007fff7e773000 4 4 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ---------------- ------ ------ ------ total kB 55132 51584 51284  上述命令只是输出信息的详细程度不同，在我们理解了进程的内存类型、pmap的使用之后，就可以对发生内存泄露的程序进行一定的分析。\n排查示例：用例准备 # 比如现在写一个测试用的程序，目录结构如下：\nleaks |-- conf | `-- load.go |-- go.mod |-- leaks |-- main.go `-- task `-- load.go  file: main.go，该文件启动conf、task下的两个逻辑，conf.LoadConfig中启动一个循环，每次申请1KB内存并全部设置为字符C，task.NewTask启动一个循环，每次申请1KB内存并设置为字符T。 conf.LoadConfig循环体每次迭代间隔1s，task.NewTask循环体每次迭代间隔2s。\npackage main import ( \u0026quot;leaks/conf\u0026quot; \u0026quot;leaks/task\u0026quot; ) func main() { conf.LoadConfig(\u0026quot;aaa\u0026quot;) task.NewTask(\u0026quot;bbb\u0026quot;) select {} }  file: conf/load.go:\npackage conf import ( \u0026quot;time\u0026quot; ) type Config struct { A string B string C string } func LoadConfig(fp string) (*Config, error) { kb := 1 \u0026lt;\u0026lt; 10 go func() { for { p := make([]byte, kb, kb) for i := 0; i \u0026lt; kb; i++ { p[i] = 'C' } time.Sleep(time.Second * 1) println(\u0026quot;conf\u0026quot;) } }() return \u0026amp;Config{}, nil }  file: task/load.go\npackage task import ( \u0026quot;time\u0026quot; ) type Task struct { A string B string C string } func NewTask(name string) (*Task, error) { kb := 1 \u0026lt;\u0026lt; 10 // start async process go func() { for { p := make([]byte, kb, kb) for i := 0; i \u0026lt; kb; i++ { p[i] = 'T' } time.Sleep(time.Second * 2) println(\u0026quot;task\u0026quot;) } }() return \u0026amp;Task{}, nil }  然后编译构建 go build 输出可执行文件 leaks，大家可能注意到了，我这样的写法并没有什么特殊的，是会被garbage collector回收掉的，顶多是回收快慢而已。\n是的，为了方便我们解释pmap排查方法的运用，我们假定这里的内存泄露掉了，怎么个假定法呢？我们关闭gc，运行程序的时候 GOGC=off ./leaks.\n你可以用 top -p $(pidof leaks) 验证下RSS飞涨。\n排查示例：搜索可疑内存区 # 比如，你发现有段anon内存区域，它的占用内存数量在增加，或者这样的区段数量再增加（可以对比前后两次的pmap输出来发现）:\n$ pmap -x $(pidof leaks) \u0026gt; 1.txt $ pmap -x $(pidof leaks) \u0026gt; 2.txt 86754: ./leaks/leaks 86754: ./leaks/leaks Address Kbytes RSS Dirty Mode Mapping Address Kbytes RSS Dirty Mode Mapping 0000000000400000 372 372 0 r-x-- leaks 0000000000400000 372 372 0 r-x-- leaks 000000000045d000 496 476 0 r---- leaks 000000000045d000 496 476 0 r---- leaks 00000000004d9000 16 16 16 rw--- leaks 00000000004d9000 16 16 16 rw--- leaks 00000000004dd000 176 36 36 rw--- [ anon ] 00000000004dd000 176 36 36 rw--- [ anon ] 000000c000000000 131072 98508 98508 rw--- [ anon ] | 000000c000000000 131072 104652 104652 rw--- [ anon ] 00007f26010ad000 39816 3236 3236 rw--- [ anon ] | 00007f26010ad000 39816 3432 3432 rw--- [ anon ] 00007f260378f000 263680 0 0 ----- [ anon ] 00007f260378f000 263680 0 0 ----- [ anon ] 00007f261390f000 4 4 4 rw--- [ anon ] 00007f261390f000 4 4 4 rw--- [ anon ] 00007f2613910000 293564 0 0 ----- [ anon ] 00007f2613910000 293564 0 0 ----- [ anon ] 00007f26257bf000 4 4 4 rw--- [ anon ] 00007f26257bf000 4 4 4 rw--- [ anon ] 00007f26257c0000 36692 0 0 ----- [ anon ] 00007f26257c0000 36692 0 0 ----- [ anon ] 00007f2627b95000 4 4 4 rw--- [ anon ] 00007f2627b95000 4 4 4 rw--- [ anon ] 00007f2627b96000 4580 0 0 ----- [ anon ] 00007f2627b96000 4580 0 0 ----- [ anon ] 00007f262800f000 4 4 4 rw--- [ anon ] 00007f262800f000 4 4 4 rw--- [ anon ] 00007f2628010000 508 0 0 ----- [ anon ] 00007f2628010000 508 0 0 ----- [ anon ] 00007f262808f000 384 44 44 rw--- [ anon ] 00007f262808f000 384 44 44 rw--- [ anon ] 00007ffcdd81c000 132 12 12 rw--- [ stack ] 00007ffcdd81c000 132 12 12 rw--- [ stack ] 00007ffcdd86d000 12 0 0 r---- [ anon ] 00007ffcdd86d000 12 0 0 r---- [ anon ] 00007ffcdd870000 8 4 0 r-x-- [ anon ] 00007ffcdd870000 8 4 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ---------------- ------- ------- ------- ---------------- ------- ------- ------- total kB 771528 102720 101868 | total kB 771528 109060 108208  我们注意到起始地址为000000c000000000 和 00007f26010ad000的区间，RSS内存数量涨了，这说明这里物理内存占用增加了，在明确程序存在内存泄露的前提下，这样的内存区域可以作为可疑内存区去分析一下。或者，是有连续的大内存区块，也是待分析的可疑对象，或者这样的内存区块数量比较多，也应该作为可疑的分析对象。\n找到可疑内存区域之后，就尝试里面的内容导出，导出后再借助strings、hexdump等工具进行分析，通常会打印出一些字符串相关的信息，一般这些信息会帮我们联想起，这些数据大约对应着程序中的哪些数据结构、代码逻辑。\n先执行 gdb -p $(pidof leaks) attach 目标进程，然后执行下面两条命令导出可疑内存区：\ngdb\u0026gt; dump binary memory leaks.p1 0x000000c000000000 0x000000c000000000+131072*1024 gdb\u0026gt; dump binary memory leaks.p2 0x00007f26010ad000 0x00007f26010ad000+39816*1024  然后尝试用strings或者hexdump\n$ strings leaks.p1 ... e[0;34m\\]\\W\\[$(git_color)\\]$(git_branch) \\[\\e[0;37m\\]$\\[\\e[0m\\] SXPFD EXPF e[0;34m\\]\\W\\[$(git_color)\\]$(git_branch) \\[\\e[0;37m\\]$\\[\\e[0m\\] SXPFD EXPF TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT....CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT ...  or\n$ hexdump -C leaks.p1 ... 0008e030 00 00 00 00 00 00 00 00 08 9d f0 00 35 43 00 00 |............5C..| 0008e040 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 0008e050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00090000 00 e0 08 00 c0 00 00 00 00 00 00 00 00 00 00 00 |................| 00090010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00100000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00200000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00400000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00500000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00700000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00800000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00a00000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00b00000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00d00000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00e00000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 01000000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * ...  通过这里的输出，假定这里的输出的一些字符串信息CCCCCCC or TTTTTTTTT是一些更有意义的信息，那它可能帮助我们和程序中的一些数据结构、代码逻辑建立起联系，比如看到这里的字符串C，就想到了配置加载conf.LoadConfig，看到字符串T，就想到了task.NewTask，然后进去追查一下一般也能定位到问题所在。\n使用 gcore转储整个进程，原理类似，gcore会在转储完后立即detach进程，比手动dump速度快，对traced进程的影响时间短，但是转储文件一般比较大（记得ulimit -c设置下），core文件使用hexdump分析的时候也可以选择性跳过一些字节，以分析感兴趣的可疑内存区。\n其他方式 # 内存泄露的排查方式有很多，工具也有很多，比如比较有名的valgrind，但是我测试过程中，valgrind没有像bcc那样精确地定位到内存泄露的位置，可能是我的使用方式有问题。see debugging cgo memory leaks，感兴趣的可以自己研究下。这里就不再展开了。\n总结 # 本文介绍了内存泄露相关的定位分析方法，虽然是面向go开发介绍的，但是也不局限于go，特别是ebpf-memleak的应用，应用面应该会比较广。eBPF对Linux内核版本是有严格要求的，使用过程中也需要注意，eBPF的优势在于它为观测、测量提供了强大的基础支持，所以bcc才会有那么多的分析工具，是不可多得利器。\n本文也算是自己对eBPF的一个初步尝试吧，希望掌握它对自己以后的工作有帮助。开发人员手上可以用的工具不少，但是真的好用、省心的也没有那么多，如果能bcc一行代码定位到位置，我想我也不会愿意pmap、gdb gcore、gdb dump、strings+hexdump\u0026hellip;来分析内存泄露位置，当然如果情况不允许，比如内核版本不支持bcc，那还是灵活选择合适的方式。\n除了掌握上述分析方法，解决已经引入的内存泄露问题，研发流程上也应该多关注上线前测试、CR等基础的规范，尽量将一些问题前置，早发现早解决。\n参考内容 #  memory leaking, https://go101.org/article/memory-leaking.html golang memory leaks, https://yuriktech.com/2020/11/07/Golang-Memory-Leaks/#:~:text=A%20goroutine%20leak%20happens%20when,an%20out%20of%20memory%20exception. finding memory leak in cgo, https://kirshatrov.com/2019/11/04/finding-memory-leak-in-cgo/ dive-into-bpf, https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ introduction to xdp and ebpf, https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/ debugging cgo memory leaks, https://www.youtube.com/watch?v=jiSWxpcuGPw choosing a linux tracer, http://www.brendangregg.com/blog/2015-07-08/choosing-a-linux-tracer.html taming tracepoints in the linux kernel, https://blogs.oracle.com/linux/taming-tracepoints-in-the-linux-kernel linux tracing systems \u0026amp; how they fit together, https://jvns.ca/blog/2017/07/05/linux-tracing-systems/  "}),a.add({id:274,href:"/tags/pprof/",title:"pprof",description:"",content:""}),a.add({id:275,href:"/tags/%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/",title:"内存泄露",description:"",content:""}),a.add({id:276,href:"/tags/clock/",title:"clock",description:"",content:""}),a.add({id:277,href:"/tags/clock-skew/",title:"clock skew",description:"",content:""}),a.add({id:278,href:"/tags/leap-second/",title:"leap second",description:"",content:""}),a.add({id:279,href:"/tags/%E6%97%B6%E9%92%9F/",title:"时钟",description:"",content:""}),a.add({id:280,href:"/tags/%E6%97%B6%E9%92%9F%E6%BC%82%E7%A7%BB/",title:"时钟漂移",description:"",content:""}),a.add({id:281,href:"/blog/2021-03-09-%E8%81%8A%E8%81%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4/",title:"聊聊计算机系统中的时间",description:"我相信很多人都是时间管理大师，几乎所有人都知道生活中如何运用时间，但是我相信很多人并不知道这个世界的时间是如何工作的。\n你了解时间吗 # 如果不相信，那我问几个问题，看读者知道不？\n 你听说过石英晶体吗？ 你听说过晶振振荡周期吗？ 你听说过时钟中断吗？ 你听说过计时电路吗？ 你听说过时钟漂移吗？ 你听说过铯原子钟吗？ 你听说过BIH这个机构吗？ 你听说过闰秒吗？ 你听说过NTP协议吗？ etc.  如果，你不能一一回答上述问题，那这个地球上的时间是如何工作的，你可能并不太清楚 :)。\n我们日出而出、日落而息，我们规划工作事项，我们协调重要工作，我们安排计算机程序精密协作……时间是非常重要的，以至于我们生物进化过程中形成了“生物钟”来适应，它无影无形，它无处不在。\n我们如何测量时间的 # 凭感觉不靠谱 # 先介绍下，我们试如何测量时间的。这并不像大多数人想象的那样简单，烧一炷香？个时辰，或者来个沙漏一只椰子鸡炖熟了，这个有一定的实用价值，但是非常不精确，对于精度要求较高时更是如此。\n天文学测量方式 # 自动17世纪机械钟发明以来，我们就一直在用天文学的方法测量时间。每天太阳都是从东方地平线上升起，然后升到天空的最高处，最后再落到西边。太阳到达天空中的最高点时，称为“中天”（transit of the sun），它在每天正午达到最高点。两次连续的太阳中天之间的时间称为一个“太阳日”（solar day）。因为每天都会有24小时，每小时都有3600s，所以一个“太阳秒”（solar second）被精确定义为 1/86400 个太阳日。\n那么平均太阳日的几何算法，则可以由下图所示：\nps：有些人想为什么不地球自转一周算1天？其实这就是上图中的“恒星日”（sidereal day），以遥远的恒星为参考物，每天转到这个方位算是一个恒星日。但是我们自然万物向阳而生，以太阳这颗大恒星作为参考系似乎是更合理的计时方法。\n在20世纪40年代，科学家们证实了地球的自转周期并非常数（const value，固定值）。由于潮汐摩擦和大气的阻力，地球的自转速度正在变慢。基于对远古时代珊瑚的生长图案的研究，低质学家现在相信，在3亿年前每年大约有400天（太阳日）。年的长度（地球绕太阳一周的时间）被认为是不变的，那么每天的时间就简单地边长了。除了这种长期变化趋势，也存在一点长短的短期变化，这可能是是由于地球地核层熔岩的剧烈沸腾而引起的。\n这些发现，促使天文学家们在计算天的长度时要测量很多天的长度，然后再对它们取平均值，最后除以86400得到的结果称为“平均太阳秒”（mean solar second）。\n物理学测量方式 # 1948年的时候，原子钟诞生，它使更精确地测量时间成为可能。原子钟不受地球的摆动和振动的影响，而是通过铯133原子的跃迁来计时。物理学家从天文学家的手中接管了计时的工作，定义1秒是铯133原子做9192631770次跃迁所用的时间。选择9192631770是为了是原子秒与引入原子秒那一年的平均太阳秒相等。\n目前世界上大约有50个实验室拥有铯133原子钟。每个实验室都定期向巴黎的BIH（Bureau International Heure）报告其时钟滴答数。BIH将这些值平均起来产生“国际原子时间”（international atomic time，简称TAI）。这样TAI就是铯133原子钟从1958年1月1日午夜（起始时间）以来被9192631770除后的平均滴答数。\n尽管TAI相当稳定，并且任何人只要愿意，都可以买到一只铯原子钟，但是它仍然存在一个严重的问题，那就是86400个TAI秒比现在一个平均太阳日要少3微秒（因为平均太阳日越来越长了）。使用TAI计时将意味着多年以后，中午会出现地越来越早，直到最终出现在凌晨（太阳还不知道在哪睡觉，TAI秒却显示已经中午了）。\nUTC与闰秒 # 人们也许早晚会注意到这些变化，今后可能将会发生与1582年古罗马教皇Pope Gregory十三世宣布从日历中删除10天时类似的情况。这一事件导致了街头暴动，因为地主要收一个整月的地租，银行家要收一个整月的利息，而雇主拒绝向雇员支付他们没有工作的那10天的工资，这里只是提到了其中的几个冲突。在一些新教区，人们拒绝任何与教皇法令相关的事情，有长达170年不接受罗马教皇颁布的日历。\nBIH通过引入“闰秒”（leap second）来解决这个问题，避免以后出现类似罗马教皇一次删10天日历的情况，也避免造成世界范围内难以协调、预料的灾难。闰秒什么意思呢，即当TAI和太阳秒计时之间的差增加到800微秒的时候就要使用一次闰秒。闰秒的使用如下图所示。即在箭头指向的时刻处，TAI和太阳秒相差超过阈值时，在UTC中应用一次闰秒，使得UTC保持同步。\n这种修正，产生了一种时间系统，该时间系统基于恒定长度的TAI秒，并力求和太阳的运动保持一致，它被称为“统一协调时间”（universal coordinated time，简称UTC）。UTC是现代人计时的基础。它从根本上取代了原有的标准“格林尼治天文时间”（greenwich mean time），格林尼治天文时间是一种天文时间。\n闰秒的\u0026quot;阴暗面\u0026quot; # 值得一提的是，闰秒有正有负，因为地球自转受很多因素影响，有时变快有时变慢（显然我们很难直观察觉到），不同的时间段内情况也不同，比如从1972年到2020年平均每21个月就有一次闰秒出现，但是有的时间段内则没有闰秒。\n 闰秒为正的情况，UTC时间戳可能会出现这样的时间序列：23:59:59 -\u0026gt; 23:59:60 -\u0026gt; 00:00:00 闰秒为负的情况，UTC时间戳可能会出现这样的时间序列：23:59:58 -\u0026gt; 00:00:00   ps：自1970年后，这过去的几十年里基本上地球自转都是变慢的，所以出现的闰秒都是正闰秒，但是最近几年地球自转有变快的情况，如果一直持续下去，后面可能会出现负闰秒。不过现在也有很多提案希望废除闰秒，因为它确实带来太多问题了。",content:"我相信很多人都是时间管理大师，几乎所有人都知道生活中如何运用时间，但是我相信很多人并不知道这个世界的时间是如何工作的。\n你了解时间吗 # 如果不相信，那我问几个问题，看读者知道不？\n 你听说过石英晶体吗？ 你听说过晶振振荡周期吗？ 你听说过时钟中断吗？ 你听说过计时电路吗？ 你听说过时钟漂移吗？ 你听说过铯原子钟吗？ 你听说过BIH这个机构吗？ 你听说过闰秒吗？ 你听说过NTP协议吗？ etc.  如果，你不能一一回答上述问题，那这个地球上的时间是如何工作的，你可能并不太清楚 :)。\n我们日出而出、日落而息，我们规划工作事项，我们协调重要工作，我们安排计算机程序精密协作……时间是非常重要的，以至于我们生物进化过程中形成了“生物钟”来适应，它无影无形，它无处不在。\n我们如何测量时间的 # 凭感觉不靠谱 # 先介绍下，我们试如何测量时间的。这并不像大多数人想象的那样简单，烧一炷香？个时辰，或者来个沙漏一只椰子鸡炖熟了，这个有一定的实用价值，但是非常不精确，对于精度要求较高时更是如此。\n天文学测量方式 # 自动17世纪机械钟发明以来，我们就一直在用天文学的方法测量时间。每天太阳都是从东方地平线上升起，然后升到天空的最高处，最后再落到西边。太阳到达天空中的最高点时，称为“中天”（transit of the sun），它在每天正午达到最高点。两次连续的太阳中天之间的时间称为一个“太阳日”（solar day）。因为每天都会有24小时，每小时都有3600s，所以一个“太阳秒”（solar second）被精确定义为 1/86400 个太阳日。\n那么平均太阳日的几何算法，则可以由下图所示：\nps：有些人想为什么不地球自转一周算1天？其实这就是上图中的“恒星日”（sidereal day），以遥远的恒星为参考物，每天转到这个方位算是一个恒星日。但是我们自然万物向阳而生，以太阳这颗大恒星作为参考系似乎是更合理的计时方法。\n在20世纪40年代，科学家们证实了地球的自转周期并非常数（const value，固定值）。由于潮汐摩擦和大气的阻力，地球的自转速度正在变慢。基于对远古时代珊瑚的生长图案的研究，低质学家现在相信，在3亿年前每年大约有400天（太阳日）。年的长度（地球绕太阳一周的时间）被认为是不变的，那么每天的时间就简单地边长了。除了这种长期变化趋势，也存在一点长短的短期变化，这可能是是由于地球地核层熔岩的剧烈沸腾而引起的。\n这些发现，促使天文学家们在计算天的长度时要测量很多天的长度，然后再对它们取平均值，最后除以86400得到的结果称为“平均太阳秒”（mean solar second）。\n物理学测量方式 # 1948年的时候，原子钟诞生，它使更精确地测量时间成为可能。原子钟不受地球的摆动和振动的影响，而是通过铯133原子的跃迁来计时。物理学家从天文学家的手中接管了计时的工作，定义1秒是铯133原子做9192631770次跃迁所用的时间。选择9192631770是为了是原子秒与引入原子秒那一年的平均太阳秒相等。\n目前世界上大约有50个实验室拥有铯133原子钟。每个实验室都定期向巴黎的BIH（Bureau International Heure）报告其时钟滴答数。BIH将这些值平均起来产生“国际原子时间”（international atomic time，简称TAI）。这样TAI就是铯133原子钟从1958年1月1日午夜（起始时间）以来被9192631770除后的平均滴答数。\n尽管TAI相当稳定，并且任何人只要愿意，都可以买到一只铯原子钟，但是它仍然存在一个严重的问题，那就是86400个TAI秒比现在一个平均太阳日要少3微秒（因为平均太阳日越来越长了）。使用TAI计时将意味着多年以后，中午会出现地越来越早，直到最终出现在凌晨（太阳还不知道在哪睡觉，TAI秒却显示已经中午了）。\nUTC与闰秒 # 人们也许早晚会注意到这些变化，今后可能将会发生与1582年古罗马教皇Pope Gregory十三世宣布从日历中删除10天时类似的情况。这一事件导致了街头暴动，因为地主要收一个整月的地租，银行家要收一个整月的利息，而雇主拒绝向雇员支付他们没有工作的那10天的工资，这里只是提到了其中的几个冲突。在一些新教区，人们拒绝任何与教皇法令相关的事情，有长达170年不接受罗马教皇颁布的日历。\nBIH通过引入“闰秒”（leap second）来解决这个问题，避免以后出现类似罗马教皇一次删10天日历的情况，也避免造成世界范围内难以协调、预料的灾难。闰秒什么意思呢，即当TAI和太阳秒计时之间的差增加到800微秒的时候就要使用一次闰秒。闰秒的使用如下图所示。即在箭头指向的时刻处，TAI和太阳秒相差超过阈值时，在UTC中应用一次闰秒，使得UTC保持同步。\n这种修正，产生了一种时间系统，该时间系统基于恒定长度的TAI秒，并力求和太阳的运动保持一致，它被称为“统一协调时间”（universal coordinated time，简称UTC）。UTC是现代人计时的基础。它从根本上取代了原有的标准“格林尼治天文时间”（greenwich mean time），格林尼治天文时间是一种天文时间。\n闰秒的\u0026quot;阴暗面\u0026quot; # 值得一提的是，闰秒有正有负，因为地球自转受很多因素影响，有时变快有时变慢（显然我们很难直观察觉到），不同的时间段内情况也不同，比如从1972年到2020年平均每21个月就有一次闰秒出现，但是有的时间段内则没有闰秒。\n 闰秒为正的情况，UTC时间戳可能会出现这样的时间序列：23:59:59 -\u0026gt; 23:59:60 -\u0026gt; 00:00:00 闰秒为负的情况，UTC时间戳可能会出现这样的时间序列：23:59:58 -\u0026gt; 00:00:00   ps：自1970年后，这过去的几十年里基本上地球自转都是变慢的，所以出现的闰秒都是正闰秒，但是最近几年地球自转有变快的情况，如果一直持续下去，后面可能会出现负闰秒。不过现在也有很多提案希望废除闰秒，因为它确实带来太多问题了。\nsee：https://www.timeanddate.com/time/negative-leap-second.html\n 对于计算机系统中的石英晶体，由于其精度的问题，会导致时间上出现偏差（过快或过慢都有可能），计算机系统通过NTP协议（network time protocol）与时间服务器（time server）进行通信来同步最新的时间。当出现闰秒时，NTP服务器一般会告知客户端出现了闰秒（通过Leap Indicator告知客户端），客户端收到后要进行适当的处理，当然不同的操作系统处理方式不一样。\nUTC与Unix时间戳 # 再重复下，UTC是协调世界时（Coordinated Universal Time）的缩写，是一种国际标准的时间标准，用于协调全球各地的时间。UTC时间标准是基于原子钟的时间测量，它的秒长是固定的，每秒钟恒定为9192631770个周期的辐射。UTC时间标准是世界上最广泛使用的时间标准之一，它被广泛应用于科学、技术、航空、航天、通信、金融等领域。\n一个完整的UTC时间表示是“YYYY-MM-DDTHH:mm:ss.sssZ”，其中Z表示时区信息，当你拿到一个UTC时间之后，就可以转换成全球其他时区的时间，比如北京是东八区，和UTC时区差8个小时，可以zdump -v /usr/share/zoneinfo/Asia/Shanghai查看。\nUnix时间戳通常是一个整数，表示从1970年1月1日00:00:00 UTC开始到当前时间所经过的秒数，将其转换为Unix timestamp后，这个值是与timezone无关的，因为UTC包含了时区信息。既然是基于UTC时间1970-01-01 00:00:00+时区offset以后的秒数，那么就是与时区无关的了。see Do UNIX timestamps change across timezones?。\n闰秒与UTC、Unix时间戳 # 当出现闰秒时，会对UTC时间进行调整，导致计算出的Unix时间戳也会收到影响，比如下面这个例子，正闰秒1s以及紧跟着的1s，unix时间戳会重复。当从unix时间戳转换为UTC时间时会对应着2个时间，这就出现了歧义。\n要解决这个问题，就需要查闰秒表，通过这个来修正才能比较好地解决此问题。\n很多应用程序都是使用Unix时间戳（没有考虑闰秒的）来作为应用程序中的时间的，如果操作系统贸然插入1s或者减去1s都会对时间敏感的应用造成严重后果。用户先后发起了两个操作，修改订单、下单请求，请求里面都带有时间戳，但是如果取消订单时因为闰秒的原因导致时间向过去跳了1s，造成服务端看来用户是先下单，后修改订单，那么将导致订单修改失败（通常是下单后无法修改的）。\nps: 比这个问题严重的多的场景多的是，当然健壮的系统会考虑采用逻辑时钟等手段来解决，如向量时钟，这里不多说了。\n为了避免应用程序处理这个闰秒问题的复杂性，屏蔽不同操作系统的差异，有些大厂会自建NTP服务器，在收到上游NTP服务器的闰秒事件时，会通过leap smear的方式，将这个闰秒事件的影响均匀地打散到接下来的时间里，使得时间一直是只增不减的。这样公司内部从自建NTP服务器上同步过去的时间虽然可能会有点点不那么精准，但是却很有效地解决了闰秒可能带来的潜在的灾难。\nGoogle内部就是借助leap smear的方式来做的，当接收到通知某天有闰秒出现，自建NTP服务器（修改代码支持leap smear）将闰秒打散到全天，保证时间慢慢增加，内部服务器都用这个时间，就不用处理闰秒带来的跳变的问题了。Amazon采取了类似的方式，稍有不同，以及其他的一些做法，可以参考维基百科。\n鉴于UTC引入leap second所带来的的问题，比如对计算机系统、分布式系统等等，国际会议也在讨论要不要考虑更好的方式，比如应用程序中希望使用精确时间时总是使用TAI，而在希望人类可读的场景下将其转换成UTC显示。其实Google采用的leap smear的方式也是一种比较好的实践。\n计算机如何测量时间的 # 计算机的物理时钟 # 计算机中有一个计时电路，尽管通常使用“时钟”这个概念，但是用“计时器（timer）”更恰当一点。计算机的计时器通常是一个精密加工的石英晶体，石英晶体在其张力限度内以一定的频率振荡，这个频率取决于晶体本身如何被切割及其受到的张力的大小。\n有两个寄存器与每个石英晶体相关联，一个是计数器（counter），另一个是保持寄存器（holding register）。石英晶体的每次振荡使计数器-1，当减为0时则触发一个中断；然后，计数器从保持寄存器中重新装入初始值。每次中断称为一个时钟滴答。\n系统初次启动时，通常要求用户输入日期和时间，然后将它们转换成某一个已知起始时间后的时钟滴答次数，并将它存储在存储器中。许多计算机都有一个特殊的电池支持的CMOS RAM，其目的是为了以后启动时不再需要输入日期和时间。\n时钟每滴答一次，就产生一个时钟中断，时钟中断服务程序就使存储在存储器里面的时间值+1。用这种方法进行（软）时钟计时。\nps：多CPU系统中，每个CPU都有自己的时钟。\n大家了解到我们现在已经用原子钟测量时间了，我们不禁要问，这个晶振振荡周期规律么、精准吗？不精准！时间久了，计算机的物理时钟时间与世界真实时间就有了偏差，称之为”时间偏移“（time skew）。\n别担心，我们还有计算机网络，我们可以让计算机通过计算机网络与时间更精准的服务器进行通信，来同步时间。\n网络时间协议NTP # 我们可以让自己的服务器与时间服务器（time server）进行通信完成时间的同步。时间服务器可以精确地提供当前时间，因为它装备了一个WWV接收器或一个精确的时钟。\nps: WWV（shortwave radio station）接收器，使得安装有该设备的接收器可以通过GPS全球定位系统来同步时间，声称误差在20~35ns误差范围内，可以说是相当精确了。GPS卫星上也是安装的原子钟。如果想了解如何借助GPS全球定位系统实现时间同步，可以自行查阅相关资料，这里不再展开。\n当然，问题是，何时与该服务器联系，消息延时会使得报告的时间过时，这里有个技巧，就是给消息带上时间戳，好让我们对消息的传输延时做出很好的估计。比如像下图这样：\n要求client A、server B发送接收消息时都带上当时时刻的时间信息，这样我们就可以大致算出client A发送请求到server B接收的传输时延为T2-T1，同理可知server B发送响应给client A的传输时延为T4-T3，我们有理由相信这两次传输的时间应该相差无几，为了让传输时延影响更小，就取平均值作为传输时延吧。然后基于T3这个响应的时间点，我们相信T3是NTP server的准确时间，所以就可以计算出当前client A同步到的时间为：\nT = T3 + ((T2-T1)+(T4-T3))/2  这个很好理解。\n不要高兴太早，我们还需要意识到一个问题，就是时间不允许后退的问题。时间一旦出现后退，对无数的电子设备、计算机系统而言将是十足的灾难。\n这里的同步到的时间T相对本地当前时间而言，是更快的话，直接设置当前时间为T就行了？似乎没问题。那如果是慢了呢？直接调慢行吗，前面说了，不行，这回让时间倒退。\n实际上，计算机系统可以采用一种逐步调整的方式。比如，假设计时器设置为每秒产生100个中断。正常情况下，每个中断将添加10ms，当减慢时，每个中断例程只添加9ms，直到校正完成为止。同样的，通过在每个中断中添加11ms，时钟也可以逐步往前调快。\n网络时间协议在服务器之间创建了两条连接，比如上面讲了A可以参考B的时间调整自己的时间，原则上B也可以参照A的调整自己的呀！是这样吗，如果B上面装了WWV接收器或者原子钟，那么一个拥有精确时间的NTP去参考一个靠普通石英晶体维护时间的NTP，这不是犯傻吗？怎么解决这个问题呢？\nNTP服务器也是分层的，通常拥有WWV接收器或者原子钟的，称为1层服务器，那0层是谁？OK，0层指的是时钟本身。其他k层（k\u0026gt;1）服务器可以参考k-1层的服务器来完成时间同步，反过来则不行。如果一个NTP服务器是k层服务器，另一个服务器是k+2层服务器，其如果通过k层服务器调整后，它将从k+2层变为k+1层。\nNTP中还是有很多重要的特性的，并不是像我们想象的那么简单，感兴趣的话可以参考相关资料。\n如何解决时间漂移问题 # 前面我们介绍了测量时间的方式，从经验主义，到天文学测量，到物理学测量，以及兼顾物理学、天文学的测量，方式也一步步更加精确、完善、实用。我们还谈到了计算机系统中的时间系统是如何更新的。想必大家感觉对于这个星球上的时间系统的工作原理更清晰了。\n这里还有个问题，就是时间漂移问题。尽管我们前面提及了精确测量时间、时间同步协议等尽可能保证时间准确的方式，但是效果也是”尽可能”让其精确，我们还是不能百分百地保证全球所有电子设备、分布式系统中节点的时间是完全一致的，甚至是同一个计算机但是是多处理器系统中的多个时钟也不是完全一致的。\n这回带来什么问题呢？如果运行其上的系统，依赖“时间”对操作顺序执行先后做判断，那这样的系统很可能是存在问题的。\n在分布式系统设计中，一般会采用“逻辑时钟”、“向量时钟”等方式来代替真实时钟，来作为操作顺序执行先后的判断依据。这里的内容有很多，后面我们有机会再单独写一篇文章来介绍。\n总结 # 本文开头给大家泼了点冷水，很可能让部分读者对自信了解的时间没了信心 :) ，然后我们介绍了时间测量方式的一些演变，以及计算机系统中如何保持时间的同步，最后又抛出了另一个值得深思的问题，如何解决时间漂移问题在多处理器系统、分布式系统中带来的时序相关的问题。\n相信大家对时间有了一个更深的认识，也希望激发了大家对时间的进一步思考吧。\n参考文献：\n leap second five different ways handle leap seconds what is a leap second leapsecond.com interesting info on leap second gps network time synchonization what is a negative leap second Do UNIX timestamps change across timezones?  "}),a.add({id:282,href:"/tags/%E9%97%B0%E7%A7%92/",title:"闰秒",description:"",content:""}),a.add({id:283,href:"/tags/invalidate-queue/",title:"invalidate queue",description:"",content:""}),a.add({id:284,href:"/tags/memory-barrier/",title:"memory barrier",description:"",content:""}),a.add({id:285,href:"/tags/store-buffer/",title:"store buffer",description:"",content:""}),a.add({id:286,href:"/blog/2020-12-15-%E7%A1%AC%E4%BB%B6%E8%A7%86%E8%A7%92%E5%89%96%E6%9E%90%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/",title:"硬件视角剖析内存屏障实现原理",description:"内存屏障类型 # 软件开发中创建屏障 # 硬件视角看屏障实现 # 总结 # text goes here",content:"内存屏障类型 # 软件开发中创建屏障 # 硬件视角看屏障实现 # 总结 # text goes here\n"}),a.add({id:287,href:"/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/",title:"代码规范",description:"",content:""}),a.add({id:288,href:"/tags/%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F/",title:"代码质量",description:"",content:""}),a.add({id:289,href:"/tags/%E5%8F%AF%E8%AF%BB%E6%80%A7/",title:"可读性",description:"",content:""}),a.add({id:290,href:"/blog/2020-10-16-%E5%81%B7%E6%87%92%E4%BB%8E%E6%8F%90%E5%8D%87%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F%E5%BC%80%E5%A7%8B/",title:"如何“偷懒”：从提升代码质量开始",description:"如果一件事情只需要做一次，我们可能怎么方便怎么来，但是如果一件事情要重复千百遍，怎么方便怎么来就会变成灾难。对身体，对时间，对团队。停下来想想过去做的一些事情，都是为了做好事情的同时，能让自己更好地慢下来，让身体可以偷懒。本文先从提升代码质量开始谈起。\nLinus Torvards在一次采访中，主持人贴了两个链表操作的实现，让其评价哪一种更好一点，Torvards说更喜欢消除了特殊逻辑的那种，并将这种偏好称为“taste”。每个人的taste不同，也不方便评价好与坏，但是“脑筋急转弯似”的做法一点都不“聪明”。好的思路很多都是相同的，不好的东西千差万别的厉害。\n站在巨人肩膀上 # 从什么时候开始，我开始思考如何在有限的时间里涉猎更多的东西，awesome、101、patterns、slideshare、best practices\u0026hellip;似乎有限的时间被延长了，我们没必要一个个坑的踩过来摸索中前进，别把别人头破血流总结出的经验教训不当回事。以前我奉行“纸上得来终觉浅、绝知此事要躬行”，很好，但是生命是有限的。\n想要更大的世界，必须懂得借力，吸收经验教训，好的坏的全部统统吸纳滋养自己。\n对异常关注不足，未养成安全编程习惯 # 经常看到 if ok {...} else {...} 这样的代码，没有养成优先处理异常的习惯。导致出现多余的if-else分支是小事，怕的是，这么习惯了容易产生下面的问题：if中先处理正常逻辑，else中再事后补异常处理逻辑，而对异常情景的细分，也可能会因为“功能已完成、异常哪有那么巧出现”的侥幸心理而有所倦怠，如rpc错误是网络错误、超时还是逻辑逻辑，每种该作何处理，可能会草草了事。不能说这种担心是多余的，人都是属驴的，自己也会有这种惰性。\n对输入不做校验，“不大可能”，这不能算是一个合理的理由，“调用方判断”，这更不合理。这就好比我想吃饭了，从商家买到过保质期的食物，那我作为活动的发起方（调用方）我肯定会检查下食物保质期，但是商家也不能不管保质期就卖给我吧。那这么看，是调用方检查，还是提供方检查，还是没必要。自己的函数坑自己的服务，也是坑。\n每每提及“高可用”、5个9，大家就竖起耳朵听，可是连基本的进程级的健壮性都不下功夫，又怎么去奢求诗和远方。\n写的虽然是代码，但其实是逻辑的表达 # 发明高级语言的目的，就是为了更好的表达，但是我们学会了编程语言，却忘了怎么表达。\n我想了想那些好的文章是怎么写的，我们需要一个吸睛的标题来惹人关注，需要时刻不忘中心思想避免论述过于涣散，还需要凤头猪肚豹尾来层层论述，每个段落也要有提纲挈领的中心句。如果说是一本书，也还是类似的，但是又有了其他的要求，章节并不是硬性的切割，有时候我们前言里会看到，您可以根据情况自主选择感兴趣的章节阅读，那是因为各个章节相对独立，结合起来又形成一个更完备的论述。\n那，代码该怎么写呢？\n一个服务的所有逻辑，平铺在一个工程下的源文件中，没有任何模块化的组织，比如go项目没有任何package，那我们的逻辑是变复杂了还是变简单了？ 函数、方法调用体现的是一种通信，当我们去和别人沟通时，我们一定是清晰地知道别人能提供我们需要的服务，才会去选择与其沟通，而且为了有效率的沟通，还要言简意赅。那一个package、receiver下的函数、方法不区分导出、非导出，那该选择哪个发起通信呢？而且内部的一些实现细节也不关心，我只关心能不能买到服务。 完成一项任务，总可以拆分成几个步骤，所以我们可以先写伪代码列出todolist，基本上每一项todo都是一个相对独立的逻辑，还可以为每个相对独立的逻辑加一行简单的注释，末尾加空行隔开，以体现出逻辑区块。难道从头撸到尾能将逻辑表达的更清晰？想象一篇没有标点的作文该怎样阅读？ …… 有时候，我们说编码好坏是习惯问题，是taste，但我觉得是思维习惯的问题。这样的习惯日积月累，负面影响可能会更大。\n简单点再简单点，简单可依赖 # 什么是简单？是方便，是省心？我觉得是诚实不隐瞒，是就是，不是就不是。最恨的就是那些表面光正背后搞小动作的代码。\n有些代码表里不一，表面是一套，背后是一套。命名说是做这个，结果背后不干这个，或者除了干这个还干别的。为什么我们使用一些标准库的api的时候就愿意选择相信它，但是看我们自己代码的时候就不得不频繁地跳来跳去呢？\n不相信写的代码，原因跟下面经常遇到的问题相关，经过了现实的捶打只能先“另眼相看”； 导出类型、方法、函数、变量、常量缺乏必要的注释，不得已只能跳过去看代码； 函数签名多返回值没有必要说明，如返回值变量名，除了最后一个是error不知其他干嘛的，只能跳过去看return，问题是还有多个return出口； 函数签名参数列表，shorter \u0026amp; simpler，如果有近10个、20来个参数，怎么记得住形参？传实参的时候会不会对应错误？哪些参数是必填、选填？命名是否能准确清晰地覆盖这些参数？ hack逻辑，如硬编码，这些损失的不只是灵活性，也植入了一些暗黑操作。一个好的软件架构师应该做到“make the invisible visible”，invisible的一个直观的害处就是，越俎代庖的事情会变得普遍，本来可以由调用方支配的一些控制参数，被独断专行了，本来应该上升到系统层面的问题，被一个模块偷偷代表了； …… 我的逻辑是，只要阅读代码的时候有非常频繁的跳转、推导、假设、验证的过程，那这个代码的可读性就真的不怎么样。\n公司代码规范 # 只要是规范，就有局限性、滞后性。我理解，规范不是让我们追求完美主义，而是追求better code，better practices。如果一个开发者有好的taste，他写出来的代码可能已经接近或达到规范的要求了。但是并不是每个开发者都有这样的taste，所以我们才需要规范来约束我们做一件共同的事情。\n遵守代码规范的一个明显的好处是，可读性会有比较明显的提升，这是很有意义的。可读性提升，意味着维护成本降低，意味着省下时间，意味着可以在正常工作时间做更多事情，可以早下班休息、充电。这可能不是对每个人都是个好事情，但是是对团队有意义的事情，对多数人有意义的事情，就应该坚持！\n最后 # 多年前翻阅Linux文档，Torvards解释为什么一个Tab非要8个空格而非通用的4个，他说，我就是要让那些爱写嵌套多层代码的人“难受”……\n省下大把自己、大家的时间，这难道不是一种很聪明的“偷懒”行为？",content:"如果一件事情只需要做一次，我们可能怎么方便怎么来，但是如果一件事情要重复千百遍，怎么方便怎么来就会变成灾难。对身体，对时间，对团队。停下来想想过去做的一些事情，都是为了做好事情的同时，能让自己更好地慢下来，让身体可以偷懒。本文先从提升代码质量开始谈起。\nLinus Torvards在一次采访中，主持人贴了两个链表操作的实现，让其评价哪一种更好一点，Torvards说更喜欢消除了特殊逻辑的那种，并将这种偏好称为“taste”。每个人的taste不同，也不方便评价好与坏，但是“脑筋急转弯似”的做法一点都不“聪明”。好的思路很多都是相同的，不好的东西千差万别的厉害。\n站在巨人肩膀上 # 从什么时候开始，我开始思考如何在有限的时间里涉猎更多的东西，awesome、101、patterns、slideshare、best practices\u0026hellip;似乎有限的时间被延长了，我们没必要一个个坑的踩过来摸索中前进，别把别人头破血流总结出的经验教训不当回事。以前我奉行“纸上得来终觉浅、绝知此事要躬行”，很好，但是生命是有限的。\n想要更大的世界，必须懂得借力，吸收经验教训，好的坏的全部统统吸纳滋养自己。\n对异常关注不足，未养成安全编程习惯 # 经常看到 if ok {...} else {...} 这样的代码，没有养成优先处理异常的习惯。导致出现多余的if-else分支是小事，怕的是，这么习惯了容易产生下面的问题：if中先处理正常逻辑，else中再事后补异常处理逻辑，而对异常情景的细分，也可能会因为“功能已完成、异常哪有那么巧出现”的侥幸心理而有所倦怠，如rpc错误是网络错误、超时还是逻辑逻辑，每种该作何处理，可能会草草了事。不能说这种担心是多余的，人都是属驴的，自己也会有这种惰性。\n对输入不做校验，“不大可能”，这不能算是一个合理的理由，“调用方判断”，这更不合理。这就好比我想吃饭了，从商家买到过保质期的食物，那我作为活动的发起方（调用方）我肯定会检查下食物保质期，但是商家也不能不管保质期就卖给我吧。那这么看，是调用方检查，还是提供方检查，还是没必要。自己的函数坑自己的服务，也是坑。\n每每提及“高可用”、5个9，大家就竖起耳朵听，可是连基本的进程级的健壮性都不下功夫，又怎么去奢求诗和远方。\n写的虽然是代码，但其实是逻辑的表达 # 发明高级语言的目的，就是为了更好的表达，但是我们学会了编程语言，却忘了怎么表达。\n我想了想那些好的文章是怎么写的，我们需要一个吸睛的标题来惹人关注，需要时刻不忘中心思想避免论述过于涣散，还需要凤头猪肚豹尾来层层论述，每个段落也要有提纲挈领的中心句。如果说是一本书，也还是类似的，但是又有了其他的要求，章节并不是硬性的切割，有时候我们前言里会看到，您可以根据情况自主选择感兴趣的章节阅读，那是因为各个章节相对独立，结合起来又形成一个更完备的论述。\n那，代码该怎么写呢？\n一个服务的所有逻辑，平铺在一个工程下的源文件中，没有任何模块化的组织，比如go项目没有任何package，那我们的逻辑是变复杂了还是变简单了？ 函数、方法调用体现的是一种通信，当我们去和别人沟通时，我们一定是清晰地知道别人能提供我们需要的服务，才会去选择与其沟通，而且为了有效率的沟通，还要言简意赅。那一个package、receiver下的函数、方法不区分导出、非导出，那该选择哪个发起通信呢？而且内部的一些实现细节也不关心，我只关心能不能买到服务。 完成一项任务，总可以拆分成几个步骤，所以我们可以先写伪代码列出todolist，基本上每一项todo都是一个相对独立的逻辑，还可以为每个相对独立的逻辑加一行简单的注释，末尾加空行隔开，以体现出逻辑区块。难道从头撸到尾能将逻辑表达的更清晰？想象一篇没有标点的作文该怎样阅读？ …… 有时候，我们说编码好坏是习惯问题，是taste，但我觉得是思维习惯的问题。这样的习惯日积月累，负面影响可能会更大。\n简单点再简单点，简单可依赖 # 什么是简单？是方便，是省心？我觉得是诚实不隐瞒，是就是，不是就不是。最恨的就是那些表面光正背后搞小动作的代码。\n有些代码表里不一，表面是一套，背后是一套。命名说是做这个，结果背后不干这个，或者除了干这个还干别的。为什么我们使用一些标准库的api的时候就愿意选择相信它，但是看我们自己代码的时候就不得不频繁地跳来跳去呢？\n不相信写的代码，原因跟下面经常遇到的问题相关，经过了现实的捶打只能先“另眼相看”； 导出类型、方法、函数、变量、常量缺乏必要的注释，不得已只能跳过去看代码； 函数签名多返回值没有必要说明，如返回值变量名，除了最后一个是error不知其他干嘛的，只能跳过去看return，问题是还有多个return出口； 函数签名参数列表，shorter \u0026amp; simpler，如果有近10个、20来个参数，怎么记得住形参？传实参的时候会不会对应错误？哪些参数是必填、选填？命名是否能准确清晰地覆盖这些参数？ hack逻辑，如硬编码，这些损失的不只是灵活性，也植入了一些暗黑操作。一个好的软件架构师应该做到“make the invisible visible”，invisible的一个直观的害处就是，越俎代庖的事情会变得普遍，本来可以由调用方支配的一些控制参数，被独断专行了，本来应该上升到系统层面的问题，被一个模块偷偷代表了； …… 我的逻辑是，只要阅读代码的时候有非常频繁的跳转、推导、假设、验证的过程，那这个代码的可读性就真的不怎么样。\n公司代码规范 # 只要是规范，就有局限性、滞后性。我理解，规范不是让我们追求完美主义，而是追求better code，better practices。如果一个开发者有好的taste，他写出来的代码可能已经接近或达到规范的要求了。但是并不是每个开发者都有这样的taste，所以我们才需要规范来约束我们做一件共同的事情。\n遵守代码规范的一个明显的好处是，可读性会有比较明显的提升，这是很有意义的。可读性提升，意味着维护成本降低，意味着省下时间，意味着可以在正常工作时间做更多事情，可以早下班休息、充电。这可能不是对每个人都是个好事情，但是是对团队有意义的事情，对多数人有意义的事情，就应该坚持！\n最后 # 多年前翻阅Linux文档，Torvards解释为什么一个Tab非要8个空格而非通用的4个，他说，我就是要让那些爱写嵌套多层代码的人“难受”……\n省下大把自己、大家的时间，这难道不是一种很聪明的“偷懒”行为？\n"}),a.add({id:291,href:"/tags/uml/",title:"uml",description:"",content:""}),a.add({id:292,href:"/tags/visualize/",title:"visualize",description:"",content:""}),a.add({id:293,href:"/blog/2020-10-06-visualizing-your-go-code/",title:"Visualizing Your Go Code",description:"代码可读性 # 作为一名开发人员，代码可读性是我们常常挂在嘴边的。代码写出来除了让计算机能够正常执行以外，终究还是要让人能够理解它，后续才能做进一步的维护工作。如果代码写出来，只有它的作者能够看得懂，那只能说明这个作者逻辑表达能力有问题，透过其代码难以看出解决问题的思路。这是软件工程中要尽力避免的。\n在软件工程方法论指导下，为了尽可能让代码可读性达标，我们往往会根据一些最佳实践拟定一些大多数人认可的标准，让所有开发人员遵守，然后通过代码评审、代码规范检查、持续集成交付流水线等综合起来，以尽可能逼近这一目标。当绝大多数人能够在约定的框架下，保质保量提交代码时，我们已经在代码可读性、可维护性方面前进了一大步。\n然而，这样足够了吗？我认为还不够。\n代码是思维的表达 # 代码，不过是通过一种大家都理解的语言书写出来的篇章。就好比写文章一样，要有中心思想，然后围绕中心思想要展开层层描述。写代码一样，中心思想就是我们要解决的问题，围绕中心思想的层层描述就是我们解决问题的思路。所以，代码没有什么神秘的，它是人类思维的表达。\n我们是如何快速理解一篇文章的呢？\n 先看标题，掌握其核心关键词； 看下第一段落的内容，往往第一段会引出问题； 看下其余段落的首句、末句，往往会给出该段落的中心思想； 看下最后一段的内容，一般会给出一个结论； 通篇串下，了解文章整体含义；  为什么我们会通过这种方式？因为一篇好的文章一定有承上启下、过渡。这种循序渐进的方式，步步逼近中心思想。\n那代码呢？某种程度上，代码也是类似的。\n 以go语言为例，通常对于一个package，我们会提供package注释来表示当前package要解决的问题； 每个package内部又包含了不同的types、variables、functions，它们结合起来来解决一个问题； 每一个function内部又分为多个步骤，每一步完成一个小功能，为下一步做好准备； 每一个小功能、步骤可能是if-else, switch-case, for-loop……之类的语言结构； 同时，我们还会提供测试用例，来验证上述方案的正确性。  有没有觉得很相似，或许我们应该采用已有的读书的经验来辅助更好地理解程序？\nOOP思想认识世界 # 代码，和文章不同的是，它虽然有明显的程序构造，但是却没有明显的段落之分。\n那我如何才能借鉴多年来养成的还不错的阅读习惯，来帮助我理解代码呢？当然不能盲目套用，不过俗话说，能工摹形，巧匠窃意，思想很多地方还是可以相通的。\n如何更好地理解这个世界，对各种各样的问题进行抽象呢？比如一辆摩托车，它有离合器、发动机、链条、轮毂、轮胎、减震、油箱、排气等很多部件构成，我听说宝马水鸟电子控制很厉害，可以实现无人驾驶，那可是两轮的400多斤的大机器。那它的电子控制系统怎么做到的？至少要能理解一个摩托车有核心部件，整体运转起来如何理解其状态，如何控制个别部件以影响其他部件进而控制整体状态。那它如何控制部件呢？电子操作或机械操作。\n扯远了，我只是有点喜欢水鸟而已。整个世界可以看做是一个个对象及其之间的联系所构成，代码也不例外。\n道法自然，OOP的思想不过是借鉴了人类认识世界的方式，将其运用到了软件工程领域，以更好地对问题进行抽象，从而构建出设计更合理的软件。那代码里面有哪些语言构造体现了OOP的思想呢。\n 类型与对象，生物学里区分物种、种群、个体，那是因为它们既有共性，也有个性； 通信的方式，自然界个体之间的交互也有多种方式，比如雄狮撒泡尿标记领地也不管入侵者认不认同，或者低吼驱赶入侵者离开，人和人用听得懂的语言沟通； 隐私与距离，每个人都有自己的隐私，如果你的朋友跟你借100块钱你可能给了，但是他如果问是你老婆给的还是你自己的，你可能就不想借给他了，给你就行了你管那么多干嘛呢，我还不想拿自家的借你呢，说不定借你老婆的给你的呢。每个人在一副外表下总有些不愿意被人触碰、靠近的地方。  了解一个人，其实你不需要深入他的家庭本身去了解，看看他天天接触什么人，说些什么话，你也就大致清楚了。感兴趣就继续了解，不感兴趣也就拉倒了。我想绝大多数人都不是窥视狂，在拥有一定判断力的基础上，通过一些局部的信息是可以了解大致的整体信息的。\n理解代码有相同之处？\n流程控制 + 组件交互 # 某种程度上，我认为理解代码也有相似之处。\n如果能够拎出那些比较重要的对象（objects），以及他们之间的通信（function call, chan send/recv），或者他们的私密信息（注释），是不是也能够大致有个了解呢？\n如果想更深入了解下，加上事情的脉络（控制结构，if-else, switch-case, for-loop）呢？\n其他信息? 我相信还有其他有用的有用信息，能够通过一些更加有效率的方式呈现出来。\n认识 go/ast # 计算机编程语言，有多少种？我认为只有一种，就是人类可以理解的语言。有趣的是，编程语言之多可以覆盖元素周期表，不信来瞧瞧。\n       语言是什么？语言有精确的数学定义，它不是胡编乱造，尤其是编程语言； 编程语言更精确？那倒未必，人类社会多姿多彩之处，就在于会演绎出更加丰富多彩的内容，包括对语言的破坏性“创造”，人脑纠错能力太强了，我们甚至没有察觉到自己犯了错误，如网上津津乐道的山东人倒装玩法； 我能发明一门语言吗？当然，只要你能给出严谨的数学定义，没有歧义，找到一群人学会并开始用它交流，姑且可以称为语言了，比如生活大爆炸谢耳朵他老婆； 语言不是主谓宾之类的吗？主谓宾也可以进一步形式化，数学之美也让我感到惊叹；  So\u0026hellip;假如我用编程语言写了一段代码，如何知道我有没有犯错误呢？那就是编译器的工作，词法分析、语法分析、语义分析，一切OK之后会进入中间代码生成、代码优化、生成最终代码。通常一般在语法分析会构建语法分析树AST（Abstract Syntax Tree），如果能够正常构建出AST，表示代码是按照语言对应生成规则来写的，就没什么大问题，反之则可能又自我“发挥”犯错了。",content:"代码可读性 # 作为一名开发人员，代码可读性是我们常常挂在嘴边的。代码写出来除了让计算机能够正常执行以外，终究还是要让人能够理解它，后续才能做进一步的维护工作。如果代码写出来，只有它的作者能够看得懂，那只能说明这个作者逻辑表达能力有问题，透过其代码难以看出解决问题的思路。这是软件工程中要尽力避免的。\n在软件工程方法论指导下，为了尽可能让代码可读性达标，我们往往会根据一些最佳实践拟定一些大多数人认可的标准，让所有开发人员遵守，然后通过代码评审、代码规范检查、持续集成交付流水线等综合起来，以尽可能逼近这一目标。当绝大多数人能够在约定的框架下，保质保量提交代码时，我们已经在代码可读性、可维护性方面前进了一大步。\n然而，这样足够了吗？我认为还不够。\n代码是思维的表达 # 代码，不过是通过一种大家都理解的语言书写出来的篇章。就好比写文章一样，要有中心思想，然后围绕中心思想要展开层层描述。写代码一样，中心思想就是我们要解决的问题，围绕中心思想的层层描述就是我们解决问题的思路。所以，代码没有什么神秘的，它是人类思维的表达。\n我们是如何快速理解一篇文章的呢？\n 先看标题，掌握其核心关键词； 看下第一段落的内容，往往第一段会引出问题； 看下其余段落的首句、末句，往往会给出该段落的中心思想； 看下最后一段的内容，一般会给出一个结论； 通篇串下，了解文章整体含义；  为什么我们会通过这种方式？因为一篇好的文章一定有承上启下、过渡。这种循序渐进的方式，步步逼近中心思想。\n那代码呢？某种程度上，代码也是类似的。\n 以go语言为例，通常对于一个package，我们会提供package注释来表示当前package要解决的问题； 每个package内部又包含了不同的types、variables、functions，它们结合起来来解决一个问题； 每一个function内部又分为多个步骤，每一步完成一个小功能，为下一步做好准备； 每一个小功能、步骤可能是if-else, switch-case, for-loop……之类的语言结构； 同时，我们还会提供测试用例，来验证上述方案的正确性。  有没有觉得很相似，或许我们应该采用已有的读书的经验来辅助更好地理解程序？\nOOP思想认识世界 # 代码，和文章不同的是，它虽然有明显的程序构造，但是却没有明显的段落之分。\n那我如何才能借鉴多年来养成的还不错的阅读习惯，来帮助我理解代码呢？当然不能盲目套用，不过俗话说，能工摹形，巧匠窃意，思想很多地方还是可以相通的。\n如何更好地理解这个世界，对各种各样的问题进行抽象呢？比如一辆摩托车，它有离合器、发动机、链条、轮毂、轮胎、减震、油箱、排气等很多部件构成，我听说宝马水鸟电子控制很厉害，可以实现无人驾驶，那可是两轮的400多斤的大机器。那它的电子控制系统怎么做到的？至少要能理解一个摩托车有核心部件，整体运转起来如何理解其状态，如何控制个别部件以影响其他部件进而控制整体状态。那它如何控制部件呢？电子操作或机械操作。\n扯远了，我只是有点喜欢水鸟而已。整个世界可以看做是一个个对象及其之间的联系所构成，代码也不例外。\n道法自然，OOP的思想不过是借鉴了人类认识世界的方式，将其运用到了软件工程领域，以更好地对问题进行抽象，从而构建出设计更合理的软件。那代码里面有哪些语言构造体现了OOP的思想呢。\n 类型与对象，生物学里区分物种、种群、个体，那是因为它们既有共性，也有个性； 通信的方式，自然界个体之间的交互也有多种方式，比如雄狮撒泡尿标记领地也不管入侵者认不认同，或者低吼驱赶入侵者离开，人和人用听得懂的语言沟通； 隐私与距离，每个人都有自己的隐私，如果你的朋友跟你借100块钱你可能给了，但是他如果问是你老婆给的还是你自己的，你可能就不想借给他了，给你就行了你管那么多干嘛呢，我还不想拿自家的借你呢，说不定借你老婆的给你的呢。每个人在一副外表下总有些不愿意被人触碰、靠近的地方。  了解一个人，其实你不需要深入他的家庭本身去了解，看看他天天接触什么人，说些什么话，你也就大致清楚了。感兴趣就继续了解，不感兴趣也就拉倒了。我想绝大多数人都不是窥视狂，在拥有一定判断力的基础上，通过一些局部的信息是可以了解大致的整体信息的。\n理解代码有相同之处？\n流程控制 + 组件交互 # 某种程度上，我认为理解代码也有相似之处。\n如果能够拎出那些比较重要的对象（objects），以及他们之间的通信（function call, chan send/recv），或者他们的私密信息（注释），是不是也能够大致有个了解呢？\n如果想更深入了解下，加上事情的脉络（控制结构，if-else, switch-case, for-loop）呢？\n其他信息? 我相信还有其他有用的有用信息，能够通过一些更加有效率的方式呈现出来。\n认识 go/ast # 计算机编程语言，有多少种？我认为只有一种，就是人类可以理解的语言。有趣的是，编程语言之多可以覆盖元素周期表，不信来瞧瞧。\n       语言是什么？语言有精确的数学定义，它不是胡编乱造，尤其是编程语言； 编程语言更精确？那倒未必，人类社会多姿多彩之处，就在于会演绎出更加丰富多彩的内容，包括对语言的破坏性“创造”，人脑纠错能力太强了，我们甚至没有察觉到自己犯了错误，如网上津津乐道的山东人倒装玩法； 我能发明一门语言吗？当然，只要你能给出严谨的数学定义，没有歧义，找到一群人学会并开始用它交流，姑且可以称为语言了，比如生活大爆炸谢耳朵他老婆； 语言不是主谓宾之类的吗？主谓宾也可以进一步形式化，数学之美也让我感到惊叹；  So\u0026hellip;假如我用编程语言写了一段代码，如何知道我有没有犯错误呢？那就是编译器的工作，词法分析、语法分析、语义分析，一切OK之后会进入中间代码生成、代码优化、生成最终代码。通常一般在语法分析会构建语法分析树AST（Abstract Syntax Tree），如果能够正常构建出AST，表示代码是按照语言对应生成规则来写的，就没什么大问题，反之则可能又自我“发挥”犯错了。\n以下面的go程序为例：\npackage main import ( \u0026quot;fmt\u0026quot; ) func add(a, b int) int { return a + b } func main() { c := add(1, 2) fmt.Printf(\u0026quot;1 + 2 = %d\\n\u0026quot;, c) }  以下是两个不错的ast可视化工具，可以将上述代码拷贝以下以查看对应的AST。\n ast-explorer goast-viewer  ps: 推荐前者，实现了类似chrome inspect element时选中区域查看对应代码的操作，光标移到对应代码区域，即可高亮显示对应的AST部分区域。\n比如现在我们选中了import相关的部分，对应右边展示出了import声明对应的AST中的部分子树，对应的就是一个GenDecl结构。函数声明也有对应的FuncDecl，类型也有对应的\u0026hellip;\nps: AST展示形式竟然不是一棵树？它确实是一棵树，只不过，AST是非常庞大的，如果通过树的形式来展示，篇幅太大，反而不方便查看。\ngo标准库提供了一个package go/ast，用它来对源码进行分析并构建出AST，然后基于AST可以对源码结构进行理解加工，举几个常见的用途：\n go标准库有频率不高的package迁移、方法签名变化、其他情况，go fix实现了旧代码像新代码的快速迁移，其实就是通过对AST操作实现的； 代码中检测error处理、是否有合理注释等，也可以基于AST进行分析，开发可能一不小心忽略对error处理、goroutine panic处理，有些三方库就可以基于AST分析有没有上述情况，以对源码中的问题进行自动修复； 提取关键操作信息进行可视化，如apitest.dev将HTTP操作、DB操作作为重点关注对象对代码中的相关交互进行提取、可视化展示，Ballerina框架中也有类似实现。 提取关键的网络调用操作，自动化opentracing埋点，Instrumenting Go code via AST。 其他；  可见了解 go/ast，将有助于我们更好地理解代码，并作出一些更有创意的工具。\n微服务可视化 # 我正在调研一些业界流行的微服务框架，吸收一些比较好的创意，在我从事的团队，现在基本都是采用微服务架构设计、开发、部署了，某种程度上，微服务一点都不微，有些逻辑也很复杂，而且业务代码真的没什么好看的。绝大多数时候，我希望1min了解其逻辑，超过10min我还看不懂的，心里已经开始在犯嘀咕了，这写的啥？\n是我“没耐心”？我倒是不这么认为，如果一个操作我每天要人肉重复几十遍，我就得想办法“偷偷懒”提高下效率了。身为工程师，卖肉是耻辱。\n再回想一下哪些语言构造比较重要，rpc、对象之间的通信（方法调用）、包方法调用、goroutine之间通信（chan send/recv），还有控制逻辑if-else、switch-case、for-loop。\n我们可以先从实用又简单点的开始，比如rpc、对象方法调用、包方法调用，其他的后续再完善。OK!\n找到关心的入口点 # 按照一些微服务框架的编码风格，通常main.go里面会注册service接口级实现，这里就可以作为一个入口，我们可以找出AST中main.go中注册的所有service及其实现，并分析service接口中定义的方法，然后再将service实现中的对应方法作为入口点。\n找到这些入口点之后，我们将可以从AST中遍历所有的方法定义，直到匹配到receiver type、method signature匹配的定义。\nfile: main.go\nfunc main() { s := gorpc.NewServer() pb.RegisterHelloService(s, \u0026amp;helloServiceImpl{}) if err := s.Serve(); err != nil { log.Fatal(err) } }  从入口点处开始层层展开 # 每个函数在AST中都有对应的结构，函数体内包括的每一条语句也是这样，那还有什么不能干的？\n我们可以递归地将一条语句层层展开，抽丝剥茧，直到看到关心的脉络。刚才我们说先只考虑rpc、对象方法调用、包导出函数调用就可以了，这类基本可以形式化成xxx.Func(args...)的形式，就覆盖了上面这几种情况。\n只要碰到这样的语句，我们就记录一下，并将其递归地展开，展开过程中依然记录所有xxx.Func(args...)形式的函数调用……直到没什么可继续展开为止。\n这样，我们就可以大致实现最初的设想：看到对象之间的所有通信过程。\n增加通信过程的说明信息 # 在go代码规范里面，对于导出方法、导出函数、导出类型通常都是需要添加godoc注释的，这些注释本身就具有一定的说明性。那当我们通过对象间的调用关系进行可视化时，是否可以将这些注释信息添加上，以提供更好的说明呢？当然。\n何时何地以及如何触发 # 何时何地以及如何触发了特定的函数调用？\n 何时何地？filename:lineno:columnno，每一个ast对象都有一个Pos()方法，配合token.Position(astobj.Pos())就可以计算出源码位置； 如何触发？函数调用时的参数信息，函数调用发生的作用域（function scope）；  Put It Together # 当我们将上述提及的操作全部组织在一起，就可以实现大致如下效果，篇幅以及时间原因，这里就不再一步步详细描述代码逻辑了。\n      如果您对这里的实现确实感兴趣，您可以查看这里的代码来进一步了解MR: gorpc support visualize subcmd。\nps: 我也在做一些gorpc101教程之类的材料准备，包括书籍、框架、工具、插件之类的小玩意，一方面是为了沉淀自己，一方面是为了验证想法，如果能有些许建议或者愿意参与进来，那我先表示欢迎。\n debugger101 gorpc101  "}),a.add({id:294,href:"/contributors/henk-verlinde/",title:"hitzhangjie",description:"Creator of Hyas.\n@hitzhangjie",content:"Creator of Hyas.\n@hitzhangjie\n"}),a.add({id:295,href:"/contributors/",title:"Contributors",description:"The Doks contributors.",content:"The Doks contributors.\n"}),a.add({id:296,href:"/blog/",title:"Blog",description:"The Doks Blog.",content:"🎶 欢迎来到 Kn\u0026rsquo;s Blog\u0026hellip; 这里记录着我的认识和思考\n 👀 所有分类 | 👀 所有标签\n "}),a.add({id:297,href:"/tags/debugger/",title:"debugger",description:"",content:""}),a.add({id:298,href:"/books/debugger101/",title:"Debugger101: Go调试器开发内幕",description:"授人以鱼不如授人以渔，调试器正是这样一款工具，它虽然不知道您程序中何处引入了bug或者理解不到位，但是当你想到它、捡起它，它就可以指引你一步步追根溯源。不仅要做授人以渔的工具，也要做授人以渔的人，不禁要问读者，你们可曾了解过调试器的内部实现？它是如何控制你程序执行的，它是如何知道指定内存地址处的指令或者数据类型的…本书旨在帮助读者打通对编译、调试工具链、调试信息标准以及操作系统之间的认识，使具备一定的调试器定制化开发的能力。",content:"授人以鱼不如授人以渔，调试器正是这样一款工具，它虽然不知道您程序中何处引入了bug或者理解不到位，但是当你想到它、捡起它，它就可以指引你一步步追根溯源。\n不仅要做授人以渔的工具，也要做授人以渔的人，不禁要问读者，你们可曾了解过调试器的内部实现？它是如何控制你程序执行的，它是如何知道指定内存地址处的指令或者数据类型的…本书旨在帮助读者打通对编译、调试工具链、调试信息标准以及操作系统之间的认识，使具备一定的调试器定制化开发的能力。\n 由于本书内容涉及大量系统原理、调试信息标准、设计实现、go源码分析内容，篇幅很大，很难用几篇博文讲述清楚，因此单独写一本电子书，《Debugger101：go调试器开发内幕》。\n欢迎阅读，如您在阅读过程中遇到错误、疏漏、建议，不要犹豫，请给我提issue。\n"}),a.add({id:299,href:"/tags/dwarf/",title:"dwarf",description:"",content:""}),a.add({id:300,href:"/books/gorpc101/",title:"GoRPC101: 微服务框架开发内幕",description:"如今微服务架构大行其道，微服务框架也层出不穷，如grpc、springcloud、vert.x、ballerina，等等，这也反映出技术团队对开发效率、运营质量的不断探索与追求。合格的工程师要熟练运用框架，有追求的工程师则应掌握更全面的技能，能对框架进行定制化开发。",content:"如今微服务架构大行其道，微服务框架也层出不穷，如grpc、springcloud、vert.x、ballerina，等等，这也反映出技术团队对开发效率、运营质量的不断探索与追求。合格的工程师要熟练运用框架，有追求的工程师则应掌握更全面的技能，能对框架进行定制化开发。\n 由于本内容涉及到大量的设计实现、系统原理、性能调优、研发流程、工程素养、社区维护等等诸多内容，几篇博文实在难以介绍清楚。为了保证内容的完整性，让读者能够感受到笔者微服务框架开发工作中的真实例程，还是决定单独写一本电子书，《GoRPC101：微服务框架开发内幕》。\n欢迎阅读，如果您在阅读过程中发现有错误、疏漏、建议，不要很犹豫，请给我提issue。\n"}),a.add({id:301,href:"/journey/",title:"Journey",description:"journey.",content:""}),a.add({id:302,href:"/books/libmill/",title:"libmill: go风格协程库设计实现",description:"我们只想要一个协程化的开发能力以及基于CSP的数据共享，难道我们就需要一门新的语言，比如golang？有很多开发人员曾经提出类似的质疑，笔者刚接触go时也抱着类似的想法。那么不妨思考下如果用c/c++的话，如果要实现上述功能，我们应该如何实现呢？ZeroMQ之父Martin Sustrik就用1w多行代码实现了一个非常优雅的go风格协程库，不妨来一起学习下。",content:"我们只想要一个协程化的开发能力以及基于CSP的数据共享，难道我们就需要一门新的语言，比如golang？有很多开发人员曾经提出类似的质疑，笔者刚接触go时也抱着类似的想法。那么不妨思考下如果用c/c++的话，如果要实现上述功能，应该如何实现呢？\n ZeroMQ之父Martin Sustrik就用1w多行代码实现了一个非常优雅的go风格协程库，不妨来一起学习下。\n本内容涉及大量的系统基础知识、设计实现细节，为了保证知识点的系统性，单独写了一本电子书，《libmill：go风格协程库设计实现》。\n欢迎阅读，如果您在阅读过程中发现有错误、疏漏、建议，不要犹豫，请给我提issue。\n"}),a.add({id:303,href:"/books/",title:"My Books",description:"My Books.",content:""}),a.add({id:304,href:"/",title:"欢迎来到 Kn's Space",description:"好记性不如烂笔头，学习、实践、总结，塑造更好的自己",content:'$\u0026gt; Keep! 日出之时，再行万里! 🎶\n Your browser does not support the audio element.\n  var player = document.getElementById("music-player"); player.volume = 0.1;  -- '}),a.add({id:305,href:"/blog/2020-09-28-go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-go%E5%91%BD%E4%BB%A4/",title:"go源码剖析 - go命令",description:"1. 本文简介 # 首先我们看下go命令行有哪些功能，运行go help可以查看go命令的详细帮助信息，go命令有很多子命令，每个子命令有特定的功能。go命令功能之丰富涵盖了源文件编译、汇编、连接、反汇编、逃逸分析、代码生成、模块解析等等非常系统性的功能，了解go命令的实现将有助于系统性掌握整个go编译工具链。本文介绍下go命令的详细功能及大致实现，供后续参考。\n2. go子命令列表 # go支持的子命令列表如下，下面我们逐一来简单说下。\n bug, start a bug report build, compile packages and dependencies clean, remove object files and cached files doc, show documentation for package or symbol env, print Go environment information fix, update packages to use new APIs fmt, gofmt (reformat) package sources generate, generate Go files by processing source get, add dependencies to current module and install them install, compile and install packages and dependencies list, list packages or modules mod, module maintenance run, compile and run Go program test, test packages tool, run specified go tool version, print Go version vet, report likely mistakes in packages  3.",content:"1. 本文简介 # 首先我们看下go命令行有哪些功能，运行go help可以查看go命令的详细帮助信息，go命令有很多子命令，每个子命令有特定的功能。go命令功能之丰富涵盖了源文件编译、汇编、连接、反汇编、逃逸分析、代码生成、模块解析等等非常系统性的功能，了解go命令的实现将有助于系统性掌握整个go编译工具链。本文介绍下go命令的详细功能及大致实现，供后续参考。\n2. go子命令列表 # go支持的子命令列表如下，下面我们逐一来简单说下。\n bug, start a bug report build, compile packages and dependencies clean, remove object files and cached files doc, show documentation for package or symbol env, print Go environment information fix, update packages to use new APIs fmt, gofmt (reformat) package sources generate, generate Go files by processing source get, add dependencies to current module and install them install, compile and install packages and dependencies list, list packages or modules mod, module maintenance run, compile and run Go program test, test packages tool, run specified go tool version, print Go version vet, report likely mistakes in packages  3. go subcmds # go bug # go bug，用于快速创建bug report。\n作为开源项目的维护人员，非常希望开发人员“会”提问题！为什么这么说呢，就是因为如果不会提问题、问问题，沟通成本就会非常高，这对于开源项目维护人员来说，时间上是个极大的浪费。\n在腾讯我也参与维护了好几个比较大型的开源项目，经常受到一些同学的问题，很多时候我真的感谢求学阶段长时间泡stackoverflow的经历，stackoverflow上教会了我怎么提问题，这个在我后面学习、沟通、检索、开源协同中起到了很重要的作用。\n为了降低沟通成本，go bug内部定义了一个issue模板（其实github也支持定义模板），包括了几个部分：问题简述、go版本、go env信息、执行的操作、期望的结果、实际的结果。这里呢，为了保护go issuer的体验，go bug会自动获取go环境信息，填充到issue模板中，这里的内容将作为issue的body部分。\n接下来会判断go issuer当前系统信息，并决定如何打开web浏览器，浏览器打开一个issue创建页面，通过GET参数填充issue的body，一个简单的issue基本信息就填充完成了。go issuer只需要填充下标题、问题简述、执行操作、期望结果、实际结果就创建完成了。\ngo build # go build可以细分为如下几个操作：\n compile, src/cmd/compile/main.go asm, \u0026hellip; link, src/cmd/link/main.go ld, \u0026hellip;  go build过程分析，假定待编译的工程开启了go module：\n  初始化操作\n modload.Init(), 进行go module相关的初始化，如检查环境变量GO111MODULE决定是否启用go module、定位go.mod所在的目录、设置git等； instrumentInit()，代码织入初始化，什么是代码织入呢，比如go build -race对代码中的竞态条件进行检查，需要在原程序中加入一些特殊代码来统计对某些数据结构的并发读写操作，这就称之为代码织入，熟悉Java字节码织入的话应该很容易看懂这里的概念，比如Kilim、Quasa等字节码织入。go build -msan应该是启用与内存清理相关的操作。这里也就是检查一下flag的正确性（如-race、-msan不能同时指定），检查一下平台是否支持race检查、msan检查； buildModeInit()，构建模式初始化，包括决定是构建一个共享库，还是一个可执行程序，还是其他等，也会检查平台是否支持、是否开启go module等；    builder初始化: builder保存着一次构建过程中的全局状态，不保存package的全局状态，不同package的编译是并发进行的，builder是单例共享的\n 初始化打印函数 初始化action cache 初始化mkdir cache 初始化tool id cache 初始化build id cache 初始化临时构建目录 检查GOOS、GOARCH是否合法 检查指定的tag列表    加载要构建的路径对应的package信息\n 加载路径对应的pacakge 移除纯测试用的package    创建要执行的actions：一个action表示action图中的一个单独的动作\n 创建一个go build的action（根节点），我猜这个action是一个表示全局构建完成的action； 针对各个要构建的package创建一个auto action，都是前一步go build这个action的前置依赖； 这里的actions构成了一个dag，也称之为action graph；    b.Do()开始执行构建\n 从根节点执行扫描，按照深度优先搜索、后序遍历的方式进行遍历，正好符合前置（子节点）执行完成后，后置才可以执行的问题； 根据查看选项是否指定，决定是否输出action graph； action dag执行的时候，相当于先执行最底层的叶子节点，执行完再执行上一层的父节点\u0026hellip;以此类推，直到到达根节点； 根据action.Deps构建反向的触发关系，如a.Deps=b，那么b.Triggers=a，方便b执行完后驱动a执行； action.pending表示当前该action剩下的等待执行完成的前置依赖的数量，如果pending为0，表示无依赖或者依赖都已执行完成，当前action变为就绪状态，转移到b.ready这中，b.readySema信号量也ok了； 启动多个goroutine执行并发的构建任务，当b.readySema就绪后，从b.ready栈中取出要处理的action去执行，记录构建的时间之类的，应该是为了方便统计编译耗时信息； 这里要注意action.Func，默认是挺过(*Builder).build来构建的，层层展开，其实看得就是gc.go的gc方法，这个方法最终调用的其实是go tool compile来完成编译过程； go tool compile的代码位于src/cmd/compile/main.go下；    go tool compile逻辑实现：\n 我擦，一开始各种a#239?fafx8\u0026mdash; 构建语法树，不是用的go/ast包，而是syntax包，据说这是因为之前是用c写的，即便后面用go重写了，但基本上是翻译了一遍，工程结构没再改； 基于语法树进行语义分析，如检查类型是否正确，typecheck(node,...)，这里又分为几个步骤：  const、type、以及func的类型和名称的检查； 变量赋值检查； 函数体类型检查，检查返回值类型？ 类型检查完之后，检查map类型的keys   检查如何捕获closed的变量，需要在逃逸分析之前进行； 内联检查； 逃逸分析； 将闭包中对外部变量的引用，根据使用方式转换为按值捕获、按引用捕获的对应形式； 编译顶层函数，详见函数：funccompile(node)，这个函数就是根据函数定义（参数列表、返回值）以及语句，生成一系列的操作（操作码、操作数等）; \u0026hellip;. 写对象数据到磁盘，object data，翻译是“对象数据”，不是“目标文件数据”。详见函数dumpdata()，貌似是在函数compileSSA()中实现的，还要确认具体逻辑；  哇，好复杂!\ngo clean # 我们在编译构建的过程中，一般都会生成一些临时文件，比如.o文件，如果是使用Makefile管理工程构建的时候一般会定义个PHONY Target clean，通过make clean来清理临时文件、目标文件、程序等，MVN构建也会定义clean这样的target，go也不例外。\ngo build，编译输出可执行程序，go install还会将可执行程序安装到GOBIN或者GOPATH/bin，那现在要清理的话，go clean会清理当前module下的编译产物，go clean -i还会把安装到GOBIN或者GOPATH/bin下安装的程序给清理掉，另外go modules之间也有依赖关系，go clean -r还可以递归地清理依赖产物。\n举个例子，假如现在有个工程目录叫hello，那么在该工程目录下执行go clean，将清理目录下的下述文件：hello, hello.exe, hello.test, hello.test.exe, main, main.exe, main.test, main.test.exe。那假如hello目录下go.mod定义的module是a.b.c呢？会清理a.b.c, a.b.c.exe, a.b.c.test, a.b.c.test.exe吗？不会！但是go clean -i会从GOBIN或GOPATH/bin下清理这些文件。为啥？目前go clean就是这么实现的。\ngo clean之前实现的有bug，我稍微修改了下，实现了清理${module}, ${module}.exe的功能。\ngo doc # go doc 可以用来显示指定package下的类型、函数、方法及其注释信息，其用法比较多，如go doc、go doc pkg.symbol.fieldOrMethod、go doc pkg.Function等等。\n比如我们运行go doc os.Signal，会显示如下信息：\npackage os // import \u0026quot;os\u0026quot; type Signal interface { String() string Signal() // to distinguish from other Stringers } A Signal represents an operating system signal. The usual underlying implementation is operating system-dependent: on Unix it is syscall.Signal. var Interrupt Signal = syscall.SIGINT ...  从这里我们可以看到整个接口的定义，及其godoc注释信息，那么不禁要问，go doc 是如何准确找到这个符号os.Signal定义的呢？\n如果之前有了解过go/ast的用法、用途之后，应该就不难理解了。我还写过一篇讲微服务代码逻辑可视化的文章，也是使用了go/ast。\ngo doc的逻辑其实很简单，它首先会将os.Signal split一下，发现是os这个package，然后是Signal这个符号，然后它就会根据build package提供的信息来定位到os对应的目录，然后通过parser.ParseDir(...)来对目录下go文件进行语法分析。分析完之后就将得到AST，然后再基于AST去查找符号Symbol的定义，比如这里是个类型定义，找到AST中对应的节点之后，再提取出注释信息。最后将这些信息格式化输出到stdout。\ngo doc大致就是这样实现的。\ngo env # go env 命令用来查看、设置、取消设置go相关的一些环境变量。\n我们知道go env会显示出一个环境变量列表，这里面这些环境变量名称都是go envCmd里面预定义好的，比如要设置一个不相干的变量名go env -w xxx是会报错的。\ngo env 列出的环境变量一般都有一个默认值，如GOSUMDB=sum.golang.org，但是我们有时候希望对齐进行调整，那么可以通过go env -w GOSUMDB=off来进行设置，如果要取消设置恢复到原来的默认设置，则可以执行go env -u GOSUMDB。\n那这里不禁要问，用户手动设置的环境变量存储在哪里呢？其实是存储在环境变量GOENV对应的文件中，macOS下为/Users/zhangjie/Library/Application Support/go，linux下为~/.config/go/env，其实就是os.UserConfigDir()+/go/env路径下。当我们设置、取消设置的时候，会更新文件中的数据。\ngo env大致就是这么工作的。\ngo fix # 一门快速演进中的编程语言也会面临一些调整的时候，如果发生了变化，比如将golang.org/x/tools/net/context内容转移到标准库context中，可能已经存在一些存量代码了，或者说开发者已经习惯了使用老的import的包路径了，那怎么办呢？想让开发者付出最小的迁移成本而转到使用最新的标准库context上来。go fix就是干这个事情的。\nfix命令执行的时候会检查当前支持那些修复操作，每一个修复操作都指定了要搜索的代码，以及要替换成的代码，比如上面提及的context包导入路径的问题。fix命令会首先解析源文件得到抽象语法树AST，然后基于对AST的操作，搜索出可以修复的问题代码，然后将其替换成对应的新代码，然后再将AST转换成代码输出到源文件中。\n这大概就是go fix (go tool fix) 的一个执行过程，$GOROOT/pkg/tool/$GOOS_$GOARCH/下保存了go tool对应的一些工具，如fix，vet等，运行go vet, go fix就会最终转换成执行上述路径下的vet、fix命令。go fix的入口在$GOROOT/src/cmd/go/fix/fix.go，实际调用的是go tool fix，其入口在$GOROOT/src/cmd/fix/main.go。\nps: go fix的内部实现，是基于go/ast实现，通过对源码进行语法分析构建ast，通过对ast进行查找、修改，完成对代码的调整，最后再将ast转换为源码输出。\ngo fmt # go fmt实际上是调用的命令gofmt，它其实也是利用了package go/ast完成对特定源文件或者目录下所有源文件的语法分析，构建出语法树，然后基于对语法树的理解和操作，来最终完成对代码的格式化。\ngo fmt在使用的时候，有几个地方比较方便，选项-d可以将格式化后的代码打印到标准输出，-w则可以直接将文件写入到文件，-s则支持对代码进行简化。\n这里也没有特别多要强调的，继续看其他子命令的实现逻辑。\ngo generate # go提供了代码生成能力，在go源文件中通过//go:generate ....定义的注释，其实是一种特殊的指令，它告诉go工具可以提取出这些指令来生成代码。当然理论上通过go:generate可以执行任何指令，但是从go工具设计者的初衷来看，它主要是为了用来作为一种包开发者的工具，用来生成或者更新特定源文件的。\n比如一个代码生成工具可以通过代码模板来生成一个完整的服务工程，代码模板里面就可以包含这样的//go:generate mockgen ...指令来生成mock测试相关的桩代码。\ngo generate实现的逻辑比较简单，它就是遍历源文件，然后去逐行读取每个源文件，检查读取行是不是匹配//go:generate ...，是的话则解析出命令来，然后执行对应的命令。\ngo get # go get用来下载对应模块并安装，同时将该模块添加到当前模块的依赖文件go.mod中。当然go get也有很多一些常用选项，如-u用来更新模块等。这里可以通过go help get来了解详细的信息。\ngo install # go install，它主要是下载对应模块，并完成程序的构建、安装逻辑。需要注意的是，这里在go1.13前后发生了一点变化。\n在go1.13之前的版本中，是要通过go install来安装的，go1.13及之后的版本go get会自动下载、并构建、安装，go install只能安装本地已经下载下来的模块。\ngo list # go list列出packages或依赖，具体如何实现的呢？这个命令怎么实现的不是很感兴趣，先跳过了。\ngo mod # go mod主要是用来对依赖进行管理，常用操作包括go mod init, go mod tidy，go mod vendor等等吧。\n这个有时间再看，当前不是很感兴趣，先跳过了。\ngo run # go run一般用来快速执行一个go文件，这个go文件必须是package main下的，并且包含一个方法func main(){}。go run现在也支持指定一个package main的路径名，要求是一样的，就是这个目录下的go源文件必须是package main，并且有一个源文件中包含func main(){}的定义。\ngo run其实也需要进行编译、链接过程，只不过这个过程都在一个临时目录中完成，结果产物没有输出到源码目录或者命令执行时的工作目录下。并且go run执行完会后，会自动清理掉这些临时目录。执行完成前是怎么清理的呢？它这里模拟了c里面的函数atexit()来注册退出时要执行的函数，go run进程最终在调用os.Exit()之前会先将之前注册过的处理函数执行一遍，跟c库函数atexit的逻辑类似。这里注册的处理函数就包括清理go run触发编译、链接时生成的临时目录。\ngo test # go test主要是用来执行单元测试用的，它还比较牛，不仅仅可以用来支持\u0026quot;test.go\u0026quot;文件的单元测试，还支持像\u0026quot;cmd/go/testdata/scripts/\u0026ldquo;下的通过txt文件+自定义指令来实现的测试。这里还是有点创新点的。\n这里先说下\u0026quot;test.go\u0026quot;文件的单元测试是如何实现的吧。实际上是这样执行的，它会为当前package下的\u0026quot;test.go\u0026quot;文件，生成一个新的go文件，这个go文件的内容是根据预先定义好的go测试模板文件生成的，内部会通过-test.run选项来选择我们自定义的TestXXX(t)来执行。\n当然go test也支持覆盖率测试等等的操作，这个覆盖率测试实际上也简单，其实是把源文件重写了，每一行语句都对应了一个计数器，执行语句之后，紧跟着一条增加计数器的操作，最后测试程序跑完，检查所有语句的计数器就可以统计出覆盖率信息。\n\u0026hellip;\n其他的，当前也不是很关心了。\ngo tool # go这个命令行工具是一个集大成者，它内部其实也是调用了一些其他的工具的，如通过go fmt或go tool fmt来调用命令gofmt，还有一些其他的工具，这些工具可以在如下路径中找到：$GOROOT/pkg/tool/$GOOS_$GOARCH。\n这里的工具有很多，我在后面的文章中会有选择的进行介绍。\ngo version # go version就是打印当前go程序的版本信息，这个信息是在go编译构建期间由工具go tool dist生成的，详见runtime/sys/zversion.go。\n还有一种常见的做法，是设置好一个包级别的变量，然后通过go build -ldflags=\u0026quot;-X 'pkg.Varable=value'\u0026quot;，这也是一种办法。\ngo vet # go vet用来报道packages中可能的错误，之前有了解过并发map读写的问题，可以通过go vet检查出来，它是怎么检查的呢？它还能检查出什么其他的错误呢？\ngo vet默认使用的vet工具是go自带的vet工具，也可以通过go vet -vettool=$prog替换成自定义的vet工具。OK，现在我们来看一下go自带的vet分析工具都支持分析哪些类型的错误，以及怎么实现的。\ngo自带的vet工具，其实现位于：src/cmd/vet/main.go，从源码中不难看出，vet支持对如下类型的错误进行检查：\n asmdecl: reports mismatches between assembly files and Go declarations assign: detects useless assignments atomic: checks for common mistakes using the sync/atomic package bools: detects common mistakes involving boolean operators buildtag: check that +build tags are well-formed and correctly located cgocall: detect some violations of the cgo pointer passing rules composite: check for unkeyed composite literals copylock: check for locks erroneously passed by value errorsas: report passing non-pointer or non-error values to errors.As httpresponse: check for mistakes using HTTP response ifaceassert: detect impossible interface-to-interface type assertions loopclosure: check references to loop variables from within nested functions lostcancel: check cancel func returned by context.WithCancel is called nilfunc: check for useless comparisons between functions and nil printf: check consistency of Printf format strings and arguments shift: check for shifts that equal or exceed the width of the integer stdmethods: check signature of methods of well-known interfaces stringintconv: check for string(int) conversions structtag: check that struct field tags conform to reflect.StructTag.Get tests: check for common mistaken usages of tests and examples unmarshal: report passing non-pointer or non-interface values to unmarshal unreachable: check for unreachable code unsafeptr: check for invalid conversions of uintptr to unsafe.Pointer unusedresult: check for unused results of calls to some functions  如何实现的呢，单独查看各个analyzer的实现就可以了，举例copylock是基于go/ast语法分析来检测出来的。\n4. 总结 # "}),a.add({id:306,href:"/tags/toolchain/",title:"toolchain",description:"",content:""}),a.add({id:307,href:"/blog/2020-09-20-%E5%AE%B6%E4%BA%BA%E7%94%9F%E6%B4%BB%E6%AF%94%E5%B7%A5%E4%BD%9C%E9%87%8D%E8%A6%81/",title:"家人\u0026生活，比工作重要",description:"为什么工作不开心 # 2020上半年绩效考评出来了，Outerstanding，5星好评，技术通道晋升答辩结果也出来了，T10，算是同事们对自己工作的认可吧，对我自己来说也是个好事，尽管我并没有感觉多么开心。老婆说，虽然你没觉得多么开心，但是如果没过的话一定会觉得不开心……听着很有道理。\n这个5星的考核，我也没什么好开心的，因为业务团队这边一开始给的是4星，后面呢，因为在中台中的贡献比较突出，bg层面有绩效的加成，所以从4星提到了5星。leader告诉我这个好消息后，我并没有觉得开心或者不开心。我做的工作就摆在这里，为什么不是自己业务团队给我考核5星，反而是技术运营部反馈的bg层面的中台贡献，让我的绩效从4星提到了5星？\n年初3月份晋升T10没通过，原因一堆有的没的评语，其实这次评级在内容层面也并没有特别大的变化，只是补充了些业务数据、贡献获奖情况，PPT讲的时候微调了下目录结构，不过基本上没按流程讲下来，评委全程挑战，最后通过了。和上次答辩相比，答辩内容比上次进步了哪些呢，内容组织的更容易被听众接受了，列了些业务对比数据、系统未来规划，列了些获奖数据，上次评委挑战我要控制变量、给数据，哥我是在做工程，不是在做论文实验数据，没有数据就不能判断出我的方案是否可行？看不到我的贡献？评委的专业能力体现在哪呢？\n\u0026hellip;\n所以我纠结的问题是什么呢？自己的工作没有被看见。可能在向上管理上我没有花心思去做，评审时也没有花心思去展示。我还是倾向于对事情本身负责，对这种考核、评价体系，我是不很乐于去融入的。就如同一些评委提到现在评审存在很多缺陷一样，我也不想去融入，并不是不能。\nSo，我还是不开心，因为我无法影响更无法控制整个评价考核体系，我必须做出一些改变才可以去掉这些不开心的东西。再接再厉，但是也确实需要考虑“选择”的重要性，我不能一直因为欣赏个别领导而一直在没有前景的业务线耗着，我还想做些其他的，也需要进一步成长，也需要养家，必须更好地平衡工作和生活。\n旅行是消愁的良药 # 这几天，刚好中心有些小伙伴要外出团建，趁这个机会，我也想休息下，请了几天假，去看望下多年未见的老婆家人，也顺便调整下自己的情绪。这次一行，让我感觉，家人\u0026amp;生活，远远比工作重要。\n工作再忙再烦，也不能将这些负面信息带入到自己家庭、家人、生活中，工作就是工作，生活就是生活，工作就是为了生活，而不能将生活看做工作的附属品。不工作怎么生活，不加班怎么买房买车……竞争奋斗是一种成长方式，但是也不是成长的终点，直线虽然路径最短，但是并不定速度最快。大多数人走的路，肯定没什么新意，你没必要踩着别人脚印重走一遍，重新换条路走避开人流说不定能有突破。\n这几天，我看到各种各样工作的人，开着哈雷送外卖的，买土豆条的，打扫公共卫生的，商场导售员，政务工作人员，保安，街头卖唱的，景区卖票的，农家种地的，……他们似乎并没有因为职业问题而不开心，也应该不会有很多人因为自己不是开发人员而不开心，就好比我并没有因为自己不是一个设计师而后悔一样。我们羡慕别人并不是因为他的职业，而是因为他的待遇。\n羡慕什么样的待遇呢？简言之，我认为只有两个维度，时间和金钱。我们总是在做选择、权衡、取舍。工作时间越长，收入也更多些，反之就少些。有时候我们觉得自己时间可以多投入以换取金钱，所以我们加班，有时我们累了宁可想挣点钱已避免别人压榨自己的时间，于是我们就开始提前下班，或者休假以避免自己工作时疲倦消耗更多时间。\n看到没，我们并没有第一时间将健康摆在第一位，它几乎总是时间和金钱相持不下或者一方优势明显时才会想到的一个参考因素。不过能想到总比想不到好。我就经常没有考虑健康。\n这是自己对自己极端不负责任的行为，也是对自己的家庭不负责任。感谢这次“旅行”教会了我这么多。\n接下来做什么呢 # 要做的事情，在自己脑海里已经规划的差不多了，最近思考着思考着更坚定了自己的想法。还是要按照自己预先设定的目标去达成，我相信自己。\nps: 在我写完本文第二天，得知一个惊人的消息，一个大学同学诊断得了胶质瘤，马上两个孩子的爸爸了，结果遭此不幸。疾病并非离我们很远，努力奋斗的同时，也要注意保护好身体。",content:"为什么工作不开心 # 2020上半年绩效考评出来了，Outerstanding，5星好评，技术通道晋升答辩结果也出来了，T10，算是同事们对自己工作的认可吧，对我自己来说也是个好事，尽管我并没有感觉多么开心。老婆说，虽然你没觉得多么开心，但是如果没过的话一定会觉得不开心……听着很有道理。\n这个5星的考核，我也没什么好开心的，因为业务团队这边一开始给的是4星，后面呢，因为在中台中的贡献比较突出，bg层面有绩效的加成，所以从4星提到了5星。leader告诉我这个好消息后，我并没有觉得开心或者不开心。我做的工作就摆在这里，为什么不是自己业务团队给我考核5星，反而是技术运营部反馈的bg层面的中台贡献，让我的绩效从4星提到了5星？\n年初3月份晋升T10没通过，原因一堆有的没的评语，其实这次评级在内容层面也并没有特别大的变化，只是补充了些业务数据、贡献获奖情况，PPT讲的时候微调了下目录结构，不过基本上没按流程讲下来，评委全程挑战，最后通过了。和上次答辩相比，答辩内容比上次进步了哪些呢，内容组织的更容易被听众接受了，列了些业务对比数据、系统未来规划，列了些获奖数据，上次评委挑战我要控制变量、给数据，哥我是在做工程，不是在做论文实验数据，没有数据就不能判断出我的方案是否可行？看不到我的贡献？评委的专业能力体现在哪呢？\n\u0026hellip;\n所以我纠结的问题是什么呢？自己的工作没有被看见。可能在向上管理上我没有花心思去做，评审时也没有花心思去展示。我还是倾向于对事情本身负责，对这种考核、评价体系，我是不很乐于去融入的。就如同一些评委提到现在评审存在很多缺陷一样，我也不想去融入，并不是不能。\nSo，我还是不开心，因为我无法影响更无法控制整个评价考核体系，我必须做出一些改变才可以去掉这些不开心的东西。再接再厉，但是也确实需要考虑“选择”的重要性，我不能一直因为欣赏个别领导而一直在没有前景的业务线耗着，我还想做些其他的，也需要进一步成长，也需要养家，必须更好地平衡工作和生活。\n旅行是消愁的良药 # 这几天，刚好中心有些小伙伴要外出团建，趁这个机会，我也想休息下，请了几天假，去看望下多年未见的老婆家人，也顺便调整下自己的情绪。这次一行，让我感觉，家人\u0026amp;生活，远远比工作重要。\n工作再忙再烦，也不能将这些负面信息带入到自己家庭、家人、生活中，工作就是工作，生活就是生活，工作就是为了生活，而不能将生活看做工作的附属品。不工作怎么生活，不加班怎么买房买车……竞争奋斗是一种成长方式，但是也不是成长的终点，直线虽然路径最短，但是并不定速度最快。大多数人走的路，肯定没什么新意，你没必要踩着别人脚印重走一遍，重新换条路走避开人流说不定能有突破。\n这几天，我看到各种各样工作的人，开着哈雷送外卖的，买土豆条的，打扫公共卫生的，商场导售员，政务工作人员，保安，街头卖唱的，景区卖票的，农家种地的，……他们似乎并没有因为职业问题而不开心，也应该不会有很多人因为自己不是开发人员而不开心，就好比我并没有因为自己不是一个设计师而后悔一样。我们羡慕别人并不是因为他的职业，而是因为他的待遇。\n羡慕什么样的待遇呢？简言之，我认为只有两个维度，时间和金钱。我们总是在做选择、权衡、取舍。工作时间越长，收入也更多些，反之就少些。有时候我们觉得自己时间可以多投入以换取金钱，所以我们加班，有时我们累了宁可想挣点钱已避免别人压榨自己的时间，于是我们就开始提前下班，或者休假以避免自己工作时疲倦消耗更多时间。\n看到没，我们并没有第一时间将健康摆在第一位，它几乎总是时间和金钱相持不下或者一方优势明显时才会想到的一个参考因素。不过能想到总比想不到好。我就经常没有考虑健康。\n这是自己对自己极端不负责任的行为，也是对自己的家庭不负责任。感谢这次“旅行”教会了我这么多。\n接下来做什么呢 # 要做的事情，在自己脑海里已经规划的差不多了，最近思考着思考着更坚定了自己的想法。还是要按照自己预先设定的目标去达成，我相信自己。\nps: 在我写完本文第二天，得知一个惊人的消息，一个大学同学诊断得了胶质瘤，马上两个孩子的爸爸了，结果遭此不幸。疾病并非离我们很远，努力奋斗的同时，也要注意保护好身体。\n"}),a.add({id:308,href:"/tags/%E5%B9%B3%E8%A1%A1/",title:"平衡",description:"",content:""}),a.add({id:309,href:"/tags/%E7%94%9F%E6%B4%BB/",title:"生活",description:"",content:""}),a.add({id:310,href:"/tags/disassembler/",title:"disassembler",description:"",content:""}),a.add({id:311,href:"/tags/gapstone/",title:"gapstone",description:"",content:""}),a.add({id:312,href:"/blog/2020-09-06-%E5%89%96%E6%9E%90go%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/",title:"剖析go二进制文件",description:"为什么要反汇编？ # 这篇文章介绍下反汇编的基本概念，以及如何用go语言写一个简单的反汇编器。本文的目标就是为了尽可能描述下反汇编的的相关概念，以及让读者朋友们了解go二进制程序内部大致是什么样的。\n汇编代码不会撒谎，阅读汇编代码能够让我们更细致地了解处理器执行的指令到底做了什么。这也是为什么反汇编很重要的原因之一。如果我们有一个二进制程序，并且怀疑它有一些恶意的行为，通过反汇编来研究它就是一种很好的途径。再或者，如果你分析代码难以发现性能瓶颈，那么反汇编也是一种可以简化分析的途径。\n如果你担心能不能阅读x86_64汇编代码的问题，其实不用担心，我们大部分都不能很顺畅地阅读。你也没有必要为了搞懂这篇文章去阅读其他任何的汇编代码，不过如果有汇编基础的话确实会感觉更有意思点。这里有一篇介绍汇编基础的文章 A fundamental introduction to x86 assembly programming。\n什么是反汇编？ # 那么，什么是反汇编呢？\n反汇编，其实是将已经编译好的二进制程序，重新转换为汇编代码的过程。为了解释清楚，我们先考虑下从源代码编译构建的过程：\n汇编代码，其实是一种介于源代码、机器指令之间的中间代码表示，虽然大多数汇编指令是和机器指令对应的，但是也不绝对，比如go汇编就是一种跟机器指令没有明显对应关系的汇编形式。详细地可以参考go assembler设计对应的go blog一文。ok，言归正传。编译器首先将源代码转换为OS/架构特定的汇编代码，然后再通过汇编器将汇编代码转换为机器指令。从字面上就可以看出disassemble是assemble的一个逆向的过程，俗称反汇编。\n庆幸地是，go语言有一个相对标准、完整的工具链，汇编、反汇编都会比较方便。我们可以直接将源码转换成汇编代码来查看，例如通过运行命令 go build -gcflags -S program.go。如果我们已经有了一个编译构建好的二进制程序，这个时候想查看汇编代码的话，就得通过反汇编，可以运行命令 go tool objdump binaryFile。\n如果想了解如何实现汇编、反汇编的话，这篇文章其实已经可以结束了。但是如果来解释下如何从0到1构建一个反汇编器的话，还是有意思的。\n从0到1构建反汇编器？ # 首先，为了构建一个反汇编器，我们需要先知道二进制程序对应的目标机器架构包含的所有的机器指令。为了实现这个，我们可能要参考特定架构的手册来查阅到底有多少机器指令。如果对这个不熟悉，这个过程其实是比较困难的。其实，有很多种微处理器架构、汇编语法、指令集、编码模式，而且一直在变。光掌握这些不同机器架构包含的指令集就是一个很困难的事情，至于如何困难可以参考下这篇文章 how many x86_64 instructions are there anyway。\n庆幸地是，这些繁重的工作应被解决了，反汇编框架Capstone就是干这个事情的。Capstone其实已经是一个事实上的标准了，在各种反汇编工具中应用广泛。重新实现一个反汇编框架，其实没必要，这个过程只会是一个学习性的、枯燥的、重复的任务，我们不会介绍如何实现一个Capstone反汇编框架，只会介绍如何借助Capstone来实现反汇编的能力。在go语言中使用Capstone也简单，有一个针对go的实现gapstone。\n通过下面的代码我们可以初始化一个gapstone反汇编框架引擎，用它来执行后续的反汇编任务。\nengine, err := gapstone.New( gapstone.CS_ARCH_X86, gapstone.CS_MODE_64, ) if err != nil { log.Fatal(err) }  例如，我们可以将下面的原始指令数据传递给Capstone反汇编框架，然后该反汇编框架将会将这些原始指令数据转换为对应的x86_64下的指令。\n0x64 0x48 0x8B 0xC 0x25 0xF8 0xFF 0xFF 0xFF | mov rcx, qword ptr fs:[0xfffffffffffffff8]  把上面的操作放在一起，如下：",content:"为什么要反汇编？ # 这篇文章介绍下反汇编的基本概念，以及如何用go语言写一个简单的反汇编器。本文的目标就是为了尽可能描述下反汇编的的相关概念，以及让读者朋友们了解go二进制程序内部大致是什么样的。\n汇编代码不会撒谎，阅读汇编代码能够让我们更细致地了解处理器执行的指令到底做了什么。这也是为什么反汇编很重要的原因之一。如果我们有一个二进制程序，并且怀疑它有一些恶意的行为，通过反汇编来研究它就是一种很好的途径。再或者，如果你分析代码难以发现性能瓶颈，那么反汇编也是一种可以简化分析的途径。\n如果你担心能不能阅读x86_64汇编代码的问题，其实不用担心，我们大部分都不能很顺畅地阅读。你也没有必要为了搞懂这篇文章去阅读其他任何的汇编代码，不过如果有汇编基础的话确实会感觉更有意思点。这里有一篇介绍汇编基础的文章 A fundamental introduction to x86 assembly programming。\n什么是反汇编？ # 那么，什么是反汇编呢？\n反汇编，其实是将已经编译好的二进制程序，重新转换为汇编代码的过程。为了解释清楚，我们先考虑下从源代码编译构建的过程：\n汇编代码，其实是一种介于源代码、机器指令之间的中间代码表示，虽然大多数汇编指令是和机器指令对应的，但是也不绝对，比如go汇编就是一种跟机器指令没有明显对应关系的汇编形式。详细地可以参考go assembler设计对应的go blog一文。ok，言归正传。编译器首先将源代码转换为OS/架构特定的汇编代码，然后再通过汇编器将汇编代码转换为机器指令。从字面上就可以看出disassemble是assemble的一个逆向的过程，俗称反汇编。\n庆幸地是，go语言有一个相对标准、完整的工具链，汇编、反汇编都会比较方便。我们可以直接将源码转换成汇编代码来查看，例如通过运行命令 go build -gcflags -S program.go。如果我们已经有了一个编译构建好的二进制程序，这个时候想查看汇编代码的话，就得通过反汇编，可以运行命令 go tool objdump binaryFile。\n如果想了解如何实现汇编、反汇编的话，这篇文章其实已经可以结束了。但是如果来解释下如何从0到1构建一个反汇编器的话，还是有意思的。\n从0到1构建反汇编器？ # 首先，为了构建一个反汇编器，我们需要先知道二进制程序对应的目标机器架构包含的所有的机器指令。为了实现这个，我们可能要参考特定架构的手册来查阅到底有多少机器指令。如果对这个不熟悉，这个过程其实是比较困难的。其实，有很多种微处理器架构、汇编语法、指令集、编码模式，而且一直在变。光掌握这些不同机器架构包含的指令集就是一个很困难的事情，至于如何困难可以参考下这篇文章 how many x86_64 instructions are there anyway。\n庆幸地是，这些繁重的工作应被解决了，反汇编框架Capstone就是干这个事情的。Capstone其实已经是一个事实上的标准了，在各种反汇编工具中应用广泛。重新实现一个反汇编框架，其实没必要，这个过程只会是一个学习性的、枯燥的、重复的任务，我们不会介绍如何实现一个Capstone反汇编框架，只会介绍如何借助Capstone来实现反汇编的能力。在go语言中使用Capstone也简单，有一个针对go的实现gapstone。\n通过下面的代码我们可以初始化一个gapstone反汇编框架引擎，用它来执行后续的反汇编任务。\nengine, err := gapstone.New( gapstone.CS_ARCH_X86, gapstone.CS_MODE_64, ) if err != nil { log.Fatal(err) }  例如，我们可以将下面的原始指令数据传递给Capstone反汇编框架，然后该反汇编框架将会将这些原始指令数据转换为对应的x86_64下的指令。\n0x64 0x48 0x8B 0xC 0x25 0xF8 0xFF 0xFF 0xFF | mov rcx, qword ptr fs:[0xfffffffffffffff8]  把上面的操作放在一起，如下：\nfile: main.go\ninput := []byte{0x64, 0x48, 0x8B, 0xC, 0x25, 0xF8, 0xFF, 0xFF, 0xFF} instructions, err := engine.Disasm(input, 0, 0) if err != nil { log.Fatal(err) } for _, instruction := range instructions { fmt.Printf(\u0026quot;0x%x:\\t%s\\t\\t%s\\n\u0026quot;, instruction.Address, instruction.Mnemonic, instruction.OpStr) }  测试下：\n$ go run main.go 0x0:	mov	rcx, qword ptr fs:[0xfffffffffffffff8]  有了这个反汇编框架Capstone之后，要实现一个反汇编器，我们还有一个剩下的工作要做，就是从二进制程序中提取指令对应的原始数据，然后将其传给Capstone翻译引擎就可以了。\n当你在一个笔记本上编译一个go程序、默认输出是64位ELF格式（Executable Linkable Format）。ELF内部其实是被组织成了多个不同的节（section），每一个section都有不同的目的，如存储版本信息、程序元数据信息、可执行代码等等。ELF是被广泛采用的一个二进制程序标准，go语言标准库里面提供了一个 debug/elf package用来进行ELF文件数据的读写。ELF其实有点复杂，但是要实现反汇编的话其实我们只关心两个section就可以了。一个是符号表section（.symtab），一个是指令section （.text）。\n首先，我们先来看下术语symbol的定义，其实它指的是代码中任何有名的东西，如变量、函数、类型、常量等都是symbols。go编译器会编译每一个符号，并存储对符号表中符号的引用信息。go标准库 debug/elf 中提供了对ELF文件的读写能力，每一个符号都通过结构体 Symbol 来表示，它包括了符号的名字、地址、原始数据的多少等等吧。\n// A Symbol represents an entry in an ELF symbol table section. type Symbol struct { Name string Info byte Other byte Section SectionIndex Value uint64 Size uint64 }  现在，如果我们想快速提取ELF文件中的所有符号的话，我们就可以这么实现：\n// Open the ELF file elfFile, err := elf.Open(path) if err != nil { log.Fatalf(\u0026quot;error while opening ELF file %s: %+s\u0026quot;, path, err.Error()) } // Extract the symbol table symbolTable, err := elfFile.Symbols() if err != nil { log.Fatalf(\u0026quot;could not extract symbol table: %s\u0026quot;, err.Error()) } // Traverse through each symbol in the symbol table for _, symbol := range symbolTable { /* symbol.Info lets us tell if this symbol is a function that we want to disassemble symbol.Value gives us the offset from the start of the .text section symbol.Size lets us calculate the full address range of this symbol in the .text section */ }  从Symbol各个字段的名字命名上看并不是很清晰，符号对应的内存偏移量其实是存储在Value字段中的。通过这个偏移量，可以通过计算与.text section的偏移量的差值，我们可以计算出符号对应的指令数据在.text section中的起始索引。通过进一步的Size我们可以计算出包含的指令数据对应的字节数量。还有一个就是Info字段，这个字段起始是类型的意思，在go里面Info=byte(2)表示的是函数，Info=byte(18)表示的是方法。所以，如果想实现对函数、方法的反汇编的话，我们只处理这两种类型的就可以了。\n有了这些之后，我们就可以快速的再完善一下了：\n// extract the .text section textSection := elfFile.Section(\u0026quot;.text\u0026quot;) if textSection == nil { log.Fatal(\u0026quot;No text section\u0026quot;) } // extract the raw bytes from the .text section textSectionData, err := textSection.Data() if err != nil { log.Fatal(err) } // traverse through the symbol table for _, symbol := range symbolTable { // skip over any symbols that aren't functinons/methods if symbol.Info != byte(2) \u0026amp;\u0026amp; symbol.Info != byte(18) { continue } // skip over empty symbols if symbol.Size == 0 { continue } // calculate starting and ending index of the symbol within the text section symbolStartingIndex := symbol.Value - textSection.Addr symbolEndingIndex := symbolStartingIndex + symbol.Size // collect the bytes of the symbol symbolBytes := textSectionData[symbolStartingIndex:symbolEndingIndex] // disasemble the symbol instructions, err := engine.Disasm(symbolBytes, symbol.Value, 0) if err != nil { log.Fatalf(\u0026quot;could not disasemble symbol: %s\u0026quot;, err) } // print out each instruction that's part of this symbol fmt.Printf(\u0026quot;\\n\\nSYMBOL %s\\n\u0026quot;, symbol.Name) for _, ins := range instructions { fmt.Printf(\u0026quot;0x%x:\\t%s\\t\\t%s\\n\u0026quot;, ins.Address, ins.Mnemonic, ins.OpStr) } }  完整的实例代码，详见 full disassembler。实现一个简单的反汇编器，实际上只用了70~80行代码而已。下面是一个简单的运行实例。\n 注意: 在测试的时候，需要注意下capstone的版本、gapstaone的版本，不然测试的时候可能会出错。这里先暂时不详细写了，遇到问题可以去repo下查issue。\n参考内容 # 1.dissecting go binaries, https://www.grant.pizza/dissecting-go-binaries\n"}),a.add({id:313,href:"/tags/forkexec/",title:"forkexec",description:"",content:""}),a.add({id:314,href:"/blog/2020-08-28-go%E7%A8%8B%E5%BA%8F%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%83%AD%E9%87%8D%E5%90%AF/",title:"go程序如何实现热重启",description:"服务器重启、发布时，应该如何做到平滑重启呢？这个问题可能很多人都思考过，本文就来详细说说……特别是go程序中如何实现热重启。",content:"最近在优化公司框架trpc时发现了一个热重启相关的问题，优化之余也总结沉淀下，对go如何实现热重启这方面的内容做一个简单的梳理。\n1.什么是热重启？ # 热重启（Hot Restart），是一项保证服务可用性的手段。它允许服务重启期间，不中断已经建立的连接，老服务进程不再接受新连接请求，新连接请求将在新服务进程中受理。对于原服务进程中已经建立的连接，也可以将其设为读关闭，等待平滑处理完连接上的请求及连接空闲后再行退出。通过这种方式，可以保证已建立的连接不中断，连接上的事务（请求、处理、响应）可以正常完成，新的服务进程也可以正常接受连接、处理连接上的请求。当然，热重启期间进程平滑退出涉及到的不止是连接上的事务，也有消息服务、自定义事务需要关注。\n这是我理解的热重启的一个大致描述。热重启现在还有没有存在的必要？我的理解是看场景。\n以后台开发为例，假如运维平台有能力在服务升级、重启时自动踢掉流量，服务就绪后又自动加回流量，假如能够合理预估服务QPS、请求处理时长，那么只要配置一个合理的停止前等待时间，是可以达到类似热重启的效果的。这样的话，在后台服务里面支持热重启就显得没什么必要。但是，如果我们开发一个微服务框架，不能对将来的部署平台、环境做这种假设，也有可能使用方只是部署在一两台物理机上，也没有其他的负载均衡设施，但不希望因为重启受干扰，热重启就很有必要。当然还有一些更复杂、要求更苛刻的场景，也需要热重启的能力。\n热重启是比较重要的一项保证服务质量的手段，还是值得了解下的，这也是本文介绍的初衷。\n2.如何实现热重启？ # 如何实现热重启，这里其实不能一概而论，要结合实际的场景来看（比如服务编程模型、对可用性要求的高低等）。大致的实现思路，可以先抛一下。\n一般要实现热重启，大致要包括如下步骤：\n 首先，要让老进程，这里称之为父进程了，先要fork出一个子进程来代替它工作； 然后，子进程就绪之后，通知父进程，正常接受新连接请求、处理连接上收到的请求； 再然后，父进程处理完已建立连接上的请求后、连接空闲后，平滑退出。  听上去是挺简单的\u0026hellip;\n2.1.认识fork # 大家都知道fork() 系统调用，父进程调用fork会创建一个进程副本，代码中还可以通过fork返回值是否为0来区分是子进程还是父进程。\nint main(char **argv, int argc) { pid_t pid = fork(); if (pid == 0) { printf(\u0026quot;i am child process\u0026quot;); } else { printf(\u0026quot;i am parent process, i have a child process named %d\u0026quot;, pid); } }  可能有些开发人员不知道fork的实现原理，或者不知道fork返回值为什么在父子进程中不同，或者不知道如何做到父子进程中返回值不同……了解这些是要有点知识积累的。\n2.2.返回值 # 简单概括下，ABI定义了进行函数调用时的一些规范，如何传递参数，如何返回值等等，以x86为例，如果返回值是rax寄存器能够容的一般都是通过rax寄存器返回的。\n如果rax寄存器位宽无法容纳下的返回值呢？也简单，编译器会安插些指令来完成这些神秘的操作，具体是什么指令，就跟语言编译器实现相关了。\n c语言，可能会将返回值的地址，传递到rdi或其他寄存器，被调函数内部呢，通过多条指令将返回值写入rdi代指的内存区； c语言，也可能在被调函数内部，用多个寄存器rax,rdx\u0026hellip;一起暂存返回结果，函数返回时再将多个寄存器的值赋值到变量中； 也可能会像golang这样，通过栈内存来返回；  2.3.fork返回值 # fork系统调用的返回值，有点特殊，在父进程和子进程中，这个函数返回的值是不同的，如何做到的呢？\n联想下父进程调用fork的时候，操作系统内核需要干些什么呢？分配进程控制块、分配pid、分配内存空间……肯定有很多东西啦，这里注意下进程的硬件上下文信息，这些是非常重要的，在进程被调度算法选中进行调度时，是需要还原硬件上下文信息的。\nLinux fork的时候，会对子进程的硬件上下文进行一定的修改，我就是让你fork之后拿到的pid是0，怎么办呢？前面2.2节提过了，对于那些小整数，rax寄存器存下绰绰有余，fork返回时就是将操作系统分配的pid放到rax寄存器的。\n那，对于子进程而言，我只要在fork的时候将它的硬件上下文rax寄存器清0，然后等其他设置全ok后，再将其状态从不可中断等待状态修改为可运行状态，等其被调度器调度时，会先还原其硬件上下文信息，包括PC、rax等等，这样fork返回后，rax中值为0，最终赋值给pid的值就是0。\n因此，也就可以通过这种判断 “pid是否等于0” 的方式来区分当前进程是父进程还是子进程了。\n2.4.局限性 # 很多人清楚fork可以创建一个进程的副本并继续往下执行，可以根据fork返回值来执行不同的分支逻辑。如果进程是多线程的，在一个线程中调用fork会复制整个进程吗？\nfork只能创建调用该函数的线程的副本，进程中其他运行的线程，fork不予处理。这就意味着，对于多线程程序而言，寄希望于通过fork来创建一个完整进程副本是不可行的。\n前面我们也提到了，fork是实现热重启的重要一环，fork这里的这个局限性，就制约着不同服务编程模型下的热重启实现方式。所以我们说具体问题具体分析，不同编程模型下实际上可以采用不同的实现方式。\n3.单进程单线程模型 # 单进程单线程模型，可能很多人一听觉得它已经被淘汰了，生产环境中不能用，真的么？强如redis，不就是单线程。强调下并非单线程模型没用，ok，收回来，现在关注下单进程单线程模型如何实现热重启。\n单进程单线程，实现热重启会比较简单些:\n fork一下就可以创建出子进程， 子进程可以继承父进程中的资源，如已经打开的文件描述符，包括父进程的listenfd、connfd， 父进程，可以选择关闭listenfd，后续接受连接的任务就交给子进程来完成了， 父进程，甚至也可以关闭connfd，让子进程处理连接上的请求、回包等，也可以自身处理完已建立的连接上的请求； 父进程，在合适的时间点选择退出，子进程开始变成顶梁柱。  核心思想就是这些，但是具体到实现，就有多种方法：\n 可以选择fork的方式让子进程拿到原来的listenfd、connfd， 也可以选择unixdomain socket的方式父进程将listenfd、connfd发送给子进程。  有同学可能会想，我不传递这些fd行吗？\n 比如我开启了reuseport，父进程直接处理完已建立连接connfd上的请求之后关闭，子进程里reuseport.Listen直接创建新的listenfd。  也可以！但是有些问题必须要提前考虑到：\n reuseport虽然允许多个进程在同一个端口上多次listen，似乎满足了要求，但是要知道只要euid相同，都可以在这个端口上listen！是不安全的！ reuseport实现和平台有关系，在Linux平台上在同一个address+port上listen多次，多个listenfd底层可以共享同一个连接队列，内核可以实现负载均衡，但是在darwin平台上却不会！  当然这里提到的这些问题，在多线程模型下肯定也存在。\n4.单进程多线程模型 # 前面提到的问题，在多线程模型中也会出现：\n fork只能复制calling thread，not whole process！ reuseport多次在相同地址+端口listen得到的多个fd，不同平台有不同的表现，可能无法做到接受连接时的load banlance！ 非reuseport情况下，多次listen会失败！ 不传递fd，直接通过reuseport来重新listen得到listenfd，不安全，不同服务进程实例可能会在同一个端口上监听，gg！ 父进程平滑退出的逻辑，关闭listenfd，等待connfd上请求处理结束，关闭connfd，一切妥当后，父进程退出，子进程挑大梁！  5. 其他线程模型 # 其他线程都基本上避不开上述3、4的实现或者组合，对应问题相仿，不再赘述。\n6. go实现热重启：触发时机 # 需要选择一个时机来触发热重启，什么时候触发呢？操作系统提供了信号机制，允许进程做出一些自定义的信号处理。\n杀死一个进程，一般会通过kill -9发送SIGKILL信号给进程，这个信号不允许捕获，SIGABORT也不允许捕获，这样可以允许进程所有者或者高权限用户控制进程生死，达到更好的管理效果。\nkill也可以用来发送其他信号给进程，如发送SIGUSR1、SIGUSR2、SIGINT等等，进程中可以接收这些信号，并针对性的做出处理。这里可以选择SIGUSR1或者SIGUSR2来通知进程热重启。\ngo func() { ch := make(chan os.Signal, 1) signal.Notify(ch, os.SIGUSR2) \u0026lt;- ch //接下来就可以做热重启相关的逻辑了 ... }()  7. 如何判断热重启 # 那一个go程序重新启动之后，所有运行时状态信息都是新的，那如何区分自己是否是子进程呢，或者说我是否要执行热重启逻辑呢？父进程可以通过设置子进程初始化时的环境变量，比如加个HOT_RESTART=1。\n这就要求代码中在合适的地方要先检测环境变量HOT_RESTART是否为1，如果成立，那就执行热重启逻辑，否则就执行全新的启动逻辑。\n8. ForkExec # 假如当前进程收到SIGUSR2信号之后，希望执行热重启逻辑，那么好，需要先执行syscall.ForkExec(\u0026hellip;)来创建一个子进程，注意go不同于cc++，它本身就是依赖多线程来调度协程的，天然就是多线程程序，只不过是他没有使用NPTL线程库来创建，而是通过clone系统调用来创建。\n前面提过了，如果单纯fork的话，只能复制调用fork函数的线程，对于进程中的其他线程无能为力，所以对于go这种天然的多线程程序，必须从头来一遍，再exec一下。所以go标准库提供的函数是syscall.ForkExec而不是syscall.Fork。\n9. go实现热重启: 传递listenfd # go里面传递fd的方式，有这么几种，父进程fork子进程的时候传递fd，或者后面通过unix domain socket传递。需要注意的是，我们传递的实际上是file description，而非file descriptor。\n附上一张类unix系统下file descriptor、file description、inode三者之间的关系图：\nfd分配都是从小到大分配的，父进程中的fd为10，传递到子进程中之后有可能就不是10。那么传递到子进程的fd是否是可以预测的呢？可以预测，但是不建议。所以我提供了两种实现方式。\n9.1 ForkExec+ProcAttr{Files: []uintptr{}} # 要传递一个listenfd很简单，假如是类型net.Listener，那就通过tcpln := ln.(*net.TCPListener); file, _ := tcpln.File(); fd := file.FD() 来拿到listener底层file description对应的fd。\n需要注意的是，这里的fd并非底层的file description对应的初始fd，而是被dup2复制出来的一个fd（调用tcpln.File()的时候就已经分配了），这样底层file description引用计数就会+1。如果后面想通过ln.Close()关闭监听套接字的话，sorry，关不掉。这里需要显示的执行 file.Close() 将新创建的fd关掉，使对应的file description引用计数-1，保证Close的时候引用计数为0，才可以正常关闭。\n试想下，我们想实现热重启，是一定要等连接上接收的请求处理完才可以退出进程的，但是这期间父进程不能再接收新的连接请求，如果这里不能正常关闭listener，那我们这个目标就无法实现。所以这里对dup出来的fd的处理要慎重些，不要遗忘。\nOK，接下来说下syscall.ProcAttr{Files: []uintptr{}}，这里就是要传递的父进程中的fd，比如要传递stdin、stdout、stderr给子进程，就需要将这几个对应的fd塞进去os.Stdin.FD(), os.Stdout.FD(), os.Stderr.FD()，如果要想传递刚才的listenfd，就需要将上面的file.FD()返回的fd塞进去。\n子进程中接收到这些fd之后，在类unix系统下一般会按照从0、1、2、3这样递增的顺序来分配fd，那么传递过去的fd是可以预测的，假如除了stdin, stdout, stderr再传两个listenfd，那么可以预测这两个的fd应该是3，4。在类unix系统下一般都是这么处理的，子进程中就可以根据传递fd的数量（比如通过环境变量传递给子进程FD_NUM=2），来从3开始计算，哦，这两个fd应该是3，4。\n父子进程可以通过一个约定的顺序，来组织传递的listenfd的顺序，以方便子进程中按相同的约定进行处理，当然也可以通过fd重建listener之后来判断对应的监听network+address，以区分该listener对应的是哪一个逻辑service。都是可以的！\n需要注意的是，file.FD()返回的fd是非阻塞的，会影响到底层的file description，在重建listener先将其设为nonblock, syscall.SetNonBlock(fd)，然后file, _ := os.NewFile(fd); tcplistener := net.FileListener(file)，或者是 udpconn := net.PacketConn(file)，然后可以获取tcplistener、udpconn的监听地址，来关联其对应的逻辑service。\n 前面提到file.FD()会将底层的file description设置为阻塞模式，这里再补充下，net.FileListener(f), net.PacketConn(f)内部会调用newFileFd()-\u0026gt;dupSocket()，这几个函数内部会将fd对应的file description重新设置为非阻塞。父子进程中共享了listener对应的file description，所以不需要显示设置为非阻塞。\n 有些微服务框架是支持对服务进行逻辑service分组的，google pb规范中也支持多service定义，这个在腾讯的goneat、trpc框架中也是有支持的。\n当然了，这里我不会写一个完整的包含上述所有描述的demo给大家，这有点占篇幅，这里只贴一个精简版的实例，其他的读者感兴趣可以自己编码测试。须知纸上得来终觉浅，还是要多实践。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;time\u0026quot; ) const envRestart = \u0026quot;RESTART\u0026quot; const envListenFD = \u0026quot;LISTENFD\u0026quot; func main() { v := os.Getenv(envRestart) if v != \u0026quot;1\u0026quot; { ln, err := net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;localhost:8888\u0026quot;) if err != nil { panic(err) } wg := sync.WaitGroup{} wg.Add(1) go func() { defer wg.Done() for { ln.Accept() } }() tcpln := ln.(*net.TCPListener) f, err := tcpln.File() if err != nil { panic(err) } os.Setenv(envRestart, \u0026quot;1\u0026quot;) os.Setenv(envListenFD, fmt.Sprintf(\u0026quot;%d\u0026quot;, f.Fd())) _, err = syscall.ForkExec(os.Args[0], os.Args, \u0026amp;syscall.ProcAttr{ Env: os.Environ(), Files: []uintptr{os.Stdin.Fd(), os.Stdout.Fd(), os.Stderr.Fd(), f.Fd()}, Sys: nil, }) if err != nil { panic(err) } log.Print(\u0026quot;parent pid:\u0026quot;, os.Getpid(), \u0026quot;, pass fd:\u0026quot;, f.Fd()) f.Close() wg.Wait() } else { v := os.Getenv(envListenFD) fd, err := strconv.ParseInt(v, 10, 64) if err != nil { panic(err) } log.Print(\u0026quot;child pid:\u0026quot;, os.Getpid(), \u0026quot;, recv fd:\u0026quot;, fd) // case1: 理解上面提及的file descriptor、file description的关系 // 这里子进程继承了父进程中传递过来的一些fd，但是fd数值与父进程中可能是不同的 // // 取消注释来测试... //ff := os.NewFile(uintptr(fd), \u0026quot;\u0026quot;) //if ff != nil { //	_, err := ff.Stat() //	if err != nil { //	log.Println(err) //	} //} // case2: 假定父进程中共享了fd 0\\1\\2\\listenfd给子进程，那再子进程中可以预测到listenfd=3 ff := os.NewFile(uintptr(3), \u0026quot;\u0026quot;) fmt.Println(\u0026quot;fd:\u0026quot;, ff.Fd()) if ff != nil { _, err := ff.Stat() if err != nil { panic(err) } // 这里pause, 运行命令lsof -P -p $pid，检查下有没有listenfd传过来，除了0，1，2，应该有看到3 // ctrl+d to continue ioutil.ReadAll(os.Stdin) fmt.Println(\u0026quot;....\u0026quot;) _, err = net.FileListener(ff) if err != nil { panic(err) } // 这里pause, 运行命令lsof -P -p $pid, 会发现有两个listenfd, // 因为前面调用了ff.FD() dup2了一个，如果这里不显示关闭，listener将无法关闭 ff.Close() time.Sleep(time.Minute) } time.Sleep(time.Minute) } }  这里用简单的代码大致解释了如何用ProcAttr来传递listenfd。这里有个问题，假如后续父进程中传递的fd修改了呢，比如不传stdin, stdout, stderr的fd了，怎么办？服务端是不是要开始预测应该从0开始编号了？我们可以通过环境变量通知子进程，比如传递的fd从哪个编号开始是listenfd，一共有几个listenfd，这样也是可以实现的。\n这种实现方式可以跨平台。\n感兴趣的话，可以看下facebook提供的这个实现grace。\n9.2 unix domain socket + cmsg # 另一种，思路就是通过unix domain socket + cmsg来传递，父进程启动的时候依然是通过ForkExec来创建子进程，但是并不通过ProcAttr来传递listenfd。\n父进程在创建子进程之前，创建一个unix domain socket并监听，等子进程启动之后，建立到这个unix domain socket的连接，父进程此时开始将listenfd通过cmsg发送给子进程，获取fd的方式与9.1相同，该注意的fd关闭问题也是一样的处理。\n子进程连接上unix domain socket，开始接收cmsg，内核帮子进程收消息的时候，发现里面有一个父进程的fd，内核找到对应的file description，并为子进程分配一个fd，将两者建立起映射关系。然后回到子进程中的时候，子进程拿到的就是对应该file description的fd了。通过os.NewFile(fd)就可以拿到file，然后再通过net.FileListener或者net.PacketConn就可以拿到tcplistener或者udpconn。\n剩下的获取监听地址，关联逻辑service的动作，就与9.1小结描述的一致了。\n这里我也提供一个可运行的精简版的demo，供大家了解、测试用。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;time\u0026quot; passfd \u0026quot;github.com/ftrvxmtrx/fd\u0026quot; ) const envRestart = \u0026quot;RESTART\u0026quot; const envListenFD = \u0026quot;LISTENFD\u0026quot; const unixsockname = \u0026quot;/tmp/xxxxxxxxxxxxxxxxx.sock\u0026quot; func main() { v := os.Getenv(envRestart) if v != \u0026quot;1\u0026quot; { ln, err := net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;localhost:8888\u0026quot;) if err != nil { panic(err) } wg := sync.WaitGroup{} wg.Add(1) go func() { defer wg.Done() for { ln.Accept() } }() tcpln := ln.(*net.TCPListener) f, err := tcpln.File() if err != nil { panic(err) } os.Setenv(envRestart, \u0026quot;1\u0026quot;) os.Setenv(envListenFD, fmt.Sprintf(\u0026quot;%d\u0026quot;, f.Fd())) _, err = syscall.ForkExec(os.Args[0], os.Args, \u0026amp;syscall.ProcAttr{ Env: os.Environ(), Files: []uintptr{os.Stdin.Fd(), os.Stdout.Fd(), os.Stderr.Fd(), /*f.Fd()*/}, // comment this when test unixsock Sys: nil, }) if err != nil { panic(err) } log.Print(\u0026quot;parent pid:\u0026quot;, os.Getpid(), \u0026quot;, pass fd:\u0026quot;, f.Fd()) os.Remove(unixsockname) unix, err := net.Listen(\u0026quot;unix\u0026quot;, unixsockname) if err != nil { panic(err) } unixconn, err := unix.Accept() if err != nil { panic(err) } err = passfd.Put(unixconn.(*net.UnixConn), f) if err != nil { panic(err) } f.Close() wg.Wait() } else { v := os.Getenv(envListenFD) fd, err := strconv.ParseInt(v, 10, 64) if err != nil { panic(err) } log.Print(\u0026quot;child pid:\u0026quot;, os.Getpid(), \u0026quot;, recv fd:\u0026quot;, fd) // case1: 有些同学觉得可以通过环境变量传fd，通过环境变量肯定是不行的，fd根本不对应子进程中的fd //ff := os.NewFile(uintptr(fd), \u0026quot;\u0026quot;) //if ff != nil { //	_, err := ff.Stat() //	if err != nil { //	log.Println(err) //	} //} // case2: 有些同学觉得如果只有一个listenfd的情况下，那如果fork子进程时保证只传0\\1\\2\\listenfd，那子进程中listenfd一定是3 //ff := os.NewFile(uintptr(3), \u0026quot;\u0026quot;) //if ff != nil { //	_, err := ff.Stat() //	if err != nil { //	panic(err) //	} // //	// pause, ctrl+d to continue //	ioutil.ReadAll(os.Stdin) //	fmt.Println(\u0026quot;....\u0026quot;) //	_, err = net.FileListener(ff) //会dup一个fd出来，有多个listener //	if err != nil { //	panic(err) //	} //	// lsof -P -p $pid, 会发现有两个listenfd //	time.Sleep(time.Minute) //} // 这里我们暂停下，方便运行系统命令来查看进程当前的一些状态 // run: lsof -P -p $pid，检查下listenfd情况 ioutil.ReadAll(os.Stdin) fmt.Println(\u0026quot;.....\u0026quot;) unixconn, err := net.Dial(\u0026quot;unix\u0026quot;, unixsockname) if err != nil { panic(err) } files, err := passfd.Get(unixconn.(*net.UnixConn), 1, nil) if err != nil { panic(err) } // 这里再运行命令：lsof -P -p $pid再检查下listenfd情况 f := files[0] f.Stat() time.Sleep(time.Minute) } }  这种实现方式，仅限类unix系统。\n如果有服务混布的情况存在，需要考虑下使用的unix domain socket的文件名，避免因为重名所引起的问题，可以考虑通过”进程名.pid“来作为unix domain socket的名字，并通过环境变量将其传递给子进程。\n10. go实现热重启: 子进程如何通过listenfd重建listener # 前面已经提过了，当拿到fd之后还不知道它对应的是tcp的listener，还是udpconn，那怎么办？都试下呗。\nfile, err := os.NewFile(fd) // check error tcpln, err := net.FileListener(file) // check error udpconn, err := net.PacketConn(file) // check error  11. go实现热重启：父进程平滑退出 # 父进程如何平滑退出呢，这个要看父进程中都有哪些逻辑要平滑停止了。\n11.1. 处理已建立连接上请求 # 可以从这两个方面入手：\n shutdown read，不再接受新的请求，对端继续写数据的时候会感知到失败； 继续处理连接上已经正常接收的请求，处理完成后，回包，close连接；  也可以考虑，不进行读端关闭，而是等连接空闲一段时间后再close，是否尽快关闭更符合要求就要结合场景、要求来看。\n如果对可用性要求比较苛刻，可能也会需要考虑将connfd、connfd上已经读取写入的buffer数据也一并传递给子进程处理。\n11.2. 消息服务 #  确认下自己服务的消息消费、确认机制是否合理 不再收新消息 处理完已收到的消息后，再退出  11.3. 自定义AtExit清理任务 # 有些任务会有些自定义任务，希望进程在退出之前，能够执行到，这种可以提供一个类似AtExit的注册函数，让进程退出之前能够执行业务自定义的清理逻辑。\n不管是平滑重启，还是其他正常退出，对该支持都是有一定需求的。\n12. 其他 # 有些场景下也希望传递connfd，包括connfd上对应的读写的数据。\n比如连接复用的场景，客户端可能会通过同一个连接发送多个请求，假如在中间某个时刻服务端执行热重启操作，服务端如果直接连接读关闭会导致后续客户端的数据发送失败，客户端关闭连接则可能导致之前已经接收的请求也无法正常响应。 这种情况下，可以考虑服务端继续处理连接上请求，等连接空闲再关闭。会不会一直不空闲呢？有可能。\n其实服务端不能预测客户端是否会采用连接复用模式，选择一个更可靠的处理方式会更好些，如果场景要求比较苛刻，并不希望通过上层重试来解决的话。这种可以考虑将connfd以及connfd上读写的buffer数据一并传递给子进程，交由子进程来处理，这个时候需要关注的点更多，处理起来更复杂，感兴趣的可以参考下mosn的实现。\n13. 总结 # 热重启作为一种保证服务平滑重启、升级的实现方式，在今天看来依然非常有价值。本文描述了实现热重启的一些大致思路，并且通过demo循序渐进地描述了在go服务中如何予以实现。虽然没有提供一个完整的热重启实例给大家，但是相信大家读完之后应该已经可以亲手实现了。\n由于作者本人水平有限，难免会有描述疏漏之处，欢迎大家指正。\n参考文章 #  Unix高级编程：进程间通信，W.Richard Stevens mosn启动流程，https://mosn.io/blog/code/mosn-startup/  "}),a.add({id:315,href:"/tags/unixsock/",title:"unixsock",description:"",content:""}),a.add({id:316,href:"/tags/%E7%83%AD%E9%87%8D%E5%90%AF/",title:"热重启",description:"",content:""}),a.add({id:317,href:"/tags/debug/",title:"debug",description:"",content:""}),a.add({id:318,href:"/blog/2020-08-25-delve%E8%B0%83%E8%AF%95%E5%99%A8%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"delve调试器设计实现",description:"研究调试器设计实现有段时间了，前几天在调试一个程序时，发现go调试器go-delve/delve竟然不支持类似gdb的x/FMT格式，于是在之前工作上又优化了一下。CR期间，也学习到一些之前理解不深的地方，也顺便了解了下delve的整体架构设计、大致实现，今天就来说道说道。\ndelve简介 # go-delve/delve是Derekparker发起的一个调试器项目，面向go语言的。为什么针对go语言要创建一个新的调试器呢？为什么不使用GDB呢？这里涉及到go的一些特性。\n作为符号级调试器，要能正常实现源码级调试，有这么几个事情必须要做的：\n 首先，就必须要有调试信息的支持，比如编译器、连接器在构建过程中插入DWARF相关的sections，以供后续调试器提取、解析以重建指令、地址与源码的映射关系，还有在活动记录中跳转等等。 此外，有了调试信息，还需要理解语言内部实现，比如go的类型系统、协程、运行时，这样你才能读写源码级的运行状态信息； 还没完，你还需要一些平台级实现相关的玩意，不同的语言在不同的平台上有不同的实现，调试器要理解这些差异并做针对性处理；  这些工作，在GDB里扩展插件来实现，不一定能很好地实现的，比如GDB支持的DWARF标准版本问题，和go编译器没有对齐之类的，比如GDB里面Target层（对tracee）控制层考虑的大多是进程、线程级别的，没有对goroutine类似的控制能力，诸如此类。\nAnyway，我们需要一款更理解go的调试器，delve就这么诞生了。现在大已经是go官方推荐的调试器了，也是GoLand、VSCode、vim-go中使用的调试器。能有幸了解一款调试器的实现、参与贡献还是很爽的一件事情。\ndelve整体架构 # delve大致实现 # ",content:"研究调试器设计实现有段时间了，前几天在调试一个程序时，发现go调试器go-delve/delve竟然不支持类似gdb的x/FMT格式，于是在之前工作上又优化了一下。CR期间，也学习到一些之前理解不深的地方，也顺便了解了下delve的整体架构设计、大致实现，今天就来说道说道。\ndelve简介 # go-delve/delve是Derekparker发起的一个调试器项目，面向go语言的。为什么针对go语言要创建一个新的调试器呢？为什么不使用GDB呢？这里涉及到go的一些特性。\n作为符号级调试器，要能正常实现源码级调试，有这么几个事情必须要做的：\n 首先，就必须要有调试信息的支持，比如编译器、连接器在构建过程中插入DWARF相关的sections，以供后续调试器提取、解析以重建指令、地址与源码的映射关系，还有在活动记录中跳转等等。 此外，有了调试信息，还需要理解语言内部实现，比如go的类型系统、协程、运行时，这样你才能读写源码级的运行状态信息； 还没完，你还需要一些平台级实现相关的玩意，不同的语言在不同的平台上有不同的实现，调试器要理解这些差异并做针对性处理；  这些工作，在GDB里扩展插件来实现，不一定能很好地实现的，比如GDB支持的DWARF标准版本问题，和go编译器没有对齐之类的，比如GDB里面Target层（对tracee）控制层考虑的大多是进程、线程级别的，没有对goroutine类似的控制能力，诸如此类。\nAnyway，我们需要一款更理解go的调试器，delve就这么诞生了。现在大已经是go官方推荐的调试器了，也是GoLand、VSCode、vim-go中使用的调试器。能有幸了解一款调试器的实现、参与贡献还是很爽的一件事情。\ndelve整体架构 # delve大致实现 # "}),a.add({id:319,href:"/tags/jsonrpc/",title:"jsonrpc",description:"",content:""}),a.add({id:320,href:"/tags/starlark/",title:"starlark",description:"",content:""}),a.add({id:321,href:"/tags/mock/",title:"mock",description:"",content:""}),a.add({id:322,href:"/blog/2020-08-23-monkey_patching_in_go/",title:"Monkey Patching in Go",description:"很多go开发者使用gomonkey来写mock测试，但是很多连原理都没搞明白，本文从0开始介绍如何实现monkey patching，希望读者能了解这里的实现原理，以及从原理认识到gomonkey的优缺点。",content:"前几天写了篇x64汇编开发介绍的文章，当时有提到接下来会介绍下go中如何实现monkey patching，嗯，今天就来说下这个事情。\nMonkey Patching 简介 # monkey patching，一说到这个，很多熟悉go的同学可能会联想起gomonkey这个mock测试框架。该术语的定义取决于使用它的社区。在Ruby，Python 和许多其他动态编程语言中，“monkey patching”一词仅指在运行时对类或模块的动态修改，其目的是为了修补现有的第三方代码，以此作为解决方法。错误或功能无法正常运行。根据其不同的意图，在运行时修改类的其他形式也具有不同的名称。例如，在Zope和Plone中，安全补丁通常是使用动态类修改来提供的，但它们被称为热修补程序(hot fixes)。\nmonkey pathcing，它常用语如下场景：\n 在运行时替换方法/类/属性/函数，例如在测试过程中取消功能； 修改/扩展第三方产品的行为，而无需维护源代码的私有副本； 在运行时将补丁程序的结果应用于内存中的状态，而不是磁盘上的源代码； 分发与原始源代码一起存在的安全性或行为修复程序（例如，将其作为Ruby on Rails平台的插件分发）； 探索各种自动修复程序以提供自我修复。  Monkey Patching in Go # 最近在写mock测试的时候，有些场景下用到了gomonkey，这个测试框架挺好用的，之前也简单了解过大致的实现，最近也在看些底层工具链相关的东西，就想整理下这方面的一点东西。也希望能帮助到想了解这方面内容的同学。\n那现在就就开始吧，首先我会简单介绍下go函数的实现、指令patching的概念，然后看下反汇编、指令级调试如何帮助快速定位问题，然后通过几个简单的demo来演示下如何实现指令patch，然后我们再回到go实现monkey patching。\n 怎么说呢，如果不感兴趣就真的不要看了，就好像别人骑车摔破头也觉得很爽，但是你觉得骑车没什么好玩的，一个道理。\n Go函数表示 # demo1 # 下面定义了一个简单的函数a()，然后再main函数中调用它，然后调用通过print打印出它的返回值。\nfile: main.go\npackage main func a() int { return 1 } func main() { print(a()) }  这个函数非常简单，monkey patching离不开汇编，所以我们先看下其对应的汇编代码，了解这个程序干了些啥。\n这里顺便推荐几个工具:\n dlv，适用于go的调试器 radare2，静态分析工具，类似的IDA、Hopper  我这里就先试用radare2（下文简称r2）来演示如何操作了。\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main main.go $ r2 ./main -- give | and \u0026gt; a try piping and redirection [0x00454330]\u0026gt; s sym.main.main [0x00459270]\u0026gt; af [0x00459270]\u0026gt; pdf ; CODE XREF from sym.main.main @ 0x4592c2 ┌ 84: sym.main.main (); │ ; var int64_t var_10h @ rsp+0x8 │ ; var int64_t var_8h @ rsp+0x10 │ ┌─\u0026gt; 0x00459270 64488b0c25f8. mov rcx, qword fs:[0xfffffffffffffff8] ;; 这里是go函数栈检查 │ ╎ 0x00459279 483b6110 cmp rsp, qword [rcx + 0x10] │ ┌──\u0026lt; 0x0045927d 763e jbe 0x4592bd │ │╎ 0x0045927f 4883ec18 sub rsp, 0x18 ;; 栈没问题开始执行 │ │╎ 0x00459283 48896c2410 mov qword [var_8h], rbp │ │╎ 0x00459288 488d6c2410 lea rbp, qword [var_8h] │ │╎ 0x0045928d e8beffffff call sym.main.a ;; 调用函数sym.main.a │ │╎ 0x00459292 488b0424 mov rax, qword [rsp] │ │╎ 0x00459296 4889442408 mov qword [var_10h], rax │ │╎ 0x0045929b e83003fdff call sym.runtime.printlock │ │╎ 0x004592a0 488b442408 mov rax, qword [var_10h] │ │╎ 0x004592a5 48890424 mov qword [rsp], rax │ │╎ 0x004592a9 e8a20afdff call sym.runtime.printint │ │╎ 0x004592ae e89d03fdff call sym.runtime.printunlock │ │╎ 0x004592b3 488b6c2410 mov rbp, qword [var_8h] │ │╎ 0x004592b8 4883c418 add rsp, 0x18 │ │╎ 0x004592bc c3 ret │ └──\u0026gt; 0x004592bd e83e7affff call sym.runtime.morestack_noctxt └ └─\u0026lt; 0x004592c2 ebac jmp sym.main.main [0x00459270]\u0026gt; s sym.main.a ;; 查看sym.main.a地址为0x00459250 [0x00459250]\u0026gt;  函数main中调用函数a的过程就这么简单call sym.main.a，也就是call 0x00459250，再看下a这个函数，它很简单将返回值1存储到[arg_8h]中，就是前一个栈帧中的一个8字节空间，之后的我们就先不关心了。\n[0x00459250]\u0026gt; af [0x00459250]\u0026gt; pdf ; CALL XREF from sym.main.main @ 0x45928d ┌ 19: sym.main.a (int64_t arg_8h); │ ; arg int64_t arg_8h @ rsp+0x8 │ 0x00459250 48c744240800. mov qword [arg_8h], 0 │ 0x00459259 48c744240801. mov qword [arg_8h], 1 └ 0x00459262 c3 ret  demo2 # 看完上面这个，我们看点跟monkey patching相关的一个demo。\n这个demo也很简单，定义了一个函数a，然后定义了一个变量b，将a赋值给b。有过cc++基础的同学，会自然联想到函数指针，我也是写cc++过来的，所以很自然会想到，f是一个函数指针，它指向a这个函数。下面的打印语句呢，它应该打印出函数a的地址。\nfile: main2.go\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func main() { f := a fmt.Printf(\u0026quot;%p\\n\u0026quot;, a) fmt.Printf(\u0026quot;0x%x\\n\u0026quot;, *(*uintptr)(unsafe.Pointer(\u0026amp;f))) }  测试下看下结果：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main2 main2.go $ ./main2 0x4abf20 0x4ecc28  发现这两个地址并不相同，说明什么，说明我们对go函数值的理解有偏差，至少可以确定的是它不是一个函数指针。要想理解go的函数值表示，可以参考funcval表示。\n那这么看应该是一个指针的指针，验证一下：\n[0x0045c410]\u0026gt; px/1ag 0x4ecc28 0x004ecc28 0x004abf20 0x00000000 .J.....  px/1ag就是就是类似gdb调试器里面的x/FMT或者dlv里面的x -FMT hex -len 8 address。我们打印地址0x4ecc28地址处的一个8字节地址出来，发现刚好就是函数a的地址0x004abf20。所以，上述f := a 关于f结构的猜想就得到了验证，它就是一个funcval，并非cc++意义上的函数指针。\ndemo3 # 理解了funcval之后，再来一个demo，再来一个修改版的demo，这下应该可以打印出相同的地址了。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func main() { f := a fmt.Printf(\u0026quot;%p\\n\u0026quot;, a) fmt.Printf(\u0026quot;0x%x\\n\u0026quot;, **(**uintptr)(unsafe.Pointer(\u0026amp;f))) }  运行一下：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main3 main3.go $ ./main3 0x4abf20 0x4abf20  OK，到这里，我们理解了funcval，那么当我们调用 f() 的时候，编译器安插了什么指令来实现对a这个函数的调用呢？\nfile: main4.go\npackage main() func a() int { return 1 } func main() { f := a f() }  运行以下操作：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main4 main4.go $ $ r2 ./main4 -- Enable ascii-art jump lines in disassembly by setting 'e asm.lines=true'. asm.lines.out and asm.linestyle may interest you as well [0x00454330]\u0026gt; s sym.main.main [0x00459270]\u0026gt; af [0x00459270]\u0026gt; pdf ; CODE XREF from sym.main.main @ 0x4592b1 ┌ 67: sym.main.main (); │ ; var int64_t var_10h @ rsp+0x8 │ ; var int64_t var_8h @ rsp+0x10 │ ┌─\u0026gt; 0x00459270 64488b0c25f8. mov rcx, qword fs:[0xfffffffffffffff8] │ ╎ 0x00459279 483b6110 cmp rsp, qword [rcx + 0x10] │ ┌──\u0026lt; 0x0045927d 762d jbe 0x4592ac │ │╎ 0x0045927f 4883ec18 sub rsp, 0x18 │ │╎ 0x00459283 48896c2410 mov qword [var_8h], rbp │ │╎ 0x00459288 488d6c2410 lea rbp, qword [var_8h] │ │╎ 0x0045928d 488d15fc7002. lea rdx, qword [0x00480390] │ │╎ 0x00459294 4889542408 mov qword [var_10h], rdx │ │╎ 0x00459299 488b05f07002. mov rax, qword [0x00480390] ; [0x480390:8]=0x459250 sym.main.a │ │╎ 0x004592a0 ffd0 call rax │ │╎ 0x004592a2 488b6c2410 mov rbp, qword [var_8h] │ │╎ 0x004592a7 4883c418 add rsp, 0x18 │ │╎ 0x004592ab c3 ret │ └──\u0026gt; 0x004592ac e84f7affff call sym.runtime.morestack_noctxt └ └─\u0026lt; 0x004592b1 ebbd jmp sym.main.main  这里其实可以确定的是，0x00480390 就是变量f这个funcval的地址，下面又取 [0x00480390] 这个内存单元中的内容送rax，此时rax中的内容也就是函数a的地址了，最后 call rax 完成函数调用。\n这里其实实现了一个操作，本来f也可以指向另一个函数b，但是我却通过赋值操作 f := a 将其执行了另一个函数a去执行。这样类似的操作，提炼下是否可以拿来用于实现monkey patching呢？可以。\n现在要在程序运行的时候，动态调整一个函数要执行的目的代码，其实也可以通过类似的操作。\n指令Patching # 指令patching是一个比monkey patching覆盖面更广的范畴，意思就是运行时修改程序执行的指令。其实，指令patching技术大家都已经用过无数次了，只不过不是你亲自操作的。\n比如，当你调试一个程序的时候，就需要指令patch让你的被调试任务（俗称tracee）停下来，这个时候就需要将tracee下一条要执行的指令的首字节篡改为0xcc，处理器遇到这个指令就会让你的程序停下来。通常int3用来生成一字节指令0xcc，处理器取值、译码、执行完之后就会停下来触发中断，然后内核提供的中断服务程序开始执行。正常BIOS提供的都是16位中断服务程序，以Linux为例，内核初始化的时候会重建保护模式下的32/64中断服务程序，意思也就是说，碰到这个指令之后，内核就相当于收到了通知来处理tracee的暂停工作。等tracee停下来之后就会通知tracer（也就是调试器），tracer就可以通过系统调用等手段来检查tracee的运行时信息，包括registers、ram等等。\n这里的monkey patching呢，其实也是有点类似，简单一句就是篡改指令而已。问题是这里该怎么篡改？\n其实这里的改法，也比较简单，假如我们有这样的一个函数 func a() int {return 1}，我们希望main函数中调用a()的时候，执行的是func b() int {return 2}，那怎么搞呢？我们可以写一个函数replace(a, b)将对a的调用替换成对b的调用。\npackage main func a() int { return 1 } func b() int { return 2 } func main() { replace(a, b) print(a()) }  大致实现 # 因为是在运行时修改，在运行时能干什么呢？我们不能修改a的地址，只能再a的地址处玩些花招：指令patch，篡改这里的指令。怎么篡改呢？\n 前面讲过，我们是可以拿到一个funcval变量中保存的目的函数地址的； 操作系统，提供了一些可以使用的系统调用来让我们修改进程地址空间中的数据；  两个条件都具备了，我们可以通过ptrace+peekdata/pokedata来读写指令，也可以获取函数对应的页面（注意对齐），然后申请对这个页面的读写执行权限。两种办法应该都可行。更安全、细粒度的控制，ptrace+peekdata/pokedata要好些，这里纯粹是为了演示，就用后面这个办法了。大致实现如下。\nfile5: main5.go\npackage main import ( \u0026quot;syscall\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func b() int { return 2 } func rawMemoryAccess(b uintptr) []byte { return (*(*[0xFF]byte)(unsafe.Pointer(b)))[:] } func assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) return []byte{ // TODO 动态生成跳转到函数funcval f目的地址的指令 // MOV rdx, funcVal // JMP [rdx] } } func replace(orig, replacement func() int) { bytes := assembleJump(replacement) functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig)) window := rawMemoryAccess(functionLocation) copy(window, bytes) } func main() { replace(a, b) // 将对a的调用替换成对b的调用 print(a()) // 这里输出的不是1，是2，注意禁用内联-gcflags=\u0026quot;all=-N -l\u0026quot; }  大致实现思路就是上面这样，replace内部：\n 会首先生成跳转到函数b的汇编指令， 然后再找到函数a的内存地址， 再将生成的跳转指令拷贝到函数a的地址处，覆盖a原来的指令；  这样当程序跑起来之后，跑到a的地址处，立即就JMP到函数b的地址处执行函数b的指令。我们这里不考虑将a数据恢复的问题，其实要做也很简单，你记录一下哪个地址，覆写了多少哪些数据就行了。调试器调试安插0xcc指令的时候都是需要做好保存、恢复类操作的，不然生成的端点（0xcc）就把指令弄乱套了。我们这里就不做这些了。\nOK，那这里的函数 assembleJump(f func() int) 如何动态生成它的跳转指令呢？这里可以先借助指令级调试先自己测试下。\n指令级调试 # 调试器，大家都熟悉吧？其实调试器也是可以分成好几类比较通俗的分类是源码级调试器、指令级调试器。\n指令级调试器，大家听说过的应该有IDA、OlleDbg、Hopper、Cutter、Radare2，指令级调试器一般工作在汇编指令层级，对上层高级语言的东西不怎么理解，它理解的就是一些最原始的信息，指令、数据、寄存器、内存，没有文件、源码、行号、变量名\u0026hellip;各自有各自的用途，一些符号级调试器如dlv、gdb、lldb等等的也会支持一些基础的指令级调试的能力，比如反汇编、step、step reverse等等的。\n我们这里希望在指令级完成调试，比如修改些指令看看效果之类的，一般的工具还是不方便的。Radare2支持指令级调试、指令修改、根据调用约定动态生成调用图等之类的，还是很方便的。\n今天就用Radare2来演示下这个如何操作，要调试的是下面这段代码。我们在函数跳转到a地址执行之后，将a地址处的指令篡改下，比如写个JMP到b函数地址的指令，看能不能正常跳转到b处执行，调试成功应该输出2 2。\nfile: mainx.go\npackage main func a() int { return 1 } func b() int { return 2 } func main() { println(a(), b()) }  运行以下操作：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o mainx mainx.go $ $ r2 -w ./mainx $ r2 -w ./mainx -- To debug a program, you can call r2 with 'dbg://\u0026lt;path-to-program\u0026gt;' or '-d \u0026lt;path..\u0026gt;' [0x00454330]\u0026gt; s sym.main. sym.main.a sym.main.b sym.main.main [0x00454330]\u0026gt; s sym.main.a ; 发现函数a的低质是0x00454330 [0x00459250]\u0026gt; af [0x00459250]\u0026gt; s sym.main.b ; 发现函数b的地址是0x00459250 [0x00459270]\u0026gt; af  好，我们接着操作看下在sym.main.a地址处写入个跳转到b的指令。\n[0x00459270]\u0026gt; s sym.main.a [0x00459250]\u0026gt; pdf ┌ 19: sym.main.a (int64_t arg_8h); │ ; arg int64_t arg_8h @ rsp+0x8 │ 0x00459250 48c744240800. mov qword [arg_8h], 0 │ 0x00459259 48c744240801. mov qword [arg_8h], 1 └ 0x00459262 c3 ret [0x00459250]\u0026gt;  我们看到函数a处的逻辑是返回值1，我们从起起始地址0x00459250处开始，用JMP bAddress的指令覆盖。\n我们希望写到此处的指令有：\nmov rdx, 0x00459270 ; 首先将函数b地址放到rdx寄存器 jmp rdx ; 然后直接跳转过去执行  这里有这么两个办法：\n r2 -w写模式下，直接用wa+汇编指令替换函数a的指令； r2附带工具生成汇编对应的16进制数据，用wx+16进制数来覆写指令； 其实你也可以用一些在线的汇编工具生成，再用其他16进制工具打开可执行程序，然后修改替换。  r2: wa+汇编指令 # 通过wa来直接写入汇编指令，这个比较省事，不用单独运行rasm2去得到汇编后的指令16禁止数据再去覆写。\n[root@centos test]# r2 -w ./mainx -- The '?' command can be used to evaluate math expressions. Like this: '? (0x34+22)*4' [0x00454330]\u0026gt; s sym.main.b [0x00459270]\u0026gt; af [0x00459270]\u0026gt; s sym.main.a [0x00459250]\u0026gt; af [0x00459250]\u0026gt; pdf ┌ 19: sym.main.a (int64_t arg_8h); │ ; arg int64_t arg_8h @ rsp+0x8 │ 0x00459250 48c744240800. mov qword [arg_8h], 0 │ 0x00459259 48c744240801. mov qword [arg_8h], 1 └ 0x00459262 c3 ret [0x00459250]\u0026gt; wa mov rdx, 0x00459270 ;; 写mov指令，提示成功，写入了7个字节 Written 7 byte(s) (mov rdx, 0x00459270) = wx 48c7c270924500 [0x00459250]\u0026gt; wa jmp rdx @0x00459257 ;; 写jmp指令，提示成功，写入了2个字节 Written 2 byte(s) (jmp rdx) = wx ffe2 [0x00459250]\u0026gt; px/20xb 0x00459250 ;; 校验一下写入的9个字节 [0x00459250]\u0026gt; wci ;; 保存退出 [0x00459250]\u0026gt; q  注意一下，就是我们写入指令之后，直接运行命令pdf（print disassembly function）看到的指令有些是没正常显示的，不过我们px/校验数据是成功写入的就ok。\n运行下patch之后的程序：\n$ ./mainx 2 2  完全符合预期。\nr2: wx+hex # 那我们得看下这些汇编指令对应的机器指令是啥样的，radare2也提供了工具来处理。\n汇编、机器指令都是平台相关的，汇编前先看下平台相关信息，好，我的是Intel x86_64, 64位。\n$ uname -a Linux centos 4.19.76-linuxkit #1 SMP Tue May 26 11:42:35 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux $ $ rasm2 -a x86 -b 64 'mov rdx, 0x00459270' 48c7c270924500 $ rasm2 -a x86 -b 64 'jump rdx' ffe2  生成机器指令后，在r2会话窗口中执行：\n[0x00459250] wx 48c7c270924500ffe2 [0x00459250]\u0026gt; px/9xb - offset - 0 1 2 3 4 5 6 7 8 9 A B C D E F 0123456789ABCDEF 0x00459250 48c7 c270 9245 00ff e2 H..p.E... ;; 写入成功了 [0x00459250]\u0026gt; wci ;; 保存退出 [0x00459250]\u0026gt; q  运行下patch之后的程序：\n$ ./mainx 2 2  上面只是为了测试下，行还是不行，肯定是行啊，我只是想炫耀下radare2有多强大好玩而已。\nMonkey Patching # 上面兜了个圈子，给大家演示了下radare2怎么使用，接下来我们运行时patch下指令测试下。还是mainx.go这个程序。\npackage main func a() int { return 1 } func b() int { return 2 } func main() { println(a(), b()) }  前面radare2都是运行在修改模式下，这次运行再调试模式下radare2 -d。\n执行如下操作：\n$ r2 -d ./mainx Process with PID 1243 started... ;; 显示已经attach到tracee = attach 1243 1243 bin.baddr 0x00400000 Using 0x400000 asm.bits 64 -- Use 'e' and 't' in Visual mode to edit configuration and track flags. [0x00454330]\u0026gt; s sym.main.b ;; 继续看下b函数地址 [0x00459270]\u0026gt; af [0x00459270]\u0026gt; s sym.main.a ;; 继续看下a函数地址 [0x00459250]\u0026gt; af [0x00459250]\u0026gt; pdf ;; 看下a函数包含的指令 ┌ 9: sym.main.a (); │ bp: 0 (vars 0, args 0) │ sp: 0 (vars 0, args 0) │ rg: 0 (vars 0, args 0) │ 0x00459250 48c7c2709245. mov rdx, sym.main.b ; 0x459270 ; \u0026quot;H\\xc7D$\\b\u0026quot; └ 0x00459257 ffe2 jmp rdx [0x00459250]\u0026gt; wx 48c7c270924500ffe2 ;; 跟前面讲的一样，指令patch，调到b去 [0x00459250]\u0026gt; [0x00459250]\u0026gt; s sym.main.main ;; 定位到main函数 [0x00459290]\u0026gt; af ;; 分析main函数 [0x00459290]\u0026gt; pdf ;; 看下main函数指令集调用关系 ; CODE XREF from sym.main.main @ 0x459308 ┌ 122: sym.main.main (); │ ; var int64_t var_18h @ rsp+0x8 │ ; var int64_t var_10h @ rsp+0x10 │ ; var int64_t var_8h @ rsp+0x18 │ ┌─\u0026gt; 0x00459290 64488b0c25f8. mov rcx, qword fs:[0xfffffffffffffff8] │ ╎ 0x00459299 483b6110 cmp rsp, qword [rcx + 0x10] │ ┌──\u0026lt; 0x0045929d 7664 jbe 0x459303 │ │╎ 0x0045929f 4883ec20 sub rsp, 0x20 │ │╎ 0x004592a3 48896c2418 mov qword [var_8h], rbp │ │╎ 0x004592a8 488d6c2418 lea rbp, qword [var_8h] │ │╎ 0x004592ad e89effffff call sym.main.a │ │╎ 0x004592b2 488b0424 mov rax, qword [rsp] │ │╎ 0x004592b6 4889442410 mov qword [var_10h], rax │ │╎ 0x004592bb e8b0ffffff call sym.main.b │ │╎ 0x004592c0 488b0424 mov rax, qword [rsp] │ │╎ 0x004592c4 4889442408 mov qword [var_18h], rax │ │╎ 0x004592c9 e80203fdff call sym.runtime.printlock │ │╎ 0x004592ce 488b442410 mov rax, qword [var_10h] │ │╎ 0x004592d3 48890424 mov qword [rsp], rax │ │╎ 0x004592d7 e8740afdff call sym.runtime.printint │ │╎ 0x004592dc e82f05fdff call sym.runtime.printsp │ │╎ 0x004592e1 488b442408 mov rax, qword [var_18h] │ │╎ 0x004592e6 48890424 mov qword [rsp], rax │ │╎ 0x004592ea e8610afdff call sym.runtime.printint │ │╎ 0x004592ef e86c05fdff call sym.runtime.printnl │ │╎ 0x004592f4 e85703fdff call sym.runtime.printunlock │ │╎ 0x004592f9 488b6c2418 mov rbp, qword [var_8h] │ │╎ 0x004592fe 4883c420 add rsp, 0x20 │ │╎ 0x00459302 c3 ret │ └──\u0026gt; 0x00459303 e8f879ffff call sym.runtime.morestack_noctxt └ └─\u0026lt; 0x00459308 eb86 jmp sym.main.main [0x00459290]\u0026gt; dc ;; 我们这里没有什么加断点的必要了，直接continue (1243) Created thread 1244 (1243) Created thread 1245 PTRACE_CONT: No such process (1243) Created thread 1246 PTRACE_CONT: No such process [+] SIGNAL 19 errno=0 addr=0x00000000 code=0 ret=0 [+] signal 19 aka SIGSTOP received 0 [0x004549f3]\u0026gt; dc ;; 再来一次，continue到tracee结束 2 2 ;; 输出了结果 `2 2`  OK，经过上面相关的演示之后，应该已经了解了我们patch的大致方法及实际效果了，也介绍了radare2的常用操作。\nPut It Together # 现在我们收一下，将前面掌握的技能点综合起来，来实现我们前面遗留的任务：\nfunc assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) return []byte{ // TODO 动态生成跳转到函数funcval f目的地址的指令 // MOV rdx, funcVal // JMP [rdx] } }  那这里就很简单了，就是填充这里的[]byte{}，构造出我们前面radare2 wx命令写入的数据而已。 多次测试下rasm2对jmp指令的编码你可以发现：\n mov操作码编码为48c7 rdx编码为为c2 接下来是要移动的数据funcval地址，这个通过移位运算符搞下就行了，多少个字节呢？看mov操作码知道操作数位宽32bits，所以4个字节  那么 MOV rdx, funcVal 对应的就是:\n[]byte{ 0x48, 0xC7, 0xC2, byte(funcVal \u0026gt;\u0026gt; 0), byte(funcVal \u0026gt;\u0026gt; 8), byte(funcVal \u0026gt;\u0026gt; 16), byte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal  再看下 JMP [rdx]，注意这里和我们前面举的例子不同，前面是对JMP rdx编码的，这两种方式涉及到处理器寻址方式的差异。\n JMP [rdx]，是说rdx中存储的是地址，取出这个地址对应内存单元中的数据作为有效地址； JMP rdx，是说rdx中存储的就是有效地址，前面的例子中我们是直接将func b的地址拿来用的；  这里的assembleJump函数接受的参数是funcVal，拿到的是funcVal的地址，需要再解一次引用，才能拿到func b的有效地址。\n说这么多，应该没有歧义了，使用rasm2继续对JMP [rdx]编码得到ff22:\n$ rasm2 -a x86 -b 64 'jmp [rdx]' $ ff22  那我们这个函数就可以写完了：\nfunc assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) return []byte{ // TODO 动态生成跳转到函数funcval f目的地址的指令 0x48, 0xC7, 0xC2, byte(funcVal \u0026gt;\u0026gt; 0), byte(funcVal \u0026gt;\u0026gt; 8), byte(funcVal \u0026gt;\u0026gt; 16), byte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal 0xff, 0x22, // JMP [rdx] } }  那最后的示例就是这样的，你可以直接运行下面的程序来测试下，期望的结果是输出2，而不是1。\n如果你测试的时候输出了1，说明你可能忽视了一个问题：这里的monkey patching是基于函数地址处的指令patch来实现的。如果编译过程中，不巧期望被patch的函数被go inline处理掉了，那这里的patch铁定就失效了。\n所以测试的时候记得禁用内联，比如go run -gcflags=\u0026quot;all=-N -l\u0026quot; jump.go。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func b() int { return 2 } func getPage(p uintptr) []byte { return (*(*[0xFFFFFF]byte)(unsafe.Pointer(p \u0026amp; ^uintptr(syscall.Getpagesize()-1))))[:syscall.Getpagesize()] } func rawMemoryAccess(b uintptr) []byte { return (*(*[0xFF]byte)(unsafe.Pointer(b)))[:] } func assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) fmt.Printf(\u0026quot;target address: %#x\\n\u0026quot;, funcVal) return []byte{ 0x48, 0xC7, 0xC2, byte(funcVal \u0026gt;\u0026gt; 0), byte(funcVal \u0026gt;\u0026gt; 8), byte(funcVal \u0026gt;\u0026gt; 16), byte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal 0xFF, 0x22, // JMP rdx } } func replace(orig, replacement func() int) { bytes := assembleJump(replacement) functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig)) fmt.Printf(\u0026quot;orig address: %#x\\n\u0026quot;, functionLocation) window := rawMemoryAccess(functionLocation) page := getPage(functionLocation) syscall.Mprotect(page, syscall.PROT_READ|syscall.PROT_WRITE|syscall.PROT_EXEC) copy(window, bytes) fmt.Printf(\u0026quot;bytes: %v\\n\u0026quot;, bytes) fmt.Printf(\u0026quot;wind: %v\\n\u0026quot;, window[0:len(bytes)]) } func main() { fmt.Printf(\u0026quot;a address: %p\\n\u0026quot;, a) fmt.Printf(\u0026quot;b address: %p\\n\u0026quot;, b) replace(a, b) print(a()) }  运行测试下：\n$ go run -gcflags=\u0026quot;all=-N -l\u0026quot; jump.gomonkey 2  gomonkey写mock测试，对函数的处理大致就是这个这么实现的，这里就不继续说gomonkey的具体实现细节了。\n总结 # 本文所提内容并非原创，在了解gomonkey的过程中看到了《monkey-patching-in-go》这篇文章，结合自己的一些理解重新解释下背后的原理。\n其实本没有必要解释这么多，我可以一句话总结完，”go funcval + 指令patch“。但是呢，”纸上得来终觉浅”，没有经过实践检验的“懂”也只是自己骗自己罢了。\n大篇幅介绍了radare2调试器的一些使用，应该有读者会对调试器工作原理、底层实现比较感兴趣，这也是大篇幅介绍的一点小小的私心。\n从2018年开始陆续整理调试原理的一些知识，将这些整理的内容放在了github上golang-debugger-book。原理的部分大致已经介绍完了，现在还需要结合一个实现来辅助使内容更加详实一点，这里也会涉及到对go实现细节的一些知识点补充，感兴趣的可以一起来。\n时间精力实在有限，拖得久了，很没有成就感。\n参考文章 # 1.monkey-patching-in-go, https://bou.ke/blog/monkey-patching-in-go/\n2.a-journey-into-radare2, https://www.megabeets.net/a-journey-into-radare-2-part-1/\n3.monkey patching, https://en.wikipedia.org/wiki/Monkey_patch\n4.radare2 book, https://radare.gitbooks.io/radare2book/content/tools/rasm2/assemble.html\n"}),a.add({id:323,href:"/tags/monkey-patching/",title:"monkey-patching",description:"",content:""}),a.add({id:324,href:"/tags/assembly/",title:"assembly",description:"",content:""}),a.add({id:325,href:"/tags/intel/",title:"intel",description:"",content:""}),a.add({id:326,href:"/tags/x64/",title:"x64",description:"",content:""}),a.add({id:327,href:"/blog/2020-08-20-x64%E6%B1%87%E7%BC%96%E5%BC%80%E5%8F%91%E4%BB%8B%E7%BB%8D/",title:"x64汇编开发介绍",description:"最近在工作和学习中发现，其实汇编是非常重要的，即便现在高级语言已经非常方便了，但是了解汇编对于深入理解计算机系统，以及一些高深的知识点是不可或缺的。举几个例子，比如说Linux操作系统有一个系统调用函数叫Fork我们都知道Fork的返回值在子进程中是0，在父进程中是非0，那这个是如何实现的呢？对于不了解汇编的人也很难有能力去阅读Linux操作系统源码，只能道听途说了解到个大概原因。再比如接下来要讲的gomonkey测试框架实现的一些指令patching操作，这些都是与汇编操作分不开的。甚至你想了解下上下文切换开销，你都需要深入了解下指令执行周期等等的问题。\n不懂汇编，不妨碍你开发上层应用，但是对你的深度就是一道坎，你很难跨国这个鸿沟去窥探更底层的一些原理。\n有感而发，今天就回顾下intel官方开发发布的x64汇编知识，做一个简单的回顾，也为后面研究gomonkey指令patching等等做一些准备和铺垫。\n介绍 # 大家使用x86汇编来写一些对性能比较敏感的程序嗯，这个情况已经持续很多年了嗯，但是现在32位机器应逐渐被64位机器取代了，对应的汇编代码也发生了变化。这篇文章主要就是介绍x64汇编的，如果不了解x86汇编也没什么大碍，当然了解的话理解起来会更简单一点。\nx64是一个通用的名字，它表示的是对Intel以及AMD 32位指令集架构的一个64位扩展。AMD首先引入了x64指令集，最初叫x86-64，后面又改成了AMD64。Intel呢，将其支持64位指令集的架构称之为IA-32e，后面又改成了EMT64。这两个版本之间有一点细微的不兼容的地方，但是大部分指令在两个版本上都可以很好的工作，相关的细节可以参考Intel开发手册Intel 64 And IA-32 Architectures Software Developer\u0026rsquo;s Manuals，以及AMD64架构的技术文档。我们将这两个版本的交集部分称之为x64。不要将x64与64位Intel Itanium架构（称之为IA-64）混为一谈。\n这篇文章没有涉及硬件相关的细节，如caches、分支预测，以及其他高级话题。文章最后会给出一些这些领域的参考手册供了解更多。\n汇编语言，往往会用来编写对性能要求比较苛刻的程序或其中的一部分。但是对大部分普通程序员来说，与其让其写汇编，还不如写cc++然后配上一个好的编译器来的实在，后者编译器优化的性能可能比其写出的汇编代码质量更高。汇编语言对于调试代码也是有用的，有时一个编译器可能生成了一些不正确的汇编指令，通过调试器在程序中单步调试可以帮助定位到问题的原因。代码优化器，有时也会犯错。汇编的另外一个用途，你可以用它来研究没有源码的程序。反汇编让你能够改变、修复现有的可执行程序（推荐下几个工具hopper or cutter）。如果你想了解或者调查为什么某种编程语言比较慢，其他的比较快之类的问题，汇编也是你的好帮手。最后吧，掌握汇编知识，对于诊断一些恶意软件，也是必不可少的技能。\n架构 # 当要去学习特定平台的汇编时，首先应该学习的是，该平台的寄存器集合。\n通用架构 # 64位寄存器允许容纳更大的尺寸的数据，或者是地址，所以我们定义的更多的类型，将1个字节byte定义成8bits，将1个字word定义成16bits，将一个双字double word定义成32bits，将一个四字quadword定义成64位，将一个八字double quadword定义成128bits。关于字节序的问题，Intel是小端字节序，意味着低有效位存储在内存的低地址中。\n上图显示了16个64bits的通用目的寄存器，前8个被命名成rax、rbx、rcx、rdx、rbp、rsi、rdi、rsp，这个命名和历史原因有关系，后面8个被命名成了r8~r15。如果前8个自己存器名，将字符r换成e，就变成了对应的地位的32位寄存器，比如rax的低32位是eax。类似地，如果想访问低16位，就直接把前缀去掉，如AX就是访问的rax的低16位，如果低8位呢，那就是AL了，AH就是次低8位（8~15位）。新加的8个寄存器r8~r15可以用类似的方式来访问低位数据，如r8（qword），r8d（lower dword），r8w（lowest word）、r8b（lowest byte MASM风格，intel风格是r8l）。注意没有r8h这种表示法。\n使用REX操作码前缀去访问新添加的这8个通用寄存器的字节时，有一些限制，不能像访问之前的8个通用寄存器一样通过AH、BH、CH、DH来访问，并且一次只能访问一个（如R11B），但是可以使用AL、BL、CL、DL，为啥来，因为它就是强制要求将AH、BH、CH、DH转换成BPL、SPL、DIL、SIL来使用。\n64位指令指针寄存器RIP，指向下一条要执行的指令的低质，并且支持64位平坦内存模型，当前操作系统中的内存地址布局将在后面提及。\n栈指针寄存器RSP，指向当前刚push进栈的元素空间地址，也就是栈顶了，栈从高地址向低地址方向增长。栈用来存储调用例程（函数）的返回值、传递参数，或者用以支持ABI中的调用惯例（如保存调用方现场）。\nRFLAGS寄存器，用来存储一些标识信息，它用来标识一些操作的结果（如是否溢出、运算结果的正负等）或者控制处理器的执行。这在x86 32位寄存器EFLAGS中就已经形成了这些，现在在以前基础上又添加了高32位，用来预留支持扩展，当前是没有使用的。下表列出了最常使用的一些flags。大多数其他flags是用于操作系统级别的任务。\n   Symbol Bit Name Set if\u0026hellip;     CF 0 Carry Operation generated a carry or borrow   PF 2 Parity Last byte has even number of 1\u0026rsquo;s, else 0   AF 4 Adjust Denotes Binary Coded Decimal in-byte carry   ZF 6 Zero Result was 0   SF 7 Sign Most significant bit of result is 1   OF 11 Overflow Overflow on signed operation         DF 10 Direction Direction string instructions operate (increment or decrement)   ID 21 Identification Changeability denotes presence of CPUID instruction    浮点运算单元（FPU，Floating Point Unit）包含了8个寄存器FPR0-FPR7，还有状态寄存器、控制寄存器，以及其他的几个寄存器。FPR0-7这几个寄存器，每个都可以存储下表中列出的数据类型的值。浮点操作遵从IEEE 754标准。注意，大多数c/c++编译器支持32位和64位的float、double数据类型，但是没有支持80位的浮点数据类型，但是汇编是支持的。这8个寄存器和另外8个MMX？寄存器实际上是共享的同一组物理寄存器。",content:"最近在工作和学习中发现，其实汇编是非常重要的，即便现在高级语言已经非常方便了，但是了解汇编对于深入理解计算机系统，以及一些高深的知识点是不可或缺的。举几个例子，比如说Linux操作系统有一个系统调用函数叫Fork我们都知道Fork的返回值在子进程中是0，在父进程中是非0，那这个是如何实现的呢？对于不了解汇编的人也很难有能力去阅读Linux操作系统源码，只能道听途说了解到个大概原因。再比如接下来要讲的gomonkey测试框架实现的一些指令patching操作，这些都是与汇编操作分不开的。甚至你想了解下上下文切换开销，你都需要深入了解下指令执行周期等等的问题。\n不懂汇编，不妨碍你开发上层应用，但是对你的深度就是一道坎，你很难跨国这个鸿沟去窥探更底层的一些原理。\n有感而发，今天就回顾下intel官方开发发布的x64汇编知识，做一个简单的回顾，也为后面研究gomonkey指令patching等等做一些准备和铺垫。\n介绍 # 大家使用x86汇编来写一些对性能比较敏感的程序嗯，这个情况已经持续很多年了嗯，但是现在32位机器应逐渐被64位机器取代了，对应的汇编代码也发生了变化。这篇文章主要就是介绍x64汇编的，如果不了解x86汇编也没什么大碍，当然了解的话理解起来会更简单一点。\nx64是一个通用的名字，它表示的是对Intel以及AMD 32位指令集架构的一个64位扩展。AMD首先引入了x64指令集，最初叫x86-64，后面又改成了AMD64。Intel呢，将其支持64位指令集的架构称之为IA-32e，后面又改成了EMT64。这两个版本之间有一点细微的不兼容的地方，但是大部分指令在两个版本上都可以很好的工作，相关的细节可以参考Intel开发手册Intel 64 And IA-32 Architectures Software Developer\u0026rsquo;s Manuals，以及AMD64架构的技术文档。我们将这两个版本的交集部分称之为x64。不要将x64与64位Intel Itanium架构（称之为IA-64）混为一谈。\n这篇文章没有涉及硬件相关的细节，如caches、分支预测，以及其他高级话题。文章最后会给出一些这些领域的参考手册供了解更多。\n汇编语言，往往会用来编写对性能要求比较苛刻的程序或其中的一部分。但是对大部分普通程序员来说，与其让其写汇编，还不如写cc++然后配上一个好的编译器来的实在，后者编译器优化的性能可能比其写出的汇编代码质量更高。汇编语言对于调试代码也是有用的，有时一个编译器可能生成了一些不正确的汇编指令，通过调试器在程序中单步调试可以帮助定位到问题的原因。代码优化器，有时也会犯错。汇编的另外一个用途，你可以用它来研究没有源码的程序。反汇编让你能够改变、修复现有的可执行程序（推荐下几个工具hopper or cutter）。如果你想了解或者调查为什么某种编程语言比较慢，其他的比较快之类的问题，汇编也是你的好帮手。最后吧，掌握汇编知识，对于诊断一些恶意软件，也是必不可少的技能。\n架构 # 当要去学习特定平台的汇编时，首先应该学习的是，该平台的寄存器集合。\n通用架构 # 64位寄存器允许容纳更大的尺寸的数据，或者是地址，所以我们定义的更多的类型，将1个字节byte定义成8bits，将1个字word定义成16bits，将一个双字double word定义成32bits，将一个四字quadword定义成64位，将一个八字double quadword定义成128bits。关于字节序的问题，Intel是小端字节序，意味着低有效位存储在内存的低地址中。\n上图显示了16个64bits的通用目的寄存器，前8个被命名成rax、rbx、rcx、rdx、rbp、rsi、rdi、rsp，这个命名和历史原因有关系，后面8个被命名成了r8~r15。如果前8个自己存器名，将字符r换成e，就变成了对应的地位的32位寄存器，比如rax的低32位是eax。类似地，如果想访问低16位，就直接把前缀去掉，如AX就是访问的rax的低16位，如果低8位呢，那就是AL了，AH就是次低8位（8~15位）。新加的8个寄存器r8~r15可以用类似的方式来访问低位数据，如r8（qword），r8d（lower dword），r8w（lowest word）、r8b（lowest byte MASM风格，intel风格是r8l）。注意没有r8h这种表示法。\n使用REX操作码前缀去访问新添加的这8个通用寄存器的字节时，有一些限制，不能像访问之前的8个通用寄存器一样通过AH、BH、CH、DH来访问，并且一次只能访问一个（如R11B），但是可以使用AL、BL、CL、DL，为啥来，因为它就是强制要求将AH、BH、CH、DH转换成BPL、SPL、DIL、SIL来使用。\n64位指令指针寄存器RIP，指向下一条要执行的指令的低质，并且支持64位平坦内存模型，当前操作系统中的内存地址布局将在后面提及。\n栈指针寄存器RSP，指向当前刚push进栈的元素空间地址，也就是栈顶了，栈从高地址向低地址方向增长。栈用来存储调用例程（函数）的返回值、传递参数，或者用以支持ABI中的调用惯例（如保存调用方现场）。\nRFLAGS寄存器，用来存储一些标识信息，它用来标识一些操作的结果（如是否溢出、运算结果的正负等）或者控制处理器的执行。这在x86 32位寄存器EFLAGS中就已经形成了这些，现在在以前基础上又添加了高32位，用来预留支持扩展，当前是没有使用的。下表列出了最常使用的一些flags。大多数其他flags是用于操作系统级别的任务。\n   Symbol Bit Name Set if\u0026hellip;     CF 0 Carry Operation generated a carry or borrow   PF 2 Parity Last byte has even number of 1\u0026rsquo;s, else 0   AF 4 Adjust Denotes Binary Coded Decimal in-byte carry   ZF 6 Zero Result was 0   SF 7 Sign Most significant bit of result is 1   OF 11 Overflow Overflow on signed operation         DF 10 Direction Direction string instructions operate (increment or decrement)   ID 21 Identification Changeability denotes presence of CPUID instruction    浮点运算单元（FPU，Floating Point Unit）包含了8个寄存器FPR0-FPR7，还有状态寄存器、控制寄存器，以及其他的几个寄存器。FPR0-7这几个寄存器，每个都可以存储下表中列出的数据类型的值。浮点操作遵从IEEE 754标准。注意，大多数c/c++编译器支持32位和64位的float、double数据类型，但是没有支持80位的浮点数据类型，但是汇编是支持的。这8个寄存器和另外8个MMX？寄存器实际上是共享的同一组物理寄存器。\n   Data Type Length Precision (bits) Decimal digits Precision Decimal Range     Single Precision 32 24 7 1.1810^-38 to 3.4010^38   Double Precision 64 53 15 2.23 10^-308 to 1.7910^308   Extended Precision 80 64 19 3.3710^-4932 to 1.1810^4932    有几个8位指令支持二进制编码的十进制（BCD），浮点寄存器支持的奇特格式还提供了一种80位，17位的BCD类型。\n 不确定是否翻译有误，原文：Binary Coded Decimal (BCD) is supported by a few 8-bit instructions, and an oddball format supported on the floating point registers gives an 80 bit, 17 digit BCD type.\n 这16个128bits的XMM寄存器（比x86多了8个）后面会有更详细介绍。\n还有就是，段寄存器（在x64下大多数没有用）、控制寄存器、内存管理寄存器、调试寄存器、虚拟化寄存器、性能寄存器（跟踪记录各种类型的内部参数，如cache命中、miss，分支预测命中、miss，微码执行，定时等等）。最突出的性能相关的操作码就是RDTSC，它是用来技术处理器时钟周期的，经常通过它来测量一小段代码的执行耗时。通常c库里面提供的函数gettimeofday是比较耗时间的，所以在高频使用的时候会有性能问题，一般在网络框架里面做定时器、时间测量相关的任务，是会通过RDTSC来推送系统时间进而推算耗时的（在我的文章libmill定时器中也有提及，hitzhangjie.gitbook.io/libmill）。\n更多其他细节信息，可以参考全5卷 \u0026ldquo;Intel 64 And IA-32 Architectures Software Developer\u0026rsquo;s Manuals\u0026rdquo;，可以从这里免费下载，http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html。\nSIMD架构 # 单指令多数据（SIMD）指令对多条数据并行执行一条命令，这是汇编例程的常用用法。 MMX和SSE命令（分别使用MMX和XMM寄存器）支持SIMD操作，该操作可并行处理多达八段数据。例如，可以使用MMX在一条指令中将八个字节与另外八个字节相加。\n八个64位MMX寄存器MMX0-MMX7是FPR0-7的别名，这意味着任何将FPR和MMX混合起来操作的代码都必须小心，不要覆盖所需的值。 MMX指令对整数类型进行操作，允许对MMX寄存器中的值并行执行字节，字和双字操作。大多数MMX指令以“P”开头表示“packed”。算术，移位/旋转，比较，例如：PCMPGTB表示“比较packed的的有符号1字节整数是否大于”。\n16个128位XMM寄存器允许每条指令对四个单精度或两个双精度值进行并行运算。一些指令还适用于压缩字节，字，双字和四字整数。这些称为流式SIMD扩展（SSE）的指令具有多种形式：SSE，SSE2，SSE3，SSSE3，SSE4，以及在本文印制之时可能还会更多。英特尔已经宣布了这些扩展，称为英特尔®高级矢量扩展（Intel®AVX），具有新的256位宽数据路径。 SSE指令包含对浮点和整数类型的移动，算术，比较，重排和拆包以及按位运算。指令名称包括诸如PMULHUW和RSQRTPS之类的。最后，SSE引入了一些有关内存预取（出于性能）和内存屏障（出于多线程安全）的指令。\n下表列出了一些命令集，操作的寄存器类型，并行操作的项目数以及项目类型。例如，使用SSE3和128位XMM寄存器，您可以并行处理2个（必须为64位）浮点值，或者并行处理16个（必须为字节大小）整数值。\n为了找到给定芯片支持的技术，有一条CPUID指令返回特定于处理器的信息。\n   Technology Register size/type Item type Items in Parallel     MMX 64 MMX Integer 8, 4, 2, 1   SSE 64 MMX Integer 8,4,2,1   SSE 128 XMM Float 4   SSE2/SSE3/SSSE3\u0026hellip; 64 MMX Integer 2,1   SSE2/SSE3/SSSE3\u0026hellip; 128 XMM Float 2   SSE2/SSE3/SSSE3\u0026hellip; 128 XMM Integer 16,8,4,2,1    工具 # assemblers # 互联网搜索显示了具有x64功能的汇编程序，例如Netwide汇编程序NASM，在NASM基础上重写的YASM，快速的Flat Assembler FASM和传统的Microsoft MASM。甚至还有一个免费的用于x86和x64程序集的IDE，称为WinASM。每个汇编程序对其他汇编程序的宏和语法都有不同的支持，并不是完全兼容的。\n对于以下示例，我使用平台SDK中免费提供的MASM的64位版本ML64.EXE。对于以下示例，请注意，MASM语法的格式为：“指令 目标操作数或地址，源操作数或地址”，有些汇编器中的语法中的源操作、目的操作的顺序是反着的。请参考对应汇编器的语法说明。\nc/c++ compilers # C/C++编译器通常允许使用内联汇编将汇编嵌入代码中，但是Microsoft Visual Studio C/C++为x64代码删除了该汇编，这可能简化了代码优化器的工作。剩下两个选择：使用单独的汇编文件和外部汇编器，或使用头文件“ intrn.h”中的内在函数（请参见Birtolo和MSDN）。其他编译器具有类似的选项。\n使用启发式的理由：\n x64中不支持内联汇编了； 方便使用，你可以使用变量名，来代替对寄存器的手动分配； 启发式相比写汇编而言更容易实现跨平台，编译器会针对不同的平台做对应的启发式优化处理； 配合启发式操作，优化器工作的更好；  例如，Microsoft Visual Studio 2008就有启发式操作，unsigned short _rotr16(unsigned short_rot16 b, unsigned char c)，这个操作将一个16位操作数b中向右rotate c位，并返回结果。使用c来实现的话，可以这么写unsigned short a1 = (b\u0026gt;\u0026gt;c)|(b\u0026lt;\u0026lt;(16-c))，这个汇编完成后大约是15条指令（debug模式下，如果是release模式下的话也差不太多），但是如果使用启发式操作unsigned short a1 = _rotr16(b,c)的话呢，汇编完成后只有4条指令，你说哪个更牛逼呢？！\n指令基础 # 寻址模式 # 在学习之前，得先了解下寻址模式，寻址模式指明了指令访问寄存器或者内存的方式 ，以下是常见的几种寻址模式：\n  立即数寻址（immediate）：操作数就在指令中，如ADD EAX, 14 ;将操作数14与32位寄存器EAX中值相加并存储到EAX中\n  寄存器寻址（register to register）：操作数就在寄存器中，如ADD R8L, AL ;将AL中的值与R8L中的值相加\n  间接寻址（indirect）：就是指令中给出的不是操作数本身，也不是操作数本身所在的地址，而是存储操作数地址的地址，甚至有可能出现多重间址的情况。这样的寻址中允许使用8，16，32位偏移量，或者任何通用目的寄存器来作为基地址或者索引，也允许使用1，2，4，8来对索引进行乘积运算。也可以为其加上段前缀，如FS:, GS:等，但是比较少使用。下面是一个示例，MOV R8W, 1234[8*RAX+RCX] ;将地址8*RAX+RCX+1234处的一个word移动到R8W，这种方式常用来访问结构体数组中的成员，1234往往是数组起始地址，8表示数组元素大小，RAX表示数组索引，RCX表示结构体字段相对结构体起始地址的偏移量。\n这种寻址方式，起始有很多种写法了，下面这些都是等价的。\nMOV ECX, dword ptr table[RBX][RDI] MOV ECX, dword ptr table[RDI][RBX] MOV ECX, dword ptr table[RBX+RDI] MOV ECX, dword ptr [table+RBX+RDI]  这里的dword ptr告诉汇编器如何编码MOV指令。\n  RIP相对寻址：这是x64中新加的寻址模式，它允许访问相对当前指令地址某偏移量出的数据，使得实现位置无关的代码更加容易了。如MOV AL,[RIP] ;RIP指向下一条待执行指令的低质，aka NOP NOP。可是，并不是所有汇编器都支持这种操作，MASM就不支持，但是FASM、YASM支持。MASM隐式地嵌入了RIP相对寻址，如MOV EAX, TABLE ;使用RIP相对寻址来获取表地址。\n  其他比较特殊的寻址：有些操作码使用寄存器的方式比较不一样，例如，有符号整数除操作IDIV，128位操作数RDX:RAX除以一个64位的操作数，会将商存储到RAX中，将余数存储到RDX中。\n  指令集 # 下表列出了一些比较常见的指令，其中*表示改指令有多个操作码，*表示后缀的意思：\n   Opcode Meaning Opcode Meaning     MOV Move to/from/between memory and registers AND/OR/XOR/NOT Bitwise operations   CMOV* Various conditional moves SHR/SAR Shift right logical/arithmetic   XCHG Exchange SHL/SAL Shift left logical/arithmetic   BSWAP Byte swap ROR/ROL Rotate right/left   PUSH/POP Stack usage RCR/RCL Rotate right/left through carry bit   ADD/ADC Add/with carry BT/BTS/BTR Bit test/and set/and reset   SUB/SBC Subtract/with carry JMP Unconditional jump   MUL/IMUL Multiply/unsigned JE/JNE/JC/JNC/J* Jump if equal/not equal/carry/not carry/ many others   DIV/IDIV Divide/unsigned LOOP/LOOPE/LOOPNE Loop with ECX   INC/DEC Increment/Decrement CALL/RETCall subroutine/return   NEG Negate NOP No operation   CMP Compare CPUID CPU information    一个常见的指令就是LOOP指令，它将RCX，ECX或者CX的值减去1，然后如果结果不是0的话，就执行跳转，下面是个示例：\nXOR	EAX, EAX	; zero out eax MOV ECX, 10 ; loop 10 times Label:	; this is a label in assembly INX EAX ; increment eax LOOP Label	; decrement ECX, loop if not 0  不太常见的操作码可实现字符串操作，重复指令前缀，端口I / O指令，标志设置/清除/测试，浮点操作（通常以F开头，并支持move from一个整数、move to一个整数，算术，比较，先验，代数移入/移出）以及控制功能），用于多线程和性能问题的缓存和内存操作码等。英特尔®64和IA-32体系结构软件开发人员手册第2卷分为两部分，详细介绍了每个操作码。\n操作系统 # 从理论上讲，64位系统允许寻址2^64字节的数据，但是当前没有芯片允许访问所有16 EB字节（18,446,744,073,709,551,616字节）。例如，AMD体系结构仅使用地址的低48位，并且48至63位必须是47位的副本，否则处理器会引发异常。因此，地址为0到00007FFFFFFFFFFF，从FFFF800000000000到FFFFFFFFFFFFFFFF，总共有256 TB（281,474,976,710,656字节）的可用虚拟地址空间。另一个缺点是，要寻址所有64位内存，需要更多的页表供OS存储，需要使用宝贵的内存。请注意，这些是虚拟地址，而不是物理地址。\n结果，许多操作系统使用此空间的上半部分，从顶部开始，然后向下扩展；而用户程序则使用下半部分，从底部开始，然后向上扩展。当前的Windows *版本使用44位寻址（16 TB = 17,592,186,044,416字节）。结果地址如下图所示。由于地址是由OS分配的，因此结果地址对用户程序而言不太重要，但是用户地址和内核地址之间的区别对于调试很有用。\n最后一个与OS相关的问题与多线程编程有关，但是此主题太大，无法在此处讨论。唯一要提到的是，有内存屏障操作码可帮助保护共享资源不受破坏。\n调用约定 # 每种架构都有自己的例程（函数）调用的一些约束，操作系统与对应架构的CPU打交道都必须要考虑如何传递对应的参数、如何获取返回值的问题，这里的具体到某个平台的约束，就称为调用约定。\n常见的x64调用约定是用于C样式函数调用的Microsoft 64调用约定（请参阅MSDN，Chen和Pietrek）。在Linux下，也将其称为应用程序二进制接口（ABI）。\n请注意，此处涉及的调用约定与x64 Linux系统上使用的约定不同：对于Microsoft x64调用约定，附加的寄存器空间使fastcall成为唯一的调用约定（在x86下有很多：stdcall，thiscall，fastcall，cdecl等）。与C / C ++样式函数接口的规则：\n RCX, RDX, R8, R9 are used for integer and pointer arguments in that order left to right. XMM0, 1, 2, and 3 are used for floating point arguments. Additional arguments are pushed on the stack left to right. Parameters less than 64 bits long are not zero extended; the high bits contain garbage. It is the caller\u0026rsquo;s responsibility to allocate 32 bytes of \u0026ldquo;shadow space\u0026rdquo; (for storing RCX, RDX, R8, and R9 if needed) before calling the function. It is the caller\u0026rsquo;s responsibility to clean the stack after the call. Integer return values (similar to x86) are returned in RAX if 64 bits or less. Floating point return values are returned in XMM0. Larger return values (structs) have space allocated on the stack by the caller, and RCX then contains a pointer to the return space when the callee is called. Register usage for integer parameters is then pushed one to the right. RAX returns this address to the caller. The stack is 16-byte aligned. The \u0026ldquo;call\u0026rdquo; instruction pushes an 8-byte return value, so the all non-leaf functions must adjust the stack by a value of the form 16n+8 when allocating stack space. Registers RAX, RCX, RDX, R8, R9, R10, and R11 are considered volatile and must be considered destroyed on function calls. RBX, RBP, RDI, RSI, R12, R14, R14, and R15 must be saved in any function using them. Note there is no calling convention for the floating point (and thus MMX) registers. Further details (varargs, exception handling, stack unwinding) are at Microsoft\u0026rsquo;s site.  我们再看下Linux man手册，这里整理了两张调用约定相关的表: https://man7.org/linux/man-pages/man2/syscall.2.html，读后可以加深我们对调用约定 or ABI的认识。\n ## 示例 ### MessageBox 前面讲这么多，现在用上面讲过的内容来写一个demo展示下x64汇编的使用，第一个demo是一个x64独立可运行的程序，运行之后会弹出一个Windows MessageBox。 ```asm ; Sample x64 Assembly Program ; Chris Lomont 2009 www.lomont.org extrn ExitProcess: PROC ; external functions in system libraries extrn MessageBoxA: PROC .data caption db '64-bit hello!', 0 message db 'Hello World!', 0 .code Start PROC sub rsp,28h ; shadow space, aligns stack mov rcx, 0 ; hWnd = HWND_DESKTOP lea rdx, message ; LPCSTR lpText lea r8, caption ; LPCSTR lpCaption mov r9d, 0 ; uType = MB_OK call MessageBoxA ; call MessageBox API function mov ecx, eax ; uExitCode = MessageBox(...) call ExitProcess Start ENDP End  将上述汇编程序保存为hello.asm，然后使用ML64进行编译，在Microsoft Windows x64 SDK中有这个程序的，这么编译：\nml64 hello.asm /link /subsystem:windows /defaultlib:kernel32.lib /defaultlib:user32.lib /entry:Start  执行完成后会构建出一个可执行程序（已经链接好库函数、启动代码了），运行这个程序hello.exe，就会看到弹出一个消息窗口。\n# 第二个示例，是在Visual Studio 2008这个IDE中，在C/C++文件中引用一个x64汇编文件中的代码，还记得Visual Studio后续删除了对支持内联汇编的支持吧。好。\n Create a new empty C++ console project. Create a function you\u0026rsquo;d like to port to assembly, and call it from main. To change the default 32-bit build, select Build/Configuration Manager. Under Active Platform, select New\u0026hellip; Under Platform, select x64. If it does not appear figure out how to add the 64-bit SDK tools and repeat. Compile and step into the code. Look under Debug/Windows/Disassembly to see the resulting code and interface needed for your assembly function. Create an assembly file, and add it to the project. It defaults to a 32 bit assembler which is fine. Open the assembly file properties, select all configurations, and edit the custom build step. Put command line ml64.exe /DWIN_X64 /Zi /c /Cp /Fl /Fo $(IntDir)\\$(InputName).obj $(InputName).asm j:w    ok，下面开始，我们先写一个c++文件，如下，main里面会调用两个函数CombineC、CombineA先后打印出计算的结果，实际上我们准备让CombineA和CombineC实现完全一致的逻辑，区别就是CombineA是在外部的汇编文件中实现的。\n// C++ code to demonstrate x64 assembly file linking #include \u0026lt;iostream\u0026gt; using namespace std; double CombineC(int a, int b, int c, int d, int e, double f) { return (a+b+c+d+e)/(f+1.5); } // NOTE: 这里必须加上extern \u0026quot;C\u0026quot;来阻止C++ name mangling，否则连接的时候会出现符号解析错误 extern \u0026quot;C\u0026quot; double CombineA(int a, int b, int c, int d, int e, double f); int main(void) { cout \u0026lt;\u0026lt; \u0026quot;CombineC: \u0026quot; \u0026lt;\u0026lt; CombineC(1,2,3,4, 5, 6.1) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026quot;CombineA: \u0026quot; \u0026lt;\u0026lt; CombineA(1,2,3,4, 5, 6.1) \u0026lt;\u0026lt; endl; return 0; }  好的，下面继续写汇编文件：\nfile: CombineA.asm\n.code PUBLIC CombineA CombineA PROC ADD ECX, DWORD PTR [RSP+28H] ; add overflow parameter to first parameter ADD ECX, R9D ; add other three register parameters ADD ECX, R8D ; ADD ECX, EDX ; MOVD XMM0, ECX ; move doubleword ECX into XMM0 CVTDQ2PD XMM0, XMM0 ; convert doubleword to floating point MOVSD XMM1, realVal ; load 1.5 ADDSD XMM1, MMWORD PTR [RSP+30H] ; add parameter DIVSD XMM0, XMM1 ; do division, answer in xmm0 RET ; return CombineA ENDP End  编译并运行上述程序，会发现输出了两次1.97368，第一次是CombineC的运算结果，第二次就是汇编实现的CombineA的运算结果\n总结 # 这是对x64汇编编程的必要的简要介绍。下一步是浏览《英特尔®64和IA-32架构软件开发人员手册》。第1卷包含体系结构的详细信息，如果您知道汇编的话，这是一个很好的开始。其他地方是汇编书籍或在线汇编教程。为了了解代码的执行方式，指导您在调试器中逐步执行代码，查看反汇编，直到您可以阅读汇编代码以及您喜欢的语言为止，这对您很有帮助。对于C / C ++编译器，调试版本比发行版本更容易阅读，因此请确保从此处开始。最后，阅读masm32.com上的论坛以获取大量材料。\n参考内容 #  原文地址: https://software.intel.com/content/www/us/en/develop/articles/introduction-to-x64-assembly.html NASM: http://www.nasm.us/ YASM: http://www.tortall.net/projects/yasm/ Flat Assembler (FASM): http://www.flatassembler.net/ \u0026ldquo;Intel® 64 and IA-32 Architectures Software Developer\u0026rsquo;s Manuals,\u0026rdquo; available online at http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html \u0026ldquo;Compiler Intrinsics\u0026rdquo;, available online at http://msdn.microsoft.com/en-us/library/26td21ds.aspx Matt Pietrek, \u0026ldquo;Everything You Need To Know To Start Programming 64-Bit Windows Systems\u0026rdquo;, available online at http://msdn.microsoft.com/en-us/magazine/cc300794.aspx, 2009. Intel® 64 and IA-32 Architectures Software Developer Manuals  "}),a.add({id:328,href:"/tags/goconvey/",title:"goconvey",description:"",content:""}),a.add({id:329,href:"/tags/gomonkey/",title:"gomonkey",description:"",content:""}),a.add({id:330,href:"/tags/gostub/",title:"gostub",description:"",content:""}),a.add({id:331,href:"/tags/gotest/",title:"gotest",description:"",content:""}),a.add({id:332,href:"/tags/test/",title:"test",description:"",content:""}),a.add({id:333,href:"/blog/2020-08-19-go%E5%BC%80%E5%8F%91%E5%A6%82%E4%BD%95%E5%81%9A%E6%B5%8B%E8%AF%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/",title:"选择合适的测试框架",description:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。这篇主要总结下常见的测试框架的优缺点。",content:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。这篇主要总结下常见的测试框架的优缺点。\n如何做好测试，是一门系统性的方法学，而不只是一些零零散散的经验。根据测试目的的不同，对测试方法可以作如下分类：\n 稳定性测试 压力测试 回归测试 冒烟测试 性能测试 功能测试 安全测试 可用性测试 \u0026hellip;  这么多的测试方法，最初我还是在填写一项IntelliJ IDEA发起的问卷调查时了解到的，后面在研发过程中也渐渐加深了对这些测试方法的认识。这里面的每一项测试，我认为开发都是应该去了解的。\n很多测试方法是通用的，和具体语言无关，这篇文章只重点关注go开发如何做单元测试。这是每位开发首先应该掌握起来的，它是其他测试得以顺利展开的基础。\n开发在编码阶段，应该在本地完成单测相关的工作，保证测试用例通过，在自动化构建阶段应该有能力执行一些跑单测、BVT测试的任务，通过后才允许提交给测试团队。当然现在EPC实行起来之后，大部分团队都是这么执行的了。\n研发效能要求提升代码库的测试覆盖率，要提高测试的价值，我们得先学些下掌握比较好的测试的方法。\n参考了下go测试的一些实践，业务中肯定会遇到如下这些情况，或多或少：\n 新老服务都有比较多的外部依赖，比如网络调用、读db等 存量服务维护、开发，有些不适合大范围重构的 测试不要侵入业务代码，不能为了测试写太多不相干的东西  go单测中使用的比较多的，大致有如下这些选择， gomock+gostub+gomonkey+goconvey，现在go用的比较多的就是这几个，我比较推荐gomock、gomonkey，看情况，灵活组合使用吧，先总结下这几个的使用方式、优缺点。\n gomock是基于interface的，mockgen生成interface对应的mock桩代码，然后再去写mock代码。 如果前期没这些interface设计的话，也不方便测试。有的话，看起来也不是特别方便。 gostub支持对变量、方法、过程进行mock，但是用上它，存量代码的话就要做些调整，对代码有侵入， 因为它是基于变量去作mock，比如func Hello(\u0026hellip;)要改成var Hello=func(\u0026hellip;)才能用 gomonkey也支持对变量、方法、过程进行mock，我现在感觉这个比较好用，简单，对代码无侵入， 和gostub实现原理不太一样，比如函数，它通过汇编调整跳转地址，这么着对内联函数就支持不到了，就得-gcflags=\u0026ldquo;all=-l\u0026quot;禁用内联 goconvey主要是用来更好地管理测试用例，可以根据情况用或者不用  这里有几篇文章，感兴趣的可以先看下：\n 组合灵活使用，gomock+gostub+gomonkey+goconvey：https://www.jianshu.com/p/2f675d5e334e gomonkey实现原理：https://bouk.co/blog/monkey-patching-in-go/  在深度使用上述几个测试框架之后，个人感觉gomonkey+goconvery组合是比较合适的，goconvey也可以考虑用go testing框架t.Run代替来维护子测试。\n很多同学对开发阶段写单测，多少还是有些抵触的，常见的理由大多是没时间写单测。我的理解是，这里有个因果倒置的问题，写单测的目的并不是为了写而写，写单侧的目的是为了验证你的逻辑或者测试先行驱动逻辑开发，甚至还会为后续的修改保驾护航。\n在开发阶段写单测，客观上会花些时间，但是也会节省频繁提交构建、部署、测试的时间，开发阶段在上述操作中频繁切换的次数会大幅减少。\n我的体验是这样的，仅供参考。\n"}),a.add({id:334,href:"/blog/2020-08-19-go%E5%BC%80%E5%8F%91%E5%A6%82%E4%BD%95%E5%81%9A%E6%B5%8B%E8%AF%95%E8%A1%A8%E9%A9%B1%E5%8A%A8%E6%B5%8B%E8%AF%95/",title:"go开发如何做测试：表驱动测试",description:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。本文转自Dave Cheney的表驱动测试一文，这篇文章写得挺好的。",content:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。本文转自Dave Cheney的表驱动测试一文，这篇文章写得挺好的。\nPrefer table driven tests # I’m a big fan of testing, specifically unit testing and TDD (done correctly, of course). A practice that has grown around Go projects is the idea of a table driven test. This post explores the how and why of writing a table driven test.\nLet’s say we have a function that splits strings:\n// Split slices s into all substrings separated by sep and // returns a slice of the substrings between those separators. func Split(s, sep string) []string { var result []string i := strings.Index(s, sep) for i \u0026gt; -1 { result = append(result, s[:i]) s = s[i+len(sep):] i = strings.Index(s, sep) } return append(result, s) }  In Go, unit tests are just regular Go functions (with a few rules) so we write a unit test for this function starting with a file in the same directory, with the same package name, strings.\npackage split import ( \u0026quot;reflect\u0026quot; \u0026quot;testing\u0026quot; ) func TestSplit(t *testing.T) { got := Split(\u0026quot;a/b/c\u0026quot;, \u0026quot;/\u0026quot;) want := []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;} if !reflect.DeepEqual(want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, want, got) } }  Tests are just regular Go functions with a few rules:\n The name of the test function must start with Test. The test function must take one argument of type *testing.T. A *testing.T is a type injected by the testing package itself, to provide ways to print, skip, and fail the test.  In our test we call Split with some inputs, then compare it to the result we expected.\nCode coverage # The next question is, what is the coverage of this package? Luckily the go tool has a built in branch coverage. We can invoke it like this:\n% go test -coverprofile=c.out PASS coverage: 100.0% of statements ok split 0.010s  Which tells us we have 100% branch coverage, which isn’t really surprising, there’s only one branch in this code.\nIf we want to dig in to the coverage report the go tool has several options to print the coverage report. We can use go tool cover -func to break down the coverage per function:\n% go tool cover -func=c.out split/split.go:8: Split 100.0% total: (statements) 100.0%  Which isn’t that exciting as we only have one function in this package, but I’m sure you’ll find more exciting packages to test.\nSpray some .bashrc on that # This pair of commands is so useful for me I have a shell alias which runs the test coverage and the report in one command:\ncover () { local t=$(mktemp -t cover) go test $COVERFLAGS -coverprofile=$t $@ \\ \u0026amp;\u0026amp; go tool cover -func=$t \\ \u0026amp;\u0026amp; unlink $t }  Going beyond 100% coverage # So, we wrote one test case, got 100% coverage, but this isn’t really the end of the story. We have good branch coverage but we probably need to test some of the boundary conditions. For example, what happens if we try to split it on comma?\nfunc TestSplitWrongSep(t *testing.T) { got := Split(\u0026quot;a/b/c\u0026quot;, \u0026quot;,\u0026quot;) want := []string{\u0026quot;a/b/c\u0026quot;} if !reflect.DeepEqual(want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, want, got) } }  Or, what happens if there are no separators in the source string?\nfunc TestSplitNoSep(t *testing.T) { got := Split(\u0026quot;abc\u0026quot;, \u0026quot;/\u0026quot;) want := []string{\u0026quot;abc\u0026quot;} if !reflect.DeepEqual(want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, want, got) } }  We’re starting build a set of test cases that exercise boundary conditions. This is good.\nIntroducing table driven tests # However the there is a lot of duplication in our tests. For each test case only the input, the expected output, and name of the test case change. Everything else is boilerplate. What we’d like to to set up all the inputs and expected outputs and feel them to a single test harness. This is a great time to introduce table driven testing.\nfunc TestSplit(t *testing.T) { type test struct { input string sep string want []string } tests := []test{ {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, } for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, tc.want, got) } } }  We declare a structure to hold our test inputs and expected outputs. This is our table. The tests structure is usually a local declaration because we want to reuse this name for other tests in this package.\nIn fact, we don’t even need to give the type a name, we can use an anonymous struct literal to reduce the boilerplate like this:\nfunc TestSplit(t *testing.T) { tests := []struct { input string sep string want []string }{ {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, } for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, tc.want, got) } } }  Now, adding a new test is a straight forward matter; simply add another line the tests structure. For example, what will happen if our input string has a trailing separator?\n{input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, // trailing sep  But, when we run go test, we get\n% go test --- FAIL: TestSplit (0.00s) split_test.go:24: expected: [a b c], got: [a b c ]  Putting aside the test failure, there are a few problems to talk about.\nThe first is by rewriting each test from a function to a row in a table we’ve lost the name of the failing test. We added a comment in the test file to call out this case, but we don’t have access to that comment in the go test output.\nThere are a few ways to resolve this. You’ll see a mix of styles in use in Go code bases because the table testing idiom is evolving as people continue to experiment with the form.\nEnumerating test cases # As tests are stored in a slice we can print out the index of the test case in the failure message:\nfunc TestSplit(t *testing.T) { tests := []struct { input string sep . string want []string }{ {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for i, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;test %d: expected: %v, got: %v\u0026quot;, i+1, tc.want, got) } } }  Now when we run go test we get this\n% go test --- FAIL: TestSplit (0.00s) split_test.go:24: test 4: expected: [a b c], got: [a b c ]  Which is a little better. Now we know that the fourth test is failing, although we have to do a little bit of fudging because slice indexing—and range iteration—is zero based. This requires consistency across your test cases; if some use zero base reporting and others use one based, it’s going to be confusing. And, if the list of test cases is long, it could be difficult to count braces to figure out exactly which fixture constitutes test case number four.\nGive your test cases names # Another common pattern is to include a name field in the test fixture.\nfunc TestSplit(t *testing.T) { tests := []struct { name string input string sep string want []string }{ {name: \u0026quot;simple\u0026quot;, input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {name: \u0026quot;wrong sep\u0026quot;, input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {name: \u0026quot;no sep\u0026quot;, input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, {name: \u0026quot;trailing sep\u0026quot;, input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;%s: expected: %v, got: %v\u0026quot;, tc.name, tc.want, got) } } }  Now when the test fails we have a descriptive name for what the test was doing. We no longer have to try to figure it out from the output—also, now have a string we can search on.\n% go test --- FAIL: TestSplit (0.00s) split_test.go:25: trailing sep: expected: [a b c], got: [a b c ]  We can dry this up even more using a map literal syntax:\nfunc TestSplit(t *testing.T) { tests := map[string]struct { input string sep string want []string }{ \u0026quot;simple\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, \u0026quot;wrong sep\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, \u0026quot;no sep\u0026quot;: {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, \u0026quot;trailing sep\u0026quot;: {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for name, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;%s: expected: %v, got: %v\u0026quot;, name, tc.want, got) } } }  Using a map literal syntax we define our test cases not as a slice of structs, but as map of test names to test fixtures. There’s also a side benefit of using a map that is going to potentially improve the utility of our tests.\nMap iteration order is undefined 1 This means each time we run go test, our tests are going to be potentially run in a different order.\nThis is super useful for spotting conditions where test pass when run in statement order, but not otherwise. If you find that happens you probably have some global state that is being mutated by one test with subsequent tests depending on that modification.\nIntroducing sub tests # Before we fix the failing test there are a few other issues to address in our table driven test harness.\nThe first is we’re calling t.Fatalf when one of the test cases fails. This means after the first failing test case we stop testing the other cases. Because test cases are run in an undefined order, if there is a test failure, it would be nice to know if it was the only failure or just the first.\nThe testing package would do this for us if we go to the effort to write out each test case as its own function, but that’s quite verbose. The good news is since Go 1.7 a new feature was added that lets us do this easily for table driven tests. They’re called sub tests.\nfunc TestSplit(t *testing.T) { tests := map[string]struct { input string sep string want []string }{ \u0026quot;simple\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, \u0026quot;wrong sep\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, \u0026quot;no sep\u0026quot;: {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, \u0026quot;trailing sep\u0026quot;: {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for name, tc := range tests { t.Run(name, func(t *testing.T) { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, tc.want, got) } }) } }  As each sub test now has a name we get that name automatically printed out in any test runs.\n% go test --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: [a b c], got: [a b c ]  Each subtest is its own anonymous function, therefore we can use t.Fatalf, t.Skipf, and all the other testing.Thelpers, while retaining the compactness of a table driven test.\nIndividual sub test cases can be executed directly # Because sub tests have a name, you can run a selection of sub tests by name using the go test -run flag.\n% go test -run=.*/trailing -v === RUN TestSplit === RUN TestSplit/trailing_sep --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: [a b c], got: [a b c ]  Comparing what we got with what we wanted # Now we’re ready to fix the test case. Let’s look at the error.\n--- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: [a b c], got: [a b c ]  Can you spot the problem? Clearly the slices are different, that’s what reflect.DeepEqual is upset about. But spotting the actual difference isn’t easy, you have to spot that extra space after c. This might look simple in this simple example, but it is any thing but when you’re comparing two complicated deeply nested gRPC structures.\nWe can improve the output if we switch to the %#v syntax to view the value as a Go(ish) declaration:\ngot := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %#v, got: %#v\u0026quot;, tc.want, got) }  Now when we run our test it’s clear that the problem is there is an extra blank element in the slice.\n% go test --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}, got: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;\u0026quot;}  But before we go to fix our test failure I want to talk a little bit more about choosing the right way to present test failures. Our Split function is simple, it takes a primitive string and returns a slice of strings, but what if it worked with structs, or worse, pointers to structs?\nHere is an example where %#v does not work as well:\nfunc main() { type T struct { I int } x := []*T{{1}, {2}, {3}} y := []*T{{1}, {2}, {4}} fmt.Printf(\u0026quot;%v %v\\n\u0026quot;, x, y) fmt.Printf(\u0026quot;%#v %#v\\n\u0026quot;, x, y) }  The first fmt.Printfprints the unhelpful, but expected slice of addresses; [0xc000096000 0xc000096008 0xc000096010] [0xc000096018 0xc000096020 0xc000096028]. However our %#v version doesn’t fare any better, printing a slice of addresses cast to *main.T;[]*main.T{(*main.T)(0xc000096000), (*main.T)(0xc000096008), (*main.T)(0xc000096010)} []*main.T{(*main.T)(0xc000096018), (*main.T)(0xc000096020), (*main.T)(0xc000096028)}\nBecause of the limitations in using any fmt.Printf verb, I want to introduce the go-cmp library from Google.\nThe goal of the cmp library is it is specifically to compare two values. This is similar to reflect.DeepEqual, but it has more capabilities. Using the cmp pacakge you can, of course, write:\nfunc main() { type T struct { I int } x := []*T{{1}, {2}, {3}} y := []*T{{1}, {2}, {4}} fmt.Println(cmp.Equal(x, y)) // false }  But far more useful for us with our test function is the cmp.Diff function which will produce a textual description of what is different between the two values, recursively.\nfunc main() { type T struct { I int } x := []*T{{1}, {2}, {3}} y := []*T{{1}, {2}, {4}} diff := cmp.Diff(x, y) fmt.Printf(diff) }  Which instead produces:\n% go run {[]*main.T}[2].I: -: 3 +: 4  Telling us that at element 2 of the slice of Ts the Ifield was expected to be 3, but was actually 4.\nPutting this all together we have our table driven go-cmp test\nfunc TestSplit(t *testing.T) { tests := map[string]struct { input string sep string want []string }{ \u0026quot;simple\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, \u0026quot;wrong sep\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, \u0026quot;no sep\u0026quot;: {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, \u0026quot;trailing sep\u0026quot;: {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for name, tc := range tests { t.Run(name, func(t *testing.T) { got := Split(tc.input, tc.sep) diff := cmp.Diff(tc.want, got) if diff != \u0026quot;\u0026quot; { t.Fatalf(diff) } }) } }  Running this we get\n% go test --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:27: {[]string}[?-\u0026gt;3]: -: \u0026lt;non-existent\u0026gt; +: \u0026quot;\u0026quot; FAIL exit status 1 FAIL split 0.006s  Using cmp.Diff our test harness isn’t just telling us that what we got and what we wanted were different. Our test is telling us that the strings are different lengths, the third index in the fixture shouldn’t exist, but the actual output we got an empty string, “”. From here fixing the test failure is straight forward.\n Please don’t email me to argue that map iteration order is random. It’s not.  Related Posts: #  Writing table driven tests in Go Internets of Interest #7: Ian Cooper on Test Driven Development Automatically run your package’s tests with inotifywait How to write benchmarks in Go  This entry was posted in Go, Programming and tagged testing, unit test on May 7, 2019.\n"}),a.add({id:335,href:"/tags/life/",title:"life",description:"",content:""}),a.add({id:336,href:"/blog/2020-08-13-%E9%AA%91%E8%87%AA%E8%A1%8C%E8%BD%A6%E4%B8%80%E7%82%B9%E9%83%BD%E4%B8%8D%E8%88%92%E6%9C%8D%E4%BD%86%E6%98%AF%E5%BE%88%E7%88%BD/",title:"骑自行车一点都不舒服，但是很爽",description:'/* Three image containers (use 25% for four, and 50% for two, etc) */ .column { float: left; width: 50%; padding: 5px; } /* Clear floats after image containers */ .row::after { content: ""; clear: both; display: table; } .fixsize { width: 340px; height: 280px; } .fullsize { width: 680px; }  19年5月底，时长感觉身体疲倦，想锻炼下身体，我想买辆自行车骑着上班。左看右看，还是想买一辆公路赛自行车，太享受那种“破风”的感觉了。左看右看，看上了Giant OCR 5700，买的时候这两自行车已经几近停产了，但是因为它黑白色的涂装，实在是太招人喜欢了，简单又不失美感。几乎没什么犹豫的，就买了一辆，然后几天之后收到车，自己组装完毕，满心欢喜。\n将其立在落地窗边，忍不住这么看那么看，真的是太漂亮了，这里还保留了一张刚开始组装好后的照片。\n其实，这并不是我买的第一辆公路赛自行车，本科读书时，就买了一辆，那时候下课没事、周末的时候，就喜欢骑车去跑个环海路、逛逛这座小城、探探周边的校园，很是惬意。直到现在，我还依稀记得沿着环海路骑行时的场景，那扑面而来带着点腥味的海风，那静谧又干净的大马路，那一望无边的大海，听着海浪拍打着海滩、岩石，吹着海风，就这么走啊走，真想一直这么走下去……\n   读研究生时，又买了一辆，时不时就围着学校、九眼桥、大熊猫繁育基地等周边地方来一圈。成都市区热闹非凡，交通也堵，骑着车从图书馆附近的东门窜出，到九眼桥听听急流的水声，感受下那股潮湿的新鲜，心情就会很舒畅。这辆车骑了没多久，被小偷偷走了，那几年真的是不停地换自行车，买了丢丢了买。随着共享单车的兴起，我想学校周边的小偷们应该没什么可偷的了吧。\n   为什么几番买公路赛自行车呢？看它的造型，每个男同学应该都会喜欢它线条中透出的那股动感吧！另外，和我的性格也有关系，我比较喜欢独行。骑上它，想去哪就去哪，不用担心堵车，不用担心错过公交、地铁，骑行在大街小巷、公园绿道等等，就尽情享受和自然融为一体的那种快感吧。骑车一时爽，一直骑车一直爽，哈哈！\n骑车虽然有时候不太舒服，但是爽还是挺爽的。现在我每天从宝安体育馆附近出发，到腾讯万利达大厦上班，沿途9公里左右，交通状况好的话大概25分钟左右能到。如果是交通不好的情况呢，多等上几个红绿灯，那可能要40分钟左右。我们中心下班有点晚，很多时候都是11点左右才下班，有的时候走到半夜之后的也不少。那么晚了，相比打车，我还是愿意骑车回家。那种被汗水浸透、长时间带来的身体素质的提升、想冲就能冲的体能，让整个人都会很兴奋，心情也好。所以，尽管那么晚了，我还是选择骑车回家。当然，这里是深圳，深圳的夜晚灯火通明……\n附上两个上班、下班路上的视频，哦，对了，配上一副好的蓝牙耳机，会更让你获得骑行的乐趣。我用的是韶音 Aftershokz AS 650，这是一款骨传导耳机，可以让你在路上感知到周边环境的重要声音，比如骑车喇叭声等等，完全入耳的设计在这种场景下有点不安全。最开始有个同学觉得，1200块钱买这个”音质”的耳机有点不值，嗯，我追求的不是音质，我想要的是感觉（追求音质我有BOSE）……PS，Aftershokz AS 650之前丢了一个，现在已经是第二个了。',content:'/* Three image containers (use 25% for four, and 50% for two, etc) */ .column { float: left; width: 50%; padding: 5px; } /* Clear floats after image containers */ .row::after { content: ""; clear: both; display: table; } .fixsize { width: 340px; height: 280px; } .fullsize { width: 680px; }  19年5月底，时长感觉身体疲倦，想锻炼下身体，我想买辆自行车骑着上班。左看右看，还是想买一辆公路赛自行车，太享受那种“破风”的感觉了。左看右看，看上了Giant OCR 5700，买的时候这两自行车已经几近停产了，但是因为它黑白色的涂装，实在是太招人喜欢了，简单又不失美感。几乎没什么犹豫的，就买了一辆，然后几天之后收到车，自己组装完毕，满心欢喜。\n将其立在落地窗边，忍不住这么看那么看，真的是太漂亮了，这里还保留了一张刚开始组装好后的照片。\n其实，这并不是我买的第一辆公路赛自行车，本科读书时，就买了一辆，那时候下课没事、周末的时候，就喜欢骑车去跑个环海路、逛逛这座小城、探探周边的校园，很是惬意。直到现在，我还依稀记得沿着环海路骑行时的场景，那扑面而来带着点腥味的海风，那静谧又干净的大马路，那一望无边的大海，听着海浪拍打着海滩、岩石，吹着海风，就这么走啊走，真想一直这么走下去……\n   读研究生时，又买了一辆，时不时就围着学校、九眼桥、大熊猫繁育基地等周边地方来一圈。成都市区热闹非凡，交通也堵，骑着车从图书馆附近的东门窜出，到九眼桥听听急流的水声，感受下那股潮湿的新鲜，心情就会很舒畅。这辆车骑了没多久，被小偷偷走了，那几年真的是不停地换自行车，买了丢丢了买。随着共享单车的兴起，我想学校周边的小偷们应该没什么可偷的了吧。\n   为什么几番买公路赛自行车呢？看它的造型，每个男同学应该都会喜欢它线条中透出的那股动感吧！另外，和我的性格也有关系，我比较喜欢独行。骑上它，想去哪就去哪，不用担心堵车，不用担心错过公交、地铁，骑行在大街小巷、公园绿道等等，就尽情享受和自然融为一体的那种快感吧。骑车一时爽，一直骑车一直爽，哈哈！\n骑车虽然有时候不太舒服，但是爽还是挺爽的。现在我每天从宝安体育馆附近出发，到腾讯万利达大厦上班，沿途9公里左右，交通状况好的话大概25分钟左右能到。如果是交通不好的情况呢，多等上几个红绿灯，那可能要40分钟左右。我们中心下班有点晚，很多时候都是11点左右才下班，有的时候走到半夜之后的也不少。那么晚了，相比打车，我还是愿意骑车回家。那种被汗水浸透、长时间带来的身体素质的提升、想冲就能冲的体能，让整个人都会很兴奋，心情也好。所以，尽管那么晚了，我还是选择骑车回家。当然，这里是深圳，深圳的夜晚灯火通明……\n附上两个上班、下班路上的视频，哦，对了，配上一副好的蓝牙耳机，会更让你获得骑行的乐趣。我用的是韶音 Aftershokz AS 650，这是一款骨传导耳机，可以让你在路上感知到周边环境的重要声音，比如骑车喇叭声等等，完全入耳的设计在这种场景下有点不安全。最开始有个同学觉得，1200块钱买这个”音质”的耳机有点不值，嗯，我追求的不是音质，我想要的是感觉（追求音质我有BOSE）……PS，Aftershokz AS 650之前丢了一个，现在已经是第二个了。\n附上上下班路上的两个视频，感受一下骑行带来的快感：\n     '}),a.add({id:337,href:"/tags/alfred/",title:"alfred",description:"",content:""}),a.add({id:338,href:"/tags/awgo/",title:"awgo",description:"",content:""}),a.add({id:339,href:"/tags/workflow/",title:"workflow",description:"",content:""}),a.add({id:340,href:"/blog/2020-07-31-%E4%BD%BF%E7%94%A8awgo%E5%BC%80%E5%8F%91alfred.workflow/",title:"使用awgo开发alfred.workflow",description:"Alfred是macOS下非常方便的一款效率工具，它集成了很多功能，包括websearch、snippets、workflow等等，本文讲述的就是如何借助开发workflow来提效。本文以一个简单的datex命令实现时间戳、字符串之间的转换功能为例，介绍下如何开发workflow。",content:" img { width: 680px; }  本文简介 # 该workflow主要是为了对 \u0026ldquo;时间戳\u0026rdquo; \u0026amp;\u0026amp; \u0026ldquo;格式化日期+时间字符串\u0026rdquo; 进行快速转换，方便使用。\n开发人员，经常会涉及到时间相关的转换操作，有个趁手的工具还是很有必要的。\n我平时使用alfred比较多，自然就想通过workflow的方式来实现，当然用hammerspoon、pet等其他工具也可以。\nalfred workflow和alfred本身的交互是通过管道方式进行连接的：\n alfred将用户输入的信息转发给匹配的workflow； workflow对接收到的参数进行处理，并将处理的结果按照指定格式输出到stdout； alfred读取stdout中的数据作为响应展示到用户界面；  这里主要使用了awgo来编写workflow，实现逻辑可以参考下代码，逻辑很简单。下面主要介绍下如何使用。\n如何安装？ # 下载项目下 workflow/Date Formats Go.alfredworkflow，双击即可安装。\n如何使用？ #   运行 datex 唤起workflow\n  常用转换操作: 获取当前时间对应的Unix时间戳，以及格式化字符串\ndatex now，将当前时间转换为时间戳以及格式化后的字符串(多种日期格式)。\n可以用上下键移动进行选择，当按下回车键时，会将对应的结果拷贝到剪贴板，方便粘贴使用。   常用转换操作: 将时间戳转换为对应的格式化字符串\n以时间戳1596137272为例，datex 1596137272，此时会将时间戳转换为格式化后的字符串。\n选择、复制数据操作类似。   常用转换操作: 将格式化字符串转换为时间戳，或其他格式\n以字符串2020-07-30为例，datex 2020-07-30，此时会先将其与候选的格式化字符串进行匹配。\n并转换成一个有效的时间戳。 然后再根据此时间戳，转换为其他格式对应的字符串。选择、复制数据操作类似。   这大致就是该workflow的使用方式。\n关于日期时间格式转换的workflow，github上已经有几个比较好的实现了，轮子不好用就得自己造。\n 实现对timezone支持不好; 采用的时间格式不符合国人习惯; 掌握awgo开发alfred workflow以后可以写更多效率工具;  希望这个小工具能帮助到有需要的同学，也给准备开发alfred workflow或使用awgo开发workflow的同学提供一个示例。\n如何实现？ # 流程图梳理下逻辑 # 先画个流程图，简单理下思路，思路理清楚了，写代码就快了。\nalfred.workflow编排 # 好，理清楚思路之后，我们开始尝试对worklow进行编排，如下所示：\nworkflow中包含2个节点：\n  节点1，是一个script filter，我们可以配置一个关键字datex来激活它，当然还可以继续输入参数。激活该script filter之后，它将调用我们编写的时间转换程序alfred-datetime-workflow，程序返回的结果将在alfred界面上进行展示，展示的样式是列表。如我们输入datex now，将显示现在的时间戳以及其他格式的datetime字符串。\n  节点2，是Copy to Clipboard，它干什么呢？节点1中显示了列表之后，用户选择一个列表项+回车之后，选中的列表项对应的参数值将被传递给该节点作为参数，Copy to Clipboard就是将参数拷贝到剪贴板；\n   如果希望在workflow各节点中传递参数，则可以通过 workflow.Var(envname, value) 来设置变量，通过 workflow.Config.Get${Type}(envname) 来获取变量。\n 好的，下面来看下这里的时间转换程序怎么写，怎么与alfred衔接起来。\nalfred.workflow时间转换程序 # 这里的时间转换程序，可以是任意语言编写构建的二进制程序，也可以是shell脚本，都可以，只要能解析alfred传递的输入参数、返回alfred指定格式的结果就可以。awgo这个库简化了和alfred交互的部分，我们用这个库主要是简化和alfred数据格式的衔接。\n主体逻辑很简单，实例化awgo.Workflow，然后注册回调函数，等待用户输入后唤醒执行。这里的回调函数，就是这里的run方法，在该方法内部完成时间的转换逻辑即可。\npackage main import ( aw \u0026quot;github.com/deanishe/awgo\u0026quot; ) func main() { workflow = aw.New() workflow.Run(run) }  实现时间转换逻辑 # 前面我们给出的流程图，大部分是run方法的逻辑，照着流程图来写代码逻辑，基本上一遍完成。so easy!\npackage main import ( ... aw \u0026quot;github.com/deanishe/awgo\u0026quot; ) var ( workflow *aw.Workflow icon = \u0026amp;aw.Icon{ Value: aw.IconClock.Value, Type: aw.IconClock.Type, } layouts = []string{ \u0026quot;2006-01-02 15:04:05.999 MST\u0026quot;, \u0026quot;2006-01-02 15:04:05.999 -0700\u0026quot;, time.RFC3339, time.RFC3339Nano, time.UnixDate, time.RubyDate, time.RFC1123Z, } moreLayouts = []string{ \u0026quot;2006-01-02\u0026quot;, \u0026quot;2006-01-02 15:04\u0026quot;, \u0026quot;2006-01-02 15:04:05\u0026quot;, \u0026quot;2006-01-02 15:04:05.999\u0026quot;, } regexpTimestamp = regexp.MustCompile(`^[1-9]{1}\\d+$`) ) func run() { var err error args := workflow.Args() if len(args) == 0 { return } defer func() { if err == nil { workflow.SendFeedback() return } }() // 处理 now input := strings.Join(args, \u0026quot; \u0026quot;) if input == \u0026quot;now\u0026quot; { processNow() return } // 处理时间戳 if regexpTimestamp.MatchString(input) { v, e := strconv.ParseInt(args[0], 10, 32) if e == nil { processTimestamp(time.Unix(v, 0)) return } err = e return } // 处理时间字符串 err = processTimeStr(input) } func processNow() { now := time.Now() // prepend unix timestamp secs := fmt.Sprintf(\u0026quot;%d\u0026quot;, now.Unix()) workflow.NewItem(secs). Subtitle(\u0026quot;unix timestamp\u0026quot;). Icon(icon). Arg(secs). Valid(true) // process all time layouts processTimestamp(now) } // process all time layouts func processTimestamp(timestamp time.Time) { for _, layout := range layouts { v := timestamp.Format(layout) workflow.NewItem(v). Subtitle(layout). Icon(icon). Arg(v). Valid(true) } } func processTimeStr(timestr string) error { timestamp := time.Time{} layoutMatch := \u0026quot;\u0026quot; layoutMatch, timestamp, ok := matchedLayout(layouts, timestr) if !ok { layoutMatch, timestamp, ok = matchedLayout(moreLayouts, timestr) if !ok { return errors.New(\u0026quot;no matched time layout found\u0026quot;) } } // prepend unix timestamp secs := fmt.Sprintf(\u0026quot;%d\u0026quot;, timestamp.Unix()) workflow.NewItem(secs). Subtitle(\u0026quot;unix timestamp\u0026quot;). Icon(icon). Arg(secs). Valid(true) // other time layouts for _, layout := range layouts { if layout == layoutMatch { continue } v := timestamp.Format(layout) workflow.NewItem(v). Subtitle(layout). Icon(icon). Arg(v). Valid(true) } return nil } func matchedLayout(layouts []string, timestr string) (matched string, timestamp time.Time, ok bool) { for _, layout := range layouts { v, err := time.Parse(layout, timestr) if err == nil { return layout, v, true } } return }  导出alfred.workflow # 开发、测试、验证，一切ok之后，就可以在alfred内部将workflow整个导出了，导出后的文件以*.alfredworkflow作为扩展名，这个文件是可以拿来分发的文件，使用者直接双击就可以安装使用。\nawgo试用小结 # 这是使用awgo编写的第一个workflow程序，整体感觉来说，开发者可以专注于功能的实现，不用过度关注alfred数据格式方面的问题。\nalfred本身很强大，支持各种各样的workflow算子，awgo到底能支持到什么程度，这个还要在后续使用中逐渐探索。\n感兴趣的话，不妨一试，至少比写apple script脚本、bash脚本等要方便多了。\n"}),a.add({id:341,href:"/tags/bindata/",title:"bindata",description:"",content:""}),a.add({id:342,href:"/blog/2020-07-25-%E5%A6%82%E4%BD%95%E5%9C%A8go%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%A8%8B%E5%BA%8F%E4%B8%AD%E6%89%93%E5%8C%85%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6/",title:"如何在go二进制程序中打包静态资源文件",description:"如何在go程序里面打包一些静态资源文件呢，然后方便在程序里面使用它？今天介绍一种方案。",content:"Why? # 有时我们希望在go二进制程序中打包一些静态资源文件，目的可能有多种，比较常见的是为了简化安装。通常我们安装一个go编写的工具，更倾向于使用 go get $repo 的方式来完成，这似乎已经成为了一种共识。当然，也有些项目还依赖一些静态资源文件，这些静态资源文件是不会被自动安装的，就需要借助其他方式来完成静态资源的安装，比如通过install.sh脚本，后者Makefile构建脚本等等。\n今天，我想讨论下，如何简单快速地支持静态资源打包到二进制程序中，以及在二进制程序中对这些静态资源加以引用。\nHow? # github上已经有不少开发者在探索，方法其实都比较雷同，大致思路就是：\n 读取静态资源文件，转换成bytes数据； 内部提供一些类似文件系统的接口，提供文件名，返回文件数据； blabla\u0026hellip;  开发者的需求，可能不完全一致，比如：\n 我想像遍历本地文件系统一样遍历文件目录，不只是提供一个文件名返回一个文件； 我的代码已经写完了，我只想做最小修改，将静态资源文件打包到二进制程序中，而后还原回文件系统； 我的代码不需要支持类似文件服务器的功能，不需要那么多华丽呼哨的功能；  开发者提供了很多类似的实现，这里有篇文章可供参考：https://tech.townsourced.com/post/embedding-static-files-in-go/。能工模形，巧匠窃意。其实在大致了解了实现的方式之后，就懒得再去学如何使用这些五花八门的第三方工具了。说真的，真的没几个好用的，至少从我的角度来说。可能它设计的比较通用，但是与我来说没有用处，我追求极简。\n而且，go官方是有意来支持打包静态资源的，关于这一点，已经有issue在跟进讨论：https://github.com/golang/go/issues/35950。\n尽管现在的状态还是Proposal-Hold状态，但是我觉得这个feature的到来也不会等很久了，anyway，我不想在这些即将被淘汰的三方工具上浪费学习的时间、改写代码的时间。\n所以呢，为什么不简单一点，自己写一个当下比较适用项目本身的？写这个东西花不了二十分钟时间！\nLet\u0026rsquo;s Do it! # 功能分析 # 我理解实现打包静态资源文件，有这么几个点需要考虑：\n 提供一个小工具，通过它可以反复执行类似的静态资源打包的操作； 可以指定一个文件或者目录，将其转换成一个go文件放入项目中，允许编译时连接； go文件可以通过导出变量的形式，导出文件数据，允许在其他go代码中引用文件的内容； 静态资源文件可能有很多，希望能对文件内容进行压缩，以便减小go binary文件尺寸； 通常是本地组织好静态资源文件，写代码、测试ok、最后发布前希望将其打包到go binary，打包、解包、使用静态资源要最小化项目代码修改；  功能实现 # 我们先实现这个打包静态资源的工具，需要这几个参数：input、output，分别代表输入文件（or 目录）、输出文件名（go文件），gopkg代表输出go文件的包名（默认gobin）。\npackage main var ( input = flag.String(\u0026quot;input\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;read data from input, which could be a regular file or directory\u0026quot;) output = flag.String(\u0026quot;output\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;write transformed data to named *.go, which could be linked with binary\u0026quot;) gopkg = flag.String(\u0026quot;gopkg\u0026quot;, \u0026quot;gobin\u0026quot;, \u0026quot;write transformed data to *.go, whose package is $package\u0026quot;) )  我们的工具将从input对应的文件中读取文件内容，并转换成一个output对应的go文件中的导出变量。如果input是一个目录呢，我们则需要对目录下文件进行遍历处理。由于静态资源文件数据可能较大，这里需要进行gzip压缩（对于文本压缩率可高达80%左右）有助于减少go binary文件尺寸。\n那读取到文件内容之后，如何将其转换成go文件中的导出变量呢？很简单，我们定义一个go模板，将读取到的文件内容gzip压缩后转换成bytes数组传递给模板引擎就可以了。模板中的{{.GoPackage}}将引用命令选项$gopkg的值，{{.Variable}}即为导出变量的值，这里我们会使用选项$input对应的CamelCase转换之后的文件名（或目录名），{{.Data}}即为gzip压缩后的文件数据。\nvar tpl = `package {{.GoPackage}} var {{.Variable}} = []uint8{ {{ range $idx, $val := .Data }}{{$val}},{{ end }} }`  接下来，我们看下怎么读取文件的内容，再强调下，要读取的内容可能是单个文件，也可能是一个目录。\n// ReadFromInputSource 从输入读取内容，可以是一个文件，也可以是一个目录（会先gzip压缩然后再返回内容） func ReadFromInputSource(inputSource string) (data []byte, err error) { _, err := os.Lstat(inputSource) if err != nil { return nil, err } buf := bytes.Buffer{} err = compress.Tar(inputSource, \u0026amp;buf) if err != nil { return nil, err } return buf.Bytes(), nil }  gzip对文件数据进行压缩，篇幅原因，这里只贴个链接地址，感兴趣的可以自行查看：https://github.com/hitzhangjie/codemaster/blob/master/compress/compress.go。\n好，现在我们将这个打包工具的完整逻辑再完整梳理一下。\nfunc main() { // 输入输出参数校验 if len(*input) == 0 || len(*gopkg) == 0 { fmt.Println(\u0026quot;invalid argument: invalid input\u0026quot;) os.Exit(1) } // 读取输入内容 buf, err := ReadFromInputSource(*input) if err != nil { fmt.Errorf(\u0026quot;read data error: %v\\n\u0026quot;, err) os.Exit(1) } // 将内容转换成go文件写出 inputBaseName := filepath.Base(*input) if len(*output) == 0 { *output = fmt.Sprintf(\u0026quot;%s_bindata.go\u0026quot;, inputBaseName) } outputDir, outputBaseName := filepath.Split(*output) tplInstance, err := template.New(outputBaseName).Parse(tpl) if err != nil { fmt.Printf(\u0026quot;parse template error: %v\\n\u0026quot;, err) os.Exit(1) } _ = os.MkdirAll(outputDir, 0777) fout, err := os.OpenFile(*output, os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0666) if err != nil { fmt.Printf(\u0026quot;open input error: %v\u0026quot;, err) os.Exit(1) } err = tplInstance.Execute(fout, \u0026amp;struct { GoPackage string Variable string Data []uint8 }{ GoPackage: *gopkg, Variable: strcase.ToCamel(outputBaseName), Data: buf, }) if err != nil { panic(fmt.Errorf(\u0026quot;template execute error: %v\u0026quot;, err)) } fmt.Printf(\u0026quot;ok, filedata stored to %s\\n\u0026quot;, *output) }  下面我们演示下如何使用这个工具来对静态资源打包。\n假定存在如下静态资源目录static，其下包含了多个文件，现在我想将其全部打包到一个go文件中。\n$ tree . . |- static |- file1.txt |- file2.txt |- file3.txt  运行 go build -v bindata 编译我们之前写的工具，然后运行 bindata -input=path/to/static -output=goin/static.go -gopkg=gobin。\n$ tree . . |- static |- file1.txt |- file2.txt |- file3.txt |- gobin |- static.go  我们看到当前目录下多生成了一个gobin目录，其下多了个go文件static.go，查看下文件内容：\n$ cat gobin/static.go package gobin var StaticGo = []uint8{ 31,139,8,0,0,0,0,0,0,255,236,213,193,10,194,48,12,128,225,158,125,138,62,129,36,77,219,60,79,15,171,171,136,7,91,65,124,122,105,39,131,29,244,182,58,89,190,75,24,140,209,145,253,44,166,203,128,199,242,40,106,61,0,0,222,218,54,217,187,54,193,76,215,13,178,66,98,240,236,25,136,21,32,121,100,165,97,197,51,205,238,185,132,155,2,120,142,225,122,58,167,225,211,125,185,132,24,191,60,231,253,42,243,252,19,101,76,89,167,172,235,119,160,241,240,235,227,136,206,234,222,205,150,250,183,78,250,239,104,209,191,145,254,247,166,238,157,182,212,191,155,254,255,134,164,255,30,22,253,147,244,47,132,16,123,241,10,0,0,255,255,106,242,211,179,0,16,0,0, }  哈哈，现在看到static目录及其下的文件已经被完整打包到一个go文件中了，且通过导出变量进行了导出，后续使用的时候，可以先将其还原到本地文件系统，以前已经写好的代码不用做任何修改，怎么还原到本地文件系统呢，并使用呢？\n// 在你需要引用这些静态资源的package中释放这些静态资源文件到本地文件系统 func init() { compress.UnTar(path/to/static, bytes.NewBuffer(gobin.StaticGo)) val := config.Read(path/to/static/file1.go, \u0026quot;section\u0026quot;, \u0026quot;property\u0026quot;, defaultValue) ... }  现在，是不是感觉超级简单呢？:)\n"}),a.add({id:343,href:"/tags/cache/",title:"cache",description:"",content:""}),a.add({id:344,href:"/tags/cc++/",title:"cc++",description:"",content:""}),a.add({id:345,href:"/blog/2019-01-07-%E4%BD%A0%E4%B8%8D%E8%AE%A4%E8%AF%86%E7%9A%84cc-volatile/",title:"你不认识的cc++ volatile",description:"学习c语言时初始volatile，学习java时认识了不一样的volatile，但是对它们的理解还是没那么详细。后台来有次学习Linux内核时读到了torvalds关于使用volatile可能潜藏了隐患的评论，开始重视并深入学习了这个问题……有一次参加中心的技术分享听到大佬降到volatile可以解决线程可见性问题，我顿时感觉不太对吧，但是作为一个新人……后面几番求证之后，终于发现大佬们认识也不到位啊，这个问题其实要把别人真的讲明白牵扯的知识还挺多挺细的，希望对感兴趣同学有帮助。",content:" img { width: 680px; }  1. 令人困惑的volatile # volatile字面意思是“不稳定的、易变的”，不少编程语言中存在volatile关键字，也有共同之处，如“表示程序执行期间数据可能会被外部操作修改”，如被外设修改或者被其他线程修改等。这只是字面上给我们的一般性认识，然而具体到不同的编程语言中volatile的语义可能相差甚远。\n很多人以为自己精通CC++，但是被问起volatile的时候却无法清晰、果断地表明态度，那只能说明还是处在“从入门到精通”的路上，如果了解一门语言常见特性的使用、能够写健壮高效的程序就算精通的话，那实在是太藐视“大师”的存在了。从一个volatile关键字折射出了对CC++标准、编译器、操作系统、处理器、MMU各个方面的掌握程度。\n几十年的发展，很多开发者因为自己的偏见、误解，或者对某些语言特性（如Java中的volatile语义）的根深蒂固的认识，赋予了CC++ volatile本不属于它的能力，自己却浑然不知自己犯了多大的一个错误。\n我曾经以为CC++中volatile可以保证线程可见性，因为Java中是这样的，直到后来阅读Linux内核看到Linus Torvards的一篇文档，他强调了volatile可能带来的坏处“任何使用volatile的地方，都可能潜藏了一个bug”，我为他的“危言耸听”感到吃惊，所以我当时搜索了不少资料来求证CC++ volatile的能力，事后我认为CC++ volatile不能保证线程可见性。但是后来部门内一次分享，分享中提到了volatile来保证线程可见性，我当时心存疑虑，事后验证时犯了一个错误导致我错误地认为volatile可以保证线程可见性。直到我最近翻阅以前的笔记，翻到了几年前对volatile的疑虑……我决定深入研究下这个问题，以便能顺利入眠。\n2. 从规范认识volatile # 以常见的编程语言C、C++、Java为例，它们都有一个关键字volatile，但是对volatile的定义却并非完全相同。\n  Java中对volatile的定义：\n 8.3.1.4. volatile Fields\nThe Java programming language allows threads to access shared variables (§17.1). As a rule, to ensure that shared variables are consistently and reliably updated, a thread should ensure that it has exclusive use of such variables by obtaining a lock that, conventionally, enforces mutual exclusion for those shared variables.\nThe Java programming language provides a second mechanism, volatile fields, that is more convenient than locking for some purposes.\nA field may be declared volatile, in which case the Java Memory Model ensures that all threads see a consistent value for the variable (§17.4).\n Java清晰地表达了这样一个观点，Java内存模型中会保证volatile变量的线程可见性，接触过Java并发编程的开发者应该都清楚，这是一个不争的事实。\n  CC++中对volatile的定义：\n 6.7.3 Type qualifiers\nvolatile: No cacheing through this lvalue: each operation in the abstract semantics must be performed (that is, no cacheing assumptions may be made, since the location is not guaranteed to contain any previous value). In the absence of this qualifier, the contents of the designated location may be assumed to be unchanged except for possible aliasing.\n C99中也清晰地表名了volatile的语义，不要做cache之类的优化。这里的cache指的是software cacheing，即编译器生成指令将内存数据缓存到cpu寄存器，后续访问内存变量使用寄存器中的值；需要与之作出区分的是hardware cacheing，即cpu访问内存时将内存数据缓存到cpu cache，硬件操作完全对上层应用程序透明。大家请将这两个点铭记在心，要想搞清楚CC++ volatile必须要先理解这里cache的区别。\nC99清晰吗？上述解释看上去很清晰，但是要想彻底理解volatile的语义，绝非上述一句话就可以讲得清的，C99中定义了abstract machine以及sequence points，与volatile相关的描述有多处，篇幅原因这里就不一一列举了，其中与volatile相关的abstract machine行为描述共同确定了volatile的语义。\n  3. 对volatile持何观点 # 为了引起大家对CC++ volatile的重视并及时表明观点，先贴一个页面“Is-Volatile-Useful-with-Threads”，网站中简明扼要的告知大家，“Friends don’t let friends use volatile for inter-thread communication in C and C++”。But why？\nisocpp专门挂了这么个页面来强调volatile在不同编程语言中的差异，可见它是一个多么难缠的问题。即便是有这么个页面，要彻底搞清楚volatile，也不是说读完上面列出的几个技术博客就能解决，那也太轻描淡写了，所以我搜索、整理、讨论，希望能将学到的内容总结下来供其他开发者参考，我也不想再因为这个问题而困扰。\n结合CC++ volatile qualifier以及abstract machine中对volatile相关sequence points的描述，可以确定volatile的语义：\n 不可优化性：不要做任何软件cache之类的优化，即多次访问内存对象时，编译器不能优化为cache内存对象到寄存器、后续访问内存对象转为访问寄存器 [6.7.3 Type qualifiers - volatile]； 顺序性：对volatile变量的多次读写操作，编译器不能以预测数据不变为借口优化掉读写操作，并且要保证前面的读写操作先于后面的读写操作完成 [5.1.2.3 Program execution]； 易变性：从不可优化性、顺序性语义要求，不难体会出其隐含着数据“易变性”，这也是volatile字面上的意思，也是不少开发者学习volatile时最熟知的语义；  CC++规范没有显示要求volatile支持线程可见性，gcc也没有在标准允许的空间内做什么“发挥”去安插什么保证线程可见性的处理器指令（Java中volatile会使用lock指令使其他处理器cache失效强制读内存保证线程可见性）。而关于CPU cache一致性协议，x86原先采用MESI协议，后改用效率更高的MESIF，都是强一致性协议，在x86这等支持强一致的CPU上，CC++中结合volatile是可以“获得”线程可见性的，在非强一致CPU上则不然。\n但是CC++ volatile确实是有价值的，很多地方都要使用它，而且不少场景下似乎没有比它更简单的替代方法，下面首先列举CC++ volatile的通用适用场景，方便大家认识volatile，然后我们再研究为什么CC++ volatile不能保证线程可见性。CC++标准中确实没有说volatile要支持线程可见性，大家可以选择就此打住，但是我怀疑的是gcc在标准允许的空间内是怎么做的？操作系统、MMU、处理器是怎么做的？“标准中没有显示列出”，这样的理由还不足以让我停下探索的脚步。\n4. CC++ need volatile # CC++ volatile语义“不可优化型”、“顺序性”、“易变性”，如何直观感受它的价值呢？看C99中给出的适用场景吧。\n  setjmp、longjmp用于实现函数内、函数间跳转（goto只能在函数内跳转），C Spec规定longjmp之后希望跳到的栈帧中的局部变量的值是最新值，而不是setjmp时的值，考虑编译器可能作出一些优化，将auto变量cache到寄存器中，假如setjmp保存硬件上下文的时候恰巧保存了存有该局部变量值的寄存器信息，等longjmp回来的时候就用了旧值。这违背了C Spec的规定，所以这个时候可以使用volatile来避免编译器优化，满足C Spec！\n  signal handler用于处理进程捕获到的信号，与setjmp、longjmp类似，进程捕获、处理信号时需要保存当前上下文再去处理信号，信号处理完成再恢复上下文继续执行。信号处理函数中也可能会修改某些共享变量，假如共享变量在收到信号时加载到了寄存器，并且保存硬件上下文时也保存起来了，那么信号处理函数执行完毕返回（可能会修改该变量）恢复上下文后，访问到的还是旧值。因此将信号处理函数中要修改的共享变量声明为volatile是必要的。\n  设备驱动、Memory-Mapped IO、DMA。 我们先看一个示例，假如不使用volatile，编译器会做什么。编译器生成代码可能会将内存变量sum、i放在寄存器中，循环执行过程中，编译器可能认为这个循环可以直接优化掉，sum直接得到了最终的a[0]+a[1]+…a[N]的值，循环体执行次数大大减少。\nsum = 0; for (i=0; i\u0026lt;N; ++i) sum += a[i];  这种优化对于面向硬件的程序开发（如设备驱动开发、内存映射IO）来说有点过头了，而且会导致错误的行为。下面的代码使用了volatile qualifer，其他与上述代码基本相同。如果不存在volatile修饰，编译器会认为最终*ttyport的值就是a[N-1]，前N-1次赋值都是没必要的，所以直接优化成*ttyport = a[N-1]。但是ttyport是外设的设备端口通过内存映射IO得到的虚拟内存地址，编译器发现存在volatile修饰，便不会对循环体中*ttyport = a[i]进行优化，循环体会执行N次赋值，且保证每次赋值操作都与前一次、后一次赋值存在严格的顺序性保证。\nvolatile short *ttyport; for (i=0; i\u0026lt;N; ++i) *ttyport = a[i];  可能大家会有疑问，volatile只是避免编译器将内存变量存储到寄存器，对cpu cache却束手无策，谁能保证每次对*ttyport的写操作都确定写回内存了呢？这里就涉及到cpu cache policy问题了。\n对于外设IO而言，有两种常用方式：\n Memory-Mapped IO，简称MMIO，将设备端口（寄存器）映射到进程地址空间。以x86为例，对映射内存区域的读写操作通过普通的load、store访存指令来完成，处理器通过内存类型范围寄存器（MTRR，Memory Type Range Regsiters）和页面属性表（PAT，Page Attribute Table）对不同的内存范围设置不同的CPU cache policy，内核设置MMIO类型范围的cpu cache策略为uncacheable，其他RAM类型范围的cpu cache策略为write-back！即直接绕过cpu cache读写内存，但实际上并没有物理内存参与，而是将读写操作转发到外设，上述代码中*ttyport = a[i]这个赋值操作绕过CPU cache直达外设。 Port IO，此时外设端口（寄存器）采用独立编址，而非Memory-Mapped IO这种统一编址方式，需要通过专门的cpu指令来对设备端口进行读写，如x86上采用的是指令in、out来完成设备端口的读写。  而如果是**DMA（Direct Memory Access）**操作模式的话，它绕过cpu直接对内存进行操作，期间不中断cpu执行，DMA操作内存方式上与cpu类似，都会考虑cpu cache一致性问题。假如DMA对内存进行读写操作，总线上也会对事件进行广播，cpu cache也会观测到并采取相应的动作。如DMA对内存进行写操作，cpu cache也会将相同内存地址的cache line设置为invalidate，后续读取时就可以重新从内存加载最新数据；假如DMA进行内存读操作，数据可能从其他cpu cache中直接获取而非从内存中。这种情况下DMA操作的内存区域，对应的内存变量也应该使用volatile修饰，避免编译器优化从寄存器中读到旧值。\n以上示例摘自C99规范，通过上述示例、解释，可以体会到volatile的语义特点：“不可优化型、易变性、顺序性”。\n下面这个示例摘自网络，也比较容易表现volatile的语义特点：\n// 应为 volatile unsigned int *p = .... unsigned int *p = GetMagicAddress(); unsigned int a, b; a = *p; b = *p; *p = a; *p = b;  GetMagicAddress()返回一个外设的内存映射IO地址，由于unsigned int *p指针没有volatile修饰，编译器认为*p中的内容不是“易变的”因此可能会作出如下优化。首先从p读取一个字节到寄存器，然后将其赋值给a，然后认为*p内容不变，就直接将寄存器中内容再赋值给b。写*p的时候认为a == b，写两次没必要就只写了一次。\n而如果通过volatile对*p进行修饰，则就是另一个结果了，编译器会认为*p中内容是易变的，每次读取操作都不会沿用上次加载到寄存器中的旧值，而内存映射IO内存区域对应的cpu cache模式又是被uncacheable的，所以会保证从内存读取到最新写入的数据，成功连续读取两个字节a、b，也保证按顺序写入两个字节a、b。\n  相信读到这里大家对CC++ volatile的适用场景有所了解了，它确实是有用的。那接下来我们针对开发者误解很严重的一个问题“volatile能否支持线程可见性”再探索一番，不能！不能！不能！\n5. CC++ thread visibility # 5.1. 线程可见性问题 # 多线程编程中经常会通过修改共享变量的方式来通知另一个线程发生了某种状态的变化，希望线程能及时感知到这种变化，因此我们关心“线程可见性问题”。\n在对称多处理器架构中（SMP），多处理器、核心通过总线共享相同的内存，但是各个处理器核心有自己的cache，线程执行过程中，一般会将内存数据加载到cache中，也可能会加载到寄存器中，以便实现访问效率的提升，但这也带来了问题，比如我们提到的线程可见性问题。某个线程对共享变量做了修改，线程可能只是修改了寄存器中的值或者cpu cache中的值，修改并不会立即同步回内存。即便同步回内存，运行在其他处理器核心上的线程，访问该共享数据时也不会立即去内存中读取最新的数据，无法感知到共享数据的变化。\n5.2. diff volatile in java、cc++ # 有些编程语言中定义了关键字volatile，如Java、C、C++等，对比下Java volatile和CC++ volatile，差异简直是太大了，我们只讨论线程可见性相关的部分。\nJava中语言规范明确指出volatile保证内存可见性，JMM存在“本地内存”的概念，线程对“主存”变量的访问都是先加载到本地内存，后续写操作再同步回主存。volatile可以保证一个线程的写操作对其他线程立即可见，首先是保证volatile变量写操作必须要更新到主存，然后还要保证其他线程volatile变量读取必须从主存中读取。处理器中提供了MFENCE指令来创建一个屏障，可以保证MFENCE之前的操作对后续操作可见，用MFENCE可以实现volatile，但是考虑到AMD处理器中耗时问题以及Intel处理器中流水线问题，JVM从MFENCE修改成了LOCK: ADD 0。\n但是在C、C++规范里面没有要求volatile具备线程可见性语义，只要求其保证“不可优化性、顺序性、易变性”。\n5.3. how gcc handle volatile # 这里做个简单的测试：\n#include \u0026lt;stdio.h\u0026gt; int main() { // volatile int a = 0; int a = 0; while(1) { a++; printf(\u0026quot;%d\\n\u0026quot;, a); } return 0; }  不开优化的话，有没有volatile gcc生成的汇编指令基本是一致的，volatile变量读写都是针对内存进行，而非寄存器。开gcc -O2优化时，不加volatile情况下读写操作通过寄存器，加了volatile则通过内存。\n1）不加volatile ：gcc -g -O2 -o main main.c\n这里重点看下对变量a的操作，xor %ebx,%ebx将寄存器%ebx设为0，也就是将变量a=0存储到了%ebx，nopl不做任何操作，然后循环体里面每次读取a的值都是直接在%ebx+1，加完之后也没有写回内存。假如有个共享变量是多个线程共享的，并且没有加volatile，多个线程访问这个变量的时候就是用的物理线程跑的处理器核心寄存器中的数据，是无法保证内存可见性的。\n2）加volatile：gcc -g -O2 -o main main.c\n这里变量a的值首先被设置到了0xc(%rsp)中，nopl空操作，然后a++时是将内存中的值移动到了寄存器%eax中，然后执行%eax+1再写回内存0xc(%rsp)中，while循环中每次循环执行都是先从内存里面取值，更新后再写回内存。但是这样就可以保证线程可见性了吗？No！\n5.4. how cpu cache works # 是否有这样的疑问？CC++中对volatile变量读写，发出的内存读写指令不会被CPU转换成读写CPU cache吗？这个属于硬件层面内容，对上层透明，编译器生成的汇编指令也无法反映实际执行情况！因此，只看上述反汇编示例是不能确定CC++ volatile支持线程可见性的，当然也不能排除这种可能性？\nStack Overflow上Dietmar Kühl提到，‘volatile’阻止了对变量的优化，例如对于频繁访问的变量，会阻止编译器对其进行编译时优化，避免将其放入寄存器中（注意是寄存器而不是cpu的cache）。编译器优化内存访问时，会生成将内存数据缓存到寄存器、后续访问内存操作转换为访问寄存器，这称为“software cacheing”；而CPU实际执行时硬件层面将内存数据缓存到CPU cache中，这称为“hardware cacheing”，是对上层完全透明的。现在已经确定CC++ volatile不会再作出“将内存数据缓存到CPU寄存器”这样的优化，那上述CPU hardware caching技术就成了我们下一个怀疑的对象。\n保证CPU cache一致性的方法，主要包括write-through（写直达）或者write-back（写回），write-back并不是当cache中数据更新时立即写回，而是在稍后的某个时机再写回。写直达会严重降低cpu吞吐量，所以现如今的主流处理器中通常采用写回法，而写回法又包括了write-invalidate和write-update两种方式，可先跳过。\n write-back：\n write-invalidate，当某个core（如core 1）的cache被修改为最新数据后，总线观测到更新，将写事件同步到其他core（如core n），将其他core对应相同内存地址的cache entry标记为invalidate，后续core n继续读取相同内存地址数据时，发现已经invalidate，会再次请求内存中最新数据。 write-update，当某个core（如core 1）的cache被修改为最新数据后，将写事件同步到其他core，此时其他core（如core n）立即读取最新数据（如更新为core 1中数据）。   write-back（写回法）中非常有名的cache一致性算法MESI，它是典型的强一致算法，intel就凭借MESI优雅地实现了强一致CPU，现在intel优化了下MESI，得到了MESIF，它有效减少了广播中req/rsp数量，减少了带宽占用，提高了处理器处理的吞吐量。关于MESI，这里有个可视化的MESI交互演示程序可以帮助理解其工作原理，查看MESI可视化交互程序。\n我们就先结合简单的MESI这个强一致性协议来试着理解下“x86下为什么就可以保证可见性”，结合多线程场景分析：\n 一个volatile共享变量被多个线程读取，假定这几个线程跑在不同的cpu核心上，每个核心有自己的cache，线程1跑在core1上，线程2跑在core2上。 现在线程1准备修改变量值，这个时候会先修改cache中的值然后稍后某个时刻写回主存或者被其他core读取。cache同步策略“write-back”，MESI就是其中的一种。处理器所有的读写操作都能被总线观测到，snoop based cache coherency，当线程2准备读取这个变量时： 假定之前没读取过，发现自己的cache里面没有，就通过总线向内存请求，为了保证cpu cache高吞吐量，总线上所有的事务都能被其他core观测到，core1发现core2要读取内存值，这个数据刚好在我的cache里面，但是处于dirty状态。core1可能灰采取两种动作，一种是将dirty数据直接丢给core2（至少是最新的），或者告知core2延迟read，等我先写回主存，然后core2再尝试read内存。 假定之前读取过了，core1对变量的修改也会被core2观测到，core1应该将其cache line标记为modified，将core2 cache line标记为invalidate使其失效，下次core2读取时从core1获取或内存获取（触发core1将dirty数据写回主存）。  这么看来只要处理器的cache一致性算法支持，并且结合volatile避免寄存器相关优化，就能轻松保证线程可见行。真的是这样吗？并不是。\n认为有了MESIF volatile就可以在x86平台上实现可见性，这种理解是有问题的：\n volatile只是避免了software caching，不能避免hardware caching； 现在x86处理器中都引入了store buffer，volatile变量更新操作会先放入store buffer中； store buffer中的更新操作会尽可能快地更新到cache，有多快不确定，反正不是立即（过段时间或者有write barrier都可以清空）； store buffer中的更新落到L1 cache后会触发MESIF操作，如将当前cache的cacheline修改为Modified，并广播给其他核MESIF invalidate请求，其他核将其放入invalidate queue中，回复ack但不立即处理； 等其他核下次读取时，如果还没处理完invalidate queue中的请求，就会从本地的cacheline中读取到旧值，因为此时cacheline的状态是Shared，还是可以读取的； 如果已经处理完了invalidate queue中的事件（过一段时间或者有read barrier都可以清空），会将对应cacheline状态修改为Invalidated，此时会重试从总线读取该cacheline对应内存块的最新数据。其他核也会observe/snoop其它核发送到总线的内存读取事件，如果它知道该内存块对应的cacheline自己的才是最新的（Modified），就会将其最新数据作为响应并写回主存，此时两边的cacheline全部改为Shared状态。  从基于对现代CPU架构、cache一致性协议的了解，我不认为x86平台下volatile就可以保证线程可见性。我甚至怀疑当时跟我提“我们用volatile之前有问题用了之后OK了”的同学是不是真的验证没问题了，还是说用的其实是atomic或者其他barriers。总之我在Intel Core i7上没有构造出合适的用例来证明volatile可以保证线程可见性，可能硬件store buffer和invalidate queue处理还是很快的，我们构造两三个线程并发读写volatile不容易复现这个问题。\n而且，不同的处理器设计不一样，我们只是以MESI协议来粗略了解了x86的处理方式，对于其他弱一致性CPU，即便使用了volatile也不一定能保证线程可见性。\n但若是对volatile变量读写时安插了类似MFENCE、LOCK指令也是可以保证可见性的，如何进一步判断编译器有没有生成类似barriers指令呢？还需要判断编译器（如gcc）是否有对volatile来做特殊处理，如安插MFENCE、LOCK指令之类的。上面编写的反汇编测试示例中，gcc生成的汇编没有看到lock相关的指令，但是因为我是在x86上测试的，而x86刚好是强一致CPU，我也不确定是不是因为这个原因，gcc直接图省事略掉了lock指令？所以现在要验证下，在其他非x86平台上，gcc -O2优化时做了何种处理。如果安插了类似指令，问题就解决了，我们也可以得出结论，c、c++中volatile在gcc处理下可以保证线程可见性，反之则不能得到这样的结论！\n我在网站godbolt.org交叉编译测试了一下上面gcc处理的代码，换了几个不同的硬件平台也没发现有生成特定的类似MFENCE或者LOCK相关的致使处理器cache失效后重新从内存加载的指令。\n 备注：在某些处理器架构下，gcc确实有提供一些特殊的编译选项允许绕过CPU cache直接对内存进行读写，可参考gcc man手册“-mcache-volatile”、“-mcache-bypass”选项的描述。\n 想了解下CC++中volatile的真实设计“意图”，然后，在stack overflow上我又找到了这样一个回答：https://stackoverflow.com/a/12878500，重点内容已加粗显示。\n[Nicol Bolas](https://stackoverflow.com/users/734069/nicol-bolas)回答中提到：\n What volatile tells the compiler is that it can\u0026rsquo;t optimize memory reads from that variable. However, CPU cores have different caches, and most memory writes do not immediately go out to main memory. They get stored in that core\u0026rsquo;s local cache, and may be written\u0026hellip; eventually.**\nCPUs have ways to force cache lines out into memory and to synchronize memory access among different cores. These memory barriers allow two threads to communicate effectively. Merely reading from memory in one core that was written in another core isn\u0026rsquo;t enough; the core that wrote the memory needs to issue a barrier, and the core that\u0026rsquo;s reading it needs to have had that barrier complete before reading it to actually get the data.\nvolatile guarantees none of this. Volatile works with \u0026ldquo;hardware, mapped memory and stuff\u0026rdquo; because the hardware that writes that memory makes sure that the cache issue is taken care of. If CPU cores issued a memory barrier after every write, you can basically kiss any hope of performance goodbye. So C++11 has specific language saying when constructs are required to issue a barrier.\n Dietmar Kühl回答中提到:\n The volatile keyword has nothing to do with concurrency in C++ at all! It is used to have the compiler prevented from making use of the previous value, i.e., the compiler will generate code accessing a volatile value every time is accessed in the code. The main purpose are things like memory mapped I/O. However, use of volatile has no affect on what the CPU does when reading normal memory: If the CPU has no reason to believe that the value changed in memory, e.g., because there is no synchronization directive, it can just use the value from its cache. To communicate between threads you need some synchronization, e.g., an std::atomic, lock a std::mutex, etc.\n 最后看了标准委员会对volatile的讨论：http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2016.html 简而言之，就是CC++中当然也想提供java中volatile一样的线程可见性、阻止指令重排序，但是考虑到现有代码已经那么多了，突然改变volatile的语义，可能会导致现有代码的诸多问题，所以必须要再权衡一下，到底值不值得为volatile增加上述语义，当前C++标准委员会建议不改变volatile语义，而是通过新的std::atmoic等来支持上述语义。\n结合自己的实际操作、他人的回答以及CC++相关标准的描述，我认为CC++ volatile确实不能保证线程可见性。但是由于历史的原因、其他语言的影响、开发者自己的误解，这些共同导致开发者赋予了CC++ volatile很多本不属于它的能力，甚至大错特错，就连Linus Torvards也在内核文档中描述volatile时说，建议尽量用memory barrier替换掉volatile，他认为几乎所有可能出现volatile的地方都可能会潜藏着一个bug，并提醒开发者一定小心谨慎。\n6. 实践中如何操作 #  开发者应该尽量编写可移植的代码，像x86这种强一致CPU，虽然结合volatile也可以保证线程可见性，但是既然提供了类似memory barrier()、std::atomic等更加靠谱的用法，为什么要编写这种兼顾volatile、x86特性的代码呢？ 开发者应该编写可维护的代码，对于这种容易引起开发者误会的代码、特性，应该尽量少用，这虽然不能说成是语言设计上的缺陷，但是确实也不能算是一个优势。  凡事都没有绝对的，用不用volatile、怎么用volatile需要开发者自己权衡，本文的目的主要是想总结CC++ volatile的“能”与“不能”以及背后的原因。由于个人认识的局限性，难免会出现错误，也请大家指正。\n 本文撰写于 2019-01-07, 现在拿出来分享给感兴趣的技术同行，一起学习交流。\n 关于对volatile的理解，会引出对内存模型的理解，即便看完一些针对内存模型的描述之后，还是会有一些开发者提出更深入细微的问题，比如lock, lock cmpxchg如何实现的，mfence、lfence、sfence如何实现的。陷入细节是可怕的，它会让我们感觉无法适可而止。\n补充一篇文章，我觉得挺不错的，Memory Barrier: A Hardware View for Software Hackers。\n它介绍了现在处理器的cache结构设计（包括指令cache、数据cache、cacheline、store buffer、多级cache）、cache一致性协议MESI，以及所谓的内存屏障与cache设计中cache一致性协议、store buffer、invalidate queue之间的关系。理解下这篇文章，大致搞明白硬件的工作过程，非常有助于加深这部分的理解。\n 本文最后更新于 2020-12-15, 补充了上述内存屏障相关的描述及参考资料。\n 这里还少了一层，在cpu执行更新操作时，为了避免cpu stall提高指令吞吐，写更新其实是落store buffer中的，cache中并没有立即体现出更新，cache一致性协议也还没工作……所以这个时候还需要内存屏障来讲storebuffer中的更新刷到cache，读的核上还需要通过内存屏障处理invalidate queue才能观察到新值。\n那x86+volatile没有应用内存屏障，又是怎么能实现可见性的呢？\n首先上述理解及质疑都是正确的思考路径，我们需要考虑的是x86体系结构里面是否有我们所不知道的东西，这篇论文也许能解答我们的问题：x86 tso model：\n Moreover, different processors or hardware threads do not observably share store buffers. This is in sharp contrast to x86-CC, where each processor has a separate view order of its memory accesses and other processors' writes.\n 意思大概就是说x86的设计，每个处理器核心不仅有自己的内存访问视图，还有一个其他处理器的write操作的视图，这样它就能感知到谁有真正的最新的数据。所以x86上面只要c程序加了volatile避免寄存器优化就可以保证线程可见性。\n参考资料 #  Memory Barrier: A Hardware View for Software Hackers x86 TSO: A Programmer\u0026rsquo;s Model for x86 Multiprocessors x86-TSO: A Rigorous and Usable Programmer’s Model for x86 Multiprocessors  "}),a.add({id:346,href:"/blog/2020-07-01-%E5%BC%80%E5%8F%91%E8%80%85%E5%BA%94%E6%8E%8C%E6%8F%A1%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%80%A7%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/",title:"开发者应掌握的系统性测试方法",description:"很多人觉得测试是徒劳的，这种情况只有可能是问题规模比较小、肉眼可分析的情境下才会为true",content:'/* Three image containers (use 25% for four, and 50% for two, etc) */ .column { float: left; width: 50%; padding: 5px; } /* Clear floats after image containers */ .row::after { content: ""; clear: both; display: table; } .fixsize { width: 400px; } .fullsize { width: 680px; }  如何做好测试，是一门系统性的方法学，而不只是一些零零散散的经验。了解并掌握各种测试的目的、方法是非常有必要的。\n最近工作中也在推动测试相关的一些事项，有一点感触，这里先简单总结下常见测试方法的目的，大致包括如下几类。\n1. 研发流程中构建环节\n 冒烟测试\n该术语，取自集成电路开发领域，集成电路在测试之前，先要加电检查，如果没有冒烟才能进行后续的测试。冒烟测试并不是测试过程的一个阶段，它是软件构建过程中的一个环节，它包含一些非常基础的测试，如保证编译通过、部分核心用例通过，它随每次构建触发，处于持续集成的一个环节。英文表述为BVT测试，Build Verification Testing，从中更能感受的到。将其理解为测试的一个阶段，是一个巨大的误区。  2. 功能性指标相关测试\n  功能测试\n软件需求说明中对软件需要的功能进行了描述，软件需求分析阶段会对需求说明进行详细分析，并整理出相关的规格说明，包括每个用例的输入、输出等等。功能测试，其实也就是对这里的软件需求规格说明进行测试用例的覆盖，考察的是对各个点、异常路径的把控程度。在实际研发过程中，开发人员一般会先自测通过后，再转给测试团队进行进一步的测试。\n  回归测试\n之前已经测试过的用例，可以沉淀下来，供以后进行回归，已发现软件变更、升级期间是否引入了bug。\n  其他\n  3. 非功能性指标相关测试\n     性能测试 (how much + how fast)\n对软件的性能指标进行测试，以验证是否达到预期设计的性能要求。在软件设计之初，需求方一般会提出明确的性能要求，如希望支撑N个用户的并发访问请求，希望响应时间能控制在2s以内等等。除了用户提出的性能指标要求，软件设计人员在系统设计的时候，也会对系统中交互的各个子系统、组件之间的性能有一定要求，如各组件通信响应时间在100ms以内等。\n性能测试，是对系统的一个检验，检验是否达到了预期的设计标准。性能测试，通常可以参考系统最大吞吐量时的请求量级、响应时间，来确定系统的最佳运行点，科学合理地部署设备资源来平衡性能和成本。\n性能测试，通常会和负载测试、压力测试等结合起来，以获得系统的最佳运行点、系统最大负载点、系统崩溃点。\n  负载测试 (how much)\n在性能测试请求量基础上进一步增大请求量，直到系统吞吐量不随请求量增加而增加（而是下降）。这个临界点就是最大负载点，表示系统当前已经满负荷运行，继续增大请求量的话，请求处理就会变得更慢。\n  压力测试 (how much)\n在压力测试的基础上，继续增大请求量，以检验系统的耐压能力，请求量的继续增大，意味着会消耗更多的系统资源，如内存、CPU、网卡等等，资源不足肯定会影响到请求处理，服务本身需要具备一定的过载保护能力，如限制入连接数、入请求数等，服务本身如果不够健壮的话，极有可能会导致拒绝响应，如内存不足频繁GC甚至影响到了正常请求处理无法响应。\n系统无法做出响应的点，即为系统崩溃点，请求量继续增加系统将无法做出响应。\n  可用性测试\n系统的可用性，表示系统在任意指定的时间点，系统是否可用，通常有N个9来表示，如系统达到5个9的可用性，表示系统全年只有365x24x3600x(1-0.99999)=315s=5min的不可用时间。\n服务级别协议（service-level agreement，缩写SLA）也称服务等级协议、服务水平协议，是服务提供商与客户之间定义的正式承诺。服务提供商与受服务用户之间具体达成了承诺的服务指标——质量、可用性、责任。SLA最常见的组成部分是以合同约定向客户提供的服务。例如，互联网服务供应商（ISP）和电信公司通常在与客户的合同条款内包含简单定义的服务级别协议。在此事例下，SLA通常定义有平均故障间隔（MTBF）、平均修复时间或平均修复时间（MTTR）；哪一方负责报告错误与支付费用；吞吐量；抖动；或类似的可衡量细节。 通常，服务提供商需要有SLA保证客户权益。\n  稳定性测试\n稳定性测试，是用来验证产品在一定的负载下，是否能够长时间的稳定性运行，其主要目的是验证能力，并在验证过程中发现系统不稳定的因素并进行分析解决。\n  安全测试\n对系统进行安全性相关的测试，如敏感权限、sql注入、csrf供给、api鉴权、有漏洞的不安全组件等等，通常这是一个系统性的工程，需要有专业团队来支撑，并提供安全相关的服务供业务团队接入使用。\n  软件研发流程中的各个阶段，仔细观察之后你会发现，每一环都与软件最终交付质量息息相关。了解并掌握各个阶段常见的一些系统性测试方法，是非常有必要的。\n'}),a.add({id:347,href:"/blog/2020-06-27-%E4%B8%AD%E5%9B%BD%E4%BA%BA%E8%A6%81%E5%AD%A6%E7%9D%80%E5%8B%87%E6%95%A2%E8%AE%B2%E7%9C%9F%E8%AF%9D/",title:"中国人要学着勇敢讲真话",description:"中国人什么时候都敢于讲话、讲真话、敢质疑的时候，再谈屹立于世界民族之林。",content:"最近苟晶被冒名顶替上大学的事情，成为社会关注焦点，作为山东老乡，也忍不住回想起求学时的一些经历，一些从内心里颠覆我认知、改变我看法的经历。有时，我会觉得自己是不是过于理想主义，是不是有点愤世嫉俗，不接地气，就算是吧。一个人思想的转变，肯定也是有原因的。\n那年我还上初中，当时学校正在搞数学竞赛吧，我对这玩意真的不是很感兴趣，也没有认真去准备，学校组织考试的时候也没有竞争过其他同学，也不出我意外。但是，我数学应该还挺好的吧，也比较聪明吧，但是我对这种无脑地做题竞赛真的不感兴趣。当时，我的数学老师找到我希望我继续参加后续相关的培训、竞赛，我说我没通过筛选。老师劝我说之前也有同学开始成绩不好后面取得好成绩的，还答应说给我争取一个名额，怎么争取呢？就是让一个通过筛选的女同学让给我，额，被我婉言拒绝了……\n这只是发生在我身上的一个老师私自做主、让度学生利益的一个案例，为了“出成绩”，老师似乎并不是很在乎个别学生的利益。现在已经13年过去了，我不想评价当年老师的做法有多么不好，我只是想指出这样的情况发生在学生身上，是有多么地轻描淡写。不要觉得这是个小事，“度”严重到一定程度，也可能会酿成像受害人苟晶一样的恶性事件，本属于你的教育经历被偷走，人生被乱涂一笔，你会不会愤怒？\n上高二那年，大家应该有相似的经历，就是上午上完第二节课是要跑操的。上午第三节课，我们班刚好是体育课，所以跑完操就直接带队到了操场。操场里面有个同学仰面躺在地上，穿着一身运动服，脸色苍白，没有任何喘息……他的时间停止在了那一天。没有校医的急救，大家都在等医院的医生到来，包括周围围观的几名体育老师。过了15~20分钟吧，医生来了，做了下心肺按压后，医生说，有点晚了可能不行了。医生让我们周围几名同学把这位同学抬上救护车想再抢救一下……\n我亲手将这名同学抬上救护车，也还记得他穿着一身黄色的运动服，已经记不清他的脸，比我低一届吧。我也不知道他是因何而死，学校要求师生统一口径“先天性心脏病”。后面听说是因为在网吧通宵，后面跑操时猝死，跟老师请假不参加跑操老师没同意。这个事情很难评价，作为一名老师也很难预见这样的情况。至于学校统一口径的做法，我一开始并没过多思考，但是当我看到去世学生的父母跪在学校门口，哭喊着还我孩子的时候，我开始慢慢产生了一些质疑。\n大一那年，百度首页有条消息，是关于我们高中的，“邹平一中谈话死”。事情大致是这样的，一名高中生在课外活动时观看班主任老师打篮球，班主任一个球没投进，这个球在很多打球的同学来看应该是很容易进的一个球,这名同学随手说了句“臭手”。其班主任听到后在操场当着很多人的面直接扇耳光教训，还不解气，又在晚自习时，将该同学叫到偏僻处继续体罚。这名班主任踹了学生一脚，力有多大就不讨论了，总之学生倒地后头部严重受伤死亡……但是，学校还是那老一套做法，先天性心脏病。当我看到多方爆料的消息之后，一下子就联想起当年那位低我一届、冰冷地躺在地上、没有施加任何急救措施、也是以“先天性心脏病”被了事的同学，我觉得学校是不是在做缺德事了？\n这次，我选择站在学生这边，积极地跟进相关事态的报道，了解相关的信息发展。一开始我就没有选择继续相信学校，或者说继续盲目地相信学校，这些都源于我此前的经历在我内心深处埋下的质疑。我不相信一名身体健康的学生兼班长，会犯什么罪大恶极的事情，也不会来个突然猝死，更不会相信一个身体部位严重受伤的同学是因为先天性心脏病。我只有一种想法，那就是这名班主任老师、学校领导们背后达成了某种“默契”，选择继续做一次缺德事。最后随着关注度的提高，陆陆续续地消息被爆料出来，医院、警察、社区论坛、新闻媒体，有些被金钱利益收买，有些选择了良知……最后，涉事老师自首了！\n那些为死去同学争夺真相、尊严的同学们，我这辈子都对他们表示敬佩，如果没有他们的良知、不屈，这名意外去世的同学也只能是作为一粒尘埃淹没在一浪又一浪的谎言中。\n现在，应该有很多人能理解我内心深处的一些愤世嫉俗，或者傲慢，或者偏见了，并非我见不得和谐社会好，并非我不知理想与现实有差距，并非我不知发展要循序渐进。只是，我不再愿意轻易说妥协，尤其是你明明做了才60分，却天天彪炳千秋、延迟或拒绝改变的时候！父母离开之后，你将直面死亡，我们二三十来岁的人，很多人对死亡是没有什么特别的感受的，可能很多人没有见过在病魔面前，一个健壮的成年人是如何一步步走向衰弱离开，大致上也不知道生命有多脆弱，或者有多坚韧。\n我其实不想经历这些，他对我来说是挫折，另一方面也淬炼了我，我用我的生命做赌注，我永远压在真相这边！也希望，中国的年轻人不要怕事，要敢于讲出自己的想法，社会发展、国家未来靠的是创新，如果你们都不敢发声，难道我们要靠80、90岁的老爷爷们吗，还是要去刨祖坟把敢说真话的人刨出来？当一个社会只有一种声音的时候，不被理解的人也就成了另类，像什么思辨、创意、创造，也就基本与未来无缘了。今天的你们选择闭嘴，明天你们的孩子就只能把嘴缝起来才会安全了！\n"}),a.add({id:348,href:"/tags/%E4%BA%BA%E6%80%A7/",title:"人性",description:"",content:""}),a.add({id:349,href:"/tags/%E6%96%87%E6%98%8E/",title:"文明",description:"",content:""}),a.add({id:350,href:"/tags/%E6%AD%A3%E7%9B%B4/",title:"正直",description:"",content:""}),a.add({id:351,href:"/tags/cmd/",title:"cmd",description:"",content:""}),a.add({id:352,href:"/tags/cobra/",title:"cobra",description:"",content:""}),a.add({id:353,href:"/tags/flag/",title:"flag",description:"",content:""}),a.add({id:354,href:"/tags/flagset/",title:"flagset",description:"",content:""}),a.add({id:355,href:"/blog/2020-06-26-%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/",title:"如何高效开发一个命令行工具",description:"如何高效开发一个命令行工具呢？需要能支持子命令，选项要支持长短两种形式，需要能自动生成help信息，包括对命令的说明、选项的说明，需要支持不分选项可走配置文件，需要能很方便地扩展新功能……别慌，听我慢慢道来。",content:"我经常会开发一些命令行工具来协助处理一些事情，如开发一个代码生成工具快速生成服务代码，或者开发一个工具来方便管理github上的工具，或者开发一个工具rm来替换掉不安全的rm，等等。\n命令行工具开发过程中，比较常见的一个问题就是对功能进行分组，开发多个命令不利于使用，在命令中支持子命令是一个更常见、更友好的做法，如go build，go tool，go pprof，等等。我们还希望为不同的子命令添加不同的命令行选项，如go build -gcflags=，go pprof --seconds=，等等。\n如何支持子命令字呢？ # 假如我们开发一个命令行程序 gox，我们希望能为它添加一个子命令gox create来创建一个完整的服务工程，包括自动生成工程下的代码。\n那如何为命令行程序gox添加这个子命令字呢？\ngox是shell搜索路径定位到的程序，create只能是shell传递给进程的一个普通参数，在gox程序启动之后只能从os.Args来获取该参数，以及后续gox create -protofile= -protodir的参数-protofile及-protodir。\n然后呢，为了方便以后扩展其他子命令，我们最好将subcmd进行一下抽象，通过一个Command interface{}约定好一个subcmd必须要完成那些操作。接口并不是为了抽象而抽象，而是用来清晰地表明要做什么。\n// Command what does a command do type Command interface{ // PreRun run before the command logic execution PreRun() error // Run run the command logic Run() error // PostRun run after the command logic execution PostRun() error } // BaseCommand basic implemention // // this BaseCommand could be embeded into a customized subcmd type BaseCommand struct{ } func (bc *BaseCommand) PreRun() error { return nil } func (bc *BaseCommand) Run() error { panic(\u0026quot;implement me\u0026quot;) } func (bc *BaseCommand) PostRun() error { return nil }  Command接口定义了一个command应该干什么，然后也可以提供一个基本的Command实现BaseCommand，它提供了一些基本的操作可以供后续复用，后面我们要扩展其他子命令字的时候，通过将该BaseCommand嵌入，可以少实现几个函数，这也是go里面提倡的通过组合来实现继承。\n现在我们实现一个CreateCmd：\ntype CreateCmd struct { *BaseCommand } func NewCreateCmd() Command { return \u0026amp;CreateCmd{ \u0026amp;BaseCommand{}, } } func (c *CreateCmd) Run() error { println(\u0026quot;create cmd running\u0026quot;) // execute the logic of create cmd println(\u0026quot;create cmd finished\u0026quot;) }  那我们怎么在执行gox create的时候运行CreateCmd.Run()方法呢？\nvar cmds map[string]Command = { \u0026quot;create\u0026quot;: NewCreateCmd, } func main() { args := os.Args[1:] if len(args) == 0 { panic(\u0026quot;invalid subcmd\u0026quot;) } cmd, ok := cmds[args[0]] if !ok { panic(fmt.Errorf(\u0026quot;cmd: %s not registered\u0026quot;, args[0])) } if err := cmd.PreRun(); err != nil { panic(err) } if err := cmd.Run(); err != nil { panic(err) } if err := cmd.PostRun(); err != nil { panic(err) } }  是不是很简单？本来就很简单 :)\n如何为子命令字添加不同的选项呢？ # 那现在要给各个子命令字添加独立的命令行选项怎么办呢？比如gox create的命令参数和gox update的命令行参数是不同的，那怎么办呢？你当然可以根据os.Args[1:]来解析，想怎么解析都可以，我们这里讨论如何借助go标准库提供的flag包来解析。\n大家可能都使用过flag.Parse()来解析命令行参数，这个函数其实是将os.Args[1:]中的参数解析完后填充到一个默认的flagset。如果要为不同的子命令添加不同的命令行选项，那么为每个子命令创建独立的flagset就可以了。各个子命令使用自己的flagset来执行flagset.Parse()代替flag.Parse()就可以了。\n就这么简单，我们对前面的程序进行一点调整：\nCommand接口增加命令参数解析接口：\n// Command what does a command do type Command interface{ // ParseFlags parse flags into command's own flagset ParseFlags(os.Args) ... }  BaseCommand 添加一个参数解析的方法，给自定义子命令字复用\n// BaseCommand basic implemention // // this BaseCommand could be embeded into a customized subcmd type BaseCommand struct{ flagSet *flag.FlagSet } func (bc *BaseCommand) ParseFlags(args os.Args) error { return bc.flagset.Parse(args) } ...  为create子命令创建独立的flagset来解析参数\nfunc NewCreateCmd() error { fs := flag.NewFlagSet(\u0026quot;create\u0026quot;, flag.PanicOnError), fs.String(\u0026quot;protofile\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to process\u0026quot;) fs.String(\u0026quot;protodir\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to search）\u0026quot; return \u0026amp;CreateCmd{ \u0026amp;BaseCommand{ flagSet: fs, } } }  程序启动的时候统一解析命令行参数：\nfunc main() { ... // parse the flags if err := cmd.ParseFlags(args[1:]; err != nil { panic(err) } ... }  这样就完成了，是不是很简单，本来就很简单。\n如何显示命令帮助信息？ # 当然了，只能运行命令还不行，有多少注册的子命令可执行？每个子命令有什么命令行参数呢？我们还需要能够显示命令行的帮助信息。\n这个怎么实现呢？各个子命令需要能够指明命令的使用帮助：\n 一个简单的表述，以供我们显示gox包含的各个子命令字的使用信息； 一个详细的描述，以供我们显示gox help create时的各个选项的帮助信息；  我们的代码简单做下调整就可以支持到。\n添加Usage、UsageLong方法：\ntype Command interface{ ... // 返回简单的帮助信息 Usage() string // 返回详细的帮助信息 UsageLong() string }  然后为BaseCommand添加两个字段：\ntype BaseCommand struct{ ... Usage string UsageLong string } ... func (bc *BaseCommand) Usage() string { return bc.Usage } func (bc *BaseCommand) UsageLong() string { return bc.UsageLong }  为createCmd添加帮助信息：\nfunc NewCreateCmd() Command { fs := flag.NewFlagSet(\u0026quot;create\u0026quot;, flag.PanicOnError), fs.String(\u0026quot;protofile\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to process\u0026quot;) fs.String(\u0026quot;protodir\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to search）\u0026quot; return \u0026amp;CreateCmd{ \u0026amp;BaseCommand{ flagSet: fs, Usage: 'create a project', UsageLong: 'create a project quickly.\\n\\n'+ fs.FlagUsages(), } } }  然后呢，为了能够使用帮助信息，我们需要添加一个help命令字：\ntype HelpCmd struct{ cmd string } func NewHelpCmd() Command { return \u0026amp;HelpCmd{ \u0026amp;BaseCommand{}, } } func (c *HelpCmd) ParseFlags(args os.Args) error { cmd = args[1:] } func (c *HelpCmd) Run() error { // help specific subcmd if len(c.cmd) != 0 { v, ok := cmds[c.cmd] if !ok { return fmt.Errorf(\u0026quot;cmd: %s not registered\u0026quot;, c.cmd) } println(v.UsageLong()) } // help all subcmds for _, v := range cmds { println(v.Usage()) } }  然后呢，我们主程序启动的时候执行gox 或 gox help都执行help命令：\nfunc main() { args := os.Args[1:] if len(args) == 0 { cmds[\u0026quot;help\u0026quot;].Run() } ... }  嗯，就这些了，是不是很简单？本来就很简单。\n小结 # 当然，除了这些，我们可能还希望为命令行工具添加shell auto-completion输入补全功能，提示信息的国际化、本地化，命令字扩展时的便利程度等，还是有些问题需要进一步考虑的。\n我这里只是介绍下实现的一个大致思路，具体实践的时候倒并不一定要这么去实现，可以考虑下cobra，通过cobra来实现posix风格的命令行是很方便的。这些内容感兴趣的话可以自己了解下。\n和本文内容接近的，可以参考我的一个工具rm-safe，希望对读者朋友有帮助！\n"}),a.add({id:356,href:"/tags/%E4%BA%BA%E7%94%9F/",title:"人生",description:"",content:""}),a.add({id:357,href:"/tags/%E7%88%B6%E4%BA%B2/",title:"父亲",description:"",content:""}),a.add({id:358,href:"/blog/2020-06-21-%E7%88%B6%E4%BA%B2%E8%8A%82%E4%BA%8E%E6%88%91%E5%B7%B2%E6%98%AF%E7%A7%8D%E5%A5%A2%E4%BE%88/",title:"父亲节，于我已是种奢侈",description:"img {width:640px;}  昨天是周六，优化了一下代码生成工具gorpc，解决了几个遗留的问题，总算是做了点有意思的事情，心里有点窃喜。临睡前，掏出手机，惯例地刷了刷推送的消息，原来明天是父亲节了。心里忍不住被扎了一下，父亲节，于我已是种奢侈。30岁的年纪，或好或坏，或小有成绩或满怀迷茫，不管怎样，至少你们还有父亲，我只能在一个人的时候才能去享受下那久违的回忆，那些有父亲的时光。\n在我还很小的时候，家里很是拮据，父母很辛苦，为了维持一家人生活，父母付出了很多。父母的辛苦，在我很小的时候就埋进了心底……如今，二三十年过去，那每逢下雨就要滴滴答答漏水的矮旧房子不见了，那为了维持生计的小卖部柜台、一斤一两积攒收入的称也不见了，那些养过兔子的笼子、养过猪马的破旧草房、人力打水的小压井、黑咕隆咚的饭屋（厨房），还有那棵一人抱不过腰身的大槐树，大槐树下的狗屋（小黑的屋），都不见了。现在依稀还能回想起它们的样子，甚至还记得，那个拿着鞭炮吓唬小黑的我，那个压不动小压井、跳起来压水的我。它们都不见了，变成了现在宽敞明亮、便利方便的大房子，那是父母一点一滴打拼的结果，现在却唯独少了他。",content:" img {width:640px;}  昨天是周六，优化了一下代码生成工具gorpc，解决了几个遗留的问题，总算是做了点有意思的事情，心里有点窃喜。临睡前，掏出手机，惯例地刷了刷推送的消息，原来明天是父亲节了。心里忍不住被扎了一下，父亲节，于我已是种奢侈。30岁的年纪，或好或坏，或小有成绩或满怀迷茫，不管怎样，至少你们还有父亲，我只能在一个人的时候才能去享受下那久违的回忆，那些有父亲的时光。\n在我还很小的时候，家里很是拮据，父母很辛苦，为了维持一家人生活，父母付出了很多。父母的辛苦，在我很小的时候就埋进了心底……如今，二三十年过去，那每逢下雨就要滴滴答答漏水的矮旧房子不见了，那为了维持生计的小卖部柜台、一斤一两积攒收入的称也不见了，那些养过兔子的笼子、养过猪马的破旧草房、人力打水的小压井、黑咕隆咚的饭屋（厨房），还有那棵一人抱不过腰身的大槐树，大槐树下的狗屋（小黑的屋），都不见了。现在依稀还能回想起它们的样子，甚至还记得，那个拿着鞭炮吓唬小黑的我，那个压不动小压井、跳起来压水的我。它们都不见了，变成了现在宽敞明亮、便利方便的大房子，那是父母一点一滴打拼的结果，现在却唯独少了他。\n"}),a.add({id:359,href:"/blog/2020-06-09-a-golang-debugger-book/",title:"A Golang Debugger Book",description:"18年开始学习go时，发现了一款调试器delve，陆陆续续地看了些源码、调试标准的东西，发现调试器是一个很好的切入视角来认识计算机系统，就想把这些东西理顺、分享一下。到现在为止，对开发工具链的认识都还有些认识上的不足，关键还是，觉得调试器就好比一个放大镜，放大一倍看清内存变量，放大两倍看清类型系统，放大三倍看清机器物理结构……这是简单的，涉及到运行时、操作系统、硬件等的特性，我是觉得很有意思，尤其是对部分想了解这些知识的人来说，还是有一定的参考意义的。\nhttps://github.com/hitzhangjie/golang-debugger-book。\n后来工作变动没有持续投入了，19年下半年支持trpc也没太多时间投入，19年年底的时候买了ipad花了连续几个周末啃了300页dwarf标准，坚持写完了dwarf相关的部分。后面开始支持epc又没时间了……\n现在各项工作陆陆陆续续有了眉目，也想把之前放下的东西再捡起来，感兴趣可以简单翻下，如果有小伙伴也有兴趣的话，欢迎业余时间一起继续下去，倒不是觉得是项多么出彩的内容，就是觉得有些值得深究的东西想去探索一下，还有就是一项工作搁置太久会有很浓的挫败感。\n腾讯的小伙伴们很优秀，如果能有小伙伴们助攻，这个应该会加速很多。\n  dwarf v4标准解析 已完成\n  dwarf数据提取 go标准库已提供\n  delve源码解析 一小部分\n  go类型系统、运行时、调试器结合 待补充\n  go新版本准备切换dwarf v5、更好的linker，有些相关的知识，涉及到compiler、linker、debugger的协作\u0026hellip;\n  其他\n  其实，还有很多内容要补充，我也不知道最终会变成啥样，可能就是现在这样……曾经试图邀请几个小伙伴来搞下，可能本身没什么吸引力吧，最终还是这样。\n感兴趣才能坚持下去，每次想到它，都有种立即想投入的冲动，一个人的周末有点有限 :)",content:"18年开始学习go时，发现了一款调试器delve，陆陆续续地看了些源码、调试标准的东西，发现调试器是一个很好的切入视角来认识计算机系统，就想把这些东西理顺、分享一下。到现在为止，对开发工具链的认识都还有些认识上的不足，关键还是，觉得调试器就好比一个放大镜，放大一倍看清内存变量，放大两倍看清类型系统，放大三倍看清机器物理结构……这是简单的，涉及到运行时、操作系统、硬件等的特性，我是觉得很有意思，尤其是对部分想了解这些知识的人来说，还是有一定的参考意义的。\nhttps://github.com/hitzhangjie/golang-debugger-book。\n后来工作变动没有持续投入了，19年下半年支持trpc也没太多时间投入，19年年底的时候买了ipad花了连续几个周末啃了300页dwarf标准，坚持写完了dwarf相关的部分。后面开始支持epc又没时间了……\n现在各项工作陆陆陆续续有了眉目，也想把之前放下的东西再捡起来，感兴趣可以简单翻下，如果有小伙伴也有兴趣的话，欢迎业余时间一起继续下去，倒不是觉得是项多么出彩的内容，就是觉得有些值得深究的东西想去探索一下，还有就是一项工作搁置太久会有很浓的挫败感。\n腾讯的小伙伴们很优秀，如果能有小伙伴们助攻，这个应该会加速很多。\n  dwarf v4标准解析 已完成\n  dwarf数据提取 go标准库已提供\n  delve源码解析 一小部分\n  go类型系统、运行时、调试器结合 待补充\n  go新版本准备切换dwarf v5、更好的linker，有些相关的知识，涉及到compiler、linker、debugger的协作\u0026hellip;\n  其他\n  其实，还有很多内容要补充，我也不知道最终会变成啥样，可能就是现在这样……曾经试图邀请几个小伙伴来搞下，可能本身没什么吸引力吧，最终还是这样。\n感兴趣才能坚持下去，每次想到它，都有种立即想投入的冲动，一个人的周末有点有限 :)\n"}),a.add({id:360,href:"/tags/golang/",title:"golang",description:"",content:""}),a.add({id:361,href:"/tags/tencent/",title:"tencent",description:"",content:""}),a.add({id:362,href:"/tags/work/",title:"work",description:"",content:""}),a.add({id:363,href:"/blog/2020-06-05-%E6%88%91%E5%9C%A8%E8%85%BE%E8%AE%AF%E8%BF%99%E5%87%A0%E5%B9%B4/",title:"我在腾讯这几年",description:"img {width:680px;} video {width:680px;}  写在前面 # 很长一段时间没有更新个人博客了，回头一看竟然有一年没更新，这一年工作上确实比以前忙了很多。有点时间也拿来体验生活、钻研感兴趣的技术了。感兴趣也可以看下我的github，这一年几乎也在不停地探索、尝试，因为兴趣和那份好奇，还有就是，想做点有深度的东西取悦自己。\n自从2016年7月份入职腾讯以来，也算是勤勤恳恳地工作，至少不让自己成为团队的瓶颈吧，事实上做的应该还可以吧。当然和自己的兴趣、领导的指点、工作项的安排，也有密切的关系，绝大部分工作时间，我还是比较开心的。\n今天收拾房间，无意中发现了腾讯学院的一个笔记本，翻开一看，原来是16年刚入职时培训用的材料，里面还有自己的笔记，字迹还清晰，算不上太工整。翻开新的一页，忍不住想写点什么，有感激，有欣赏，有郁闷，也有质疑，最后竟也无法落笔。\n2016年7月，我入职了 # 最早想来腾讯还是一次实习生招聘会上，自己也没有准备，就大大咧咧去了，结果挂了。面试官我感觉还算比较专业吧，当时就想着毕业后去腾讯锻炼下吧。校招季，自己也没怎么认真准备，但是还是拿了好几个offer，新浪（SP？面试官很喜欢我还愿意替我和HR沟通薪资，最终因为新浪发offer太慢没去）、去哪儿（SP？当天给的offer，不太想去北京最后没去）、阿里天猫（没认真准备，给了个B+，被各种寒酸最后没去）、华为（我就是想去搞内核，凭学习能力应该没问题，但是去了估计也不是这个方向，没去）\u0026hellip;最后我想到腾讯上次实习给我挂了，在腾讯校招补录阶段的时候过了（SP）。\n我也不知道当初面这么多是为了什么，只是想证明下自己可以通过某些公司的面试？可能吧，人缺乏自信的时候，就容易做这些傻事，总是希望从别人口中的评价来认识自己。\n入职之前，我问早进来的同学，正式入职那天，我需要穿正装吗？结果当天来的时候发现有些人等电梯的时候，穿拖鞋的小哥，为了凉快，直接把脚踩地上。暗自庆幸，穿正装来了反而是个另类。\n 2016.7.24 入职+破冰 2016.7.25 开班典礼 + \u0026ldquo;腾讯用户导向\u0026quot;培训 2016.7.26 走进腾讯与腾讯文化 \u0026hellip;  十几天的封培，认识了很多同事，也大概了解了腾讯的一些文化、工作方式，这期间吃的也不错，我还想会不会我这常年120斤的体重也可以增重下了。\n封培结束时，也有部分总办领导来参加了闭幕式，还跳了一段。当时我觉得领导和一线工作人员能这么互动，应该工作氛围很不错，应该很有活力，当时对腾讯有很高的期望值，自己也愿意加入其中，贡献一点力量。\nYour browser doesn't support the video tag.  2016年8月，来到组织 # 封培结束后，来到当时的即通应用部/互动视频产品部，我就成了这里的一名后台开发，开始写自己的代码。当时我的导师磊哥，对我还是挺照顾的，还有leader，周围的小伙伴，他们的帮助下，我快速融入了团队。不过嘛，我来了快一周的时候，就忍不住想吐槽，当时做个消息推送的工具，调用的API竟然连个文档说明也没有。我是比较喜欢写文档的，一个是比较专业，一个是能减少不必要的沟通，何乐而不为。关键当时的API的负责人还贼难沟通，我也是服气，从那开始，就陆陆续续地认识了真实的腾讯，褒贬参半，比较真实。\n2016年10月，邀父母来深圳玩 # 我东西差不多准备好了之后，自己也开始挣钱了，想着父母一直勤勤恳恳工作，供我上学工作，现在可以请他们来深圳玩玩，以前父母也没有舍得出去玩过。我内心里是特别希望他们出来走走的，我也尽尽孝心。\n那时候家里面也挺忙的，爸爸没有过来，妈妈一个人过来了，我当时心里略有点遗憾，还想着爸爸你也不来，那就只能看妈妈在这玩的照片了，只能有羡慕的份了。和妈妈逛了深圳的几个比较好玩的地方，世界之窗、锦绣中华、动物园、深圳湾公园……妈妈走的那天，妈妈很开心，觉得我长大了，可以自己闯荡了，在这里呆了两周也想回家了。\n那次爸爸没有来，本来我想着后面有的是机会，可没想到竟然成了永远的遗憾。17年爸爸就走了，病痛折磨地父亲不轻，我第一次觉得生命是脆弱的，又是坚强的，生命是短暂的，又是无限的，正如我的父亲走了，但是他永远活在我心里，直到我也离开，直到这些文字丢失，淹没在互联网信息的大海里。\n2016年10月，组织架构调整 # 那天我发高烧，请了个病假，晚上导师给我电话说，我们组织架构调整，把我调到一个新的组里面了，我有点错愕。不过也还好，新leader、组内同事，都很不错，工作上对我指导都不少，特别是leader，是我学习计算机以来，少有的几个真心佩服的人，不管是领导能力，还是沟通、技术，都非常值得学习。\n2017年X月，最痛苦的一年 # 2017年，是我经历过的最痛苦的一年，我想可能也是我以后几十年中最痛苦的一年。如果人的记忆可以像日历那样，翻来翻去，我愿意撕去我的2017年。\n17年我看到爸爸被病魔折磨，爸爸走后，多少次做梦，不论前面的故事多好，最后总会变成父亲哭着不舍离开的画面，一次又一次从梦里醒来。我们平日里既没有单独晒过朋友圈，也没有留下多少照片。我感谢Apple创造的live photos，让我还能未来几十年间一遍又一遍地看到父亲的音容笑貌，我的设备里还有2段爸爸的音频，那是我仅有的贵重的东西，担心它丢失，所有的设备、移动硬盘、云存储、微信、qq中都做了备份。这些，就是我仅有的东西，是我最重要的东西……其他的钱、房、股票，I don\u0026rsquo;t care.\n爸爸的离开，对于他来说，是种解脱，作为儿子，面对我深爱着的父亲，我说不出任何安慰的话，任何安慰的话都显得苍白无力，任何安慰的话都显得是对生命的不敬，更何况那是我的父亲，我能做的就是陪在他身旁，减轻他的疼痛、想念，也让他放心，让他放心我会照顾好妈妈。最开始，我想着，我需要挣钱给爸爸治病，陪爸爸做了第一次手术休养了一周，感觉好像在变好。我内心里充满了希望，回来更卖力的工作挣钱。让我感觉到绝望的不是自己没准备好，是在我充满希望的时候，现实一次次突破我希望的底线，一次又一次，从充满希望，到有一丁点希望，到没有希望想去试一下，到最后不愿接受不得不接受的事实真相……\n我从小到大，第一次感觉那么挫败，我没有能力挽救爸爸，脑海里无数次飘过父亲会怎样离开我们，我以为我做了最坏的打算，我以为我准备好了，事实上没有。爸爸，一定去了天堂，如果真的有天堂，有上帝，上帝一定会让他这样的好人去天堂！天堂不再有痛苦！\n不知不觉中，我的手机壁纸已经3年没有更换了！3年了！从来没有更换过！我已经习惯了每次拿出手机，都可以看到爸爸，我已经习惯了那个手机号码，多花了几千块钱把爸爸的手机号码转到了自己名下。家里爸爸用过的工具、躺椅、推车、扳手等，也都成了我视如生命的遗产。我不想家里有一丝一毫的改变，最好是封存这一切。有人说我还没走出来，其实不是，我的内心很强大，我只是选择了习惯有爸爸的生活，而不是像多数人一样扔掉烧掉来淡忘。我并没有往过去的伤口上撒盐，我只是想让这些疤痕更清晰一些，清晰到我看到摸到身边的东西时，就可以置身于2017年以前的时段，那里有我熟悉得不能再熟悉的爸爸。\n爸爸走后，我变成了家里的顶梁柱，我会努力丢掉小性子，成为他期望我成为的样子。18年春节回到家，翻看爸爸以前的记账本，第一页写着“干干净净做人，利利索索做事”，朴实中透漏出他的人格。我是他的儿子，那也是我的座右铭，“堂堂正正做人，踏踏实实做事”，这是06年读初中时，我的物理老师口授给我的，我一直印在心里。想想，也是种缘分，好像10来年后，我和爸爸一对暗号，原来是一样的！果然是父子俩！\n此后，也更全身心地投入到了工作当中，努力工作，努力挣钱，照顾家人，我觉得自己算是相对比较努力的了，希望爸爸在天之灵不会对我失望。\n17年，有同事参与赌博，拆东墙补西墙，向我借钱，结果还没偿还一分，就被公安带走了，自己才得知真相。17年各种事情，各种不确定性下，我决定先买套房做个后路，现在也没增值多少，不过也还可以。借了姨妈、姐姐他们些钱，也都还清了，没什么压力了。现在也陆陆续续地有了积蓄。\n17年下半年就是努力工作吧，尽力做到对的起领导的栽培、同事这段时间的帮助、包容，感谢了！\n2018年X月 # 认真工作，做好业务+学习技术 # 上半年，也算是认认真真的工作，认真做好产品的业务需求，认真维护好常用的管理后台，包括相关的后端框架jungle-admin的维护、前端使用体验的优化，我自己觉得还是做了些工作的，方便了大家的开发效率，提升了使用体验。\n我们leader（现在已经是总监了），对技术很有钻研，也很有创新能力，经常带领我们高些比较有建设性的东西，比如接口测试工具、代码生成工具、微服务框架设计开发等等吧，很多。在这期间，自己也锻炼了很多，成长了很多。当然也很开心，学到东西就很开心。\n这一次，我收获了来腾讯后的第一个四星，很开心。\n拥抱变化，加入内容平台中心 # 18年上半年，互动视频相关的建设基本比较稳定了，业务上也没有那么紧张了，7月份之后吧，我们又拥抱变化，加入了内容平台中心来支持信息流相关的内容中台建设，直到现在。",content:" img {width:680px;} video {width:680px;}  写在前面 # 很长一段时间没有更新个人博客了，回头一看竟然有一年没更新，这一年工作上确实比以前忙了很多。有点时间也拿来体验生活、钻研感兴趣的技术了。感兴趣也可以看下我的github，这一年几乎也在不停地探索、尝试，因为兴趣和那份好奇，还有就是，想做点有深度的东西取悦自己。\n自从2016年7月份入职腾讯以来，也算是勤勤恳恳地工作，至少不让自己成为团队的瓶颈吧，事实上做的应该还可以吧。当然和自己的兴趣、领导的指点、工作项的安排，也有密切的关系，绝大部分工作时间，我还是比较开心的。\n今天收拾房间，无意中发现了腾讯学院的一个笔记本，翻开一看，原来是16年刚入职时培训用的材料，里面还有自己的笔记，字迹还清晰，算不上太工整。翻开新的一页，忍不住想写点什么，有感激，有欣赏，有郁闷，也有质疑，最后竟也无法落笔。\n2016年7月，我入职了 # 最早想来腾讯还是一次实习生招聘会上，自己也没有准备，就大大咧咧去了，结果挂了。面试官我感觉还算比较专业吧，当时就想着毕业后去腾讯锻炼下吧。校招季，自己也没怎么认真准备，但是还是拿了好几个offer，新浪（SP？面试官很喜欢我还愿意替我和HR沟通薪资，最终因为新浪发offer太慢没去）、去哪儿（SP？当天给的offer，不太想去北京最后没去）、阿里天猫（没认真准备，给了个B+，被各种寒酸最后没去）、华为（我就是想去搞内核，凭学习能力应该没问题，但是去了估计也不是这个方向，没去）\u0026hellip;最后我想到腾讯上次实习给我挂了，在腾讯校招补录阶段的时候过了（SP）。\n我也不知道当初面这么多是为了什么，只是想证明下自己可以通过某些公司的面试？可能吧，人缺乏自信的时候，就容易做这些傻事，总是希望从别人口中的评价来认识自己。\n入职之前，我问早进来的同学，正式入职那天，我需要穿正装吗？结果当天来的时候发现有些人等电梯的时候，穿拖鞋的小哥，为了凉快，直接把脚踩地上。暗自庆幸，穿正装来了反而是个另类。\n 2016.7.24 入职+破冰 2016.7.25 开班典礼 + \u0026ldquo;腾讯用户导向\u0026quot;培训 2016.7.26 走进腾讯与腾讯文化 \u0026hellip;  十几天的封培，认识了很多同事，也大概了解了腾讯的一些文化、工作方式，这期间吃的也不错，我还想会不会我这常年120斤的体重也可以增重下了。\n封培结束时，也有部分总办领导来参加了闭幕式，还跳了一段。当时我觉得领导和一线工作人员能这么互动，应该工作氛围很不错，应该很有活力，当时对腾讯有很高的期望值，自己也愿意加入其中，贡献一点力量。\nYour browser doesn't support the video tag.  2016年8月，来到组织 # 封培结束后，来到当时的即通应用部/互动视频产品部，我就成了这里的一名后台开发，开始写自己的代码。当时我的导师磊哥，对我还是挺照顾的，还有leader，周围的小伙伴，他们的帮助下，我快速融入了团队。不过嘛，我来了快一周的时候，就忍不住想吐槽，当时做个消息推送的工具，调用的API竟然连个文档说明也没有。我是比较喜欢写文档的，一个是比较专业，一个是能减少不必要的沟通，何乐而不为。关键当时的API的负责人还贼难沟通，我也是服气，从那开始，就陆陆续续地认识了真实的腾讯，褒贬参半，比较真实。\n2016年10月，邀父母来深圳玩 # 我东西差不多准备好了之后，自己也开始挣钱了，想着父母一直勤勤恳恳工作，供我上学工作，现在可以请他们来深圳玩玩，以前父母也没有舍得出去玩过。我内心里是特别希望他们出来走走的，我也尽尽孝心。\n那时候家里面也挺忙的，爸爸没有过来，妈妈一个人过来了，我当时心里略有点遗憾，还想着爸爸你也不来，那就只能看妈妈在这玩的照片了，只能有羡慕的份了。和妈妈逛了深圳的几个比较好玩的地方，世界之窗、锦绣中华、动物园、深圳湾公园……妈妈走的那天，妈妈很开心，觉得我长大了，可以自己闯荡了，在这里呆了两周也想回家了。\n那次爸爸没有来，本来我想着后面有的是机会，可没想到竟然成了永远的遗憾。17年爸爸就走了，病痛折磨地父亲不轻，我第一次觉得生命是脆弱的，又是坚强的，生命是短暂的，又是无限的，正如我的父亲走了，但是他永远活在我心里，直到我也离开，直到这些文字丢失，淹没在互联网信息的大海里。\n2016年10月，组织架构调整 # 那天我发高烧，请了个病假，晚上导师给我电话说，我们组织架构调整，把我调到一个新的组里面了，我有点错愕。不过也还好，新leader、组内同事，都很不错，工作上对我指导都不少，特别是leader，是我学习计算机以来，少有的几个真心佩服的人，不管是领导能力，还是沟通、技术，都非常值得学习。\n2017年X月，最痛苦的一年 # 2017年，是我经历过的最痛苦的一年，我想可能也是我以后几十年中最痛苦的一年。如果人的记忆可以像日历那样，翻来翻去，我愿意撕去我的2017年。\n17年我看到爸爸被病魔折磨，爸爸走后，多少次做梦，不论前面的故事多好，最后总会变成父亲哭着不舍离开的画面，一次又一次从梦里醒来。我们平日里既没有单独晒过朋友圈，也没有留下多少照片。我感谢Apple创造的live photos，让我还能未来几十年间一遍又一遍地看到父亲的音容笑貌，我的设备里还有2段爸爸的音频，那是我仅有的贵重的东西，担心它丢失，所有的设备、移动硬盘、云存储、微信、qq中都做了备份。这些，就是我仅有的东西，是我最重要的东西……其他的钱、房、股票，I don\u0026rsquo;t care.\n爸爸的离开，对于他来说，是种解脱，作为儿子，面对我深爱着的父亲，我说不出任何安慰的话，任何安慰的话都显得苍白无力，任何安慰的话都显得是对生命的不敬，更何况那是我的父亲，我能做的就是陪在他身旁，减轻他的疼痛、想念，也让他放心，让他放心我会照顾好妈妈。最开始，我想着，我需要挣钱给爸爸治病，陪爸爸做了第一次手术休养了一周，感觉好像在变好。我内心里充满了希望，回来更卖力的工作挣钱。让我感觉到绝望的不是自己没准备好，是在我充满希望的时候，现实一次次突破我希望的底线，一次又一次，从充满希望，到有一丁点希望，到没有希望想去试一下，到最后不愿接受不得不接受的事实真相……\n我从小到大，第一次感觉那么挫败，我没有能力挽救爸爸，脑海里无数次飘过父亲会怎样离开我们，我以为我做了最坏的打算，我以为我准备好了，事实上没有。爸爸，一定去了天堂，如果真的有天堂，有上帝，上帝一定会让他这样的好人去天堂！天堂不再有痛苦！\n不知不觉中，我的手机壁纸已经3年没有更换了！3年了！从来没有更换过！我已经习惯了每次拿出手机，都可以看到爸爸，我已经习惯了那个手机号码，多花了几千块钱把爸爸的手机号码转到了自己名下。家里爸爸用过的工具、躺椅、推车、扳手等，也都成了我视如生命的遗产。我不想家里有一丝一毫的改变，最好是封存这一切。有人说我还没走出来，其实不是，我的内心很强大，我只是选择了习惯有爸爸的生活，而不是像多数人一样扔掉烧掉来淡忘。我并没有往过去的伤口上撒盐，我只是想让这些疤痕更清晰一些，清晰到我看到摸到身边的东西时，就可以置身于2017年以前的时段，那里有我熟悉得不能再熟悉的爸爸。\n爸爸走后，我变成了家里的顶梁柱，我会努力丢掉小性子，成为他期望我成为的样子。18年春节回到家，翻看爸爸以前的记账本，第一页写着“干干净净做人，利利索索做事”，朴实中透漏出他的人格。我是他的儿子，那也是我的座右铭，“堂堂正正做人，踏踏实实做事”，这是06年读初中时，我的物理老师口授给我的，我一直印在心里。想想，也是种缘分，好像10来年后，我和爸爸一对暗号，原来是一样的！果然是父子俩！\n此后，也更全身心地投入到了工作当中，努力工作，努力挣钱，照顾家人，我觉得自己算是相对比较努力的了，希望爸爸在天之灵不会对我失望。\n17年，有同事参与赌博，拆东墙补西墙，向我借钱，结果还没偿还一分，就被公安带走了，自己才得知真相。17年各种事情，各种不确定性下，我决定先买套房做个后路，现在也没增值多少，不过也还可以。借了姨妈、姐姐他们些钱，也都还清了，没什么压力了。现在也陆陆续续地有了积蓄。\n17年下半年就是努力工作吧，尽力做到对的起领导的栽培、同事这段时间的帮助、包容，感谢了！\n2018年X月 # 认真工作，做好业务+学习技术 # 上半年，也算是认认真真的工作，认真做好产品的业务需求，认真维护好常用的管理后台，包括相关的后端框架jungle-admin的维护、前端使用体验的优化，我自己觉得还是做了些工作的，方便了大家的开发效率，提升了使用体验。\n我们leader（现在已经是总监了），对技术很有钻研，也很有创新能力，经常带领我们高些比较有建设性的东西，比如接口测试工具、代码生成工具、微服务框架设计开发等等吧，很多。在这期间，自己也锻炼了很多，成长了很多。当然也很开心，学到东西就很开心。\n这一次，我收获了来腾讯后的第一个四星，很开心。\n拥抱变化，加入内容平台中心 # 18年上半年，互动视频相关的建设基本比较稳定了，业务上也没有那么紧张了，7月份之后吧，我们又拥抱变化，加入了内容平台中心来支持信息流相关的内容中台建设，直到现在。\n清理了很多历史遗留问题，也做了一些架构设计、优化方面的工作，也得到了些锻炼。\n下半年，由于内部团队技术栈不统一，存在各种各样的问题，为了提升大家的开发效率、开发质量，我们开始准备把上半年自研的微服务框架goneat给打磨地更好。这半年，我们在这里面投入了很多，我自己也乐在其中，经常晚上一两点钟了，还在那里写代码。但是看到自己写的代码能够支撑团队技术同学稳定上线一个服务，心里就很开心。遇到问题，也乐于及时去帮助定位，去解决。\n截止到现在为止，goneat框架已经支撑了线上1k+多个服务的稳定运行了，感觉就有点成就感。\n2019年X月 # 计划持续打磨goneat并推广 # 19年上半年，我给自己定了点KPI，就是好好打磨goneat并做一个比较大范围的推广。我确实很想把这个事情做成，让投入其中的同学也都有获得感、成就感，当然更希望它能解决公司内部开发框架的一些问题。\n公司内有很多框架，相对来说，我觉得goneat是设计的比较好的，虽然也有这样那样的问题吧，但是相对来说，有些设计理念还是比较好的。\n然后，上半年我和小伙伴花了很多时间做了框架文档、网站方面的建设，有的小伙伴喜欢建网站，我比较喜欢写文档、分析源码，有的支持下demo，我们感觉做的也算是如火如荼。因为我们投入的比较好，协作的一些数据什么的都挺不错，代码、文档都不错，还拿了2019年5月刊的公司级代码文华奖。\n感觉很有成就感，下面准备再进一步建设、推广的时候，却被一下子喊停了，因为bg层面要牵头做一个更好的微服务框架了。\n支持公司级微服务框架建设 # 19年下半年，就投入了公司级微服务框架trpc的设计、开发，在设计的过程中，我们也参考了很多开源框架的设计，然后参与核心架构设计的同学也大多是参与过框架相关建设的，各个语言层面统一设计、规划、协调、开发、推广，做的还是很不错的。\n在这期间呢，也少不了讨论，有的时候会演变为辩论。现在觉得程序员Show me the code是非常有必要的！对于框架设计而言，有时候说show me the code并不是为了炫耀你很厉害，而是阐述你的思想是不是行的通。当时针对协议编解码支持方面，我就有比较大的意见，和大多数同学意见不一致，最后也是少数服从多数按照大家的意思进行支持的。我为此愤懑了很久，为什么就get不到我的思路呢。\n现在我其实也想通了，如果当时我及时show me the code，那这里的设计可能就不是这个样子！即便是现在，我对这里的设计也是不满意的，因为它的问题很明显，只是很多业务开发的同学，或者没有挑剔眼光的框架开发者，感觉不到它的存在罢了。\n发现问题，从混乱中抽象出更清晰的设计脉络，本身就是种特殊的能力。不过我已经不那么愤懑了，相比一个点的设计优劣而言，能有一个靠谱的全局落地计划，会更重要一些。毕竟我们是来解决问题的，而不是要创造一个什么完美的东西！追求better code，而非perfect code！better and better，会慢慢趋近perfect！\n这期间有成长，有郁闷，有认可，有质疑，这并不是一个多么轻松的活，坚持下来，从0到1，也算是我从头到尾跟完的一个比较大型的项目了。期间也进一步加深了自己对架构设计、微服务架构设计、项目管理、代码质量、推广运营等相关方面的一些理解。我将在我的书 go-rpc-book 中讲述我的心得体会，敬请关注。\n2020年X月 # 如今2020年已经过半，来到这个档口，又多了一些思考。从公司组织架构调整以来，公司的很多团队在整合优势资源，通过开源协同去共建一些优秀项目，而不再是抱残守缺似的闭门造车。\n我相信，腾讯的技术在未来几年肯定会越来越好的，但是因为有很多存量系统的选型、实践，这个还是要时间来消化的，业务上势必会经历一段时间的阵痛，这些阵痛一定会落在研发同学身上。或长或短，看技术建设推进的力度和领导的魄力，一线开发的自主选择能力。如果大家都选择闭嘴，只唯上不唯是，那这样的技术推进，也有可能剑走偏锋，有弊无利。这半年吧，一直在承担trpc框架的应用推广、研发效能提升方面的工作，我非常认同这背后的理念，只是落地的计划上我觉得是可以改善的。\n说真的，这半年我觉得有点累，心累、身体累、没有成就感，包括答辩晋升在内吧，心里有点不甘，对评委专业能力、评审合理性也有质疑。\n总结一句话，没有达到自己想要的那种成长吧。\n还有，原本想按计划推进下业务方面的建设，突然来个研发效能提升，但是工具平台建设，半年多了还是一团糟，我很难知道团队现状到底好在哪里，坏在哪里。继续这么干下去，慢腾腾的，下半年多半还是这样的工作。\n我想做出一些改变，思维上，行动上，自己为自己做主，不能被动地等待机会或外部改变。\n客观上房子是全款买的，有存款，没有经济上的压力。自己对现在工作状态不满，也许工作就是这样吧，但是我想做更多有价值的东西，而不是替别人频繁擦屁股。虽然自己没强到那么强，但是学习谁不会，而且我觉得自己学习能力很强呢，只是我不愿意和这种做事的人一起鬼混了而已了。\n最最重要的，我有一些想法，感觉很不错，想去尝试一下。万一成功了呢，就可以摆脱这种猪狗不如的日子了。到时候我就可以开开心心地写写自己想写的代码。也没必要因为评委不专业、评审规则的问题来等他们评审晋升，不值得。更没必要因为一些合作方的懒惰、不作为，搞的自己婚假期间还要为了他们的KPI去做一些老板面子上的事情。谁的时间不是时间！\n现在，我也知道自己有哪些优点和不足，通过一些学习、对比也能清晰地认识到未来自己的可能发展路径，我也不会因为别人一时的评价、工作的不如意，再反过来质疑自己。看上去一切都已经慢慢变得更好，但我真的不满足于这样了，我想挑战更多，体验更多。时间不应该这样被浪费掉。\n现在的工作、生活、时间，都与我个人的目标产生了激烈的对抗和冲突。人和人还是不一样的，毕竟不是每个人都想机械地工作，原封不动地按照前辈们踩出的脚印重新走一遍人生……有些人说，你应该知足，相比老家很多人工作都发愁，你这工作不风吹雨晒坐办公室的，怎么还不知足呢？不是不知足，追求的东西不一样而已，自己喜欢的东西，就不要去问别人好不好，因为在别人看来可能根本就毫无意义。有次和朋友开玩笑说，我可能会放弃技术这条线，他感觉很不理解，认为我做技术很不错、钻研的也不错，不是太可惜了吗？有什么可惜的，相比某些人认为的成功，我宁可去争取骑个摩托，跑遍中国。\n最后 # 既然已经考虑的这么清楚了，无论结果如何，都应该行动起来。最后，我坚定地落下了笔，做一个对自己负责的舵手！\n"}),a.add({id:364,href:"/tags/gatsby/",title:"gatsby",description:"",content:""}),a.add({id:365,href:"/tags/generator/",title:"generator",description:"",content:""}),a.add({id:366,href:"/tags/gitbook/",title:"gitbook",description:"",content:""}),a.add({id:367,href:"/tags/hugo/",title:"hugo",description:"",content:""}),a.add({id:368,href:"/tags/jekyll/",title:"jekyll",description:"",content:""}),a.add({id:369,href:"/tags/mkdocs/",title:"mkdocs",description:"",content:""}),a.add({id:370,href:"/tags/readthedocs/",title:"readthedocs",description:"",content:""}),a.add({id:371,href:"/tags/static-site/",title:"static site",description:"",content:""}),a.add({id:372,href:"/blog/2020-05-30-%E9%9D%99%E6%80%81%E7%AB%99%E7%82%B9%E7%94%9F%E6%88%90%E5%99%A8/",title:"静态站点生成器，为什么选择hugo？",description:"技术人没个自己的技术博客怎么行，及时总结分享一下自己学习的东西，不仅仅是对自己现阶段的工作总结，对别人也可能是一种无形的帮助，没准有需要的人接触到了什么问题刚好能获得帮助。那么有什么工具可以帮助开发人员快速建立技术博客呢？结合技术人的技术栈、常用工具，技术人用的比较多的就是markdown，如果能有工具迅速将markdown以web页面的形式进行发布并提供一致便捷的阅读体验就好了。本文就来介绍相关的工具。",content:" img {width:680px;} video {width:680px;}  Hugo 是一个静态站点生成器，是评测最快的静态站点生成器，采用golang编写，依赖bep、spf13、friends这几个第三方库来实现。Hugo是一个不错的静态站点生成器，类似的还有readthedoc、gitbook、jekyll、gatsby等等，谈谈我对这几个流行的站点生成器的看法。\njekyll # jekyll，是我使用的第一个静态站点生成器，用于我的 github pages， 它有比较丰富的主题，这个是我当时选择的一个原因，我可以专心于文档的编写，文档也是markdown格式。但是由于它对markdown的支持比较鸡肋，比如缺乏对图片引用、图表、plantuml、flowchart等的良好的支持，最终让我觉得通过jekyll来维护一个静态站点比较痛苦。\ngitbook # gitbook，是我平时经常使用的一个编辑工具吧，特别是涉及到类似书籍章节的大量内容组织的时候，现在依旧是我常用的编辑工具之一。gitbook-cli是其配套的一个工具，现在已经不再更新、维护，离线编辑已经不再被支持，现在转为线上服务。我还是比较倾向于离线编辑，不得不寻求其他可替代方案。\nreadthedoc # 见名知意，readthedoc确实比较用来写技术文档，其本身也是为了给python写api文档的，其用来构建类似的技术文档、手册还比较合适，但是用来构建一个更通用点的静态站点的话就有些不合适，不管多大的屏幕，它展示的区域总是那么小，有点死守每行N个字符的味道。\ngatsby # 这个也是一个比较好用的静态站点生成器，网上也有很多它和hugo的对比，由于我对背后的实现js等不太熟悉，而我本人也经常有些定制化的修改需求，我还是有可能会去改下源码为自己所用的，所以选型阶段直接放弃。\nmkdocs # mkdocs和gitbook类似，使用都比较简单，但是其风格定制化比较难操作，如果你对它的默认风格不太满意，又想定制主题，而不想沾染什么前端相关的工作，mkdocs可能并不一定合适。\nhugo # hugo的支持、维护、更新都还不错，生态也不错，也有很多使用hugo的公司、团队、个人用它来维护自己产品、个人的文档、博客等等，也有比较丰富的主题可供选择。hugo的好处是它的主题是完整的，包括各种各样的插件，可以体验、下载安装、应用中意的主题，后续切换主题也比较方便。而且hugo也提供了一些命令行操作来快速发布静态站点。还有就是对golang的偏爱，意味着我可以在有需要的时候了解其实现，修改其源码进行定制化，或者做贡献。\n综合上述考虑和对比，现在呢，我更倾向于使用hugo来作为接下来的静态站点生成器。\n"}),a.add({id:373,href:"/tags/hammerspoon/",title:"hammerspoon",description:"",content:""}),a.add({id:374,href:"/tags/ical/",title:"iCal",description:"",content:""}),a.add({id:375,href:"/tags/mac/",title:"mac",description:"",content:""}),a.add({id:376,href:"/tags/shortcuts/",title:"shortcuts",description:"",content:""}),a.add({id:377,href:"/tags/spotlight/",title:"spotlight",description:"",content:""}),a.add({id:378,href:"/blog/2020-04-25-%E4%BD%A0%E7%9A%84mac%E6%9C%89%E5%93%AA%E4%BA%9B%E8%B6%81%E6%89%8B%E7%9A%84%E9%85%8D%E7%BD%AE/",title:"你的mac有哪些“趁手”的配置呢？",description:"每个人的习惯不一样，每个人电脑到手后要做的定制化配置也不一样，比如常用的软件、快捷键、效率工具等等的，程序员可能会开发些常用的工具来增强操作效率等等。我就感觉我老婆mac操作效率挺低效的，实际工作中据我观察很多同事的操作效率都很低效，于是有此文，分享下自己在mac使用方面上的一点心得。效率低也无所谓，完成工作就可以，但是我不行，我不能忍受无休止的体力劳动，所以我会想办法来提效，如果我每天要重复一个操作很多次以上。",content:" img {width:680px;} video {width:680px;}  这阵子上班在同事之间走动比较多，发现基本上已经人手一台mac，但是对系统的配置、使用却大不同。也有新同学估计是windows转过来的，适应起来也有困难。听物资管理的同事提起过，有同学因为不习惯mac重新换机器的也不少。\n前几天生日，买了台新设备送自己（原本打算买Aprilia 150，先放放），恰好生日前一天到😃。刚好也在做一些配置的事，就把过程中觉得比较有分享价值的整理分享下。\n回想起16年参加工作刚领工资那个月，兴冲冲地买了mbp，端端正正的16:10屏幕，细腻的分辨率，舒服的键盘，人性化的键盘灯，灵敏的触控板……哇，硬件完美，这就是我想要的工具。试用了一天之后，发现很难适应。狂吐槽，经常拿它和Linux桌面做对比，过了一段时间的调教，发现还是可以的😃。\n自己老设备也没使用time machine来做快照，没那么大硬盘分区了，而且有很多垃圾，还是干干净净从头来一遍吧，也把过程中值得分享的记录下（尽量做到合适的归类）。\n1 Spotlight\n以前，搜索引擎是大家了解信息的主要入口，搜索、热门词条等，spotlight是一个类似的东西，它提供了一个入口让用户可以快速触达待访问的内容，可能是启动一个应用程序，进入一个文件路径，打开一个文件，翻译一个单词，进行一段科学计算，执行一个工作流，全文搜索，OCR搜索你的网页批注……网络搜索……\n听起来很美好是吧，这个玩意也不是什么新鲜的东西，在Windows、Linux上都有类似的工具，比如KDE上按键F2 进入搜索基本上是同样的效果，Unity、GNOME上都有类似的，特别是XBuntu上对spotlight进行了高度“抄袭”😃。\n调整原因：默认command+space是启动spotlight，与输入法切换冲突\n调整推荐：快捷键调整成 command+/，这个组合键简单，又避免冲突\n2 Launchpad\nLaunchpad有点类似于windows下的开始菜单，这里可以搜索安装的应用程序，和windows相比一个好点的地方是，可以对应用进行分组，现在Android、iOS都支持，大家应该不陌生，好处就是避免了冗长的程序列表，定位也更快。\n因为有了Spotlight、Alfred（下面会提到），Launchpad并不算是一个高频操作，所以我把Option按键用来分配组合键，Option+W。\n另外，Launchpad偶尔会抽风，将应用顺序、组合全部搞的错乱，这个也不用怕，安装Launchpad Manager来管理Launchpad布局，并将最新布局导出到icloud进行备份，如果哪天抽风了，拿出来恢复一下就可以。CleanMyMac扫描大文件的时候偶尔会干掉Launchpad对应的数据文件，从CleanMyMac的搜索路径里屏蔽掉就可以了。\n3. Desktops\n现代的桌面操作系统都支持多任务，一边听着音乐，一边写着文档等等，这是常有的事情，然而每个人理解的多任务可能不太一样。\n可能有的用户真的没那么多任务要处理，也就是一边公放着音乐，一遍斗地主，诸如此类，那一个桌面可能就够了。但是，多任务也可能是下面这样的，甚至更多。如果真的只能通过Alt+Tab来切换简直是噩梦。\n多个虚拟桌面的好处就体现出来了，Ubuntu Unity里面的workspace，KDE里面的Pages，macOS里面的Desktop，Windows 10里面的taskview，anyway，总之都是一个意思，无非就是为了方便用户进行任务管理。按照任务类别适当将任务组织到不同的Desktop，并按照就近原则将常用的任务放在切换时更快速访问到的Desktop，是个比较好的做法。\n通过触控板可以方便地在上述虚拟Desktop间进行切换，也可以将窗口移动到其他的Desktop。说到这里就不得不提触控板、窗口拖动、快捷键的设置，嗯，这里先只讲快捷键设置吧。\n快捷键快速切换Desktop，默认改成了Ctrl+Command+ Left Arrow，其实用触控板也可以，至于为什么想用快捷键？可能电脑大小比例不符合人体工程学，经常性地触控板左右滑动之后，会感觉手腕很累……所以键盘、触控板交替着用，会舒服一点。\n如果左右切换都嫌累，嫌麻烦，拖拽窗口到其他Desktop就更麻烦了，比如有的时候你在Desktop1打开了一个编辑器，但是你后面意识到它应该移动到其他Desktop2中去（KDE里面有种更好的管理方式叫Activity），那你就得手动移动过去，问题是如果Desktop2中窗口比较多，你移动过去发现，唉，移动错了，应该移动到Desktop3中去，然后你又开始拖动……\n效率是什么，效率就是短小精悍，让响应跟上思维的速度，这种看似不起眼的事情，我是不愿意让它悄悄消耗掉自己的时间。如果支持快捷键快速将一个窗口移动到另一个Desktop会方便一点，因为快捷键可以连续触发，而不用再次拖拽来个位移。KDE里面pages管理，是有考虑到这些的，macOS里面没有，当然也可以做到，只不过嘛就要自己动手了。\nHammerspoon（下文会提到）是针对macOS提供的一个可扩展的工具，通过lua脚本封装了大多数的macOS系统编程接口，如果你想定制化一些操作，只要看着hammerspoon的文档写lua脚本就可以了，论一个开发者的好处。\n写这么一段lua脚本，放置到~/.hammerspoon目录下，就支持快捷键Shift+Ctrl+Cmd+Arrow Keys来快速移动窗口了，至于为什么选择这个快捷键，习惯，KDE下面多年养成的习惯。\n4 Trackpad\n触控板还需要设置吗，要设置，适合自己的才是最好的。\nTap to click，点选这个勾上，这样就不用每次“按”一下才触发单击操作。\nScroll direction: Natural，这个滚动方向，现在虽然不用鼠标了，但是习惯养成了。比如浏览网页的时候，想从页面底部回到顶部，或者希望向上滚动，我想的是，把页面往下拽一下页面顶部的位置就展示在眼前了。这里的natural滚动方向我就很难适应，有相似的可以取消勾选。\n我不想知道自己干什么的时候该用几根手指，我只想完成想干的事情。所以我几乎都设置成了四指操作，有的最多只有三指的，那就三指好了，反正四指也可以触发，去掉这些记忆负担。\n使用触摸板拖动窗口，默认设置是先点按窗口标题栏，按住不放，再一只手将其拖动，这个操作很不方便，设置下可以直接三指窗口拖动。现实场景中，一般我是通过hammerspoon自定义脚本来完成的：最大化、最小化、居中、左半屏、右半屏等。但是，移动窗口的需求还是有的。\n5 Keyboard\n键盘设置，默认键盘设置，对经常需要文字编辑工作的朋友来讲不算友好，主要有几个方面我觉得要调整。\n中英文切换方面\n搜狗输入法用了很多年，也是国内厂商比较早支持Linux的全拼输入法，对其印象很好，而且支持个人词库同步，这么多年录入的词库也是愿意继续使用的主要原因，没有使用系统自带的拼音输入法。\n搜狗输入法shift按键支持快速在中英文之间进行切换，这个想必大家都知道。作为一名开发者，快速在中英文之间进行切换是常有的事，但是切换输入法也要细分场景。\n比如现在要准备写一大段代码了，那可能这段时间内全是英文比较好，那按shift切换成英文就不太合适，因为一不小心再按下shift可能会让我误输入中文；\n再比如现在准备切成中文写几行注释，写完立即接着写代码，那可能按shift切换就比较合适；\n再比如编辑期间涉及到窗口切换，比如去参考下文档、资料……然后回来接着继续刚才的工作，你会发现输入法中英文你已经不记得了，如何确保现在输入英文或中文；\n这都是影响文字编辑效率的问题，我是这么解决的，也很简单：\nCommand+Space执行切换时，总是会将搜狗切换到中文输入法，而Ctrl+Space不一定，还有另一个区别，前者进行输入法切换时，如果按键释放时间稍长，会提示当前正切换到的输入法名称。一举三得！\n文字输入速度方面\n影响文字输入的，不仅有实际的击键速度、准确率，还有这玩意。Key Repeat、Delay Until Repeat这两个选项一个是用于控制按键重复重发的速率，一个是用于控制按键初始延迟，默认值是考虑到用户误输入的情景，减小了前者，增大了后者。\n不过，对有特殊需求的开发者、文字工作者，可能就没那么友好了，直接将Key Repeat调到最大，Delay Until Repeat调到最低。\n修改完成后，如果感觉还是不满意，那只能通过defaults命令来修改配置了，不对这里的设置进行优化，会让Vim党很抓狂，绝对暴躁的起来（想象下hjkl怎么玩）。\ndefaults write NSGlobalDomain KeyRepeat -int 3 defaults write NSGlobalDomain InitialKeyRepeat -int 12 defaults write -g ApplePressAndHoldEnabled -bool false  快捷键方面\n新版的mbp都带了touchbar，touchbar有时候有用，有时候没用，对实际经常需要用到F1~F12快捷键的同学来说，touchbar还真有点没那么实用。所以touchbar上面默认显示F1, F2, etc. Keys。\n截屏操作：算是个比较常用的快捷键吧，一个是截屏指定区域到剪贴板，一个是截屏指定区域保存到本地。\nFinder搜索：Finder中搜索文件也是常见操作？不会吧，已经有spotlight了，但是打开Finder应该是个常见操作，但是macOS没有提供这样的快捷键，可以通过这里的Show Finder search window来代替下，快捷键保持了与windows一致，Ctrl+F。\n那如果真的只想快速打开Finder新窗口呢？比如Option+E打开Finder窗口，定位到home目录？一样可以通过hammerspoon lua脚本搞定。\n再或者，通过Ctrl+Cmd+T打开一个新的终端，也可以通过hs lua脚本搞定。\n嗯，还有个不得不提的问题，那就是Command+H这个快捷键，macOS下默认是Hide Window，这个不行，我在IDE里面希望用这个快捷键来唤出API说明信息，你给我隐藏了不行。那怎么办，把这个Command+H快捷键重新映射，不让它执行系统默认的操作。一样的通过hs lua脚本来完成。\n当用户按下Command+H这个动作的时候，实际上应用程序看到的是Command+M，一般Command+M应用程序没这个快捷键的话，也就没有任何动作，就屏蔽掉了“Hide Window”这个动作，如果你真的想通过Command+H来唤出API说明的话，那么只要将这个动作绑定到Command+M上就可以了😃。\n此外，还有很多应用程序也需要定制快捷键，Chrome提供的默认快捷键真的是反人类，让我觉得要多长几只手才够用，4个按键分布在一只手的区域，怎么按过来，或者我的手指能多拐几个弯？哈哈，搞不了，必须改。\n但是普通应用程序快捷键，可能会有很多，怎么同步呢？几十个肯定是有的！对照着老的机器全部设置一遍也不是不行，问题是不想这么机械地搞一遍呢。macOS里面要一个菜单名一个菜单名这样的录入，才能再绑定快捷键。并不是说只是重新换个快捷键组合就完事，所以这还是体力活。\n这里先在老机器上，通过defaults find命令找到用户所有的快捷键设置，比如：\ndefaults find NSUserKeyEquivalents Found 1 keys in domain 'abnerworks.Typora': { NSUserKeyEquivalents = { Articles = \u0026quot;\\\\Uf706\u0026quot;; Code = \u0026quot;@k\u0026quot;; \u0026quot;Code Fences\u0026quot; = \u0026quot;@^k\u0026quot;; \u0026quot;File Tree\u0026quot; = \u0026quot;\\\\Uf704\u0026quot;; \u0026quot;Focus Mode\u0026quot; = \u0026quot;@$f\u0026quot;; \u0026quot;Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; Outline = \u0026quot;\\\\Uf705\u0026quot;; \u0026quot;Rename...\u0026quot; = \u0026quot;$\\\\Uf709\u0026quot;; Search = \u0026quot;@^f\u0026quot;; \u0026quot;Source Code Mode\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Toggle Sidebar\u0026quot; = \u0026quot;\\\\Uf707\u0026quot;; \u0026quot;Typewriter Mode\u0026quot; = \u0026quot;@$t\u0026quot;; }; } Found 1 keys in domain 'com.apple.Preview': { NSUserKeyEquivalents = { Bookmarks = \u0026quot;@3\u0026quot;; \u0026quot;Hide Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Hide Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Highlights and Notes\u0026quot; = \u0026quot;@2\u0026quot;; \u0026quot;Show Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Show Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Table of Contents\u0026quot; = \u0026quot;@1\u0026quot;; }; } Found 1 keys in domain 'com.google.Chrome': { NSUserKeyEquivalents = { \u0026quot;Always Show Bookmarks Bar\u0026quot; = \u0026quot;^$b\u0026quot;; \u0026quot;Close Window\u0026quot; = \u0026quot;@w\u0026quot;; \u0026quot;Developer Tools\u0026quot; = \u0026quot;\\\\Uf70f\u0026quot;; Downloads = \u0026quot;^j\u0026quot;; \u0026quot;Force Reload This Page\u0026quot; = \u0026quot;\\\\Uf708\u0026quot;; \u0026quot;New Incognito Window\u0026quot; = \u0026quot;^i\u0026quot;; \u0026quot;Open Location...\u0026quot; = \u0026quot;\\\\Uf709\u0026quot;; Redo = \u0026quot;@y\u0026quot;; \u0026quot;Reload This Page\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Reopen Closed Tab\u0026quot; = \u0026quot;^$t\u0026quot;; \u0026quot;Show Full History\u0026quot; = \u0026quot;^h\u0026quot;; }; } ...  把这个导出来，写一个bash脚本，用defaults write命令来更新系统中应用的默认设置：\n#!/bin/bash defaults write Apple Global Domain NSUserKeyEquivalents ' { \u0026quot;Enter Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; \u0026quot;Exit Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; Hyperlink = \u0026quot;@l\u0026quot;; Minimize = \u0026quot;~^\\\\U2193\u0026quot;; }' defaults write com.apple.Preview NSUserKeyEquivalents ' { Bookmarks = \u0026quot;@3\u0026quot;; \u0026quot;Hide Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Hide Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Highlights and Notes\u0026quot; = \u0026quot;@2\u0026quot;; \u0026quot;Show Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Show Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Table of Contents\u0026quot; = \u0026quot;@1\u0026quot;; }' defaults write com.google.Chrome NSUserKeyEquivalents ' { \u0026quot;Always Show Bookmarks Bar\u0026quot; = \u0026quot;^$b\u0026quot;; \u0026quot;Close Window\u0026quot; = \u0026quot;@w\u0026quot;; \u0026quot;Developer Tools\u0026quot; = \u0026quot;\\\\Uf70f\u0026quot;; Downloads = \u0026quot;^j\u0026quot;; \u0026quot;Force Reload This Page\u0026quot; = \u0026quot;\\\\Uf708\u0026quot;; \u0026quot;New Incognito Window\u0026quot; = \u0026quot;^i\u0026quot;; \u0026quot;Open Location...\u0026quot; = \u0026quot;\\\\Uf709\u0026quot;; Redo = \u0026quot;@y\u0026quot;; \u0026quot;Reload This Page\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Reopen Closed Tab\u0026quot; = \u0026quot;^$t\u0026quot;; \u0026quot;Show Full History\u0026quot; = \u0026quot;^h\u0026quot;; }' defaults write abnerworks.Typora NSUserKeyEquivalents ' { Articles = \u0026quot;\\\\Uf706\u0026quot;; Code = \u0026quot;@k\u0026quot;; \u0026quot;Code Fences\u0026quot; = \u0026quot;@^k\u0026quot;; \u0026quot;File Tree\u0026quot; = \u0026quot;\\\\Uf704\u0026quot;; \u0026quot;Focus Mode\u0026quot; = \u0026quot;@$f\u0026quot;; \u0026quot;Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; Outline = \u0026quot;\\\\Uf705\u0026quot;; \u0026quot;Rename...\u0026quot; = \u0026quot;$\\\\Uf709\u0026quot;; Search = \u0026quot;@^f\u0026quot;; \u0026quot;Source Code Mode\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Toggle Sidebar\u0026quot; = \u0026quot;\\\\Uf707\u0026quot;; \u0026quot;Typewriter Mode\u0026quot; = \u0026quot;@$t\u0026quot;; }' ... killall cfprefsd  在新机器上，把bash脚本执行下就可以了，so easy! 下次如果有需要拿来重跑下就可以，应用程序快捷键设置很快就能搞定。\n快捷键到这里就差不多了。\n6 效率工具\nHammerspoon\nHammerspoon，前面不止一次提到了，它的强大自不必多言，看文档https://www.hammerspoon.org/docs/index.html，支持的操作涉及到了系统的方方面面，只要会看着文档拼积木就可以。我用它来实现复杂的键映射处理、窗口管理、桌面管理等定制的操作。\n对普通用户没那么友好，但是一些难搞的问题，特别是个人的定制化，往往也要自己来搞了，用它撸几行代码就可以搞定。\nAlfred\nAlfred，是一个非常好的效率工具，可以说它和Spotlight有异曲同工之妙，我们前面先提了Spotlight的原因是，如果你认同Spotlight的价值，那么花时间去探索Alfred才有意义。\nAlfred在Spotlight功能的基础上，提供了额外的定制能力，它能干什么呢？\n定制Web Search\n这样你就可以通过关键字快速打开（浏览器收藏夹是个好东西，但绝不是最好的东西），然后输入的关键字会被当做搜索参数传入，例如让google帮你搜索，当然也可以当做浏览器收藏夹来用。\n定制Workflow\niOS上面的捷径，大家体验过没，大致上是一样的东西，macOS上本身是有Automation的，Alfred的好处就是提供了一个统一的管理、可视化配置、同步配置，而且还要比较好的用户生态，你可以搜索到他人贡献的workflow，也可以自己写。\n比如下面gist是一个支持gist搜索、创建的workflow，当你想使用以前积累的代码snippet，或者创建新的备用的时候，非常方便。\n再比如，这是一个强密码生成器，想靠人肉记住的密码都算不上什么强密码，安全的做法就是随机生成一个，连自己也不知道是什么，然后交给keychain来管理。\n时间久了，这里的设置就会比较多，如果涉及到多台设备的话，如何同步也需要考虑。这里不建议使用icloud此类进行存储，因为一旦出现多台设备Alfred版本不一致，有可能因为无法正常解析配置而重建配置，到时候如果icloud同步了多台设备上的数据，就玩完了（遇到过一次）。\n建议通过github等支持版本管理的第三方平台进行配置托管，我现在是通过github 仓库进行版本管理。\n7 浏览器\n浏览器你选哪款？iOS设备我选Safari，macOS我选Chrome，为啥，我当然想全部用Safari，移动端Safari体验比Chrome强太多，电脑上不行，没那么多extensions、apps来扩展浏览器功能，Chrome在桌面上很强大。\n我的常用扩展列表，屏蔽广告、代理、油猴扩展脚本、vim党专属vimium。之前有个同学问我你的百度页面怎么没广告啊，因为被Adblock屏蔽了啊。油猴上脚本多的了不得，下载视频啊等等等。\n我比较喜欢vimium，它让我可以用vim的操作方式来操作Chrome页面。比如：\nx: 关闭当前标签页\nyt: 创建新标签页\n/: 开始页面内搜索\nhjkl：页面内上下左右滚动\ngg：回到页面顶部\nf: 将页面中超链接全部高亮显示，并按字母编号，然后你可以通过编号触发链接，网页浏览的时候可以忘掉触摸板了\ni：直接进入搜索框，tab在多个文本框之间切换\n\u0026hellip;\n当然Chrome Web Store里面也有一些离线可以使用的Apps，想象一下ChromeBook能搞起来就知道Web Store里面应用有多丰富。\n当然你也可以自己写插件、应用，以开发者模式离线加载使用，也可以发布到Web Store。比如我自己写了个插件分屏阅读代码。\n上述一些配置优化方面的分享，对macOS的普通用户、高频用户、开发者等，应该都是通用的，这里分享一下，也欢迎大家分享自己的一些使用心得、技巧。\n关于开发相关的一些特定配置，后面有时间了整理后再分享。\n"}),a.add({id:379,href:"/blog/2020-02-23-go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-gotest%E5%AE%9E%E7%8E%B0/",title:"go源码剖析-gotest实现",description:"写了这么多年go，你了解go test是如何工作的吗？",content:"问题背景 # 在go1.13出来后不久，有不少同学遇到了go test报错的问题 “flag -test.timeout provided but not defined”。这个问题是如何引起的呢？\n 公司微服务代码，通常是借助代码生成工具统一生成的，包括针对接口的测试用例； 在生成单元测试文件时，如helloworld_test.go中，在该文件中定义了一些测试选项如-timeout、-service、-method、-target、-req、-rsp等； 上述定义的选项，在helloworld_test.go中的func init()中执行flag.Parse()操作完成选项解析。  这是被测试代码的一点背景信息，上述测试代码在go1.12中是没有问题的，但是当升级到go1.13后，就出现了上述“flag \u0026hellip; provided but not defined”的错误。\n实现细节 # go test实现细节，需要跟踪一下命令go test的执行过程，具体对应这个源文件：src/cmd/go/internal/test/test.go。\n假如现在，我们创建一个package名为xxxx的go文件，然后创建一个package名为xxxx_test的_test文件，如：\nfile: helloworld_test.go\npackage xxxx_test import \u0026quot;testing\u0026quot; import \u0026quot;xxxx\u0026quot; func TestHelloWorld(t *testing.T) { xxxx.Hello() } /* func init() { flag.Parse() } */ /* func TestMain(m *testing.M) { os.Exit(m.Run()) } */  file: helloworld.go\npackage xxxx func Hello() { }  这里的实例代码，做了适当的简化，方便大家查看。为了更好地跟踪go test过程，我们可以以调试模式运行go test，如GOTMPDIR=$(pwd)/xxx dlv exec $(which go) -- test -c：\n 首先指定了临时目录GOTMPDIR为当前目录下的xxx，在执行编译构建过程中的临时文件将生成到该目录下； dlv执行的时候，在--后面添加传递给被调试程序的命令行参数，如这里传递给go的参数是test -c；  此外，我们可以执行fswatch $(pwd)/xxx来跟踪文件系统的变化，从而帮助我们分析go test到底干了什么，这样比较直观，直接看源码，代码量有点多，容易抓不住头绪。\n接下来只需要执行next、next、next步进的形式执行go test的代码逻辑就可以了。过程中，我们看到fswatch输出了如下信息：\nzhangjie@knight test $ fswatch . /Users/zhangjie/test/test/xxx/go-build3964143485 /Users/zhangjie/test/test/xxx/go-build3964143485/b001 /Users/zhangjie/test/test/xxx/go-build3964143485/b001/_testmain.go  此时查看下_testmain.go的文件内容：\nfile: _testmain.go\n// Code generated by 'go test'. DO NOT EDIT. package main import ( \u0026quot;os\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;testing/internal/testdeps\u0026quot; _ \u0026quot;xxxx\u0026quot; _xtest \u0026quot;xxxx_test\u0026quot; ) var tests = []testing.InternalTest{ {\u0026quot;TestHelloWorld\u0026quot;, _xtest.TestHelloWorld}, } var benchmarks = []testing.InternalBenchmark{ } var examples = []testing.InternalExample{ } func init() { testdeps.ImportPath = \u0026quot;xxxx\u0026quot; } func main() { m := testing.MainStart(testdeps.TestDeps{}, tests, benchmarks, examples) os.Exit(m.Run()) }  上述文件中包含了一个main函数，是go test -c生成的测试程序的入口函数。\n  上述文件中，import了我们自己编写的两个package，如import _ \u0026quot;xxxx\u0026quot;，以及import _xtest \u0026quot;xxxx_test\u0026quot;，这两个package的代码就是我们上面给出的，一个Hello函数定义，一个对Hello函数的单元测试，没有什么复杂的。在helloworld_test.go中我们注释掉了两段代码，一个是func init()逻辑，一个是func TestMain()逻辑。我们稍后再说这个。\n  func init()中也没有什么需要关注的。\n  func main中，先执行了一个testing.MainStart(\u0026hellip;)初始化逻辑，这里面赶了什么呢？它执行了一个testing.Init()函数，来初始化go testing这个package中自定义的一些flags，如-test.timeout之类的。主意这些flags的注册逻辑是在所有package的func init()执行之后才发起的。\n  func main中，接着执行了一个os.Exit(m.Run())来执行测试，展开m.Run()能够看到根据-test.run选择性运行测试用例，或执行所有测试用例的逻辑。注意，当我们在测试文件中定义了TestMain方法之后，这里生成的代码就不是os.Exit(m.Run())了，而是_xtest.TestMain(m),这将允许先执行我们自己的测试代码设置逻辑。如在TestMain中执行一些准备测试数据、工作目录、注册命令选项 逻辑。\n  该问题产生原因 # 好，事情至此，我们先来解答本文开头遇到的问题？\n go1.13中对testing package的初始化逻辑做了一点调整，它将flags的初始化逻辑放在了main程序中，所有的其他package的func init()执行之后； go官方其实不建议在func init()中定义一些flags的，除非是main package。但是我们很多开发并不了解这个背景，经常在func init()中定义一些flags并Parse，甚至是在_test.go文件中; go1.13做了上述调整之后，在func init()中执行flag.Parse()时，如果go test传递了一些还没有来得及注册的选项，如-test.timeout是在func main()执行后注册，就会报错\u0026quot;flag -test.timeout provided but not defined\u0026quot;。  到这，我们解释了问题产生的原因了。\n如何规避该问题 # 现在，我们再来看下如何规避上述问题，有些情况下，确实有需要在_test.go中定义一些flags进行精细化控制的情况。\n我们了解到，如果我们自定义了TestMain函数，go test就会生成这样的代码:\nfile: _testmain.go\nfunc main() { m := testing.MainStart(testdeps.TestDeps(), tests, benchmarks, examples) _xtest.TestMain(m) }  在testing.MainStart中执行testing框架的选项注册逻辑，如-test.run、-test.timeout等等，我们可以在_xtest这个导入别名对应package中定义好flags，可以在package级别定义，也可以在func init()中定义，也可以在func TestMain()中定义，只要保证，执行flag.Parse()的时候是在TestMain或者更之后的单元测试函数中就可以。\n这个时候，所有的package的选项都正常注册了，包括testing package的，在TestMain中执行flag.Parse()就不会再出现“flag \u0026hellip; provided but not defined\u0026quot;的奇葩情况。\n区分testing flags以及自定义flags # 另外，关于自定义flag与testing package定义的重名的问题，其实go test是有考虑到的，用参数\u0026ndash;args分开就可以了，前面的是给testing解析的，后面是给自定义的解析的，testing自己的flag名带“test.”前缀，其实是可以省略掉的。\n再看go test代码生成 # 下面是问题的回归，及定位过程中的源码分析！\n_testmain.go的生成，是通过go模板来生成的，模板路径详见：src/cmd/go/internal/load/test.go，搜索变量’testmainTmpl’：\n// Code generated by 'go test'. DO NOT EDIT. package main import ( \u0026quot;os\u0026quot; {{if .TestMain}} \u0026quot;reflect\u0026quot; {{end}} \u0026quot;testing\u0026quot; \u0026quot;testing/internal/testdeps\u0026quot; {{if .ImportTest}} {{if .NeedTest}}_test{{else}}_{{end}} {{.Package.ImportPath | printf \u0026quot;%q\u0026quot;}} {{end}} {{if .ImportXtest}} {{if .NeedXtest}}_xtest{{else}}_{{end}} {{.Package.ImportPath | printf \u0026quot;%s_test\u0026quot; | printf \u0026quot;%q\u0026quot;}} {{end}} ... ) var tests = []testing.InternalTest{ {{range .Tests}} {\u0026quot;{{.Name}}\u0026quot;, {{.Package}}.{{.Name}}}, {{end}} } var benchmarks = []testing.InternalBenchmark{ {{range .Benchmarks}} {\u0026quot;{{.Name}}\u0026quot;, {{.Package}}.{{.Name}}}, {{end}} } var examples = []testing.InternalExample{ {{range .Examples}} {\u0026quot;{{.Name}}\u0026quot;, {{.Package}}.{{.Name}}, {{.Output | printf \u0026quot;%q\u0026quot;}}, {{.Unordered}}}, {{end}} } func init() { testdeps.ImportPath = {{.ImportPath | printf \u0026quot;%q\u0026quot;}} } ... func main() { ... m := testing.MainStart(testdeps.TestDeps{}, tests, benchmarks, examples) {{with .TestMain}} {{.Package}}.{{.Name}}(m) os.Exit(int(reflect.ValueOf(m).Elem().FieldByName(\u0026quot;exitCode\u0026quot;).Int())) {{else}} os.Exit(m.Run()) {{end}} }  结合前面给出的测试用例helloworld.go、helloworld_test.go，以及go test生成的_testmain.go，只要对go模板稍有认识，就很容易建立起模板和代码生成的联系，是很容易理解的。\n总结 # go1.13 testing package初始化flags顺序发生改变，引起了一些go test时\u0026quot;flag \u0026hellip; provided but not defined\u0026quot;的错误，暴露了我们一些开发者对go test不熟悉、对go flags官方推荐用法不熟悉。本文解释了go test的大致处理逻辑、问题产生原因以及规避该问题的建议。\n"}),a.add({id:380,href:"/tags/framework/",title:"framework",description:"",content:""}),a.add({id:381,href:"/tags/goneat/",title:"goneat",description:"",content:""}),a.add({id:382,href:"/blog/2020-02-04-goneat-rpc%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%E8%AF%A6%E8%A7%A3/",title:"GoNeat RPC框架设计详解",description:"GoNeat框架是一款在腾讯期间开发的RPC框架，支撑了团队几千个微服务，后续PCG建设tRPC框架后，GoNeat框架也最终走向了停止后续开发的命运。虽然未来难免被遗忘，但是它过去也曾经”繁荣“过，几十人的活跃开发组织，几百个的issue沟通讨论、几千的commit、很多次技术分享，沉淀下来的东西也可以对新同学成长起到些指引帮助作用，对后续框架设计开发者也具有一定的参考价值，希望本文能对框架设计实现感兴趣的同学有帮助。",content:" img { width: 680px; padding-bottom: 1rem; }  GoNeat框架一直持续演进中，抽时间整理了下框架从服务启动到结束退出这一连串流程中涉及到的设计、实现细节，希望能对想了解GoNeat框架设计、实现感兴趣的同学有帮助。 本文初衷是为了介绍GoNeat框架的设计，本人觉得按照一个服务的生命周期进行介绍，读者会比较容易接受、介绍起来也没那么枯燥，缺点是一个模块的多个实现细节可能会在不同的地方提及，读者可能需要一定的前后联想。内容比较多，也可以直接跳过部分内容阅读感兴趣的章节。 由于语言功底不是特别好，在用词、句式、断句、篇章组织上难免存在不尽如人意的地方，请多多包涵。\nGoNeat RPC框架设计详解 # GoNeat，追求“小而美”的设计，是基于golang开发的面向后台开发的微服务框架，旨在提升后台开发效率，让大家摆脱各种琐碎的细节，转而更加专注于服务质量本身。Simple \u0026amp; Powerful，是我们始终追求的设计理念。\n本文从整体上介绍GoNeat的设计，GoNeat包括哪些核心部件，它们又是是如何协作的，服务运行期间涉及到哪些处理流程，等等。如果读者想更深入地了解，可以在本文基础上再阅读相关源码，或与我们开发者交流。\nGoNeat 整体架构 # 下图展示了GoNeat的整体架构设计，包括其核心组成部分，以及不同组成部分之间的交互： GoNeat包括如下核心组成部分：\n Server，代表一个服务实例，一个Server可以插入多个ServerModule； ServerModule，代表一个服务模块，实现包括StreamServer、PacketServer、HttpServer、HippoServer； NHandler，即Codec Handler，代表一个协议Handler，实现包括nrpc、ilive、sso、http等协议Handler；  不同port上可以分别提供不同协议的服务，如8000端口提供tcp/udp的nrpc服务，而8080提供http服务； 不同port上到达的请求，经协议Handler解析出请求，并根据请求中的命令字，找到注册的CmdHandler；   Server将请求以函数参数的形式递交给注册的CmdHandler处理，处理完毕返回结果给调用方；  介绍完框架的核心组件之后，下面结合一个服务示例，介绍下服务启动、请求处理、服务退出的详细流程及设计细节。\nGoNeat 服务示例 # 我们仍然使用“test_nrpc.proto”作为示例服务pb（您可以在 go-neat/demo/quickstart 中找到该示例）：\nfile: test_nrpc.proto\nsyntax = \u0026quot;proto2\u0026quot;; package test_nrpc; // BuyApple message BuyAppleReq { optional uint32 num = 1; }; message BuyAppleRsp { optional uint32 errcode = 1; optional string errmsg = 2; }; // SellApple message SellAppleReq { optional uint32 num = 1; }; message SellAppleRsp { optional uint32 errcode = 1; optional string errmsg = 2; }; // service test_nrpc service test_nrpc { rpc BuyApple(BuyAppleReq) returns(BuyAppleRsp); // CMD_BuyApple rpc SellApple(SellAppleReq) returns(SellAppleRsp); // CMD_SellApple }  使用goneat命令行工具来创建一个新的go-neat服务：\ngoneat create -protocol=nrpc -protofile=test_nrpc.proto -httpon  与“Program Your Next Server in GoNeat”章节不同的是，这里额外加了一个参数“-httpon”，目的是介绍支持多协议的相关处理。运行上述命令后，应生成如下目录结构的服务模板。\ntest_nrpc ├── Makefile ├── README.md ├── client │ └── test_nrpc_client.go ├── conf │ ├── log.ini │ ├── monitor.ini │ ├── service.ini │ └── trace.ini ├── deploy.ini ├── log └── src ├── exec │ ├── exec_test_nrpc.go │ ├── exec_test_nrpc_impl.go │ └── exec_test_nrpc_init.go └── test_nrpc.go 5 directories, 12 files  GoNeat 内部设计 # 一直没想清楚，该以什么样的方式来描述GoNeat的内部设计，想了两种叙述方式：\n  按照核心组件单独拎出来挨个介绍下？\n这种方式比较容易介绍，但是读者不容易理解这玩意在哪些场景下用、怎么用。因为核心组件可能功能比较多，大而全地介绍反而有点虚，一次性介绍完不光读者头大，介绍的人也头大。\n  按照执行流程中涉及到的组件逐个介绍？\n这种方式比较容易让读者明白什么场景下用到了什么组件，对组件的介绍也可以适可而止，但是同一个组件可能在多个不同的流程中被提到，需要读者适当地对思路进行下梳理。不过GoNeat框架内组件实现一般都比较简单。\n  综合考虑以后，决定用第二种方式进行叙述，既方便读者理解，介绍过程本身也不至于过于枯燥。\nGoNeat框架是按照如下方式进行组织的，相关子工程托管在git.code.oa.com/groups/go-neat：\n core，是核心框架逻辑，负责框架整体流程处理，即某些通用能力的抽象，如监控、分布式跟踪、日志能力； tencent，提供了公司常用中间件，如ckv、hippo、monitor、tnm、dc、habo、l5、cmlb等等； common，提供了框架中一些常用的工具类实现，如共享内存操作等等； tool，提供了GoNeat开发所需要的一些外围工具，如代码生成工具、monitor监控打点工具等；  为大家方便使用第三方组件，也创建了components方便大家在goneat服务开发中使用：\n components，提供了第三方的一些支持，如etcd、zookeeper等等；  此外，为了方便大家理解GoNeat框架的设计，以及快速上手开发，也提供了wiki和demo：\n wiki，也就是您正在看的这份文档，所有的文档都在这里维护，如果对文档有疑问或建议，也可在此提issue； demo，提供了一些示例代码，助力大家快速上手goneat开发；   为方便大家在公司内网体验GoNeat，减少解决外部依赖所需要的时间（如访问github可能要申请外网访问权限等），我们也维护了go-neat/deps来维护框架的依赖（库+版本），install.sh搭建的时候会自动拉取这里的依赖。\n我们建议您使用go module对依赖进行管理，goneat相关依赖已经补充在go.mod，请知悉。\n GoNeat - 初始化 # 初始化：配置说明 # GoNeat框架读取的配置文件，主要包括：\n test_nrpc/conf/service.ini，包含服务的核心配置； test_nrpc/conf/monitor.ini，包含服务不同接口的耗时分布的monitorid； test_nrpc/conf/log.ini，包含日志文件滚动方式、日志级别的相关定义； test_nrpc/conf/trace.ini，包含分布式跟踪相关backend的定义；  如果您已经对GoNeat配置项很熟悉，可以选择跳过该小节，当然我们还是建议通读一下以尽可能全面地了解不同的配置项，当后续您有需求要对框架做出约束或者改变的时候，有助于判断现有框架能力能否满足您的需要。\n下面对各个日志文件中的配置项进行介绍：\n  test_nrpc/conf/service.ini，包括框架核心配置项，以及habo、业务协议、rpc相关配置项：\n[service] 框架核心配置项：\n  日志相关：日志级别，保留日志文件数量，单日志文件的大小；\n  性能相关：允许的最大入tcp连接数，允许的最大并发请求数，\n  内存调优：workerpool允许创建最大协程数，udp收包buffer大小；\n  服务质量：服务接口的超时时间，处理请求时进行全局超时控制；\n  服务名称：分布式跟踪时用于追踪span节点；\n[service] name = test_nrpc #服务名称 log.level = 1 #框架日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR log.size = 64MB #日志文件大小,默认64MB,可以指定单位B/KB/MB/GB log.num = 10 #日志文件数量,默认10个 limit.reqs = 100000 #服务允许最大qps limit.conns = 100000 #允许最大入连接数 workerpool.size = 20000 #worker数量 udp.buffer.size = 4096 #udp接收缓冲大小(B),默认1KB,请注意收发包尺寸 BuyApple.cmd.timeout = 5000 #服务接口BuyApple超时时间(ms) SellApple.cmd.timeout = 5000 #服务接口SellApple超时时间(ms)    [habo] 哈勃监控配置项：\n  是否启用哈勃监控；\n  申请的dcid，dc上报数据同步到habo；\n  dc上报测试环境，还是线上环境；\n[habo] enabled = true #是否开启模调上报 caller = content_strike_svr #主调服务名称 dcid = dc04125 #罗盘id env = 0 #0:现网(入库tdw), 1:测试(不入库tdw)    [nrpc-service] 协议handler配置项：\n  nrpc协议handler监听的tcp端口；\n  nrpc协议handler监听的udp端口；\n[nrpc-service] tcp.port = 8000 #tcp监听端口 udp.port = 8000 #udp监听端口    [http-service] 协议http配置项：\n  http协议监听的端口；\n  http请求URL前缀；\n[http-service] http.port = 8080 #监听http端口 http.prefix = /cgi-bin/web #httpUrl前缀    [rpc-test_nrpc] rpc配置项：\n  rpc调用地址，支持ip://ip:port、l5://mid:cid、cmlb://appid（“服务发现”正在开发验证中）\n  传输模式，支持UDP、UDP全双工、TCP短连接、TCP长连接、TCP全双工，TCP/UDP SendOnly\n  rpc超时时间，包括默认的timeout以及细化到各个接口的超时时间；\n  rpc监控monitorid，包括总请求、成功、失败、耗时分布monitor id；\n[rpc-test_nrpc] addr = ip://127.0.0.1:8000 #rpc调用地址 proto = 3 #网络传输模式, #1:UDP, #2:TCP_SHORT, #3:TCP_KEEPALIVE, #4:TCP_FULL_DUPLEX, #5:UDP_FULL_DUPLEX, #6:UDP_WITHOUT_RECV timeout = 1000 #rpc全局默认timeout BuyApple.timeout = 1000 #rpc-BuyApple超时时间(ms) SellApple.timeout = 1000 #rpc-SellApple超时时间(ms) monitor.BuyApple.timecost10 = 10001 #耗时\u0026lt;10ms monitor.BuyApple.timecost20 = 10002	#耗时\u0026lt;20ms monitor.BuyApple.timecost50 = 10003	#耗时\u0026lt;50ms ... monitor.BuyApple.timecost2000 = 10005	#耗时\u0026lt;2000ms monitor.BuyApple.timecostover2000 = 10006	#耗时\u0026gt;=2000ms ...      test_nrpc/conf/monitor.ini，用于监控服务接口本身的总请求量、处理成功、处理失败量，以及处理耗时分布情况：\n[test_nrpc] 服务接口本身监控打点monitor id：\n[test_nrpc] //服务接口-BuyApple monitor.BuyApple.timecost10=0 #接口BuyApple延时10ms monitor.BuyApple.timecost20=0 #接口BuyApple延时20ms monitor.BuyApple.timecost50=0 #接口BuyApple延时50ms ... monitor.BuyApple.timecost3000=0 #接口BuyApple延时3000ms monitor.BuyApple.timecostover3000=0 #接口BuyApple延时\u0026gt;3000ms //	服务接口-SellApple monitor.SellApple.timecost10=0 #接口SellApple延时10ms monitor.SellApple.timecost20=0 #接口SellApple延时20ms monitor.SellApple.timecost50=0 #接口SellApple延时50ms ... monitor.SellApple.timecost3000=0 #接口SellApple延时3000ms monitor.SellApple.timecostover3000=0 #接口SellApple延时\u0026gt;3000ms    test_nrpc/conf/log.ini，代替service.ini中logging相关配置，用来支持工厂模式获取logger：\n这里默认配置了三个logger：\n 框架处理日志log，go_neat_frame.log，最多保留5个日志文件，单文件上限100MB，写满则滚动； 框架请求流水log，go_neat_access.log，最多保留5个日志文件，单文件无上限，按天滚动； 默认log，default.log，最多保留5个日志文件，单文件上限100MB，写满则滚动；  #框架内部日志 [log-go_neat_frame] level = 1 #日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR logwrite = rolling logFileAndLine = 1 rolling.filename = go_neat_frame.log rolling.type = size rolling.filesize = 100m rolling.lognum = 5 #框架流水日志 [log-go_neat_access] level = 1 #日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR) logwrite = rolling logFileAndLine = 0 rolling.filename = go_neat_access.log rolling.type = daily rolling.lognum = 5 #服务默认日志 [log-default] level = 1 #日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR) logwrite = rolling logFileAndLine = 0 rolling.filename = default.log rolling.type = size rolling.filesize = 100m rolling.lognum = 5    test_nrpc/conf/trace.ini，用于分布式跟踪相关的配置：\nGoNeat框架通过opentracing api支持分布式跟踪，支持三种backend实现，zipkin、jaeger、天机阁：\n  [zipkin] 配置\n[zipkin] enabled = true #是否启用zipkin trace service.name = test_nrpc #当前服务名称(span endpoint) service.addr = *:8000 #当前服务地址(span endpoint) collector.addr = http://9.24.146.130:8080/api/v1/spans #zipkin collector接口地址 traceId128bits = true #是否启用128bits traceId    [jaeger] 配置\n[jaeger] enabled = false #是否启用jaeger trace(暂未验证兼容性) service.name = test_nrpc #当前服务名称(span endpoint) service.addr = *:8000 #当前服务地址(span endpoint) collector.addr = http://9.24.146.130:8080/api/v1/spans #jaeger collector接口地址 traceId128bits = true #是否启用128bits traceId    [天机阁] 配置\n[tianjige] enabled = false #是否启用天机阁 trace service.name = test_nrpc #当前服务名称(span endpoint) service.addr = *:8000 #当前服务地址(span endpoint) collector.addr = 10.101.192.79:9092 #天机阁 collector接口地址 traceId128bits = true #是否启用128bits traceId appid = ${your_applied_appid} #天机阁申请的appid      初始化：配置加载 # 在介绍了GoNeat依赖的配置文件及各个配置项之后，继续介绍下GoNeat的配置解析、加载过程。\nGoNeat支持两种格式的配置文件:\n 一种是“ini格式”的配置文件， 一种是“json格式”的配置文件。  配置加载，发生在Server实例化过程中，default_nserver.NewNServer()，此时会加载service.ini、monitor.ini、log.ini，并根据配置信息完成Server实例化。 初始化：logging # Server实例化过程中，会创建三个logger对象：\n go_neat_frame，框架处理逻辑日志，对应log.ini中的[go_neat_frame]； go_neat_access，框架请求流水日志，对应log.ini中的[go_neat_access]； default，框架默认日志，对应log.ini中的[default]；  每个logger对象的创建都是按照如下流程去执行的，nlog.GetLogger(logger)，会首先检查loggerCache中key=$logger的logger对象是否已经存在，如果存在则直接返回，反之，加载log.ini中的配置[$logger]，检查logwrite配置项，logwrite指定了日志输出的目的地，如：\n console，输出到控制台； simple，普通日志文件，不支持滚动； rolling，支持滚动的日志文件，包括按照日期滚动、文件大小滚动；  logwrite允许逗号分隔多个输出，如logwrite = console, rolling，那么此时logger.Info(…)输出的信息将同时输出到控制台和滚动日志文件，详细可参考nlog.MultiWriterLogWriter实现。\n nlog.MultiWriterLogWriter可以进一步重构，如支持将日志信息上报到elasticsearch、天机阁等其他远程日志系统，现在的实现稍作修改就可以支持第三方日志组件实现，elasticsearch、天机阁等远程日志组件只要实现nlog.NLog接口并完成该实现的注册即可。  初始化：tracing # 分布式调用链对GoNeat框架来说是可插拔的，回想一下trace.ini，我们支持三种调用链backend实现，包括zipkin、jaeger以及公司内部的天机阁，如果希望在服务中使用tracing：\n 使用zipkin，那么在程序中import _ “git.code.oa.com/go-neat/core/depmod/trace/zipkin即可； 使用jaeger，那么在程序中import _ “git.code.oa.com/go-neat/core/depmod/trace/jaeger即可； 使用天机阁，那么在程序中import _ “git.code.oa.com/go-neat/core/depmod/trace/tianjige即可；  当然除了import对应的调用链实现，也要对配置文件做调整：\n 使用zipkin，trace.ini里面设置zipkin.enabled = true； 使用jaeger，trace.ini里面设置jaeger.enabled = true; 使用天机阁，trace.ini里面设置tianjige.enabled = true;   如果后续想要扩展tracing backend，只需要提供对应的tracer初始化方法就可以了，类似于zipkin、jaeger、天机阁初始化方式。如果要在项目中使用该tracing实现，通过import对应实现+配置文件激活就可以。import对应的tracing backend初始化，并添加对应的初始化配置，that’s it!\n 初始化：协议handler # 不同的业务协议，其字段定义、编解码方式可能不同，协议handler就是对业务协议的编解码进行处理。目前，GoNeat框架支持公司内大多数业务协议，如nrpc、sso、simplesso、ilive、qconn、taf等等。\n协议处理方面的亮点？ # GoNeat框架支持在单个进程中同时支持多种业务协议，如：\n 在port 8000提供nrpc服务； 在port 8001提供ilive协议； 在port 8080提供http服务；  同一份业务处理代码，可以通过不同的业务协议对外提供服务，在涉及到多端、多业务方交互的时候会很方便。\n服务中如何支持nrpc协议？ # 以提供nrpc服务为例，只需要做3件事情，包括：\n 配置文件service.ini中增加[nrpc-service]配置项，指明业务协议nrpc绑定的端口，如tcp.port = 8000； 代码中引入对应协议handler，如import _ \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nprc_svr/default_nrpc_handler\u0026quot;； 代码注册nrpc命令字及处理方法，如default_nserver.AddExec(“BuyApple”, BuyApple)；  如果要在此基础上继续支持http服务呢，一样的三件事，包括：\n  配置文件service.ini中增加[http-service]配置项，指明要绑定的端口及url前缀，如：\n[http-service] http.port = 8080 http.prefix = /cgi-bin/web    代码引入协议handler，如import _ “git.code.oa.com/go-neat/core/proto/http/dft_httpsvr”；\n  代码注册http uri，如default_nserver.AddExec(“/BuyApple”, BuyApple)；\n  That’s all！GoNeat要支持常用的业务协议，只需要做上述修改即可，是不是看上去还挺简单方便！\n 还记得写一个spp服务同时支持多种协议，需要在spp_handle_input里面区分端口来源，然后再调用对应的解包函数，判断请求命令字，转给对应的函数处理，每次有这种需要都需要写一堆这样的代码，好啰嗦！\n 框架做了什么？ # 读者是否注意到前文中AddExec(cmd,BuyApple)，nrpc命令字BuyApple，http请求$host:8080/cgi-bin/web/BuyApple，这两种不同的请求最终是被路由到了相同的方法BuyApple进行处理，意味着开发人员无需针对不同的协议做任何其他处理，GoNeat框架帮你搞定这一切，业务代码零侵入。\n真的业务代码零侵入吗？http请求参数Get、POST方式呢？nrpc协议是protbuf格式呢？同一份业务代码如何兼容？\nGoNeat对不同的业务协议抽象为如下几层：\n 协议定义，如nrpc、ilive、simplesso、http包格式； 协议handler，完成协议的编码、解码操作（接口由NHandler定义）； 会话session，维持客户端请求、会话信息（接口由NSession定义）；  当希望扩展GoNeat的协议时，需要提供协议的包结构定义、协议的编解码实现、协议会话实现，nrpc协议对应的会话实现为NRPCSession、http协议对应的会话实现时HttpSession。\n好，现在介绍下GoNeat中同一份代码func BuyApple(ctx context.Context, session nsession.NSession) (interface{}, error)如何支持多种业务协议。\nfile: test_nrpc/src/exec/test_nrpc.go：\nfunc BuyApple(ctx context.Context, session nsession.NSession) (interface{}, error) { req := \u0026amp;test_nrpc.BuyAppleReq{} err := session.ParseRequestBody(req) ... rsp := \u0026amp;test_nrpc.BuyAppleRsp{} err = BuyAppleImpl(ctx, session, req, rsp) ... return rsp, nil }  file: test_nrpc/src/exec/test_nrpc_impl.go：\nfunc BuyAppleImpl(ctx context.Context, session nsession.NSession, req *test_nrpc.BuyAppleReq, rsp *test_nrpc.BuyAppleRsp) error { // business logic return nil }  从上面的代码中 test_nrpc.go 不难看出，秘密在于不同协议会话对NSession.ParseRequestBody(…)的实现：\n 如果是pb协议，session里面会直接通过proto.Unmarshal(data []byte, v interface{})来实现请求解析； 如果是http协议，session里面会多做些工作：  如果是POST方法，且Content-Type=“application/json”，则读取请求体然后json.Unmarshal(...)接口；   其他情况下，读取GET/POST请求参数转成map[param]=value，编码为json再反序列化为目标结构体；  Google Protocol Buffer是一种具有自描述性的消息格式，凭借良好的编码、解码速度以及数据压缩效果，越来越多的开发团队选择使用pb来作为服务间通信的消息格式，GoNeat框架也推荐使用pb作为首选的消息格式。\n由于其自描述性，pb文件被用来描述一个后台服务是再合适不过了，基于此也衍生出一些周边工具，如自动化代码生成工具goneat（由gogen重命名而来）用来快速生成服务模板、client测试程序等等。\nGoNeat - 服务启动 # 前面零零散散地介绍了不少东西，配置文件、配置加载、logging初始化、tracing集成、协议handler注册，了解了这些之后，现在我们从整体上来认识下GoNeat服务的启动过程。\n说是从整体上来认识启动流程，并不意味着这里没有新的细节要引入。中间还是会涉及到一些比较细节的问题，如tcp、udp监听如何处理的，为什么要支持端口重用，为支持平滑退出需要做哪些准备等等。这里章节划分的可能不太科学，希望按照一个GoNeat服务的生命周期来叙述，能尽可能多地覆盖到那些必要的设计和细节。\n启动：实例化Server # 一个GoNeat服务对应着一个Server实例，为了方便快速裸写一个GoNeat服务，go-neat/core内部提供了一个package default_nserver，代码中只需要添加如下两行代码就可以快速启动一个GoNeat服务：\npackage main import ( “git.code.oa.com/go-neat/core/nserver/default_nserver” ) func main() { default_nserver.Serve() }  当然，该Server实例会直接退出，因为该实例没有注册要处理的业务协议，需要注册协议handler服务才能工作。当我们创建一个pb文件，并通过命令goneat -protofile=*.proto -protocol=nrpc创建工程时，goneat自动在生成代码中包含了nrpc协议对应的协议handler，这里的协议handler做了什么呢？或者说import这个协议handler时，发生了什么呢？\nimport ( _ \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nrpc_svr/default_nrpc_handler\u0026quot; )   Server实例化过程中，会涉及到配置加载、logger实例化相关的操作，这里在GoNeat - 初始化一节中已有提及，这里相关内容不再赘述。\n 启动：加入协议handler # 以nrpc协议handler为例：\nfile: go-neat/core/proto/nrpc/nrpc_svr/default_nrpc_handler/nrpc_svr_init.go\npackage default_nrpc_handler import ( \u0026quot;git.code.oa.com/go-neat/core/nserver/default_nserver\u0026quot; \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nrpc_svr\u0026quot; ) func init() { default_nserver.RegisterHandler(nrpc_svr.NewNRPCHandler()) }  当import default_nrpc_handler时，func init()会自动执行，它会向上述Server实例中注册协议handler，注册过程中发生了什么呢？可参考如下简化版的代码，它主要做这些事情：\n 读取service.ini中的配置[nrpc-service]section下的tcp.port，如果大于0创建一个StreamServer； 读取service.ini中的配置[nrpc-service]section下的udp.port，如果大于0创建一个PacketServer； 将上述新创建的StreamServer和PacketServer添加到Server实例的ServerModule集合中；  file: go-neat/core/nserver/neat_svr.go\nfunc (svr *NServer) RegisterHandler(handler NHandler) { ... moduleNode := handler.GetProto() + \u0026quot;-service\u0026quot; if svr.config.ReadInt32(moduleNode, \u0026quot;tcp.port\u0026quot;, 0) \u0026gt; 0 { nserverModule := \u0026amp;StreamServer{protoHandler: handler} svr.serverModule = append(svr.serverModule, nserverModule) } if svr.config.ReadInt32(moduleNode, \u0026quot;udp.port\u0026quot;, 0) \u0026gt; 0 { nserverModule := \u0026amp;PacketServer{protoHandler: handler} svr.serverModule = append(svr.serverModule, nserverModule) } ... }  file: test_nrpc/conf/service.ini\n[nrpc-service] tcp.port = 8000 #tcp监听端口 udp.port = 8000 #udp监听端口  启动：Server启动 # default_nserver.Serve()发起了Server实例的启动，Server实例会遍历其上注册的所有ServerModule，然后逐一启动各个ServerModule，如tcp服务模块StreamServer、udp服务模块PacketServer。\nfile: test_nrpc/src/test_nrpc.go\npackage main import ( \u0026quot;git.code.oa.com/go-neat/core/nserver/default_nserver\u0026quot; _ \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nrpc_svr/default_nrpc_handler\u0026quot; _ \u0026quot;git.code.oa.com/go-neat/core/proto/http/dft_httpsvr\u0026quot; _ \u0026quot;exec\u0026quot; ) func main() { default_nserver.Serve() }  file: go-neat/core/nserver/neat_svr.go\nfunc (svr *NServer) Serve() { ... for _, serverModule := range svr.serverModule { if e := serverModule.Serve(); e != nil { ... } } ... }  以下是Server实例启动过程图解：\n package default_nserver实例化了一个Server实例，package main只需要import这个包即可完成实例化； package main中import对应的协议handler，协议handler将向默认Server实例注册handler； 每个协议handler又有协议之分，如支持tcp、udp、http，要为不同的协议创建ServerModule并注册到Server； Server实例调用Serve()开始启动，该方法逐一启动已注册的所有ServerModule；   下面介绍下框架中实现的几个ServerModule，了解下它们的设计细节。\n启动：ServerModule # Server允许插入多个ServerModule实现，来扩展Server的能力，如支持不同协议的ServerModule实现：tcp（StreamServer）、udp（PacketServer）、http（HttpServer）。\nfile: go-neat/core/nserver/neat_svr.go\ntype NServer struct { serverName string serverModule []NServerModule ... }  file: go-neat/core/nserver/neat_comm.go\ntype NServerModule interface { Init(nserver *NServer, module string, cfg *config.Ini, log *nlog.NLog) error SetHandler(requestHandler RequestHandler) GetProto() string Serve() error Close() }  Module：StreamServer # StreamServer是GoNeat封装的面向字节流（SOCK_STREAM）的服务模块，支持tcp和unix服务。\nStreamServer的创建时刻，我们在前面描述“服务启动”的部分已有提及，这里描述其启动的过程。\n启动监听，处理入连接请求 # func (svr *StreamServer) Serve() error { tcpListener, err := net.Listen(svr.Network, svr.Addr) if nil != err { panic(fmt.Errorf(\u0026quot;listen tcp error %s\u0026quot;, err.Error())) } svr.ctx, svr.cancel = context.WithCancel(context.Background()) if nil != tcpListener { go svr.tcpAccept(svr.protoHandler, tcpListener) } return nil }  StreamServer启动的逻辑简单明了，它监听svr.Addr（传输层协议svr.Network）创建一个监听套接字，然后为该svr.ctx创建一个CancelContext，然后启动一个协程负责执行svr.tcpAccept(…)，处理tcp入连接请求。\n广播事件，支持平滑退出 # 这里提一下svr.ctx, svr.cancel，服务有自己的生命周期，有启动也有停止，服务停止的时候，存在某些未完结的任务需要清理，如HippoServer中可能拉取了一批消息但是还未处理完成，服务重启会造成消息丢失。类似这样的场景的存在，要求框架必须有能力对服务停止事件进行广播，广播给服务内的所有组件，各个组件根据需要自行执行清理动作，如HippoServer可能会选择停止继续收消息、处理完收取消息后退出。\n这里的svr.ctx, svr.cancel就是负责对服务停止事件进行广播的，当Server实例停止时，会遍历其上注册的所有ServerModule并调用其Close()方法，以StreamServer为例：\n// Close shutdown StreamServer func (svr *StreamServer) Close() { if svr.cancel != nil { svr.cancel() } }  StreamServer.Close()调用了svr.cancel()来取消svr.ctx的所有child context，因为svr.ctx是整个tcp服务处理的root context，所有后续的请求处理的context都是派生自svr.ctx，当执行svr.cancel()的时候，所有派生出来的请求处理，都可以通过各个child context的Done()方法来检测StreamServer是否已经准备停止，从而采取必要的清理动作。\n这里的设计，也为GoNeat服务能够优雅地“实现平滑退出”打下了基石。\n建立连接，全双工处理 # func (svr *StreamServer) tcpAccept(handler NHandler, listener net.Listener) { defer listener.Close() ctx := svr.ctx for { select { case \u0026lt;-ctx.Done():	//服务停止，不再接受入连接请求 return default:	//建立新连接，并处理 conn, ex := listener.Accept() if ex != nil { log.Error(\u0026quot;accept error:%s\u0026quot;, ex) } else { if svr.connLimiter.TakeTicket() { //自我防护，对入连接数量进行限制 if tcpConn, ok := conn.(*net.TCPConn); ok { tcpConn.SetKeepAlive(true) tcpConn.SetKeepAlivePeriod(10 * time.Second) } endpoint := newEndPoint(svr, conn) go endpoint.tcpReader()	//全双工模式处理，收包、处理、回包以并发的方式进行 go endpoint.tcpWriter()	//充分发挥tcp全双工的特点和优势 } else { conn.Close()	//入连接数量超过上限，关闭连接 } } } } }  对于创建好的tcp连接，StreamServer充分发挥了tcp全双工的特点和优势：\n 启动一个goroutine专门负责收包 启动一个goroutine专门负责回包 针对连接上到达的请求包，则通过协程池进行处理 同一个连接上的收包、处理、回包是并发的  回想下我们写C++服务端的经历，通过epoll监听每个连接套接字上的读写就绪事件，read-ready的时候要及时从连接中取出数据放到请求队列中，write-ready的时候如果请求处理完就回包。单进程多线程模型，往往有专门的io线程来进行数据包的收发，逻辑处理线程从请求队列中取走请求赶紧处理并准备好回包数据，io线程取走回包执行响应动作；如果是单进程单线程模型，io事件未就绪的情况下就要赶紧执行逻辑处理；多进程模型，则可能会采用类似spp的架构，proxy负责io，请求放入共享内存，worker进程从共享内存获取请求并写入响应，proxy再负责回包。\n使用go进行开发呢？go对阻塞型系统调用进行了完整的解剖，所有的网络io、请求处理，都显得那么简单、自然，以至于都已经淡忘了C++服务端开发中存在的不同网络模型。当然，网络模型的思想在，但已经无需关注多进程单进程、多线程单线程了，只需要铭记 “tcp是全双工模式”，借助golang这一强大的基础设施来最优化tcp服务性能即可。\n关于 go endpoint.tcpReader() 和 go endpoint.tcpWriter() 的细节，我们在后面服务怠速、请求处理中介绍。\n过载保护，限制入连接数 # StreamServer循环执行Accept()方法来建立连接，当然由于计算资源有限，服务能处理的连接数、请求数是有限的，服务需要进行一定的防护避免过载、雪崩。当svr.connLimiter.TakeTicket()成功时表示连接数未超限，可以继续处理，反之表示超出入连接数上限，关闭连接。\n循环Accept()过程中，如果检测到StreamServer停止ctx.Done()，关闭监听套接字不再接受入连接请求。\n过载保护，限制入请求数 # 除了对入tcp连接数进行限制，StreamServer也对入请求数进行限制，这部分在后续“请求处理”中介绍。\nModule：PacketServer # PacketServer是GoNeat封装的面向数据报（SOCK_PACKET）的服务模块，支持udp服务。\n与介绍StreamServer的方式类似，PacketServer实例化的部分前文已介绍过，这里只介绍其启动的过程。\n启动监听，处理入udp请求 # PacketServer.Server()中调用 reuseport.ListenPacket(...) 或者 net.ListenPacket(...) 监听svr.Addr（传输层协议类型svr.Network）创建监听套接字，并从中接收udp请求、处理请求、响应，详见svr.udpRead(…)，我们会在后续“请求处理”小节中进行介绍。\n// Serve start the PacketServer func (svr *PacketServer) Serve() error { svr.ctx, svr.cancel = context.WithCancel(context.Background()) if svr.shouldReusePort() {	//如果支持重用端口，linux+darwin reuseNum := runtime.NumCPU() for i := 0; i \u0026lt; reuseNum; i++ { udpConn, err := reuseport.ListenPacket(svr.Network, svr.Addr) if nil != err { panic(fmt.Errorf(\u0026quot;listen udp error %s\u0026quot;, err.Error())) } if nil != udpConn { go svr.udpRead(svr.protoHandler, udpConn) } } } else {	//如果不支持端口重用，windows udpConn, err := net.ListenPacket(svr.Network, svr.Addr) if nil != err { panic(fmt.Errorf(\u0026quot;listen udp error %s\u0026quot;, err.Error())) } if nil != udpConn { go svr.udpRead(svr.protoHandler, udpConn) } } return nil }  端口重用，加速udp收包 # 阅读上述代码，您一定关注到了这么一点， reuseport.ListenPacket(...) 和 net.ListenPacket(...) 。在继续描述之前，需要对比下tcp收包和udp收包的区别。\n tcp是面向连接的，往往为每一个连接创建一个专门的goroutine进行收包； udp是无连接的，要分配多少个协程进行收包呢？1个或者N个？对同一个fd进行操作，开多个goroutine是没有价值的，那么1个的话呢，收包效率和tcp对比又有点低效。这就是PacketServer重用端口reuseport的由来了，借此提高udp收包的效率。  重用端口（REUSEPORT）和重用地址（REUSEADDR），二者诞生的初衷和作用是不同的：\n TCP/UDP连接（UDP无连接但可以connect），由五元组表示：\u0026lt;协议类型，源ip，源端口，目的ip，目的端口\u0026gt;； REUSEADDR解决的是监听本地任意地址0.0.0.0:port与另一个监听本地特定地址相同端口a.b.c.d:port的问题； REUSEPORT解决多个sockets（可能归属于相同或者不同的进程）是否允许bind到相同端口的问题，  Linux下为了避免port hijack，只允许euid相同的进程bind到相同的port（bind设置socket源port，connect设置socket目的端口），同时对于tcp listen socket、udp socket还会进行“均匀的”流量分发，也是一个轻量的负载均衡方案。\ngolang标准库中暂没有提供reuseport的能力，这里是引入了第三方实现，目前支持Linux+Darwin平台下的udp reuseport，Windows暂不支持。\n过载保护，限制入请求数 # 与StreamServer类似，PacketServer也有过载保护机制，就是限制入udp请求数，我们在后续“请求处理”小节中介绍。\nModule：HttpServer # HttpServer是GoNeat在golang标准库基础上封装的http服务模块，支持与StreamServer、PacketServer一样的接口注册、接口路由、接口处理逻辑。\n标准库http基础上实现 # 从下面代码不难看出，HttpServer，该ServerModule的实现时基于标准库http package实现的，对大家来说应该都比较熟悉，但是这里也有个适配GoNeat的地方，也就是请求路由这里。\n// Serve start HttpServer func (svr *HttpServer) Serve() error { svr.serve() return nil } // serve start HttpServer func (svr *HttpServer) serve() { var h http.Handler = http.HandlerFunc(svr.doService) listener, err := net.Listen(\u0026quot;tcp\u0026quot;, fmt.Sprintf(\u0026quot;:%d\u0026quot;, svr.port)) if err != nil { panic(err) } server := \u0026amp;http.Server{ Addr: fmt.Sprintf(\u0026quot;:%d\u0026quot;, svr.port), Handler: http.StripPrefix(svr.prefix, h), } go func() { err := server.Serve(listener) if err != nil { svr.log.Error(\u0026quot;http svr start failed, err: %v\u0026quot;, err) } }() }  httpserver请求路由转发 # 借助标准库实例化 http.Server{} 时，指定了将请求URI Prefix为svr.prefix的请求，交由handler h处理。而h是svr.doService(…)强制类型转换成的http.HandlerFunc。\n看doService的定义，可知它确实是一个http.HandlerFunc（满足HandlerFunc的定义），这样请求就递交给了doService进行处理，doService中调用svr.requestHandler(req.Context(), httpSession)对请求进行处理，注意这里为请求专门创建了一个HttpSession，而这里的svr.requestHandler(…)是在哪里设置呢？\nsvr.requestHandler字段的设置，要追溯到HttpServer这个ServerModule实例化的时候，default_nserver示例会调用serverModule.SetHandler(nserver.process)方法将HttpServer.requestHandler设置为nserver.process(…)，即：func process(svr *NServer, ctx Context, NSession) error才是请求处理的核心逻辑之一，涉及到鉴权、命令字路由、请求处理、tracing、耗时监控等，稍后在“请求处理”部分进行介绍。\n// HttpServer defines the http NServerModule implementation type HttpServer struct { nserver *NServer port int32 log *nlog.NLog prefix string requestHandler RequestHandler enableGzip bool svr *http.Server } ... // doService process http request `req` func (svr *HttpServer) doService(w http.ResponseWriter, req *http.Request) { requestLimiter := svr.nserver.reqLimiter if requestLimiter.TakeTicket() { addr := svr.getClientAddr(req) defer func() { requestLimiter.ReleaseTicket() }() httpSession := NewHttpSession(addr, svr.log, req, w) ex := svr.requestHandler(req.Context(), httpSession) if ex != nil { w.WriteHeader(505) return } if httpSession.retcode == errCodeCmdNotFound { w.WriteHeader(404) } else { if len(httpSession.rspData) \u0026gt; 0 { w.Write(httpSession.rspData) } } } else { svr.log.Error(\u0026quot;http svr req overload\u0026quot;) } }  过载保护，限制入http请求数 # HttpServer也对入请求数进行了限制，实现对自身的过载保护，采用的方式与之前tcp、udp的处理方式类似。\nModule：ScheduleServer # ScheduleServer是GoNeat为定时任务封装的一个服务模块，简化定时任务实现逻辑。\n由于这里的实现逻辑比较简单、清晰，这里读者可以自己阅读代码进行了解。\nModule：HippoServer # HippoServer是针对消息驱动的业务场景封装的一个消费者服务，简化消息消费的任务处理。\n由于这里的实现逻辑比较简单、清晰，这里读者可以自己阅读代码进行了解。\nGoNeat - 请求处理 # 前文描述了Server实例及各个ServerModule启动的过程，至此服务已经完全启动，可以进行请求处理了。\n这里选择StreamServer、PacketServer、HttpServer作为重点描述对象，这几个ServerModule是日常业务开发中使用最频繁的，应该也是读者最希望了解的。在逐一描述之前，先介绍下用到的重要“基础设施”。\n基础设施：协程池 # 对于操作系统而言，进程是资源分配的基本单位，线程是任务调度的基本单位。协程是相比于线程而言更加轻量的调度实体，它的轻量体现在创建、任务切换、销毁时的代价，如初始分配的栈帧大小、任务切换时保存恢复的寄存器数量等。\ngo官方声称可以轻松创建几百万的协程，初始协程栈大小2KB，100w的话也就是2GB，尽管当前的服务主流机器配置应该都可以支持到，但是有些问题我们却不能不去不考虑。\n  一个请求创建一个协程，请求量大时协程数大涨，会因为OOM Kill被操作系统杀死；\n请求量上涨、协程数上涨、吃内存严重，操作系统可能会判定OOM分值时将其率先列入死亡名单，进程挂掉服务不可用，这是不可接受的。服务允许出现过载、处理超时、丢弃请求自保，但是不能挂掉。\n  尽管协程的创建、销毁更加轻量，但是开销还是存在；\n协程池，预先创建一定数量的协程备用，协程从任务队列中获取请求进行处理，避免频繁创建、销毁的开销。同时，为了避免单一锁竞争，为每个协程分配单独的一个chan作为任务队列。\n  尽管协程的切换代价更小，当协程数量很多时，协程切换的代价就不能忽略了；\nio事件就绪引起协程g1被唤醒，我们期望g1继续执行处理，结果协程g2的io事件就绪又唤醒协程g2，runtime scheduler可能在某个时刻（如g1进入function prologue时）将g1切换为g2……程序执行路径类似于多重中断处理，那什么时候被中断的协程g1可以继续恢复执行呢？如果协程数量很多，上下文切换的代价就需要引起关注。\n特别是希望尽可能并发处理连接上的多个请求的时候，可能会比一个连接一个协程创建更多的协程。又想并发处理连接上的多个请求，又想降低协程数过多带来的上下文切换开销，通过协程池限制协程数量，也是一种选择。\n  其他考虑；\n  鉴于上述考虑，我们采用协程池来处理并发请求，而不是为每个请求创建一个协程进行处理。\n基础设施：内存池 # go自带内存管理，内存分配、逃逸分析、垃圾回收，内存分配算法如何提高分配效率、减少碎片是一个常被提及的问题，即便go在这方面基于tcmalloc和go自身特性做了优化，框架开发仍需要关注内存分配问题，此外还要关注gc。\n考虑内存分配的情景，如果我们频繁在heap中申请内存（逃逸分析会决定分配在heap上还是stack上），不仅会增加内存分配的开销，也会增加gc扫描、回收时的压力。\n内存分配次数增加引入额外开销不难理解，使用sync.Pool可以在两次gc cycle间隙返回已分配的内存来复用以减轻内存分配的次数，自然也会减轻gc扫描、标记、回收的压力。\n每次 gcStart(){...} 开始新一轮gc时，会首先清理sync.Pools，清理逻辑也比较简单暴力，sync.Pools中的空闲内存块都会被清空，进入后续垃圾回收，所以内存池不适合用作连接池等有状态的对象池。\n在GoNeat框架中我们将其用作收发包buffer池，用完即释放，不存在上述有状态对象被清理的问题。\nModule：StreamServer # StreamServer，提供tcp网络服务，前文已经介绍了StreamServer整个生命周期的一个大致情况，包括启动监听、建立连接、接收请求、过载保护、退出等，现在我们把视角锁定在“请求处理”这个环节，进一步了解其工作过程。\n再简单回顾一下，服务端StreamServer已经启动，现在正调用listener.Accept()等待客户端连接。\nfunc (svr *StreamServer) tcpAccept(handler NHandler, listener net.Listener) { ... for { ... conn, ex := listener.Accept() endpoint := newEndPoint(svr, conn) go endpoint.tcpReader() go endpoint.tcpWriter() } }  客户端发起建立连接请求，listener.Accept()将返回建立的连接，并为连接创建两个协程，一个负责收包，一个负责回包。下面我们就看下收包、解包、请求处理、组包、回包的完整过程。\n收包解包 # go endpoint.tcpReader() 创建了一个协程从连接上读取请求数据。由于tcp是面向字节流的无边界协议，客户端可能会同时发送多个请求包过来，这些包与包之间没有明显的数据边界，即所谓的粘包。tcp服务必须根据业务协议编解码规则处理粘包问题，否则会导致请求解码失败，更无法正常处理请求。\n下面看下框架是如何进行收包解包的，网络交互过程涉及到大量的错误处理（先不展开），这里只截取了收包、解包的部分代码，方便大家理解。\nfunc (endpoint *EndPoint) tcpReader() { ... // 回忆下，不同的协议都有注册对应的协议handler，如nrpc协议对应NRPCHandler handler := svr.protoHandler // resizable buffer是网络收包过程非常倚重的一种存储结构，其大小可伸缩 // 同时为了减少内存分配、回收压力，采用了内存池的方式，预先分配特定大小的buffer用于收包， // 如果收包数据当前buffer不够用的情况下，buffer就会动态增长以满足对存储空间的要求 buf := bufPool.Get() defer bufPool.Put(buf) OUT: for { select { case \u0026lt;-ctx.Done(): return default: // 读取连接上到达的数据，这里设置一个读超时时间 // 如果连续一段时间(默认5min)连接上没有数据到达，则认为连接空闲，服务端为节省资源可以主动断开连接 ex := conn.SetReadDeadline(time.Now().Add(time.Millisecond * time.Duration(timeout))) // 读取连接上的请求数据，一次读取可能遇到如下情形： // - 完全没有读取到数据，这种会出现读取超时，for循环continue OUT，继续执行下次读取 // - 读取到了不足一个包的数据，这种会返回io.ErrUnexpectedEOF，for循环continue OUT继续收取包的剩余数据 // - 刚好读取到了一个完整包的数据，这种handler.Input(...)会返回一个请求session处理， // - 读取到了不止一个请求包的数据，这种会返回最前面请求对应的session，剩余数据参考上述情形之一继续处理 _, ex = buf.ReadFromOnce(conn) // 可能一次读取了多个请求包，需要循环处理 for { buf.MarkReadIndex() // 这里使用协议handler对buf中接收的数据进行解码操作，如果能成功解出一个请求体，则返回对应的session nSession, ex := handler.Input(remoteAddr, buf) // 包不完整不全直接忽略，继续收包 if io.ErrUnexpectedEOF == ex { buf.ResetReadIndex() continue OUT } // 如果包不合法，如校验发现严重错误（非收包补全）如幻数、长度校验失败，关闭连接 if ex != nil { return } } } ... }  请求处理 # 假定从连接上读取的数据，经协议handler校验并解码出了一个完整的请求包，此时协议handler会创建一个匹配的session（如nrpc协议对应NRPCSession），见 nSession,ex := handler.Input(remoteAddr, buf 。创建的session用于跟踪一个请求的完整生命周期，session记录了客户端请求、服务端响应、服务处理过程中的错误事件、分布式跟踪、日志信息等等。\n当StreamServer成功从连接上读取到一个请求准备开始处理之前，需要检查下当前是否已经超过了服务允许同时处理的最大请求数，如果服务端将触发过载保护动作，直接丢弃请求。\nfunc (endpoint *EndPoint) tcpReader() { ... OUT: for { select { ... //可能一次收到多个请求包，需要循环处理 for { buf.MarkReadIndex() nSession, ex := handler.Input(remoteAddr, buf) ... if requestLimiter.TakeTicket() { svr.nserver.workpool.Submit(func() { //process defer func() { requestLimiter.ReleaseTicket() }() ex := svr.requestHandler(ctx, nSession) if ex != nil { svr.log.Error(\u0026quot;[tcp-%s] handler Process error:%s\u0026quot;, handler.GetProto(), ex.Error()) return } endpoint.sendChan \u0026lt;- nSession.GetResponseData() cost := time.Since(nSession.ProcessStartTime()).Nanoseconds() / 1000000 svr.nserver.monitorCost(nSession.GetCmdString(), cost) }) } else { //过载了直接关闭连接 log.Error(\u0026quot;[tcp-%s] [!!close conn!!] nserver reqs overload\u0026quot;, handler.GetProto()) return } } } } }  在请求没有触发服务过载保护的前提下，即 requestLimiter.TakeTicket() == true 时，此时会将请求递交给协程池处理，svr.nserver.workerpool.Submit(func(){…})。协程池的大致实现逻辑前面已有提及，它负责执行我们提交的任务，也就是这里workerpool.Submit(f func(){…})的参数f。注意到参数f中包含了这样一段代码：\nfunc f() { defer func() { requestLimiter.ReleaseTicket() }() ex := svr.requestHandler(ctx, nSession) if ex != nil { return } endpoint.sendChan \u0026lt;- nSession.GetResponseData() cost := time.Since(nSession.ProcessStartTime()).Nanoseconds/1000000 svr.nserver.monitorCost(nSession.GetCmdString(), cost) }  收包处理流程结束之后，需要释放ticket，见defer函数。关于请求的正常处理流程的入口则是 svr.requestHandler(ctx, nSession) ，这里的svr.requestHandler其实就是 cmd_handler.go:process(…) 方法，在 neat_svr.go:NewNServer() 方法体中 svr.requestHandler = NewRequestHandler()，而NewRequestHandler的返回值则是cmd_handler.go:process(…) 方法。\ncmd_handler.go:process(ctx context.Context, session nserver.NSession)请求处理的核心逻辑，包括请求命令字与处理方法的路由控制策略、调用用户自定义处理函数，方法执行完成后nSession中将包含该请求对应的响应结果。\n组包回包 # 回包协程，执行下面的逻辑，循环从endpoint.sendChan中取出响应包，并发送给请求方。\nfunc (endpoint *EndPoint) tcpWriter() { ... for { select { case \u0026lt;-ctx.Done(): return case dataRsp := \u0026lt;-endpoint.sendChan: conn.SetWriteDeadline(time.Now().Add(time.Millisecond * time.Duration(timeout))) dataLen, ex := conn.Write(dataRsp) } } }  StreamServer的大致执行逻辑就介绍到此，更多细节信息，可以阅读下相关代码。\nModule：PacketServer # PacketServer，提供udp网络服务，前文已经介绍了PacketServer整个生命周期的一个大致情况，包括启动监听、端口重用、过载保护、退出等，现在我们把视角锁定在“请求处理”这个环节，进一步了解其工作过程。\nREUSEPORT # UDP是无连接协议，不存在TCP数据传输过程中的粘包问题，在收包、解包方面的处理逻辑会简单一点。与TCP不同的是，tcpClient和tcpServer建立连接的时候，tcpServer端会创建连接套接字， 我们每个连接套接字创建了一个专门的协程进行收包、解包。相比之下，UDP本身没有连接的概念，udpServer收包就是通过监听套接字，如果我们只创建一个协程来进行数据包的收包、解包操作，和tcpServer相比，在性能上就会有点逊色。\n为此，udpServer的收包，这里利用了reuseport相关的能力。socket选项SO_REUSEPORT允许多线程或者多进程bind到相同的端口，网络数据包到达的时候，内核会在这些线程或进程之间进行分发，具备一定的负载均衡的能力。目前框架是基于当前CPU核数N来决定reuseport的次数，每reuseport.ListenPacket(…)一次，都会创建一个udpsocket，此时再创建一个协程用于udpsocket的收包、解包操作。这种方式和单纯从一个监听套接字上收包、解包相比，提高了收包、解包的效率。\n其实TCP、UDP都可以基于reuseport进一步提升性能，框架目前将其应用在UDP上。\n收包解包 # 相比较TCP收包而言，UDP收包的逻辑就简单了很多。\n在监听套接字上循环收包，一旦检测到ctx.Done上游超时、cancel事件，则执行退出逻辑，关闭udp监听套接字。反之，则读取请求体，注意，这里有个允许同时处理请求数限制，因此会先检查 requestLimiter.TakeTicket() 是否成功，如果成功则执行实际的收包、处理逻辑，反之框架认为当前请求量过载，执行丢弃逻辑，调用方会感知到超时。\n未过载的情况下，框架会从内存池里面分配或者复用一个以前分配的buffer，用来接收UDP请求体，并构建一个协议匹配的session，此时buffer已经完成了当前次的使命，将其放回内存池备用。\n详细的UDP收包处理逻辑如下所示：\nfunc (svr *PacketServer) udpRead(handler NHandler, udpConn net.PacketConn) { defer udpConn.Close() ctx, cancel := context.WithCancel(svr.ctx) ... requestLimiter := svr.nserver.reqLimiter for { select { case \u0026lt;-ctx.Done(): return default: if requestLimiter.TakeTicket() { data := udpRecvBufPool.Get().([]byte) n, remoteAddr, ex := udpConn.ReadFrom(data) ... r := bytes.NewBuffer(data[:n]) nSession, ex := handler.Input(remoteAddr, r) udpRecvBufPool.Put(data) ... } else { udpSvrReceiveExceedMax.Inc(1) //udp-svr 收包过载丢弃 } } } }  请求处理 # 与TCP的处理方式类似，当正确收取了一个UDP请求，并为之构建好协议匹配的session之后，就会将其一个任务处理的闭包函数作为一个task递交给workerpool进行处理，svr.nserver.workpool.Submit(func() {…})，该闭包函数执行完毕后也要注意释放requestLimiter，闭包函数中的 svr.requestHandler(ctx, nSession) 就是 cmd_handler.go:process(ctx, session) 方法，与TCP的处理逻辑是一致的。之所以在svr.requestHandler和cmd_handler.go:process(…)中间再加一层抽象，是考虑到业务开发者可能希望定制化requestHandler的能力，cmd_handler.go:process(\u0026hellip;)方法只是提供了一个还不错的默认实现。\nsvr.requestHandler(ctx, nSession)执行完成后，nSession中将包含请求体的响应结果，响应结果将写入sendChan中，由负责回包的协程 go svr.udpWrite(...) 执行回包操作。\nfunc (svr *PacketServer) udpRead(handler NHandler, udpConn net.PacketConn) { ... sendChan := make(chan *packet, 1000) go svr.udpWrite(ctx, cancel, udpConn, sendChan) ... for { select { case \u0026lt;-ctx.Done(): ... default: if requestLimiter.TakeTicket() { nSession, ex := handler.Input(remoteAddr, r) svr.nserver.workpool.Submit(func() { defer func() { requestLimiter.ReleaseTicket() }() ex = svr.requestHandler(ctx, nSession) dataRsp := nSession.GetResponseData() ... sendChan \u0026lt;- \u0026amp;packet{dataRsp, remoteAddr} }) } else { ... } } } }  组包回包 # 回包协程执行下面的逻辑，它循环从sendChan中收取UDP请求对应的响应，并检查响应数据是否超过64KB，超过则丢弃，反之则将响应返回给请求方。\nfunc (svr *PacketServer) udpWrite(ctx context.Context, cancel context.CancelFunc, conn net.PacketConn, sendChan chan *packet) { defer cancel() for { select { case \u0026lt;-ctx.Done(): return case p := \u0026lt;-sendChan: if len(p.data) \u0026gt; 65536 { udpRspExceed64k.Inc(1) //udp回包超过64k continue } conn.SetWriteDeadline(time.Now().Add(time.Millisecond * time.Duration(timeout))) datalen, ex := conn.WriteTo(p.data, p.addr) ... } } }  PacketServer的大致执行逻辑就介绍到此，更多细节信息，可以阅读下相关代码。\nModule：HttpServer # HttpServer中有没有使用worker池（协程池）进行处理呢？该ServerModule是建立在标准库http实现之上的，GoNeat只是将请求处理的Handler传给了标准库http实现，并没有对标准库具体如何处理该请求做什么干预，比如是否采用worker池（协程池）。关于这一点，答案是否，可以查看下go标准库源码。\n为每个连接创建一个协程进行处理 # 标准库实现中，建立监听套接字之后，调用 svr.Serve(listener) 开始接受入连接请求，该方法循环 Accept() 取出建立好的tcp连接并进行处理。标准库实现针对每一个连接都启动了一个goroutine进行处理，这与我们StreamServer的实现方式是类似的，所不同的是处理连接上并发请求的方式。\nnet/http/server.go:\n// After Shutdown or Close, the returned error is ErrServerClosed. func (srv *Server) Serve(l net.Listener) error { ... for { rw, e := l.Accept() ... c := srv.newConn(rw) ... go c.serve(ctx) } }  同一连接，串行收包、处理、回包 # 注意 c.Serve(ctx context.Context) 的注释部分，其中有提到HTTP/1.x pipelining的处理局限性，一个连接上可能会有多个http请求，标准库当前实现逻辑是读取一个请求、处理一个请求、发送一个响应，然后才能继续读取下一个请求并执行处理、响应，所以多个http请求的处理是串行的。\n注释中也有提到，可以收取多个请求，并发处理，然后按照pipeling请求顺序按序返回结果（http协议头并没有类似我们业务协议seqno的字段），但是当前没有这么做。\n连接上请求的读取、处理、回包都是在同一个连接中完成处理的，并没有像我们StreamServer、PacketServer那样将请求递交给worker池（协程池）进行处理。\nnet/http/server.go:\n// Serve a new connection. func (c *conn) serve(ctx context.Context) { ... // HTTP/1.x from here on. c.r = \u0026amp;connReader{conn: c} for { // 读取连接上的请求 w, err := c.readRequest(ctx) // 读取一个请求，串行处理一个请求 // HTTP cannot have multiple simultaneous active requests.[*] // Until the server replies to this request, it can't read another, // so we might as well run the handler in this goroutine. // [*] Not strictly true: HTTP pipelining. We could let them all process // in parallel even if their responses need to be serialized. // But we're not going to implement HTTP pipelining because it // was never deployed in the wild and the answer is HTTP/2. serverHandler{c.server}.ServeHTTP(w, w.req) // 请求处理结束，finishRequest flush响应数据 w.cancelCtx() w.finishRequest() ... } } func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == \u0026quot;*\u0026quot; \u0026amp;\u0026amp; req.Method == \u0026quot;OPTIONS\u0026quot; { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req) }  sh.svr.Handler其实就是nserver.HttpServer.doService()方法。\nnserver/neat_http.go:\n// doService process http request `req` func (svr *HttpServer) doService(w http.ResponseWriter, req *http.Request) { ... }  接管标准库Request URI路由转发 # HttpServer只是在标准库http实现基础上自定义了请求Handler，所有Request URI匹配http.prefix的请求将递交给doService(…)方法处理，在doService方法内再调用nserver.process()方法转入GoNeat框架内置的命令字路由逻辑，与StreamServer、PacketServer不同的是，这里的命令字不再是rpc方法名、命令字拼接字符串，而是Request URI。\nprocess()方法内通过URI路由到对应的处理函数Exec，并完成Exec的调用，拿到处理结果，process()方法返回处理结果，doService方法负责将响应结果写入连接中，c.Serve()中w.finishRequest()负责将响应数据flush。\n至此，一次http请求、处理、响应就结束了。\n而关于HTTP/2中pipelining的处理情况，与之类似，读者可以自行查阅、跟进标准库实现了解相关细节，这里不再赘述。\nHttpServer的大致执行逻辑就介绍到此，更多细节信息，可以阅读下相关代码。\nGoNeat - 服务怠速 # 前文描述了Server实例及各个ServerModule启动、请求处理的过程，当服务空闲的时候会发生什么呢？为这个阶段起了一个好听的名字”怠速”，“怠速”意味着并不是停止服务，服务依旧在空跑，那空跑阶段会发生什么呢？\nGoNeat框架还是会做些事情的，比如清理、释放一些不必要的资源占用，为后续请求处理再次做好准备。\nsync.Pool # 前文提到，在两次gc cycle间隔期，sync.Pool可以有效提升内存分配效率，sync.Pool.Get()申请新内存或者复用已分配的内存，sync.Pool.Put(buf)重新将sync.Pool.Get()返回的buf放回池子以备复用，如果gc来临，sync.Pool中遗留的未使用的内存区将被释放掉。\nfunc poolCleanup() { // This function is called with the world stopped, at the beginning of a garbage collection. // It must not allocate and probably should not call any runtime functions. // Defensively zero out everything, 2 reasons: // 1. To prevent false retention of whole Pools. // 2. If GC happens while a goroutine works with l.shared in Put/Get, // it will retain whole Pool. So next cycle memory consumption would be doubled. for i, p := range allPools { allPools[i] = nil for i := 0; i \u0026lt; int(p.localSize); i++ { l := indexLocal(p.local, i) l.private = nil for j := range l.shared { l.shared[j] = nil } l.shared = nil } p.local = nil p.localSize = 0 } allPools = []*Pool{} }  虽然这部分不是框架本身所施加的，这里列出来也是为了强调下，希望开发者对计算资源保持足够的敏感度，即便是在使用自带gc机制的编程语言条件下，也应该保持这种敏感度。gc不是万能的，可以找出一种case将gc阈值推高进而将内存撑爆。\nworkerpool # 一个workerpool的内部构造大致如下，每个worker其实就是一个goroutine，每个goroutine都绑定了一个独占的任务队列。当请求量上涨的时候，在workers都处于busy状态的情况下，workerpool会检查workers数量是否已经超过指定的上限，如果没有就继续创建worker，如此worker数量会越来越多……\nworkerpool |--worker1 ---- tasks|t1|t2|t3|..| |--worker2 ---- tasks|t4|t5|..| |--worker3 ---- tasks|| |--worker? ---- tasks|| |--workerN ---- tasks|tx|ty|tz|  当请求量降低，甚至是空闲的时候呢？这些worker（goroutine）难道还会存在？似乎没有必要。workerpool也会定时检查workers空闲时间，每次workerpool.Submit(task)的时候，会更新实际接收该task的worker的最近使用时间lastUsedTime，如果currentTime.Since(lastUsedTime) \u0026gt; maxIdleDuration，则认为worker空闲，终止worker执行就可以了。\n空闲连接 # 连接保活，是一个容易引起争论的话题，当前TCP协议本身支持连接保活，每隔一定时间发送一个TCP探针，但是也有人认为这加重了网络拥塞，保活应该在应用层自己实现，如通过心跳机制。\n尽管存在这些争议，TCP保活机制仍然是首选的保活机制之一，因为它不需要引入额外的开发、保活策略。连接保活可以在客户端做，也可以在服务端做，其作用只是为了探测连接是否还健康地保持着。框架中在服务端进行保活，对于短连接的情况，继续保活显得有点多余，那为什么框架实现时选择了在服务端进行保活呢？\n因为框架中对TCP完全是以双工的方式进行处理的，如在一个连接上循环收包、处理、回包，并没有做客户端是TCP短连接的假设，客户端不管是TCP短连接、长连接，StreamServer都是一样的处理逻辑，也可以理解成StreamServer鼓励客户端使用TCP长连接，所以在服务端发起保活机制也是很自然的选择。\n一个进程允许打开的文件描述符（fd数量）是有限的，Linux下可以通过ulimit -s进行设置。允许打开的fd数量有限代表什么呢？在Linux下，一切皆文件，几乎所有的资源都被抽象成了文件，而每个文件”句柄“基本上都对应着一个fd。fd数量有限，意味着允许创建的socket数量也是有限的。\n而ulimit -s可能给到了一个很高的值，但是如果我们不小心，也极容易泄露fd。笔者就曾经见过Web服务中client实例化没有使用单例、并且client销毁时没有close(fd)而导致fd泄露，进而迅速拖垮了现网几十台Web服务器的案例。\n考虑到这种种因素，框架还是需要做些事情，将这些服务端空闲的TCP连接及时销毁，并且为了适应不同的业务场景，允许自定义连接空闲时间（记为T）。当连接上连续时间T没有请求到达，服务端认为连接空闲，并关闭连接释放系统资源。\nserver端关闭空闲连接，对client端来说，client收到TCP FIN包，client认为server端只是关闭了连接的写端、读端并未关闭，所以下次client继续向server发送数据时，网络io也已经设置为非阻塞，此时conn.Write(…)返回成功，但其实稍后请求到达server端，server端请求的端口早就已经没有进程使用了，因此会返回TCP RST，此时client端意识到对端已经关闭连接了，但是这个错误client如何能感知到？只能通过额外的conn.Read(…)来感知！\n这里会影响到客户端TCP连接池的实现，要想实现一个可靠的TCP连接池，必须意识到这个问题的存在，我们会在后续client相关实现中继续描述。\n其他问题 # 其他的一些不可或缺，但是可能没那么重要的点，这里先暂时不列出。\nGoNeat - 监控上报 #   Metric\n框架支持metric，将框架属性监控能力与公司组件进行了解耦，metric当前支持4个维度：counter、gauge、timer、histogram，也提供了适配monitor的metric reporter。框架上报了自身的一些关键指标，方便业务开发人员及时根据框架监控，感知业务中潜伏的问题。\n  Tracing\n框架支持分布式跟踪，对rpc调用自动植入trace数据，业务开发无感知，只需部署或者接入相关的tracing backend（如zipkin、jaeger或者天机阁即可），可以很方便地对全链路进行跟踪、错误回溯。\n  Monitor\n作为公司常用监控组件，go-neat/tencent/attr提供了monitor相关的封装，业务开发人员可以方便地拿来使用，并提供了批量申请monitor的工具，简轻业务开发人员监控打点的负担。\n  Habo\n哈勃作为公司级下一代监控平台，框架层也进行了尝试，目前对模调信息进行了上报，可以很方便地对服务成功率、耗时分布进行统计，可以作为服务运营质量的一个参考指标。\n  GoNeat - 平滑退出 #   监听信号，平滑退出\n框架支持监听指定信号执行平滑退出逻辑，目前来看框架退出时，会完成log刷盘、等待指定时长后再退出，等待退出期间server端可以尽力处理入队请求，但是不保证100%处理完。\n  context.Context超时\n框架设计时对context.Context的使用场景非常明确，将其用于全局超时控制，而不用来传值。给到一个context，想了解它里面携带了什么数据，除了明确知道key没有什么更加直观的方法，而key可能分散在多个文件、同一个文件的不同地方，这非常不直观、不友好。我们不希望业务开发者来猜测，我们会在context里面塞入什么特殊的东西，我们什么都不塞，仅仅是全局超时控制。\nnserver.ctx是root context，框架中ServerModule、Endpoint、收发包实现、业务逻辑处理中等等出现的context，默认都是派生自nserver.ctx，这意味着当框架收到信号执行退出逻辑时，取消nserver.ctx将取消所有的child context，我们在ServerModule、Endpoint、收发包实现、业务逻辑处理代码中等等，都植入了检测context.Done()的判断逻辑，以让系统中各个零部件及时作出步调一致的动作，如logger组件快速刷盘后退出、StreamServer关闭监听套接字尽最大努力处理已入队请求等。\n  还没有那么平滑？\n可能看到这里，不少开发者认为，似乎还没有那么平滑，关于平滑退出的设计可以在go-neat/core issues中进行更详细地讨论。\n  GoNeat - More # 其实还有很多地方没有介绍，如ClientAdapter实现、高并发写操作Map实现、Json Map WeakDecode、限频措施、客户端连接池更可靠地连接活性检测、可靠的应用层协议设计等，这里感兴趣的朋友可以先查阅下相关代码，稍后我们会继续补充。\n写在最后，GoNeat框架一直处于比较活跃的开发状态，框架代码一直在小幅度、不间断地优化中，文档和框架比较起来，可能会略显滞后，如果您发现文档有问题，也请反馈给我们。\n感谢如下同学为框架开发作出的贡献：脱敏处理 :)\n GoNeat - End of Life :( # 2020年7月份开始，PCG开始组织大规模的技术治理，其中就包括事实上的公司级的微服务框架tRPC的建设，自此以后我便将人力投入到了tRPC的建设、贡献中，GoNeat自这个时间点开始开始停止新特性更新。\nGoNeat框架是一款在2018.3月开始陆陆续续编写的框架，到2018.8月份开始小规模测试，之后的两年里成为了团队的核心开发框架，支撑了团队几千个微服务，直到PCG建设tRPC框架后，GoNeat框架也最终走向了停止后续开发的命运。\n虽然未来难免被遗忘、废弃，但是它过去也曾经”繁荣“过，几十人的活跃开发组织，几百个的issue沟通讨论、几千的commit、很多次技术分享，沉淀下来的东西也可以对新同学成长起到些指引帮助作用，对后续框架设计开发者也具有一定的参考价值，希望本文能对框架设计实现感兴趣的同学有帮助。\n"}),a.add({id:383,href:"/tags/microservice/",title:"microservice",description:"",content:""}),a.add({id:384,href:"/tags/rpc/",title:"rpc",description:"",content:""}),a.add({id:385,href:"/tags/trpc/",title:"trpc",description:"",content:""}),a.add({id:386,href:"/tags/rm/",title:"rm",description:"",content:""}),a.add({id:387,href:"/tags/rm-safe/",title:"rm-safe",description:"",content:""}),a.add({id:388,href:"/blog/2019-10-18-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%AE%89%E5%85%A8%E7%9A%84%E5%88%A0%E9%99%A4%E5%91%BD%E4%BB%A4rm/",title:"如何实现一个更安全的删除命令rm",description:"rm -rf，这个命令乍一看浑身起鸡皮疙瘩，很多操作过Linux服务器的人都对此小心翼翼。前不久一不小心在macOS上执行了rm -rf，命令执行过程中看着闪过的文件，我竟然删除了HOME下的东西，眼睁睁看着文件被删除，ctrl+c已经失去响应……于是便有了本文介绍的rm-safe工具，避免以后误删除重要文件。",content:" img { width: 680px; padding-bottom: 1rem; }  背景 # 大家有没有因为一时大意，错误地执行了rm -rf而导致重要文件被删除的情况？一定有那么一次两次的吧。前几天，我又犯了这一次这样的错误。本来是要删除当前目录下的一个文件，于是执行 rm -rf .，这里还没有输入完，因为我调整了KeyRepeat设置项的原因吧，按键延迟很短，结果命令变成了 rm -rf ..，这个时候..已经指向了HOME目录……额，没关注右手，左手还没有tab候选，右手已经键入了回车，gg，眼睁睁地看着大量文件被删除，ctrl+c已经太晚了 :( 。\n多亏macOS默认对Desktop、Document等目录下的文件做了自动地备份，不然就真的要苦了，虽然对重要文件、数据也有做过备份，但是也不能做到按月、按天的备份，哪怕是最近几个月的数据、配置的丢失，对我来说也是挺伤的。果不其然，后续几天陆陆续续发现丢失了各种各样的配置，IDE的、bash的、git的、pet的……各种各样的！\n不幸中的万幸，一些自己认为真的很重要的数据，一般在Document中交给icloud做了备份，这些数据倒是可以恢复，虽然慢了点，但是能恢复总还是好的！感谢icloud提供的云存储服务！\n如何避免误删除文件 # 经此一役之后，我还是思考了一些如何规避的问题，我有多年的Linux使用经验，竟然也会犯这样的错误，我将其归因于：过失问题，虽然像我这样的有经验的开发者极少会犯这样的错误，但是还是会偶尔发生！很多开发者都提出了自己的一些想法，如何规避rm造成的文件误删问题，我们这里不考虑如何恢复的问题，如果是私人笔记本单硬盘单分区的话，恢复的困难度是比较高的。\n  删除只用系统gui删除，如macOS、windows、kde下删除文件到垃圾箱，误删的话还是可以从垃圾箱恢复的；\n不适用：执行删除动作是很常见的，作为一名开发者，我不大可能使用gui来频繁切换目录后才删除文件。\n  自定义bash中的alias，如alias rm=\u0026ldquo;function rm() {\u0026hellip;.}\u0026quot;，该函数内部做一些检查，以决定是否删除文件；\n不适用：这也是一个解决问题的思路，但是能否与原生的/bin/rm命令完全兼容是一个问题，而且检查逻辑可能要频繁改动才能胜任各种避免误删的场景，使用起来不是那么灵活。\n  使用第三方的删除工具，如github上的一些类似rm-safe的工具，代替原生的/bin/rm命令；\n不适用：这些工具不能完全与/bin/rm兼容，尤其是那些命令选项不完全兼容，而/bin/rm是一个非常好用的工具，我们只是想尽力规避下误删除的风险而已。\n  看上去没有一个现有工具能够完全满足自己的选择，那就自己按自己的需要开发一个吧！\n设计更安全的rm工具 # 分析/bin/rm # 首先，不得不说，/bin/rm是一个非常好用的命令，删除文件、删除没目录等等，可以说使用频率非常高，它也确实很好用。说白了，我们只是要在它的基础上做些安全方面的风险规避就能满足需求。\n/bin/rm，它有一系列的命令选项，且是POSIX风格的。\n 如果我们开发一个工具，或者在/bin/rm基础上包一层的话，我们最好也使用POSIX风格的命令选项来解析; 涉及到rm相关的选项，原来rm有的我们也要有，而且功能必须保持一致；  说白了就是，我们要保证用户使用的时候，习惯保持不变，甚至没有意识到自己在使用一个安全增强的rm。\n如何安全增强 # rm动作是用户自己执行的，除了用户自己清楚目标文件是否重要，没有其他人可以做出胜过文件拥有者的决定，所以安全增强的决定还是交给用户自己来做出，我们的工具只是协助用户完成这样的动作。\n设计一个安全增强的rm：\n 支持pin命令，如rm pin Documents，保护Documents目录及其下的文件；  当执行rm -rf Documents时，发现有.pinLock文件存在，表示Documents目录及其下的文件、子目录受保护，拒绝删除； 当执行rm -rf Documents/dir/file时，会递归地回溯目录层级，如果路径上任一父目录受保护，该文件不能被删除；   支持unpin命令，如rm unpin Documents，取消Documents当前一级目录的保护；  当执行rm -rf Documents/dir/file时，如果Documents处于unpin状态，但是dir处于pin状态，file也是受保护的，不能删除；   支持-r选项，允许递归地添加、移除保护；  实现该rm命令 # 以下是大致的rm命令操作的help信息，它有3个子命令，help显示帮助信息，pin用来对目录添加保护，unpin移除保护。\n$ rm help hitzhangjie/rm is an security-enhanced version of /bin/rm, which could avoid the deletion of files by mistake. rm help: display help info rm pin: -r, pin target recursively rm unpin: -r, unpin target recursively  当传递给rm的选项，不是rm help/pin/unpin这样的选项时，会将选项当做/bin/rm的选项，进而执行rm相关的动作，所不同的是，这里的删除并不是由/bin/rm来执行，而是由我们重写的一个rmCmd来执行，其内部会首先检查待删除文件、目录是否正在被保护。\n该安全增强的rm工具的代码，请戳 hitzhangjie/rm 查看。\n代码量不多，有几个重要的点阐述下：\n 执行rm命令时，给用户必要的提示信息，让用户知道这是一个安全增强版的rm命令，并非shell原生的rm； 执行rm pin时，创建文件锁.pinLock，该文件的存在表示其所在的目录及目录下的文件、子目录统统受保护，执行rm时不能删除； 执行rm unpin时，删除文件锁.pinLock，改文件备移除之后，表示所属目录及目录下的同级文件、目录不再受保护，但是若子目录中有.pinLock文件仍受保护； 执行rm时，因为rm是POSIX风格的命令选项，意味着实现pin、unpin时，最好就别再使用go标准库提供的选项风格进行解析，不然两种风格的选项混在一起，使用起来多有不便； 这里我们使用的是pflags这一基于POSIX风格的flags解析库。  代码量不多，感兴趣的话，可以自行查看源码，了解具体的实现细节。\n如果希望自己也能避免因为手贱带来的文件误删问题，欢迎使用体验该工具！\n小结 # 从日常使用角度出发，思考了靠人来避免误删除文件的操作是基本行不通的，还是要提供有效的工具去协助人来对重要文件进行保护。经历过一两次这样的文件误删除操作之后，痛得难受，就醒了，于是自己开发了这个安全增强版本的rm工具，其实寥寥数行代码而已，但是却帮了我大忙。现在偶尔也是会敲出很可怕的命令，但是因为我已经提前对重要文件目录做了保护，再没发生过重要文件被rm误删除的场景了。\n我不能保证自己以后不会手贱，但是有这个工具的存在，很大程度上减轻了我的心理压力，哈哈！希望对读者们有帮助! :)\n"}),a.add({id:389,href:"/tags/code-reivew/",title:"code reivew",description:"",content:""}),a.add({id:390,href:"/tags/cr/",title:"cr",description:"",content:""}),a.add({id:391,href:"/tags/google/",title:"google",description:"",content:""}),a.add({id:392,href:"/blog/2019-09-10-%E5%A6%82%E4%BD%95%E6%9B%B4%E5%A5%BD%E5%9C%B0%E8%BF%9B%E8%A1%8C%E4%BB%A3%E7%A0%81review/",title:"Google CR指引, 如何推进代码评审",description:"代码评审，是一种协作的方式，也是一种做事的方式，也是一种思想交流、对待错误的态度……但是要想把代码评审做好，却不是一件简单的事情。代码评审不能太功利、太敷衍、太随意，需要好的“实践经验”来指导。",content:"最近学习了Google的CodeReview指引，整理了其中一些比较有价值的点，分享给大家。\nGoogle Code Review Guidelines # Google积累了很多最佳实践，涉及不同的开发语言、项目，这些文档，将Google工程师多年来积攒的一些最佳实践经验进行了总结并分享给众开发者。学习下这里的经验，我们在进行项目开发、开源协同的过程中，相信也可以从中受益。\nGoogle目前公开的最佳实践相关文档，目前包括：\n Google\u0026rsquo;s Code Review Guidelines，Google代码review指引，包含以下两个系列的内容：  The Code Reviewer\u0026rsquo;s Guide The Change Author\u0026rsquo;s Guide    这了涉及到Google内部使用的一些术语，先提下：\n  CL: 代表changelist，表示一个提交到VCS的修改，或者等待review的修改，也有组织称之为change或patch；\n  LGTM：代表Looks Good to ME，负责代码review的开发者对没有问题的CL进行的评论，表明代码看上去OK；\n  The Code Reviewer\u0026rsquo;s Guide # 从代码reviewer的角度出发，介绍下Google内部积累的一些good practices。\nIntroduction # Code Review（代码评审）指的是让第三者来阅读作者修改的代码，以发现代码中存在的问题。包括Google在内的很多公司会通能过Code Review的方式来保证代码和产品的质量。\n前文已有提及，CR相关内容主要包括如下两个系列：\n The Code Reviewer\u0026rsquo;s Guide The Change Author\u0026rsquo;s Guide  这里先介绍下CR过程中应该做什么，或者CR的目标是什么。\nWhat Do Code Reviewers Look For? # Code review应该关注如下方面：\n Design：程序设计、架构设计是否设计合理 Functionality：代码功能是否符合作者预期，代码行为是否用户友好 Complexity：实现是否能简化，代码可读性是否良好，接口是否易用 Tests：是否提供了正确、设计良好的自动化测试、单元测试 Naming：变量名、类名、方法名等字面量的选择是否清晰、精炼 Comments：是否编写了清晰的、有用的注释 Style：代码风格是否符合规范 Documentation：修改代码的同时，是否同步更新了相关文档  Picking the Best Reviewers # 一般，Code review之前，我们应该确定谁才是最好的、最合适的reviewer，这个reviewer应该**“有能力在比较合理的时间内对代码修改是否OK做出透彻、全面的判断”**。通常reviewer应该是编写被修改代码的owner，可能他是相关项目、相关源文件、相关代码行的创建者或者修改者，意味着我们发起Code review时，同一个项目可能需要涉及到多个reviewer进行Code review，让不同的、最合适的reviewer来review CL中涉及到的不同部分。\n如果你心目中有一个合适的reviewer人选，但是这个人当前无法review，那么我们至少应该“@”或者“邮件抄送”该reviewer。\nIn-Person Reviews # 如果是结对编程的话，A写的代码B应该有能力进行代码review，那么直接找B进行review就可以了。\n也可以进行现场评审（In-Person Reviews），一般是开发者介绍本次CL的主要内容、逻辑，其他reviewer对代码中年可能的问题、疑惑进行提问，本次CL的开发者进行解答，这种方式来发现CL中的问题也是常见的一种方式。较大型、急速上线的项目，这种方式团队内部用的还是比较多的。\nHow to Do a Code Review # 这里总计了一些Code review的建议，主要包括如下一些方面：\n The Standard of Code Review What to Look For In a Code Review Navigating a CL in Review Speed of Code Reviews How to Write Code Review Comments Handling Pushback in Code Reviews  The Standard of Code Review # 代码review的主要目的就是为了保证代码质量、产品质量，另外Google的大部分代码都是内部公开的，一个统一的大仓库，通过代码review的方式来保证未来Google代码仓库的质量，Google设计的代码review工具以及一系列的review规范也都是为了这个目的。\n为了实现这个目标，某些方面需要做一些权衡和取舍。\n首先，开发者必须能够持续优化。如果开发者从来不对代码做优化，那么最终代码仓库一定会烂掉。如果一个reviewer进行代码review时很难快速投入，如不知道做了哪些变更，那么代码reviewer也会变得很沮丧。这样就不利于整体代码质量的提高。\n另外，代码reviewer有责任维护CL中涉及到的修改的质量，要保证代码质量不会出现下降，时间久了也不至于烂尾。有的时候，某些团队可能由于时间有限、赶项目，代码质量就可能会出现一定的下降。\n还有，代码reviewer对自己review过的代码拥有owner权限，并要为代码后续出现的问题承担责任。通过这种方式来进一步强化代码质量、一致性、可维护性。\n基于上述考虑，Google制定了如下规定来作为Code review的内部标准：\n In general, reviewers should favor approving a CL once it is in a state where it definitely improves the overall code health of the system being worked on, even if the CL isn’t perfect.\n一般，reviewers对CL进行review的时候，达到approved的条件是，CL本身可能不是完美的，但是它至少应保证不会导致系统整体代码质量的下降。\n 当然，也有一些限制，例如，如果一个CL添加了一个新特性，reviewer目前不想将其添加到系统中，尽管这个CL设计良好、编码良好，reviewer可能也会拒绝掉。\n值得一提的是，没有所谓的perfect code，只有better code。\n 代码reviewers应该要求开发者对CL中每一行代码进行精雕细琢，然后再予以通过，这个要求并不过分。 或者，代码reviewers需要权衡下他们建议的“精雕细琢”的必要性和重要性。代码reviewers应该追求代码的持续优化，不能一味地追求完美。对于提升系统可维护性、可读性、可理解性的代码CL，reviewers应该尽快给出答复，不能因为一味追求完美主义将其搁置几天或者几周。  Mentoring # Code review对于教授开发者一些新的东西，如编程语言、框架、软件设计原则等是非常重要的手段。进行代码review的时候添加一些comments有助于帮助开发者之间分享、学习一些新东西。分享知识也是持续改进代码质量的重要一环。\n需要注意的是，如果comments内容是纯教育性的、分享性的，不是我们前面提到的强制性的必须应该做出优化的，那么最好在comments内容里面添加前缀“Nit (Not Important)”，这样的评论表示当前CL中不一定非要做出对应的优化、修改，只是一个建议、分享。\nPrinciples #  技术本身、数据至上，以及一些个人偏好 代码风格的重要性，力求代码风格的一致，如果没有明确的代码风格，就用之前作者的风格 业内的代码风格、个人偏好，需要在二者之间适当平衡，reviewer也应该在代码风格上注意 如果没有明确的一些规定，reviewer可以要求CL作者遵循当前代码库中的一些惯用的做法  上述各条，均以不降低系统整体代码质量为度量标准。\nResolving Conflicts # 如果在代码review中出现了冲突的意见、观点，首先，开发者、reviewer应尽可能基于之前的代码、现在CL的代码达成一个共识，如果仍然达不成共识，或者很困难，最好能进行面对面沟通，或者将当前CL升级一下，供更多的人员进行讨论。可以考虑将技术Leader、项目经理拉进来一起讨论下。\n这种面对面的方式比单纯地通过comments进行讨论要高效、友好地多，如果条件不允许只能通过comments方式进行，那么对于讨论的结果，应进行适当的总结，给出一个结论，方便之后的开发者能够了解之前的讨论结果。\n目标就是，不要因为代码reviewer和CL作者之间达不成一致，就长时间将CL搁置。\nWhat to Look For In a Code Review # 结合前面提到的一些Code review标准，将Code review中应该关注的点进一步细化，主要以下内容。\nDesign # Code review过程中最重要的事情就是看CL的整体设计是否合理，如CL中涉及到的各个部分的代码之间的接口、交互、衔接是否合理，是业务代码修改还是库的修改，和系统整体的集成是否合理，现在这个时间点添加这个新特性是否合理等等。\nFunctionality # CL的功能是否符合开发者预期，开发者期望的这部分修改是否对用户友好，这里的用户包括产品用户（实际使用产品的人员）和开发者（将来可能使用这部分代码的人员，如CL修改的库代码）。\n一般，我们希望开发者发起Code review之前，能够对CL进行充分的测试确保功能是符合预期的。但作为reviewer，还是要检查下边界条件的处理是否到位，比如并发中的data race问题，确保代码中不存在“可能”的bug。\nreviewer有条件的话，也可以亲自验证下CL，比如CL是面向用户的产品（如UI改变），单纯看代码不能直觉地感受到做的调整，reviewer可以亲自patch这部分代码、编译构建、安装之后来体验下具体的改变。如果不是特别方便的话，也可以找相应的开发者提供一个demo演示下CL中涉及的变化。\n另一个非常重要的点是，要检查CL中是否存在某种类型的并发问题，如deadlocks、race conditions等。这些问题也不是运行一下代码就能发现的，往往需要reviewer来细致地考虑下相关的操作，才能判定是否有引入该类问题。\nComplexity # CL是否过于复杂，这个需要对CL中的不同层次的内容进行逐一检查，如每行代码是否过于复杂，函数实现是否过于复杂，类实现是否过于复杂等。“过于复杂”意味着，不能被其他开发者快速吸收、理解。也有个笑话，开发者在调用、修改自己编写的代码的时候容易引入引入bug。这些都说明了复杂性的问题所在。\n过度设计也是Complexity中的一种，开发人员可能对当前需要解决的问题进行了解决，但是在此基础上进行了过度的、不必要的延伸。reviewers需要小心判断，识别出一个CL中是否存在过度设计的问题。reviewers应鼓励开发人员解决当前已经存在的、明确的问题，避免开发人员做些主观上认为未来可能需要的某些功能。\nTests # CL中应该包含必要的单元测试、集成测试等必要的测试用例，除非这个CL是为了紧急解决线上问题，这种情况下未能及时添加可以原谅。\n确保CL中包含的测试用例是正确的、有意义的、有效的，不要为了写测试用例而写测试用例，测试用例是为了辅助验证我们的代码是否符合预期的，因此几乎任何时候，确保测试用例有效都是至关重要的，测试用例也是代码维护工作的一部分。\nNaming # 命名（变量名、函数名、类名等等）是否合理，一个好的名字应该长度适中，又能够清晰地表达其代表什么。\nComments # 开发者是否提供了清晰、易于理解的英文注释。\n提供的注释是否是必要的，注释不是笔记，注释应该用来解释某段代码为什么存在，不需要解释这段代码要干什么，这样的注释才有意义。如果不提供该注释将无法理解该代码，请考虑一下设计、编码实现复杂度等是否有问题，是否可以简化。也有一些例外情况，如正则表达式或者复杂的算法，提供注释注明其作用是有价值的。\n当前CL之前的注释，也需要检查一下，可能当前CL解决了一个问题，对应的某个TODO可以删除了。\n注：这里的注释不同于类注释、模块注释、函数注释，这些注释需要表明其存在的目的、功能、如何使用、有什么行为或副作用。\nStyle # 代码风格问题，Google也提供了一些代码规范，这里的规范涵盖了多种编程语言的规范，请确认CL遵循此规范。\n如果某些地方没有明确的代码规范指引，而你有觉得开发者这种写法不太好，你想提出点建议的话，review的时候请在意见里面加个前缀“Nit:”，Not Import Pick，以表明这是个非强制性的建议。不要因为个人偏好问题，阻塞CL的代码review过程。\nCL里面不要既做代码逻辑修改，又做大范围格式化的操作，这可能让review、merge、rollback等变得复杂，如果确实有必要做这样的调整，请提供两个CL。第一个用来格式化，第二个在此基础上再进行代码逻辑的修改。反过来也可以，但是不要一次做两件“变动巨大”的事情。\nDocumentation # 如果一个CL改变了用户build、test、interact with、release code的方式，请同步检查下文档是否也要更新，包含READMEs、g3doc pages以及其他一些生成的reference docs。如果CL删除了或者废弃了某些代码，考虑下是否对应的文档内容也有需要删除的。\n如果发现缺少某些文档内容，请联系开发者补齐。\nEvery Line # 检查review任务中你分配的每一行代码。对于某些自动化生成的数据文件、代码文件（如*.pb.go）、大型数据结构，你可以快速扫过去，但是如果是开发者自己写的class、function、block of code，这种不能扫一下就过去了，需要仔细检查。\n开发者自己写的代码，也有重要的、不重要的之分，某些代码片段需要更仔细地review，比如某些分支判断逻辑，reviewer需要培养这方面的识别重要代码路径的能力。如果目前没有这种识别关键路径的能力，也至少应该确保你看懂了这些代码。\n如果review过程中，你发现某些代码实在是费解，严重拖慢了review进度，这种情况下不要犹豫，直接联系代码作者来解释它是干什么的、能否简化实现，然后再review。在Google雇佣了很多优秀的开发者，如果某位看不懂，那么其他人可能也看不懂，随着业务需求变更，将来新加入的开发者更可能看不懂。在Tencent以及其他公司，这种情况也是一样的，reviewer应该直接联系代码作者来解释、优化代码实现，某种意义上这也是为提升整体代码质量做贡献了。\n如果你理解了代码逻辑，但是对于某些部分你拿不准，请邀请另一位资历更深的reviewer来review，特别是对于那些安全、并发、可用、国际化等方面复杂的问题。\nContext # review过程中查看CL相关代码上文是有帮助的。代码review的时候，代码review工具只会显示几行修改的代码，但是前后与之相关的代码却可能大范围折叠。有时，你不得不查看整个文件内容来确保CL是有意义的。再比如，有时review工具只显示了4行代码，但是这四行代码位于一个几十上百行的方法中，如果你查看了CL的上下文，就会意识到这个函数的实现需要适当拆分成几个小的函数。\n将整个系统的代码作为Context来判定CL代码质量也是有必要的，如果这个CL中的代码质量低于系统整体代码的质量，请不要接受这样的代码，这回导致整体代码质量的下降。\nGood Things # 如果CL中有比较好的做法，请告诉开发者，特别是对于你的修改建议开发者很好地完成的时候。代码review通常是聚焦于可能的错误，但是这个过程也给了我们鼓励、学习good practices的机会。Mentoring机制，我们Tencent也有，去鼓励新人如何做的更好，比告诉他们哪里错了，更有价值。\nSummary # 简单总结下，Code review的时候也确保如下几点：\n 代码是否设计良好 功能对于代码的使用者而言更友好 UI的改变是有意义的 并发处理是安全的 不进行过度设计，没有演变到那种不必要的复杂 没有去实现一些将来可能需要但是现在不需要的东西 提供了有效的测试用例，包括单元测试等 测试是有用的，测试是经过精心设计的，不要写一堆没用的测试 命名选择都是合理的，如变量名、函数名等 注释是有价值的、有用的，注释解释了why而不是what，当然也有例外 文档中对代码变更也进行了合理的补充 代码遵循制定好的代码规范  确保逐行review分配的代码（代码生成工具生成的可以快速浏览），当然你可以合理分配review时间对部分代码进行重点review，但请确保你看懂了每行代码。注意code context，确保提升整体代码质量，对于review过程中发现的good practices适当鼓励开发者。\nNavigating a CL in Review # 现在我们知道了What to look for，如果review涉及到多个文件，如何最高效地进行review呢？\n review之前，查看CL的整体表述，确认是否有意义 首先，看CL中最有价值的部分，整体设计是否良好 然后，再根据合理顺序看CL中剩余的部分  Step One: Take a broad view of the change # 查看CL描述，先理解CL是做了什么工作，这个CL是否有意义。如果reviewer觉得这个修改没有意义，并决定拒绝该CL的时候，请选择合适的措辞向开发者解释清楚。\n例如，reviewer：“哇看上去你做了很多工作，非常感谢，但是我们未来方向是要移除你这里修改的FooWidget组件，如果你有时间，可以帮忙重构下BarWidget组件吗？”\n通能过这种方式，reviewer既向developer or contributor表明了立场、态度，也不失礼貌，保持礼貌是重要的，特别是对于开源项目，即便是你不认同贡献者的CL，也至少应看到他尝试进行付出。保持礼貌的review、讨论、沟通有助于维护开源协同的氛围。\n如果你收到了不少CLs，但是这些都不是你想要的，可能就需要从更高角度出发来解决这个问题，比如完善下Contributing文档，告知开发者项目需要什么，哪些方面鼓励优先解决等等。\nStep Two: Examine the main parts of the CL # 找到CL涉及的最主要修改部分，优先进行review。CL中逻辑的变动可能主要集中在少数几个文件中，找到这些changes优先进行review，这有助于聚焦修改的主要部分，加速整体的review进度。如果CL涉及代码太多，很难识别哪部分是主要部分，那可以先问下开发者哪部分是主要修改，或者让开发者把当前这次CL拆分成多个CLs，然后再发起review。\n如果在review CL主要部分的时候，发现设计上明显存在不合理的地方，reviewer应该立即发送review comments给开发者，其他的代码可以不用review了，继续review纯粹是浪费时间。因为既然存在明显的设计问题，等开发者修改之后，剩余的要review的代码可能根本不存在了。\n发现有明显设计问题，立即发送design review comments，还有两个好处：\n 开发者可能会发起一个CL之后，会立即在这个CL的基础上继续进行其他的修改工作。如果前面的CL存在明显的设计问题，那么很可能会将这里的问题继续带入到后续的CL中，并继续发起新的Code review。所以尽快发送设计上的review意见一定程度上会避免、减少这类问题的发生，避免后续review重复解决同一类问题。 主要的设计变更，比其他小修小补，花费的时间更多，每个开发者排需求都是有deadline的，及时发送review意见有助于在deadline之前，让开发者仍然由机会对设计做出调整，以保证项目进度，又能兼顾整体代码质量。  Step Three: Look through the rest of the CL in an appropriate sequence # 一旦确定CL中主体代码没有明显的设计问题，就可以按照合理的顺序review剩下的部分，比如按照逻辑处理的顺序来review，reviewer可以根据逻辑处理中的过程、分支判断来review相关的代码，从而确保不遗漏每一行变更。\n通常review完CL的主体部分之后，review剩下的部分就相对简单多了。有时阅读测试用例对于review代码也是有帮助的，比如，通过测试用例你能清楚地知道各个函数参数的含义，如何使用该函数，当然你可以联想到一些边界条件，带着这些问题去review CL主体代码效果也不错。\nSpeed of Code Reviews # Why Should Code Reviews Be Fast? # Google对于Speed的追求，更期望的是团队能够更快更好地生产一个好的产品的速度，而不是个人开发者编码的速度，当然这并不是说开发者的开发效率就不重要。团队整体推进的速度是非常重要的，它关系到产品迭代的进度，关系到团队的氛围，关系到每个开发者的感受，设置是他们的日常生活。\n在追求速度的过程中，Code review的速度扮演者一个比较重要的角色。如果review速度很慢，可能会发生：\n  团队整体推进的速度被严重拖慢。\n如果reviewer没有对CL进行快速的响应，可能就会耽误CL作者的其他后续工作，因为它可能要在此CL上开展其他工作。如果这里的修改是解决一个线上bug、重要的features等，如果搁置换一个几天、周、月，这种项目速度是不可接受的。\n  开发者开始抗议或者不重视Code review。\n如果一个reviewer每隔几天才回复一次CL review意见，但是每次review意见都要求CL作者进行修改，对于CL作者这种体验是非常沮丧的，开发者可能会抱怨这样的reviewer，为什么这么review个代码这么苛刻。但是如果reviewer能够快速、及时地回复review意见，这种抱怨往往会消失了。大家在意的不是CL有没有问题，而是reviewer的怠慢、反应迟缓。所以reviewer要尽快回复review意见。\n  代码整体健康度会受到影响。\n如果review速度过慢，就会给开发人员、reviewer人员持续带来更多的压力，这意味着开发人员会提交更多不符合标准的CLs，reviewer人员需要回复、拒绝、解释、二次review的工作做会更多。进一步，也会降低开发者代码清理、重构、优化的积极性，导致整体代码质量下降。\n  How Fast Should Code Reviews Be? # 如果当前没有对专注度要求很高的任务的话，reviewer应该立即或者稍后进行review。\n一个工作日，这个是Google内部指定的上限，在Code review发起的一个工作日内，reviewer必须进行review。\n如果一个CL进行review之后，提出了修改意见，并且CL作者进行了修改，那一天之内可能要进行多轮review，尽量不要拖到第二天，跨天就不太好了。\nSpeed vs. Interruption # 对于review速度和个人工作专注度之间需要做个权衡，如果正在进行某些对专注度要求比较高的任务，如正在写代码，这个时候还是不要让自己的工作中断。研究表明开发者被中断之后，再回到之前的工作，是需要比较长的时间的，为了追求review进度反而拖慢了个体开发进度，反过来也可能会拖慢项目整体进度。\n所以建议在当前没有对专注度要求很高的时间进行review，比如你写完一段关键代码之后，或者吃完午饭、午休之后，等等，这个就要根据自己情况选择了。\nFast Responses # 我们谈论Code review的速度，其实强调的是CL的review意见的回复速度，而不是CL最终通过的速度。当然，如果review意见回复速度够快，CL作者修改也会更快，CL整体通过速度也会快些。\n尽管CL整体通过耗时可能比较久，维持比较快的CL review意见还是很重要，CL作者不会因为review过慢而沮丧。\n如果你现在太忙了，实在没有时间对CL进行完整的review，你也可以发送一个回复信息让开发者知道你大约会在什么时间段进行review，好让他心理有底，他也可以继续安排自己接下来的工作。或者你也可以邀请其他合适的review代你进行review。这里并不是说你就要立即放下手里的编码工作立即去回复，你可以选个稍微可以放松难点的时间去回复，比如你刚刚写完一段关键代码，大脑可以稍微休息几分钟的时候。\nreviewers花费足够的时间进行review是很重要的，时间充足，reviewer回复“LGTM”才更有底气。CL中每个意见的回复还是要能快就快。\nCross-Time-Zone Reviews # 如果review涉及到多地的、不同时区的开发人员，reviewer最好能在CL作者还在公司工作的时候给到回复review意见，如果开发人员已经下班回家了，尽量在隔日开发人员上班前完成review，尽量不要中断、delay他人的工作。\nLGTM With Comments # 为了加速Code review整体通过进度，有些场景下，即便开发者没有完全完成reviewer的修改意见，reviewer可能也会给通过“LGTM” or “Approval”，这几种情况下是允许的：\n reviewer有信心，开发者会在之后不久完成提及的修改意见 剩余的还未修改之处，是些微小的修改，可以后面改，或者不一定要当前开发者来修改  reviewer针对上述两个情况，在LGTM的时候应该注明是哪种情况。LGTM With Comments对于多地、跨时区的开发者而言，是比较有价值的，因为reviewer最终给LGTM或者Approval可能要隔一天的时间呢，这个时候会比较久，如果是LGTM的同时附带上reviewer对开发者的一点小期望，开发者后续再修改、优化，也是可以的，毕竟这两种情况都是无伤大雅的事情。\nLarge CLs # 如果开发者提交的一个CL非常大，以至于你不知道要从哪开始看起，这个时候可以要求开发者将这个大的CL拆分成几个小的CL，CL2 build on CL1， CL3 build on CL2\u0026hellip; 然后再进行review。这对reviewer而言是比较有帮助的，对开发者而言可能需要额外的一点工作。\n如果换一个CL无法拆分成多个小的CLs，并且你眼下也没有时间去快速地完成整体的review，可以考虑看下整体设计，回复下对整体设计的意见，开发者可以先进行适当的优化。reviewer的目标，就是激励开发者持续地对代码质量进行提升。\nCode Review Improvements Over Time # 持续地遵循上述的Code review流程，坚持下去，就会发现自己在review代码的时候，处理地越来越好、越来越快。开发者也能够学习到符合代码质量要求的代码应该是什么样子的，后续提交的CLs也会变得越来越合理，花费的reviewer的时间也会越来越少。reviewer也会更快地进行review意见回复，对于整体review进度delay的时间也会越来越少。\n但是，但是，但是……不要为了“快”而降低Code review标准或者破坏整体代码的质量。\nEmergencies # 也存在一些非常紧急的情况，这些情况下CLs可能必须非常快地通过review过程，这种情况下review时的要求可以适当放低。在应用这里的Emergencies指引之前，先了解下What is An Emergency?，区分什么是紧急场景，什么不是，避免滥用。\nHow to Write Code Review Comments # Summary #  保持友好 解释原因 权衡“给出可能的方案并指出问题”、“给出可能的方案让开发者自主决策”两种方式 鼓励开发者简化代码，鼓励开发者添加注释，而不是解释问题有多复杂  Courtesy # review别人代码的时候，保持礼貌、尊重是非常重要的，至少不要让开发者、贡献者感觉到明显的不适，如何做到这点呢？一个比较好的办法就是在写review意见的时候，只对code本身进行评论，不要对开发者本人进行评论，对于某些人称代词是否有必要出现，也需要斟酌下。\n举个例子：\nBad：“%#@!$ 这个场景下多线程并不会有太大的性能提升，为什么你要用多线程？”\nGood：“多线程并发增加了复杂性，但%#@!$ 场景下收到的性能提升并不明显，最好用单线程模型代替多线程。”\nExplain Why # 上面展示的这个good example向开发者解释了review不通过的原因，同时也解释了为什么多线程模型在这个场景 %#@!$ 下并不好，开发者就会从中学习，意识到自己的方案存在的问题，并进行优化。\n当然不需要每次review的时候都进行大篇幅的解释，但是适当的解释是有必要的。\nGiving Guidance # 修复一个CL中存在的问题，是CL开发者的责任，而不是reviewer的责任。没有要求reviewer要代替开发者给出一个完整的详细设计，或者亲自帮助其写代码。\n但是这并不意味着reviewer可以无视，不去主动帮助他人，特别是在CL开发者确实get不到reviewer的点或者束手无策的时候，reviewer可以选择性的指出问题，并给出一个直接的指引，或者给出几个备选方案让开发者去对比、选择，或者给一个简单的设计让开发者去进一步细化、完善，或者可以写一个简单的demo以供开发者参考。这也是Mentoring精神的一种发扬吧，这可以帮助开发者学习，使得Code review变得更加简单、正向、积极。最终达成的结果也往往更好。\nCode review追求的第一目标就是尽可能高质量的CL，第二目标就是提升开发者的技能，这样后续的开发、Code review工作都会变得越来越简单、积极，技术传承也更加温和、有效。\nAccepting Explanations # 如果reviewer有段代码不太懂，并请开发者进行解释的话，最终的结果往往是开发者需要重写这段不清晰的代码。偶尔，代码中添加注释也是一种类似于“解释”的回应，但是如果代码实现太过复杂，该重写还是要重写，不能用注释解释，套逃脱应该简化、重构的工作。\n代码review工具中填写的解释（对reviewer疑问的解释）对将来阅读代码的人的帮助微乎其微，这个很好理解，阅读工程代码时，别人很少会去翻之前的review意见，而要等到翻review意见的时候，意味着这里的代码可能已经需要重写了。\n通过注释的方式来解释代码的行为，往往只在很少的几种场景下有效，比如在review一个自己不太熟悉的领域的代码时，如果有注释reviewer更容易理解，但是对于熟知这个领域的人而言，这些注释可能都是些常识，是多余的。\nHandling Pushback in Code Reviews # Handling Pushback in Code Reviews # 有时候，reviewer的意见开发者会“怼”回来，可能是开发者不同意reviewer的建议，也可能是抱怨reviewer过于苛刻。\nWho is Right? # 当开发者不同意reviewer的建议时，reviewer应该停下来先想想他们的想法是不是对的。通常，开发者可能比reviewer更加熟悉相关代码，可能在某些方面他们理解的比reviewer更清楚。那么，他们的争论是否有意义?从代码健康度的角度考虑，他们的修改是否有意义？如果确实有意义，让他们知道他们是对的，并且解决掉issue。\n然而，开发者也不都是对的。有些情况下，reviewer应该更透彻地解释为什么他们给出的建议时正确的。一个好的解释应该能展示出开发者角度的理解、reviewer角度的理解，以及reviewer的修改建议为什么是有价值的。\n某些情况下，reviewer可能要与开发者进行好几轮的沟通、解释，不管怎么样，保持礼貌的态度，应该让开发者感觉到“你一直在倾听他们在说什么，你只是不同意他们的做法”。\nUpsetting Developers # reviewers有时会觉得自己一直坚持CL代码的优化，开发者本人会不会觉得有点沮丧。有时，开发者可能会，或者刚开始时，开发者可能会，但是当他们觉得reviewer的建议有效确实帮助他提升了代码质量的时候，他就不会觉得沮丧了。\n通常，只要在review的时候保持礼貌的沟通，开发者可能根本不会感觉到沮丧，这里的担心可能只是reviewer自己头脑中的一种直觉而已。\nCleaning it Up Later # 开发者针对reviewer的建议，有时会用这样的方式，“这次先review通过吧，我后面再优化下”，确实有些开发者会这么做，他们这么做的原因，无非是不想再经过一轮新的耗时的review过程。\nreviewer可能会给通过，有些开发者确实会在本次CL通过后，继续写一个新的CL来解决上次reviewer提到的问题，大部分是这样的。但是也有不少开发者事后就忘了这些，并没有提交新的CL cleanup之前遗留的问题。并不是说这些开发者就是不负责任，很可能是因为他们被其他工作填满了，时间被挤占了之后人就会失忆或者“选择性”失忆，最终慢慢地就忘了cleanup。\n因此，一个好的做法是，CL通过之后，reviewer应该立即通过开发者、督促开发者cleanup遗留的问题。\nGeneral Complaints About Strictness # 如果之前Code review都比较松，后面Code review比较严的话，开发者刚开始肯定不适应，他们可能会抱怨多起来，这个时候，提升下Code review的速度有助于减少大家的抱怨。\n对于一个团队而言，如果是Code review从松到严，大家抱怨的时间可能持续的比较久，几个月都有可能，但是最终开发者会看到严格执行Code review的好处，抗议声最高的开发者可能会变成最有力的支持者，只要他能感受到严格之上的价值。\nResolving Conflicts # 如果在review代码时遵循了上述Code review的建议，但是仍然遇到了一些和开发者之间难以解决的问题，请参考 前面的章节 The Standard of Code Review来浏览下相关的指引和原则，应该有助于解决遇到的问题或冲突。\nThe Change Author\u0026rsquo;s Guide # 从代码CL开发者的角度出发，介绍下Google内部积累的一些good practices。\nWriting Good CL Descriptions # CL描述用来记录做了什么改变、为什么做这个改变，它会作为VCS中的提交历史记录下来，之后可能会有更多的开发者阅读到这里的CL描述。\n将来，开发者也可能根据一些关键词来搜索这里的CL描述，如果CL相关的关键信息只记录在代码中，在CL描述中不能予以体现的话，那么别人定位你的CL就会异常困难。\nFirst Line #  需要对修改进行一个精炼的总结 描述应该是一个完整的句子 描述后跟一个空行  CL描述的首行应该对做的修改进行一个精炼的总结、概括，然后后面跟一个空行。大部分情况下，开发者查看、检索CL描述信息（log信息）是看的这些内容，所以CL描述的首行信息是至关重要的。\n通常，首行信息应该是一个完整的句子，例如，一个好的首行表述：\u0026quot;Delete the FizzBuzz RPC and replace it with the new system.\u0026quot;, 下面这个则是一个不好的示例：\u0026quot;Deleting the FizzBuzz RPC and replacing it with the new system.\u0026quot;\nBody is Informative # CL描述的剩余部分应该详细一点，可以包含对要解决问题的描述，以及为什么CL中的实现是比较好的或者是最优的方案。如果该方法有什么不足，也应该提一下。如果有一些bug编号、性能结果、设计文档之类的背景信息，也应该包含进来，方便后来者查看。\n即使CLs涉及到的改动不多，有必要的话，也需要在body部分描述下。\nBad CL Descriptions # “Fix bug”不是一个足够充分的CL描述，修的什么bug？为了修bug做了哪些修改？其他类似的不良CL表述包括：\n Fix build Add patch Moving code from A to B Add convennience functions kill weired URLs  上面这些是Google代码仓库中捞出来的真实CL描述，作者可能认为他们的描述比较清晰了，但是实际上这样的CL描述没有任何意义，完全没有起到CL描述应有的作用。\nGood CL Descriptions # 下面是一些比较好的CL描述示例。\nFunctionality change #  rpc: remove size limit on RPC server message freelist.\nServers like FizzBuzz have very large messages and would benefit from reuse. Make the freelist larger, and add a goroutine that frees the freelist entries slowly over time, so that idle servers eventually release all freelist entries.\n 这个CL描述的首行信息概述了做的修改，后面body部分又解释了为什么做这个修改，以及自己是怎么做的，有什么好处，还提供了实现相关的一些信息。\nRefactoring #  Construct a Task with a TimeKeeper to use its TimeStr and Now methods.\nAdd a Now method to Task, so the borglet() getter method can be removed (which was only used by OOMCandidate to call borglet’s Now method). This replaces the methods on Borglet that delegate to a TimeKeeper.\nAllowing Tasks to supply Now is a step toward eliminating the dependency on Borglet. Eventually, collaborators that depend on getting Now from the Task should be changed to use a TimeKeeper directly, but this has been an accommodation to refactoring in small steps.\nContinuing the long-range goal of refactoring the Borglet Hierarchy.\n 这个CL描述的首行信息指出了CL做了什么，相对于以前的实现做了哪些修改。body部分介绍了实现细节、CL的context，也指出了虽然这个方案没有那么理想，但是也指出了未来的改进方向。同时也解释了为什么需要做这里的重构。\nSmall CL that needs some context #  Create a Python3 build rule for status.py.\nThis allows consumers who are already using this as in Python3 to depend on a rule that is next to the original status build rule instead of somewhere in their own tree. It encourages new consumers to use Python3 if they can, instead of Python2, and significantly simplifies some automated build file refactoring tools being worked on currently.\n 这个CL的首行信息描述了做了什么，body部分解释了为什么要做这里的修改，并且给reviewer提供了充分的context（领域相关知识）信息。\nReview the description before submitting the CL # CLs在review过程中可能会再次修改，再次review的时候，CL描述信息可能会与最新的修改不符，在提交CL之前review一下描述信息是否与代码修改仍然一致，这个是有必要的。\nSmall CLs # Why Write Small CLs? # Small, simple CLs有这样的好处：\n **Review更快。**如果提交一个大的CL，reviewer可能要专门抽30分钟才能完成review过程，这个可能比较困难，但是如果CL拆的都比较小，reviewer每次抽个5分钟完成一次review，多次review，回比前者更快完成。 **Review更充分。**如果提交一个大的CL，改动东西很多情况下，reviewer需要游走在更多代码中，心理上会倾向于关注更加重要的代码，难免某些代码会被降权，review可能不那么充分。如果CL比较小，很容易就能看懂，也不需要来回翻代码，review的会更充分。 **不易引入bug。**因为每次改动都比较小，CL作者不容易引入bug，reviewer也更容易发现bug。 **如果被拒绝，可减少无谓的工作。**CL可能会被拒绝，如果一次做大量修改，被拒绝的话，CL中的所有修改动作可能都要重新来过，不管是合理的、不合理的，相当于做了更多无谓的工作。 **更易merge。**如果提交一个大的CL，涉及修改比较多，冲突可能也会比较多，那么解决冲突花费的时间会更多，不容易merge。小的CL在merge的时候就简单多了。 **设计不至于出大问题。**如果CL涉及修改比较少，那么很容易把修改优化到最佳，对于reviewer的建议也更容易完成，如果CL比较大，reviewer意见、建议比较多，就很难一次完成了。 **后续工作不至于阻塞在review上。**CL作者可能希望基于这个CL做更多工作，如果CL比较小那么review可以很快通过，但是如果CL比较大，那么CL作者将不得不等待更多的时间 **merge后有问题，更易回退。**merge之后有时候也会意识到merge的代码有问题，如果要回退的话，小的CL更容易回退，如果CL很大，哇，涉及到的代码多，回退就比较痛苦、复杂。  reviewer不会因为某个CL很大，我不review了，然后给你拒绝掉，通常他们会表现的比较礼貌，告知你将这个大的CL拆分成几个小的CLs。当你已经完成了一个CL时，再将其拆分成几个小的CLs，其实这里的工作量可能不少的，当然和reviewer争辩为什么要求拆分成多个CLs花的时间可能也会很长。最省力的做法就是，一开始就坚持写小的CL，多次CLs。\nWhat is Small? # 一般，CL一般建议的大小：\n CL包含最少内容，一次只做一件事情，比如新增feature，CL只包含feature的一个部分，而不是所有的部分。也可以与reviewer进行沟通，确定合适的CL大小，不同的reviewer习惯也不一样，对reviewer而言，CL太大太小都是负担。我们的建议是CL一次只做一件事情。 reviewer需要看到的任何东西都已经包含在了CL中，这些信息可能位于CL代码中、描述中、已经存在的代码中、reviewer之前review过的CL中。 当把这个CL合入之后，系统仍然能够工作的很好。 CL也不小到隐晦难懂的程度。比如新增了一个API，应该同时包含API的使用示例，这样reviewer能够更好地理解API的使用方式，这样也可以避免引入没有用的API。  也没有硬性的规定指明CL多大才算大，一般100行代码是一个比较合理的CL尺寸，1000行有点太大了，主要还是要看reviewer的态度。CL中涉及到的文件的数量也是CL大小的一个度量维度，如果CL中包含了一个文件，文件修改了200行代码，这个感觉还是OK的，但是如果同样是修改了200行代码但是散落在50个文件中，那CL有点太大了。\n体会一下，我们写代码的时候是有了解对应的背景的，但是reviewer可能了解比较少或者完全不知道。一个可接受的CL大小，对reviewer而言是很重要的。如果你不确定reviewer期待的CL大小是怎样的，那就尽量写一个比自己预期中的合理大小更小点的，很少有reviewer会嫌弃CL太小。\nWhen are Large CLs OK? # 下面这些场景，如果CL比较大也还OK，不算坏：\n 删除整个文件的内容，或者删除大段内容，可以看做是一行修改，因为它不会花费reviewer太多时间review。 有时一个大的CL是有自动化refactor工具生成的，而我们信任这些工具，reviewer的工作就是检查并确认这里的修改没问题。这样的CL很大，但是对reviewer而言仍然不会花太多时间。  Splitting by Files # 另一种拆分大的CL的方式是，将修改的文件进行适当分组，并将不同分组的文件做成CL并提交不同的reviewer进行review。\n例如：你发送了一个CL修改，同时包含了对protocol buffer文件的修改，另一个CL是业务代码修改但是使用了这里修改后的protocol buffer文件。首先我们要先提交proto文件对应的CL，然后再提交引用它的业务代码CL。虽然提交的时候有先后，但是review过程可以是同时进行的。这么做的同时，最好也知会下reviewer另一个CL中的存在以及与当前CL的关系。\nSeparate Out Refactorings # 一般将CL中的重构之类的工作和其中包含的feature开发、bug修改区分开是比较好的做法。例如，将CL中包含的移动、重命名类名之类的操作单独放在一个CL中，这样reviewer能够更容易理解每个CL中的修改。\n不过，一个小的变量名修改的也可以包含在另一个feature change或者bugfix相关的CL中。如果一个CL中包含了一些重构之类的修改，让开发者、reviewer判断这部分重构相关的修改是否对当前CL来说太大了，太大了会让review变得更加困难，开发者应该据此作出一些调整。\nKeep related test code in the same CL # 避免将相关的测试代码单独放在另一个CL中。测试代码验证代码修改的正确性，所以和代码修改相关的测试代码，应该放置在一个相同的CL中，尽管测试代码增加了修改代码的行数。\n不相关的测试代码修改，可以放到另一个CL中，类似于 Separate Out Refactorings， 包含：\n 验证已经存在的、提交过的代码，当前只是新增、完善测试代码； 重构测试代码（如引入了新的helper函数） 引入了更大的测试框架（如集成测试）  Don\u0026rsquo;t Break the Build # 如果多个CLs互相依赖，需要找一个办法来确保这几个CL每提交一个，系统整体仍然能够正常工作，不能因为提交了一个CL就导致系统构建失败或者工作不正常。比如，可以考虑将几个依赖的小的CL修改合并。\nCan\u0026rsquo;t Make it Small Enough # 有时会遇到这种情况，看上去CL会无可避免地变得很大，其实，这种情况几乎是不存在的。只要开发者尝试练习去写小的CLs多次code review，习惯了之后开发者总能找到合适的办法来将一个大的修改分解成几个小的修改。\n在开发者动手进行一个很大的CL之前，开发者应考虑下是否先来一次只包含重构（只修改设计，不变动功能）的CL然后在此基础上再做修改，这样是不是会更好一点。如果一个CL中既包含重构代码，又包含逻辑变动代码，这个修改就很重。多数情况下，先来一次只包含重构的CL会为后续的修改扫清障碍，后续的修改会更clean。\n如果因为某些客观原因，无法做到上述这些，那就先提前向reviewer说明情况，让reviewer做好心理准备，准备好review一个大的CL，review可能花费比较长的时间，请务必小心引入bug、务必添加好测试用例并通过测试，reviewer在这么大的CL中review的效果可能会大打折扣。\nHow to Handle Reviewer Comments # 当开发者针对CL发起Code review时，reviewer一般会通过comments写一些意见、建议，那开发者该如何处理reviewer comments呢？\nDon\u0026rsquo;t Take it Personally # Code review的初衷是为了维护代码的质量、产品的质量，当一个reviewer对开发者代码写了些意见时，开发者应该将其看作是来自reviewer的帮助，不要将其看做是对开发者个人、个人能力的人身攻击。\n有时，reviewers会变得很沮丧，并且可能将沮丧、不满情绪在评论中体现出来。一个好的reviewer是不会这么做的，但是作为一个好的开发者，应该做好面对这种情况的准备。开发者可以反问下自己，当reviewer的评论到底是在描述一个什么代码问题，然后尝试去修改就可以了。\n**对于别人的review意见，永远不要用愤怒去回应！**这违反了Code review或者开源协同的精神，并且这样的负面信息可能会永远留存在review历史中。如果你心里面很愤怒，并且想愤怒地做出回应，请尝试离开你的电脑、键盘，或者先干点别的，直到你内心平静下来再礼貌地做出回应。\n一般，如果reviewer回复的评审意见不是建设性的，或者没有礼貌，可以试着向reviewer私下里诉说下你的看法。如果能面对面交流最好，不能就尝试发一封私人邮件，向reviewer说下你不喜欢他的这种review方式，你期望他能做出好的改变。如果对方还是拒绝做出改变，那就不要浪费时间了，升级一下知会你的项目经理。\nFix the Code # 如果reviewer说他看不懂你的代码中的某个部分，首先你应该尝试简化这里的代码实现。如果代码已经无法再精简实现，那就在代码中添加合适的注释来解释。如果添加额外的注释没有什么太大意义，只有这种情况下，可以尝试通过code review工具添加一些comments来解释。\n如果某个reviewer看不懂这里的代码，那么将来可能其他开发者阅读代码的时候，也是看不懂的。但是通过code review工具添加comments进行解释，对将来的开发者是没有帮助的，但是精简代码实现、代码添加注释是有帮助的。\n"}),a.add({id:393,href:"/tags/float/",title:"float",description:"",content:""}),a.add({id:394,href:"/blog/2019-05-23-%E5%88%AB%E7%94%A8float%E4%BD%9C%E4%B8%BAmap%E7%9A%84key/",title:"别用float作为map的key",description:"使用float作为map的key，非常容易留坑",content:"遇到个好玩的问题，使用float类型作为go map的key，示例代码如下： 其实就是浮点数精度的问题，随手翻了下go map的源码，备忘下。这里要涉及到几个问题：\n  golang如何针对key计算hash的，阅读源码后发现就是有个key *_type，h.key.alg.hash(key)来计算得到hash，问题就出在这里的hash计算过程，可以阅读下alg.go，里面针对不同的key类型定义了计算hash的方法：\nvar algarray = [alg_max]typeAlg{ alg_NOEQ: {nil, nil}, alg_MEM0: {memhash0, memequal0}, alg_MEM8: {memhash8, memequal8}, alg_MEM16: {memhash16, memequal16}, alg_MEM32: {memhash32, memequal32}, alg_MEM64: {memhash64, memequal64}, alg_MEM128: {memhash128, memequal128}, alg_STRING: {strhash, strequal}, alg_INTER: {interhash, interequal}, alg_NILINTER: {nilinterhash, nilinterequal}, alg_FLOAT32: {f32hash, f32equal}, alg_FLOAT64: {f64hash, f64equal}, alg_CPLX64: {c64hash, c64equal}, alg_CPLX128: {c128hash, c128equal}, }  float64就是要使用f64hash这个方法来计算hash值。\n  golang里面利用计算得到的hash值的后5位作为hmap的bucket index，先定位到bucket，然后再根据hash的前8位作为与bucket内部\u0026lt;k,v\u0026gt; entries的hash进行比较找到对应的entry。\n  下面我们看下f64hash的实现：\nfunc f64hash(p unsafe.Pointer, h uintptr) uintptr { f := *(*float64)(p) switch { case f == 0: return c1 * (c0 ^ h) // +0, -0 case f != f: return c1 * (c0 ^ h ^ uintptr(fastrand())) // any kind of NaN default: return memhash(p, h, 8) } }  f==0或者f!=f是两种极端情况，不考虑直接看f64hash里面调用方法memhash(p, h, 8)，memhash实现，省略无关代码：\nfunc memhash(p unsafe.Pointer, seed, s uintptr) uintptr { if (GOARCH == \u0026quot;amd64\u0026quot; || GOARCH == \u0026quot;arm64\u0026quot;) \u0026amp;\u0026amp; GOOS != \u0026quot;nacl\u0026quot; \u0026amp;\u0026amp; useAeshash { return aeshash(p, seed, s) } h := uint64(seed + s*hashkey[0]) tail: switch { case s == 0: case s \u0026lt; 4: ... case s \u0026lt;= 8: h ^= uint64(readUnaligned32(p)) h ^= uint64(readUnaligned32(add(p, s-4))) \u0026lt;\u0026lt; 32 h = rotl_31(h*m1) * m2 case s \u0026lt;= 16: ... case s \u0026lt;= 32: ... default: ... } h ^= h \u0026gt;\u0026gt; 29 h *= m3 h ^= h \u0026gt;\u0026gt; 32 return uintptr(h) }  现在可以看到它其实是把浮点数的内存表示（IEEE 754 double encoding format) 当做一个普通的数字来计算的，先读4字节计算，再读剩下的4字节计算，再做其他计算。\n两个浮点数最终hash值相同，其实就是浮点数精度导致的，写代码的时候，看上去我们定义了两个完全不同的浮点数，但是内存中按照IEEE 754 double的规范进行内存表示的时候，很可能就是一样的。\n上面是IEEE 754 double的格式，1位符号位，11位阶码，52位尾数，像NaN、Inf的定义也都跟这些不同的组成部分有关。这里只关心尾数部分就好了，只有52位，当超过52 bits可以表示的精度之后，代码里面定义的数值就被截断了。\n示例代码中，看似数值上有一两位末尾数字不同的浮点数，内存表示是相同的，hash值也相同，就会出现map赋值时值被覆盖的问题。\n浮点数的更多细节如符号位、阶码（bias）、尾数，以及NaN、Inf的定义等，可以参考wikipedia了解更多细节。\n"}),a.add({id:395,href:"/tags/%E6%B3%A2%E9%9F%B3737/",title:"波音737",description:"",content:""}),a.add({id:396,href:"/blog/2019-03-17-%E6%B3%A2%E9%9F%B3737%E5%9D%A0%E6%AF%81%E4%BA%8B%E6%95%85%E7%9A%84%E8%83%8C%E5%90%8E/",title:"波音737坠毁事故的背后",description:"波音，从诞生到现在，一直都是全球空客市场的强有力竞争者，然而，就是这么一家顶尖的企业，却接连制造了惨不忍睹的杀人事故。波音737 Max，在人们心目中已然成为了一款“杀人”机器，几百个家庭就此陷入无尽的悲伤，即便能获取高额赔偿，又有什么用呢？忍不住内心的怒火，忍不住要追问，究竟是谁导致了这一系列事故的发生！\n波音737 Max机型事故回顾\n2019年3月10日，一架载有149名乘客和8位机组人员的波音737 Max，从埃色俄比亚的亚的斯亚贝巴机场起飞后大约6分钟坠毁。飞机起飞后，垂直速度一直不稳定，机长也非常警觉地发现了问题请求返航，但是他没想到的是，他驾驶的是一架杀人机器，而不是受飞行员控制的飞机，在其几次与飞控系统组件MCAS（强制压低机头软件系统）抢夺控制权后还是失败了，157条生命就此销声匿迹。\n波音737 Max机型事故原因\n然而，在全世界人民关注的目光中，在全世界人民表达哀悼、同情的同时，波音公司却丑陋地站在了利益的一边，而完全将责任、道义抛之不顾。波音发表声明称，对737 Max的技术足够自信，并表示如果埃航空公司有需要，会协助其恢复机队人员的新人。完全没有自我审视的意识，这是极其不应该的！因为这款机型737 Max在此之前，已经出现了两次坠机事故，且坠机过程中表现的异常极为相似！这完全是基于波音自身利益考量，宁可为了多卖出几架飞机，也不愿意为本次事故承担责任、赔偿、安抚遇难者家属！\n2018年10月29日，印度尼西亚狮航737 Max 8起飞13分钟后坠入爪哇海，而同年12月14日，挪威航空公司737 Max 8起飞后也被迫做出紧急迫降。可笑的是，狮航事故发生之后波音才马后炮似的向狮航提供了一份操作手册，用来解决错误的驾驶舱读数问题，从这个时候开始，MCAS（强制压低机头软件系统）才被揭露于飞行员面前，而波音对这个软件的隐瞒更加凸显了在利益面前波音的胡作非为。\nMCAS（强制压低机头软件系统）是在设计737 Max机型时引入的，由于为了更好地与欧洲空中客车航空公司进行竞争，波音在原来的737机型上进行了改进，一是为了载客量，一是为了省油，飞机后端进行了窄体设计，并增高了起落架高度，以方便在飞机前端挂装性能更好的发动机。但这一设计存在一个致命缺陷，飞机起飞时容易仰角过大导致飞机坠毁。为此波音引入了软件系统MCAS，在飞机速度比较低时（如起飞过程中）强制压低机头。\n波音处于自身利益的考虑，并没有在一开始就外界告知有这样的一个软件系统存在，而且更加糟糕的是，该软件系统对飞机的操控权限，比飞行员还要高，即便飞行员很有经验，意识到出现了危险，如飞机压低机头坠向地面，飞行员也没办法将机头拉高回归至正常飞行状态，飞机也就会表现出垂直高度不稳定，直至坠毁。\n波音在整个过程中极端不负责任，已经发生了多起事故，自己不去召回并修正设计上的缺陷，反而继续签订了更多的订单，全球订单量5500+，已出货350+。被全世界各国相继停飞、拒单，简直是活该！谁愿意花重金买一个机器回来“残害”自己的人民呢？\n美国政府在当中扮演的角色\n在埃航坠机事故发生后，先前发生过类似事故的狮航高度敏感，整件事情也愈演愈烈，被完整地曝光于世界面前。各国相继停飞737 Max机型，并出现了大量拒单的情况。美国政府最终也不得不宣布停飞，还有跟屁虫加拿大！波音公司对事故的处理过程，让我们寒心，美国政府在世界人民面前表现出来的冷漠也让我们坚信，美国并没有那么美，在人民面前，还是本国政府最关心自己的人民。\n最后希望我国商飞能挺起民族的脊梁，自古以来“领袖”从来都是有能者居之，希望商飞能在不远的将来，在航空市场上傲视群雄。",content:"波音，从诞生到现在，一直都是全球空客市场的强有力竞争者，然而，就是这么一家顶尖的企业，却接连制造了惨不忍睹的杀人事故。波音737 Max，在人们心目中已然成为了一款“杀人”机器，几百个家庭就此陷入无尽的悲伤，即便能获取高额赔偿，又有什么用呢？忍不住内心的怒火，忍不住要追问，究竟是谁导致了这一系列事故的发生！\n波音737 Max机型事故回顾\n2019年3月10日，一架载有149名乘客和8位机组人员的波音737 Max，从埃色俄比亚的亚的斯亚贝巴机场起飞后大约6分钟坠毁。飞机起飞后，垂直速度一直不稳定，机长也非常警觉地发现了问题请求返航，但是他没想到的是，他驾驶的是一架杀人机器，而不是受飞行员控制的飞机，在其几次与飞控系统组件MCAS（强制压低机头软件系统）抢夺控制权后还是失败了，157条生命就此销声匿迹。\n波音737 Max机型事故原因\n然而，在全世界人民关注的目光中，在全世界人民表达哀悼、同情的同时，波音公司却丑陋地站在了利益的一边，而完全将责任、道义抛之不顾。波音发表声明称，对737 Max的技术足够自信，并表示如果埃航空公司有需要，会协助其恢复机队人员的新人。完全没有自我审视的意识，这是极其不应该的！因为这款机型737 Max在此之前，已经出现了两次坠机事故，且坠机过程中表现的异常极为相似！这完全是基于波音自身利益考量，宁可为了多卖出几架飞机，也不愿意为本次事故承担责任、赔偿、安抚遇难者家属！\n2018年10月29日，印度尼西亚狮航737 Max 8起飞13分钟后坠入爪哇海，而同年12月14日，挪威航空公司737 Max 8起飞后也被迫做出紧急迫降。可笑的是，狮航事故发生之后波音才马后炮似的向狮航提供了一份操作手册，用来解决错误的驾驶舱读数问题，从这个时候开始，MCAS（强制压低机头软件系统）才被揭露于飞行员面前，而波音对这个软件的隐瞒更加凸显了在利益面前波音的胡作非为。\nMCAS（强制压低机头软件系统）是在设计737 Max机型时引入的，由于为了更好地与欧洲空中客车航空公司进行竞争，波音在原来的737机型上进行了改进，一是为了载客量，一是为了省油，飞机后端进行了窄体设计，并增高了起落架高度，以方便在飞机前端挂装性能更好的发动机。但这一设计存在一个致命缺陷，飞机起飞时容易仰角过大导致飞机坠毁。为此波音引入了软件系统MCAS，在飞机速度比较低时（如起飞过程中）强制压低机头。\n波音处于自身利益的考虑，并没有在一开始就外界告知有这样的一个软件系统存在，而且更加糟糕的是，该软件系统对飞机的操控权限，比飞行员还要高，即便飞行员很有经验，意识到出现了危险，如飞机压低机头坠向地面，飞行员也没办法将机头拉高回归至正常飞行状态，飞机也就会表现出垂直高度不稳定，直至坠毁。\n波音在整个过程中极端不负责任，已经发生了多起事故，自己不去召回并修正设计上的缺陷，反而继续签订了更多的订单，全球订单量5500+，已出货350+。被全世界各国相继停飞、拒单，简直是活该！谁愿意花重金买一个机器回来“残害”自己的人民呢？\n美国政府在当中扮演的角色\n在埃航坠机事故发生后，先前发生过类似事故的狮航高度敏感，整件事情也愈演愈烈，被完整地曝光于世界面前。各国相继停飞737 Max机型，并出现了大量拒单的情况。美国政府最终也不得不宣布停飞，还有跟屁虫加拿大！波音公司对事故的处理过程，让我们寒心，美国政府在世界人民面前表现出来的冷漠也让我们坚信，美国并没有那么美，在人民面前，还是本国政府最关心自己的人民。\n最后希望我国商飞能挺起民族的脊梁，自古以来“领袖”从来都是有能者居之，希望商飞能在不远的将来，在航空市场上傲视群雄。\n"}),a.add({id:397,href:"/tags/%E7%A7%91%E6%8A%80/",title:"科技",description:"",content:""}),a.add({id:398,href:"/tags/calendar/",title:"calendar",description:"",content:""}),a.add({id:399,href:"/tags/macos/",title:"macOS",description:"",content:""}),a.add({id:400,href:"/blog/2019-02-23-macos%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88todolist/",title:"macOS实现高效todolist",description:"macOS的日历其实做的挺方便的，可以纵览所有的日程安排，还可以生成提醒，如果能很方便的通过alfred添加待办事项到日历中，岂不是妙哉？那么如何写一个alfred workflow来实现此功能呢？",content:" img { width: 680px; padding-bottom: 1rem; }  高效 “Todo” # Apple设备上有一个非常好的效率工具“Calendar.app（日历）”，在日历中可以添加待办事项，并且支持按天、周、月、年视图进行快速浏览，是工作、学习的好帮手。工作中，自己的想法、他人的反馈、问题要点等需要快速记录下来，每次唤醒日历进行手动添加还是有点低效，能不能实现更高效地“Todo”呢？ 想象一下手动打开日历，定位到今天，滑动到下方找一个合适的时间点添加待办事项，输入描述信息再回到原来的工作，麻烦！结合Alfred+AppleScript编写了一个Workflow，现在方便多了，实现了如下效果。快捷键快速呼出Alfred交互输入框，然后键入“todo 待办事项描述信息，然后键入“回车”，此时就可以自动添加一条新的待办事项到日历中，是不是方便多了！ 执行上述操作之后：\n 若日历程序没启动，添加成功会启动日历并提到前台，展示当前添加的待办事项； 若日历程序已启动，添加成功不会再将日历提到前台，在通知中心发一条添加成功的通知；   我想要的高效“Todo”是近似这样的，目前能基本满足我的要求。这里的实现方式是，打开Alfred-\u0026gt;Preferences-\u0026gt;Workflows，新建一个Blank Flow，然后配置如下： workflow中todo节点获取输入的待办事项，并将输入信息通过脚本参数的形式传递给后续的osacript进行处理，该脚本负责添加待办事项到日历。workflow中两个节点的配置如下所示： 完整的脚本代码如下：\non run set theQuery to \u0026quot;{query}\u0026quot; -------------------------------------------------------------------------- -- 今天的开始、结束，用于筛选今天的事件列表 set todayStart to (current date) set time of todayStart to 0 copy todayStart to todayEnd set time of todayEnd to 86400 -- 待添加事件的开始、结束时间，我喜欢按照时间顺序追加的添加方式 copy todayStart to todoStart set minutes of todoStart to 0 set seconds of todoStart to 0 -- 启动Calendar筛选今天内添加的todo事件列表 tell application \u0026quot;Calendar\u0026quot; tell calendar \u0026quot;todo\u0026quot; -- 遍历todo事件列表找到最后添加的事件 set allEvents to (every event where its start date is greater than or equal to todayStart and end date is less than todayEnd) repeat with e in allEvents set t to start date of e if t ≥ todoStart then copy t to todoStart end if end repeat -- 继续追加新todo事件 if hours of todoStart is equal to 0 then set hours of todoStart to 8 else set todoStart to todoStart + (1 * hours) end if set todoEnd to todoStart + (1 * hours) make new event with properties {summary:theQuery, start date:todoStart, end date:todoEnd} end tell -- 启动Calendar显示 if not running then run delay 0.25 activate else set msg to \u0026quot;添加成功：\u0026quot; \u0026amp; theQuery display notification msg end if end tell ---------------------------------------------------------------------- return theQuery end run  AppleScript不太熟，东拼西凑攒出来这个小工具，还攒了一些其他小工具\u0026hellip; 希望对大家有帮助！\n"}),a.add({id:401,href:"/tags/todo/",title:"todo",description:"",content:""}),a.add({id:402,href:"/tags/todolist/",title:"todolist",description:"",content:""}),a.add({id:403,href:"/tags/eof/",title:"eof",description:"",content:""}),a.add({id:404,href:"/tags/fin/",title:"fin",description:"",content:""}),a.add({id:405,href:"/tags/half-closed/",title:"half closed",description:"",content:""}),a.add({id:406,href:"/tags/tcp/",title:"tcp",description:"",content:""}),a.add({id:407,href:"/blog/2018-12-20-write-closed-tcpconn/",title:"write closed tcpconn",description:"TCP连接管理向来是高性能服务器开发所需要掌握的内容，服务器通常会检测客户端连接是否空闲，为了节省资源会在连接空闲一段时间后主动清理空闲的连接。在TCPServer主动close连接时，会发生什么呢？与其是TCPClient使用了连接池时会发生什么呢？在维护RPC框架过程中遇到不少类似的反馈，优化框架之余，于是有此文来解释下。",content:"问题背景 # tcp client: write to a half-closed tcp connection!\n这里探讨一下这个问题，Write to a closed tcp connection的问题。在深入讨论这些问题之前，首先要了解tcp state diagram，为此文末特地附上了经典的tcp状态转换图。\n我们的场景是这样的，tcp server已经启动，然后tcp client主动建立连接请求，连接成功建立后，tcp client并不立即发送数据而是等待一段时间之后才会发送数据（这种在client端的tcp连接池中非常常见），tcp server端为了防止连接被滥用，会每隔30s钟检查一下tcp连接是否空闲，如果两次检查都发现tcp连接空闲则主动将连接关闭。\n原因分析 # 此时tcp server端会调用conn.Close()方法，该方法最终会导致传输层发送tcp FIN包给对端，tcp client这边的机器收到FIN包后会回一个ACK，然后呢？tcp client不会继续发FIN包给tcp server吗？不会！仅此而已。问题就是这么诞生的，什么问题呢，tcp client仍然可以发包，但是n, err := tcpconn.Write(...)这个时候并不会检测到err != nil，只有等到n, err := tcpconn.Read(...)的时候才会发现err为io.EOF，这个时候才能判断得知tcp server已经把连接销毁了。\n从RPC框架角度而言，希望为client维护的tcp连接池是高效可用的，所以想对上述情况下的客户端连接进行检测，避免连接池中存在上述被tcp server关闭的连接。\n再简单总结下tcp server、tcp client两端的不同处理逻辑：\n  从tcp server的视角来看，\ntcp server调用的conn.Close()，对应的是系统调用close，tcp server端认为它已经彻底关闭这个连接了！\n  从tcp client的视角来看，\n这个连接是我主动建立的，我还没有给你发送FIN包发起关闭序列呢，因此这个连接仍然是可以使用的。tcp client认为tcp server只是关闭了写端，没有关闭读端，因此tcp client仍然是可写的，并且socket被设置成了nonblocking，conn.Write()仍然是成功返回的，返回的err == nil。但是当真正传输层执行数据发送的时候，tcp server端认为这个连接已销毁，因此会返回RST！这个时候上层go代码因为已经返回已经感知不到写的时候存在错误，这个RST会将tcp client端的socket标记为已关闭。下次tcpconn.Read的时候就能感知到io.EOF错误了，如果再发起一次tcpconn.Write也可以立即返回错误。\n  关于close与shutdown # 假如tcp server调用的不是conn.Close()，而是conn.CloseWrite()，这个对应的系统调用shutdown(SHUT_WR)，那只表示写端关闭，这个时候tcp client发送数据过去，tcp server端返回的就不是RST了，而是正常的ACK，因为tcp server端也认为这个连接只是关闭了写端。\n本质上来说，内核在处理系统调用close、shutdown的时候对套接字的处理是有差异的，close的时候对fd引用计数减1，如果引用计数为0了，那么就直接销毁套接字，认为对应的连接不再有效了（所以收到tcp client发来的数据会回RST）。但是shutdown(SHUT_WR)的时候，不会减引用计数，内核并不会直接销毁套接字，虽然也会发FIN包，但也只是认为这个连接是写端关闭、读端正常，所以还可以正常接收数据！\nRPC框架关心这个问题 # 问题出现：\n对于上层应用程序来说，conn.Write()返回nil就认为是返回成功了，但是实际包并没有发送出去，所以后续等待接收响应的时候conn.Read()就会返回io.EOF错误显示对端连接已关闭。\n假如满足下面几个条件，那么tcp client请求tcp server失败的概率就会很大了！\n tcp client请求tcp server是通过连接池来实现的； tcp client请求tcp server并不频繁的情况下； tcp server又存在主动销毁空闲连接的时候；  如何避免这里的问题呢？在go里面tcp client中的连接池实现，可以定期地检查tcp连接是否有效，实现方法就是conn.Read()一下，如果返回的是io.EOF错误则表示连接已关闭，执行conn.Close()并重新获取连接即可。conn.Write()是不会返回这个io.EOF错误的，会想上面的场景来看，tcp client端现在还认为tcp连接是有效的呢，所以conn.Write()是肯定不会返回io.EOF错误的。\ngo网络库为什么这么设计 # 这里再延伸一下，为什么go里面conn.Write()的时候不去检查一下连接是否已关闭呢？比如显示地conn.Read()一下？这要考虑tcp的设计宗旨了，tcp本身就是支持全双工模式的，tcp连接的任意一端都有权利关闭读端或者写端，所以从go api设计者的角度来看，conn.Write()就只是单纯地认为我这段tcpconn的写端未关闭即可！对端是否写关闭根本无需考虑，而从更通用的角度来考虑，有些服务端逻辑上可以只收请求不回响应。为了通用性，conn.Write()不可能去检查对端是否写关闭！\n那从一个网络框架设计或者一个应用程序开发者角度来说呢？我们关心一个请求是否能拿到对应的响应！如果我们要避免这个问题，以c、c++为例，我们完全可以借助epoll_wait来轮询是否有EPOLLRDHUP事件就绪，有就认为连接关闭销毁就可以了，或者轮询EPOLLIN事件就绪接着read(fd, buf, 0)返回0==EOF就可以了。但是每次write之前都这样检查一下，还是很蛋疼的，要陷入多次系统调用，而且即便在epoll_wait返回之后、write之前这段时间内，仍然对端可能会发一个FIN包过来！所以说这样也并不能一劳永逸地解决问题！\n如何更好地解决问题 # 再回到问题的起点，其实我们不想关心这些网络细节，我们只想关心，我发送出去的请求是否得到了可靠的响应！\n失败重试！失败后重试一次、两次已经成为了大家写代码时候的常态，但是一个网络框架，是否应该减少这种负担？可能上面我们讨论的情形在线上环境中并不多见，但它确实是一个已知的问题！如果请求量比较大，连接不会因为空闲被关掉，那么这个问题出现的概率很少，但是假如请求量确实不大，这个问题就会凸显出来了。\n连接池连接活性检测优化 # 为此我们想了一种改良的方法来检测是否出现了对端关闭连接的情况，思路是这样的，因为不方便再去poll类似的EPOLLIN、EPOLLRDHUP事件，这里再从连接池获取空闲连接时，借助系统调用n, err := syscall.Read(fd, buf)直接去非阻塞读一下，如果返回err == nil 并且 n==0，那么就可以判定对端连接写关闭（refer to poll/fd_unix.go:145~180, fd.eofError(n, err)）。\nfunc (nci *NConnItem) readClosed(conn net.Conn) bool { var ( readClosed bool rawConn syscall.RawConn err error ) f := func(fd uintptr) bool { one := []byte{0} n, e := syscall.Read(int(fd), one) if e != nil \u0026amp;\u0026amp; e != syscall.EAGAIN { // connection broken, close it readClosed = true } if e == nil \u0026amp;\u0026amp; n == 0 { // peer half-close connection, refer to poll/fd_unix.go:145~180, fd.eofError(n, err) readClosed = true } // only detect whether peer half-close connection, don't block to wait read-ready. return true } switch conn.(type) { case *net.TCPConn: tcpconn, _ := conn.(*net.TCPConn) rawConn, err = tcpconn.SyscallConn() case *net.UnixConn: unixconn, _ := conn.(*net.UnixConn) rawConn, err = unixconn.SyscallConn() default: return false } err = rawConn.Read(f) if err != nil { return true } if readClosed { return true } return false }  如果我们利用tcp全双工能力，实现client、server的全双工通信模式，一边发送多个请求、一边接收多个响应，假如接收响应的时候发现io.EOF，那么后续的发送直接返回失败就行了。但是假如网络抖动的情况下，这种全双工通信模式容易出现失败激增的毛刺。\n这种情境下，貌似UDP会是更好的选择，当然也要考虑服务端是否支持UDP。\n在RPC级别支持重试对冲 # 还有一种更优雅的做法，在RPC框架设计上支持interceptor扩展，包括前置interceptor、后置interceptor，比如grpc框架的interceptor是以递归的形式形成了一个链条，前面interceptor的完成驱动后一个执行，最后的interceptor驱动真正的RPC方法执行。\n我们可以在interceptor层面上支持重试对冲，比如本文提及的失败重试，我们可以不用过度优化tcp连接池连接活性检测，而是将关注重点放在如何更好地解决失败后的重试上：\n 立即重试 重试次数 指数退避 etc  RPC方法中，在tcpconn.Write发送请求成功后，继续通过tcpconn.Read读取响应，此时读取到io.EOF则返回错误，此时驱动该RPC方法执行的重试interceptor会根据配置的重试策略进行重试，从而更优雅地解决这里write closed tcpconn的问题。\n附录 # 1 测试tcp server close空闲连接\nmac下测试方法：\n 服务端：nc -kl 5555 -w 2 客户端：go run client.go，client.go代码如附录3。  linux下测试方法：\n 服务端：nc -kl 5555 -i 2（与mac下参数不同，效果相同，都是2s后close连接） 客户端：go run client.go，client.go代码如附录3。  2 测试tcp server shutdown(SHUT_WR)空闲连接\n服务端：go run server.go\n3 测试代码server.go+client.go\nfile server.go\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; ) func init() { log.SetFlags(log.LstdFlags | log.Lshortfile) } func main() { listener, err := net.Listen(\u0026quot;tcp4\u0026quot;, \u0026quot;:5555\u0026quot;) if err != nil { fmt.Println(err) os.Exit(1) } for { conn, err := listener.Accept() if err != nil { fmt.Println(err) continue } go func() { go func() { time.Sleep(time.Second * time.Duration(2)) tcpconn, ok := conn.(*net.TCPConn) if !ok { fmt.Println(err) return } tcpconn.CloseWrite() }() time.Sleep(time.Second * time.Duration(4)) buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil { fmt.Println(err) return } fmt.Println(\u0026quot;read bytes size:%v, data:%s\u0026quot;, n, string(buf)) }() } }  file: client.go\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;net\u0026quot; \u0026quot;time\u0026quot; ) func main() { strEcho := \u0026quot;Halo\u0026quot; servAddr := \u0026quot;localhost:5555\u0026quot; tcpAddr, err := net.ResolveTCPAddr(\u0026quot;tcp\u0026quot;, servAddr) if err != nil { println(\u0026quot;ResolveTCPAddr failed:\u0026quot;, err.Error()) os.Exit(1) } println(\u0026quot;connection established\u0026quot;) conn, err := net.DialTCP(\u0026quot;tcp\u0026quot;, nil, tcpAddr) if err != nil { println(\u0026quot;Dial failed:\u0026quot;, err.Error()) os.Exit(1) } // sleep until connection closed time.Sleep(3000 * time.Millisecond) // first write to half-closed connection time.Sleep(3000 * time.Millisecond) _, err = conn.Write([]byte(strEcho)) if err != nil { println(\u0026quot;Write to server failed:\u0026quot;, err.Error()) os.Exit(1) } println(\u0026quot;writen to server = \u0026quot;, strEcho) // second write to half-closed connection time.Sleep(3000 * time.Millisecond) strEcho = \u0026quot;Halo2\u0026quot; _, err = conn.Write([]byte(strEcho)) if err != nil { println(\u0026quot;Write to server failed:\u0026quot;, err.Error()) os.Exit(1) } println(\u0026quot;writen to server = \u0026quot;, strEcho) conn.Close() }  4 c++版的tcp client\n一个类似上述go版tcp client的c++版实现，看看要多少代码吧。\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;sys/un.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #define MAX_EVENTS 1024 static int processClient(); int main(int argc, char *argv[]) { int fd; int ret; struct sockaddr_in addr = { 0 }; struct in_addr x; inet_aton(\u0026quot;127.0.0.1\u0026quot;, \u0026amp;x); addr.sin_family = AF_INET; addr.sin_addr = x; addr.sin_port = htons(5555); int set = 30; int i = 0; int fdFlag = 0; int epollFd = epoll_create(MAX_EVENTS); if (epollFd == -1) { printf(\u0026quot;epoll_create failed\\n\u0026quot;); return -1; } struct epoll_event ev; // epollÊ¼þ½ṹÌ struct epoll_event events[MAX_EVENTS]; // Ê¼þ¼à¶ÓÐ // connect to server fd = socket(AF_INET, SOCK_STREAM, 0); if (fd == -1) { printf(\u0026quot;error:%s\\n\u0026quot;, strerror(errno)); return -1; } // set timer is valid ? //setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, \u0026amp;set, sizeof(set)); // set socket non block? if ((fdFlag = fcntl(fd, F_GETFL, 0)) \u0026lt; 0) printf(\u0026quot;F_GETFL error\u0026quot;); fdFlag |= O_NONBLOCK; if (fcntl(fd, F_SETFL, fdFlag) \u0026lt; 0) printf(\u0026quot;F_SETFL error\u0026quot;); // connect to server ret = connect(fd, (struct sockaddr *)\u0026amp;addr, sizeof(addr)); if (ret == -1) { if (errno == EINPROGRESS) { printf(\u0026quot; connect error:%s\\n\u0026quot;, strerror(errno)); //return -1; } else { printf(\u0026quot; connect error:%s\\n\u0026quot;, strerror(errno)); return -1; } } // epoll watch socket EPOLLOUT ev.events = EPOLLOUT; ev.data.fd = fd; if (epoll_ctl(epollFd, EPOLL_CTL_ADD, fd, \u0026amp;ev) == -1) { printf(\u0026quot;epoll_ctl:server_sockfd register failed\u0026quot;); return -1; } int nfds; // check whether tcpconn established, howto? write-ready! while (1) { nfds = epoll_wait(epollFd, events, MAX_EVENTS, -1); if (nfds == -1) { printf(\u0026quot;start epoll_wait failed\u0026quot;); return -1; } if (nfds == 0) { continue; } if (events[0].events \u0026amp; EPOLLOUT) { printf(\u0026quot; connection is established\\n\u0026quot;); break; } } // sleep 3 seconds, before wakeup let the server close connection! // run `nc -kl 5555 -w 1` to start a tcp server. sleep(3); char sendbuf[512] = { 0 }; char recvbuf[5120] = { 0 }; int count = 0; // check whether epoll_wait can detect half-open tcpconn ev.events = EPOLLIN | EPOLLET | EPOLLRDHUP; ev.data.fd = fd; if (epoll_ctl(epollFd, EPOLL_CTL_MOD, fd, \u0026amp;ev) == -1) { printf(\u0026quot;epoll_ctl:server_sockfd register failed\\n\u0026quot;); return -1; } while (1) { nfds = epoll_wait(epollFd, events, MAX_EVENTS, -1); if (nfds == -1) { printf(\u0026quot;start epoll_wait failed\\n\u0026quot;); return -1; } if (nfds == 0) { printf(\u0026quot;epoll_wait: no events ready\\n\u0026quot;); continue; } int i = 0; for (i=0; i\u0026lt;nfds; i++) { /* if (events[i].events \u0026amp; EPOLLRDHUP) { printf(\u0026quot; epoll_wait: EPOLLRDHUP, peer close connection\\n\u0026quot;); close(events[i].data.fd); return -1; } */ if (events[i].events \u0026amp; EPOLLIN) { printf(\u0026quot; epoll_wait: read-ready\\n\u0026quot;); memset(recvbuf, 0, sizeof(recvbuf)); count = recv(events[i].data.fd, recvbuf, sizeof(recvbuf), 0); printf(\u0026quot;read bytes size:%d, data:%s\\n\u0026quot;, count, recvbuf); if (count == -1) { /* If errno == EAGAIN, that means we have read all data. So go back to the main loop. */ if (errno != EAGAIN) { printf(\u0026quot;read error\\n\u0026quot;); close(events[i].data.fd); return -1; } } else if (count == 0) { /* End of file. The remote has closed the connection. */ close(events[i].data.fd); printf(\u0026quot;tcpconn is closed by peer\\n\u0026quot;); return -1; } } } } // when write-ready, send data to server // when read-ready, read data from server int token_length = 5; char *token_str = \u0026quot;12345\u0026quot;; char *ch = \u0026quot;yumgkevin\u0026quot;; char socketId[10] = { 0 }; while (1) { nfds = epoll_wait(epollFd, events, MAX_EVENTS, -1); if (nfds == -1) { printf(\u0026quot;start epoll_wait failed\u0026quot;); return -1; } for (i = 0; i \u0026lt; nfds; i++) { /* if ((events[i].events \u0026amp; EPOLLERR) || (events[i].events \u0026amp; EPOLLHUP) || (!(events[i].events \u0026amp; EPOLLIN)) || (!(events[i].events \u0026amp; EPOLLOUT)) ) { printf(\u0026quot;enter 1\u0026quot;); fprintf (stderr, \u0026quot;epoll error\\n\u0026quot;); close (events[i].data.fd); continue; } */ if (events[i].events \u0026amp; EPOLLOUT) { printf(\u0026quot;write-ready, send data to server\\n\u0026quot;); memset(sendbuf, 0, sizeof(sendbuf)); memset(socketId, 0, sizeof(socketId)); strcpy(sendbuf, token_str); strcat(sendbuf, \u0026quot;hellow, world\u0026quot;); strcat(sendbuf, ch); sprintf(socketId, \u0026quot;%d\u0026quot;, events[i].data.fd); strcat(sendbuf, socketId); strcat(sendbuf, \u0026quot;\\r\\n\u0026quot;); ret = send(events[i].data.fd, sendbuf, strlen(sendbuf), 0); if (ret == -1) { if (errno != EAGAIN) { printf(\u0026quot;error:%s\\n\u0026quot;, strerror(errno)); close(events[i].data.fd); } continue; } printf(\u0026quot;send buf content is %s, size is %d\\n\u0026quot;, sendbuf, ret); // add revelant socket read event ev.data.fd = events[i].data.fd; ev.events = EPOLLIN | EPOLLET; epoll_ctl(epollFd, EPOLL_CTL_MOD, events[i].data.fd, \u0026amp;ev); } else if (events[i].events \u0026amp; EPOLLIN) { printf(\u0026quot;read-ready, read data from server\\n\u0026quot;); count = 0; memset(recvbuf, 0, sizeof(recvbuf)); count = recv(events[i].data.fd, recvbuf, sizeof(recvbuf), 0); if (count == -1) { /* If errno == EAGAIN, that means we have read all data. So go back to the main loop. */ if (errno != EAGAIN) { printf(\u0026quot;read error\\n\u0026quot;); close(events[i].data.fd); } continue; } else if (count == 0) { /* End of file. The remote has closed the connection. */ close(events[i].data.fd); continue; } printf(\u0026quot;receive data is:%s\u0026quot;, recvbuf); // add revelant socket write event ev.data.fd = events[i].data.fd; ev.events = EPOLLOUT; epoll_ctl(epollFd, EPOLL_CTL_MOD, events[i].data.fd, \u0026amp;ev); } } } // close socket close(fd); return 0; }  5 tcp状态转换图 "}),a.add({id:408,href:"/tags/dapper/",title:"dapper",description:"",content:""}),a.add({id:409,href:"/tags/opentracing/",title:"opentracing",description:"",content:""}),a.add({id:410,href:"/tags/tracing/",title:"tracing",description:"",content:""}),a.add({id:411,href:"/blog/2018-10-03-%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%88%86%E5%B8%83%E5%BC%8F%E8%B7%9F%E8%B8%AA%E7%B3%BB%E7%BB%9Fdapper/",title:"大规模分布式跟踪系统dapper",description:"dapper，大规模分布式跟踪系统，现在有不少开源实现是基于dapper的核心思想来设计的，如zipkin、jaeger、lightstep、appdash等。了解dapper的工作原理，也方便理解zipkin、jaeger这几个常用的分布式跟踪实现，使用opentracing来集成不同的backend的时候也不至于一头雾水。所以又把dapper的论文阅读了几遍，梳理了下其核心思想。网上也有不少这篇论文的中文译文，但是翻译的蹩脚，理解起来很晦涩，所以还是自己梳理下方便以后查阅，也希望对大家有帮助。",content:" img { width: 680px; padding-bottom: 1rem; }  dapper，大规模分布式跟踪系统，现在有不少开源实现是基于dapper的核心思想来设计的，如zipkin、jaeger、lightstep、appdash等。了解dapper的工作原理，也方便理解zipkin、jaeger这几个常用的分布式跟踪实现，使用opentracing来集成不同的backend的时候也不至于一头雾水。所以又把dapper的论文阅读了几遍，梳理了下其核心思想。网上也有不少这篇论文的中文译文，但是翻译的蹩脚，理解起来很晦涩，所以还是自己梳理下方便以后查阅，也希望对大家有帮助。\n[TOC]\n分布式跟踪 # 分布式跟踪系统，能够将系统中各个服务之间的调用关系（依赖关系）、请求耗时情况、请求方式（串行、并发）等等清晰地展示出来，对于快速定位系统调用链路中出现的异常问题有着非常重要的作用。不管是普通程序开发人员，还是web、rpc或其他框架开发人员，都希望能集成分布式跟踪的能力。\ndapper简介 # 现在主流的分布式跟踪系统，基本都是基于google发布的论文dapper来进行后续开发的，论文中详细解释了dapper实现分布式跟踪的原理，点击查看 dapper：大规模分布式跟踪系统。\n设计初衷 # 分布式跟踪系统，其职责就是“无所不在的部署，持续的监控”，这也是真正提现分布式跟踪能力的前提。“无所不在的部署”，这非常重要，因为即使一小部分监控没有监控到，也会让人对整个跟踪结果产生质疑。“持续的监控”，监控应该是7x24小时不间断的，对于某些小概率事件或者难以重现的事件，如果不能做到持续监控就有可能遗漏这部分异常。\n设计目标 # dapper将“无所不在的部署，持续的监控”作为大的方向，由此也确定了具体的3个设计目标。\n 低开销，跟踪系统对在线服务的影响应该足够小 有些服务是经过开发人员高度优化后的，如果跟踪系统引入的overhead比较大，就可能抵消掉之前优化工作带来的性能提升，开发人员不得不关停分布式跟踪能力。 应用透明，分布式跟踪的实现细节应该对应用开发人员透明 应用开发人员是不需要知道有分布式跟踪这回事的，如果一个跟踪系统不能屏蔽这些细节、需要开发者配合的话，这种业务侵入性很强的跟踪系统是难以大力推广的，也就难以实现“无所不在的部署”这样的能力，也就不能实现全面细致的跟踪。 可伸缩性，面对未来N年服务集群扩大的趋势，都应该能对其进行有力地把控 分布式跟踪系统不只是跟踪几个、十几个服务，它在设计上要能够对大规模的服务集群进行全局把控。这就要求其必须保持足够的可伸缩性，在服务集群扩大之后要通过某种形式的“扩容”来保证分布式跟踪能力的线性增长。这里的扩容可能是机器级别的、网络级别的、存储级别的。  这3个设计目标之外，还有另一个设计目标，“信息处理的速度要足够快”。如果信息处理的速度足够快，就可以近乎实时地发现线上系统中存在的异常问题。\n实现方案 # dapper在许多高阶的设计思想上吸取了pinpoint和Magpie的研究成果，但在分布式跟踪领域中，dapper的实现包含了许多新的贡献。例如为了保证对业务服务的“低开销”，引入了“采样率”。dapper的另一个特征就是在足够低的层级实现分布式跟踪，以对应用级透明。\n跟踪树 # dapper的分布式跟踪方案可以借助下图来一探究竟，其核心思想是从客户端（user）发起的请求一直到接入层服务A，再到后端服务B、C，再从C到D、E，整个请求处理链路可以借由一个树形结构来表示出来。可以通过将服务器上发生的每一次请求、响应作为一个记录收集起来，收集信息包括跟踪标识符（message identifier）和时间戳（timestamped events）。通过添加标注（annotation），依赖于应用程序或中间件明确地标记一个全局id，从而连接每一条收集的记录和用户发起的请求。显然这里需要代码植入，不过我们可以代码植入的范围收敛到框架层，保证对应用层透明。\n下面对dapper的设计思想进行更深入的了解，我们将先从上图中涉及到的几个关键概念开始。\n跟踪（trace） # 在dapper跟踪树结构中，树节点是整个架构的基本单元，而每一个节点是一个span，它又包含了对其他span的引用。节点之间的连线表示的是当前span与它的父span或者派生出的子span之间的关系。span在日志文件中的表示只是简单的记录请求开始时间、请求结束时间，span在整个树形结构中它们是相对独立的。\n)\n上图是一个分布式跟踪过程的示意图，图中说明了span在一个完整的跟踪过程中是什么样的，dapper记录了span的名称、span-id、父span-id，以重建一次跟踪过程中不同span之间的关系。如果一个span没有父span-id那么它是root span，也就是整个调用链的起始点。所有span都挂在一个特定的跟踪链上，也共用同一个跟踪id，即trace-id（图中未标出）。所有这些id（trace-id、span-id）都是全局唯一的64位整数表示。\n在一个典型的dapper跟踪中，我们希望为每一个rpc对应到一个单一的span上，而且每一个额外的组件层都对应到一个跟踪树型结构的层级。\n跨度（span） # 下图中给出了一个更加详细的dapper跟踪中span记录点的视图，其实每个span记录点都包含了两个不同的视角（client端RPC视角，server端RPC视角），图中也画出了rpc Helper.Call的client、server端视角，如client发送请求、server接收请求、server处理、server发送响应、client接收响应的过程。span的开始、结束时间，以及任何rpc的时间信息都可以通过dapper在rpc组件库中植入代码以记录下来。\n如果应用程序开发者希望在跟踪中增加自己的注释信息（业务数据），如图中的“foo”，这些信息也会和其他span一样记录下来。\n此外，任何一个span记录点都包括了来自rpc client、rpc server端的主机信息。每一个span记录点可以包含来自client、server两端的注释信息，使得span记录点能够记录请求方、响应方这两个主机的信息。另外由于记录的时间戳来自不同的主机，不同的主机上的时间可能存在一定的时间偏差（时钟漂移），必须考虑时间偏差带来的影响，因为它会影响到我们判断某个span的发生时间的先后顺序。我们可以基于这样的一个事实，就是rpc client发送一个请求之后server才可以收到，对于响应也是一样，server响应之后client才能收到响应，这样一来rpc server端的接收响应时间戳、发送响应时间戳就确定了一个上下限。\n植入点（instrumentation point） # dapper可以对应用开发者以近乎零侵入的成本对分布式控制路径进行跟踪，几乎完全依赖于少量通用组件库的改造，如在框架层对现有rpc代码进行改造，植入分布式跟踪相关的代码。\n如何记录跟踪上下文信息呢（trace-id、parent span-id、span-id）？不同的rpc框架可能基于不同的网络服务模型（同步、异步、多进程、多线程、协程）实现，需要考虑清楚如何保存这里的跟踪上下文，可以结合不同的编程语言提供的语言特性来辅助实现，如基于java多线程模型实现的rpc框架可能会考虑通过ThreadLocal来存储跟踪上下文信息，golang可以通过goroutine局部变量来寄存跟踪上下文信息，C++可以通过一个全局map结构来维护请求seq与跟踪上下文的映射关系等，这只是一种保存跟踪上下文信息的思路，具体的场景还需要具体分析。\n注释（annotation） # 下面是通过c++和java向跟踪中span记录点添加注释的方法：\n上述植入点可以帮助推导出复杂的分布式系统的跟踪细节，使得dapper可以在不改动应用代码的情境下就可以发挥其核心功能。然而，dapper还允许应用开发人员在跟踪的过程中添加额外的信息，以监控更高级别的系统行为，或帮助调试问题。\ndapper允许用户通过一个简单的api来定义时间戳的annotation，核心代码如上图所示，这些annotation可以添加任意内容，为了避免dapper使用者过分热衷于添加注释，dapper也添加了一些限制，即单个span有一个可配置的annotation数量上限。\n除了上图中展示的添加的文本annotation，dapper也支持添加key-value形式的annotation，提供给开发人员更强的跟踪能力。\n采样率（sampling） # 低开销是dapper的关键设计目标之一，如果这个工具一开始设计的时候其价值还未被充分认可，而又对性能有明显开销的话，其他开发人员、运维人员是肯定不愿意去应用、推广这个玩意的。况且，dapper希望能够让开发人员通过使用annotation的方式来增强跟踪能力，而又不用担心性能方面的开销。而在开发过程中也发现，某些类型的web服务性能对植入代码确实比较明显。因此dapper开发人员除了把dapper的收集工作进一步优化，使其对应用性能影响尽可能小之外，还引入了进一步控制性能开销的方法，那就是当遇到大量请求时只记录其中一小部分。我们在文章的后续部分会进一步描述采样率方案更多的细节。\n跟踪的收集 # 下图展示了dapper的跟踪的收集过程，大致可以分为图中1、2、3三个过程。\n 应用程序通过dapper api将span数据写入本地日志文件中 dapper守护进程和收集组件把这些日志信息从生产环境的日志文件中拉取出来 dapper守护进程和收集组件将拉取到的日志信息整理，并写入BigTable仓库中  一次跟踪，被设计成BigTable中的一行 每行中的每一列都代表了一个span 不同跟踪涉及到的span数量可能不同，BigTable支持稀疏表格，很适合这种场景    dapper还提供了额外的api来帮助我们快速访问BigTable仓库中的跟踪数据。\n安全和隐私 # 前面提到了应用程序中可以在当前span中添加一定数量的annotation来进一步增强跟踪能力（因为trace分析工具可以在收集到的日志数据中提取出这些信息），这些annotation可以帮助定位系统为何表现异常的原因。然而，有些情况下，这些数据中可能包含了敏感信息，这些信息不应该暴露给未经授权的用户（包括正在debug的工程师）。\n安全和隐私问题应予以足够的重视，dapper中可以记录rpc的名称，但是不记录任何有效载荷数据，如请求体、响应体信息。相反，应用程序级别的annotation提供了一个方便的可选机制：应用程序开发人员可以在span中选择关联那些为以后分析提供价值的注释信息。\ndapper还提供了一些安全上的便利，这是dapper的设计者所始料未及的。通过跟踪公开的安全协议参数，dapper可以过检相应级别的认证或加密系统，来监视应用程序是否满足安全策略。dapper还可以提供信息来决定是否启用期望的系统隔离策略，例如支撑敏感数据的应用程序不得与未经授权的系统组件进行交互。这样的措施提供了比源码审核更强大的安全保障。\n部署状况 # 无处不在的部署，持续监控，应用级透明！dapper在谷歌使用已经有多年，通过了线上环境的检验。\ndapper运行库 # 在谷歌内部，dapper主要是被植入到了一些通用的基础rpc框架、线程控制和流程控制组件库中，其中包括span的创建、采样率设置，以及把日志写入本地磁盘中。除了做到轻量级，植入的代码更需要稳定和健壮，因为它与海量的应用对接，一旦植入代码有问题，将使得维护和修复bug变得很困难。实际植入的代码是由未超过1000行的c++和不超过800行的java代码组成。为了支持key-value形式的annotation还额外植入了500行左右代码。\ndapper覆盖情况 # dapper的推广是从两个维度进行，一个是在生产环境应用中生成dapper traces（这里的应用链接了前面提到的dapper运行库），另一个是收dapper traces colletion daemon来收集生成的这些dapper traces。dapper daemon是我们的机器安装的OS镜像的一部分，因此几乎谷歌内部的所有的线上服务器都支持dapper跟踪。\n在某些情况下dapper可能不能够正确地跟踪控制路径，这可能是因为使用了非标准的控制流操作，或者是dapper错误地将跟踪信息归类到不相关的事件上。dapper提供了一个简单的库来帮助开发人员手动控制跟踪的传播信息，也算是一种上述问题的办法吧。当前大约有40多个c++程序和33个java程序需要手动控制跟踪信息传播，只是google线上应用的九牛一毛，足可以忽略不计。还有一部分是因为没有使用dapper运行时库，如使用原生的tcp socket、soap rpc进行通信，这种dapper肯定也是无法跟踪的。\n早期部署的时候，dapper还没有那么稳定，所以默认是关闭的， 直到dapper开发人员对其稳定性和开销有了足够的信心之后才将其修改为默认开启。\n注释使用情况 # 程序员倾向于将应用层级的一些dapper annotation作为一种分布式调试日志使用，或者用来对dapper traces进行分类。例如，所有的BigTable请求都添加了要访问的表名来作为annotation。当前几乎70%的dapper spans以及90%的dapper traces包括了至少1个dapper annotation信息。\n41个java应用、68个c++应用添加了自定义应用层级的annotation来更好地理解span内的活动信息。现在来看java开发人员在span内添加的annotation比c++开发人员要多一些，这可能是因为c++服务更偏底层，java应用更接近用户，逻辑更重一些，其中涉及到的各种服务器请求更多一些。\n管理跟踪开销 # 跟踪系统的开销主要有两部分组成，一是被监控系统生成trace数据和trace daemon收集这部分trace数据所带来的系统性能下降，二是需要使用一部分资源来存储和分析trace数据。虽然说我们认为对一个有价值的中间件植入跟踪带来一部分性能开销是值得，但是如果能讲这里的开销降低到可以忽略的程度，那是最好不过了，推广该跟踪系统也会变得更加简单。\n从3个方面展示跟踪系统的开销情况：dapper组件操作的开销，跟踪收集的开销，dapper对生产环境负载的影响。这里也会介绍dapper的可变采样率机制如何帮助降低开销，以及如何在低开销和获得代表性的跟踪二者之间获得平衡。\n生成跟踪的开销 # 生成trace数据的开销是dapper性能影响中最关键的部分，因为收集、分析trace数据的工作可以在紧急情况下更容易被关闭。dapper运行库中生成trace数据的开销，主要是创建和销毁span、annotation，并将其记录到磁盘供后续收集而引入的。root span的创建和销毁平均需要消耗204ns的事件，创建、销毁其他span则只需要大约176ns，这是因为root span的创建需要生成一个全局唯一的id，开销稍大些。\n如果一个span没有被采样的话，这个span下创建annotation的成本几乎可以忽略不计，平均只需要9ns。如果被纳入采样的话，会用一个字符串来进行标注，平均需要40ns。这些数据都是在2.2GHz的x86服务器上采集的。\n在dapper运行期将trace数据写入到本地磁盘是开销最大的操作，但是他们的可见开销大大减少了，因为写入日志文件的操作相对于被跟踪的应用系统来说是一个异步的操作。不过，如果请求量特别大的情况下，尤其是采样率很高的情况下，日志写入的操作仍然是开销比较大的操作。后面会展示一个web搜索的负载下的的性能开销示例。\n跟踪收集的开销 # 读取生成的trace数据也会对负载产生一定的干扰，下表展示了最坏情况下，dapper trace collector daemon在高于实际情况负载情况下进行trace收集过程中cpu使用率情况。在生产环境中，这个守护进程从来没有超过0.3%的单核cpu使用率，而且只有很少量的内存使用（以及堆碎片噪音）。我们还限制了dapper守护进程的调度优先级为最低优先级，以避免在一台高负载的服务器上出现cpu竞争。\ndapper也是一个带宽资源的轻量级消费者，每一个span在传输到BigTable仓库过程中平均只占用了426个字节。作为网络行为中的极小部分，dapper的trace数据收集在谷歌的生产环境中只占用了0.01%的网络资源。\n生产环境的开销 # 每个用户请求可能会牵扯到对大量的高吞吐量的线上服务的请求调用，这也是为了进行分布式跟踪的原因之一。这种情况下会生成大量的trace数据，并且他们对性能的影响是最敏感的。在下表中我们用集群下的网络搜索作为例子，通过调整采样率来衡量dapper在延迟和吞吐量方面对线上服务性能的影响。\n从表中可以看到，采样率的变化对服务吞吐量的影响不是很明显，但是对服务延迟的影响还是比较大的，因此也可以得出这样的结论，对trace数据进行采样还是很有必要的。\n当我们把采样率调整到1/16之后，引入的服务延迟和吞吐量的开销就全部在实验误差范围内了。在实践中，我们还发现即便采样率调整到1/1024后仍然有足够量的trace数据来跟踪大量服务。保持dapper的性能开销基准在一个非常低的水平是非常重要的，因为它为哪些应用提供了一个宽松的环境来使用完整的annotation api来增强跟踪能力的同时而无需担心性能损失。使用较低的采样率也是有额外的好处的，可以让持久化到硬盘中的trace数据在垃圾回收机制处理之前保留更长的事件，这样为dapper的收集组件保留了更多的灵活性。\n可变采样 # 进程中dapper所引入的开销与采样率成正比。dapper的第一个生产版本统一将采样率设置为了1/1024。这个简单的方案对高吞吐量的线上服务是很有用的，因为那些感兴趣的事件在吞吐量大了之后通常可能会经常出现，容易被再次捕捉到。\n但是，这种较低的采样率，对于吞吐量比较小的线上服务可能就不太明智了，会很容易错过一些事件，这个时候可能希望配置成较高的采样率，如1，但是又可能要担心引入的性能开销。关键的是，这种情况下要覆盖默认的采样率1/1024还需要人工进行干预，这可不是dapper设计者所期望的，这样就引入了可变采样。\n在部署可变采样(也称自适应采样)的过程中，参数化配置采样率时，不再使用一个统一的采样方案，而是使用一个采样期望率来标识单位时间内采样的trace数量。例如希望1min内采样100条记录，在高吞吐量的线上服务中就多丢弃一些trace数据，在低吞吐量的线上服务中就少丢弃一些trace数据。这样一来，高吞吐量的将自动降低采样率，低吞吐量的将自动提高采样率，从而使得开销一直低于开销基准以下。实际使用的采样率会随着跟踪本身记录下来，有利于trace分析工具进行准确的分析。\n应对积极采样 # 在高吞吐量的线上服务中往往采样率会低至0.01%，新的dapper用户往往会觉得这不利于他们的分析。但我们在谷歌的实践经验使我们相信，对于高吞吐量服务，如果一个显著的操作在系统出发生了一次，那它就会出现成千上万次，因此积极采样（agreessive sampling）（指的应该是可变采样动态调整采样率）并不会妨碍他们的分析。低吞吐量的服务，也许每秒就几十次请求，而不是几十万，即便采样率为100%也可以负担的起每一个请求。综合这两种情况，积极采样（可变采样而非固定采样率不变）没什么问题，这是促使我们决心使用可变采样的原因。\n额外采样 # 上述采样策略描述的是应用程序生成trace数据时是否记录到本地磁盘中，通过可变采样减少性能开销的同时不丢失过多的跟踪事件以保证跟踪能力。dapper的团队还需要将收集到的trace数据写入中央资料库的BigTable仓库中，需要控制写入规模，因此为了达到这个目的，还需要结合“二级采样”。\n目前我们的生产集群每天产生超过1TB的trace数据，dapper的用户希望生产环境下的进程的跟踪数据从被记录之后能够保存至少两周的事件。逐渐增长的trace数据密度必须和dapper中央仓库锁消耗的服务器及硬盘存储进行权衡。高采样率还使得dapper收集器写入BigTable中央仓库的速率接近了BigTable写吞吐量上限。\n为了维持所需的硬件成本和渐增的BigTable写吞吐量之间的灵活性，我们在trace数据收集系统自身中增加了额外的采样控制。这里充分利用了所有span都来自一个特定的trace并共享同一个trace-id这个事实，有些span可能横跨了数千个主机。对于收集系统中的每一个span，我们用hash算法把trace-id转成一个标量z，这里0\u0026lt;=z\u0026lt;=1。如果z比我们收集系统中指定的系数（阈值）低的话，我们就保留这个span信息，并写入到BigTable仓库中；反之，我们就丢弃它。trace-id唯一标识了一个trace，我们要么保存整个跟踪信息，要么全部丢弃，而不是单独处理trace数据内的某个span。\n有了这个额外的“全局写入率参数”之后，使我们的收集管道变得简单多了，因为我们可以很容易地在配置文件中调整它来控制写入率。\n总结 # dapper结合两种采样策略，来平衡开销、跟踪效果、硬件成本之间的关系：\n 应用程序中生成trace数据并记录到本地磁盘，此过程应用“可变采样策略”； trace数据收集系统收集数据写入BigTable中央仓库，此过程应用“额外采样策略”；  dapper工具 # 关于dapper的配套工具，这里只给一个dapper操作界面的展示，方便大家了解大致上具备哪些能力，如下图所示。\n大家可以了解下zipkin、jaeger，他们都是基于dapper演化而来，这里我们就再详细介绍dapper自身的工具了，因为我们也无法使用它，只能用开源实现zipkin、jaeger之类的。\n本文主要是为了阐述dapper的设计思想，方便我们大家了解分布式跟踪系统的工作原理，然后方便我们将现有的开源实现zipkin、jaeger集成到我们自身的框架中，方便自己的业务开发人员定位线上问题。\n如果对谷歌dapper的工具感兴趣的话，可以参考这里的说明，点击查看 dapper：大规模分布式跟踪系统。\ndapper使用 # dapper在谷歌被广泛使用，一部分直接通过dapper的用户界面，另一部分间接地通过对dapper api的二次开发或者在现有的api基础上建立的应用。\n原dapper论文中列举了一些成功的dapper使用场景，大家也可以参考下，决定将dapper，或者zipkin、jaeger用在什么场景下呢？能够通过二次开发定制化一些自己需要的可视化工具出来呢？这个是我们要思考的，也是对我们的应用开发人员、维护人员最优价值的部分。\n在开发中使用dapper # Google AdWords借助dapper来优化自己的系统，发现系统中延迟过高的服务调用，发现不必要的串行请求并推动团队修复，以改善性能问题等等。\n与异常监控的集成 # Google维护了一个不断从进程中收集异常信息并集中异常信息报告的服务，如果这些异常发生在跟踪采样的过程中，对应的trace-id和span-id也会被记录到异常记录中，后续借助可视化工具可以容易定位异常发生在链路中的哪一个环节，并借助annotation来进一步定位问题。\n解决延迟的长尾效应 # 当一个系统不仅涉及数个子系统，而是几十个开发团队的涉及到的系统的情况下，端到端性能较差的根本原因到底在哪，这个问题即使是我们最好的和最有经验的工程师也无法正确回答。在这种情况下，Dapper可以提供急需的数据，而且可以对许多重要的性能问题得出结论。\n推断服务依赖 # 线上服务基本都是集群部署，每一个服务上运行的任务可能依赖了其他的很多服务，而不同的任务依赖的服务也是是动态改变的，所以不可能仅从配置信息上推断出所有这些服务之间的依赖关系。dapper核心组件与dapper跟踪annotation一并使用的情况下，“Service Dependencies”项目能够推算出任务各自之间的依赖，以及任务和其他软件组件之间的依赖。在公司内部的各个流程需要准确的服务依赖关系信息，以确定瓶颈所在，以及指导服务的迁移计划。\n不同服务的网络使用率 # 谷歌投入了大量的人力和物力优化其网络，以前网络管理员只能关注独立的硬件信息、常用工具及以及搭建出的各种全局网络鸟瞰图的dashboard上的信息。网络管理员确实可以一览整个网络的健康状况，但是，当遇到问题时，他们很少有工具可以及时准确地定位到导致网络负载高的应用程序级别的罪魁祸首。 虽然dapper不是设计用来做链路级的监控的，但我们发现，它非常适合去做集群之间应用级网络活动的分析。谷歌利用dapper这个平台，建立一个不断更新的控制台，来显示集群之间最活跃的应用级网络流量热点。此外，使用dapper我们能够为昂贵的网络请求指出具体到应用级的原因，而不是面对不同服务器之间的信息孤岛无所适从。\n分层和共享存储系统 # 在Google的许多存储系统是由多重独立复杂层级的分布式基础设备组成的。例如，Google的App Engine就是搭建在一个可扩展的实体存储系统上的，该实体存储系统在BigTable基础上封装、暴露了某些RDBMS功能。 BigTable呢，又同时使用了Chubby（分布式锁系统）及GFS。 在这种分层的系统中，并不总是很容易确定最终用户资源的消费模式。例如，针对一个给定的BigTable单元格的大量GFS请求主要来自于一个用户或是由多个用户，但是在GFS层面，这两种明显的使用场景是很难界定的。而且，如果缺乏一个像dapper一样的工具的情况下，对共享服务的竞争可能会同样难于调试。 dapper的用户界面可以聚合那些调用任意公共服务的多个客户端的跟踪的性能信息。这就很容易让提供这些服务从多个维度给他们的用户排名，例如，入站的网络负载，出站的网络负载，或服务请求的总时间。这样就便于对一个共享服务确定其上游服务对其造成的负载情况进行界定，便于后续推动上游优化服务调用逻辑或者独立部署共享服务等等吧。\ndapper的救火能力 # 对于一些“救火”任务，dapper可以处理其中的一部分。对于那些高延迟，不，可能在正常负载下都会响应超时的服务，Dapper用户界面通常会把这些瓶颈的位置隔离出来。通过与dapper收集跟踪的守护进程的直接通信，那些特定的高延迟的跟踪数据轻易的就能收集到。当出现灾难性故障时，通常是没有必要去看统计数据以确定根本原因的，只查看示例跟踪就足够了。 但是，除非收集到的dapper数据的批量分析能在问题出现10分钟之内完成，否则dapper就不能处理这样的“救火”任务。\n总结 # 本文中，我们介绍了谷歌dapper分布式跟踪系统，并汇报了谷歌内部的开发、使用经验。 dapper几乎部署在所有的谷歌线上系统上，并可以在不需要应用级修改的情况下进行跟踪，而且没有明显的性能开销。dapper对于开发人员和运维团队带来的好处，可以从大家对跟踪用户界面的广泛使用上看出来，另外我们还列举了一些dapper的使用案例来说明dapper的作用，这些案例有些甚至都没有dapper开发团队参与，而是被应用的开发者设计、开发出来的。\n据我们所知，这是第一篇汇报生产环境下分布式系统跟踪框架的论文。事实上，我们的主要贡献源于这个事实：论文中回顾的这个系统已经运行两年之久。我们发现，结合对开发人员提供简单API和对应用系统完全透明来增强跟踪的这个决定，是非常值得的。\n我们相信，Dapper比以前的基于Annotation的分布式跟踪达到更高的应用透明度，这一点已经通过只需要少量人工干预的工作量得以证明。虽然一定程度上得益于我们的系统的同质性，但它本身仍然是一个重大的挑战。最重要的是，我们的设计提出了一些实现应用级透明性的充分条件，对此我们希望能够对更错杂环境下的解决方案的开发有所帮助。\n最后，通过开放dapper跟踪仓库的代码给内部开发者，促使了更多的基于跟踪仓库的分析工具的产生，而仅仅由dapper团队埋头苦干的是远远不能达到现在这么大规模的，这个决定促使了设计和实施的展开。\n参考文献：\n Dapper, a Large-Scale Distributed Systems Tracing Infrastructure Dapper，大规模分布式系统的跟踪系统  "}),a.add({id:412,href:"/tags/bloom-filter/",title:"bloom filter",description:"",content:""}),a.add({id:413,href:"/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/",title:"布隆过滤器",description:"",content:""}),a.add({id:414,href:"/blog/2018-09-29-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%8E%9F%E7%90%86%E5%8F%8A%E5%BA%94%E7%94%A8/",title:"布隆过滤器的原理及应用",description:"布隆过滤器在很多场景中都有应用，如根据发件人过滤垃圾邮件、避免已浏览视频的重复推荐、避免分布式缓存中不存在key的访问穿透，等等，布隆过滤器发挥了非常大的作用，布隆过滤器其实也存在很多的变体。本文就来结合作者业务中遇到的问题、布隆过滤器的应用来详细了解下布隆过滤器的原理及应用。",content:" img { width: 680px; padding-bottom: 1rem; }  布隆过滤器在很多场景中都有应用，如根据发件人过滤垃圾邮件、避免已浏览视频的重复推荐、避免分布式缓存中不存在key的访问穿透，等等，布隆过滤器发挥了非常大的作用，布隆过滤器其实也存在很多的变体。本文就来结合作者业务中遇到的问题、布隆过滤器的应用来详细了解下布隆过滤器的原理及应用。\n布隆过滤器 # 描述布隆过滤器之前，首先描述下背景，经常遇到“快速查询、插入”等操作的场景，这个时候第一时间想到的可能是set、map数据结构，因为它的时间复杂度为O(1)，是首选的数据结构。但是当要记录的数据量非常大时，set、map可能并不是一种合适的选择。\n假如我们有一个短视频推荐的场景，用户每次拉取短视频列表时都只返回用户没有看过的短视频，短视频通过短视频id（uint32）唯一标识，假如我们用map来存储，一个短视频id就需要4字节，假如一个用户一天可以观看50个短视频，1个月就是1500个，1年就是18000个，这样一个用户1年就需要占用存储72KB，假如我们有100w用户，那就是72GB，这些信息是要放在内存里面进行计算的，什么样的机型才可以拥有72GB大小的内存啊？要尽量做到“低成本、高性能”的方案设计，这种选型是有问题的。\n布隆过滤器（bloom filter），其实就是一种折中的设计方案。内存是按字节寻址，但是1个字节是8位，存储1个短视频id，比如值1，1bit就可以表示的情况下却需要多占用31个bit，岂不是极大的浪费？布隆过滤器的底层存储其实也就是一段连续的内存空间，所有的查询、插入操作都转换成对bit的查询、写入操作。比如要写入一个短视频id，将通过多轮hash(短视频id)计算出多个bit offset，如b1~b8，然后存储操作就转换为将b1~b8全部设置为1，查询操作就转换为查询b1~b8是否全部为1。\n布隆过滤器，以接近O(1)的性能进行查询、插入操作，但是由于hash碰撞的存在，会引入一定的误差率。存在这样的问题，本来短视频id NNN没有存储，但是却由于多轮hash(NNN)得到的b1~b8与其他某个短视频id MMM计算得到的b1~b8完全相同，更可能由于之前存储多个短视频id A、B、C、D时将b1~b8设置为1，此时就会导致判断NNN已存储。这种情况就引入了“误差率”的概念。\n误差率： 布隆过滤器现在要存储N个元素，存储指定元素e时，先进行多轮hash计算得到b1~bn，然后依次检查offset为b1~bn的bit位是否已经设置为1，如果全部为1则表示布隆过滤器中已存储该元素。当不全为1时认为没有存储过元素e，将b1~bn设置为1。 由于写入操作时，我们总是遵循test、set的方式，所以当我们逐次将N个元素写入布隆过滤器时，假如test时发现元素已存储，这种情况下一定是由于hash碰撞引起，引入了误差。 所以如果要求写入N个元素却只成功写入了M个元素（M\u0026lt;=N），误差率=(N-M)/N。\n优缺点： 优点：速度快，又节省存储空间。 缺点：存在一定的误差 \u0026amp;\u0026amp; 不支持删除操作。\n如果应用场景允许一定的判定误差，例如短视频推荐场景、信息流推荐场景等，那么布隆过滤器也不失为一种合适的选择。刚才提到set、map占用内存空间大，那么布隆过滤能占用多少呢，这里就涉及到误差率和存储成本之间的权衡了。\n误差率 \u0026amp; 存储空间 # 误差率，一般是根据应用场景或者产品体验、产品表现来指定的，如用布隆过滤器记录用户观看过的短视频id误差率不超过1/1000。\n其实指定了误差率之后，一般也就可以确定存储1个这样的短视频id所需要的大致bit数量了，简称bpe（bits per element），double bpe = - (log(error) / (ln(2)^2))，但是到底需要多少bit数量（bpe是浮点型），还需要进一步确定，int hashes = (int)ceil(ln(2) * bpe)，这表名要计算得到hashes个hash值，然后用这个值对布隆过滤器内存空间bits数量取模，从而得到hashes个bit offset。\ndouble denom = 0.480453013918201; // ln(2)^2 double bpe = -(log(error) / denom); int hashes = (int)ceil(0.693147180559945 * bpe); // ln(2)  假如希望存储entries个元素的话，在满足上述误差率的情况下，布隆过滤器需要分配内存空间为int bits = (int)(bpe * entries)。\nint bits = (int)(bpe * entries)  murmurhash算法 # 前面描述了在预期误差率的情况下，存储一个元素所需要的平均存储空间是多少bpe，以及实际存储时需要设置的bits数量，也就是需要计算的hash轮数。现在描述下hash算法，murmurhash是现在比较常用的一种hash算法，不少开源的布隆过滤器实现都是采用了murmurhash算法来实现。\nmurmurhash算法的名字来源于它的两个重要操作MU（multiply）以及R（Rotate），它在设计上并不是为了密码学上增加单向加密的难度，所以它不适用于安全领域。如果是向做一个快速的hash且希望hash碰撞满足预设指标的话，murmurhash是一个不错的hash算法。\n详细信息可以参考wikipedia，点击查看 MurmurHash算法。\n多分区布隆过滤器 # 上述描述了一个布隆过滤器的大致原理、如何确定误差率以及bpe和hash轮数、依赖的hash算法等，在实际应用中，我们可能会遇到更多的问题。\n仍以短视频推荐场景为例，假定我们设计容量是为每个用户记录最近访问过的2000个短视频，假定需要的存储空间是m，随着时间的推移，布隆过滤器中的bit=1的bits越来越多，我们不能将所有的bits写的过多，更不能写满，以为会导致误差率急剧升高，甚至超过预设的误差率。\n那么写多少bits算是合理的呢？这个可以通过实测进行计算，看看写了多少bits后误差率升高到预设值，当布隆过滤器所有bits的1/2都是1时可以看做是“写满”的标识。这个时候该如何操作呢？\n1）一种方式是清空布隆过滤器（全部设为0），但是会导致用户最近看过的短视频被重复拉取到，会直接影响用户体验。\n2）另一种思路是，布隆过滤器内部存储由一块固定内存修改为可动态增加的多块分区（slice）形式，当一个slice写满，创建一个新的slice用来执行写入操作，查询操作在新、旧slice同时查询，任一个slice命中则认为命中。等新的slice也写满时清空旧的，继续用来写入，也可以继续创建新的slice。这种带来了查询操作耗时稍微增加，存储占用有所增加，但是可以避免对用户体验造成影响，对于推荐这种要求保证用户体验的场景，特别是保证不重复观看同一个内容，这种思路也是可取的。\n3）还需要考虑的一个问题是，产品策略是随时会进行调整的，当产品希望进一步降低误差率时，该如何操作呢？可以创建一个新的布隆过滤器实例来适配错误率调整，并增加一个过渡期，在这个过渡期内，新旧两个布隆过滤器实例同时执行查询，新布隆过滤器负责写入，等过渡期结束之后，废弃旧的布隆过滤器，新的布隆过滤器单独工作。这样可以动态支持产品策略调整，不足是误差率在过渡期内可能会发生短暂波动。\n在上述2）3）思路的基础上，在项目开发中我设计开发了一个bloom实例支持多分区的布隆过滤器，并提供了序列化、反序列化能力，是对普通布隆过滤器的一种改进型设计，感兴趣的可以参考，点击查看 一种改进的布隆过滤器实现。\n计数布隆过滤器 # 上述所描述的布隆过滤器是不支持删除操作的，但是某些情境下我们是有删除需求的（这里我们就不举例了），如果要增加删除的能力，还需要额外增加一些overhead。\n考虑一下，标准的布隆过滤器不能支持删除操作的原因，很简单，就是因为要clear的bits可能同时被多个元素所使用了，直接clear bits将影响到对其他已存储元素的判断逻辑。那么又想删除当前元素，又不影响到共用该bits的其他元素，怎么办？\n判断内存对象是否被使用经常通过引用计数的方式来解决，布隆过滤器也可以借助引用计数的方式来标志某个bits是否是否被使用。我们为每个bit位额外维护一个引用计数值，当该bit被set为1时，引用计数+1，当该bit被clear为0时，引用计数-1。这样就解决了直接clear该bit所带来的问题。\n有一个非常重要的点，要回忆一下，我们数据结构选型不选用set、map是为了节省内存存储空间，现在我们却为每一个bit来额外分配了一个引用计数值，这里的值又要占用一定的存储空间。这不是又绕回以前了吗？\n这里就要考虑下引用计数值占用bits数量的问题了，这里也可以引出另一种布隆过滤器变体了，Counting Bloom Filter，简称CBF。CBF将标准的布隆过滤器位数组的每一位扩展为一个小的计数器（Counter），在插入元素时给对应的k（k为哈希函数个数）个Counter的值分别加1，删除元素时给对应的k个Counter的值分别减1。Counting Bloom Filter通过多占用几倍的存储空间的代价，给Bloom Filter增加了删除操作。下一个问题自然就是，到底要多占用几倍呢？\n我们先计算第i个Counter被增加j次的概率，其中n为集合元素个数，k为哈希函数个数，m为Counter个数（对应着原来位数组的大小）：\n上面等式右端的表达式中，前一部分表示从nk次哈希中选择j次，中间部分表示j次哈希都选中了第i个Counter，后一部分表示其它nk – j次哈希都没有选中第i个Counter。因此，第i个Counter的值大于j的概率可以限定为：\n上式第二步缩放中应用了估计阶乘的斯特林公式：\n在Bloom Filter概念和原理一文中，我们提到过k的最优值为(ln2)m/n，现在我们限制k ≤ (ln2)m/n，就可以得到如下结论：\n如果每个Counter分配4位，那么当Counter的值达到16时就会溢出。这个概率为：\n这个值足够小，因此对于大多数应用程序来说，4位就足够了。\n其他布隆过滤器变体 # 由于现实应用场景多样，布隆过滤器变体也非常多。维基百科中列出了很多布隆过滤器变体，例如：\n Cache Filtering Avoiding False Positives in a Finite Universe Counting filters Decentralized aggregation Data synchronization Bloomier filters Compact approximators Stable Bloom filters Scalable Bloom filters Spatial Bloom filters Layered Bloom filters Attenuated Bloom filters Chemical structure searching  感兴趣的可以参考维基百科中的相关描述，这里权做抛砖引玉了，点击查看 布隆过滤器。\n布隆过滤器设计实现 # 作者在工作过程中，写过一个C++版本的分段式的布隆过滤器，支持指定误差率来推算容量，并能支持后期的扩容需求，感兴趣请点击hitzhangjie/bloomfilter。\n"}),a.add({id:415,href:"/tags/comment/",title:"comment",description:"",content:""}),a.add({id:416,href:"/tags/godoc/",title:"godoc",description:"",content:""}),a.add({id:417,href:"/blog/2018-06-29-godoc%E6%96%87%E6%A1%A3/",title:"godoc文档",description:"了解godoc文档的作用，以及如何为你的项目生成godoc文档，应该如何编写godoc注释。",content:"godoc文档 # 标准库文档 # 当要查看go标准库文档时，可借助godoc命令进行查询，如godoc container/list，也可以在本地开启一个web服务来查询，如godoc -http=:6060。\n非标注库文档 # 当要查看非标准库（如自建项目）的文档时，我们也是借助godoc来查看，但是执行godoc命令之前需要做些准备工作。\n希望在文档中看到什么信息 #  package介绍 type介绍 func介绍 示例代码 针对package的示例代码 针对type的示例代码  上述几种希望看到的信息，我们首先需要在代码中按照godoc约定的方式提供上述信息，godoc才能找到这些信息展示出来。下面就分别描述下如何在代码中包含上述信息。\npackage \u0026amp; type \u0026amp; func 介绍 # 这里对package、type、func的介绍是以leading comments的方式在代码中直接提供的，就是package声明、type声明、func声明前面紧邻的注释，该注释与声明之间没有空行分隔。\n以如下文件$GOPATH/src/kisslulu/conf/conf.go为例：\n// Package conf provides support for loading json, ini, properties configuration. package conf // JsonCfg type JsonCfg struct { } // IniCfg type IniCfg struct { } // PropCfg type PropCfg struct { } // Load json config from filepath func LoadJsonCfg(filepath string) (*JsonCfg, error) { } // Load Ini config from filePath func LoadIniCfg(filepath string) (*IniCfg, error) { } // Load PropCfg from filepath func LoadPropCfg(filepath string) (*PropCfg, error) { }  运行godoc -http=:6060找到对应的package kisslulu/conf即可预览文档中对package、type、func的介绍。\npackage \u0026amp; type 示例代码 # godoc中的示例代码是存放在一个独立的文件“example_test.go”中的，这个文件名是固定的。以上文中这个conf package为例，为其编写相应的package示例代码和type示例代码。\nexample_test.go # 这个示例代码文件的包名定义为package conf_test或者package conf都可以，其他包的话go install会提示error: can't load package...，godoc运行时会对example_test.go中的示例代码进行加载并渲染。\npackage示例代码 # package示例代码是编写在在func example() {...}函数里面，只能包含一个package示例代码，通常在package示例代码里面详细描述该package的使用方法，比如完整package conf解析json、ini、prop配置文件的方法。\n以下是一个示例：\npackage conf_test import \u0026quot;fmt\u0026quot; func example() { fmt.Println(\u0026quot;hello world\u0026quot;) // how to load json cfg fp1 := \u0026quot;path1\u0026quot; cfg1, _ := LoadJsonCfg(fp1) // how to load ini cfg fp2 := \u0026quot;path2\u0026quot; cfg2,_ := LoadIniCfg(fp2) // how to load prop cfg fp3 := \u0026quot;path3\u0026quot; cfg3,_ := LoadPropCfg(fp3) fmt.Println(\u0026quot;cfg1:\u0026quot;, cfg1) fmt.Println(\u0026quot;cfg2:\u0026quot;, cfg2) fmt.Println(\u0026quot;cfg3:\u0026quot;, cfg3) // Output: {\u0026quot;port\u0026quot;:8000,\u0026quot;timeout\u0026quot;:2000} // Output: \u0026quot;ilive-service.port\u0026quot;:8000, \u0026quot;ilive-service.timeout\u0026quot;:2000 // Output: port=8000, timeout=2000 }  type示例代码 # 每中类型下往往定义了多个方法，可能有需要对多个方法提供示例代码，所以可以godoc约定允许通过函数“func Example${type}_${testcase} {\u0026hellip;}”提供多个示例代码，需要注意的是${testcase}必须首字母小写，否则godoc会忽略。\n以type JsonCfg为例：\npackage conf_test import \u0026quot;fmt\u0026quot; func example() { // ... } func ExampleJsonCfg_testcase1 () { // here is the testcase 1 } func ExampleJsonCfg_testcase2 () { // here is the testcase 2 }  看下文档效果 # 运行godoc -http=:6060，然后浏览器中打开localhost:6060，定位到package kisslulu/conf即可查看文档效果，如下图所示。 "}),a.add({id:418,href:"/blog/2018-05-21-golang-method-receiver-type%E7%9A%84%E6%A2%97/",title:"golang method receiver-type的梗",description:"golang中方法为什么receiver-type不能为指针类型、接口类型",content:"这里来聊聊method receiver type为什么不能是pointer和interface类型。\n1 receiver-type必须满足的条件 # golang里面提供了一定的面向对象支持，比如我们可以为类型T或者*T定义成员方法（类型T称为成员方法的receiver-type），但是这里的类型T必须满足如下几个条件：\n T必须是已经定义过的类型； T与当前方法定义必须在同一个package下面； T不能是指针； T不能是接口类型；  前面两点都比较容易理解，下面两点是什么梗？为什么就不能在指针类型上添加方法？为什么就不能在interface上添加方法？当然可以一句话待过，golang不支持，但是我想问下为什么？\n2 receiver-type为什么不能是指针类型？ # golang允许为 类型指针*T 添加方法，但是不允许为 指针类型本身 添加方法。按现有golang的实现方式，为指针类型添加方法会导致方法调用时的歧义。\n看下面这个示例程序。\ntype T int func (t *T) Get() T { return *t + 1 } type P *T func (p P) Get() T { return *p + 2 } func F() { var v1 T var v2 = \u0026amp;v1 var v3 P = \u0026amp;v1 fmt.Println(v1.Get(), v2.Get(), v3.Get()) }  示例程序中 v3.Get() 存在调用歧义，编译器不知道该调用哪个方法了。如果要支持在指针这种receiver-type上定义方法，golang编译器势必要实现地更复杂才能支持到，指针本来就比较容易破坏可读性，还要在一种指针类型上定义方法，对使用者、编译器开发者而言可能都是件费力不讨好的事情。\n3 receiver-type为什么不能是接口类型？ # 这没有什么好揣测的，只是golang runtime不支持而已。golang现在的实现里，interface内部结构只能表示方法原型，但是不包括方法定义，struct才可以包括方法定义（这部分内容感兴趣的可以翻下golang的源码，这里不展开了）。\n当一个类型实现了某个接口声明的全部方法时，就说这个类型实现了这个接口，就可以将这个类型的值赋值给该接口类型的值，此时会更新接口值的 dynamic value和dynamic type 字段。这里需要 根据接口中是否定义了方法列表 来进一步分析，可以细分为 接口方法列表为空 和 接口方法列表不空 两种情况讨论。\n下面以这里的示例代码为例进行分析：\n// - 接口类型1 type EmptyIface interface{ } // - 接口类型2 type Stringer interface { String() string } // - 类型Binary实现了接口Stringer，也实现了EmptyIface type Binary uint64 func (i Binary) String() string { return strconv.Uitob64(i.Get(), 2) } func (i Binary) Get() uint64 { return uint64(i) } // - 为接口值赋值 var b Binary = Binary(1) var eface EmptyIface = b var iface Stringer = b fmt.Println(iface)  3.1 空接口interface # eface对应接口类型是interface{}，并且Binary值b小于等于sizeof(uintptr)，那么eface的dynamic value就是直接拷贝b；如果这里是eface := anyBigStruct {\u0026hellip;.}，并且anyBigStruct size大于sizeof(uintptr)，那么就需要开辟内存拷贝anyBigStruct的值，并将新开辟内存的地址设置到dynamic value字段。dynamic type就指向对应类型的定义了。\n此时的接口类型可以表示为：\ntype eface struct { _type *_type data unsafe.Pointer }  此时的接口值可以表示为： 3.2 非空接口interface{ method-list } # 如果iface对应接口类型interface{methods-list}，这个时候dynamic value还是与1）中同样的处理，但是dynamic type处理方式不同，需要对运行时接口方法的调用地址进行处理。\n这时会创建一个 itable（类似c++虚函数vtable），这个itable里面保存了iface的接口类型以及接口中声明的各个方法原型对应的调用地址，调用地址从何而来？这里的调用地址也就是接口值动态类型中实现的方法的调用地址。设置完接口方法的所有调用地址后，itable构建完成，然后将iface接口值里面的tab字段指向该itable。\n此时的接口类型可以表示为：\ntype iface struct { tab *itab data unsafe.Pointer }  此时的接口值可以表示为： 3.3 接口方法调用 # 通过接口值调用方法的时候，需要根据 “该接口值类型、接口值对应的动态类型” 查询对应的接口方法实际的调用地址。如果该接口类型里面根本就没有方法列表，那肯定就报错了也不会查询tab，eface里面也没这个字段；如果接口类型里面有这个方法定义，那就根据iface.tab指向的itable去查询对应该接口类型、动态类型的对应方法的调用地址，然后执行目标地址处的方法体。\n从将Binary值b赋值给iface，再到通过iface查询动态类型Binary中实现的方法Stringer调用地址，最终执行Binary中实现的方法String()，这整个逻辑处理过程中如何对接口类型声明方法列表、动态类型实现方法列表进行处理，我们应该清楚了。\n总而言之，现在golang实现中interface的内部表示不包含“方法定义”相关的字段，无法表示为interface添加的方法定义，编译器当然也不允许。\n不同的编程语言对函数调用的多态实现有不同的思路，c++是通过填充基本类型的虚函数表的方式，golang是通过类似的这样一种查询表的形式。总结一下就是并非golang无法通过扩展支持在接口上添加方法，只是这样是否真的有必要，值得商榷。至少非空接口是用来定义一种明确的行为（contract）的，在上面又加个方法，是什么意思呢？因此不允许将接口类型定义为receiver type也是与接口的定位相对应的吧。\n4 总结 # receiver-type不允许为指针类型和接口类型，对其中原因进行了一点思考和总结。\n参考资料\n Russ Cox, “接口与itable关系”, https://research.swtch.com/interfaces  参考图片\n"}),a.add({id:419,href:"/tags/method/",title:"method",description:"",content:""}),a.add({id:420,href:"/tags/receiver/",title:"receiver",description:"",content:""}),a.add({id:421,href:"/tags/closure/",title:"closure",description:"",content:""}),a.add({id:422,href:"/blog/2018-05-19-golang-function-closure%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/",title:"golang function-closure 实现机制",description:"理解了go闭包的设计实现细节之后，就更容易明白闭包的工作原理，也更容易在编码时绕过一些最佳实践所没有展开讨论的神坑，比如for循环变量被闭包引用问题，比如是值捕获还是引用捕获问题。",content:"golang里面函数时first-class citizen，可以作为值进行参数传递，不管是普通函数“func abc()”，还是成员方法“func (x X) xxx()”，还是一个闭包“func () { return func(){\u0026hellip;.}}”……看上去很方便，不禁要问，golang里面funciton和closure是如何实现的呢？扒拉了下源码，这里简单总结下。\n1 golang中函数内部表示是什么样子的？ # 看下golang cmd/compile/internal/types/type.go中对Func类型的定义：\n// Func contains Type fields specific to func types. type Func struct { Receiver *Type // function receiver，接受者类型，每个函数定义都包括该字段，可以为nil或non-nil Results *Type // function results，返回值类型 Params *Type // function params，参数列表类型 Nname *Node // function name，函数名 // Argwid is the total width of the function receiver, params, and results. // It gets calculated via a temporary TFUNCARGS type. // Note that TFUNC's Width is Widthptr. Argwid int64 Outnamed bool // 是否是可导出的？ }  通过这个Func定义来看，其可以覆盖golang里面所有的函数类型声明了，不管是普通函数，还是成员方法等等。\n2 golang中闭包是怎么实现的？ # 前端时间组内分享闭包使用的时候，觉得这玩意虽然轻巧但是太容易出错了，究其原因是因为不了解闭包的实现原理。那么闭包是如何实现的呢，抽时间扒拉了一下golang中实现闭包的代码，看完后瞬间觉得闭包很简单。\n来简单总结一下，闭包就是函数+环境，问题是这里的环境是如何与函数进行绑定的呢？\n remark: 一开始看了上面的Func类型定义之后，我以为是golang创建了一个虚拟的类型（里面各个字段值为闭包捕获的变量值）然后将该虚拟类型作为receiver-type来实现的呢，可是仔细一想这种思路站不住脚，因为闭包是golang里面的first-class citizen，闭包实现应该非常轻量才对，如果像我最初这种想法那实在是太复杂了，想想要创建多少虚拟类型及其对象吧。\n 看了下源代码，总结一下golang中的实现思路，考虑到闭包对象是否能重复使用，分为两个场景进行处理：\n1) 假如闭包定义后立即被调用 因为只会被使用一次，所以应该力图避免闭包对象的内存分配操作，那怎么优化一下呢，以下面的示例代码为例。\nfunc(a int) { println(byval) byref++ }(42)  上面的闭包将被转换为简单函数调用的形式：\nfunc(byval int, \u0026amp;byref *int, a int) { println(byval) (*\u0026amp;byref)++ }(byval, \u0026amp;byref, 42)  注意看函数原型的变化，原来闭包里面捕获的变量都被转换成了通过函数参数来供值：\n 因为println操作不涉及对byval变量的修改操作，所以是按值捕获； 而byref++涉及到对捕获变量的修改，所以是按引用捕获，对于按引用捕获的变量会进行特殊处理，golang编译器会在编译时将按引用捕获的变量名byref转换成“\u0026amp;byref”，同时将其类型转换成pointer类型，捕获变量对应的写操作也会转换为通过pointer来操作。  2） 假如闭包定以后并不是立即调用 闭包定义后不是立即使用，而是后续调用，这种情况下同一个闭包可能调用多次，这种情况下就需要创建闭包对象，如何实现呢？\n 如果变量是按值捕获，并且该变量占用存储空间小于2*sizeof(int)，那么就通过在函数体内创建局部变量的形式来shadow捕获的变量，相比于通过引用捕获，这么做的好处应该是考虑到减少引用数量、减少逃逸分析相关的计算。 如果变量是按引用捕获，或者按值捕获但是捕获的变量占用存储空间较大（拷贝到本地做局部变量代价太大），这种情况下就将捕获的变量var转换成pointer类型的“\u0026amp;var”，并在函数prologue阶段将其初始化为捕获变量的值。  这部分的代码详见：cmd/compile/gc/closure.go中的方法transformclosure(\u0026hellip;)。 闭包就是函数体+环境，环境就是像这样绑定的。\n3 总结 # 本文简要描述了golang中对函数的内部定义，以及闭包的大致实现思路，加深了理解。\n附：golang闭包处理关键代码 # func transformclosure(xfunc *Node) { lno := lineno lineno = xfunc.Pos func_ := xfunc.Func.Closure if func_.Func.Top\u0026amp;Ecall != 0 { // If the closure is directly called, we transform it to a plain function call // with variables passed as args. This avoids allocation of a closure object. // Here we do only a part of the transformation. Walk of OCALLFUNC(OCLOSURE) // will complete the transformation later. // For illustration, the following closure: //	func(a int) { //	println(byval) //	byref++ //	}(42) // becomes: //	func(byval int, \u0026amp;byref *int, a int) { //	println(byval) //	(*\u0026amp;byref)++ //	}(byval, \u0026amp;byref, 42) // f is ONAME of the actual function. f := xfunc.Func.Nname // We are going to insert captured variables before input args. var params []*types.Field var decls []*Node for _, v := range func_.Func.Cvars.Slice() { if v.Op == OXXX { continue } fld := types.NewField() fld.Funarg = types.FunargParams if v.Name.Byval() { // If v is captured by value, we merely downgrade it to PPARAM. v.SetClass(PPARAM) fld.Nname = asTypesNode(v) } else { // If v of type T is captured by reference, // we introduce function param \u0026amp;v *T // and v remains PAUTOHEAP with \u0026amp;v heapaddr // (accesses will implicitly deref \u0026amp;v). addr := newname(lookup(\u0026quot;\u0026amp;\u0026quot; + v.Sym.Name)) addr.Type = types.NewPtr(v.Type) addr.SetClass(PPARAM) v.Name.Param.Heapaddr = addr fld.Nname = asTypesNode(addr) } fld.Type = asNode(fld.Nname).Type fld.Sym = asNode(fld.Nname).Sym params = append(params, fld) decls = append(decls, asNode(fld.Nname)) } if len(params) \u0026gt; 0 { // Prepend params and decls. f.Type.Params().SetFields(append(params, f.Type.Params().FieldSlice()...)) xfunc.Func.Dcl = append(decls, xfunc.Func.Dcl...) } dowidth(f.Type) xfunc.Type = f.Type // update type of ODCLFUNC } else { // The closure is not called, so it is going to stay as closure. var body []*Node offset := int64(Widthptr) for _, v := range func_.Func.Cvars.Slice() { if v.Op == OXXX { continue } // cv refers to the field inside of closure OSTRUCTLIT. cv := nod(OCLOSUREVAR, nil, nil) cv.Type = v.Type if !v.Name.Byval() { cv.Type = types.NewPtr(v.Type) } offset = Rnd(offset, int64(cv.Type.Align)) cv.Xoffset = offset offset += cv.Type.Width if v.Name.Byval() \u0026amp;\u0026amp; v.Type.Width \u0026lt;= int64(2*Widthptr) { // If it is a small variable captured by value, downgrade it to PAUTO. v.SetClass(PAUTO) xfunc.Func.Dcl = append(xfunc.Func.Dcl, v) body = append(body, nod(OAS, v, cv)) } else { // Declare variable holding addresses taken from closure // and initialize in entry prologue. addr := newname(lookup(\u0026quot;\u0026amp;\u0026quot; + v.Sym.Name)) addr.Type = types.NewPtr(v.Type) addr.SetClass(PAUTO) addr.Name.SetUsed(true) addr.Name.Curfn = xfunc xfunc.Func.Dcl = append(xfunc.Func.Dcl, addr) v.Name.Param.Heapaddr = addr if v.Name.Byval() { cv = nod(OADDR, cv, nil) } body = append(body, nod(OAS, addr, cv)) } } if len(body) \u0026gt; 0 { typecheckslice(body, Etop) walkstmtlist(body) xfunc.Func.Enter.Set(body) xfunc.Func.SetNeedctxt(true) } } lineno = lno }  "}),a.add({id:423,href:"/tags/chann/",title:"chann",description:"",content:""}),a.add({id:424,href:"/blog/2018-05-19-golang-select-case%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/",title:"golang select-case 实现机制",description:"golang chan select-case设计实现",content:"1 chan操作规则 # 在介绍select-case实现机制之前，最好先了解下chan操作规则，明白goroutine何时阻塞，又在什么时机被唤醒，这对后续理解select-case实现有帮助。所以接下来先介绍chan操作规则，然后再介绍select-case的实现。\n1.1 chan操作规则1 # 当一个goroutine要从一个non-nil \u0026amp; non-closed chan上接收数据时，goroutine首先会去获取chan上的锁，然后执行如下操作直到某个条件被满足：\n1）如果chan上的value buffer不空，这也意味着chan上的recv goroutine queue也一定是空的，该接收goroutine将从value buffer中unshift出一个value。这个时候，如果send goroutine队列不空的情况下，因为刚才value buffer中空出了一个位置，有位置可写，所以这个时候会从send goroutine queue中unshift出一个发送goroutine并让其恢复执行，让其执行把数据写入chan的操作，实际上是恢复该发送该goroutine执行，并把该发送goroutine要发送的数据push到value buffer中。然后呢，该接收goroutine也拿到了数据了，就继续执行。这种情景，channel的接收操作称为non-blocking操作。\n2）另一种情况，如果value buffer是空的，但是send goroutine queue不空，这种情况下，该chan一定是unbufferred chan，不然value buffer肯定有数据嘛，这个时候接收goroutine将从send goroutine queue中unshift出一个发送goroutine，并将该发送goroutine要发送的数据接收过来（两个goroutine一个有发送数据地址，一个有接收数据地址，拷贝过来就ok），然后这个取出的发送goroutine将恢复执行，这个接收goroutine也可以继续执行。这种情况下，chan接收操作也是non-blocking操作。\n3）另一种情况，如果value buffer和send goroutine queue都是空的，没有数据可接收，将把该接收goroutine push到chan的recv goroutine queue，该接收goroutine将转入blocking状态，什么时候恢复期执行呢，要等到有一个goroutine尝试向chan发送数据的时候了。这种场景下，chan接收操作是blocking操作。\n1.2 chan操作规则2 # 当一个goroutine常识向一个non-nil \u0026amp; non-closed chan发送数据的时候，该goroutine将先尝试获取chan上的锁，然后执行如下操作直到满足其中一种情况。\n1）如果chan的recv goroutine queue不空，这种情况下，value buffer一定是空的。发送goroutine将从recv goroutine queue中unshift出一个recv goroutine，然后直接将自己要发送的数据拷贝到该recv goroutine的接收地址处，然后恢复该recv goroutine的运行，当前发送goroutine也继续执行。这种情况下，chan send操作是non-blocking操作。\n2）如果chan的recv goroutine queue是空的，并且value buffer不满，这种情况下，send goroutine queue一定是空的，因为value buffer不满发送goroutine可以发送完成不可能会阻塞。该发送goroutine将要发送的数据push到value buffer中然后继续执行。这种情况下，chan send操作是non-blocking操作。\n3）如果chan的recv goroutine queue是空的，并且value buffer是满的，发送goroutine将被push到send goroutine queue中进入阻塞状态。等到有其他goroutine尝试从chan接收数据的时候才能将其唤醒恢复执行。这种情况下，chan send操作是blocking操作。\n1.3 chan操作规则3 # 当一个goroutine尝试close一个non-nil \u0026amp; non-closed chan的时候，close操作将依次执行如下操作。\n1）如果chan的recv goroutine queue不空，这种情况下value buffer一定是空的，因为如果value buffer如果不空，一定会继续unshift recv goroutine queue中的goroutine接收数据，直到value buffer为空（这里可以看下chan send操作，chan send写入数据之前，一定会从recv goroutine queue中unshift出一个recv goroutine）。recv goroutine queue里面所有的goroutine将一个个unshift出来并返回一个val=0值和sentBeforeClosed=false。\n2）如果chan的send goroutine queue不空，所有的goroutine将被依次取出并生成一个panic for closing a close chan。在这close之前发送到chan的数据仍然在chan的value buffer中存着。\n1.4 chan操作规则4 # 一旦chan被关闭了，chan recv操作就永远也不会阻塞，chan的value buffer中在close之前写入的数据仍然存在。一旦value buffer中close之前写入的数据都被取出之后，后续的接收操作将会返回val=0和sentBeforeClosed=true。\n1.5 小结 # 理解这里的goroutine的blocking、non-blocking操作对于理解针对chan的select-case操作是很有帮助的。下面介绍select-case实现机制。\n2 select-case实现 # 2.1 select-case原理简述 # select-case中假如没有default分支的话，一定要等到某个case分支满足条件然后将对应的goroutine唤醒恢复执行才可以继续执行，否则代码就会阻塞在这里，即将当前goroutine push到各个case分支对应的ch的recv或者send goroutine queue中，对同一个chan也可能将当前goroutine同时push到recv、send goroutine queue这两个队列中。\n不管是普通的chan send、recv操作，还是select chan send、recv操作，因为chan操作阻塞的goroutine都是依靠其他goroutine对chan的send、recv操作来唤醒的。前面我们已经讲过了goroutine被唤醒的时机，这里还要再细分一下。\nchan的send、recv goroutine queue中存储的其实是一个结构体指针*sudog，成员gp *g指向对应的goroutine，elem unsafe.Pointer指向待读写的变量地址，c *hchan指向goroutine阻塞在哪个chan上，isSelect为true表示select chan send、recv，反之表示chan send、recv。g.selectDone表示select操作是否处理完成，即是否有某个case分支已经成立。\n2 select-case执行流程 # 2.1 chan操作阻塞的goroutine唤醒时执行逻辑 # 下面我们先描述下chan上某个goroutine被唤醒时的处理逻辑，假如现在有个goroutine因为select chan 操作阻塞在了ch1、ch2上，那么会创建对应的sudog对象，并将对应的指针*sudog push到各个case分支对应的ch1、ch2上的send、recv goroutine queue中，等待其他协程执行(select) chan send、recv操作时将其唤醒： 1）源码文件chan.go，假如现在有另外一个goroutine对ch1进行了操作，然后对ch1的goroutine执行unshift操作取出一个阻塞的goroutine，在unshift时要执行方法 **func (q waitq) dequeue() sudog，这个方法从ch1的等待队列中返回一个阻塞的goroutine。\nfunc (q *waitq) dequeue() *sudog { for { sgp := q.first if sgp == nil { return nil } y := sgp.next if y == nil { q.first = nil q.last = nil } else { y.prev = nil q.first = y sgp.next = nil // mark as removed (see dequeueSudog) } // if a goroutine was put on this queue because of a // select, there is a small window between the goroutine // being woken up by a different case and it grabbing the // channel locks. Once it has the lock // it removes itself from the queue, so we won't see it after that. // We use a flag in the G struct to tell us when someone // else has won the race to signal this goroutine but the goroutine // hasn't removed itself from the queue yet. if sgp.isSelect { if !atomic.Cas(\u0026amp;sgp.g.selectDone, 0, 1) { continue } } return sgp } }  假如队首元素就是之前阻塞的goroutine，那么检测到其sgp.isSelect=true，就知道这是一个因为select chan send、recv阻塞的goroutine，然后通过CAS操作将sgp.g.selectDone设为true标识当前goroutine的select操作已经处理完成，之后就可以将该goroutine返回用于从value buffer读或者向value buffer写数据了，或者直接与唤醒它的goroutine交换数据，然后该阻塞的goroutine就可以恢复执行了。\n这里将sgp.g.selectDone设为true，相当于传达了该sgp.g已经从刚才阻塞它的select-case块中退出了，对应的select-case块可以作废了。有必要提提一下为什么要把这里的sgp.g.selectDone设为true呢？直接将该goroutine出队不就完了吗？不行！考虑以下对chan的操作dequeue是需要先拿到chan上的lock的，但是在尝试lock chan之前有可能同时有多个case分支对应的chan准备就绪。看个示例代码：\n// g1 go func() { ch1 \u0026lt;- 1\u2028}() // g2 go func() { ch2 \u0026lt;- 2 } select { case \u0026lt;- ch1: doSomething() case \u0026lt;- ch2: doSomething() }  协程g1在 chan.chansend方法中执行了一般，准备lock ch1，协程g2也执行了一半，也准备lock ch2; 协程g1成功lock ch1执行dequeue操作，协程g2页成功lock ch2执行deq	ueue操作； 因为同一个select-case块中只能有一个case分支允许激活，所以在协程g里面加了个成员g.selectDone来标识该协程对应的select-case是否已经成功执行结束（一个协程在某个时刻只可能有一个select-case块在处理，要么阻塞没执行完，要么立即执行完），因此dequeue时要通过CAS操作来更新g.selectDone的值，更新成功者完成出队操作激活case分支，CAS失败的则认为该select-case已经有其他分支被激活，当前case分支作废，select-case结束。\n这里的CAS操作也就是说的多个分支满足条件时，golang会随机选择一个分支执行的道理。\n2.2 select-case块golang是如何执行处理的 # 源文件select.go中方法 *selectgo(sel hselect) ，实现了对select-case块的处理逻辑，但是由于代码篇幅较长，这里不再复制粘贴代码，感兴趣的可以自己查看，这里只简要描述下其执行流程。\nselectgo逻辑处理简述：\n 预处理部分 对各个case分支按照ch地址排序，保证后续按序加锁，避免产生死锁问题； pass 1 部分处理各个case分支的判断逻辑，依次检查各个case分支是否有立即可满足ch读写操作的。如果当前分支有则立即执行ch读写并回，select处理结束；没有则继续处理下一分支；如果所有分支均不满足继续执行以下流程。 pass 2 没有一个case分支上chan操作立即可就绪，当前goroutine需要阻塞，遍历所有的case分支，分别构建goroutine对应的sudog并push到case分支对应chan的对应goroutine queue中。然后gopark挂起当前goroutine，等待某个分支上chan操作完成来唤醒当前goroutine。怎么被唤醒呢？前面提到了chan.waitq.dequeue()方法中通过CAS将sudog.g.selectDone设为1之后将该sudog返回并恢复执行，其实也就是借助这个操作来唤醒。 pass 3 整个select-case块已经结束使命，之前阻塞的goroutine已被唤醒，其他case分支没什么作用了，需要废弃掉，pass 3部分会将该goroutine从之前阻塞它的select-case块中各case分支对应的chan recv、send goroutine queue中移除，通过方法chan.waitq.dequeueSudog(sgp *sudog)来从队列中移除，队列是双向链表，通过sudog.prev和sudog.next删除sudog时间复杂度为O(1)。  3 总结 # 本文简要描述了golang中select-case的实现逻辑，介绍了goroutine与chan操作之间的协作关系。之前ZMQ作者Martin Sustrik仿着golang写过一个面向c的库，libmill，实际实现思路差不多，感兴趣的也可以翻翻看，libmill源码分析。\n"}),a.add({id:425,href:"/tags/chrome/",title:"chrome",description:"",content:""}),a.add({id:426,href:"/blog/2018-03-02-chrome%E5%88%86%E5%B1%8F%E9%98%85%E8%AF%BB%E6%8F%92%E4%BB%B6pagesplit/",title:"chrome分屏阅读插件：pagesplit",description:"chrome优秀的扩展性使得它成为很多开发人员的首选浏览器，不少开发人员在使用Vim或者IDE阅读源码时，都存在vsplit/hsplit分屏的习惯，那么在通过浏览器浏览网络上的代码或者页面时，如何在浏览器页面中实现类似Vim的分屏功能呢？本文结合作者的个人项目pagesplit来介绍下如何开发一个chrome分屏阅读插件。",content:" img { width: 680px; padding-bottom: 1rem; }  前言 # 这几天在钻研golang，经常在网上看些源码分析的文章，既然是源码分析就少不了code和分析的各种穿插描述，文章篇幅一长或者code block块比较长，经常需要滚动鼠标上下翻页，这种阅读体验好差劲。心想要是能够将web页面进行类似于vim的vsplit或者lsplit就好了。于是就有了这个chrome扩展。\n产品调研 # chrome网上应用商店中搜索了一下，找到了几个类似功能的插件“split tabs”、“tab resize”，体验之后不太满足个人需要。原因是：这两个扩展都是通过创建一个新的浏览器窗口来打开当前web页面，然后并排显示（支持水平、垂直并排显示），如下图。 这种实现方式，实际使用时存在如下几个缺点：\n  工作中，我们打开的应用程序窗口可能会很多，比如rtx，各种ide，各种终端……这样alt+tab切几次之后就难受了，需要手动将两个浏览器窗口给选择出来并排显示。不好用！\n  工作中，可能工作用的web标签页有很多，各种运维平台，各种视图，各种管理后台……如果在浏览器窗口中选择了其他的tab，再次切换回之前的tab比较困难，也不容易回到初始的并排显示状态。不好用！\n  解决方案 # 个人感觉还是同一个tab下能够vsplit、split比较方便，chrome网上应用商店找不到合适的了，google了一下，找到另一款扩展：\u0026ldquo;Frame two pages\u0026rdquo;，这个插件在功能上能满足需要，能够实现同一个tab下vsplit、split，如下图所示：\n但是其在使用时比较繁琐，当我们打开一个web页面，希望对其进行vsplit操作时，页面会弹出一个提示窗口，输入split方式，然后会执行对应的分割方式，看上去不错，但是有几个问题让人用起来很难受：\n 没有考虑浏览器的X-Frame-Options对iframe的影响，使用过程中会“莫名其妙”地split失败，比如我正在写这篇文章，来测试一下vsplit什么效果，如下图，并没有成功vsplit；   不实用，如果选择的tab索引index大于0，会将index-1和index进行并排展示，至少与我的页面分割的初衷不一致；  于是乎，我想改进下这个插件为我所用，说不定也可以方便大家，本着不重复造轮子的原则，安装上了这个Frame two pages扩展看了下它的代码，了解了chrome扩展的大致写法，然后对其进行了一些修改，基本符合我的功能性要求。\n设计实现 # 现在实现的功能包括：\n1）点击插件按钮，选择split方式，支持对当前已经打开的web页面进行split、vsplit分割。\n以垂直分割当前web页面为例，首先点击扩展图标，选择分割方式为vertical分割。\n就得到了如下效果的分割页面，这个页面是在原页面tab之后创建的一个tab，不影响原来的tab。\n2）忽略所有页面的X-Frame-Options选项，保证可以打开页面（为了安全使用者自己决定用不用吧），为了使用方便我我忽略掉了所有的X-Frame-Options，使得iframe可以正常加载。\n3）某些情况下可能希望分割的两部分分别展示不同的页面，也是支持的，需要在一个空白的tab页上点击页面分割，此时会展示出如下输入url的输入框，然后点击下方的按钮就可以了。\n比如一个进百度，一个进google。\n4）我觉得存在这样的使用情景，比如正在看一个博客时，希望打开搜索引擎检索部分信息，一般我们都是打开一个新的标签页进搜索引擎，看完搜索结果后再跳回原来的tab……阅读期间可能要多次跳来跳去……希望能在已经成功vsplit、split的页面里面，将其中一个reset允许我们重新输入url打开新的页面。\n于是为这个插件加了菜单：\n以重置vsplit后的左半部分页面为例，选择“Split Page -\u0026gt; Reset left/top page”。\n左半部分就被重置到重新输入url的状态了，比如希望进入google，输入google网址，点击跳转按钮即可。\n总结 # 简要了解了chrome extension的开发过程，chrome不同的版本迭代过程中增加了很多安全限制，开发、调试过程中要多注意。这只是为了平时阅读代码方便二次开发的一个小工具，另外对js了解的不多，可能存在bug，也欢迎反馈。\n感兴趣的可以从github下载进行体验，仓库地址：https://github.com/hitzhangjie/PageSplit。\n"}),a.add({id:427,href:"/tags/extension/",title:"extension",description:"",content:""}),a.add({id:428,href:"/tags/hsplit/",title:"hsplit",description:"",content:""}),a.add({id:429,href:"/tags/pagesplit/",title:"pagesplit",description:"",content:""}),a.add({id:430,href:"/tags/vsplit/",title:"vsplit",description:"",content:""}),a.add({id:431,href:"/blog/2017-10-14-assembly-language/",title:"Assembly Language",description:"现在高级语言这么方便、编译器这么牛，还需要掌握汇编语言吗？我认为需要，至少要能看懂，有些对性能要求很高、希望调优的场景下，可能要直接用汇编来实现，如字符串拷贝，等等。而且高级语言借助系统调用的方式，有时也存在局限性，比如有需要开关中断的场景，就必须要借助内联汇编。所以掌握汇编至少不是一件坏事。",content:"处理器是算逻运算、控制操作的执行部件，它只能识别机器指令并执行动作。机器指令是一系列的0、1字符串，本质上对应了总线上的高低电平信号，所以机器语言都是特定于硬件的。\n由于0、1字符串很难记忆，用机器语言开发是一个老大难的问题，汇编语言因此被开发出来用于代替机器语言。汇编指令只是机器指令中操作码的助记符，因此汇编语言仍然是机器强相关的，不同的处理器其对应的汇编指令也不同。\n学习汇编语言有助于理解：\n 程序是如何与操作系统、处理器、bios进行交互的； 数据如何在内存中以及外设中表示的； 处理器如何访问、执行指令； 指令如何访问、处理数据； 程序如何访问外设；  其他使用汇编语言的优势：\n 消耗更少的内存和处理器执行时间； 允许以更简单的方式来完成硬件特定的复杂作业； 适用于时间敏感的作业； 适用于编写中断服务程序和内存驻留程序；  1.1 PC硬件的基本特征 # 机器指令是0、1字符串，分别表示ON、OFF，对应数字信号的高低电平。机器中的最低存储单位是bit，通常8bit构成一个byte，为了对数据传输过程中传输数据的有效性进行检查，通常会在数据byte发送之后再追加一个奇偶校验bit。\n 奇校验：保证8bit数据+1bit校验位中的1的个数为奇数； 偶校验：保证8bit数据+1bit校验位中的1的个数为偶数；  发送方、接收方遵循相同的奇偶校验规则，如果接收方收到数据后发现奇偶校验不正确，则表示可能硬件出错，或者出现了电平扰动。\n处理器支持如下数据尺寸：\n|:\u0026mdash;|:\u0026mdash;\u0026mdash;| |Word|2 bytes| |Doubleword|4 bytes| |Quadword|8 bytes| |Paragraph|16 bytes| |Kilobyte|2^10 bytes| |Megabyte|2^20 bytes|\n二进制 \u0026amp; 十六进制系统：\n二进制天然适用于计算机计算领域，0、1刚好代表数字电路中的高低电平；而十六进制是用于对比较长的二进制数值进行更加优雅地简写，使我们表示起来更加清晰、简单。\n二进制、十六进制的相关运算，特别是涉及到原码、反码、补码、移码的运算，需要重点了解下，建议参考《计算机组成原理》相关章节。\n访问内存中的数据：\n处理器控制指令执行的过程可以简化为”取指令-指令移码-指令执行“的循环体，一个”取指令-指令译码-指令执行“周期称之为一个机器周期。\n 取指周期：根据CS、IP从内存指定位置取指令，并存储到指令寄存器IR； 译码周期：根据IR中的指令，分析出操作码OP、操作数或操作数地址； 执行周期：根据分析出的OP、操作数或操作地址信息执行相应的动作；  Intel架构的处理器在内存中存储时是采用的小端字节序，意味着一个多字节数值的低字节部分将在低地址存储，高字节部分将在高地址存储，但是在处理器寄存器中存储时低字节部分就在低字节，高字节部分就在高字节，所以在处理器寄存器、内存之间存储、加载数据时需要做字节序方面的转换。\n以处理器寄存器中数值0x1234为例，现在要将其存储到内存中，处理器先将0x34存储到内存低地址，然后再见0x12存储到内存高地址；假如内存中有数据0xabcd，现在要将其加载到处理器寄存器中，加载时也会做对应的处理，将0xab放在寄存器高位，将0xcd放在寄存器低位。\n指令中的操作数地址，又有多种不同的寻址方式，立即数寻址、直接寻址、间接寻址、寄存器寻址等，这里后面会做相应的介绍。\n1.2 开发环境配置 # 汇编指令特定于处理器的，因此不同的处理器系列、型号对应的汇编指令可能也会有差异，这里使用的是Intel-32架构的处理器，使用汇编器NASM进行汇编操作，其他可选的汇编器还有MASM、TASM、GAS等。\n1.3 基本语法 # 汇编程序通常包括3个节，分别是data、bss、text节：\n data，用于声明初始化的变量和常量； bss，用于声明未初始化的变量，这部分不会出现在编译后的程序中； text，用于保存程序指令；  text节中必须包括\u0026quot;global ${entry}\u0026ldquo;声明，${entry}是程序入口，通常定义未_start，见文生义嘛。\n汇编程序中的注释均以\u0026rdquo;;\u0026ldquo;开头，直到所在行结束。\n汇编语言程序包括3种不同类型的语句：\n 可执行汇编指令； 传递给汇编器的指令或伪操作； 宏；  汇编语言语句遵循如下结构：\n[标识] 助记符 [操作数] [;注释]   []内部的部分是可选的，尤其是标识和注释部分，根据汇编指令的不同，有无操作数、操作数个数、操作数类型等均有所不同。汇编指令中包括了操作码和操作数相关信息，这里的助记符其实就是操作码的符号表示。\n 下面是应用了上述基本语法的示例程序：\nhello.asm\nsection	.text global _start ;must be declared for linker (ld) _start:	;tells linker entry point mov	edx,len ;message length mov	ecx,msg ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data msg db 'Hello, world!', 0xa ;string to be printed len equ $ - msg ;length of the string  在Linux平台下由汇编文件构建可执行程序包括如下两个步骤：\n 汇编，nasm -f elf -o hello.o hello.asm 连接，ld -m elf_i386 -e _start -o hello hello.o  构建完成，即可在命令行执行./hello来进行测试。\n1.4 内存分段 # 前面一节介绍了汇编语言中的section（节），这些节也代表着各种各样的内存segment（段）。将前面示例代码hello.asm中的section关键字用segment代替，依然可以用相同的方法构建成功并得到相同的测试结果。\n汇编语言中常见的segment（段）包括：\n data segment，数据段代表了data section和bss section。其中data section用于存储初始化后的全局变量和全局变量；bss section用于声明未初始化的全局变量和静态变量，在程序运行时会被初始化未0值。 code segment，代码段也就是text节，用于存储程序指令； stack segment，堆栈段用于分配临时变量、调用函数时传递参数信息等；  1.5 寄存器 # 处理器主要是用来进行计算，计算所需要的数据来自于内存，但是处理器存取内存数据需要的时间比较长，为了ALU加速存取操作数，处理器里面内置了寄存器，将内存中的数据先加载到寄存器中，然后ALU对寄存器中的数据进行计算，最后再将计算结果搬回内存。\n处理器中的寄存器主要包括如下几类：\n 通用目的寄存器，包括数据寄存器（EAX、EBX、ECX、EDX）、指针寄存器（EIP、ESP、EBP）、索引寄存器（ESI、EDI）；   函数调用过程中会形成栈帧，ebp寄存器指向的是栈帧的栈底，esp指向的值栈帧的栈顶。通过ebp便于定位传递给函数的参数、返回地址信息，栈帧开始构建的时候，首先就会将caller的ebp压栈，然后将当前栈帧栈顶esp赋值给ebp作为新的栈帧的栈底，后面esp减去一个值N,[esp-N,ebp）就是新的栈空间。\n  段寄存器，包括ECS、ESS、EDS；   8086里面，CS包括代码段的起始地址，从80386进入保护模式开始，CS里面变成了段选择符，具体的代码段起始地址要到gdb里面去查。DS存储数据段的起始地址，SS存储堆栈段的起始地址。\n  控制寄存器，32位flags寄存器和32位指令指针寄存器共同称为控制寄存器。   常见的flag标志位包括：OF（溢出）、DF（字符串比较方向）、IF（是否允许中断）、TF（是否单步执行）、SF（符号位）、ZF（比较结果）、AF（辅助进位）、PF（1数量是否为奇数）、CF（是否进位）。\n 下面是一个使用多个寄存器的示例程序：\nsection	.text global _start	;must be declared for linker (gcc) _start:	;tell linker entry point mov	edx,len ;message length mov	ecx,msg ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	edx,9 ;message length mov	ecx,s2 ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data msg db 'Displaying 9 stars',0xa ;a message len equ $ - msg ;length of message s2 times 9 db '*'  1.6 系统调用 # 系统调用是操作系统内核提供的用户态、内核态之间的接口，用户态通过系统调用访问内核服务。\n如何通过在汇编程序里面使用系统调用呢？\n 在EAX寄存器里面设置系统调用号； 在EBX、ECX、EDX、ESI、EDI、EBP中设置系统调用参数（如果参数数量超过6个，则需特殊处理）； 调用中断服务int 0x80（系统调用都是通过中断服务的形式实现，int指令使得处理器从ring3切换到ring0，iret使处理器从ring0切换回ring3）； 系统调用的返回值通常保存在EAX中；  Linux下的系统调用定义在/usr/include/asm/unistd.h中，可以从中查看系统调用名称以及编号。下面是一个综合使用系统调用read、write、exit的例子，程序提示用户输入一个数字并读取用户输入，然后回显该数字。\nsection .data ;Data segment userMsg db 'Please enter a number: ' ;Ask the user to enter a number lenUserMsg equ $-userMsg ;The length of the message dispMsg db 'You have entered: ' lenDispMsg equ $-dispMsg section .bss ;Uninitialized data num resb 5 section .text ;Code Segment global _start _start: ;User prompt mov eax, 4 mov ebx, 1 mov ecx, userMsg mov edx, lenUserMsg int 80h ;Read and store the user input mov eax, 3 mov ebx, 2 mov ecx, num mov edx, 5 ;5 bytes (numeric, 1 for sign) of that information int 80h ;Output the message 'The entered number is: ' mov eax, 4 mov ebx, 1 mov ecx, dispMsg mov edx, lenDispMsg int 80h ;Output the number entered mov eax, 4 mov ebx, 1 mov ecx, num mov edx, 5 int 80h ; Exit code mov eax, 1 mov ebx, 0 int 80h  1.7 寻址模式 # 汇编语言中的寻址模式可以分为两类，一类是指令寻址，一类是数据寻址：\n 指令寻址：处理器要执行的指令如何寻址，分为顺序寻址（顺序执行，pc+=1）、跳跃寻址（jmp）； 数据寻址：根据数据所在存储位置的不同（内存或寄存器），以及地址提供方式的不同，数据寻址方式多种多样。  数据寻址方式虽然多样，但是都遵从如下指令格式：\n|:\u0026ndash;:|:\u0026ndash;:|:\u0026ndash;:| |操作码OP|寻址特征|形式地址A|\n根据寻址特征以及形式地址A，可以计算出操作数的有效地址EA，不同的寻址特征对形式地址A施加的计算规则也不一样。下面总结一下常见的数据寻址方式。\n 立即寻址，A是立即数（常量），EA=A； 寄存器寻址，A是寄存器编号，EA=A=Ri； 直接内存寻址，A为数据在内存中的有效地址，即EA=A； 直接内存偏移量寻址，类似于基址寻址方式，EBX做基地址，A为offset； 间接内存寻址，(A)为数据在内存中的有效地址，即EA=(A),间接内存寻址可能还会涉及到多重间址；   计算机组成原理中可能提到的数据寻址方式更加偏重于理论，寻址方式也更加多样，实际的汇编语言实现中可能并没有逐一实现，或者区分不明显，我们这里从实践出发，更加侧重于实用而不是理论，因此在使用术语的选择上也更加偏重于业内人员的偏好。\n 在汇编语言中，获取一个内存变量的有效地址的方式是：[varname]。\n下面是一个综合使用了上述多种寻址方式的示例程序：\nsection	.text global_start ;must be declared for linker (ld) _start: ;tell linker entry point ;writing the name 'Zara Ali' mov	edx,9 ;message length mov	ecx, name ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	[name], dword 'Nuha' ; Changed the name to Nuha Ali ;writing the name 'Nuha Ali' mov	edx,8 ;message length mov	ecx,name ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data name db 'Zara Ali '  1.8 定义变量 # 汇编语言中提供了多个汇编器指令用于定义变量、预留内存空间。\nsection .data，为初始化的数据分配存储空间:\nvarname define-directive initial-value[,initial-value2]  常用的define-directive包括DB、DW、DD、DQ、DT，分别用于定义1byte、1word、1doubleword、1quadword、10bytesd并进行初始化操作。\nsection .bss，为未初始化的数据分配存储空间：\n[varname] reserve-directive quantity  常用的reserve-directie指令包括RESB、RESW、RESD、RESQ、REST，分别用于分配1byte、1word、1doubleword、1quadword、10bytes的存储空间，结合操作数quantity可以计算出需要分配多少空间。\n.bss节每一个对应的define-directive语句都有一个对应的reserve-directive与之对应，reserve-directive也可以单独存在，如下所示：\nsection .bss age db resb 1 ;只预留空间没关联变量 num resb 1 ;预留空间并绑定变量  times directive允许多个变量初始化为相同的值：\nvarname times quantity define-directive [intiail-val]  注意times指令也可以用于.bss节，但是.bss节汇编的时候不会进行初始化，程序启动的时候才会进行0初始化。\n 如果没有提供initial-val，会提示没有初始值不进行初始化； 如果提供了intiail-val，会提示.bss节忽略了初始值不进行初始化操作；  1.9 定义常量 # 汇编语言中定义常量的指令包括3个，分别是EQU、%assign、%define。\nconst-name EQU value ;可以定义字符串或者数值常量 %assign const-name value ;只可以定义数值常量，可以重定义 %define const-name value ;可以定义字符串或者数值常量  前面曾多次使用EQU进行常量定义，这里就不再提供其他示例程序了。\n1.10 算术指令 # 汇编语言中的算术运算指令包括：\n INC、DEC，自增、自减一个寄存器或者内存变量的值，结果保存到当前操作数； ADD、SUB，加、减一个寄存器或者内存变量的值，结果保存到第一个操作数； MUL、IMUL，分别处理无符号、有符号数的乘法，保存存储遵循如下规则：  8位乘法，如：AL * 8bit_source = AH AL，结果高8位保存到AH、低8位保存到AL； 16位乘法，如：AX * 16bit_source = DX AX，结果高16位保存到DX，低16位保存到AX； 32位乘法，如：EAX * 32bit_source = EDX EAX，结果高32位保存到EDX，低32位保存到EAX；   DIV、IDIV，分别处理无符号、有符号数的除法，结果存储遵循如下规则：  16位除法，如：AX / 8bit_source = AL\u0026hellip;AH，商保存到AL，余数保存到AH； 32位除法，如：DX AX / 16bit_source = AX\u0026hellip;DX，被除数高16位在DX、低16位在AX，结果商在AX、余数在DX； 64位除法，如：EDX EAX / 32bit_source = EAX\u0026hellip;EDX，被除数高32位在EAX、低32位在EAX，结果商在EAX、余数在EDX；    1.11 逻辑指令 # 汇编语言中的逻辑运算指令包括：\n AND，逻辑与运算，结果保存到第一个操作数； OR，逻辑或运算，结果保存到第一个操作数； NOT，对当前操作数求反，结果保存到当前操作数； XOR，异或运算，结果保存到第一个操作数； TEST，测试运算，不会改变操作数的值，但运算会影响ZF标识；  1.12 分支控制 # 通过某些循环、分支指令可以实现分支语句，这里对应的汇编指令主要都是基于处理器中的标识寄存器来实现的。\n常用指令包括：\n 比较指令\nCMP，比较两个操作数是否相同、谁大谁小，需结合其他条件转移指令使用； 无条件转移指令\nJMP，无条件跳转到制定的指令地址处执行； 条件转移指令 有符号数、无符号数通用的包括：JE/JZ，JNE/JNZ； 无符号数特有的包括：JG、JGE、JL、JLE等； 有符号数特有的包括：JA、JAE、JB、JBE等； 特殊用途的包括：JC、JNC、JO、JNO、JS、JNS等；  这里涉及到的条件转移指令比较多，这里不一一进行描述了，有需要的话读者朋友可以参考”分支控制指令“，或者可以参考intel指令集了解更多的细节。\n1.13 循环控制 # 借助条件转移指令实现循环\n条件转移指令可以用于实现循环控制，循环控制次数可以存储在ECX寄存器中，循环体内动作每执行一次将ECX值减1，根据ECX值是否为0决定是否进行循环。下面就是一个根据这个简单思路实现的循环体：\nMOV	CL, 10 L1: \u0026lt;LOOP-BODY\u0026gt; DEC	CL JNZ	L1  借助内置的loop指令实现循环\n汇编语言内部提供了指令loop来实现循环，起实现方式跟我们上面说的是一样的，loop指令会检查当前ECX寄存器的值是否为0，为0则退出循环，大于0则执行DEC ECX并继续执行循环体。\n下面是一个借助loop指令实现的循环体版本，书写上也更加简练：\nMOV	CL, 10 L1: \u0026lt;LOOP-BODY\u0026gt; loop L1  1.14 数字 # 前面我们读入一个数位数值的时候需要将其减去'0\u0026rsquo;之后得到其真实数值，运算结果写出之前也需要将数位数值加上'0\u0026rsquo;再写出，为啥？这里涉及到ASCII码与数值之间的转换。\n上述处理方式虽然比较直观，但是负载比较大，汇编语言中有更加高效的处理方式，即以二进制形式对其进行处理。\n十进制数字有两种表示形式：\n ASCII码形式\n输入的十进制数字每个数位都用ASCII来表示，十进制数字1234的4个数位分别被编码为对应的ASCII码字符，各个字符对应的十进制值分别为：31 32 33 34，共占用了4个字节； BCD码形式  如果是unpacked BCD编码形式，输入的十进制数字每个数位都用1字节的二进制形式来表示，十进制数字1234的4个数位分别被编码为：01 02 03 04，共占用4个字节。 如果是packed BCD编码形式，输入的十进制数字每个数位用4bit来表示，十进制数字1234的4个数位被编码为：12 34，共占用2个字节。    运算完成之后，可能会涉及到某些ASCII、BCD码之间的转换动作，可以借助于对应的汇编调整指令来实现。\n1.15 字符串 # 计算字符串长度\n前面我们指定一个字符串的长度的时候，可以通过变量来显示地指明，也可以通过**”$-msg“**来计算出来，使用后者的时候我们需要为msg字符串尾部添加一个哨兵字符，例如：\nmsg db 'hello world',0xa len db $-msg  $代表的是当前的offset，offset-db正好是msg中字符的数量，不包括0xa，如果不添加0xa这个字符哨兵的话，len就应该定义成**\u0026quot;$-msg+1\u0026rdquo;**。\n字符串操作指令：\n MOVS，移动一个字符串； LODS，从内存中装载字符串； STOS，存储字符串到内存； CMPS，比较字符串； SCAS，比较寄存器和内存中的字符串； REP/REPZ/REPNZ，便利字符串并针对各个字符重复执行某个操作；  1.16 数组 # 定义数组，主要有如下几种方式，我们以定义一个byte数组为例分别说明。\n定义数组方式一：\nnumbers db 0,1,2,3,4,5  定义数组方式二：\nnumbers db 0 db 1 db 2 db 3 db 4 db 5  这种方式应该比较少用，方式一其实是这种方式的简化版。\n定义数组方式三：\nnumbers times 6 db 0  这种方式定义的6个byte都被初始化为相同的值0。\n还是要根据自己的需要来选择合适的数组定义方式。\n下面示例程序定义了一个数组byte数组x，然后以循环的形式遍历x中的元素并求和：\nsection	.text global _start ;must be declared for linker (ld) _start:	mov eax,3 ;number bytes to be summed mov ebx,0 ;EBX will store the sum mov ecx, x ;ECX will point to the current element to be summed top: add ebx, [ecx] add ecx,1 ;move pointer to next element dec eax ;decrement counter jnz top ;if counter not 0, then loop again done: add ebx, '0' mov [sum], ebx ;done, store result in \u0026quot;sum\u0026quot; display: mov edx,1 ;message length mov ecx, sum ;message to write mov ebx, 1 ;file descriptor (stdout) mov eax, 4 ;system call number (sys_write) int 0x80 ;call kernel mov eax, 1 ;system call number (sys_exit) int 0x80 ;call kernel section	.data global x x: db 2 db 4 db 3 sum: db 0  1.17 函数 # 汇编语言中函数是非常重要的一个组成部分，定义函数的语法如下：\nfunction_name: \u0026lt;function_body\u0026gt; ret  程序中调用一个函数的指令为call：\ncall \u0026lt;function_name\u0026gt;  下面示例代码总定义了一个求和函数：\nsection	.text global _start ;must be declared for using gcc _start:	;tell linker entry point mov	ecx,'4' sub ecx, '0' mov edx, '5' sub edx, '0' call sum ;call sum procedure mov [res], eax mov	ecx, msg	mov	edx, len mov	ebx,1	;file descriptor (stdout) mov	eax,4	;system call number (sys_write) int	0x80	;call kernel mov	ecx, res mov	edx, 1 mov	ebx, 1	;file descriptor (stdout) mov	eax, 4	;system call number (sys_write) int	0x80	;call kernel mov	eax,1	;system call number (sys_exit) int	0x80	;call kernel sum: mov eax, ecx add eax, edx add eax, '0' ret section .data msg db \u0026quot;The sum is:\u0026quot;, 0xA,0xD len equ $- msg segment .bss res resb 1  栈stack，是一种后进先出LIFO的数据结构，汇编语言提供了指令push、pop来进行入栈、出栈操作。\n1.18 递归 # 递归操作，指的是一个函数func在执行过程中会调用这个函数自身的情况。递归又可以细分为直接递归和间接递归。\n 直接递归，函数func的函数体中会调用自身； 间接递归，函数func的函数体中调用了其他的函数，而这个被调用的函数中又调用了函数func；  有些问题适合用递归算法来解决，递归比较容易理解，但是对栈空间消耗可能会超出系统允许的上限导致栈溢出问题，此时需要将递归算法转换为非递归算法。\n1.19 宏 # 汇编语言中可以将常用的、可能多次重复使用的指令序列以宏macro的形式进行封装，在程序中可以多次调用。\n定义宏的形式为：\n%macro macro_name params_quantity \u0026lt;macro_body\u0026gt; %endmacro  调用宏的形式为：\nmacro_name param1, param2  下面的示例程序中，将输出字符串的指令序列以宏的形式进行了封装：\n; A macro with two parameters ; Implements the write system call %macro write_string 2 mov eax, 4 ;sys_write mov ebx, 1 ;stdout mov ecx, %1 ;param1, buf mov edx, %2 ;param2, buf_len int 80h ;call kernel %endmacro section	.text global _start ;must be declared for using gcc _start: ;tell linker entry point write_string msg1, len1 write_string msg2, len2 write_string msg3, len3 mov eax,1 ;sys_exit int 0x80 ;call kernel section	.data msg1 db	'Hello, programmers!',0xA,0xD len1 equ $ - msg1	msg2 db 'Welcome to the world of,', 0xA,0xD len2 equ $- msg2 msg3 db 'Linux assembly programming! ' len3 equ $- msg3  1.20 文件操作 # Linux内核提供了一系列文件操作的系统调用，常用的几个系统调用如下：\n sys_open sys_close sys_creat sys_read sys_write sys_lseek   系统调用编号可以在/usr/include/asm/unistd.h中检查到，系统调用参数、返回值信息可以借助Linux man手册进行查询。\n 汇编语言里面对于上述系统调用的调用与前面sys_read、sys_write示例程序中的使用方式是一致的，都按照如下几个步骤进行调用：\n 将系统调用的编号设置到EAX； 将系统调用的参数依次设置到EBX、ECX、EDX、ESI、EDI、EBX； 触发内核中断int 80h； 检查EAX中保存的系统调用返回值；  如下示例程序对文件相关的系统调用进行了组合使用，首先创建一个文件并写入数据，然后关闭，再重新打开文件并读取文件内容，最后在stdout上打印文件内容。\nsection	.text global _start ;must be declared for using gcc _start: ;tell linker entry point ;create the file mov eax, 8 mov ebx, file_name mov ecx, 0777 ;read, write and execute by all int 0x80 ;call kernel mov [fd_out], eax ; write into the file mov	edx,len ;number of bytes mov	ecx, msg ;message to write mov	ebx, [fd_out] ;file descriptor mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel ; close the file mov eax, 6 mov ebx, [fd_out] ; write the message indicating end of file write mov eax, 4 mov ebx, 1 mov ecx, msg_done mov edx, len_done int 0x80 ;open the file for reading mov eax, 5 mov ebx, file_name mov ecx, 0 ;for read only access mov edx, 0777 ;read, write and execute by all int 0x80 mov [fd_in], eax ;read from file mov eax, 3 mov ebx, [fd_in] mov ecx, info mov edx, 26 int 0x80 ; close the file mov eax, 6 mov ebx, [fd_in] ; print the info mov eax, 4 mov ebx, 1 mov ecx, info mov edx, 26 int 0x80 mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data file_name db 'myfile.txt' msg db 'Welcome to Tutorials Point' len equ $-msg msg_done db 'Written to file', 0xa len_done equ $-msg_done section .bss fd_out resb 1 fd_in resb 1 info resb 26  1.21 内存管理 # Linux内核提供了系统调用sys_brk来分配堆内存区域，sys_brk实际上是增加了进程最大可动态申请的内存地址的上限，brk分配的内存区域（堆）仅仅挨着.data节，系统调用sys_brk参数为0时会返回当前可申请内存的最大地址，参数不为0时会调整当前brk边界。\n下面的示例程序通过系统调用sys_brk来动态分配了16KB的内存空间：\nsection	.text global _start ;must be declared for using gcc _start:	;tell linker entry point mov	eax, 45	;sys_brk xor	ebx, ebx int	80h add	eax, 16384	;number of bytes to be reserved mov	ebx, eax mov	eax, 45	;sys_brk int	80h cmp	eax, 0 jl	exit	;exit, if error mov	edi, eax	;EDI = highest available address sub	edi, 4	;pointing to the last DWORD mov	ecx, 4096	;number of DWORDs allocated xor	eax, eax	;clear eax std	;backward rep	stosd ;repete for entire allocated area cld	;put DF flag to normal state mov	eax, 4 mov	ebx, 1 mov	ecx, msg mov	edx, len int	80h	;print a message exit: mov	eax, 1 xor	ebx, ebx int	80h section	.data msg db	\u0026quot;Allocated 16 kb of memory!\u0026quot;, 10 len equ	$ - msg  1.22 总结 # 这里结合tutorialspoint上的汇编语言教程对相关的知识点进行了简要回顾，也有所收获，这里也分享给需要的同学。\n"}),a.add({id:432,href:"/tags/protobuf/",title:"protobuf",description:"",content:""}),a.add({id:433,href:"/tags/protoc/",title:"protoc",description:"",content:""}),a.add({id:434,href:"/tags/protoc-gen-go/",title:"protoc-gen-go",description:"",content:""}),a.add({id:435,href:"/blog/2017-05-23-protoc%E5%8F%8A%E6%8F%92%E4%BB%B6%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E7%B2%BE%E5%8D%8E%E7%89%88/",title:"Protoc及其插件工作原理分析(精华版)",description:"团队经常使用protobuf作为消息交换格式，由于protobuf具有很强的自描述性，非常适合对一个服务进行建模。结合配套的编译器protoc，可以轻松理解服务信息，在此基础上可以开发一些脚手架工具（如protoc-gen-go）来完成代码生成、接口自动测试、生成api文档等等工作。本文就来介绍下protoc及其插件的工作原理，读完后读者将具备定制化protoc插件开发的能力。",content:"在进行protoc插件开发之前，首先要了解protoc的工作原理。protobuf具有诸多优点被广泛使用，由于protoc对proto文件的强大解析能力使我们可以更进一步来开发一些插件，通过插件快速生成特定于proto文件的工具类、配置文件等，从而提高开发效率。\n本文首先会介绍一下protoc的整体工作原理，然后详细介绍一下protoc对proto文件的解析过程，最后给出编写protoc插件来扩展protoc功能的一个示例（这里以protoc-gen-go插件为例）。\n1. protoc工作原理分析 # 1.0. protoc源代码准备 # 要想了解protoc的工作机制，查看其源代码了解其核心流程是最靠谱的方法。\n获取程序源代码的方式如下：\ngit co https://github.com/google/protobuf  由于我们工程中常用的protoc版本是v2.5.0，所以这里检出对应版本的tag。\ngit ck v2.5.0  考虑到可能会进行测试、修改、注释等学习过程，这里最好创建一个新的分支来操作。\ngit branch -b ${new-branch-name}  现在源代码准备好了，下面可以阅读protoc的源码梳理一下其工作原理了。\n上述git检出后的protobuf路径，记为${protobuf}，后面如果出现${protobuf}请知晓其含义。如果在描述源代码时没有提及代码起始路径${protobuf}，那么起始路径均为${protobuf}。\n1.1. protoc执行流程说明 # protoc执行流程的相关源码，主要包括如下两个部分。\n1.1.1. protoc程序入口 # protoc程序入口为以下源文件main函数，该入口函数中完成protoc命令行接口初始化、编程语言及代码生成器注册后，调用cli.Run(argc,argv)解析proto文件并生成特定语言的源代码。\nfile: src/google/protobuf/compiler/main.cc\n// Author: kenton@google.com (Kenton Varda) // 这个头文件定义了protoc的命令行接口 #include \u0026lt;google/protobuf/compiler/command_line_interface.h\u0026gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include \u0026lt;google/protobuf/compiler/cpp/cpp_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/python/python_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/java/java_generator.h\u0026gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件 // - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头 // - 假定protoc --foo_out，那么实际调用的插件是protoc-foo google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(\u0026quot;protoc-\u0026quot;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator) google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026quot;--cpp_opt\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ header and source.\u0026quot;); // Proto2 Java (指定了--java_out将调用java::Generator) google::protobuf::compiler::java::JavaGenerator java_generator; cli.RegisterGenerator(\u0026quot;--java_out\u0026quot;, \u0026amp;java_generator, \u0026quot;Generate Java source file.\u0026quot;); // Proto2 Python (指定了python_out将调用python::Generator) google::protobuf::compiler::python::Generator py_generator; cli.RegisterGenerator(\u0026quot;--python_out\u0026quot;, \u0026amp;py_generator, \u0026quot;Generate Python source file.\u0026quot;); return cli.Run(argc, argv); }  1.1.2. 命令接口cli.Run(argc,argv)执行流程 # cli.Run(\u0026hellip;)中，完成对proto文件的读取、解析，并通过注册的代码生成器或者protoc插件生成特定语言源代码，并最终完成源代码文件的创建。\nint CommandLineInterface::Run(int argc, const char* const argv[]) { Clear(); // 解析命令行参数 switch (ParseArguments(argc, argv)) { case PARSE_ARGUMENT_DONE_AND_EXIT: return 0; case PARSE_ARGUMENT_FAIL: return 1; case PARSE_ARGUMENT_DONE_AND_CONTINUE: break; } // 设置源码树 DiskSourceTree source_tree; for (int i = 0; i \u0026lt; proto_path_.size(); i++) { source_tree.MapPath(proto_path_[i].first, proto_path_[i].second); } ... // 分配一个importer(负责解析proto文件并创建对应的FileDescriptor对象) Importer importer(\u0026amp;source_tree, \u0026amp;error_collector); // 解析成功后的proto文件都会通过一个对应的FileDescriptor来表示 vector\u0026lt;const FileDescriptor*\u0026gt; parsed_files; // 解析输入的proto文件 for (int i = 0; i \u0026lt; input_files_.size(); i++) { // 解析单个proto文件 const FileDescriptor* parsed_file = importer.Import(input_files_[i]); if (parsed_file == NULL) return 1; parsed_files.push_back(parsed_file); // 如果指定了--disallow_services则拒绝处理proto中service定义 if (disallow_services_ \u0026amp;\u0026amp; parsed_file-\u0026gt;service_count() \u0026gt; 0) { cerr \u0026lt;\u0026lt; parsed_file-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: This file contains services, but \u0026quot; \u0026quot;--disallow_services was used.\u0026quot; \u0026lt;\u0026lt; endl; return 1; } } // 为每个输出位置构造一个单独的GeneratorContext对象，有可能多个代码生成器的输出 // 位置是相同的，这种情况下，多个代码生成器应该共用同一个GeneratorContext对象以 // 使得OpenForInsert()能正常工作 typedef hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; GeneratorContextMap; GeneratorContextMap output_directories; // 针对proto文件生成特定语言的源代码 if (mode_ == MODE_COMPILE) { // 一次处理一个输出指令(--foo_out=params:dir) for (int i = 0; i \u0026lt; output_directives_.size(); i++) { string output_location = output_directives_[i].output_location; if (!HasSuffixString(output_location, \u0026quot;.zip\u0026quot;) \u0026amp;\u0026amp; !HasSuffixString(output_location, \u0026quot;.jar\u0026quot;)) { AddTrailingSlash(\u0026amp;output_location); } // 当前输出指令中的输出目录可能已经被记录下来了 GeneratorContextImpl** map_slot = \u0026amp;output_directories[output_location]; // - 如果没有记录下来则分配一个关联的GeneratorContextImpl对象 if (*map_slot == NULL) { *map_slot = new GeneratorContextImpl(parsed_files); } // - 参考输出指令，将解析成功的proto文件，生成对应的源代码信息， // 这些信息会被记录在GeneratorContextImpl *map_slot中 if (!GenerateOutput(parsed_files, output_directives_[i], *map_slot)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } // 创建源代码文件，并将生成的源代码信息写会磁盘 for (GeneratorContextMap::iterator iter = output_directories.begin(); iter != output_directories.end(); ++iter) { const string\u0026amp; location = iter-\u0026gt;first; GeneratorContextImpl* directory = iter-\u0026gt;second; if (HasSuffixString(location, \u0026quot;/\u0026quot;)) { // 创建当前目录下所有的源代码文件 if (!directory-\u0026gt;WriteAllToDisk(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } else { if (HasSuffixString(location, \u0026quot;.jar\u0026quot;)) { directory-\u0026gt;AddJarManifest(); } if (!directory-\u0026gt;WriteAllToZip(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } ... return 0; }  1.1.3. protoc执行逻辑总结 # 通过查看2.1.1、2.1.2两部分代码，可以对protoc的执行流程做一个简单的概括：\n  protoc main中初始化命令行参数接口cli;\n  开启以protoc-为前缀的插件作为第三方代码生成器使用，cli.AllowPlugins(\u0026ldquo;protoc-\u0026quot;)；\n  注册编程语言cpp、java、python及对应的代码生成器，cli.RegisterGenerator(\u0026hellip;)；\n  解析proto文件并运行代码生成器或者protoc插件生成特定语言源代码、创建源代码文件，cli.Run(argc, argv);\n Clear()清空所有的数据备用； ParseArguments(argc,argv)解析参数，对于protoc的某些内置参数的检查，对某些插件相关的\u0026ndash;${lang}_out参数的检查等，将\u0026ndash;${lang}_out作为输出指令保存起来；  struct OutputDirective { string name; // E.g. \u0026quot;--foo_out\u0026quot; CodeGenerator* generator; // NULL for plugins string parameter; string output_location; };  ``\n 参数解析成功之后，继续执行处理，设置源代码树、映射输入文件到虚拟路径、分配importer； 针对每个输入的proto文件进行解析，const FileDescriptor* parsed_file = importer.Import(input_files_[i])，解析成功后的文件会被加入到vector\u0026lt;FileDescriptor*\u0026gt; parsed_files中记录，每一个proto文件解析后都可以用一个FileDescriptor结构体来表示；   备注： 这里解析proto文件的过程是这样的，首先将proto文件中的内容分割成一个个的token，将内容拆分成一个个词素并检查有效性，也就是词法分析。如果词法分析检查无误则进入后续的语法分析过程，parser对输入token串进行文法相关的分析检查是否可以构成一棵有效的语法分析树，如果可以则表示语法正确。\n // Token定义如下 struct Token { TokenType type; string text; // The exact text of the token as it appeared in // the input. e.g. tokens of TYPE_STRING will still // be escaped and in quotes. // \u0026quot;line\u0026quot; and \u0026quot;column\u0026quot; specify the position of the first character of // the token within the input stream. They are zero-based. int line; int column; int end_column; }; // Token类型定义如下 enum TokenType { TYPE_START, // Next() has not yet been called. TYPE_END, // End of input reached. \u0026quot;text\u0026quot; is empty. TYPE_IDENTIFIER, // A sequence of letters, digits, and underscores, not // starting with a digit. It is an error for a number // to be followed by an identifier with no space in // between. TYPE_INTEGER, // A sequence of digits representing an integer. Normally // the digits are decimal, but a prefix of \u0026quot;0x\u0026quot; indicates // a hex number and a leading zero indicates octal, just // like with C numeric literals. A leading negative sign // is NOT included in the token; it's up to the parser to // interpret the unary minus operator on its own. TYPE_FLOAT, // A floating point literal, with a fractional part and/or // an exponent. Always in decimal. Again, never // negative. TYPE_STRING, // A quoted sequence of escaped characters. Either single // or double quotes can be used, but they must match. // A string literal cannot cross a line break. TYPE_SYMBOL, // Any other printable character, like '!' or '+'. // Symbols are always a single character, so \u0026quot;!+$%\u0026quot; is // four tokens. };  `` 语法分析的过程这里就不解释了，感兴趣的可以看一下protobuf中grammar的定义，无非也就是些规约的事情，只要能够按照grammar将词法分析输出的token串构建出一棵完整的语法分析树proto文件就是合法的，否则就是不合法的，至于语法分析过程中伴随的语义分析过程，语义分析过程中执行哪些语义动作，不说也知道，肯定是生成某些“中间代码”之类的鬼东西。学过编译原理的这些处理过程应该都是比较清楚的，这里就不再展开了。语法分析成功之后就得到了proto对应的FileDescriptor对象，因为可能输入的是多个proto，所以多个FileDescriptor就用vector来存储了。\n 遍历之前记录下来的输出指令OutputDirective output_directives[]，output_directives[i].output_location指明了输出目录，针对输出目录创建GeneratorContextImpl，并记录到hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; output_directories这个map中，key为flag_out,如\u0026ndash;foo_out，value为GeneratorContextImpl。由于可能多个\u0026ndash;${lang}_out都指向相同的输出目录，所以同一个GeneratorContextImpl也存在复用的情况。每个GeneratorContextImpl记录了一个输出目录、所有该目录下的待创建的源代码文件的信息，待创建的源代码文件信息记录在map\u0026lt;string,string*\u0026gt; files_里面，key为源代码文件名，val为源代码文件的内容，另外还包括了一个vector\u0026lt;FileDescriptor*\u0026gt; parsed_files记录了所有解析成功的proto文件信息。 遍历output_directives的同时，因为同一个output_directives[i]对应的输出目录下可能有多个源代码文件要输出，并且不管flag_name是什么，要处理的proto文件都是相同的，所以每个output_directives[i]都会对其调用GenerateOutput(parsed_files, output_directives[i], *map_slot)，output_directives[i].plugin指明了语言的代码生成器(为NULL则使用插件)，对所有的解析成功的proto文件parsed_files[i]生成源代码，源代码全部输出到output_directive[i].output_location下，源代码的文件名都记录在parsed_files[i].name()里面，而最终生成的源代码信息都存储在这里的CodeGeneratorImpl **map_slot中，也就相当于存储在了output_directories[]中。 最后遍历output_directories[]，将每个输出目录下要写的所有文件的数据全部写出到磁盘，即output_directories[i]-\u0026gt;WriteAllToDisk()。 done！    了解从proto到源代码生成的关键之处就是2.1.2节中cli.Run(\u0026hellip;)方法中调用的GenerateOutput是怎么实现的，接着看。\n1.1.4 protoc CommandLineInterface::GenerateOutput(\u0026hellip;)实现 # 下面看下GenerateOutput方法到底执行了哪些操作。\n// 根据输出指示, 为解析成功的proto文件调用代码生成器生成对应的代码并存储到generator_context //@param parsed_files 所有解析成功的proto文件，每个解析成功的proto文件都用一个FileDescriptor来表示 //@param output_directive 输出指示，其指明了目标语言、语言对应的代码生成器、输出目录等 //@param generator_context 代码生成器上下文，可记录生成的代码 bool CommandLineInterface::GenerateOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const OutputDirective\u0026amp; output_directive, GeneratorContext* generator_context) { string error; // 如果输出指令中没有设置对应的代码生成器，表明没有在protoc main中注册语言对应的代码生成器， // 这种情况下需要继续搜索是否存在对应的protoc插件来支持，若存在则调用该插件来充当代码生成器 if (output_directive.generator == NULL) { // 这种情况下使用的是${PATH}中可搜索到的protoc插件 GOOGLE_CHECK(HasPrefixString(output_directive.name, \u0026quot;--\u0026quot;) \u0026amp;\u0026amp; HasSuffixString(output_directive.name, \u0026quot;_out\u0026quot;)) \u0026lt;\u0026lt; \u0026quot;Bad name for plugin generator: \u0026quot; \u0026lt;\u0026lt; output_directive.name; // 实际上protoc搜索插件对应的可执行程序的时候，搜索的名称是“protoc-gen-”+“语言”， // 如果我们调用的是protoc --foo_out，那么实际搜索的就是protoc-gen-foo。 string plugin_name = plugin_prefix_ + \u0026quot;gen-\u0026quot; + output_directive.name.substr(2, output_directive.name.size() - 6); // 调用protoc插件来生成代码，这是我们要重点看的，我们就是要实现自己的protoc插件 if (!GeneratePluginOutput(parsed_files, plugin_name, output_directive.parameter, generator_context, \u0026amp;error)) { cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } else { // 这种是protoc main函数中正常注册的编程语言对应的代码生成器 string parameters = output_directive.parameter; if (!generator_parameters_[output_directive.name].empty()) { if (!parameters.empty()) { parameters.append(\u0026quot;,\u0026quot;); } parameters.append(generator_parameters_[output_directive.name]); } // 为每个解析成功的proto文件生成代码 for (int i = 0; i \u0026lt; parsed_files.size(); i++) { if (!output_directive.generator-\u0026gt;Generate(parsed_files[i], parameters, generator_context, \u0026amp;error)) { // Generator returned an error. cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; parsed_files[i]-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } } return true; }  1.1.5. protoc调用插件生成代码的执行逻辑 # 下面再来看一下GeneratePluginOutput是如何工作的。\n// 调用protoc插件为解析成功的proto文件生成代码 //@param parsed_files 解析成功的文件 //@param plugin_name protoc插件名称（这个是拼接出来的protoc-gen-${lang}） //@param parameter 传给插件的参数 //@param generator_context 代码生成器上下文，可记录生成的代码 //@param error 代码生成过程中的错误信息 bool CommandLineInterface::GeneratePluginOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const string\u0026amp; plugin_name, const string\u0026amp; parameter, GeneratorContext* generator_context, string* error) { // protoc生成一个代码生成请求，并发送给插件 CodeGeneratorRequest request; // protoc插件根据接收到的代码生成请求生成代码，并发送响应给protoc CodeGeneratorResponse response; // Build the request. if (!parameter.empty()) { request.set_parameter(parameter); } set\u0026lt;const FileDescriptor*\u0026gt; already_seen; for (int i = 0; i \u0026lt; parsed_files.size(); i++) { request.add_file_to_generate(parsed_files[i]-\u0026gt;name()); GetTransitiveDependencies(parsed_files[i], true, // Include source code info. \u0026amp;already_seen, request.mutable_proto_file()); } // fork出一个子进程，子进程来执行插件完成代码生成工作， // 父子进程之间是通过管道通信完成请求、响应过程，如何控制子进程的stdin、stdout， // 这个可以通过dup2或者dup3来控制间fd 0、1分别设置到管道的读端、写端。 // 事实上protobuf的开发人员也是这么来实现的。 // 子进程通过exec来搜索执行插件程序 Subprocess subprocess; if (plugins_.count(plugin_name) \u0026gt; 0) { subprocess.Start(plugins_[plugin_name], Subprocess::EXACT_NAME); } else { subprocess.Start(plugin_name, Subprocess::SEARCH_PATH); } string communicate_error; // 请求插件生成代码 if (!subprocess.Communicate(request, \u0026amp;response, \u0026amp;communicate_error)) { *error = strings::Substitute(\u0026quot;$0: $1\u0026quot;, plugin_name, communicate_error); return false; } // Write the files. We do this even if there was a generator error in order // to match the behavior of a compiled-in generator. scoped_ptr\u0026lt;io::ZeroCopyOutputStream\u0026gt; current_output; for (int i = 0; i \u0026lt; response.file_size(); i++) { const CodeGeneratorResponse::File\u0026amp; output_file = response.file(i); if (!output_file.insertion_point().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据已经存在，定位到准确的插入点位置执行写入，然后关闭文件 // - 这里的插入点如何定义，我们在后面再进行说明。具体可参考plugin.proto和plugin.pb.h。 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;OpenForInsert(output_file.name(), output_file.insertion_point())); } else if (!output_file.name().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据不存在，不存在插入点信息，从开始处执行写入 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;Open(output_file.name())); } else if (current_output == NULL) { *error = strings::Substitute( \u0026quot;$0: First file chunk returned by plugin did not specify a file name.\u0026quot;, plugin_name); return false; } // 从CodeGeneratorResponse中获取输出流，写出，这里输出流中的数据时存储在GeneratorContextImpl中的， // GenerateOutput调用成功之后后面会遍历每一个GenerateContextImpl完成WriteAllToDisk()的操作。 // Use CodedOutputStream for convenience; otherwise we'd need to provide // our own buffer-copying loop. io::CodedOutputStream writer(current_output.get()); writer.WriteString(output_file.content()); } // 检查有没有错误 if (!response.error().empty()) { // Generator returned an error. *error = response.error(); return false; } return true; }  1.1.6. protoc \u0026amp; protoc插件数据交互的执行逻辑 # 整体执行逻辑差不多理清楚了，然后这里我们需要看一下父进程给子进程发送的代码生成请求是什么，收到的代码生成的响应又是什么，以及父子进程通信的细节、子进程对请求的处理过程等。\n先来看下plugin.proto的定义，protoc内置的支持语言里面并不包含go，我们后面需要用go来编写我们自己的插件，所以必须使用protoc的go插件来生成go对应的plugin.go代码，然后我们自己写一些业务类插件（非语言插件）的时候才能用上plugin.go。扯这么多是为了让大家明白这里为什么需要看下plugin.proto，而不是误解为只是在堆砌内容。看了这里的plugin.proto之后才能理解到protoc中的插件机制的边界时什么，我们就可以明白利用protoc的插件机制，我们可以做到什么程度，哪些功能能实现，哪些实现不了，这个是很重要的。\nfile: src/google/protobuf/compiler/plugin.proto\n// protoc (aka the Protocol Compiler) can be extended via plugins. A plugin is // just a program that reads a CodeGeneratorRequest from stdin and writes a // CodeGeneratorResponse to stdout. // // Plugins written using C++ can use google/protobuf/compiler/plugin.h instead // of dealing with the raw protocol defined here. // // A plugin executable needs only to be placed somewhere in the path. The // plugin should be named \u0026quot;protoc-gen-$NAME\u0026quot;, and will then be used when the // flag \u0026quot;--${NAME}_out\u0026quot; is passed to protoc. package google.protobuf.compiler; option java_package = \u0026quot;com.google.protobuf.compiler\u0026quot;; option java_outer_classname = \u0026quot;PluginProtos\u0026quot;; import \u0026quot;google/protobuf/descriptor.proto\u0026quot;; // 发送给插件的代码生成请求 // An encoded CodeGeneratorRequest is written to the plugin's stdin. message CodeGeneratorRequest { // The .proto files that were explicitly listed on the command-line. The // code generator should generate code only for these files. Each file's // descriptor will be included in proto_file, below. //proto文件列表对应的要生成的文件的源代码文件的名字 repeated string file_to_generate = 1; // The generator parameter passed on the command-line. //传递给插件代码生成器的参数 optional string parameter = 2; // FileDescriptorProtos for all files in files_to_generate and everything // they import. The files will appear in topological order, so each file // appears before any file that imports it. // // protoc guarantees that all proto_files will be written after // the fields above, even though this is not technically guaranteed by the // protobuf wire format. This theoretically could allow a plugin to stream // in the FileDescriptorProtos and handle them one by one rather than read // the entire set into memory at once. However, as of this writing, this // is not similarly optimized on protoc's end -- it will store all fields in // memory at once before sending them to the plugin. // 每一个正确解析的proto文件都用一个FileDescriptorProto来表示； // 这里的FileDescriptorProto与FileDescriptor其实是对应的，在请求插件进行代码 // 生成的时候直接就有这样的代码FileDescriptor::CopyTo(FileDescriptorProto\u0026amp;) // 的用法。而在descriptor.h和descriptor.proto中查看二者的描述时，其注释清清 // 楚楚地写着都是描述的一个完整的proto文件。 repeated FileDescriptorProto proto_file = 15; } // 插件返回的代码生成响应 // The plugin writes an encoded CodeGeneratorResponse to stdout. message CodeGeneratorResponse { // Error message. If non-empty, code generation failed. The plugin process // should exit with status code zero even if it reports an error in this way. // // This should be used to indicate errors in .proto files which prevent the // code generator from generating correct code. Errors which indicate a // problem in protoc itself -- such as the input CodeGeneratorRequest being // unparseable -- should be reported by writing a message to stderr and // exiting with a non-zero status code. // 错误信息 optional string error = 1; // Represents a single generated file. // 生成的源代码文件消息类型，注意这里是一个内部类型 message File { // 待生成的源代码文件名（相对于输出目录），文件名中不能包括.或者..，路径是 // 相对输出目录的路径，不能用绝对路径，另分隔符必须用/。 // 如果name没有指定，那么输出的内容将追加到前一个输出的源代码文件中，这种 // 方式使得代码生成器能够将一个大文件的生成分多次写入来完成，不用一次性将很 // 大数据量的数据放在内存中。这里需要指出的是，protoc中并没有针对这种情况 // 进行特殊的优化，它等待读取完整的CodeGeneratorResponse再写出到磁盘。 optional string name = 1; // 如果insertion_point不空的话，name字段也不能为空，并且假定name字段指定的 // 文件已经存在了。这里的内容将被插入到name指定的文件中的特定插入点（注解）的 // 上一行。这有助于扩展代码生成器输出的内容。在一次protoc调用中，可能会同 // 时指定多个protoc插件，前面的插件可能会在输出的内容中指定插入点，后面的 // 插件可能会在这些指定的插入点的位置继续扩展代码内容。 // 例如，前面的一个插件在输出的代码内容中增加了这样一行注解： // @@protoc_insertion_point(NAME) // 这样就定义了一个插入点，插入点前面、后面可以包含任意的文本内容，即使在 // 注释里面也是可以的。这里的插入点定义中的NAME应该可以唯一标识一个插入点 // 才可以，类似于标识符，以供其他的插件使用，插件插入代码的时候将从插入点 // 的上一行开始自行插入。如果包含多个插入点的话，插入点的内容将被插件依次 // 扩展。 // // 一开始创建这个源代码文件的代码生成器或者插件与后面的继续扩展源代码插入 // 点位置内容的代码生成器或者插件，必须在protoc的同一次调用中，代码生成器 // 或者插件按照protoc命令行调用过程中指定的顺序依次调用。 optional string insertion_point = 2; // 待写入到源代码中的内容 optional string content = 15; } // 一次要处理的 proto文件可能有多个，所以插件处理后这里的file是一个list repeated File file = 15; }  下面看一下protoc与protoc插件这对父子进程之间是怎么通信的。\nclass LIBPROTOC_EXPORT Subprocess { public: Subprocess(); ~Subprocess(); enum SearchMode { SEARCH_PATH, // Use PATH environment variable. EXACT_NAME // Program is an exact file name; don't use the PATH. }; // Start the subprocess. Currently we don't provide a way to specify // arguments as protoc plugins don't have any. void Start(const string\u0026amp; program, SearchMode search_mode); // Serialize the input message and pipe it to the subprocess's stdin, then // close the pipe. Meanwhile, read from the subprocess's stdout and parse // the data into *output. All this is done carefully to avoid deadlocks. // Returns true if successful. On any sort of error, returns false and sets // *error to a description of the problem. bool Communicate(const Message\u0026amp; input, Message* output, string* error); // win32 relevant ... neglect private: #ifdef _WIN32 // ... #else // !_WIN32 pid_t child_pid_; // The file descriptors for our end of the child's pipes. We close each and // set it to -1 when no longer needed. int child_stdin_; int child_stdout_; #endif };  下面是Linux平台下的子进程启动处理逻辑。\nvoid Subprocess::Start(const string\u0026amp; program, SearchMode search_mode) { // Note that we assume that there are no other threads, thus we don't have to // do crazy stuff like using socket pairs or avoiding libc locks. // [0] is read end, [1] is write end. int stdin_pipe[2]; int stdout_pipe[2]; GOOGLE_CHECK(pipe(stdin_pipe) != -1); GOOGLE_CHECK(pipe(stdout_pipe) != -1); char* argv[2] = { strdup(program.c_str()), NULL }; child_pid_ = fork(); if (child_pid_ == -1) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;fork: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } else if (child_pid_ == 0) { // We are the child. // 将子进程的stdin重定向到stdin_pipe的读端 dup2(stdin_pipe[0], STDIN_FILENO); // 将子进程的stdout重定向到stdout_pipe的写端 dup2(stdout_pipe[1], STDOUT_FILENO); // 子进程通过0、1对管道进行操作就够了，释放多余的fd close(stdin_pipe[0]); close(stdin_pipe[1]); close(stdout_pipe[0]); close(stdout_pipe[1]); // 根据程序搜索模式调用exec族函数来调用插件执行，exec族函数通过替换当前进 // 程的代码段、数据段等内存数据信息，然后调整寄存器信息，使得进程转而去执 // 行插件的代码。插件代码执行之前进程就已经将fd 0、1重定向到父进程clone过 // 来的管道了，因此插件程序的输出将直接被输出到父进程创建的管道中。 // 正常情况下，exec一旦执行成功，那么久绝不对执行switch后续的代码了，只有 // 出错才可能会执行到后续的代码。 switch (search_mode) { case SEARCH_PATH: execvp(argv[0], argv); break; case EXACT_NAME: execv(argv[0], argv); break; } // 只有出错才可能会执行到这里的代码。 // Write directly to STDERR_FILENO to avoid stdio code paths that may do // stuff that is unsafe here. int ignored; ignored = write(STDERR_FILENO, argv[0], strlen(argv[0])); const char* message = \u0026quot;: program not found or is not executable\\n\u0026quot;; ignored = write(STDERR_FILENO, message, strlen(message)); (void) ignored; // Must use _exit() rather than exit() to avoid flushing output buffers // that will also be flushed by the parent. _exit(1); } else { free(argv[0]); // 父进程释放无用的fd close(stdin_pipe[0]); close(stdout_pipe[1]); // 子进程的stdin，对父进程来说也就是管道stdin_pipe的写端，CodeGeneratorRequest将通过这个fd写给子进程 child_stdin_ = stdin_pipe[1]; // 子进程的stdout，对父进程来说也就是管道stdout_pipe的读端，CodeGeneratorResponse将通过这个fd从子进程读取 child_stdout_ = stdout_pipe[0]; } }  下面接着看父进程读取子进程返回的CodeGeneratorResponse的执行逻辑。\n//protoc进程和protoc插件进程通信 // //@param protoc进程发送到protoc插件进程的代码生成请求 //@param protoc插件进程返回给protoc进程的代码生成响应 //@param error 错误信息 bool Subprocess::Communicate(const Message\u0026amp; input, Message* output, string* error) { GOOGLE_CHECK_NE(child_stdin_, -1) \u0026lt;\u0026lt; \u0026quot;Must call Start() first.\u0026quot;; // The \u0026quot;sighandler_t\u0026quot; typedef is GNU-specific, so define our own. typedef void SignalHandler(int); // 屏蔽信号SIGPIPE，防止没有指定信号处理函数的情况下被kill掉 SignalHandler* old_pipe_handler = signal(SIGPIPE, SIG_IGN); string input_data = input.SerializeAsString(); string output_data; int input_pos = 0; int max_fd = max(child_stdin_, child_stdout_); // child_stdout==-1的时候表示子进程返回的数据已经读取完毕了，可以gg了 while (child_stdout_ != -1) { fd_set read_fds; fd_set write_fds; FD_ZERO(\u0026amp;read_fds); FD_ZERO(\u0026amp;write_fds); if (child_stdout_ != -1) { FD_SET(child_stdout_, \u0026amp;read_fds); } if (child_stdin_ != -1) { FD_SET(child_stdin_, \u0026amp;write_fds); } // 这种情景下也用select，果然很google！ if (select(max_fd + 1, \u0026amp;read_fds, \u0026amp;write_fds, NULL, NULL) \u0026lt; 0) { if (errno == EINTR) { // 被信号中断了，再次尝试 continue; } else { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;select: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // stdout_pipe写事件就绪，写请求CodeGeneratorRequest给子进程 if (child_stdin_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdin_, \u0026amp;write_fds)) { int n = write(child_stdin_, input_data.data() + input_pos, input_data.size() - input_pos); if (n \u0026lt; 0) { // Child closed pipe. Presumably it will report an error later. // Pretend we're done for now. input_pos = input_data.size(); } else { input_pos += n; } // 代码生成请求已经成功写给子进程了，关闭相关的fd if (input_pos == input_data.size()) { // We're done writing. Close. close(child_stdin_); child_stdin_ = -1; } } // stdin_pipe读事件就绪，读取子进程返回的CodeGeneratorResponse if (child_stdout_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdout_, \u0026amp;read_fds)) { char buffer[4096]; int n = read(child_stdout_, buffer, sizeof(buffer)); if (n \u0026gt; 0) { output_data.append(buffer, n); } else { // 子进程返回的CodeGeneratorResponse已经读取完毕，关闭相关的fd close(child_stdout_); child_stdout_ = -1; } } } // 子进程还没有读取CodeGeneratorRequest完毕，就关闭了输出，这种情况下也不可 // 能读取到返回的CodeGeneratorResponse了，这种情况很可能是出现了异常。 if (child_stdin_ != -1) { // Child did not finish reading input before it closed the output. // Presumably it exited with an error. close(child_stdin_); child_stdin_ = -1; } // 等待子进程结束，子进程退出之后，需要父进程来清理子进程占用的部分资源。 // 如果当前父进程不waitpid的话，子进程的父进程会变为init或者systemd进程，同 样也会被清理的。 int status; while (waitpid(child_pid_, \u0026amp;status, 0) == -1) { if (errno != EINTR) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;waitpid: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // 刚才为了阻止SIGPIPE信号到达时导致进程终止，我们修改了SIGPIPE的信号处理函 // 数，这里可以恢复之前的SIGPIPE的信号处理函数。 signal(SIGPIPE, old_pipe_handler); // 根据子进程的退出状态执行后续的处理逻辑 // - 异常处理 if (WIFEXITED(status)) { if (WEXITSTATUS(status) != 0) { int error_code = WEXITSTATUS(status); *error = strings::Substitute(\u0026quot;Plugin failed with status code $0.\u0026quot;, error_code); return false; } } else if (WIFSIGNALED(status)) { int signal = WTERMSIG(status); *error = strings::Substitute(\u0026quot;Plugin killed by signal $0.\u0026quot;, signal); return false; } else { *error = \u0026quot;Neither WEXITSTATUS nor WTERMSIG is true?\u0026quot;; return false; } // 将子进程返回的串行化之后的CodeGeneratorResponse数据进行反串行化，反串行化 // 成Message对象，实际上这里的Message::ParseFromString(const string\u0026amp;)是个虚 // 函数，是被CodeGeneratorResponse这个类重写了的，反串行化过程与具体的类密切 // 相关，也必须在派生类中予以实现。 if (!output-\u0026gt;ParseFromString(output_data)) { *error = \u0026quot;Plugin output is unparseable.\u0026quot;; return false; } return true; }  到这里为止protoc进程的具体执行逻辑描述地已经很清楚了吧？下面再看下插件的执行逻辑。\n支持不同语言的插件的执行逻辑，总体上来讲都包括下面的执行逻辑，只是生成的目标源代码不同而已。插件就只是从stdin读取串行化之后的CodeGeneratorRequest请求，然后执行反串行化得到一个完整的CodeGeneratorRequest对象，然后根据请求进行必要的代码生成逻辑，确定要生成的源代码信息，并将其设置到CodeGeneratorResponse中并串行化后写入到stdout，插件的执行逻辑就这么简单。\n2. protoc插件工作原理分析 # 在第1节中结合protoc源代码对protoc的工作原理进行了较为详细地介绍，也重点介绍了采用protoc插件生成源代码的情况下protoc与protoc插件的交互过程。下面我们将以protoc-gen-go作为一个学习的范例来进一步理解一下插件的工作原理，也可以为我们后续开发protoc插件提供参考。\n2.1. protoc-gen-go源代码准备 # protoc-gen-go的源代码可以通过通过如下方式获取：\ngit co https://github.com/golang/protobuf git branch -b ${new-branch}  进行protoc插件开发，无非是基于解析后的proto文件生成特定语言（不一定是语言）的目标代码，要想正确地生成目标代码，首要条件就是要能够正确提取proto文件中的内容，而proto文件中定义的内容都可以通过descriptor.proto来描述。所以在我们深入protoc-gen-go的源代码之前，不妨先看下descriptor.proto的定义来看下protobuf是如何抽象、描述一个proto文件的。\n2.2. descriptor.proto，对proto文件的抽象\u0026amp;描述 # proto文件中的数据类型都是在descriptor.proto中定义好的，为了更好地帮助我们对proto文件中的数据类型进行解析，为了在插件开发过程中更加方便快速地获得与数据类型、变量、rpc等相关的相关内容，我们都需要深入地理解descriptor.proto中的相关定义以及从它延伸出来的一些概念、算法等。\n这部分的内容还不少，在不影响理解的大前提下，我还是稍微删减了些代码，避免对大家理解造成不必要的干扰。\nfile: src/google/protobuf/descriptor.proto\n// Author: kenton@google.com (Kenton Varda) // Based on original Protocol Buffers design by // Sanjay Ghemawat, Jeff Dean, and others. // descriptor.proto文件中的messages定义了proto文件中所能见到的所有的定义，一个有效的.proto文件在不提供其他信息（甚至不需要读取它的imports）能够直接被转换成一个FileDescriptorProto对象。 package google.protobuf; option java_package = \u0026quot;com.google.protobuf\u0026quot;; option java_outer_classname = \u0026quot;DescriptorProtos\u0026quot;; // descriptor.proto必须在速度方面优化，因为在启动过程中基于反射的算法不起作用 option optimize_for = SPEED; // protoc可以将解析的proto文件中的descriptor添加到FileDescriptorSet并输出到文件 message FileDescriptorSet { repeated FileDescriptorProto file = 1; } // 下面的message FileDescriptorProto可以用于描述一个完整的proto文件 message FileDescriptorProto { optional string name = 1; // proto文件名，file name，相对于源代码根目录 optional string package = 2; // proto包名，例如 \u0026quot;foo\u0026quot;、\u0026quot;foo.bar\u0026quot; repeated string dependency = 3; // proto文件中import进来的其他proto文件列表 repeated int32 public_dependency = 10; // 上面public import的proto文件在proto文件列表中的索引 // Indexes of the weak imported files in the dependency list. repeated int32 weak_dependency = 11; // 上面weak import的proto文件在proto文件列表中的索引，不要使用，只用于google内部的迁移 // proto文件中的所有顶层定义信息 repeated DescriptorProto message_type = 4; // 所有的消息(message)类型定义 repeated EnumDescriptorProto enum_type = 5; // 所有的枚举(enum)类型定义 repeated ServiceDescriptorProto service = 6; // 所有的服务(service)类型定义 repeated FieldDescriptorProto extension = 7; // 所有的扩展字段定义 optional FileOptions options = 8; // 文件选项 // 这个字段包括了源代码的相关信息，这里的信息可以给开发工具使用，也仅应该提供给开发工具使用； // 可以选择将这个字段中的信息删除，在程序运行期间并不会造成破坏。 optional SourceCodeInfo source_code_info = 9; } // 描述消息类型Message message DescriptorProto { optional string name = 1; // Message的类型名称 repeated FieldDescriptorProto field = 2; // Message中包括的字段列表 repeated FieldDescriptorProto extension = 6; // Message中包括的扩展列表 repeated DescriptorProto nested_type = 3; // Message中嵌套的Message类型列表 repeated EnumDescriptorProto enum_type = 4; // Message中嵌套的枚举类型列表 message ExtensionRange { optional int32 start = 1; optional int32 end = 2; } repeated ExtensionRange extension_range = 5; optional MessageOptions options = 7; } // 描述一个字段（字段可以是Message中的，也可以是某些扩展字段） message FieldDescriptorProto { // 字段数据类型 enum Type { // 0 is reserved for errors. // 由于历史方面的原因，这里的枚举值的顺序有点奇怪 TYPE_DOUBLE = 1; TYPE_FLOAT = 2; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT64 if // negative values are likely. TYPE_INT64 = 3; TYPE_UINT64 = 4; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT32 if // negative values are likely. TYPE_INT32 = 5; TYPE_FIXED64 = 6; TYPE_FIXED32 = 7; TYPE_BOOL = 8; TYPE_STRING = 9; TYPE_GROUP = 10; // Tag-delimited aggregate. TYPE_MESSAGE = 11; // Length-delimited aggregate. // New in version 2. TYPE_BYTES = 12; TYPE_UINT32 = 13; TYPE_ENUM = 14; TYPE_SFIXED32 = 15; TYPE_SFIXED64 = 16; TYPE_SINT32 = 17; // Uses ZigZag encoding. TYPE_SINT64 = 18; // Uses ZigZag encoding. }; // 字段修饰符optional、required、repeated enum Label { // 0 is reserved for errors LABEL_OPTIONAL = 1; LABEL_REQUIRED = 2; LABEL_REPEATED = 3; // TODO(sanjay): Should we add LABEL_MAP? }; optional string name = 1; // 字段名称 optional int32 number = 3; // 字段tag编号 optional Label label = 4; // 字段修饰符 // 如果type_name已设置，这个字段无须设置； // 如果这两个字段都设置了，这里的type字段必须是TYPE_ENUM类型或者TYPE_MESSAGE类型 optional Type type = 5; // 对于TYPE_ENUM或者TYPE_MESSAGE类型，type_name就是type的名字。 // 如果name以“.”开头那么它是完全保留的。对于C++来说，其作用域规则要求首先搜 // 索当前Message类型的嵌套类型，然后才是parent namespace中的类型，一直到root // namespace。 optional string type_name = 6; // 对于扩展，它就是被扩展的类型的名字，对它的解析与对type_name的解析时一样的 optional string extendee = 2; // 对于数值类型，存储了数值的文本表示形式； // 对于布尔类型，存储字符串\u0026quot;true\u0026quot;或\u0026quot;false\u0026quot;； // 对于字符串类型，存储原始的文本内容（未转义的） // 对于字节，存储了c转义后的值（所有\u0026gt;=128的字节都会被转义） // TODO(kenton)，基于base64编码的? optional string default_value = 7; optional FieldOptions options = 8; // 字段选项 } // 描述一个枚举类型enum message EnumDescriptorProto { optional string name = 1; // 枚举类型名称 repeated EnumValueDescriptorProto value = 2; // 枚举类型中包括的枚举值列表 optional EnumOptions options = 3; // 枚举类型选项 } // 描述一个枚举类型中的一个枚举值 message EnumValueDescriptorProto { optional string name = 1; // 枚举值对应的name optional int32 number = 2; // 枚举值对应的number（默认为0，依次递增） optional EnumValueOptions options = 3; // 枚举值选项 } // 描述一个rpc service. message ServiceDescriptorProto { optional string name = 1; // 服务名称 repeated MethodDescriptorProto method = 2; // 服务对应的方法列表 optional ServiceOptions options = 3; // 服务选项 } // 描述一个服务的方法 message MethodDescriptorProto { optional string name = 1; // 方法名称 optional string input_type = 2; // 方法入参类型 optional string output_type = 3; // 方法出参类型 optional MethodOptions options = 4; // 方法选项 } // =================================================================== // Options // 上面的每一个定义基本上都包括了选项option相关的字段，这些选项字段仅仅是一些 // 注解，这些注解会影响代码的生成，使得生成的代码稍有不同，注解也可能包含了操作 // message的代码的一些提示信息、说明信息。 // // clients可能会定义一些自定义的选项来作为*Options message的extensions，这些 // extensions在parsing阶段可能还无法确定下来，所以parser不能存储他们的值，而是 // 将这些自定义的选项先存储到一个*Options message里面，称之为 // uinterpreted_option。这个字段的名字在所有的*Options message里面都必须保证是 // 相同的。之后在我们构建descriptor的时候，这个时候所有的proto文件也都解析完了、 // 所有的extensions也都知道了，这个时候我们再用这里的uinterpreted_option字段去 // 填充那些extensions。 // // 用于自定义选项的extensions编号的选择一般遵循下面的方法： // * 对于只在一个应用程序或者组织内使用的选项，或者用于实验目的的选项，使用字 // 段编号50000~99999范围内的。对于多个选项，用户需要确保不使用相同的编号。 // * 对于可能被多个互不依赖的实体所共同使用的选项，需要给 // protobuf-global-extension-registry@google.com发邮件来申请预留扩展编号。需 // 要提供工程名称、工程站点，没必要解释为什么需要申请预留某个特定的编号。通 // 常只需要一个扩展编号，可以声明多个选项但是只使用这一个相同的扩展编号。如 // 果申请公共的扩展编号是个刚需，google可能会发布一个web service接口来自动分 // 配选项编号。 message FileOptions { // java包名，当前proto文件中生成的java类将位于这个package下 optional string java_package = 1; // 指定一个外部类名称，当前proto文件中生成的所有的类将被封装在这个外部类当中 optional string java_outer_classname = 8; // 如果设置为true，java代码生成器将为每个顶层message、enum、service定义生成 // 单独的java文件，默认为false optional bool java_multiple_files = 10 [default=false]; // 如果设置为true，java代码生成器将未每个message定义生成equals()、hashCode() // 方法，默认为false。本来AbstractMessage基类经包括了一个基于反射的equals()、 // hashCode()方法实现，这里的这个设置项是一个性能方面的优化 optional bool java_generate_equals_and_hash = 20 [default=false]; // 优化类型，生成的类可以进行速度优化、代码尺寸优化 enum OptimizeMode { SPEED = 1; // Generate complete code for parsing, serialization, // etc. CODE_SIZE = 2; // Use ReflectionOps to implement these methods. LITE_RUNTIME = 3; // Generate code using MessageLite and the lite runtime. } optional OptimizeMode optimize_for = 9 [default=SPEED]; // 设置go代码的包名 optional string go_package = 11; // 是否应该针对每一门语言都生成generice services？generic服务并不特定于任何 // 的rpc系统，它是由每个语言的注代码生成器来生成的，不借助于额外的插件。 // generic services是早期protoo2这个版本说支持的唯一一种服务类型。 // // 由于现在推崇使用plugins，plugins可以生成针对特定rpc系统的代码，generic // services现在可以看做是被废弃了。因此，以前proto2总的generice services的默 // 认设置默认为false，早期的依赖于generic services的代码需要显示设置这些选项 // 为true。 optional bool cc_generic_services = 16 [default=false]; optional bool java_generic_services = 17 [default=false]; optional bool py_generic_services = 18 [default=false]; // parser将不识别的选项存储在这里的uinterpreted_option repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message MessageOptions { // 设为true则使用老的proto1 MessageSet wire format……兼容性目的，没必要使用 optional bool message_set_wire_format = 1 [default=false]; // 禁用标准的descriptor()方法的生成，因为如果有个字段名是descriptor的话会生 // 成一个同名的函数，会冲突。这使得从proto1迁移到后续版本更简单，但是新版本 // 中还是应该避免使用字段descriptor。 optional bool no_standard_descriptor_accessor = 2 [default=false]; // parser将不识别的选项存储在这个字段里 repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message FieldOptions { // 开启packed选项之后，对于repeated基本数据类型字段的表示会更加高效。不再针 // 对repeated字段中的各个元素执行写tag、类型操作，而是将整个数组作为一个固定 // 长度的blob来存储。 optional bool packed = 2; // 当前字段是否需要lazy parsing？只是建议，lazy为true，protoc不一定lazy parsing optional bool lazy = 5 [default=false]; // 当前字段是否已经被废弃，跟目标平台相关，这个字段可以为生成的accessor方法 // 生成Deprecated注解，如果目标平台不支持就会忽略这个选项。不管目标平台是否 // 支持，proto里面要想废弃一个字段加deprecated选项还是非常正确的做法。 optional bool deprecated = 3 [default=false]; // map字段，目前还未完全实现，应避免使用 optional string experimental_map_key = 9; // google内部迁移使用，因避免使用 optional bool weak = 10 [default=false]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumOptions { // 不允许将多个不同的tag names映射到一个相同的值 // - 意思是说不允许多个字段的编号相同 optional bool allow_alias = 2 [default=true]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumValueOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message ServiceOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message MethodOptions { // 注意：字段编号1~32被保留给google内部rpc框架使用，google的解释是，在 // protobuf被公开给外部使用之前内部就已经大量使用了，且1~32倍使用的很多，也 // 是不得已的事情，总不能为了开源、推广一个内部组件就把自己的生意砸了吧。 // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } // 描述一个parser不认识的option message // - UninterpretedOption只会出现在compiler::Parser类创建的options protos中； // - 构建Descriptor对象的时候DescriptorPool会解析UninterpretedOptions； // 因此，descriptor对象中的options protos（通过Descriptor::options()返回，或者 // 通过Descriptor::CopyTo()生成）是不会包括UinterpretedOptions的。 message UninterpretedOption { // uinterpreted选项的名字，name中每个元素的name_part字段都表示name中的点分字 // 符串的一段，如果name_part是一个扩展（通过在字符串两端用括号括起来表示）， // is_extension字段为true。 // 例如，{[\u0026quot;foo\u0026quot;, false], [\u0026quot;bar.baz\u0026quot;,true], [\u0026quot;qux\u0026quot;,false]}表示\u0026quot;foo.(bar.baz).qux\u0026quot;。 message NamePart { required string name_part = 1; required bool is_extension = 2; } repeated NamePart name = 2; // uinterpreted选项的值，会设置下面字段中其中一个的值 optional string identifier_value = 3; optional uint64 positive_int_value = 4; optional int64 negative_int_value = 5; optional double double_value = 6; optional bytes string_value = 7; optional string aggregate_value = 8; } // =================================================================== // Optional source code info // FileDescriptorProto是从之前的source file中生成的（source file指的是proto文 // 件），这里的SourceCodeInfo指的是proto中的“源代码”信息。 message SourceCodeInfo { // Location用于识别proto文件中的源代码片段，往往对应着一个特定的定义。这些 // Location信息对于IDE、代码索引工具、文档生成工具等是非常重要的。 // // 下面说明一下Location的概念和作用，以下面这个message为例： // message Foo { // optional string foo = 1; // } // 我们先只看上面这个message中的字段定义： // optional string foo = 1; // ^ ^^ ^^ ^ ^^^ // a bc de f ghi // 我们可以得到下面这几个Location： // span path represents // [a,i) [ 4, 0, 2, 0 ] The whole field definition. // [a,b) [ 4, 0, 2, 0, 4 ] The label (optional). // [c,d) [ 4, 0, 2, 0, 5 ] The type (string). // [e,f) [ 4, 0, 2, 0, 1 ] The name (foo). // [g,h) [ 4, 0, 2, 0, 3 ] The number (1). // // 每个proto文件解析之后用一个FileDescriptorProto来表示，所以Lcoation路径位 // 置从FileDescriptorProto开始。 // - 因为message Foo是一个message，proto中所有顶层message类型定义都在 // FileDescriptorProto中message_type字段存储，这个字段的tag是4，所以Location为[4]； // - 又因为message_type是repeated DescriptorProto类型，因为当前proto示例中 // Foo为第一个message，所以其在message_type列表中的索引值为0，所以Location为[4,0]； // - 因为我们现在看的“源代码”是“optional string foo = 1;”，我们需要定位到 // message中的字段位置，message Foo中的所有字段都在DescriptorProto中的field字 // 段中记录，这个字段的tag=2，所以Location变为[4,0,2]； // - 又因为这个DescriptorProto中的field为repeated FieldDescriptorProto field， // 因为这个message中只有一个字段foo，所以foo在field列表中的索引值为0，Location变为[4,0,2,0]; // 上面解释了定位到完整的“optional string foo = 1”定义这个field的Location变 // 化过程，下面再说一下label、type、name、number的Location如何进一步确定。 // FieldDescriptorProto中label的tag位4，type的tag为5，name的tag为1，number的 // tag为3，Location对应的追加索引4、5、1、3。gg! // // proto文件中的源代码信息就是由一系列的Location来寻址的。 repeated Location location = 1; message Location { // 前面已经描述了Location的确定过程，一个Location如[4,0,2,0]其中的数字要么 // 是字段的tag编号要么是repeated列表中的索引值，这里的数字构成的数组保存在 // path中。 repeated int32 path = 1 [packed=true]; // 该字段span总是包括3个或者4个元素，依次表示startline、startcolumn、endline、endcolumn repeated int32 span = 2 [packed=true]; // 如果这个SourceCodeInfo代表一个完整的声明的话，可能在这个声明的前面或者 // 后面可能有一些attached的注释。 // // 连续的多个行注释看做是一个单独的注释。 // // 这个字段只记录了注释内容，不包括注释内容开头的注释符号//。对于块注释， // 注释前面的空白字符、*这几种符号也会被清理掉。但是会包括换行符。 // // Examples: // // optional int32 foo = 1; // Comment attached to foo. // // Comment attached to bar. // optional int32 bar = 2; // // optional string baz = 3; // // Comment attached to baz. // // Another line attached to baz. // // // Comment attached to qux. // // // // Another line attached to qux. // optional double qux = 4; // // optional string corge = 5; // /* Block comment attached // * to corge. Leading asterisks // * will be removed. */ // /* Block comment attached to // * grault. */ // optional int32 grault = 6; // Location前面的注释信息 optional string leading_comments = 3; // Location后面的注释信息 optional string trailing_comments = 4; } }  2.3. 可以提取proto文件中的哪些信息 \u0026amp; 如何提取 # 前一节2.2中对descriptor.proto进行了详细地描述，可以说在proto文件中写的每一行内容都可以通过解析FileDescriptorProto来访问到。proto文件只是一种自描述的消息格式，基于这种格式生成面向特定编程语言的源代码文件时，我们想获取的信息不外乎如下几个：\n 待生成的源文件的包名； 待生成的源文件的wrapper class类名； proto文件中定义的各个类型，包括枚举enum、消息message、服务service； 对于枚举enum需要知道枚举类型名、列出的枚举值（包括字段、值、注释信息）、注释信息； 对于消息message需要知道类型名、类成员（包括成员类型、成员名称、定义顺序、默认值、注释信息）、注释信息； 对于服务service需要知道服务名称、服务rpc接口（rpc接口的请求参数、返回值类型、注释信息）、注释信息； proto中可以添加注解吗？注解可以提取出来吗？  如何提取上述信息呢？可以肯定地是，只要能拿到当前proto文件对应的FileDescriptorProto，上述内容几乎都可以获取到。但是如何获取到对应的proto文件对应的这个FileDescriptorProto对象呢？下面我们先来看一个protoc-gen-go这个插件的示例代码吧，看完之后，大家也就了解了如何获取proto对应的FileDescriptorProto以及如何从中提取想要的上述1~7部分的信息，生成源代码文件也就简单了。\n2.4. proto-gen-go源代码分析 # 2.4.1. protoc-gen-go入口函数 # file: protobuf/protoc-gen-go/main.go\npackage main import ( \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; \u0026quot;github.com/c4pt0r/proto\u0026quot; \u0026quot;github.com/c4pt0r/protoc-gen-go/generator\u0026quot; ) func main() { // 首先创建一个代码生成器generator，CodeGeneratorRequest、CodeGeneratorResponse // 结构体都被保存在generator中，CodeGenerateResponse中保存着代码生成过程中 // 的错误状态信息，因此我们可以通过这个结构体提取错误状态并进行错误处理 g := generator.New() // 从标准输入中读取CodeGeneratorRequest信息（标准输入已经被重定向到了父进程 // protoc进程创建的管道stdout_pipe的读端，父进程会从管道的写端写入该请求信息） data, err := ioutil.ReadAll(os.Stdin) if err != nil { g.Error(err, \u0026quot;reading input\u0026quot;) } // 读取到的数据时串行化之后的CodeGeneratorRequest，将其反串行化成CodeGeneratorRequest if err := proto.Unmarshal(data, g.Request); err != nil { g.Error(err, \u0026quot;parsing input proto\u0026quot;) } // 检查CodeGeneratorRequest中待生成的源代码文件数量，数量为0则无需生成 if len(g.Request.FileToGenerate) == 0 { g.Fail(\u0026quot;no files to generate\u0026quot;) } // 将CodeGeneratorRequest中传递给代码生成器的参数设置到protoc插件的代码生成器中 g.CommandLineParameters(g.Request.GetParameter()) // 前面的proto.Unmarshal(...)操作将stdin中的请求反串行化成了CodeGeneratorRequest， // 这里的g.WrapTypes()将请求中的一些descriptors进行进一步封装，方便后面引用 g.WrapTypes() g.SetPackageNames() g.BuildTypeNameMap() // 生成所有的源代码文件 g.GenerateAllFiles() // 将CodeGeneratorResponse对象进行串行化处理 data, err = proto.Marshal(g.Response) if err != nil { g.Error(err, \u0026quot;failed to marshal output proto\u0026quot;) } // 将串行化之后的CodeGenerateResponse对象数据写入标准输出（标准输出已经被 // 重定向到了父进程protoc进程创建的管道stdin_pipe的写端，父进程从管道的读 // 端读取这里的响应） _, err = os.Stdout.Write(data) if err != nil { g.Error(err, \u0026quot;failed to write output proto\u0026quot;) } }  2.4.2. 回顾一下CodeGeneratorRequest \u0026amp; CodeGeneratorResponse的定义 # 下面看下CodeGeneratorRequest和CodeGeneratorResponse的定义。\nfile: ${protobuf}/src/google/protobuf/compiler/plugin.go\n// 串行化后的CodeGeneratorRequest信息会被写入到插件程序的stdin message CodeGeneratorRequest { // protoc命令执行时，我们在命令行中列出了需要进行处理的.proto文件的名称，代 // 码生成器应该只为这些.proto文件生成源代码文件。每一个.proto文件成功解析之 // 后会生成一个FileDescriptorProto对象，这个对象会被加入到字段proto_file中 repeated string file_to_generate = 1; // protoc命令行程序中传递给插件程序代码生成器的参数信息 optional string parameter = 2; // protoc命令行中列出的所有的.proto文件被添加到了字段file_to_generate中，这 // 些.proto文件中通过import引入进来的文件，这两部分文件解析成功后对应的 // FileDescriptorProto对象都会被加入到这里的proto_file中，添加后的顺序是按照 // 拓扑顺序排序的，怎么讲？就是被import的proto文件会出现在import它们的 proto // 文件前面。 repeated FileDescriptorProto proto_file = 15; } // 串行化后的CodeGeneratorResponse信息会被写入到插件的stdout message CodeGeneratorResponse { // 如果错误信息非空，表示代码生成失败。这种情况下尽管代码生成失败，插件进程 // 仍然应该返回一个状态0。 // // 这个字段用于指示.proto文件错误，.proto文件中的错误将使得代码生成器无法生 // 成正确的代码。指示protoc本身的错误，例如CodeGeneratorRequest数据无法被正 // 确地反串行化，这种情况应该被报告，错误信息应该写到stderr并且插件进程应该 // 返回一个非0状态码 optional string error = 1; // 描述一个待生成的源代码文件 message File { // 待生成的源代码文件相对于输出目录的文件名 optional string name = 1; // 写入到源代码文件中的插入点信息，方便后面的插件在插入点处进行扩展其他内容 optional string insertion_point = 2; // 写入到文件或者文件插入点位置的内容 optional string content = 15; } // 所有的待生成的源代码文件列表 repeated File file = 15; }  2.4.3. proto-gen-go generator实现分析 # main.go中调用了generator的几个关键方法，我们先来看下这几个方法都做了些什么，然 后再跟进一步看看generator的详细实现过程。\n2.4.3.1. generator.New() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// Generator类型的方法能够输出源代码，这些输出的源代码信息存储在Response成员中 type Generator struct { *bytes.Buffer Request *plugin.CodeGeneratorRequest // The input. Response *plugin.CodeGeneratorResponse // The output. Param map[string]string // Command-line parameters. PackageImportPath string // Go import path of the package we're generating code for ImportPrefix string // String to prefix to imported package file names. ImportMap map[string]string // Mapping from .proto file name to import path Pkg map[string]string // The names under which we import support packages packageName string // What we're calling ourselves. allFiles []*FileDescriptor // All files in the tree allFilesByName map[string]*FileDescriptor // All files by filename. genFiles []*FileDescriptor // Those files we will generate output for. file *FileDescriptor // The file we are compiling now. usedPackages map[string]bool // Names of packages used in current file. typeNameToObject map[string]Object // Key is a fully-qualified name in input syntax. init []string // Lines to emit in the init function. indent string writeOutput bool } // 创建一个新的代码生成器，并创建请求、响应对象 func New() *Generator { g := new(Generator) g.Buffer = new(bytes.Buffer) g.Request = new(plugin.CodeGeneratorRequest) g.Response = new(plugin.CodeGeneratorResponse) return g }  2.4.3.2. generator.CommandLineParameters(\u0026hellip;) # 这个函数是负责解析protoc传递过来的命令行参数信息的。\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 将都好分隔的key=value列表解析成\u0026lt;key,value\u0026gt; map func (g *Generator) CommandLineParameters(parameter string) { g.Param = make(map[string]string) for _, p := range strings.Split(parameter, \u0026quot;,\u0026quot;) { if i := strings.Index(p, \u0026quot;=\u0026quot;); i \u0026lt; 0 { g.Param[p] = \u0026quot;\u0026quot; } else { g.Param[p[0:i]] = p[i+1:] } } g.ImportMap = make(map[string]string) pluginList := \u0026quot;none\u0026quot; // Default list of plugin names to enable (empty means all). for k, v := range g.Param { switch k { case \u0026quot;import_prefix\u0026quot;: g.ImportPrefix = v case \u0026quot;import_path\u0026quot;: g.PackageImportPath = v // --go_out=plugins=grpc:.，解析这里的参数plugins=grpc case \u0026quot;plugins\u0026quot;: pluginList = v default: if len(k) \u0026gt; 0 \u0026amp;\u0026amp; k[0] == 'M' { g.ImportMap[k[1:]] = v } } } // 在protoc-gen-go的某个地方已经将grpc插件注册到了当前generator（也就是添 // 加到plugins []Plugin中），但是到底是在哪里注册的呢？只有注册并激活（参 // 数中通过--go_out=plugins=grpc:.)grpc子插件，该子插件才能被使用于后续的 // 代码生成过程中（生成rpc相关的go源代码）。 // // 其实这里的grpc子插件注册是利用了link_grpc.go里面的import _操作来隐式地 // 调用了grpc.init()方法，该初始化方法中负责完成向generator的注册操作，即 // generator.RegisterPlugin(new(grpc))，这里的RegisterPlugin其实就是将指定 // 的子插件加入到plugins []Plugin slice中。 // 为了能够在protoc-gen-go中正确地将grpc link进去，在构建protoc-gen-go的时 // 候需要执行命令： // cd protoc-gen-go \u0026amp; go build main.go link_grpc.go // go build的时候如果没有列出link_grpc.go，那么grpc是不会被link进 // protoc-gen-go这个插件的，这样处理.proto文件中的service时插件是不会生成 // service相关的go源代码的。 // 根据--go_out=plugins=?+?+?:.，更新激活的插件列表 if pluginList != \u0026quot;\u0026quot; { // Amend the set of plugins. enabled := make(map[string]bool) for _, name := range strings.Split(pluginList, \u0026quot;+\u0026quot;) { enabled[name] = true } var nplugins []Plugin for _, p := range plugins { if enabled[p.Name()] { nplugins = append(nplugins, p) } } plugins = nplugins } }  2.4.3.3. generator.WrapTypes() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// WrapTypes walks the incoming data, wrapping DescriptorProtos, EnumDescriptorProtos // and FileDescriptorProtos into file-referenced objects within the Generator. // It also creates the list of files to generate and so should be called before GenerateAllFiles. func (g *Generator) WrapTypes() { g.allFiles = make([]*FileDescriptor, 0, len(g.Request.ProtoFile)) g.allFilesByName = make(map[string]*FileDescriptor, len(g.allFiles)) for _, f := range g.Request.ProtoFile { // We must wrap the descriptors before we wrap the enums descs := wrapDescriptors(f) g.buildNestedDescriptors(descs) enums := wrapEnumDescriptors(f, descs) g.buildNestedEnums(descs, enums) exts := wrapExtensions(f) fd := \u0026amp;FileDescriptor{ FileDescriptorProto: f, desc: descs, enum: enums, ext: exts, exported: make(map[Object][]symbol), proto3: fileIsProto3(f), } extractComments(fd) g.allFiles = append(g.allFiles, fd) g.allFilesByName[f.GetName()] = fd } for _, fd := range g.allFiles { fd.imp = wrapImported(fd.FileDescriptorProto, g) } g.genFiles = make([]*FileDescriptor, 0, len(g.Request.FileToGenerate)) for _, fileName := range g.Request.FileToGenerate { fd := g.allFilesByName[fileName] if fd == nil { g.Fail(\u0026quot;could not find file named\u0026quot;, fileName) } fd.index = len(g.genFiles) g.genFiles = append(g.genFiles, fd) } }  2.4.3.4. generator.GenerateAllFiles() # 调用generator针对所有解析成功的proto文件生成所有的go源代码\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 生成所有.proto文件对应的go源代码，这里只是将源代码内容存储到g.Response中， // 并没有直接创建源代码文件，插件将Response传递给protoc进程后由protoc进程来负 // 责创建源代码文件 func (g *Generator) GenerateAllFiles() { // Initialize the plugins for _, p := range plugins { p.Init(g) } // Generate the output. The generator runs for every file, even the files // that we don't generate output for, so that we can collate the full list // of exported symbols to support public imports. genFileMap := make(map[*FileDescriptor]bool, len(g.genFiles)) for _, file := range g.genFiles { genFileMap[file] = true } for _, file := range g.allFiles { g.Reset() g.writeOutput = genFileMap[file] // 调用generator的generate(...)方法来生成该proto文件的 // FileDescriptorProto描述对应的go源代码 g.generate(file) if !g.writeOutput { continue } g.Response.File = append(g.Response.File, \u0026amp;plugin.CodeGeneratorResponse_File{ Name: proto.String(file.goFileName()), Content: proto.String(g.String()), }) } }  再看下generator.generate(\u0026hellip;)方法是如何实现的。\n// 针对.proto文件（由FileDescriptor表示）生成对应的go源代码 func (g *Generator) generate(file *FileDescriptor) { g.file = g.FileOf(file.FileDescriptorProto) g.usedPackages = make(map[string]bool) // 要生成源代码的首个proto文件对应的go源代码，这部分代码顶部插入版权信息 if g.file.index == 0 { // For one file in the package, assert version compatibility. g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the proto package it is being compiled against.\u0026quot;) g.P(\u0026quot;// A compilation error at this line likely means your copy of the\u0026quot;) g.P(\u0026quot;// proto package needs to be updated.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, g.Pkg[\u0026quot;proto\u0026quot;], \u0026quot;.ProtoPackageIsVersion\u0026quot;, generatedCodeVersion, \u0026quot; // please upgrade the proto package\u0026quot;) g.P() } // 生成import语句 for _, td := range g.file.imp { g.generateImported(td) } // 生成enum类型定义语句 for _, enum := range g.file.enum { g.generateEnum(enum) } // 生成message类型定义语句 for _, desc := range g.file.desc { // Don't generate virtual messages for maps. if desc.GetOptions().GetMapEntry() { continue } g.generateMessage(desc) } // 生成extension类型定义语句 for _, ext := range g.file.ext { g.generateExtension(ext) } // 生成初始化函数语句 g.generateInitFunction() // 前面生成enum、message、extension等的方式都基本类似，后面我们只给出一个 // 生成枚举类型方法的说明，生成message、extension的实现方法可以执行查看 // generator.go中的实现。 // // 需要注意的是，前面的各个生成源代码的方法不能处理service服务定义的rpc接 // 口代码，这部分rpc代码的生成需要借助于grpc子插件来完成，即下面的g.runPlugins(...) g.runPlugins(file) g.generateFileDescriptor(file) // 待输出的源代码需要知道哪些package是需要import的，哪些不需要，因此先运行 // 插件生成go代码中除import之外的其他部分代码，然后知道了哪些package需要 // import，再插入具体的import语句。 // // 最后在go源代码中插入header、import rem := g.Buffer g.Buffer = new(bytes.Buffer) g.generateHeader() g.generateImports() if !g.writeOutput { return } g.Write(rem.Bytes()) // 重新格式化生成的go源代码（gofmt） fset := token.NewFileSet() raw := g.Bytes() ast, err := parser.ParseFile(fset, \u0026quot;\u0026quot;, g, parser.ParseComments) if err != nil { // Print out the bad code with line numbers. // This should never happen in practice, but it can while changing generated code, // so consider this a debugging aid. var src bytes.Buffer s := bufio.NewScanner(bytes.NewReader(raw)) for line := 1; s.Scan(); line++ { fmt.Fprintf(\u0026amp;src, \u0026quot;%5d\\t%s\\n\u0026quot;, line, s.Bytes()) } g.Fail(\u0026quot;bad Go source code was generated:\u0026quot;, err.Error(), \u0026quot;\\n\u0026quot;+src.String()) } g.Reset() err = (\u0026amp;printer.Config{Mode: printer.TabIndent | printer.UseSpaces, Tabwidth: 8}).Fprint(g, fset, ast) if err != nil { g.Fail(\u0026quot;generated Go source code could not be reformatted:\u0026quot;, err.Error()) } }  上面generate.generate(\u0026hellip;)方法中generateEnum()、generateMessage()方法与其他几个方法都是非常类似的，由于大家使用protobuf过程中使用enum、message比较多，并且generateEnum()、generateMessage()方法执行逻辑非常相似，考虑到篇幅方面generateEnum()比generateMessage()简短，这里我们就只以generateEnum()的源代码作为示例进行分析。相信如果看懂了generateEnum的实现思路，generateMessage的实现思路也很容易搞明白，读者也具备了自己实现子插件的能力。\n// 生成指定enum类型的go源代码 func (g *Generator) generateEnum(enum *EnumDescriptor) { // enum类型的完整类型名 typeName := enum.TypeName() // CamelCased之后的完整类型名 ccTypeName := CamelCaseSlice(typeName) ccPrefix := enum.prefix() // 打印enum类型定义之前的leading comments // - 提取源代码信息SourceCodeInfo都是通过Location path来获取的； // - 提取注释信息也不例外，下面我们会介绍PrintComments(path)如何通过 // Location path来生成注释信息； g.PrintComments(enum.path) // 生成枚举类型的定义起始部分：type 枚举类型名 int32 g.P(\u0026quot;type \u0026quot;, ccTypeName, \u0026quot; int32\u0026quot;) g.file.addExport(enum, enumSymbol{ccTypeName, enum.proto3()}) // 枚举类型里面的各个枚举值都作为const int32常量来定义 g.P(\u0026quot;const (\u0026quot;) // 枚举值定义之前缩进一下 g.In() // 针对枚举类型里面的所有枚举值进行源代码生成 for i, e := range enum.Value { // 生成枚举值前面的leading comments g.PrintComments(fmt.Sprintf(\u0026quot;%s,%d,%d\u0026quot;, enum.path, enumValuePath, i)) // 生成枚举值的name = value形式的go源代码 name := ccPrefix + *e.Name g.P(name, \u0026quot; \u0026quot;, ccTypeName, \u0026quot; = \u0026quot;, e.Number) g.file.addExport(enum, constOrVarSymbol{name, \u0026quot;const\u0026quot;, ccTypeName}) } // 枚举值定义完之后取消缩进 g.Out() // 打印最后的结束信息 g.P(\u0026quot;)\u0026quot;) // 生成枚举类型相关的两个map // - 其中一个是枚举值到枚举名的映射； // - 另一个是枚举名到枚举值的映射； g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_name = map[int32]string{\u0026quot;) g.In() // 第一个map generated := make(map[int32]bool) // avoid duplicate values for _, e := range enum.Value { duplicate := \u0026quot;\u0026quot; if _, present := generated[*e.Number]; present { duplicate = \u0026quot;// Duplicate value: \u0026quot; } g.P(duplicate, e.Number, \u0026quot;: \u0026quot;, strconv.Quote(*e.Name), \u0026quot;,\u0026quot;) generated[*e.Number] = true } g.Out() g.P(\u0026quot;}\u0026quot;) // 第二个map g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_value = map[string]int32{\u0026quot;) g.In() for _, e := range enum.Value { g.P(strconv.Quote(*e.Name), \u0026quot;: \u0026quot;, e.Number, \u0026quot;,\u0026quot;) } g.Out() g.P(\u0026quot;}\u0026quot;) // 其他处理动作，也会生成部分源代码，这里可以忽略不计了 // ... }  下面看一下PrintComments如何通过Location path来提取并打印关联的注释信息。\n// 打印.proto文件中对该location path关联的leading comments注释信息 func (g *Generator) PrintComments(path string) bool { if !g.writeOutput { return false } // 在protoc进程解析.proto文件的时候就已经将各个类型、字段的comments信息维 // 护起来了，k就是location的path，通过path就能获取到对应的location，每个 // location中保存了这个位置的源代码的leading comments、trailing comments信 // 息，这里只打印leading comments if loc, ok := g.file.comments[path]; ok { text := strings.TrimSuffix(loc.GetLeadingComments(), \u0026quot;\\n\u0026quot;) for _, line := range strings.Split(text, \u0026quot;\\n\u0026quot;) { g.P(\u0026quot;// \u0026quot;, strings.TrimPrefix(line, \u0026quot; \u0026quot;)) } return true } return false }  看到这里我们对于基本的enum、message类型定义等都基本清楚了，下面我们需要看一下grpc子插件是如何生成service服务的rpc接口源代码的，这样的话，就得再来看一下g.runPlugins(file)是如何实现的。\n// Run all the plugins associated with the file. func (g *Generator) runPlugins(file *FileDescriptor) { // 在上述generator处理的基础上，继续运行generator中注册的插件，依次运行插件 for _, p := range plugins { p.Generate(file) } }  2.4.4. protoc-gen-go grpc子插件实现 # 因为上述2.4.3.4节中runPlugins(\u0026hellip;)的执行过程中，plugins这个slice内只有一个有效的、激活的子插件grpc，因此如果我们想了解service服务对应的rpc接口源代码是如何生成的话，查看一下grpc这个插件的Generate(file)方法就可以了。\n// 生成.proto文件中service定义的rpc接口的go源代码 func (g *grpc) Generate(file *generator.FileDescriptor) { // 如果没有定义service服务直接返回 if len(file.FileDescriptorProto.Service) == 0 { return } // 相关变量定义 g.P(\u0026quot;// Reference imports to suppress errors if they are not otherwise used.\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, contextPkg, \u0026quot;.Context\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P() // 断言，检查版本兼容性 g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the grpc package it is being compiled against.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, grpcPkg, \u0026quot;.SupportPackageIsVersion\u0026quot;, generatedCodeVersion) g.P() // 针对所有的service定义生成相关的service的go源代码 for i, service := range file.FileDescriptorProto.Service { g.generateService(file, service, i) } } // grpc中对generateService的实现，生成service相关的go源代码 // @param .proto解析后的各种DescriptorProto的wrapping类，通过它可以方便地访问.proto中定义的东西 // @param .proto中的某个service解析后对应的ServiceDescriptorProto // @param .proto中可能定义了多个service，当前这个service对应的索引值 func (g *grpc) generateService(file *generator.FileDescriptor, service *pb.ServiceDescriptorProto, index int) { // 构建当前service对应的path! path := fmt.Sprintf(\u0026quot;6,%d\u0026quot;, index) // 6 means service. // 获取service名称 origServName := service.GetName() fullServName := origServName if pkg := file.GetPackage(); pkg != \u0026quot;\u0026quot; { fullServName = pkg + \u0026quot;.\u0026quot; + fullServName } servName := generator.CamelCase(origServName) // 准备生成client相关的go源代码 g.P() g.P(\u0026quot;// Client API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务用户端go源代码生成 // - type 服务名+Client interface g.P(\u0026quot;type \u0026quot;, servName, \u0026quot;Client interface {\u0026quot;) // - 服务用户端定义的各个接口方法 for i, method := range service.Method { // 打印接口的leading comments g.gen.PrintComments(fmt.Sprintf(\u0026quot;%s,2,%d\u0026quot;, path, i)) // 2 means method in a service. // 生成接口的签名 g.P(g.generateClientSignature(servName, method)) } g.P(\u0026quot;}\u0026quot;) g.P() // 服务的用户端struct，其中包括了一个cc *grpc.ClientConn，后面会在该struct // 上实现上述服务接口 g.P(\u0026quot;type \u0026quot;, unexport(servName), \u0026quot;Client struct {\u0026quot;) g.P(\u0026quot;cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() // NewClient工厂 g.P(\u0026quot;func New\u0026quot;, servName, \u0026quot;Client (cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn) \u0026quot;, servName, \u0026quot;Client {\u0026quot;) g.P(\u0026quot;return \u0026amp;\u0026quot;, unexport(servName), \u0026quot;Client{cc}\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() var methodIndex, streamIndex int serviceDescVar := \u0026quot;_\u0026quot; + servName + \u0026quot;_serviceDesc\u0026quot; // 服务用户端的接口方法实现 for _, method := range service.Method { var descExpr string if !method.GetServerStreaming() \u0026amp;\u0026amp; !method.GetClientStreaming() { // Unary RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Methods[%d]\u0026quot;, serviceDescVar, methodIndex) methodIndex++ } else { // Streaming RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Streams[%d]\u0026quot;, serviceDescVar, streamIndex) streamIndex++ } g.generateClientMethod(servName, fullServName, serviceDescVar, method, descExpr) } g.P(\u0026quot;// Server API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务端接口go源代码生成 ... }  到这里为止，已经描述了protoc-gen-go中的generator做了哪些工作，与之协作的grpc又做了什么，一句话概括就是：generator负责生成除service之外的其他go代码，grpc负责生成service相关的go代码。在描述protoc-gen-go实现的过程中我们也描述了哪些信息该从哪里提取，比如定义的message类型、enum类型、service及其注释等信息。相信看到这里，读者应该可以独立开发一个protoc插件了吧。\n3. 总结 # 本文结合protoc源代码、protoc-gen-go源代码，对protoc、protoc插件工作原理进行了较为详细的分析、总结，希望能对想了解这方面内容或者有意向开发protoc插件扩展protoc功能的读者有帮助。\n由于本人水平有限，可能有理解不到位甚至错误的地方，也欢迎大家指出来。\n"}),a.add({id:436,href:"/blog/2017-05-16-protoc%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/",title:"Protoc工作原理分析",description:"团队经常使用protobuf作为消息交换格式，由于protobuf具有很强的自描述性，非常适合对一个服务进行建模。结合配套的编译器protoc，可以轻松理解服务信息，在此基础上可以开发一些脚手架工具（如protoc-gen-go）来完成代码生成、接口自动测试、生成api文档等等工作。本文就来介绍下protoc及其插件的工作原理，读完后读者将具备定制化protoc插件开发的能力。",content:"在进行protoc插件开发之前，首先要了解protoc的工作原理。在protobuf的使用过程中，protoc作为proto文件的编译器，很多开发人员只会用但是不了解其工作原理，更不了解如何扩展其功能。protobuf作为目前常用的数据交换格式在协议开发中被广泛采用，此外，protoc对proto文件的强大解析能力使我们可以开发一些插件，通过插件快速生成特定于proto文件的工具类、配置文件等，从而提高开发效率。\n本文首先会介绍一下protoc的整体工作机制，然后解释一下protoc对proto文件的解析过程，最后给出编写protoc插件扩展protoc功能的一个示例教程。\n1. protoc源代码准备 # 要想了解protoc的工作机制，查看其源代码了解其核心流程是最靠谱的方法。\n获取程序源代码的方式如下：\ngit co https://github.com/google/protobuf  由于我们工程中常用的protoc版本是v2.5.0，所以这里检出对应版本的tag。\ngit ck v2.5.0  考虑到可能会进行测试、修改、注释等学习过程，这里最好创建一个新的分支来操作。\ngit branch ${new-branch-name} git ck ${new-branch-name}  现在源代码准备好了，我比较喜欢使用vim、ctags、cscope来阅读源码，根据个人习惯吧，下面可以阅读protoc的源码梳理以下工作机制。\n2. protoc源码分析 # 上述git检出后的protobuf路径，记为${protobuf}，后面如果出现${protobuf}请知晓其含义。如果在描述源代码时没有提及起始路径${protobuf}，那么起始路径均为${protobuf}。\n2.1. protoc程序入口 # src/google/protobuf/compiler/main.cc中的main函数，为protoc的入口函数。\nfile: src/google/protobuf/compiler/main.cc\n// Author: kenton@google.com (Kenton Varda) // 这个头文件定义了protoc的命令行接口 #include \u0026lt;google/protobuf/compiler/command_line_interface.h\u0026gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include \u0026lt;google/protobuf/compiler/cpp/cpp_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/python/python_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/java/java_generator.h\u0026gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件 // - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头 // - 假定protoc --foo_out，那么实际调用的插件是protoc-foo google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(\u0026quot;protoc-\u0026quot;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator) google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026quot;--cpp_opt\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ header and source.\u0026quot;); // Proto2 Java (指定了--java_out将调用java::Generator) google::protobuf::compiler::java::JavaGenerator java_generator; cli.RegisterGenerator(\u0026quot;--java_out\u0026quot;, \u0026amp;java_generator, \u0026quot;Generate Java source file.\u0026quot;); // Proto2 Python (指定了python_out将调用python::Generator) google::protobuf::compiler::python::Generator py_generator; cli.RegisterGenerator(\u0026quot;--python_out\u0026quot;, \u0026amp;py_generator, \u0026quot;Generate Python source file.\u0026quot;); // 解析proto、生成源代码(借助内置的generator或者plugins)、创建源代码文件 return cli.Run(argc, argv); }  2.2. protoc命令行接口定义 # 下面看一下protoc的命令行接口定义，以了解其对命令行flags、options的解释过程以及对后续程序执行逻辑的影响。\nfile: src/google/protobuf/compiler/command_line_interface.h\n// Author: kenton@google.com (Kenton Varda) // Based on original Protocol Buffers design by // Sanjay Ghemawat, Jeff Dean, and others. // // Implements the Protocol Compiler front-end such that it may be reused by // custom compilers written to support other languages. #ifndef GOOGLE_PROTOBUF_COMPILER_COMMAND_LINE_INTERFACE_H__ #define GOOGLE_PROTOBUF_COMPILER_COMMAND_LINE_INTERFACE_H__ #include \u0026lt;google/protobuf/stubs/common.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;utility\u0026gt; namespace google { namespace protobuf { //proto文件中定义的数据类型可通过FileDescriptor来遍历、查看 class FileDescriptor; // descriptor.h class DescriptorPool; // descriptor.h class FileDescriptorProto; // descriptor.pb.h template\u0026lt;typename T\u0026gt; class RepeatedPtrField; // repeated_field.h namespace compiler { class CodeGenerator; // code_generator.h class GeneratorContext; // code_generator.h class DiskSourceTree; // importer.h // 这个类实现了protoc的命令行接口，使得protoc很容易扩展。 // 例如我们想让protoc既支持cpp又支持另一种语言foo，那么我们可以定义一个实现了 // CodeGenerator接口的FooGenerator，然后在protoc的main方法中对这两种语言cpp、Foo // 及其对应的CodeGenerator进行注册。 // // int main(int argc, char* argv[]) { // google::protobuf::compiler::CommandLineInterface cli; // // // 支持cpp // google::protobuf::compiler::cpp::CppGenerator cpp_generator; // cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ source and header.\u0026quot;); // // // 支持foo // FooGenerator foo_generator; // cli.RegisterGenerator(\u0026quot;--foo_out\u0026quot;, \u0026amp;foo_generator, \u0026quot;Generate Foo file.\u0026quot;); // // return cli.Run(argc, argv); // } // // The compiler is invoked with syntax like: // protoc --cpp_out=outdir --foo_out=outdir --proto_path=src src/foo.proto // // For a full description of the command-line syntax, invoke it with --help. class LIBPROTOC_EXPORT CommandLineInterface { public: CommandLineInterface(); ~CommandLineInterface(); // 为某种编程语言注册一个对应的代码生成器（其实这里也不一定非得是语言） // // 命令行接口的参数: // @param flag_name 指定输出文件类型的命令，例如--cpp_out，参数名字必须以“-”开头， 如果名字大于两个字符，则必须以“--”开头。 // @param generator 与flag_name对应的CodeGenerator接口实现 // @param help_text 执行protoc --help的时候对这里的flag_name的说明性信息 // // 某些代码生成器可接受额外参数，这些参数在输出路径之前给出，与输出路径之间用“:”分隔。 // protoc --foo_out=enable_bar:outdir // 这里的:outdir之前的enable_bar被作为参数传递给CodeGenerator::Generate()的参数。 void RegisterGenerator(const string\u0026amp; flag_name, CodeGenerator* generator, const string\u0026amp; help_text); // 为某种编程语言注册一个对应的代码生成器 // ... // @param option_flag_name 指定额外的选项 // ... // // 与前面一个函数RegisterGenerator所不同的是，这个重载函数多个参数 // option_flag_name，通过这个函数注册的语言和代码生成器可以接受额外的参数。例 // 如通过command_line_interface.RegisterGenerator(\u0026quot;--foo_out\u0026quot;, \u0026quot;--foo_opt\u0026quot;, ...) // 注册了foo以及对应代码生成器，那么我们可以在执行protoc 的时候指定额外的参数 // --foo_opt：protoc --foo_out=enable_bar:outdir --foo_opt=enable_baz，此时传 // 递给代码生成器的参数将会包括enable_bar和enable_baz。 void RegisterGenerator(const string\u0026amp; flag_name, const string\u0026amp; option_flag_name, CodeGenerator* generator, const string\u0026amp; help_text); // RegisterGenerator方法是在protoc的main方法中进行语言、代码生成器的注册，在 // 生产环境中不可能允许开发人员肆意修改公用程序库，这意味着我们如果要在稳定地 // protoc v2.5.0基础上进行源码的修改这条路是行不通的，那么如何自由地扩展其功 // 能呢？protoc提供了“plugin”机制，我们可以通过自定义插件来实现对其他语言 //（甚至不是语言）的支持。 // 开启protoc对插件的支持，这种模式下，如果一个命令行选项以_out结尾，例如 // --xxx_out，但是在protoc已经注册的语言支持中没有找到匹配的语言及代码生成器， // 这个时候protoc就会去检查是否有匹配的插件支持这种语言，将这个插件来作为代 // 码生成器使用。这里的的protoc插件是一个$PATH中可搜索到的可执行程序，当然 // 这个可执行程序稍微有点特殊。 // 这里插件名称（可执行程序名称）是如何确定的呢？选项--xxx_out中，截取“xxx”， // 然后根据${exe_name_prefix}以及xxx来拼接出一个插件的名字，假如${exe_name_prefix} // 是protoc-，那么插件的名字就是protoc-xxx，protoc将尝试执行这个程序来完成代 // 码生成的工作。 // 假定插件的名字是plugin，protoc是这样调用这个插件的： // plugin [--out=OUTDIR] [--parameter=PARAMETER] PROTO_FILES \u0026lt; DESCRIPTORS // 选项说明： // --out：指明了插件代码生成时的输出目录（跟通过--foo_out传递给protoc的一样）, // 如果省略这个参数，输出目录就是当前目录。 // --parameter：指明了传递给代码生成器的参数。 // PROTO_FILES：指明了protoc调用时传递给protoc的待处理的.proto文件列表。 // DESCRIPTORS: 编码后的FileDescriptorSet（这个在descriptor.proto中定义）， // 这里编码后的数据通过管道重定向到插件的标准输入，这里的FileDescriptorSet包括 // PROTO_FILES中列出的所有proto文件的descriptors，也包括这些PROTO_FILES中 // proto文件import进来的其他proto文件。插件不应该直接读取PROTO_FILES中的 // proto文件，而应该使用这里的DESCRIPTORS。 // // 插件跟protoc main函数中注册的代码生成器一样，它也需要生成所有必须的文件。 // 插件会将所有要生成的文件的名字写到stdout，插件名字是相对于当前输出目录的。如 // 果插件工作过程中发生了错误，需要将错误信息写到stderr，如果发生了严重错误， // 插件应该退出并返回一个非0的返回码。插件写出的数据会被protoc读取并执行后续 // 处理逻辑。 void AllowPlugins(const string\u0026amp; exe_name_prefix); // 根据指定的命令行参数来执行protocol compiler，返回值将由main返回。 // // Run()方法是非线程安全的，因为其中调用了strerror()，不要在多线程环境下使用。 int Run(int argc, const char* const argv[]); // proto路径解析的控制说明，fixme // Call SetInputsAreCwdRelative(true) if the input files given on the command // line should be interpreted relative to the proto import path specified // using --proto_path or -I flags. Otherwise, input file names will be // interpreted relative to the current working directory (or as absolute // paths if they start with '/'), though they must still reside inside // a directory given by --proto_path or the compiler will fail. The latter // mode is generally more intuitive and easier to use, especially e.g. when // defining implicit rules in Makefiles. void SetInputsAreProtoPathRelative(bool enable) { inputs_are_proto_path_relative_ = enable; } // 设置执行protoc --version时打印的版本相关的信息，这行版本信息的下一行也会打印libprotoc的版本。 void SetVersionInfo(const string\u0026amp; text) { version_info_ = text; } private: // ----------------------------------------------------------------- // 这个类的后续部分代码，虽然也比较重要，但是即便在这里先不解释，也不会给我 // 们的理解造成太多干扰，为了简化篇幅并且避免过早地陷入细节而偏离对整体的把 // 握，这里我先把这个类的后续部分代码进行删减……只保留相对比较重要的。 class GeneratorContextImpl; class MemoryOutputStream; // 清楚上次Run()运行时设置的状态 void Clear(); // 映射input_files_中的每个文件，使其变成相对于proto_path_中对应目录的相对路径 // - 当inputs_are_proto_path_relative_为false的时候才会调用这个函数； // - 出错返回false，反之返回true； bool MakeInputsBeProtoPathRelative(DiskSourceTree* source_tree); // ParseArguments() \u0026amp; InterpretArgument()返回的状态 enum ParseArgumentStatus { PARSE_ARGUMENT_DONE_AND_CONTINUE, PARSE_ARGUMENT_DONE_AND_EXIT, PARSE_ARGUMENT_FAIL }; // 解析所有的命令行参数 ParseArgumentStatus ParseArguments(int argc, const char* const argv[]); // 解析某个命令行参数 // - 参数名放name，参数值放value // - 如果argv中的下一个参数应该被当做value则返回true，反之返回false bool ParseArgument(const char* arg, string* name, string* value); // 解析某个命令行参数的状态 ParseArgumentStatus InterpretArgument(const string\u0026amp; name, const string\u0026amp; value); // 从输入的proto文件生成指定的源代码文件 struct OutputDirective; // 对解析成功的每个proto文件，生成对应的源代码文件 // @param parsed_files 解析成功的proto文件vector // @param output_directive 输出指示，包括了文件名、语言、代码生成器、输出目录 // @param generator_context 代码生成器上下文，可记录待输出文件名、文件内容、尺寸等信息 bool GenerateOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const OutputDirective\u0026amp; output_directive, GeneratorContext* generator_context); // 对解析成功的每个proto文件，调用protoc插件生成对应的源代码 // @param parsed_files 解析成功的proto文件vector // @param plugin_name 插件的名称，命名方式一般是protoc-gen-${lang} // @param parameter 传递给protoc插件的参数 // @param generator_context 代码生成器上下文，可记录待输出文件名、文件内容、尺寸等信息 // @param error 错误信息 bool GeneratePluginOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const string\u0026amp; plugin_name, const string\u0026amp; parameter, GeneratorContext* generator_context, string* error); // 编码、解码，实现命令行中的--encode和--decode选项 bool EncodeOrDecode(const DescriptorPool* pool); // 实现命令行中的--descriptor_set_out选项 bool WriteDescriptorSet(const vector\u0026lt;const FileDescriptor*\u0026gt; parsed_files); // 获取指定proto文件依赖的proto文件列表（列表中包括该proto文件本身） // - proto文件通过FileDescriptorProto表示； // - 这些依赖的proto文件列表会被重新排序，被依赖的proto会被排在依它的proto前面, // 这样我们就可以调用DescriptorPool::BuildFile()来建立最终的源代码文件； // - already_seen中已经列出的proto文件不会被重复添加，每一个被添加的proto文件都被加入到already_seen中； // - 如果include_source_code_info为true，则包括源代码信息到FileDescriptorProtos中； static void GetTransitiveDependencies(const FileDescriptor* file, bool include_source_code_info, set\u0026lt;const FileDescriptor*\u0026gt;* already_seen, RepeatedPtrField\u0026lt;FileDescriptorProto\u0026gt;* output); // ----------------------------------------------------------------- // 当前被调用的程序的名称，argv[0] string executable_name_; // 通过SetVersionInfo()设置的版本信息 string version_info_; // 注册的代码生成器 struct GeneratorInfo { string flag_name; // --foo_out string option_flag_name; // --foo_opt CodeGenerator* generator; // 对应的代码生成器 string help_text; // protoc --help时输出的--foo_out的帮助信息 }; typedef map\u0026lt;string, GeneratorInfo\u0026gt; GeneratorMap; // flag_name、代码生成器map GeneratorMap generators_by_flag_name_; // option_name、代码生成器map GeneratorMap generators_by_option_name_; // flag_name、option map // - 如果调用protoc --foo_out=outputdir --foo_opt=enable_bar ...， // map中将包括一个\u0026lt;--foo_out,enable_bar\u0026gt; entry. map\u0026lt;string, string\u0026gt; generator_parameters_; // protoc插件前缀，如果该变量为空，那么不允许使用插件 // @see AllowPlugins() string plugin_prefix_; // 将protoc插件名称映射为具体的插件可执行文件 // - 执行一个插件可执行程序时，首先搜索这个map，如果找到则直接执行； // - 如果这个map中找不到匹配的插件可执行程序，则搜索PATH寻找可执行程序执行； map\u0026lt;string, string\u0026gt; plugins_; // protoc命令行中指定的工作模式 enum Mode { MODE_COMPILE, // Normal mode: parse .proto files and compile them. MODE_ENCODE, // --encode: read text from stdin, write binary to stdout. MODE_DECODE // --decode: read binary from stdin, write text to stdout. }; Mode mode_; vector\u0026lt;pair\u0026lt;string, string\u0026gt; \u0026gt; proto_path_; // Search path for proto files. vector\u0026lt;string\u0026gt; input_files_; // Names of the input proto files. // protoc调用时每个--${lang}_out都对应着一个OutputDirective struct OutputDirective { string name; // flag_name，E.g. \u0026quot;--foo_out\u0026quot; CodeGenerator* generator; // 为NULL则表示使用protoc插件而非内置的代码生成器 string parameter; // 传递给代码生成器或者protoc插件的参数 string output_location; // 源代码文件输出目录 }; // 一次protoc调用可能会同时制定多个--${lang}_out选项 vector\u0026lt;OutputDirective\u0026gt; output_directives_; // 当使用--encode或者--decode的时候，codec_type_指明了encode或者decode的类型 // - 如果codec_type_为空则表示--decode_raw类型; string codec_type_; // 如果指定了--descriptor_set_out选项，FileDescriptorSet将被输出到指定的文件 string descriptor_set_name_; // 如果指定了--include-imports那么所有的依赖proto都要写到DescriptorSet； // 如果未指定，则只把命令行中列出的proto文件写入； bool imports_in_descriptor_set_; // 如果指定--include_source_info为true，则不能从DescriptorSet中删除SourceCodeInfo bool source_info_in_descriptor_set_; // --disallow_services_这个选项有被使用吗？ bool disallow_services_; // See SetInputsAreProtoPathRelative(). bool inputs_are_proto_path_relative_; GOOGLE_DISALLOW_EVIL_CONSTRUCTORS(CommandLineInterface); }; } // namespace compiler } // namespace protobuf } // namespace google #endif // GOOGLE_PROTOBUF_COMPILER_COMMAND_LINE_INTERFACE_H__  2.3. protoc执行流程说明 # protoc执行流程的相关源码，主要包括如下两个部分。\n2.3.1. protoc完成基本的初始化工作后调用cli.Run(argc,argv)开始生成代码 # 这部分内容在前面已经有过较为详细的解释，这里不再详细展开，只给出相应的代码、注释。\nfile: src/google/protobuf/compiler/main.cc\n// Author: kenton@google.com (Kenton Varda) // 这个头文件定义了protoc的命令行接口 #include \u0026lt;google/protobuf/compiler/command_line_interface.h\u0026gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include \u0026lt;google/protobuf/compiler/cpp/cpp_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/python/python_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/java/java_generator.h\u0026gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件 // - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头 // - 假定protoc --foo_out，那么实际调用的插件是protoc-foo google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(\u0026quot;protoc-\u0026quot;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator) google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026quot;--cpp_opt\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ header and source.\u0026quot;); // Proto2 Java (指定了--java_out将调用java::Generator) google::protobuf::compiler::java::JavaGenerator java_generator; cli.RegisterGenerator(\u0026quot;--java_out\u0026quot;, \u0026amp;java_generator, \u0026quot;Generate Java source file.\u0026quot;); // Proto2 Python (指定了python_out将调用python::Generator) google::protobuf::compiler::python::Generator py_generator; cli.RegisterGenerator(\u0026quot;--python_out\u0026quot;, \u0026amp;py_generator, \u0026quot;Generate Python source file.\u0026quot;); return cli.Run(argc, argv); }  2.3.2. protoc命令接口cli.Run(argc,argv)详细处理流程 # 这部分代码是protoc对proto文件进行读取、解析、通过注册的代码生成器或者protoc插件生成源代码、保存源代码到源文件的执行流程。\nint CommandLineInterface::Run(int argc, const char* const argv[]) { Clear(); switch (ParseArguments(argc, argv)) { case PARSE_ARGUMENT_DONE_AND_EXIT: return 0; case PARSE_ARGUMENT_FAIL: return 1; case PARSE_ARGUMENT_DONE_AND_CONTINUE: break; } // Set up the source tree. DiskSourceTree source_tree; for (int i = 0; i \u0026lt; proto_path_.size(); i++) { source_tree.MapPath(proto_path_[i].first, proto_path_[i].second); } // Map input files to virtual paths if necessary. if (!inputs_are_proto_path_relative_) { if (!MakeInputsBeProtoPathRelative(\u0026amp;source_tree)) { return 1; } } // Allocate the Importer. ErrorPrinter error_collector(error_format_, \u0026amp;source_tree); Importer importer(\u0026amp;source_tree, \u0026amp;error_collector); vector\u0026lt;const FileDescriptor*\u0026gt; parsed_files; // Parse each file. for (int i = 0; i \u0026lt; input_files_.size(); i++) { // Import the file. const FileDescriptor* parsed_file = importer.Import(input_files_[i]); if (parsed_file == NULL) return 1; parsed_files.push_back(parsed_file); // Enforce --disallow_services. if (disallow_services_ \u0026amp;\u0026amp; parsed_file-\u0026gt;service_count() \u0026gt; 0) { cerr \u0026lt;\u0026lt; parsed_file-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: This file contains services, but \u0026quot; \u0026quot;--disallow_services was used.\u0026quot; \u0026lt;\u0026lt; endl; return 1; } } // We construct a separate GeneratorContext for each output location. Note // that two code generators may output to the same location, in which case // they should share a single GeneratorContext so that OpenForInsert() works. typedef hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; GeneratorContextMap; GeneratorContextMap output_directories; // Generate output. if (mode_ == MODE_COMPILE) { for (int i = 0; i \u0026lt; output_directives_.size(); i++) { string output_location = output_directives_[i].output_location; if (!HasSuffixString(output_location, \u0026quot;.zip\u0026quot;) \u0026amp;\u0026amp; !HasSuffixString(output_location, \u0026quot;.jar\u0026quot;)) { AddTrailingSlash(\u0026amp;output_location); } GeneratorContextImpl** map_slot = \u0026amp;output_directories[output_location]; if (*map_slot == NULL) { // First time we've seen this output location. *map_slot = new GeneratorContextImpl(parsed_files); } if (!GenerateOutput(parsed_files, output_directives_[i], *map_slot)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } // Write all output to disk. for (GeneratorContextMap::iterator iter = output_directories.begin(); iter != output_directories.end(); ++iter) { const string\u0026amp; location = iter-\u0026gt;first; GeneratorContextImpl* directory = iter-\u0026gt;second; if (HasSuffixString(location, \u0026quot;/\u0026quot;)) { if (!directory-\u0026gt;WriteAllToDisk(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } else { if (HasSuffixString(location, \u0026quot;.jar\u0026quot;)) { directory-\u0026gt;AddJarManifest(); } if (!directory-\u0026gt;WriteAllToZip(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } STLDeleteValues(\u0026amp;output_directories); if (!descriptor_set_name_.empty()) { if (!WriteDescriptorSet(parsed_files)) { return 1; } } if (mode_ == MODE_ENCODE || mode_ == MODE_DECODE) { if (codec_type_.empty()) { // HACK: Define an EmptyMessage type to use for decoding. DescriptorPool pool; FileDescriptorProto file; file.set_name(\u0026quot;empty_message.proto\u0026quot;); file.add_message_type()-\u0026gt;set_name(\u0026quot;EmptyMessage\u0026quot;); GOOGLE_CHECK(pool.BuildFile(file) != NULL); codec_type_ = \u0026quot;EmptyMessage\u0026quot;; if (!EncodeOrDecode(\u0026amp;pool)) { return 1; } } else { if (!EncodeOrDecode(importer.pool())) { return 1; } } } return 0; }  2.3.3. protoc执行逻辑总结 # 通过查看上面两部分代码及其他关键代码，可以对protoc的执行流程进行一个简单的总结了：\n  protoc main中初始化命令行参数接口cli;\n  protoc 中开启protoc-前缀的插件作为第三方代码生成器使用cli.AllowPlugins(\u0026ldquo;protoc-\u0026quot;)；\n  protoc main中注册编程语言cpp、java、python及对应的代码生成器，cli.RegisterGenerator(\u0026hellip;)，原生支持cpp、java、python；\n  protoc main中cli.Run(argc, argv)，运行注册的代码生成器或者protoc插件;\n Clear()清空所有的数据备用； ParseArguments(argc,argv)解析参数，对于protoc的某些内置参数的检查，对某些插件相关的\u0026ndash;${lang}_out参数的检查等，将\u0026ndash;${lang}_out作为输出指令保存起来； struct OutputDirective { string name; // E.g. \u0026quot;--foo_out\u0026quot; CodeGenerator* generator; // NULL for plugins string parameter; string output_location; };   参数解析成功之后，继续执行处理，设置源代码树、映射输入文件到虚拟路径、分配importer； 针对每个输入的proto文件进行解析，const FileDescriptor* parsed_file = importer.Import(input_files_[i])，解析成功后的文件会被加入到vector\u0026lt;FileDescriptor*\u0026gt; parsed_files中记录，每一个proto文件解析后都可以用一个FileDescriptor结构体来表示；   备注：\n这里解析proto文件的过程是这样的，首先将proto文件中的内容分割成一个个的token，将内容拆分成一个个词素并检查有效性，也就是词法分析。如果词法分析检查无误则进入后续的语法分析过程，parser对输入token串进行文法相关的分析检查是否可以构成一棵有效的语法分析树，如果可以则表示语法正确。\n // Token定义如下 struct Token { TokenType type; string text; // The exact text of the token as it appeared in // the input. e.g. tokens of TYPE_STRING will still // be escaped and in quotes. // \u0026quot;line\u0026quot; and \u0026quot;column\u0026quot; specify the position of the first character of // the token within the input stream. They are zero-based. int line; int column; int end_column; }; // Token类型定义如下 enum TokenType { TYPE_START, // Next() has not yet been called. TYPE_END, // End of input reached. \u0026quot;text\u0026quot; is empty. TYPE_IDENTIFIER, // A sequence of letters, digits, and underscores, not // starting with a digit. It is an error for a number // to be followed by an identifier with no space in // between. TYPE_INTEGER, // A sequence of digits representing an integer. Normally // the digits are decimal, but a prefix of \u0026quot;0x\u0026quot; indicates // a hex number and a leading zero indicates octal, just // like with C numeric literals. A leading negative sign // is NOT included in the token; it's up to the parser to // interpret the unary minus operator on its own. TYPE_FLOAT, // A floating point literal, with a fractional part and/or // an exponent. Always in decimal. Again, never // negative. TYPE_STRING, // A quoted sequence of escaped characters. Either single // or double quotes can be used, but they must match. // A string literal cannot cross a line break. TYPE_SYMBOL, // Any other printable character, like '!' or '+'. // Symbols are always a single character, so \u0026quot;!+$%\u0026quot; is // four tokens. };  语法分析的过程这里就不解释了，感兴趣的可以看一下protobuf中grammar的定义，无非也就是些规约的事情，只要能够按照grammar将词法分析输出的token串构建出一棵完整的语法分析树proto文件就是合法的，否则就是不合法的，至于语法分析过程中伴随的语义分析过程，语义分析过程中执行哪些语义动作，不说也知道，肯定是生成某些“中间代码”之类的鬼东西。学过编译原理的这些处理过程应该都是比较清楚的，这里就不再展开了。语法分析成功之后就得到了proto对应的FileDescriptor对象，因为可能输入的是多个proto，所以多个FileDescriptor就用vector来存储了。\n 遍历之前记录下来的输出指令OutputDirective output_directives[]，output_directives[i].output_location指明了输出目录，针对输出目录创建GeneratorContextImpl，并记录到hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; output_directories这个map中，key为flag_out,如\u0026ndash;foo_out，value为GeneratorContextImpl。由于可能多个\u0026ndash;${lang}_out都指向相同的输出目录，所以同一个GeneratorContextImpl也存在复用的情况。每个GeneratorContextImpl记录了一个输出目录、所有该目录下的待创建的源代码文件的信息，待创建的源代码文件信息记录在map\u0026lt;string,string*\u0026gt; files_里面，key为源代码文件名，val为源代码文件的内容，另外还包括了一个vector\u0026lt;FileDescriptor*\u0026gt; parsed_files记录了所有解析成功的proto文件信息。\n遍历output_directives的同时，因为同一个output_directives[i]对应的输出目录下可能有多个源代码文件要输出，并且不管flag_name是什么，要处理的proto文件都是相同的，所以每个output_directives[i]都会对其调用GenerateOutput(parsed_files, output_directives[i], *map_slot)，output_directives[i].plugin指明了语言的代码生成器(为NULL则使用插件)，对所有的解析成功的proto文件parsed_files[i]生成源代码，源代码全部输出到output_directive[i].output_location下，源代码的文件名都记录在parsed_files[i].name()里面，而最终生成的源代码信息都存储在这里的CodeGeneratorImpl **map_slot中，也就相当于存储在了output_directories[]中。 最后遍历output_directories[]，将每个输出目录下要写的所有文件的数据全部写出到磁盘，即output_directories[i]-\u0026gt;WriteAllToDisk()。 done！    了解从proto到源代码生成的关键之处就是这里的GenerateOutput是怎么实现的，接着看。\n2.3.3.1 protoc CommandLineInterface::GenerateOutput(\u0026hellip;)实现 # 下面看下GenerateOutput方法到底执行了哪些操作。\n// 根据输出指示, 为解析成功的proto文件调用代码生成器生成对应的代码并存储到generator_context //@param parsed_files 所有解析成功的proto文件，每个解析成功的proto文件都用一个FileDescriptor来表示 //@param output_directive 输出指示，其指明了目标语言、语言对应的代码生成器、输出目录等 //@param generator_context 代码生成器上下文，可记录生成的代码 bool CommandLineInterface::GenerateOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const OutputDirective\u0026amp; output_directive, GeneratorContext* generator_context) { // Call the generator. string error; // 如果输出指示中没有设置对应的代码生成器，表明没有在protoc main中注册语言对应的代码生成器， // 这种需要protoc通过插件机制，通过调用对应的插件来充当代码生成器的功能。 if (output_directive.generator == NULL) { // This is a plugin. GOOGLE_CHECK(HasPrefixString(output_directive.name, \u0026quot;--\u0026quot;) \u0026amp;\u0026amp; HasSuffixString(output_directive.name, \u0026quot;_out\u0026quot;)) \u0026lt;\u0026lt; \u0026quot;Bad name for plugin generator: \u0026quot; \u0026lt;\u0026lt; output_directive.name; // 实际上protoc搜索插件对应的可执行程序的时候，搜索的名称是“protoc-gen-”+“语言”， // 如果我们调用的是protoc --xxx_out，那么实际搜索的就是protoc-gen-xxx。 string plugin_name = plugin_prefix_ + \u0026quot;gen-\u0026quot; + output_directive.name.substr(2, output_directive.name.size() - 6); // 调用protoc插件来生成代码，这是我们要重点看的，我们就是要实现自己的protoc插件 if (!GeneratePluginOutput(parsed_files, plugin_name, output_directive.parameter, generator_context, \u0026amp;error)) { cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } else { // 这种是protoc main函数中正常注册的语言和代码生成器 // Regular generator. string parameters = output_directive.parameter; if (!generator_parameters_[output_directive.name].empty()) { if (!parameters.empty()) { parameters.append(\u0026quot;,\u0026quot;); } parameters.append(generator_parameters_[output_directive.name]); } // 为每个解析成功的proto文件生成代码 for (int i = 0; i \u0026lt; parsed_files.size(); i++) { if (!output_directive.generator-\u0026gt;Generate(parsed_files[i], parameters, generator_context, \u0026amp;error)) { // Generator returned an error. cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; parsed_files[i]-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } } return true; }  2.3.3.2. protoc调用插件生成代码的执行逻辑 # 下面再来看一下GeneratePluginOutput是如何工作的。\n// 调用protoc插件为解析成功的proto文件生成代码 // //@param parsed_files 解析成功的文件 //@param plugin_name protoc插件名称（这个是拼接出来的protoc-gen-${lang}） //@param parameter 传给插件的参数 //@param generator_context 代码生成器上下文，可记录生成的代码 //@param error 代码生成过程中的错误信息 bool CommandLineInterface::GeneratePluginOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const string\u0026amp; plugin_name, const string\u0026amp; parameter, GeneratorContext* generator_context, string* error) { // protoc生成一个代码生成请求，并发送给插件 CodeGeneratorRequest request; // protoc插件根据接收到的代码生成请求生成代码，并发送响应给protoc CodeGeneratorResponse response; // Build the request. if (!parameter.empty()) { request.set_parameter(parameter); } set\u0026lt;const FileDescriptor*\u0026gt; already_seen; for (int i = 0; i \u0026lt; parsed_files.size(); i++) { request.add_file_to_generate(parsed_files[i]-\u0026gt;name()); GetTransitiveDependencies(parsed_files[i], true, // Include source code info. \u0026amp;already_seen, request.mutable_proto_file()); } // fork出一个子进程，子进程来执行插件完成代码生成工作， // 父子进程之间是通过管道通信完成请求、响应过程，如何控制子进程的stdin、stdout， // 这个可以通过dup2或者dup3来控制间fd 0、1分别设置到管道的读端、写端。 // 事实上protobuf的开发人员也是这么来实现的。 // Invoke the plugin. Subprocess subprocess; if (plugins_.count(plugin_name) \u0026gt; 0) { subprocess.Start(plugins_[plugin_name], Subprocess::EXACT_NAME); } else { subprocess.Start(plugin_name, Subprocess::SEARCH_PATH); } string communicate_error; // 请求插件生成代码 if (!subprocess.Communicate(request, \u0026amp;response, \u0026amp;communicate_error)) { *error = strings::Substitute(\u0026quot;$0: $1\u0026quot;, plugin_name, communicate_error); return false; } // Write the files. We do this even if there was a generator error in order // to match the behavior of a compiled-in generator. scoped_ptr\u0026lt;io::ZeroCopyOutputStream\u0026gt; current_output; for (int i = 0; i \u0026lt; response.file_size(); i++) { const CodeGeneratorResponse::File\u0026amp; output_file = response.file(i); if (!output_file.insertion_point().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据已经存在，定位到准确的插入点位置执行写入，然后关闭文件 // - 这里的插入点如何定义，我们在后面再进行说明。具体可参考plugin.proto和plugin.pb.h。 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;OpenForInsert(output_file.name(), output_file.insertion_point())); } else if (!output_file.name().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据不存在，不存在插入点信息，从开始处执行写入 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;Open(output_file.name())); } else if (current_output == NULL) { *error = strings::Substitute( \u0026quot;$0: First file chunk returned by plugin did not specify a file name.\u0026quot;, plugin_name); return false; } // 从CodeGeneratorResponse中获取输出流，写出，这里输出流中的数据时存储在GeneratorContextImpl中的， // GenerateOutput调用成功之后后面会遍历每一个GenerateContextImpl完成WriteAllToDisk()的操作。 // Use CodedOutputStream for convenience; otherwise we'd need to provide // our own buffer-copying loop. io::CodedOutputStream writer(current_output.get()); writer.WriteString(output_file.content()); } // Check for errors. if (!response.error().empty()) { // Generator returned an error. *error = response.error(); return false; } return true; }  2.3.3.3. protoc \u0026amp; protoc插件数据交互的执行逻辑 # 整体执行逻辑差不多理清楚了，然后这里我们需要看一下父进程给子进程发送的代码生成请求是什么，收到的代码生成的响应又是什么，以及父子进程通信的细节、子进程对请求的处理过程等。\n先来看下plugin.proto的定义，protoc内置的支持语言里面并不包含go，我们后面需要用go来编写我们自己的插件，所以必须使用protoc的go插件来生成go对应的plugin.go代码，然后我们自己写一些业务类插件（非语言插件）的时候才能用上plugin.go。扯这么多是为了让大家明白这里为什么需要看下plugin.proto，而不是误解为只是在堆砌内容。看了这里的plugin.proto之后才能理解到protoc中的插件机制的边界时什么，我们就可以明白利用protoc的插件机制，我们可以做到什么程度，哪些功能能实现，哪些实现不了，这个是很重要的。\nfile: src/google/protobuf/compiler/plugin.proto\n// protoc (aka the Protocol Compiler) can be extended via plugins. A plugin is // just a program that reads a CodeGeneratorRequest from stdin and writes a // CodeGeneratorResponse to stdout. // // Plugins written using C++ can use google/protobuf/compiler/plugin.h instead // of dealing with the raw protocol defined here. // // A plugin executable needs only to be placed somewhere in the path. The // plugin should be named \u0026quot;protoc-gen-$NAME\u0026quot;, and will then be used when the // flag \u0026quot;--${NAME}_out\u0026quot; is passed to protoc. package google.protobuf.compiler; option java_package = \u0026quot;com.google.protobuf.compiler\u0026quot;; option java_outer_classname = \u0026quot;PluginProtos\u0026quot;; import \u0026quot;google/protobuf/descriptor.proto\u0026quot;; // 发送给插件的代码生成请求 // An encoded CodeGeneratorRequest is written to the plugin's stdin. message CodeGeneratorRequest { // The .proto files that were explicitly listed on the command-line. The // code generator should generate code only for these files. Each file's // descriptor will be included in proto_file, below. //proto文件列表对应的要生成的文件的源代码文件的名字 repeated string file_to_generate = 1; // The generator parameter passed on the command-line. //传递给插件代码生成器的参数 optional string parameter = 2; // FileDescriptorProtos for all files in files_to_generate and everything // they import. The files will appear in topological order, so each file // appears before any file that imports it. // // protoc guarantees that all proto_files will be written after // the fields above, even though this is not technically guaranteed by the // protobuf wire format. This theoretically could allow a plugin to stream // in the FileDescriptorProtos and handle them one by one rather than read // the entire set into memory at once. However, as of this writing, this // is not similarly optimized on protoc's end -- it will store all fields in // memory at once before sending them to the plugin. // 每一个正确解析的proto文件都用一个FileDescriptorProto来表示； // 这里的FileDescriptorProto与FileDescriptor其实是对应的，在请求插件进行代码 // 生成的时候直接就有这样的代码FileDescriptor::CopyTo(FileDescriptorProto\u0026amp;) // 的用法。而在descriptor.h和descriptor.proto中查看二者的描述时，其注释清清 // 楚楚地写着都是描述的一个完整的proto文件。 repeated FileDescriptorProto proto_file = 15; } // 插件返回的代码生成响应 // The plugin writes an encoded CodeGeneratorResponse to stdout. message CodeGeneratorResponse { // Error message. If non-empty, code generation failed. The plugin process // should exit with status code zero even if it reports an error in this way. // // This should be used to indicate errors in .proto files which prevent the // code generator from generating correct code. Errors which indicate a // problem in protoc itself -- such as the input CodeGeneratorRequest being // unparseable -- should be reported by writing a message to stderr and // exiting with a non-zero status code. // 错误信息 optional string error = 1; // Represents a single generated file. // 生成的源代码文件消息类型，注意这里是一个内部类型 message File { // 待生成的源代码文件名（相对于输出目录），文件名中不能包括.或者..，路径是 // 相对输出目录的路径，不能用绝对路径，另分隔符必须用/。 // 如果name没有指定，那么输出的内容将追加到前一个输出的源代码文件中，这种 // 方式使得代码生成器能够将一个大文件的生成分多次写入来完成，不用一次性将很 // 大数据量的数据放在内存中。这里需要指出的是，protoc中并没有针对这种情况 // 进行特殊的优化，它等待读取完整的CodeGeneratorResponse再写出到磁盘。 optional string name = 1; // 如果insertion_point不空的话，name字段也不能为空，并且假定name字段指定的 // 文件已经存在了。这里的内容将被插入到name指定的文件中的特定插入点（注解）的 // 上一行。这有助于扩展代码生成器输出的内容。在一次protoc调用中，可能会同 // 时指定多个protoc插件，前面的插件可能会在输出的内容中指定插入点，后面的 // 插件可能会在这些指定的插入点的位置继续扩展代码内容。 // 例如，前面的一个插件在输出的代码内容中增加了这样一行注解： // @@protoc_insertion_point(NAME) // 这样就定义了一个插入点，插入点前面、后面可以包含任意的文本内容，即使在 // 注释里面也是可以的。这里的插入点定义中的NAME应该可以唯一标识一个插入点 // 才可以，类似于标识符，以供其他的插件使用，插件插入代码的时候将从插入点 // 的上一行开始自行插入。如果包含多个插入点的话，插入点的内容将被插件依次 // 扩展。 // // 一开始创建这个源代码文件的代码生成器或者插件与后面的继续扩展源代码插入 // 点位置内容的代码生成器或者插件，必须在protoc的同一次调用中，代码生成器 // 或者插件按照protoc命令行调用过程中指定的顺序依次调用。 optional string insertion_point = 2; // 待写入到源代码中的内容 optional string content = 15; } // 一次要处理的 proto文件可能有多个，所以插件处理后这里的file是一个list repeated File file = 15; }  下面看一下protoc与protoc插件这对父子进程之间是怎么通信的。\nfile: src/google/protobuf/compiler/subprocess.h\nclass LIBPROTOC_EXPORT Subprocess { public: Subprocess(); ~Subprocess(); enum SearchMode { SEARCH_PATH, // Use PATH environment variable. EXACT_NAME // Program is an exact file name; don't use the PATH. }; // Start the subprocess. Currently we don't provide a way to specify // arguments as protoc plugins don't have any. void Start(const string\u0026amp; program, SearchMode search_mode); // Serialize the input message and pipe it to the subprocess's stdin, then // close the pipe. Meanwhile, read from the subprocess's stdout and parse // the data into *output. All this is done carefully to avoid deadlocks. // Returns true if successful. On any sort of error, returns false and sets // *error to a description of the problem. bool Communicate(const Message\u0026amp; input, Message* output, string* error); // win32 relevant ... neglect private: #ifdef _WIN32 // ... #else // !_WIN32 pid_t child_pid_; // The file descriptors for our end of the child's pipes. We close each and // set it to -1 when no longer needed. int child_stdin_; int child_stdout_; #endif };  下面是Linux平台下的子进程启动处理逻辑。\nfile: src/google/protobuf/compiler/subprocess.cc\nvoid Subprocess::Start(const string\u0026amp; program, SearchMode search_mode) { // Note that we assume that there are no other threads, thus we don't have to // do crazy stuff like using socket pairs or avoiding libc locks. // [0] is read end, [1] is write end. int stdin_pipe[2]; int stdout_pipe[2]; GOOGLE_CHECK(pipe(stdin_pipe) != -1); GOOGLE_CHECK(pipe(stdout_pipe) != -1); char* argv[2] = { strdup(program.c_str()), NULL }; child_pid_ = fork(); if (child_pid_ == -1) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;fork: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } else if (child_pid_ == 0) { // We are the child. // 将子进程的stdin重定向到stdin_pipe的读端 dup2(stdin_pipe[0], STDIN_FILENO); // 将子进程的stdout重定向到stdout_pipe的写端 dup2(stdout_pipe[1], STDOUT_FILENO); // 子进程通过0、1对管道进行操作就够了，释放多余的fd close(stdin_pipe[0]); close(stdin_pipe[1]); close(stdout_pipe[0]); close(stdout_pipe[1]); // 根据程序搜索模式调用exec族函数来调用插件执行，exec族函数通过替换当前进 // 程的代码段、数据段等内存数据信息，然后调整寄存器信息，使得进程转而去执 // 行插件的代码。插件代码执行之前进程就已经将fd 0、1重定向到父进程clone过 // 来的管道了，因此插件程序的输出将直接被输出到父进程创建的管道中。 // 正常情况下，exec一旦执行成功，那么久绝不对执行switch后续的代码了，只有 // 出错才可能会执行到后续的代码。 switch (search_mode) { case SEARCH_PATH: execvp(argv[0], argv); break; case EXACT_NAME: execv(argv[0], argv); break; } // 只有出错才可能会执行到这里的代码。 // Write directly to STDERR_FILENO to avoid stdio code paths that may do // stuff that is unsafe here. int ignored; ignored = write(STDERR_FILENO, argv[0], strlen(argv[0])); const char* message = \u0026quot;: program not found or is not executable\\n\u0026quot;; ignored = write(STDERR_FILENO, message, strlen(message)); (void) ignored; // Must use _exit() rather than exit() to avoid flushing output buffers // that will also be flushed by the parent. _exit(1); } else { free(argv[0]); // 父进程释放无用的fd close(stdin_pipe[0]); close(stdout_pipe[1]); // 子进程的stdin，对父进程来说也就是管道stdin_pipe的写端，CodeGeneratorRequest将通过这个fd写给子进程 child_stdin_ = stdin_pipe[1]; // 子进程的stdout，对父进程来说也就是管道stdout_pipe的读端，CodeGeneratorResponse将通过这个fd从子进程读取 child_stdout_ = stdout_pipe[0]; } }  下面接着看父进程读取子进程返回的CodeGeneratorResponse的执行逻辑。\nbool Subprocess::Communicate(const Message\u0026amp; input, Message* output, string* error) { GOOGLE_CHECK_NE(child_stdin_, -1) \u0026lt;\u0026lt; \u0026quot;Must call Start() first.\u0026quot;; // The \u0026quot;sighandler_t\u0026quot; typedef is GNU-specific, so define our own. typedef void SignalHandler(int); // Make sure SIGPIPE is disabled so that if the child dies it doesn't kill us. SignalHandler* old_pipe_handler = signal(SIGPIPE, SIG_IGN); string input_data = input.SerializeAsString(); string output_data; int input_pos = 0; int max_fd = max(child_stdin_, child_stdout_); // child_stdout==-1的时候表示子进程返回的数据已经读取完毕了，可以gg了 while (child_stdout_ != -1) { fd_set read_fds; fd_set write_fds; FD_ZERO(\u0026amp;read_fds); FD_ZERO(\u0026amp;write_fds); if (child_stdout_ != -1) { FD_SET(child_stdout_, \u0026amp;read_fds); } if (child_stdin_ != -1) { FD_SET(child_stdin_, \u0026amp;write_fds); } // 这种情景下也用select，果然很google！ if (select(max_fd + 1, \u0026amp;read_fds, \u0026amp;write_fds, NULL, NULL) \u0026lt; 0) { if (errno == EINTR) { // Interrupted by signal. Try again. continue; } else { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;select: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // stdout_pipe写事件就绪，写请求CodeGeneratorRequest给子进程 if (child_stdin_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdin_, \u0026amp;write_fds)) { int n = write(child_stdin_, input_data.data() + input_pos, input_data.size() - input_pos); if (n \u0026lt; 0) { // Child closed pipe. Presumably it will report an error later. // Pretend we're done for now. input_pos = input_data.size(); } else { input_pos += n; } // 代码生成请求已经成功写给子进程了，关闭相关的fd if (input_pos == input_data.size()) { // We're done writing. Close. close(child_stdin_); child_stdin_ = -1; } } // stdin_pipe读事件就绪，读取子进程返回的CodeGeneratorResponse if (child_stdout_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdout_, \u0026amp;read_fds)) { char buffer[4096]; int n = read(child_stdout_, buffer, sizeof(buffer)); if (n \u0026gt; 0) { output_data.append(buffer, n); } else { // 子进程返回的CodeGeneratorResponse已经读取完毕，关闭相关的fd close(child_stdout_); child_stdout_ = -1; } } } // 子进程还没有读取CodeGeneratorRequest完毕，就关闭了输出，这种情况下也不可 // 能读取到返回的CodeGeneratorResponse了，这种情况很可能是出现了异常。 if (child_stdin_ != -1) { // Child did not finish reading input before it closed the output. // Presumably it exited with an error. close(child_stdin_); child_stdin_ = -1; } // 等待子进程结束，子进程退出之后，需要父进程来清理子进程占用的部分资源。 // 如果当前父进程不waitpid的话，子进程的父进程会变为init或者systemd进程，同样也会被清理的。 int status; while (waitpid(child_pid_, \u0026amp;status, 0) == -1) { if (errno != EINTR) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;waitpid: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // 刚才为了阻止SIGPIPE信号到达时导致进程终止，我们修改了SIGPIPE的信号处理函 // 数，这里可以恢复之前的SIGPIPE的信号处理函数。 signal(SIGPIPE, old_pipe_handler); // 根据子进程的退出状态执行后续的处理逻辑 // - 异常处理 if (WIFEXITED(status)) { if (WEXITSTATUS(status) != 0) { int error_code = WEXITSTATUS(status); *error = strings::Substitute( \u0026quot;Plugin failed with status code $0.\u0026quot;, error_code); return false; } } else if (WIFSIGNALED(status)) { int signal = WTERMSIG(status); *error = strings::Substitute( \u0026quot;Plugin killed by signal $0.\u0026quot;, signal); return false; } else { *error = \u0026quot;Neither WEXITSTATUS nor WTERMSIG is true?\u0026quot;; return false; } // 将子进程返回的串行化之后的CodeGeneratorResponse数据进行反串行化，反串行化 // 成Message对象，实际上这里的Message::ParseFromString(const string\u0026amp;)是个虚 // 函数，是被CodeGeneratorResponse这个类重写了的，反串行化过程与具体的类密切 // 相关，也必须在派生类中予以实现。 if (!output-\u0026gt;ParseFromString(output_data)) { *error = \u0026quot;Plugin output is unparseable.\u0026quot;; return false; } return true; }  到这里为止protoc进程的具体执行逻辑我们已经很清楚了，看到这里想必读者也看清楚了吧？下面再看下插件的执行逻辑。\n插件的执行逻辑一定也是非常简单的，插件就只是从stdin读取串行化之后的CodeGeneratorRequest请求，然后执行反串行化得到一个完整的CodeGeneratorRequest对象，然后根据请求进行必要的代码生成逻辑，确定要生成的源代码信息，并将其设置到CodeGeneratorResponse中并串行化后写入到stdout，插件的执行逻辑就这么简单。\n下面我们将进入插件的编写过程了。\n2.4. protoc插件开发 # 2.4.1. protoc中的descriptor定义 # proto文件中的数据类型都是在descriptor.proto中定义好的，为了更好地帮助我们对proto文件中的数据类型进行解析，为了在插件开发过程中更加方便快速地获得与数据类型、变量、rpc等相关的这种内容、那种内容，我们都需要深入地理解descriptor.proto中的相关定义以及从它延伸出来的一些概念、算法等。\n这部分的内容还不少，在不影响理解的大前提下，我还是稍微删减写些代码，避免对大家理解造成不必要的干扰。\nfile: src/google/protobuf/descriptor.proto\n// Author: kenton@google.com (Kenton Varda) // Based on original Protocol Buffers design by // Sanjay Ghemawat, Jeff Dean, and others. // descriptor.proto文件中的messages定义了proto文件中所能见到的所有的定义，一个有效的.proto文件在不提供其他信息（甚至不需要读取它的imports）能够直接被转换成一个FileDescriptorProto对象。 package google.protobuf; option java_package = \u0026quot;com.google.protobuf\u0026quot;; option java_outer_classname = \u0026quot;DescriptorProtos\u0026quot;; // descriptor.proto必须在速度方面优化，因为在启动过程中基于反射的算法不起作用 option optimize_for = SPEED; // protoc可以将解析的proto文件中的descriptor添加到FileDescriptorSet并输出到文件 message FileDescriptorSet { repeated FileDescriptorProto file = 1; } // 下面的message FileDescriptorProto可以用于描述一个完整的proto文件 message FileDescriptorProto { optional string name = 1; // proto文件名，file name，相对于源代码根目录 optional string package = 2; // proto包名，例如 \u0026quot;foo\u0026quot;、\u0026quot;foo.bar\u0026quot; repeated string dependency = 3; // proto文件中import进来的其他proto文件列表 repeated int32 public_dependency = 10; // 上面public import的proto文件在proto文件列表中的索引 // Indexes of the weak imported files in the dependency list. repeated int32 weak_dependency = 11; // 上面weak import的proto文件在proto文件列表中的索引 // 不要使用，只用于google内部的迁移 // proto文件中的所有顶层定义信息 repeated DescriptorProto message_type = 4; // 所有的消息(message)类型定义 repeated EnumDescriptorProto enum_type = 5; // 所有的枚举(enum)类型定义 repeated ServiceDescriptorProto service = 6; // 所有的服务(service)类型定义 repeated FieldDescriptorProto extension = 7; // 所有的扩展字段定义 optional FileOptions options = 8; // 文件选项 // 这个字段包括了源代码的相关信息，这里的信息可以给开发工具使用，也仅应该提供给开发工具使用； // 可以选择将这个字段中的信息删除，在程序运行期间并不会造成破坏。 optional SourceCodeInfo source_code_info = 9; } // 描述消息类型Message message DescriptorProto { optional string name = 1; // Message的类型名称 repeated FieldDescriptorProto field = 2; // Message中包括的字段列表 repeated FieldDescriptorProto extension = 6; // Message中包括的扩展列表 repeated DescriptorProto nested_type = 3; // Message中嵌套的Message类型列表 repeated EnumDescriptorProto enum_type = 4; // Message中嵌套的枚举类型列表 message ExtensionRange { optional int32 start = 1; optional int32 end = 2; } repeated ExtensionRange extension_range = 5; optional MessageOptions options = 7; } // 描述一个字段（字段可以是Message中的，也可以是某些扩展字段） message FieldDescriptorProto { // 字段数据类型 enum Type { // 0 is reserved for errors. // 由于历史方面的原因，这里的枚举值的顺序有点奇怪 TYPE_DOUBLE = 1; TYPE_FLOAT = 2; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT64 if // negative values are likely. TYPE_INT64 = 3; TYPE_UINT64 = 4; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT32 if // negative values are likely. TYPE_INT32 = 5; TYPE_FIXED64 = 6; TYPE_FIXED32 = 7; TYPE_BOOL = 8; TYPE_STRING = 9; TYPE_GROUP = 10; // Tag-delimited aggregate. TYPE_MESSAGE = 11; // Length-delimited aggregate. // New in version 2. TYPE_BYTES = 12; TYPE_UINT32 = 13; TYPE_ENUM = 14; TYPE_SFIXED32 = 15; TYPE_SFIXED64 = 16; TYPE_SINT32 = 17; // Uses ZigZag encoding. TYPE_SINT64 = 18; // Uses ZigZag encoding. }; // 字段修饰符optional、required、repeated enum Label { // 0 is reserved for errors LABEL_OPTIONAL = 1; LABEL_REQUIRED = 2; LABEL_REPEATED = 3; // TODO(sanjay): Should we add LABEL_MAP? }; optional string name = 1; // 字段名称 optional int32 number = 3; // 字段tag编号 optional Label label = 4; // 字段修饰符 // 如果type_name已设置，这个字段无须设置； // 如果这两个字段都设置了，这里的type字段必须是TYPE_ENUM类型或者TYPE_MESSAGE类型 optional Type type = 5; // 对于TYPE_ENUM或者TYPE_MESSAGE类型，type_name就是type的名字。 // 如果name以“.”开头那么它是完全保留的。对于C++来说，其作用域规则要求首先搜 // 索当前Message类型的嵌套类型，然后才是parent namespace中的类型，一直到root // namespace。 optional string type_name = 6; // 对于扩展，它就是被扩展的类型的名字，对它的解析与对type_name的解析时一样的 optional string extendee = 2; // 对于数值类型，存储了数值的文本表示形式； // 对于布尔类型，存储字符串\u0026quot;true\u0026quot;或\u0026quot;false\u0026quot;； // 对于字符串类型，存储原始的文本内容（未转义的） // 对于字节，存储了c转义后的值（所有\u0026gt;=128的字节都会被转义） // TODO(kenton)，基于base64编码的? optional string default_value = 7; optional FieldOptions options = 8; // 字段选项 } // 描述一个枚举类型enum message EnumDescriptorProto { optional string name = 1; // 枚举类型名称 repeated EnumValueDescriptorProto value = 2; // 枚举类型中包括的枚举值列表 optional EnumOptions options = 3; // 枚举类型选项 } // 描述一个枚举类型中的一个枚举值 message EnumValueDescriptorProto { optional string name = 1; // 枚举值对应的name optional int32 number = 2; // 枚举值对应的number（默认为0，依次递增） optional EnumValueOptions options = 3; // 枚举值选项 } // 描述一个rpc service. message ServiceDescriptorProto { optional string name = 1; // 服务名称 repeated MethodDescriptorProto method = 2; // 服务对应的方法列表 optional ServiceOptions options = 3; // 服务选项 } // 描述一个服务的方法 message MethodDescriptorProto { optional string name = 1; // 方法名称 optional string input_type = 2; // 方法入参类型 optional string output_type = 3; // 方法出参类型 optional MethodOptions options = 4; // 方法选项 } // =================================================================== // Options // 上面的每一个定义基本上都包括了选项option相关的字段，这些选项字段仅仅是一些 // 注解，这些注解会影响代码的生成，使得生成的代码稍有不同，注解也可能包含了操作 // message的代码的一些提示信息、说明信息。 // // clients可能会定义一些自定义的选项来作为*Options message的extensions，这些 // extensions在parsing阶段可能还无法确定下来，所以parser不能存储他们的值，而是 // 将这些自定义的选项先存储到一个*Options message里面，称之为 // uinterpreted_option。这个字段的名字在所有的*Options message里面都必须保证是 // 相同的。之后在我们构建descriptor的时候，这个时候所有的proto文件也都解析完了、 // 所有的extensions也都知道了，这个时候我们再用这里的uinterpreted_option字段去 // 填充那些extensions。 // // 用于自定义选项的extensions编号的选择一般遵循下面的方法： // * 对于只在一个应用程序或者组织内使用的选项，或者用于实验目的的选项，使用字 // 段编号50000~99999范围内的。对于多个选项，用户需要确保不使用相同的编号。 // * 对于可能被多个互不依赖的实体所共同使用的选项，需要给 // protobuf-global-extension-registry@google.com发邮件来申请预留扩展编号。需 // 要提供工程名称、工程站点，没必要解释为什么需要申请预留某个特定的编号。通 // 常只需要一个扩展编号，可以声明多个选项但是只使用这一个相同的扩展编号。如 // 果申请公共的扩展编号是个刚需，google可能会发布一个web service接口来自动分 // 配选项编号。 message FileOptions { // java包名，当前proto文件中生成的java类将位于这个package下 optional string java_package = 1; // 指定一个外部类名称，当前proto文件中生成的所有的类将被封装在这个外部类当中 optional string java_outer_classname = 8; // 如果设置为true，java代码生成器将为每个顶层message、enum、service定义生成 // 单独的java文件，默认为false optional bool java_multiple_files = 10 [default=false]; // 如果设置为true，java代码生成器将未每个message定义生成equals()、hashCode() // 方法，默认为false。本来AbstractMessage基类经包括了一个基于反射的equals()、 // hashCode()方法实现，这里的这个设置项是一个性能方面的优化 optional bool java_generate_equals_and_hash = 20 [default=false]; // 优化类型，生成的类可以进行速度优化、代码尺寸优化 enum OptimizeMode { SPEED = 1; // Generate complete code for parsing, serialization, // etc. CODE_SIZE = 2; // Use ReflectionOps to implement these methods. LITE_RUNTIME = 3; // Generate code using MessageLite and the lite runtime. } optional OptimizeMode optimize_for = 9 [default=SPEED]; // 设置go代码的包名 optional string go_package = 11; // 是否应该针对每一门语言都生成generice services？generic服务并不特定于任何 // 的rpc系统，它是由每个语言的注代码生成器来生成的，不借助于额外的插件。 // generic services是早期protoo2这个版本说支持的唯一一种服务类型。 // // 由于现在推崇使用plugins，plugins可以生成针对特定rpc系统的代码，generic // services现在可以看做是被废弃了。因此，以前proto2总的generice services的默 // 认设置默认为false，早期的依赖于generic services的代码需要显示设置这些选项 // 为true。 optional bool cc_generic_services = 16 [default=false]; optional bool java_generic_services = 17 [default=false]; optional bool py_generic_services = 18 [default=false]; // parser将不识别的选项存储在这里的uinterpreted_option repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message MessageOptions { // 设为true则使用老的proto1 MessageSet wire format……兼容性目的，没必要使用 optional bool message_set_wire_format = 1 [default=false]; // 禁用标准的descriptor()方法的生成，因为如果有个字段名是descriptor的话会生 // 成一个同名的函数，会冲突。这使得从proto1迁移到后续版本更简单，但是新版本 // 中还是应该避免使用字段descriptor。 optional bool no_standard_descriptor_accessor = 2 [default=false]; // parser将不识别的选项存储在这个字段里 repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message FieldOptions { // 开启packed选项之后，对于repeated基本数据类型字段的表示会更加高效。不再针 // 对repeated字段中的各个元素执行写tag、类型操作，而是将整个数组作为一个固定 // 长度的blob来存储。 optional bool packed = 2; // 当前字段是否需要lazy parsing？只是建议，lazy为true，protoc不一定lazy parsing optional bool lazy = 5 [default=false]; // 当前字段是否已经被废弃，跟目标平台相关，这个字段可以为生成的accessor方法 // 生成Deprecated注解，如果目标平台不支持就会忽略这个选项。不管目标平台是否 // 支持，proto里面要想废弃一个字段加deprecated选项还是非常正确的做法。 optional bool deprecated = 3 [default=false]; // map字段，目前还未完全实现，应避免使用 optional string experimental_map_key = 9; // google内部迁移使用，因避免使用 optional bool weak = 10 [default=false]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumOptions { // 不允许将多个不同的tag names映射到一个相同的值 // - 意思是说不允许多个字段的编号相同 optional bool allow_alias = 2 [default=true]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumValueOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message ServiceOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message MethodOptions { // 注意：字段编号1~32被保留给google内部rpc框架使用，google的解释是，在 // protobuf被公开给外部使用之前内部就已经大量使用了，且1~32倍使用的很多，也 // 是不得已的事情，总不能为了开源、推广一个内部组件就把自己的生意砸了吧。 // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } // 描述一个parser不认识的option message // - UninterpretedOption只会出现在compiler::Parser类创建的options protos中； // - 构建Descriptor对象的时候DescriptorPool会解析UninterpretedOptions； // 因此，descriptor对象中的options protos（通过Descriptor::options()返回，或者 // 通过Descriptor::CopyTo()生成）是不会包括UinterpretedOptions的。 message UninterpretedOption { // uinterpreted选项的名字，name中每个元素的name_part字段都表示name中的点分字 // 符串的一段，如果name_part是一个扩展（通过在字符串两端用括号括起来表示）， // is_extension字段为true。 // 例如，{[\u0026quot;foo\u0026quot;, false], [\u0026quot;bar.baz\u0026quot;,true], [\u0026quot;qux\u0026quot;,false]}表示\u0026quot;foo.(bar.baz).qux\u0026quot;。 message NamePart { required string name_part = 1; required bool is_extension = 2; } repeated NamePart name = 2; // uinterpreted选项的值，会设置下面字段中其中一个的值 optional string identifier_value = 3; optional uint64 positive_int_value = 4; optional int64 negative_int_value = 5; optional double double_value = 6; optional bytes string_value = 7; optional string aggregate_value = 8; } // =================================================================== // Optional source code info // FileDescriptorProto是从之前的source file中生成的（source file指的是proto文 // 件），这里的SourceCodeInfo指的是proto中的“源代码”信息。 message SourceCodeInfo { // Location用于识别proto文件中的源代码片段，往往对应着一个特定的定义。这些 // Location信息对于IDE、代码索引工具、文档生成工具等是非常重要的。 // // 下面说明一下Location的概念和作用，以下面这个message为例： // message Foo { // optional string foo = 1; // } // 我们先只看上面这个message中的字段定义： // optional string foo = 1; // ^ ^^ ^^ ^ ^^^ // a bc de f ghi // 我们可以得到下面这几个Location： // span path represents // [a,i) [ 4, 0, 2, 0 ] The whole field definition. // [a,b) [ 4, 0, 2, 0, 4 ] The label (optional). // [c,d) [ 4, 0, 2, 0, 5 ] The type (string). // [e,f) [ 4, 0, 2, 0, 1 ] The name (foo). // [g,h) [ 4, 0, 2, 0, 3 ] The number (1). // // 每个proto文件解析之后用一个FileDescriptorProto来表示，所以Lcoation路径位 // 置从FileDescriptorProto开始。 // - 因为message Foo是一个message，proto中所有顶层message类型定义都在 // FileDescriptorProto中message_type字段存储，这个字段的tag是4，所以Location为[4]； // - 又因为message_type是repeated DescriptorProto类型，因为当前proto示例中 // Foo为第一个message，所以其在message_type列表中的索引值为0，所以Location为[4,0]； // - 因为我们现在看的“源代码”是“optional string foo = 1;”，我们需要定位到 // message中的字段位置，message Foo中的所有字段都在DescriptorProto中的field字 // 段中记录，这个字段的tag=2，所以Location变为[4,0,2]； // - 又因为这个DescriptorProto中的field为repeated FieldDescriptorProto field， // 因为这个message中只有一个字段foo，所以foo在field列表中的索引值为0，Location变为[4,0,2,0]; // 上面解释了定位到完整的“optional string foo = 1”定义这个field的Location变 // 化过程，下面再说一下label、type、name、number的Location如何进一步确定。 // FieldDescriptorProto中label的tag位4，type的tag为5，name的tag为1，number的 // tag为3，Location对应的追加索引4、5、1、3。gg! // // proto文件中的源代码信息就是由一系列的Location来寻址的。 repeated Location location = 1; message Location { // 前面已经描述了Location的确定过程，一个Location如[4,0,2,0]其中的数字要么 // 是字段的tag编号要么是repeated列表中的索引值，这里的数字构成的数组保存在 // path中。 repeated int32 path = 1 [packed=true]; // 该字段span总是包括3个或者4个元素，依次表示startline、startcolumn、endline、endcolumn repeated int32 span = 2 [packed=true]; // 如果这个SourceCodeInfo代表一个完整的声明的话，可能在这个声明的前面或者 // 后面可能有一些attached的注释。 // // 连续的多个行注释看做是一个单独的注释。 // // 这个字段只记录了注释内容，不包括注释内容开头的注释符号//。对于块注释， // 注释前面的空白字符、*这几种符号也会被清理掉。但是会包括换行符。 // // Examples: // // optional int32 foo = 1; // Comment attached to foo. // // Comment attached to bar. // optional int32 bar = 2; // // optional string baz = 3; // // Comment attached to baz. // // Another line attached to baz. // // // Comment attached to qux. // // // // Another line attached to qux. // optional double qux = 4; // // optional string corge = 5; // /* Block comment attached // * to corge. Leading asterisks // * will be removed. */ // /* Block comment attached to // * grault. */ // optional int32 grault = 6; // Location前面的注释信息 optional string leading_comments = 3; // Location后面的注释信息 optional string trailing_comments = 4; } }  2.4.2. 可以提取proto文件中的哪些信息 \u0026amp; 如何提取 # 前一节2.4.1中对descriptor.proto进行了详细地描述，可以说在proto文件中写的每一行内容都可以通过解析FileDescriptorProto来访问到。proto文件只是一种自描述的消息格式，基于这种格式生成面向特定编程语言的源代码文件时，我们想获取的信息不外乎如下几个：\n 待生成的源文件的包名； 待生成的源文件的wrapper class类名； proto文件中定义的各个类型，包括枚举enum、消息message、服务service； 对于枚举enum需要知道枚举类型名、列出的枚举值（包括字段、值、注释信息）、注释信息； 对于消息message需要知道类型名、类成员（包括成员类型、成员名称、定义顺序、默认值、注释信息）、注释信息； 对于服务service需要知道服务名称、服务rpc接口（rpc接口的请求参数、返回值类型、注释信息）、注释信息； proto中可以添加注解吗？注解可以提取出来吗？  如何提取上述信息呢？可以肯定地是，只要能拿到当前proto文件对应的FileDescriptorProto，上述内容几乎都可以获取到。但是如何获取到对应的proto文件对应的这个FileDescriptorProto对象呢？下面我们先来看一个protoc插件的示例代码吧，看完之后，大家也就了解了如何获取proto对应的FileDescriptorProto以及如何从中提取想要的1~7上述信息，生成源代码文件也就简单了。\n2.4.3. protoc go语言插件protoc-gen-go # protoc-gen-go的源代码可以通过通过如下方式获取：\ngit co https://github.com/golang/protobuf git branch -b ${new-branch}  2.4.3.1. protoc-gen-go入口函数分析 # file: protobuf/protoc-gen-go/main.go\npackage main import ( \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; \u0026quot;github.com/c4pt0r/proto\u0026quot; \u0026quot;github.com/c4pt0r/protoc-gen-go/generator\u0026quot; ) func main() { // 首先创建一个代码生成器generator，CodeGeneratorRequest、CodeGeneratorResponse // 结构体都被保存在generator中，CodeGenerateResponse中保存着代码生成过程中 // 的错误状态信息，因此我们可以通过这个结构体提取错误状态并进行错误处理 g := generator.New() // 从标准输入中读取CodeGeneratorRequest信息（标准输入已经被重定向到了父进程 // protoc进程创建的管道stdout_pipe的读端，父进程会从管道的写端写入该请求信息） data, err := ioutil.ReadAll(os.Stdin) if err != nil { g.Error(err, \u0026quot;reading input\u0026quot;) } // 读取到的数据时串行化之后的CodeGeneratorRequest，将其反串行化成CodeGeneratorRequest if err := proto.Unmarshal(data, g.Request); err != nil { g.Error(err, \u0026quot;parsing input proto\u0026quot;) } // 检查CodeGeneratorRequest中待生成的源代码文件数量，数量为0则无需生成 if len(g.Request.FileToGenerate) == 0 { g.Fail(\u0026quot;no files to generate\u0026quot;) } // 将CodeGeneratorRequest中传递给代码生成器的参数设置到protoc插件的代码生成器中 g.CommandLineParameters(g.Request.GetParameter()) // 前面的proto.Unmarshal(...)操作将stdin中的请求反串行化成了CodeGeneratorRequest， // 这里的g.WrapTypes()将请求中的一些descriptors进行进一步封装，方便后面引用 g.WrapTypes() g.SetPackageNames() g.BuildTypeNameMap() // 生成所有的源代码文件 g.GenerateAllFiles() // 将CodeGeneratorResponse对象进行串行化处理 data, err = proto.Marshal(g.Response) if err != nil { g.Error(err, \u0026quot;failed to marshal output proto\u0026quot;) } // 将串行化之后的CodeGenerateResponse对象数据写入标准输出（标准输出已经被 // 重定向到了父进程protoc进程创建的管道stdin_pipe的写端，父进程从管道的读 // 端读取这里的响应） _, err = os.Stdout.Write(data) if err != nil { g.Error(err, \u0026quot;failed to write output proto\u0026quot;) } }  2.4.3.2. 回顾一下CodeGeneratorRequest \u0026amp; CodeGeneratorResponse的定义 # 下面看下CodeGeneratorRequest和CodeGeneratorResponse的定义。\nfile: ${protobuf}/src/google/protobuf/compiler/plugin.go\n// 串行化后的CodeGeneratorRequest信息会被写入到插件程序的stdin message CodeGeneratorRequest { // protoc命令执行时，我们在命令行中列出了需要进行处理的.proto文件的名称，代 // 码生成器应该只为这些.proto文件生成源代码文件。每一个.proto文件成功解析之 // 后会生成一个FileDescriptorProto对象，这个对象会被加入到字段proto_file中 repeated string file_to_generate = 1; // protoc命令行程序中传递给插件程序代码生成器的参数信息 optional string parameter = 2; // protoc命令行中列出的所有的.proto文件被添加到了字段file_to_generate中，这 // 些.proto文件中通过import引入进来的文件，这两部分文件解析成功后对应的 // FileDescriptorProto对象都会被加入到这里的proto_file中，添加后的顺序是按照 // 拓扑顺序排序的，怎么讲？就是被import的proto文件会出现在import它们的 proto // 文件前面。 repeated FileDescriptorProto proto_file = 15; } // 串行化后的CodeGeneratorResponse信息会被写入到插件的stdout message CodeGeneratorResponse { // 如果错误信息非空，表示代码生成失败。这种情况下尽管代码生成失败，插件进程 // 仍然应该返回一个状态0。 // // 这个字段用于指示.proto文件错误，.proto文件中的错误将使得代码生成器无法生 // 成正确的代码。指示protoc本身的错误，例如CodeGeneratorRequest数据无法被正 // 确地反串行化，这种情况应该被报告，错误信息应该写到stderr并且插件进程应该 // 返回一个非0状态码 optional string error = 1; // 描述一个待生成的源代码文件 message File { // 待生成的源代码文件相对于输出目录的文件名 optional string name = 1; // 写入到源代码文件中的插入点信息，方便后面的插件在插入点处进行扩展其他内容 optional string insertion_point = 2; // 写入到文件或者文件插入点位置的内容 optional string content = 15; } // 所有的待生成的源代码文件列表 repeated File file = 15; }  2.4.3.3. generator实现分析 # main.go中调用了generator的几个关键方法，我们先来看下这几个方法都做了些什么，然 后再跟进一步看看generator的详细实现过程。\n2.4.3.3.1. generator.New() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// Generator类型的方法能够输出源代码，这些输出的源代码信息存储在Response成员中 type Generator struct { *bytes.Buffer Request *plugin.CodeGeneratorRequest // The input. Response *plugin.CodeGeneratorResponse // The output. Param map[string]string // Command-line parameters. PackageImportPath string // Go import path of the package we're generating code for ImportPrefix string // String to prefix to imported package file names. ImportMap map[string]string // Mapping from .proto file name to import path Pkg map[string]string // The names under which we import support packages packageName string // What we're calling ourselves. allFiles []*FileDescriptor // All files in the tree allFilesByName map[string]*FileDescriptor // All files by filename. genFiles []*FileDescriptor // Those files we will generate output for. file *FileDescriptor // The file we are compiling now. usedPackages map[string]bool // Names of packages used in current file. typeNameToObject map[string]Object // Key is a fully-qualified name in input syntax. init []string // Lines to emit in the init function. indent string writeOutput bool } // 创建一个新的代码生成器，并创建请求、响应对象 func New() *Generator { g := new(Generator) g.Buffer = new(bytes.Buffer) g.Request = new(plugin.CodeGeneratorRequest) g.Response = new(plugin.CodeGeneratorResponse) return g }  2.4.3.3.2. generator.CommandLineParameters(\u0026hellip;) # 这个函数是负责解析protoc传递过来的命令行参数信息的。\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 将都好分隔的key=value列表解析成\u0026lt;key,value\u0026gt; map func (g *Generator) CommandLineParameters(parameter string) { g.Param = make(map[string]string) for _, p := range strings.Split(parameter, \u0026quot;,\u0026quot;) { if i := strings.Index(p, \u0026quot;=\u0026quot;); i \u0026lt; 0 { g.Param[p] = \u0026quot;\u0026quot; } else { g.Param[p[0:i]] = p[i+1:] } } g.ImportMap = make(map[string]string) pluginList := \u0026quot;none\u0026quot; // Default list of plugin names to enable (empty means all). for k, v := range g.Param { switch k { case \u0026quot;import_prefix\u0026quot;: g.ImportPrefix = v case \u0026quot;import_path\u0026quot;: g.PackageImportPath = v // --go_out=plugins=grpc:.，解析这里的参数plugins=grpc case \u0026quot;plugins\u0026quot;: pluginList = v default: if len(k) \u0026gt; 0 \u0026amp;\u0026amp; k[0] == 'M' { g.ImportMap[k[1:]] = v } } } // 在protoc-gen-go的某个地方已经将grpc插件注册到了当前generator（也就是添 // 加到plugins []Plugin中），但是到底是在哪里注册的呢？只有注册并激活（参 // 数中通过--go_out=plugins=grpc:.)grpc子插件，该子插件才能被使用于后续的 // 代码生成过程中（生成rpc相关的go源代码）。 // // 其实这里的grpc子插件注册是利用了link_grpc.go里面的import _操作来隐式地 // 调用了grpc.init()方法，该初始化方法中负责完成向generator的注册操作，即 // generator.RegisterPlugin(new(grpc))，这里的RegisterPlugin其实就是将指定 // 的子插件加入到plugins []Plugin slice中。 // 为了能够在protoc-gen-go中正确地将grpc link进去，在构建protoc-gen-go的时 // 候需要执行命令： // cd protoc-gen-go \u0026amp; go build main.go link_grpc.go // go build的时候如果没有列出link_grpc.go，那么grpc是不会被link进 // protoc-gen-go这个插件的，这样处理.proto文件中的service时插件是不会生成 // service相关的go源代码的。 // 根据--go_out=plugins=?+?+?:.，更新激活的插件列表 if pluginList != \u0026quot;\u0026quot; { // Amend the set of plugins. enabled := make(map[string]bool) for _, name := range strings.Split(pluginList, \u0026quot;+\u0026quot;) { enabled[name] = true } var nplugins []Plugin for _, p := range plugins { if enabled[p.Name()] { nplugins = append(nplugins, p) } } plugins = nplugins } }  2.4.3.3.3. generator.WrapTypes() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// WrapTypes walks the incoming data, wrapping DescriptorProtos, EnumDescriptorProtos // and FileDescriptorProtos into file-referenced objects within the Generator. // It also creates the list of files to generate and so should be called before GenerateAllFiles. func (g *Generator) WrapTypes() { g.allFiles = make([]*FileDescriptor, 0, len(g.Request.ProtoFile)) g.allFilesByName = make(map[string]*FileDescriptor, len(g.allFiles)) for _, f := range g.Request.ProtoFile { // We must wrap the descriptors before we wrap the enums descs := wrapDescriptors(f) g.buildNestedDescriptors(descs) enums := wrapEnumDescriptors(f, descs) g.buildNestedEnums(descs, enums) exts := wrapExtensions(f) fd := \u0026amp;FileDescriptor{ FileDescriptorProto: f, desc: descs, enum: enums, ext: exts, exported: make(map[Object][]symbol), proto3: fileIsProto3(f), } extractComments(fd) g.allFiles = append(g.allFiles, fd) g.allFilesByName[f.GetName()] = fd } for _, fd := range g.allFiles { fd.imp = wrapImported(fd.FileDescriptorProto, g) } g.genFiles = make([]*FileDescriptor, 0, len(g.Request.FileToGenerate)) for _, fileName := range g.Request.FileToGenerate { fd := g.allFilesByName[fileName] if fd == nil { g.Fail(\u0026quot;could not find file named\u0026quot;, fileName) } fd.index = len(g.genFiles) g.genFiles = append(g.genFiles, fd) } }  2.4.3.3.4. generator.GenerateAllFiles() # 调用generator针对所有解析成功的proto文件生成所有的go源代码\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 生成所有.proto文件对应的go源代码，这里只是将源代码内容存储到g.Response中， // 并没有直接创建源代码文件，插件将Response传递给protoc进程后由protoc进程来负 // 责创建源代码文件 func (g *Generator) GenerateAllFiles() { // Initialize the plugins for _, p := range plugins { p.Init(g) } // Generate the output. The generator runs for every file, even the files // that we don't generate output for, so that we can collate the full list // of exported symbols to support public imports. genFileMap := make(map[*FileDescriptor]bool, len(g.genFiles)) for _, file := range g.genFiles { genFileMap[file] = true } for _, file := range g.allFiles { g.Reset() g.writeOutput = genFileMap[file] // 调用generator的generate(...)方法来生成该proto文件的 // FileDescriptorProto描述对应的go源代码 g.generate(file) if !g.writeOutput { continue } g.Response.File = append(g.Response.File, \u0026amp;plugin.CodeGeneratorResponse_File{ Name: proto.String(file.goFileName()), Content: proto.String(g.String()), }) } }  再看下generator.generate(\u0026hellip;)方法是如何实现的。\n// 针对.proto文件（由FileDescriptor表示）生成对应的go源代码 func (g *Generator) generate(file *FileDescriptor) { g.file = g.FileOf(file.FileDescriptorProto) g.usedPackages = make(map[string]bool) // 要生成源代码的首个proto文件对应的go源代码，这部分代码顶部插入版权信息 if g.file.index == 0 { // For one file in the package, assert version compatibility. g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the proto package it is being compiled against.\u0026quot;) g.P(\u0026quot;// A compilation error at this line likely means your copy of the\u0026quot;) g.P(\u0026quot;// proto package needs to be updated.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, g.Pkg[\u0026quot;proto\u0026quot;], \u0026quot;.ProtoPackageIsVersion\u0026quot;, generatedCodeVersion, \u0026quot; // please upgrade the proto package\u0026quot;) g.P() } // 生成import语句 for _, td := range g.file.imp { g.generateImported(td) } // 生成enum类型定义语句 for _, enum := range g.file.enum { g.generateEnum(enum) } // 生成message类型定义语句 for _, desc := range g.file.desc { // Don't generate virtual messages for maps. if desc.GetOptions().GetMapEntry() { continue } g.generateMessage(desc) } // 生成extension类型定义语句 for _, ext := range g.file.ext { g.generateExtension(ext) } // 生成初始化函数语句 g.generateInitFunction() // 前面生成enum、message、extension等的方式都基本类似，后面我们只给出一个 // 生成枚举类型方法的说明，生成message、extension的实现方法可以执行查看 // generator.go中的实现。 // // 需要注意的是，前面的各个生成源代码的方法不能处理service服务定义的rpc接 // 口代码，这部分rpc代码的生成需要借助于grpc子插件来完成，即下面的g.runPlugins(...) g.runPlugins(file) g.generateFileDescriptor(file) // 待输出的源代码需要知道哪些package是需要import的，哪些不需要，因此先运行 // 插件生成go代码中除import之外的其他部分代码，然后知道了哪些package需要 // import，再插入具体的import语句。 // // 最后在go源代码中插入header、import rem := g.Buffer g.Buffer = new(bytes.Buffer) g.generateHeader() g.generateImports() if !g.writeOutput { return } g.Write(rem.Bytes()) // 重新格式化生成的go源代码（gofmt） fset := token.NewFileSet() raw := g.Bytes() ast, err := parser.ParseFile(fset, \u0026quot;\u0026quot;, g, parser.ParseComments) if err != nil { // Print out the bad code with line numbers. // This should never happen in practice, but it can while changing generated code, // so consider this a debugging aid. var src bytes.Buffer s := bufio.NewScanner(bytes.NewReader(raw)) for line := 1; s.Scan(); line++ { fmt.Fprintf(\u0026amp;src, \u0026quot;%5d\\t%s\\n\u0026quot;, line, s.Bytes()) } g.Fail(\u0026quot;bad Go source code was generated:\u0026quot;, err.Error(), \u0026quot;\\n\u0026quot;+src.String()) } g.Reset() err = (\u0026amp;printer.Config{Mode: printer.TabIndent | printer.UseSpaces, Tabwidth: 8}).Fprint(g, fset, ast) if err != nil { g.Fail(\u0026quot;generated Go source code could not be reformatted:\u0026quot;, err.Error()) } }  上面generate.generate(\u0026hellip;)方法中generateEnum()、generateMessage()方法与其他几个方法都是非常类似的，由于大家使用protobuf过程中使用enum、message比较多，并且generateEnum()、generateMessage()方法执行逻辑非常相似，考虑到篇幅方面generateEnum()比generateMessage()简短，这里我们就只以generateEnum()的源代码作为示例进行分析。相信如果看懂了generateEnum的实现思路，generateMessage的实现思路也很容易搞明白，读者也具备了自己实现子插件的能力。\n// 生成指定enum类型的go源代码 func (g *Generator) generateEnum(enum *EnumDescriptor) { // enum类型的完整类型名 typeName := enum.TypeName() // CamelCased之后的完整类型名 ccTypeName := CamelCaseSlice(typeName) ccPrefix := enum.prefix() // 打印enum类型定义之前的leading comments // - 提取源代码信息SourceCodeInfo都是通过Location path来获取的； // - 提取注释信息也不例外，下面我们会介绍PrintComments(path)如何通过 // Location path来生成注释信息； g.PrintComments(enum.path) // 生成枚举类型的定义起始部分：type 枚举类型名 int32 g.P(\u0026quot;type \u0026quot;, ccTypeName, \u0026quot; int32\u0026quot;) g.file.addExport(enum, enumSymbol{ccTypeName, enum.proto3()}) // 枚举类型里面的各个枚举值都作为const int32常量来定义 g.P(\u0026quot;const (\u0026quot;) // 枚举值定义之前缩进一下 g.In() // 针对枚举类型里面的所有枚举值进行源代码生成 for i, e := range enum.Value { // 生成枚举值前面的leading comments g.PrintComments(fmt.Sprintf(\u0026quot;%s,%d,%d\u0026quot;, enum.path, enumValuePath, i)) // 生成枚举值的name = value形式的go源代码 name := ccPrefix + *e.Name g.P(name, \u0026quot; \u0026quot;, ccTypeName, \u0026quot; = \u0026quot;, e.Number) g.file.addExport(enum, constOrVarSymbol{name, \u0026quot;const\u0026quot;, ccTypeName}) } // 枚举值定义完之后取消缩进 g.Out() // 打印最后的结束信息 g.P(\u0026quot;)\u0026quot;) // 生成枚举类型相关的两个map // - 其中一个是枚举值到枚举名的映射； // - 另一个是枚举名到枚举值的映射； g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_name = map[int32]string{\u0026quot;) g.In() // 第一个map generated := make(map[int32]bool) // avoid duplicate values for _, e := range enum.Value { duplicate := \u0026quot;\u0026quot; if _, present := generated[*e.Number]; present { duplicate = \u0026quot;// Duplicate value: \u0026quot; } g.P(duplicate, e.Number, \u0026quot;: \u0026quot;, strconv.Quote(*e.Name), \u0026quot;,\u0026quot;) generated[*e.Number] = true } g.Out() g.P(\u0026quot;}\u0026quot;) // 第二个map g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_value = map[string]int32{\u0026quot;) g.In() for _, e := range enum.Value { g.P(strconv.Quote(*e.Name), \u0026quot;: \u0026quot;, e.Number, \u0026quot;,\u0026quot;) } g.Out() g.P(\u0026quot;}\u0026quot;) // 其他处理动作，也会生成部分源代码，这里可以忽略不计了 // ... }  下面看一下PrintComments如何通过Location path来提取并打印关联的注释信息。\n// 打印.proto文件中对该location path关联的leading comments注释信息 func (g *Generator) PrintComments(path string) bool { if !g.writeOutput { return false } // 在protoc进程解析.proto文件的时候就已经将各个类型、字段的comments信息维 // 护起来了，k就是location的path，通过path就能获取到对应的location，每个 // location中保存了这个位置的源代码的leading comments、trailing comments信 // 息，这里只打印leading comments if loc, ok := g.file.comments[path]; ok { text := strings.TrimSuffix(loc.GetLeadingComments(), \u0026quot;\\n\u0026quot;) for _, line := range strings.Split(text, \u0026quot;\\n\u0026quot;) { g.P(\u0026quot;// \u0026quot;, strings.TrimPrefix(line, \u0026quot; \u0026quot;)) } return true } return false }  看到这里我们对于基本的enum、message类型定义等都基本清楚了，下面我们需要看一下grpc子插件是如何生成service服务的rpc接口源代码的，这样的话，就得再来看一下g.runPlugins(file)是如何实现的。\n// Run all the plugins associated with the file. func (g *Generator) runPlugins(file *FileDescriptor) { // 在上述generator处理的基础上，继续运行generator中注册的插件，依次运行插件 for _, p := range plugins { p.Generate(file) } }  因为上述runPlugins(\u0026hellip;)执行过程中，plugins这个slice内只有一个有效的、激活的子插件grpc，因此如果我们想了解service服务对应的rpc接口的实现方式，我们需要就只需要了解grpc这个插件的Generate(file)方法就可以了。\n// 生成.proto文件中service定义的rpc接口的go源代码 func (g *grpc) Generate(file *generator.FileDescriptor) { // 如果没有定义service服务直接返回 if len(file.FileDescriptorProto.Service) == 0 { return } // 相关变量定义 g.P(\u0026quot;// Reference imports to suppress errors if they are not otherwise used.\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, contextPkg, \u0026quot;.Context\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P() // 断言，检查版本兼容性 g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the grpc package it is being compiled against.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, grpcPkg, \u0026quot;.SupportPackageIsVersion\u0026quot;, generatedCodeVersion) g.P() // 针对所有的service定义生成相关的service的go源代码 for i, service := range file.FileDescriptorProto.Service { g.generateService(file, service, i) } } // grpc中对generateService的实现，生成service相关的go源代码 // @param .proto解析后的各种DescriptorProto的wrapping类，通过它可以方便地访问.proto中定义的东西 // @param .proto中的某个service解析后对应的ServiceDescriptorProto // @param .proto中可能定义了多个service，当前这个service对应的索引值 func (g *grpc) generateService(file *generator.FileDescriptor, service *pb.ServiceDescriptorProto, index int) { // 构建当前service对应的path! path := fmt.Sprintf(\u0026quot;6,%d\u0026quot;, index) // 6 means service. // 获取service名称 origServName := service.GetName() fullServName := origServName if pkg := file.GetPackage(); pkg != \u0026quot;\u0026quot; { fullServName = pkg + \u0026quot;.\u0026quot; + fullServName } servName := generator.CamelCase(origServName) // 准备生成client相关的go源代码 g.P() g.P(\u0026quot;// Client API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务用户端go源代码生成 // - type 服务名+Client interface g.P(\u0026quot;type \u0026quot;, servName, \u0026quot;Client interface {\u0026quot;) // - 服务用户端定义的各个接口方法 for i, method := range service.Method { // 打印接口的leading comments g.gen.PrintComments(fmt.Sprintf(\u0026quot;%s,2,%d\u0026quot;, path, i)) // 2 means method in a service. // 生成接口的签名 g.P(g.generateClientSignature(servName, method)) } g.P(\u0026quot;}\u0026quot;) g.P() // 服务的用户端struct，其中包括了一个cc *grpc.ClientConn，后面会在该struct // 上实现上述服务接口 g.P(\u0026quot;type \u0026quot;, unexport(servName), \u0026quot;Client struct {\u0026quot;) g.P(\u0026quot;cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() // NewClient工厂 g.P(\u0026quot;func New\u0026quot;, servName, \u0026quot;Client (cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn) \u0026quot;, servName, \u0026quot;Client {\u0026quot;) g.P(\u0026quot;return \u0026amp;\u0026quot;, unexport(servName), \u0026quot;Client{cc}\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() var methodIndex, streamIndex int serviceDescVar := \u0026quot;_\u0026quot; + servName + \u0026quot;_serviceDesc\u0026quot; // 服务用户端的接口方法实现 for _, method := range service.Method { var descExpr string if !method.GetServerStreaming() \u0026amp;\u0026amp; !method.GetClientStreaming() { // Unary RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Methods[%d]\u0026quot;, serviceDescVar, methodIndex) methodIndex++ } else { // Streaming RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Streams[%d]\u0026quot;, serviceDescVar, streamIndex) streamIndex++ } g.generateClientMethod(servName, fullServName, serviceDescVar, method, descExpr) } g.P(\u0026quot;// Server API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务端接口go源代码生成 ... }  看完之后我们已经清楚了generator做了什么、grpc子插件又做了什么，以及各自的细节是什么样的。下面我们将在此学习、理解的基础上开发一个自己的protoc插件。\n"}),a.add({id:437,href:"/tags/aio/",title:"aio",description:"",content:""}),a.add({id:438,href:"/tags/io-multiplex/",title:"io-multiplex",description:"",content:""}),a.add({id:439,href:"/blog/2017-05-02-linux-common-io-model/",title:"Linux常见IO模型",description:"高性能服务器开发，离不开对网络IO的深刻认识。本文结合Linux平台，详细总结了阻塞IO、非阻塞IO、IO多路复用、实时信号驱动、异步IO的原理、使用、适用场景，加深了对网络IO的认识。",content:"目前Linux下可用的IO模型有5种，分别为阻塞IO、非阻塞IO、IO多路复用、信号驱动IO、异步IO，其中较为成熟且高效、稳定的是IO多路复用模型，因此当前众多网络服务程序几乎都是采用这种IO操作策略。\n当一个应用程序读写（以读为例）某端口数据时，选择不同IO模型的应用程序，其执行流程也将不同。下面将对选择这5种不同IO模型时的程序的执行情形进行分析，以便了解使用IO复用模型的运行情况和性能优势。\n一个完整经典的应用程序的数据读取操作可以看做两步：\n 等待数据准备好； 将数据从内核复制到应用程序进程；  1. 阻塞IO模型 # 最流行的IO模型是阻塞IO（Blocking IO）模型，几乎所有刚开始学习IO操作的人员都是使用这个模型，虽然它存在一定的性能缺陷，但是它的确很简单。\n如下图所示，是利用该模型读取IO端口数据的典型流程。在有些情况下，当系统调用发现用户请求的IO操作不能立刻完成时（比如对IO写操作，缓冲区没有空闲空间或者空闲空间少于待写的数据量；而对于读操作，缓冲区中没有数据可读或者可读数据少于用户请求的数据量），则当前的进程会进入睡眠，也就是进程被IO读写阻塞。但是当数据可以写出或者有数据可供读入时（其他进程或线程从缓冲区中读走了数据后或者向缓冲区写入了数据），系统将会产生中断，唤醒在缓冲区上等待相应事件的进程继续执行。\n 备注：\n有必要在这里进一步解释一下“阻塞IO”的含义。通过阻塞IO系统调用进行IO操作时，以read为例，在内核将数据拷贝到用户程序完成之前，Linux内核会对当前read请求操作的缓冲区（内存中的特殊区域）进行加锁，并且会将调用read的进程的状态设置为 “uninterruptible wait”状态（不可中断等待状态），处于该状态的进程将无法参与进程调度。能够参与进程调度的进程的状态必须是处于running状态的进程或者有信号到达的处于interruptible wait状态（可中断等待状态）的进程。当read操作完成时，内核会将对应的缓冲块解锁，然后发出中断请求，内核中的中断服务程序会将阻塞在该缓冲块上的进程的状态修改为running状态以使其重新具备参与进程调度的能力。\n 2. 非阻塞IO模型 # 在有些时候并不希望进程在IO操作未完成时睡眠，而是希望系统调用能够立刻返回一个错误，以报告这一情况，然后进程可以根据需要在适当的时候再重新执行这个IO操作。这就是所谓的非阻塞IO模型。\n如下图所示，应用程序前几次read系统调用时都没有数据可供返回，此时内核立即返回一个EAGAIN错误代码，程序并不睡眠而是继续调用read，当第四次调用read时数据准备好了，于是执行数据从内核到用户空间的复制操作并成功返回，应用程序接着处理数据。这种对一个非阻塞IO端口反复调用read进行数据读取的动作称为轮询，即应用程序持续轮询内核数据是否准备好。这里的持续轮询操作将导致耗费大量的CPU时间，因此该模型并不推荐使用。\n3. IO多路复用模型 # 前面介绍了非阻塞IO模型的问题在于，尽管应用程序可以在当前IO操作不能完成的时候迫使系统调用立刻返回而不至于睡眠，但是却无法知道什么时候再次请求IO操作可以顺利完成，只能周期性地做很多无谓的轮询，每隔一段时间就要重新请求一次系统调用，这种轮询策略极大浪费了CPU时间。\nIO多路复用模型就是在此之上的改进，它的好处在于使得应用程序可以同时对多个IO端口进行监控以判断其上的操作是否可以顺利（无阻塞地）完成，达到时间复用的目的。进程阻塞在类似于select、poll或epoll这样的系统调用上，而不是阻塞在真正的IO系统调用上，意思也就是说在这些select、poll或者epoll函数内部会代替我们做非阻塞地轮询，那么它的轮询策略是怎样地呢？稍后会进行介绍。\nselect、poll或epoll使得进程可以在多个IO端口上等待IO事件（可读、可写、网络连接请求等）的发生，当有事件发生时再根据发生事件的类型进行适当的IO处理。不过进程在等待IO事件发生时仍然在代码执行序上处于“阻塞”状态，应用程序“阻塞”在这里照样还是无法做其他的工作（尽管可以指定轮询时等待时间的长短）。因此如果希望进程在没有IO事件要处理时还能做其他的工作，这种模型是不可行的。\n下图是IO多路复用模型的示例。\nIO多路复用模型主要有3种实现形式，select、poll、epoll。\n3.1. select # #include \u0026lt;sys/select.h\u0026gt; //返回值：readfds、writefds、exceptfds中事件就绪的fd的数量 int select(int nfds, // 最大文件描述符fd+1 fd_set *restrict readfds, // 等待读取的fds fd_set *restrict writefds, // 等待写入的fds fd_set *restrict exceptfds, // 异常fds struct timeval *restrict timeout); // 超时时间 //返回值：readfds、writefds、exceptfds中事件就绪的fd的数量 int pselect(int nfds, // 最大文件描述符fd+1 fd_set *restrict readfds, // 等待读取的fds fd_set *restrict writefds, // 等待写入的fds fd_set *restrict exceptfds, // 异常fds const struct timespec *restrict timeout, // 超时时间 const sigset_t *restrict sigmask); // 信号掩码   备注：\nIO事件就绪的意思是，执行对应的IO操作时可以无阻塞地完成。例如读事件就绪，表明一定有数据到达，或者已经读取到了数据的结束位置EOF。\n #define __FD_SETSIZE 1024 typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set;  select和pselect基本是相同的，它们主要有3点细微的差别：\n select使用的超时时间struct timeval是微秒级的，而pselect使用的struct timespec可以精确到纳秒级； select会更新timeout的值，将其修改为剩余轮询时间，而pselect不会对timeout做修改； select无法指定轮询时的信号掩码，而pselect允许指定信号掩码，如果pselect第6个参数不为NULL，则用其先替换当前的信号掩码，然后执行与select相同的操作，返回时再还原之前的信号掩码；  fd_set只是一个普通的用于记录待监视的fd的位图，由于__FD_SETSIZE硬编码为1024，所以select最多只能监视1024个fd。\n对fd_set的操作主要通过如下几个函数。\n#include \u0026lt;sys/select.h\u0026gt; void FD_CLR(int fd, fd_set *fdset); // 从fdset中删除fd void FD_ISSET(int fd, fd_set *fdset); // 测试fd是否已添加到fdset中 void FD_SET(int fd, fd_set *fdset); // 向fdset中添加fd void FD_ZERO(fd_set *fdset); // 清空fdset  下面对timeout相关的数据结构进行一下说明：\n 如果timeout中的两个字段均为0，则表示select立即返回； 如果timeout中的任意一个字段不为0，则表示select轮询时经过指定的时间后会返回； 如果timeout为NULL，则表示select会阻塞到有事件就绪才返回；  struct timeval { long tv_sec; long tv_usec; }; struct timespec { long tv_sec; long tv_nsec; };  在循环使用select函数时有三个地方值得注意:\n 第一，虽然在普遍情况下，参数timeout在select函数返回时不会被修改，但是有的Linux版本却会将这个值修改成函数返回时剩余的等待秒数，因此从可移植性上考虑，在每次重新调用select函数前都得再次对参数timeout初始化。 第二，select函数中间的三个参数（即感兴趣的描述符集）在select函数返回时，其保存有指示哪些描述符已经进入就绪状态（此时其对应bit被设置为1，其他未就绪描述符对应bit设置为0），从而程序可以使用宏FD_ISSET来测试描述符集中的就绪描述符。因此，在每次重新调用select函数前都得再次把所有描述符集中关注的fd对应的bit设置为1。 第三，应注意到利用select函数监控的最大描述符收到系统FD_SETSIZE宏的限制，最多能够监视1024个描述符，在高并发情景中，select是难以胜任的。  下面是select的编程模板，可在此基础上进行改进。\n// 可读、可写、异常3种文件描述符集的声明和初始化 fd_set readfds, writefds, exceptfds; FD_ZERO(\u0026amp;readfds); FD_ZERO(\u0026amp;writefds); FD_ZERO(\u0026amp;exceptfds); int max_fd; // socket配置和监听 int sock = socket(...); bind(sock, ...); listen(sock, ...); // 对socket描述符上关心的事件进行注册，select不要求fd非阻塞 FD_SET(sock, \u0026amp;readfds); max_fd = sock; while(1) { int i; fd_set r, w, e; // 为了重复使用readfds、writefds、exceptionfds，将他们复制到临时变量内 memcpy(\u0026amp;r, \u0026amp;readfds, sizeof(fd_set)); memcpy(\u0026amp;w, \u0026amp;writefds, sizeof(fd_set)); memcpy(\u0026amp;e, \u0026amp;exceptfds, sizeof(fd_set)); // 利用临时变量调用select阻塞等待，等待时间为永远等待直到事件发生 select(max_fd+1, \u0026amp;r, \u0026amp;w, \u0026amp;e, NULL); // 测试是否有客户端发起连接请求，如果有则接受并把新建的描述符加入监控 if(FD_ISSET(sock, \u0026amp;r)) { new_sock = accept(sock, ...); FD_SET(new_sock, \u0026amp;readfds); FD_SET(new_sock, \u0026amp;writefds); max_fd = MAX(max_fd, new_sock); } // 对其他描述符上发生的事件进行适当处理 // 描述符依次递增，各系统的最大值可能有所不同，一般可以通过ulimit -n进行设置 for(i=sock+1; i\u0026lt;max_fd+1; ++i) { if(FD_ISSET(i, \u0026amp;r)) { doReadAction(i); } if(FD_ISSET(i, \u0026amp;w)) { doWriteAction(i); } } }   备注： 上述只是一个非常简单的select使用示例，在实际使用过程中需要考虑一些其他的因素，例如对端的tcp连接socket关闭时应该怎样处理，关闭又可以细分为关闭读和写两种情况。\n 代码示例：\n点击这里查看基于select实现的tcp server，[click to see select-based-tcp-server]。\n3.2. poll # #include \u0026lt;poll.h\u0026gt; int poll(struct pollfd *fds, // 待监视的fd构成的struct pollfd数组 nfds_t nfds, // 数组fds[]中元素数量 int timeout); // 轮询时等待的最大超时时间 struct pollfd { int fd; // 待监视的fd short events; // 请求监视的事件 short revents; // 实际收到的事件 };  pollfd中可指定的event类型包括：\n POLLIN，普通数据读取； POLLPRI，紧急数据读取； POLLOUT，普通数据可写； POLLRDHUP，面向流的socket，对端socket关闭连接或者关闭了写半连接； POLLERR，错误； POLLHUP，挂起； POLLNVAL，无效请求，fd没有打开；  当如果通过宏_XOPEN_SOURCE进行条件编译时，还可指定如下event类型：\n POLLRDNORM，与POLLIN等效； POLLRDBAND，优先级带数据可读，在Linux上通常是无用的； POLLWRNORM，与POLLOUT等效； POLLWRBAND，优先级数据可写；  poll系统调用的第三个参数timeout指定了轮询时的等待事件，当timeout\u0026lt;0时永远等待直到监视的fds上有事件发生，当timeout=0时立即返回，单timeout\u0026gt;0时等待到指定的超时时间后返回。poll不要求监视的fd为非阻塞。\npoll与select相比具有如下优势：\n poll系统调用中通过第二个参数nfds来限定要监视的描述符的数量，与select相比，poll去掉了硬编码的FD_SETSIZE宏的监控fd数量上限； 另外poll通过pollfd中的revents来接收fd上到达的事件，events不会被修改，每次调用poll时不用像select一样每次都需要重新设置r、w、e文件描述符集，方便使用也减少数据向内核拷贝的开销。  // 新建并初始化文件描述符集 struct pollfd fds[MAX_NUM_FDS]; int max_fd; // socket配置和监听 sock = socket(...); bind(sock, ...); listen(sock, ...); // 对socket描述符上关心的事件进行注册 fds[0].fd = sock; fds[0].events = POLLIN; max_fd = 1; while(1) { int i; // 调用poll阻塞等待，等待时间为永远等待直到事件发生 poll（fds, max_fd, -1); // 测试是否有客户端发起连接请求，如果有则接受并把新建的描述符加入监控 if(fds[0].revents \u0026amp; POLLIN) { new_sock = accept(sock, ...); fds[max_fd].fd = new_sock; fds[max_fd].events = POLLIN | POLLOUT; ++ max_fd; } // 对其他描述符发生的事件进行适当处理 for(i=1; i\u0026lt;max_fd+1; ++i) { if(fds[i].revents \u0026amp; POLLIN) { doReadAction(i); } if(fds[i].revents \u0026amp; POLLOUT) { doWriteAction(i); } } }   备注：\n上面的代码也是只给出了一个最简单的编程示例，对于对端tcp连接关闭的情况也需要予以考虑，避免服用端占用大量的fd。\n从上面基于select/poll多路复用IO模型可以看出，在大量的并发连接中，如果空闲连接（即无事件发生的连接）较多，select/poll的性能会因为并发数的线性上升而成线型速度下降，实际上性能可能比线型下降更差。当连接数很大时，系统开销会异常大。\n另外select、poll每次返回时都需要从内核向用户空间复制大量的数据，数据复制的开销也会很大，select主要是从内核向用户空间复制readfds、writefds、exceptfds开销大，poll主要是从内核复制pollfd[]开销大。\n使用select/poll实现的多路复用IO模型是最稳定也是使用最为广泛的事件驱动IO模型，但是其固有的一些缺点（如性能低下、伸缩性不强）使得各种更为先进的替代方案出现在各种平台下。\n 代码示例：\n点击这里查看基于poll实现的tcp server，[click to see poll-based-tcp-server]。\n3.3. epoll # epoll作为poll的变体在Linux内核2.5中被引入，相比于select实现的多路复用IO模型，epoll的最大好处在于它不会随着监控描述符数目的增长而使效率急剧下降。在内核中的select实现是采用轮询处理的，轮询的描述符数目越多，自然耗时越多，而且在很多情况下，select最多能同时监听的描述符数目为1024个。\nepoll提供了三种系统调用，如下所示。\n#include \u0026lt;sys/poll.h\u0026gt; // 创建一个epfd，最多监视${size}个文件描述符 int epoll_create(int size); int epoll_ctl(int epfd, // epfd int op, // 操作类型（注册、取消注册） int fd, // 待监视的fd struct epoll_event *event); // 待监视的fd上的io事件 int epoll_wait(int epfd, // epfd struct epoll_event *events, // 最终返回的就绪事件 int maxevents, // 期望的就绪事件数量 int timeout); // 超时时间 int epoll_wait(int epfd, // epfd struct epoll_event *events, // 接收返回的就绪事件 int maxevents, // 期望的就绪事件数量 int timeout, // 超时时间 const sigset_t *sigmask); // 信号掩码 typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64; } epoll_data_t; struct epoll_event { __uint32_t events; // epoll events epoll_data_t data; // user data variable };  epoll中可以关注的事件主要有：\n EPOLLIN，数据可读事件； EPOLLOUT，数据可写事件； EPOLLRDHUP，流socket对端关闭连接或者关闭了写半连接； EPOLLPRI，紧急数据读取事件； EPOLLERR，错误事件； EPOLLHUP，挂起事件，epoll总是会等待该事件，不需要显示设置； EPOLLET，设置epoll以边缘触发模式工作（不指定该选项则使用级别触发Level Trigger模式）； EPOLLONESHOT，设置epoll针对某个fd上的事件只通知一次，一旦epoll通知了某个事件，该fd上后续到达的事件将不会再发送通知，除非重新通过epoll_ctl EPOLL_CTL_MOD更新其关注的事件。  epoll事件的两种模型：\n LT，Level Triggered，译为水平触发或者级别触发，我更偏向于使用级别触发。级别触发是默认的工作方式，同时支持阻塞和非阻塞socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉进程该描述符有事件发生，之后如果进程一直不对这个就绪状态做出任何操作，则内核会继续通知，直到事件处理完成。以LT方式调用的epoll接口就相当于一个速度比较快的poll模型。 ET，Edge Triggered，译为边缘触发。边缘触发方式是高速工作方式，只支持非阻塞socket。在这种工作方式下，当描述符从未就绪变为就绪时，内核通过epoll告诉进程该描述符有事件发生，之后就算进程一直不对这个就绪状态做出任何操作，内核也不会再发送更多地通知，也就是说内核仅在该描述符事件到达的那个突变边缘对进程做出一次通知。\n根据ET方式的特性，epoll工作在此模式时必须使用非阻塞文件描述符，以避免由于一个文件描述符的阻塞读、阻塞写操作把处理多个文件描述符的任务“饿死”。\n调用ET模式epoll接口的推荐步骤如下：\n1）基于非阻塞文件描述符；\n2）只有当read或write返回EAGAIN（对于面向包/令牌的文件，比如数据报套接口、规范模式的终端）时，或是read/write读到/写出的数据长度小于请求的数据长度（对于面向流的文件，比如pipe、fifo、流套接口）时才需要挂起等待下一个事件。\n总的来说，在大并发的系统中，边缘触发模式比级别触发模式更具有优势，但是对于程序员的要求也更高。如果对于这两种模式想要了解得更加深入，那么建议读者阅读epoll相关的源代码。  下面是epoll多路复用IO模型的一个编程模板，可以在此基础上进行改进。\n// 创建并初始化文件描述符集 struct epoll_event ev; struct epoll_event events[MAX_EVENTS]; // 创建epoll句柄epfd int epfd = epoll_create(MAX_EVENTS); // 监听socket配置 sock = socket(...); bind(sock, ...); listen(sock, ...); // 对socket描述符上关心的事件进行注册 ev.events = EPOLLIN; ev.data.fd = sock; epoll_ctl(epfd, EPOLL_CTL_ADD, sock, \u0026amp;ev); while(1) { int i; // 调用epoll_wait阻塞等待，等待事件未永远等待直到发生事件 int n = epoll_wait(epfd, events, MAX_EVENTS, -1); for(i=0; i\u0026lt;n; ++i) { // 测试是否有客户端发起连接请求，如果有则接受并把新建的描述符加入监控 if(events[i].data.fd == sock) { if(events[i].events \u0026amp; EPOLLIN) { new_sock = accept(sock, ...); ev.events = EPOLLIN | EPOLLOUT; ev.data.fd = new_sock; epoll_ctl(epfd, EPOLL_CTL_ADD, new_sock, \u0026amp;ev); } } else { // 对于其他描述符上发生的事件进行适当处理 if(events[i].events \u0026amp; EPOLLIN) { doReadAction(i); } if(events[i].events \u0026amp; EPOLLOUT) { doWriteAction(i); } } } }   备注： 注意上面的代码也是仅仅给出了一个编程示例，实际应用过程中也需要考虑对端tcp连接关闭时对server端套接字的处理，比如通过epoll_ctl(epfd, EPOLL_CTL_DEL, fd, NULL)取消对fd上事件的轮询，并close(fd)_。服务端如果不注意对分配的套接字fd进行回收，很有可能达到系统允许的fd上限，那时候就会出现服务瘫痪，应注意避免这种情况的发生。\n 备注：\n需要注意级别触发、边缘触发编码方式上的差别，这里首先要铭记一点，级别触发只在事件状态发生改变时通知一次，而边缘触发只要事件处于就绪状态那么就会在处理之前一直发送统治。\n使用边缘触发方式进行编程比使用级别触发编程要稍微复杂一些，需要时刻谨记上述差异，这里说两个直观的情景便于大家理解。\n 当通过epfd监听来自多个客户端的入连接请求时，可能一次会有大量客户端的入连接请求到达，一次epoll_wait，如果工作在边缘触发模式，就只会通知一次epfd可读事件就绪，因此在对epfd上的EPOLLIN进行事件处理时，需要通过一个while循环不停地调用accept来完成所有入连接请求的处理，而不是像上述编程示例（上例为LT触发模式）中一样一次EPOLLIN只调用一次accept，则级别触发模式下上述方式是可行的，但是边缘触发模式下会造成严重的bug。 当通过sock_conn对连接socket上到达的数据进行读取时，对于每一个socket_conn上的数据都要通过一个while循环不停读取知道再次read返回EAGAIN确保所有数据已读取完，因为这个时候不读取，以后就不会收到epoll_wait的再次通知，如果想读取基本上就退化为一个poll了，需要自己轮询或者测试是否可读，影响性能。 对于sock_conn上数据写操作的处理，与sock_conn上数据读的处理是相似的。  与select、poll相比，epoll具有如下优点：\n epoll每次只返回有事件发生的文件描述符信息，这样调用者不用遍历整个文件描述符队列； 使用epoll使得系统不用从内核向用户空间复制数据，因为它是利用mmap使内核和用户空间贡献一块内存； 另外epoll可以设置不同的事件触发方式，包括边缘触发和级别触发两种，为用户使用epoll提供了灵活性。  代码示例：\n点击这里查看基于epoll实现的tcp server，[click to see epoll-based-tcp-server]。注意，这里的代码实现中包括了两个tcp server实现，一个是基于边缘触发模式(ET)，一个是基于级别触发模式(LT)。\n4. 实时信号驱动IO模型 # 实时信号驱动(rtsig)IO模型使得应用程序不需要阻塞在某一个或多个IO端口上，它先利用系统调用sigaction来安装某个端口的事件信号处理函数，该系统调用sigaction执行成功后立即返回，进程继续往下工作而不被阻塞，当某个IO端口上可进行数据操作时，内核就为该进程产生一个SIGIO信号，进程收到该信号后相应地在信号处理函数里进行IO操作，因此，这种机制使得程序能够在一个更合适的时间点被通知到，被通知去执行IO事件处理，之所以说是通知的时间点更好，是因为此时进行IO需要的数据已就绪，IO处理可以保证无阻塞地完成。\n实时信号驱动IO完全不是在select/poll基础上的修改，而是对传统信号驱动IO的完善，因此它是完全不同于前面介绍的几种解决方案的事件驱动IO机制。\n要使用实时信号驱动IO模型相对于处理普通的信号要稍微复杂一点，除了要为SIGIO信号建立信号处理函数（在该处理函数内当然要包含对实际IO操作的系统调用）以外，还需要额外的步骤，如对IO端口做一些设置以便启用信号驱动IO功能。首先要设置描述符的所有者，这可以通过fcntl的F_SETOWN操作来完成，fcntl(fd, F_SETOWN, (int)pid)，接着要启用描述符的信号驱动IO模式，这个步骤一般是通过fcntl的F_SETFL来设置O_ASYNC标识来完成的，fcntl(fd, F_SETFL, O_ASYNC|O_NONBLOCK|O_RDWR)。另外，如果有必要还可以重新设置描述符可读写时要发送的信号值，这可以通过fcntl的F_SETSIG指定，fcntl(fd, F_SETSIG, ev-\u0026gt;signum)。\n 备注：\n要使用F_SETSIG常量值必须在其源文件开头包含宏定义“#define __USE_GNU”或者“#define _GNU_SOURCE”，当然也可以通过GCC -D来指定宏。不过推荐使用宏_GNU_SOURCE而不是__USE_GNU宏。原因是，双划线开头的宏一般是由系统中的头文件对其进行定义、扩展，而不是在普通应用程序中。\n 可以看到所谓的实时信号驱动IO模型就是利用了O_ASYNC来使得当描述符可读、写时发送通知信号（采用非常规可排队的POSIX实时信号）从而使得进程可以异步执行。\n该模型有一些缺点：\n O_ASYNC仅能工作于socket描述符上，而不能工作于管道（pipe）或中断（tty）上； O_ASYNC为边缘触发方式，因此事件处理函数必须完整的完成某个事件处理动作（比如读取数据则必须读取完），否则不能保证进程可靠的再次接收到信号通知；   备注：\nRTSIG的实现与进程怎样分派信号密切相关，对每一个发生的事件就递交一个信号通知将是十分浪费的，因此一般考虑使用sigtimedwait()函数来阻塞等待进程关心的信号，并且结合利用poll()函数实现对描述符事件的水平触发效果。\n 据某些开发人员测试，在一定条件下的实时信号驱动IO模型表现性能比其他基于poll的IO模型都要好，但是这种方案似乎并不可靠，很多开发人员给出的建议就是不要使用这种方式。\n下面给出了一个利用RTSIG IO的编程范例。\n// 屏蔽不关心的信号 sigset_t all; sigfillset(\u0026amp;all); sigdelset(\u0026amp;all, SIGINT); sigprocmask(SIG_SETMASK, \u0026amp;all, NULL); // 新建并初始化关心的信号 sigset_t sigset; siginfo_t siginfo; // sigwaitinfo调用时会阻塞，除非收到wait的信号集中的某个信号 sigemptyset(\u0026amp;sigset); sigaddset(\u0026amp;sigset, SIGRTMIN + 1); // socket配置和监听 sock = socket(...); bind(sock, ...); listen(sock, ...); // 重新设置描述符可读写时要发送的信号值 fcntl(sock, F_SETSIG, SIGRTMIN + 1); // 对socket描述符设置所有者 fcntl(sock, F_SETOWN, getpid()); // 启用描述符的信号驱动IO模式 int flags = fcntl(sock, F_GETFL); fcntl(sock, F_SETFL, flags|O_ASYNC|O_NONBLOCK); while(1) { struct timespec ts; ts.tv_sec = 1; ts.tv_nsec = 0; // 调用sigtimedwait阻塞等待，等待事件1s \u0026amp; sigwaitinfo会一直阻塞 // - 通过这种方式可以达到一种类似级别触发的效果，不再是边缘触发； // - 边缘触发效果，应该通过同一个sighandler进行处理，但是处理起来比较麻烦： // - 假如不同的连接socket使用相同的信号，那么sighandler里无法区分事件就绪的fd； // - 假如不同的连接socket使用不同的信号，实时信号数量有限SIGRTMIN~SIGRTMAX大约才32个！ //sigtimedwait(\u0026amp;sigset, \u0026amp;siginfo, \u0026amp;ts); sigwaitinfo(\u0026amp;sigset, \u0026amp;siginfo); // 测试是否有客户端发起连接请求 if(siginfo.si_fd == sock) { new_sock = accept(sock, ...); fcntl(new_sock, F_SETSIG, SIGRTMIN + 1); fcntl(new_sock, F_SETOWN, getpid() + 1); fcntl(new_sock, F_SETFL, O_ASYNC|O_NONBLOCK|O_RDWR); } // 对其他描述符上发生的读写事件进行处理 else { doReadAction(i); doWriteAction(i); } }  上面的代码看起来似乎挺简单，很多人看了之后可能还很想尝试并在实践中应用，这里要注意的是，rtsig driven io并没有那么简单、有效！且听我细细道来！\n4.1 rtsig在udp中应用 # rtsig driven io在udp server中较为简单，因为udp中只有两种情况会为fd raise一个rtsig：\n fd上有数据到达； fd上io操作有错误；  我的repo里面有一个基于rtsig实现的udp server，实现起来很简单，不需要做什么特殊处理逻辑就可以轻松实现，虽然说rtsig不怎么被看好吧，但是至少有个服务ntp还是使用的rtsig \u0026amp; udp来实现的，可是tcp就不同了，好像还没有一个tcp server是基于rtsig实现的，很多人都反对在tcp中应用rtsig，因为太啰嗦而且很“没用”，每个io事件都raise一个信号也是个累赘，要判断的可能的io状态太多。\n代码示例：\n点击查看基于rtsig实现的udp server示例：[click to see rtsig-udp-server]。\n4.2 rtsig在tcp中应用 # rtsig drive io在tcp server中实现就复杂多了，因为对于一个fd有7种可能的情景会为其raise一个rtsig：\n fd上完成了一个建立连接的请求； fd上发起了一个断开连接的请求； fd上完成了一个断开连接的请求； fd上有数据到达； fd上有数据写出； fd上半连接关闭； fd上有错误发生；  这么多的情景需要作很多额外的判断才能加以区分，所以很多开发人员建议在tcp中只将rtsig应用在监听套接字sock_listen上，对于连接套接字还是基于select、poll、epoll来操作，其实即便这样也是费力不讨好，因为rtsig也存在可能丢失的问题！而且它是边缘触发，对程序员要求也比较高。建议还是用epoll吧！\n这里的tcp server中采用的是通过sigtimedwait/sigwaitinfo \u0026amp; siginfo_t.si_fd来区分收到rtsig的连接套接字、监听套接字的，然后再针对性地进行io处理！在我们的另一个基于rtsig的tcpserver实现中，我们通过同一个sighandler收到SIGIO信号时建立tcp连接并随即选择一个连接进行处理，虽然我们实现了，不过也不是一个特别clean的方法，不建议使用rtsig driven io，还是用IO多路复用来的清爽！\n代码示例：\n点击查看基于rtsig实现的tcp server示例：\n 示例1，基于sigtimedwait/sigwaitinfo \u0026amp; siginfo_t.si_fd来区分连接fd，[click to see rtsig-tcp-server-1]； 示例2，基于sighandler以及一点小技巧实现的对多个连接fd进行处理，[click to see rtsig-tcp-server-2]；  5. 异步IO模型 # 异步IO也是属于POSIX规范的一部分，类似实时信号驱动IO的异步通知机制，这也使得异步IO模型常常与后者相混淆。与后者的区别在于，启用异步IO意味着告知内核启动某个IO操作，并让内核在整个操作（包括将数据从内核复制到用户空间的缓冲区）完成时通知我们。也就是说，实时信号驱动IO是由内核通知我们何时可以启动一个IO操作，而在异步IO模型中，是由内核通知我们IO操作何时完成，即实际的IO操作是异步的。\n5.1. AIO API说明 # 下面的内容摘自Linux man手册，其对POSIX下的AIO接口、实现做了一个基础的介绍。在此基础上，我们将把AIO应用于后台服务中。\nPOSIX AIO接口允许应用程序发起一个或者多个IO操作，这些IO操作是异步执行的，即相比于当前发起IO操作的线程来说这些实际的IO操作是在“后台”运行的。IO操作完成时，可以选择多种方式来通知应用程序完成这一事件，例如：\n 传递一个信号给应用程序通知其IO操作完成； 在应用程序中额外实例化一个线程来对IO完成操作进行后处理； 也可能根本不会通知应用程序；  前面第4节讲过的rtsig driven io也可以算是异步的，从其当时使用的选项O_ASYNC就可以看出来，也可以称其为AIO（Asynchronous IO），但是呢，这里本节所提到的AIO主要指的是POSIX规范里面定义的AIO API。\n5.1.1. POSIX AIO API # POSIX AIO接口包括如下几个函数：\n aio_read(3)：入队一个read请求，它是read的异步操作版本； aio_write(3)：入队一个write请求，它是write的异步操作版本； aio_fsync(3)：入队一个sync请求（针对某个fd上的IO操作），它是fsync和fdatasync的异步版本； aio_error(3)：获取一个已入队的IO请求的错误状态信息； aio_return(3)：获取一个已完成的IO请求的返回状态信息； aio_suspend(3)：挂起IO请求的发起者，直到指定的一个或多个IO事件完成； aio_cancel(3)：尝试取消已经发起的某个特定fd上的未完成的IO请求； lio_listio(3)：使用这一个函数可以一次性入队多个IO请求；  5.1.2. Linux AIO SysCall # 通过上面几个函数后面的“(3)”可以知道，上述几个函数都是普通的libc库函数，而不是系统调用，实际上上述这些纯用户态的库函数是基于5个系统调用来实现的，它们是：\n io_setup(2) - int io_setup(unsigned nr_events, aio_context_t *ctx_idp)\n该函数在内核中为进程创建一个AIO Context，AIO Context是多个数据结构的集合，用于支持内核的AIO操作。每一个进程可以拥有多个AIO Context，每一个AIO Context都有一个唯一的标识符，AIO Context类型aio_context_t变量作为io_setup的第二个参数，内核会设置其对应的值，实际上这个aio_context_t类型仅仅是一个unsigned long类型(typedef unsigned long aio_context_t），io_setup的第一个参数表示aio_context_t变量要支持的同时发起的IO请求的数量。 io_destroy(2) - int io_destroy(aio_context_t ctx_id)\n该函数用于销毁AIO Context变量，销毁之前有两个操作，首先取消基于该aio_context_t发起的未完成的AIO请求，然后对于无法取消的AIO请求就阻塞当前进程等待其执行完成，最后销毁AIO Context。 io_submit(2) - int io_submit(aio_context_t ctx_id, long nr, struct iocb **iocbpp)\n该函数将向aio_context_t ctx_id上提交nr个IO请求，每个IO请求是由一个aio control block来指示的，第三个参数struct iocb **iocbpp是一个aio控制块的指针数组。 io_getevents(2) - int io_getevents(aio_context_t ctx_id, long min_nr, long nr, struct io_event *events, struct timespec *timeout)\n等待aio_context_t ctx_id关联的aio请求已完成队列中返回最少min_nr个事件，最多nr个事件，如果指定了timeout则最多等待该指定的时间，如果timeout为NULL则至少等待min_nr个事件返回。 io_cancel(2) - int io_cancel(aio_context_t ctx_id, struct iocb *iocb, struct io_event *result)\n该函数取消之前提交到aio_context_t ctx_id的一个AIO请求，这个请求由struct iocb *iocb标识，如果这个AIO请求成功取消了，对应的事件将被拷贝到第三个参数struct io_event *result指向的内存中，而不是将其放在已完成队列中。   备注：\n上述几个内核中的函数io_setup、io_destroy、io_submit、io_getevents、io_cancel，libc中并没有提供对应的wrapper函数供我们调用，如果要使用这些函数的话，可以通过syscall(2)来调用，以调用io_setup为例：syscall(__NR_io_setup, hr, ctxp)，这也是一种发起系统调用的常见方式。\n但是呢，libaio库里面提供了对应的wrapper函数，但是其参数类型与这里有点差异，而且返回值的含义也存在一些差异，不是很建议使用。\n 5.2. AIO操作示例 # 5.2.1. Kernel AIO SysCall # 下面是一个基于内核AIO系统调用的一个示例，程序打开一个本地文件，并将一段缓冲区中的数据写入到文件中。\n#define _GNU_SOURCE /* syscall() is not POSIX */ #include \u0026lt;stdio.h\u0026gt; /* for perror() */ #include \u0026lt;unistd.h\u0026gt; /* for syscall() */ #include \u0026lt;sys/syscall.h\u0026gt; /* for __NR_* definitions */ #include \u0026lt;linux/aio_abi.h\u0026gt; /* for AIO types and constants */ #include \u0026lt;fcntl.h\u0026gt; /* O_RDWR */ #include \u0026lt;string.h\u0026gt; /* memset() */ #include \u0026lt;inttypes.h\u0026gt; /* uint64_t */ inline int io_setup(unsigned nr, aio_context_t * ctxp) { return syscall(__NR_io_setup, nr, ctxp); } inline int io_destroy(aio_context_t ctx) { return syscall(__NR_io_destroy, ctx); } inline int io_submit(aio_context_t ctx, long nr, struct iocb **iocbpp) { return syscall(__NR_io_submit, ctx, nr, iocbpp); } inline int io_getevents(aio_context_t ctx, long min_nr, long max_nr, struct io_event *events, struct timespec *timeout) { return syscall(__NR_io_getevents, ctx, min_nr, max_nr, events, timeout); } int main() { int fd = open(\u0026quot;./testfile\u0026quot;, O_RDWR|O_CREAT, S_IRUSR|S_IWUSR); if (fd \u0026lt; 0) { perror(\u0026quot;open error\u0026quot;); return -1; } // init aio context aio_context_t ctx = 0; int ret = io_setup(128, \u0026amp;ctx); if (ret \u0026lt; 0) { perror(\u0026quot;io_setup error\u0026quot;); return -1; } // setup I/O control block struct iocb cb; memset(\u0026amp;cb, 0, sizeof(cb)); cb.aio_fildes = fd; cb.aio_lio_opcode = IOCB_CMD_PWRITE; // command-specific options char data[4096] = \u0026quot;i love you, dad!\\n\u0026quot;; cb.aio_buf = (uint64_t) data; cb.aio_offset = 0; cb.aio_nbytes = strlen(data); struct iocb *cbs[1]; cbs[0] = \u0026amp;cb; ret = io_submit(ctx, 1, cbs); if (ret != 1) { if (ret \u0026lt; 0) perror(\u0026quot;io_submit error\u0026quot;); else fprintf(stderr, \u0026quot;could not sumbit IOs\u0026quot;); return -1; } // get the reply struct io_event events[1]; ret = io_getevents(ctx, 1, 1, events, NULL); printf(\u0026quot;%d io ops completed\\n\u0026quot;, ret); ret = io_destroy(ctx); if (ret \u0026lt; 0) { perror(\u0026quot;io_destroy error\u0026quot;); return -1; } return 0; }  代码示例：\n点击这里查看基于aio的fileio示例1，[click to see aio-based-fileio]。\n5.2.2. POSIX AIO API # POSIX AIO API实现基于上述5个AIO系统调用，下面看一下基于POSIX AIO API的示例。程序读取命令行参数中指定的文件，并读取文件中的内容，程序还会在异步IO过程中检查IO操作的错误信息、状态信息。\n在5.1.1节中列出了POSIX AIO API对应的函数，其中有一个非常重要的参数类型“AIO请求控制块”类型，即struct aiocb，下面是该结构体的定义：\n// 异步io请求控制块 struct aiocb { int aio_fildes; // io操作对应的文件描述符 off_t aio_offset; // 文件读写操作位置的偏移量 volatile void *aio_buf; // 异步io操作对应的数据缓冲区 size_t aio_nbytes; // aio_buf的容量 int aio_reqprio; // aio操作的优先级（一般继承自发起aio操作的线程） struct sigevent aio_sigevent; // aio操作完成时如何通知应用程序 int aio_lio_opcode; // aio操作命令 };  其中aio_sigevent定义如下：\n// Data passed with notification union sigval { int sival_int; // Integer value void *sival_ptr; // Pointer value }; struct sigevent { int sigev_notify; // Notification method // - SIGEV_NONE，不作处理 // - SIGEV_SIGNAL，发送信号 // - SIGEV_THREAD，实例化一个线程 int sigev_signo; // Notification signal union sigval sigev_value; // Data passed with notification // Function used for thread notification (SIGEV_THREAD) void (*sigev_notify_function) (union sigval); // Attributes for notification thread (SIGEV_THREAD) void *sigev_notify_attributes; // ID of thread to signal (SIGEV_THREAD_ID) pid_t sigev_notify_thread_id; };  下面是示例程序的源代码：\n#include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;aio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; // Size of buffers for read operations #define BUF_SIZE 20 #define errExit(msg) do { perror(msg); exit(EXIT_FAILURE); } while (0) #define errMsg(msg) do { perror(msg); } while (0) /* Application-defined structure for tracking I/O requests */ struct ioRequest { int reqNum; int status; struct aiocb *aiocbp; }; // On delivery of SIGQUIT, we attempt to cancel all outstanding I/O requests static volatile sig_atomic_t gotSIGQUIT = 0; // Handler for SIGQUIT static void quitHandler(int sig) { gotSIGQUIT = 1; } // Signal used to notify I/O completion #define IO_SIGNAL SIGUSR1 // Handler for I/O completion signal static void aioSigHandler(int sig, siginfo_t *si, void *ucontext) { if (si-\u0026gt;si_code == SI_ASYNCIO) { write(STDOUT_FILENO, \u0026quot;I/O completion signal received\\n\u0026quot;, 31); // The corresponding ioRequest structure would be available as: // struct ioRequest *ioReq = si-\u0026gt;si_value.sival_ptr; // // and the file descriptor would then be available via: // int fd = ioReq-\u0026gt;aiocbp-\u0026gt;aio_fildes; } } int main(int argc, char *argv[]) { if (argc \u0026lt; 2) { fprintf(stderr, \u0026quot;Usage: %s \u0026lt;pathname\u0026gt; \u0026lt;pathname\u0026gt;...\\n\u0026quot;, argv[0]); exit(EXIT_FAILURE); } int numReqs = argc - 1; // Total number of queued I/O requests, i.e, num of files listed on cmdline /* Allocate our arrays */ struct ioRequest *ioList = calloc(numReqs, sizeof(struct ioRequest)); if (ioList == NULL) errExit(\u0026quot;calloc\u0026quot;); struct aiocb *aiocbList = calloc(numReqs, sizeof(struct aiocb)); if (aiocbList == NULL) errExit(\u0026quot;calloc\u0026quot;); // Establish handlers for SIGQUIT and the I/O completion signal // - SIGQUIT struct sigaction sa; sa.sa_flags = SA_RESTART; sigemptyset(\u0026amp;sa.sa_mask); sa.sa_handler = quitHandler; if (sigaction(SIGQUIT, \u0026amp;sa, NULL) == -1) errExit(\u0026quot;sigaction\u0026quot;); // - IO_SIGNAL, actually it's SIGUSR1 sa.sa_flags = SA_RESTART | SA_SIGINFO; sa.sa_sigaction = aioSigHandler; if (sigaction(IO_SIGNAL, \u0026amp;sa, NULL) == -1) errExit(\u0026quot;sigaction\u0026quot;); // Open each file specified on the command line, and queue a read request // on the resulting file descriptor int j; for (j = 0; j \u0026lt; numReqs; j++) { ioList[j].reqNum = j; ioList[j].status = EINPROGRESS; ioList[j].aiocbp = \u0026amp;aiocbList[j]; ioList[j].aiocbp-\u0026gt;aio_fildes = open(argv[j + 1], O_RDONLY); if (ioList[j].aiocbp-\u0026gt;aio_fildes == -1) errExit(\u0026quot;open\u0026quot;); printf(\u0026quot;opened %s on descriptor %d\\n\u0026quot;, argv[j + 1], ioList[j].aiocbp-\u0026gt;aio_fildes); ioList[j].aiocbp-\u0026gt;aio_buf = malloc(BUF_SIZE); if (ioList[j].aiocbp-\u0026gt;aio_buf == NULL) errExit(\u0026quot;malloc\u0026quot;); ioList[j].aiocbp-\u0026gt;aio_nbytes = BUF_SIZE; ioList[j].aiocbp-\u0026gt;aio_reqprio = 0; ioList[j].aiocbp-\u0026gt;aio_offset = 0; ioList[j].aiocbp-\u0026gt;aio_sigevent.sigev_notify = SIGEV_SIGNAL; ioList[j].aiocbp-\u0026gt;aio_sigevent.sigev_signo = IO_SIGNAL; ioList[j].aiocbp-\u0026gt;aio_sigevent.sigev_value.sival_ptr = \u0026amp;ioList[j]; int s = aio_read(ioList[j].aiocbp); if (s == -1) errExit(\u0026quot;aio_read\u0026quot;); } // Number of requests still in progress int openReqs = numReqs; // Loop, monitoring status of I/O requests while (openReqs \u0026gt; 0) { sleep(3); /* Delay between each monitoring step */ if (gotSIGQUIT) { // On receipt of SIGQUIT, attempt to cancel each of the // outstanding I/O requests, and display status returned from the // cancellation requests printf(\u0026quot;got SIGQUIT; canceling I/O requests: \\n\u0026quot;); for (j = 0; j \u0026lt; numReqs; j++) { if (ioList[j].status == EINPROGRESS) { printf(\u0026quot;Request %d on descriptor %d:\u0026quot;, j, ioList[j].aiocbp-\u0026gt;aio_fildes); int s = aio_cancel(ioList[j].aiocbp-\u0026gt;aio_fildes, ioList[j].aiocbp); if (s == AIO_CANCELED) printf(\u0026quot;I/O canceled\\n\u0026quot;); else if (s == AIO_NOTCANCELED) printf(\u0026quot;I/O not canceled\\n\u0026quot;); else if (s == AIO_ALLDONE) printf(\u0026quot;I/O all done\\n\u0026quot;); else errMsg(\u0026quot;aio_cancel\u0026quot;); } } gotSIGQUIT = 0; } // Check the status of each I/O request that is still in progress printf(\u0026quot;aio_error():\\n\u0026quot;); for (j = 0; j \u0026lt; numReqs; j++) { if (ioList[j].status == EINPROGRESS) { printf(\u0026quot;for request %d (descriptor %d): \u0026quot;, j, ioList[j].aiocbp-\u0026gt;aio_fildes); ioList[j].status = aio_error(ioList[j].aiocbp); switch (ioList[j].status) { case 0: printf(\u0026quot;I/O succeeded\\n\u0026quot;); break; case EINPROGRESS: printf(\u0026quot;In progress\\n\u0026quot;); break; case ECANCELED: printf(\u0026quot;Canceled\\n\u0026quot;); break; default: errMsg(\u0026quot;aio_error\u0026quot;); break; } if (ioList[j].status != EINPROGRESS) openReqs--; } } } printf(\u0026quot;All I/O requests completed\\n\u0026quot;); // Check status return of all I/O requests printf(\u0026quot;aio_return():\\n\u0026quot;); for (j = 0; j \u0026lt; numReqs; j++) { ssize_t s = aio_return(ioList[j].aiocbp); printf(\u0026quot;for request %d (descriptor %d): %zd\\n\u0026quot;, j, ioList[j].aiocbp-\u0026gt;aio_fildes, s); } exit(EXIT_SUCCESS); }  代码示例：\n点击这里查看基于aio的fileio示例2，[click to see aio-based-fileio2]。\n下面是程序的执行效果：\n// run: ./a.out f1 f2 // result: I/O completion signal received I/O completion signal received opened f1 on descriptor 3 opened f2 on descriptor 4 aio_error(): for request 0 (descriptor 3): I/O succeeded for request 1 (descriptor 4): I/O succeeded All I/O requests completed aio_return(): for request 0 (descriptor 3): 20 for request 1 (descriptor 4): 20  5.3 AIO在服务端开发中的应用 # Linux下的AIO，Kernel AIO是真正的异步IO，但是glibc中的AIO是在用户态中实现的，利用多开的线程来模拟异步通知，但是这个线程里面的io操作并不是真正的异步。AIO更多的被应用于file io，而不是socket io，stack overflow上曾有人提到，AIO应用到socket上并不会返回明显的错误，只是socket上的io操作仍然是按照默认的“阻塞同步”工作方式执行，并不是异步, 这一点在github上的一篇文章中也被重点提到。\n 摘自github linux-aio\nBlocking during io_submit on ext4, on buffered operations, network access, pipes, etc. Some operations are not well-represented by the AIO interface. With completely unsupported operations like buffered reads, operations on a socket or pipes \u0026hellip;\n Asynchronous IO模型（AIO）比事件驱动的IO模型要晚，而且事件驱动的IO模型已经非常成熟、稳定，因此如果要基于socket开发高性能server，应该首先事件驱动的IO模型，如Linux下的epoll，Mac OS X下的kqueue，Solaris下的/dev/poll。\n那么既然事件驱动的IO模型已经这么成熟了，那么为什么还要设计AIO呢？设计它的目的是什么呢？这里我在stack overflow上找到了两个最具有信服力的回答，整理在此以供大家参考。\n摘自stack overflow, 点击查看原文：\n原文出处：answer-1，译文：\n 网络IO并不是AIO优先考虑的对象，现在几乎所有人编写网络服务器都是基于POSIX事件驱动模型，事件驱动模型已经非常成熟、稳定了。磁盘写一般会被缓冲、磁盘读一般会预取，还有什么不够完美的呢？要说有，那就只有Disk Direct IO这种不带缓冲形式的操作了，这是AIO最适用的地方，而Disk Direct IO仅仅被用于事务数据库或是那些趋向于自己编写线程或者进程来管理disk io的情景。所以，POSIX AIO其实没有什么多大的用途，不要用！\n 原文出处：answer-2，译文：\n 现在借助于kqueue、epoll、/dev/poll等已经可以实现非常高效的socket io操作。异步的文件IO草走是一个出现比较晚的东西（Windows的overlapped io和Solaris早期的POSIX AIO除外）。如果想实现高效的socket io操作，最好是基于上述的事件驱动机制来实现。 AIO的主要目的是为了解决异步的磁盘IO问题，以Mac OS X为例，它提供的AIO就只能作用在普通文件上而不能作用在socket上，因为已经有kqueue可以很好地完成这个工作，没必要重复造轮子。 磁盘写操作通常都会被kernel进行缓冲（将写的数据存在缓冲块中），然后在后面适当的事件将缓冲的写操作全部flush到磁盘（通常由一个额外的进程来完成，linux 0.11中是由pid=2的update进程来负责同步缓冲块数据到磁盘）。后面适当的时刻可以由内核进行选择以获得最优的效率、最少的代价，例如当磁盘的读写头经过某一个磁盘写请求对应的磁盘块时，内核可能就会将这个块对应的缓冲块的数据同步回磁盘。\n但是，对于读操作，如果我们向让内核对多个磁盘读请求根据请求优先级进行排序，AIO是唯一可供选择的方式。下面是为什么让内核来作这个工作比在用户态程序中做这个工作更有优势的原因：\n  内核可以看到所有的磁盘io请求（不止是当前某个程序的磁盘io请求）并且能够排序； 内核知道磁盘读写头的位置，并能根据当前读写头的位置挑选距离当前位置最近的磁盘io请求进行处理，尽量少的移动读写头； 内核能够利用native command queuing技术来进一步优化磁盘的读操作； 可以借助于lio_listio通过一个系统调用发起多个磁盘read操作，比readv方便，特别是如果我们的磁盘read操作不是逻辑上连续的时候还可以节省一点系统的负载； 借助于AIO程序实现可能更见简单些，因为不需要创建额外的一个线程阻塞在read、write系统调用上，完成后还要再通知其他发起io的线程io操作完成； 另外，POSIX AIO设计的接口有点尴尬，举几个例子： 唯一高效的、支持的比较好的事件回调机制就是通过信号，但是这在库里面应用起来不方便，因为这意味着要使用进程的全局信号名字空间。如果操作系统不支持实时信号，还意味着不得不便利所有的请求来判断到底哪一个请求完成了（Mac OS X是这样的，Linux下不是）。此外，在多线程环境中捕获信号也是一项比较有挑战性的工作，还不能直接在信号处理汉书里面对事件作出响应，不得不重新raise一个信号并将它写到管道里面或者使用signalfd（on Linux）然后再由其他线程或进程进行处理，如果在信号处理函数里面响应信号可能耗时较长导致后续信号丢失； lio_suspend跟select存在相同的问题，都具有最大数量限制，伸缩性差！ lio_listio，因为实现的原因也存在提交io操作数量的限制，为了兼容性试图获取这个限制的操作是没有什么意义的，只能通过调用sysconf(_SC_AIO_LISTIO_MAX)来获取，这个系统调用可能会失败，这种情况下可以使用AIO_LISTIO_MAX宏来代替。\n对于Posix AIO的真实应用情况，可以看一下lighttpd，这里面有采用基于AIO来实现server的部分实现，可以参考以下。\n现在大多数POSIX平台都支持POSIX AIO了，例如Linux、BSD、Solaris、AIX等。Windwos通过它的overlapped file io来支持aio。我的理解是只有Solaris、Windows、Linux是真正的支持异步，异步文件io会落到磁盘驱动上，其他的操作系统都是在通过某种机制来模拟异步io，如借助额外的内核线程，这里Linux是个例外，它的glibc中的POSIX AIO实现是借助的一个用户态线程来辅助模拟aio的行为，但是Linux Kernel提供的AIO是真正的异步实现，所有的操作直接落到驱动，只要驱动支持异步那就是真正的异步！\n我相信在不同的操作系统里面，POSIX AIO实现往往只支持普通文件fd类型而不支持socket fd，这种情况是很常见的，也是很正常的！  5.4 关于AIO的结论 # 如果是想基于socket io实现高性能server，还是采用基于事件驱动IO模型吧！别再想信号驱动的IO和AIO了！\n感兴趣的读者可以进一步了解AIO的相关使用和实现细节。\n6 本文总结 # 以上对阻塞IO、非阻塞IO、IO多路复用、实时信号驱动IO、异步IO这5种模型的执行流程、使用方式做了最基本的介绍。如果时间充足，后面会参考Linux内核中的相应实现进一步介绍以上IO模型的实现细节。\n附录A. 错误码定义 # 这里只列出了常见的错误码，Linux中定义的错误码可以通过man errno进行查看。\n   错误码Macro 错误码说明     EAGAIN Resource temporarily unavailable    附录B. 插图信息 # "}),a.add({id:440,href:"/tags/rtsig/",title:"rtsig",description:"",content:""}),a.add({id:441,href:"/tags/coroutine/",title:"coroutine",description:"",content:""}),a.add({id:442,href:"/blog/2017-09-23-%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%8E%86%E5%8F%B2%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/",title:"协程的历史、现在和未来!",description:"进程、线程大家并不陌生，协程呢？近些年协程得到大量运用，如Java字节码增强实现协程的Kilim、Quasar，C++ boost coroutine，微信libco、libtask，当然还有名声在外的Go语言。其实协程思想由来已久，并非近几年才诞生，不妨来了解下这段历史。",content:"计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。\n1.从磁带到协程 # COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 Burroughs 205 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕\n以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 ANTLR 构建的编译器，都遵循这样的设计。\n在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。\n以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。\n2.自顶向下，无需协同 # 虽然协程是伴随着高级语言诞生的，它却没有能像子过程一样成为通用编程语言的基本元素。\n从 1963 年首次提出到上个世纪九十年代，我们在 ALOGL, Pascal, C, FORTRAN 等主流的命令式编程语言中都没有看到原生的协程支持。协程只稀疏地出现在 Simula，Modular-2 (Pascal 升级版) 和 Smalltalk 等相对小众的语言中。协程作为一个比子进程更加通用的概念，在实际编程却没有取代子进程，这一点不得不说是出乎意外的。如果我们结合当时的程序设计思想看，这一点又是意料之中的：协程是不符合那个时代所崇尚的“自顶向下”的程序设计思想的，自然也就不会成为当时主流的命令式编程语言 (imperative programming) 的一部分。\n正如面向对象的语言是围绕面向对象的开发理念设计一样，命令式编程语言是围绕自顶向下(top-down)的开发理念设计的。在自顶向下的理念指导下，程序被切分为一个主程序和大大小小的子模块，每一个子模块又可能调用更多子模块等等。C 家族语言的 main() 函数就是这种自顶而下思想的体现。在这种理念指导下，各模块形成层次调用关系，而程序设计就是制作这些子过程。在“自顶向下”这种层次化的理念下，具有鲜明层次的子过程调用成为软件系统最自然的组织方式，也是理所当然。相较之下，具有执行中让出和恢复功能的协程在这种架构下无用武之地。可以说，自上而下的设计思想从一开始就排除了对协程的需求。其后的结构化编程(Structural Programming) 思想，更是进一步强化了“子过程调用作为唯一控制结构”的基本假设。在这样的指导思想下，协程一直没有成为当时编程语言的一等公民。\n尽管从提出到上世纪 90 年代，协程在编程语言中没有普遍成为一等公民，但作为一种易于理解的控制结构，协程的概念渗入到了软件设计的许多方面。在结构化编程思想一统天下之时， D. Knuth 曾经专门写过一篇 “Structured Programming with GOTO” 来为 GOTO 语句辩护。在他列出的几条 GOTO 可以方便编程且不破坏程序结构的例子中，有一个（例子7b）就是用 GOTO 实现协程控制结构。相比较之下，不用 GOTO 的“结构化”代码反而失去了良好的结构。当然，追求实际结果的工业界对于学界的这场要不要剔除 GOTO 的争论并不感冒。当时许多语言都附带了不建议使用的 GOTO 语句，显得左右逢源。这方面一个最明显的例子就是 Java：其语言本身预留了 goto 关键字，其编译器却没有提供任何的支持，可以说在 goto 这场争论中做足了中间派。\n3.协程的早期应用 # 实践中，协程的思想频繁应用于任务调度和流处理上。比如，UNIX 管道就可以看成是众多命令间的协同操作。当然，管道的现代实现都是以 pipe() 系统调用和进程间的通信为基础，而非简单遵循协程的 yield/resume 语法。\n许多协同式多任务操作系统，也可以看成协程运行系统。说到协同式多任务系统，一个常见的误区是认为协同式调度比抢占式调度“低级”，因为我们所熟悉的桌面操作系统，都是从协同式调度（如 Windows 3.2， Mac OS 9 等）过渡到抢占式多任务系统的。实际上，调度方式并无高下，完全取决于应用场景。抢占式系统允许操作系统剥夺进程执行权限，抢占控制流，因而天然适合服务器和图形操作系统，因为调度器可以优先保证对用户交互和网络事件的快速响应。当年 Windows 95 刚刚推出的时候，抢占式多任务就被作为一大买点大加宣传。协同式调度则等到进程时间片用完或系统调用时转移执行权限，因此适合实时或分时等等对运行时间有保障的系统。\n另外，抢占式系统依赖于 CPU 的硬件支持。 因为调度器需要“剥夺”进程的执行权，就意味着调度器需要运行在比普通进程高的权限上，否则任何“流氓（rogue）”进程都可以去剥夺其他进程了。只有 CPU 支持了执行权限后，抢占式调度才成为可能。x86 系统从 80386 处理器开始引入 Ring 机制支持执行权限，这也是为何 Windows 95 和 Linux 其实只能运行在 80386 之后的 x86 处理器上的原因。而协同式多任务适用于那些没有处理器权限支持的场景，这些场景包含资源受限的嵌入式系统和实时系统。在这些系统中，程序均以协程的方式运行。调度器负责控制流的让出和恢复。通过协程的模型，无需硬件支持，我们就可以在一个“简陋”的处理器上实现一个多任务的系统。我们见到的许多智能设备，如运动手环，基于硬件限制，都是采用协同调度的架构。\n4.协程的复兴和现代形式 # 编程思想能否普及开来，很大程度上在于应用场景。协程没有能在自顶向下的世界里立足，却在动态语言世界里大放光彩，这里最显著的例子莫过于 Python 的迭代器和生成器。\n回想一下在 C 的世界里，循环的标准写法是:\nfor (i = 0; i \u0026lt; n; ++i) { … }  这行代码包含两个独立的逻辑, for 循环控制了 i 的边界条件， ++i 控制了 i 的自增逻辑。这行代码适用于 C 世界里的数组即内存位移的范式，因此适合大多数访问场景。到了 STL 和复杂数据结构的世界，因为许多数据结构只支持顺序访问，循环往往写成:\nfor (i = A.first(); i.hasNext();i = i.next()) { … }  这种设计抽象出了一个独立于数据结构的迭代器，专门负责数据结构上元素访问顺序。迭代器把访问逻辑从数据结构上分离出来, 是一个常用的设计模式 （GoF 23个设计模式之一）.我们在 STL 和 Java Collection 中也常常看到迭代器的身影。\n在适当的时候，我们可以更进一步引入一个语法糖（脚注：这里牵涉到一个外部迭代器和内部迭代器的问题。限于篇幅不在此讨论）将循环写成:\nfor i in A.Iterator() {func(i)}。  事实上，许多现代语言都支持类似的语法。这种语法抛弃了以 i 变量作为迭代指针的功能，要求迭代器自身能够记住当前迭代位置，调用时返回下一个元素。读者不难看到，这种架构就是我们在文章开始提到的语法分析器的架构。正因为如此，我们可以从协程的角度来理解迭代器：当控制流转换到迭代器上时，迭代器负责生成和返回下一个元素。一旦下一个元素准备就绪，迭代器就让出控制流。这种特殊的迭代器实现在 Python 中又被成为生成器。以协程的角度切入的的好处是设计大大精简。实际上，在 Python 中，生成器本身就是一个普通的函数，和普通函数的唯一不同是它的返回语句是协程风格的 yield。这里，yield 一语双关，既是让出控制流，也是生成迭代器的返回值。\n以上我们仅仅讨论了生成器的最基本的特性。实际上，生成器的强大之处在于我们可以像 UNIX 管道一样串联起来，组成所谓的生成器表达式。如果我们有一个可以生成 1，2，3 … 的生成器 N，则 square = (i **2 for i in N) 就是一个生成平方数的生成器表达式。最终的控制流会在这些串联的部分间转换，无需我们写作复杂的嵌套调用。当然，yield 只是冰山的一角，现代的 Python 语言还充分利用了 yield 关键字构建了 yield from 语句，(yield) 语法等等，使得我们无困难的将协程的思想融入到 Python 编程中去。限于篇幅这里不再展开。\n5.协程的实现形式 # 我们前面说过，协程的思想本质上就是控制流的主动让出和恢复机制。在现代语言里，可以实现协程思想的方法很多，这些实现间并无高下之分，所区别的就是是否适合应用场景。理解这一点，我们对于各种协程的分类，如半对称/对称协程，有栈与无栈协程等具体实现就能提纲挈领，无需在实现细节上纠结。\n协程在实践中的实现方式千差万别，一个简单的原因，是协程本身可以通过许多基本元素构建。基本元素的选取方式不一样，构建出来的协程抽象也就有差别。比如, Lua 语言选取了 create, resume 和 yield 作为基本构建元素, 从调度器层面构建出所谓的“非对程”协程系统。而 Julia 语言绕过调度器，通过在协程内调用 yieldto 函数完成了同样的功能，构建出了一个所谓的对称协程系统。尽管这两个语言使用了同样的 setjmp 库，构造出来的原语却不一样。又比如，许多 C 语言的协程库都使用了 ucontext 库实现，这是因为 POSIX 本身提供了 ucontext 库，不少协程实现是以 ucontext 为蓝本实现的。这些实现，都不可避免地带上了 ucontext 系统的一些基本假设，比如协程间是平等的，一般带有调度器来协调协程等等（比如 libtask 实现，以及云风的 coroutine 库）。Go 语言的一个鲜明特色就是通道（channel）作为一级对象。因此，resume 和 yield 等在其他语言里的原语在 go 里都以通道方式构建。我们还可以举出许多同样的例子。这些风格的差异往往和语言的历史，演化路径，和要解决的问题相关，我们不必苛求他们的协程模型一定要如此这般。\n6.总结 # 总的来说，协程为协同任务提供了一种运行时抽象。这种抽象非常适合于协同多任务调度和数据流处理。在现代操作系统和编程语言中，因为用户态线程切换代价比内核态线程小，协程成为了一种轻量级的多任务模型。我们无法预测未来，但是可以看到，协程已经成为许多擅长数据处理的语言的一级对象。随着计算机并行性能的提升，用户态任务调度已经成为一种标准的多任务模型。在这样的大趋势下，协程这个简单且有效的模型就显得更加引人注目。\n参考文献：\n[1] 徐宥，\u0026ldquo;协程的历史，现在和未来\u0026rdquo;, https://blog.youxu.info/\n"}),a.add({id:443,href:"/blog/2017-04-26-coroutine-switching/",title:"Coroutine-Switching",description:"如今协程得到大量应用，大家对此并不陌生。本文对协程上下文切换做了一个简单的实验，以更好地认识协程切换及其开销。",content:"1. 协程Coroutine # 1.1. 协程coroutine声明 # file: coroutine.h\n#include \u0026lt;stdint.h\u0026gt; typedef int64_t (*EntryCallback)(void*); //硬件上下文信息 struct stRegister { uint64_t rax; uint64_t rbx; uint64_t rcx; uint64_t rdx; uint64_t rsi; uint64_t rdi; uint64_t r8; uint64_t r9; uint64_t r10; uint64_t r11; uint64_t r12; uint64_t r13; uint64_t r14; uint64_t r15; uint64_t rbp; uint64_t rsp; uint64_t rip; }; //协程上下文 struct stContext { struct stRegister cpu_register; void *arg; uint8_t *stack; }; typedef struct stContext Coroutine; //创建协程 Coroutine* CreateCoroutine(EntryCallback entry, void *arg); //删除协程 void DeleteCoroutine(Coroutine *ptr); //设置协程栈尺寸 void SetStackSize(uint32_t size); //协程切换 void __SwitchCoroutine__(Coroutine *cur, const Coroutine *next);  1.2. 协程Coroutine实现 # file: coroutine.c\n#include \u0026quot;coroutine.h\u0026quot; #include \u0026lt;stdlib.h\u0026gt; #define OFFSET(t, m) (\u0026amp;(((t*)0)-\u0026gt;m)) uint32_t g_stack_size = 100 * 1024; Coroutine* CreateCoroutine(EntryCallback entry, void *arg) { int size = g_stack_size + sizeof(Coroutine); Coroutine *c = (Coroutine *)calloc(size, 1); if (NULL == c) { return NULL; } uint8_t *start = (uint8_t*)c; c-\u0026gt;arg = arg; //函数入口 c-\u0026gt;cpu_register.rip = (uint64_t)entry; //第一个参数 c-\u0026gt;cpu_register.rdi = (uint64_t)arg; //rbp 栈底 c-\u0026gt;cpu_register.rbp = (uint64_t)(start + size); //rsp 当前栈顶 c-\u0026gt;cpu_register.rsp = c-\u0026gt;cpu_register.rbp; return c; } void DeleteCoroutine(Coroutine *ptr) { free(ptr); } void SetStackSize(uint32_t size) { g_stack_size = size; }  2. 协程Coroutine上下文切换 # file: switch.s\n//这里协程库是基于有栈协程的设计来实现，协程硬件上下文信息需通过%rsp来计算访问地址 //__SwitchCoroutine__(current_coroutine, next_coroutine) //- rdi, current_coroutine //- rsi, next_coroutine .globl __SwitchCoroutine__ __SwitchCoroutine__: //save rsp of calling function, here %rsp equals to return address mov %rsp, %rax //set rsp to end of coroutine.stRegister, to push rip, //when rdi coroutine return, it will return the rip to continue exec mov %rdi, %rsp add $136, %rsp push (%rax) //+8 to skip return address to get end address of calling function's %rsp add $8, %rax push %rax //store the current_coroutine's state(stRegister) push %rbp push %r15 push %r14 push %r13 push %r12 push %r11 push %r10 push %r9 push %r8 push %rdi push %rsi push %rdx push %rcx push %rbx push %rax //ready switch to next_coroutine mov %rsi, %rsp //restore the next_coroutine's stRegister to cpu pop %rax pop %rbx pop %rcx pop %rdx pop %rsi pop %rdi pop %r8 pop %r9 pop %r10 pop %r11 pop %r12 pop %r13 pop %r14 pop %r15 pop %rbp //move return address to %rax mov 8(%rsp), %rax pop %rsp //jmp to next_coroutine, ram indirect access to fetch the target address jmp *%rax  3. Coroutine使用 \u0026amp; 测试 # 3.1. 测试程序 # file: main.c\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026quot;coroutine.h\u0026quot; Coroutine *coroutines[3]; int64_t callback(void *arg) { while(1) { if(strcmp((char *)arg, \u0026quot;coroutine-a\u0026quot;)==0) { printf(\u0026quot;[%s] ready to switch to coroutine-b\\n\u0026quot;, (char *)arg); __SwitchCoroutine__(coroutines[0], coroutines[1]); } else if(strcmp((char *)arg, \u0026quot;coroutine-b\u0026quot;)==0) { printf(\u0026quot;[%s] ready to switch to coroutine-c\\n\u0026quot;, (char *)arg); __SwitchCoroutine__(coroutines[1], coroutines[2]); } else if(strcmp((char *)arg, \u0026quot;coroutine-c\u0026quot;)==0) { printf(\u0026quot;[%s] ready to switch to coroutine-a\\n\u0026quot;, (char *)arg); __SwitchCoroutine__(coroutines[2], coroutines[0]); } sleep(1); } return 0; } int main() { printf(\u0026quot;initialize coroutine's callback\\n\u0026quot;); EntryCallback cb = callback; printf(\u0026quot;create 3 coroutines\\n\u0026quot;); Coroutine *coo = CreateCoroutine(cb, (void *)\u0026quot;coroutine-o\u0026quot;); Coroutine *coa = CreateCoroutine(cb, (void *)\u0026quot;coroutine-a\u0026quot;); Coroutine *cob = CreateCoroutine(cb, (void *)\u0026quot;coroutine-b\u0026quot;); Coroutine *coc = CreateCoroutine(cb, (void *)\u0026quot;coroutine-c\u0026quot;); coroutines[0] = coa; coroutines[1] = cob; coroutines[2] = coc; printf(\u0026quot;ready to start coroutine switching\\n\u0026quot;); __SwitchCoroutine__(coo, coa); printf(\u0026quot;ready to exit\\n\u0026quot;); return 0; }  3.2. 测试程序build # file: Makefile\nall: *.c *.h *.s @echo \u0026quot;==\u0026gt; build the coroutine test module\u0026quot; gcc -g -o main *.c *.h *.s @echo \u0026quot;==\u0026gt; build successful\u0026quot; test: all @echo \u0026quot;==\u0026gt; run the coroutine test module\u0026quot; ./main clean: @echo \u0026quot;==\u0026gt; delete the build file 'main'\u0026quot; rm main  3.3. 测试结果 # make make test ==\u0026gt; build the coroutine test module gcc -g -o main *.c *.h *.s ==\u0026gt; build successful ==\u0026gt; run the coroutine test module ./main initialize coroutine's callback create 3 coroutines ready to start coroutine switching [coroutine-a] ready to switch to coroutine-b [coroutine-b] ready to switch to coroutine-c [coroutine-c] ready to switch to coroutine-a [coroutine-a] ready to switch to coroutine-b [coroutine-b] ready to switch to coroutine-c [coroutine-c] ready to switch to coroutine-a [coroutine-a] ready to switch to coroutine-b  "}),a.add({id:444,href:"/tags/libtask/",title:"libtask",description:"",content:""}),a.add({id:445,href:"/tags/ucontext/",title:"ucontext",description:"",content:""}),a.add({id:446,href:"/tags/java/",title:"java",description:"",content:""}),a.add({id:447,href:"/blog/2017-04-20-%E5%AD%A6%E4%B9%A0java-nio/",title:"Java NIO Tutorials",description:"Java网络编程中离不开对NIO的熟练运用，本文总结了NIO的实现原理、使用方式，以及并发编程中需要关注的一些核心问题。",content:"1 前言 # Java NIO，意为Java New IO，是一种相对于Java标准IO、网络API的替代方案。从JDK 1.4开始NIO就被引入了进来，它提供了另一种IO处理的方式，这使得Java在IO处理方面向前迈进了一大步。\nNIO Channel \u0026amp; Buffer # 在Java标准IO里面，IO处理的对象是字节流或字符流，在NIO里面我们处理的对象是channel和buffer，数据读总是从channel中读入到buffer，输入写总是从buffer写入到channel。\nNIO Non-Blocking IO # Java NIO使得我们可以通过非阻塞的方式执行IO处理，例如一个线程请求从channel中读取数据到buffer的时候，在channel执行数据读取操作到buffer的过程中，线程仍然可以执行其他的处理工作，当数据被读取到buffer中之后，线程再去对数据进行处理。数据写的过程也是与此类似。\n 备注：\n其实参考glibc中的pthread用户级线程库实现，可以大致想到这种channel、buffer工作模式的一种大致实现，大不了我多开一个用户线程让其执行channel和buffer之间的数据传输工作，处理完之后给原本请求channel读写数据的用户线程发个信号让其进行数据处理。Linux中的AIO就是这么搞的，可以参考《Linux设备驱动开发》。\n大家所描述的没有底层硬件支持的异步，很多都是指的软件代码执行序上的异步，本质上代码还是在以同步的方式执行，只不过在这些同步技术之上结合一些小佐料起到了类似的异步执行的效果。\n NIO Selector # Java NIO中有Selector（选择器）的概念，一个selector可以对多个channel上的事件进行监听，例如对多个channel上的连接打开、数据到达事件进行监听，因此一个selector可以用于对多个channel上的连接打开、关闭以及读写事件进行监听、处理。\n 备注：\nLinux中的selector本质上是基于epoll实现的，因此可以结合epoll来理解selector。\nchannel不过是对网络套接字的封装，buffer不过是对接收缓冲、发送缓冲的封装，selector不过是对epollfd的封装，selector对多个channel的监听，不过是epoll在epollfd上EPOLL_CTL_ADD了多个channel对应的fd，并对其上的事件进行必要的监听。selector轮询事件是否发生，本质上也就是epoll_wait轮询注册的多个fd上是否有事件发生。\n 下面将展开介绍Java NIO是如何工作的。\n2 概要 # Java NIO包括3个核心组件，即channel、buffer、selector。Java NIO里面包括的类不止这几个，但是我个人认为Java NIO API的核心类就这几个，其他的例如Pipe、FileLock子类的都是配合这3个核心组件使用的工具类，所以这里先重点介绍channel、buffer、selector，后面会在独立章节中对其他类进行介绍。\nNIO Channel \u0026amp; Buffer # Java NIO中的所有IO操作几乎都是从一个channel开始的，channel可以看做是对一对套接字的封装，例如一个tcp连接。可以从channel中读取数据到buffer，同样也可以将buffer中的数据写入到channel中，下图展示了channel和buffer的这一关系。\nChannel大致有如下几种实现：\n FileChannel DatagramChannel SocketChannel ServerSocketChannel  其中FileChannel主要用于文件io，DatagramChannel主要用于udp网络通信，SocketChannel用于tcp网络通信，而ServerSocketChannel用于建立tcp连接。\nBuffer大致有如下几种实现：\n ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer  上述多种Buffer的不同之处在于其中存储的数据类型的差异，例如ByteBuffer就是按照直接进行读写，CharBuffer就是按照字符进行读写。\nJava NIO中海油一种Buffer实现MappedByteBuffer，这种Buffer需要与内存映射文件来配合使用，我们这里暂时先不予介绍。\nNIO Selector # 一个selector允许一个单一线程对多个channel上的事件进行处理（Linux平台下的selector实现就是基于epoll），一个单一线程也可以对多个channel进行高效的io处理，例如一个可能会创建很多tcp连接每个tcp连接流量不大的情况下，比如构建一个聊天服务。\n下图是一个单线程借助selector来对3个channel进行io处理的示意图。\n使用selector对多个channel进行事件处理，类似于epoll中首先要将某些fd上的特定事件在epollfd注册一样，这里也需要先将我们关心的channel上的特定事件在selector中注册，然后就像epoll中调用epoll_wait()来等待某个事件发生一样，这里需要调用selector.select(方法来等待事件发生，等某个事件发生后再进入后续的事件处理过程，比如收到tcp入连接请求、数据到达事件等。\n3 NIO Channel # Java NIO与 Channel与标准IO中的stream（流）有某些相似之处，但是也有很大不同。\n 同一个channel既可读又可写，而同一个stream要么只可读要么只可写，从命名XXInputStream上也可以看出这个明显的不同； channel中的读写操作可以是异步的，标准io中的读写操作都是同步的（包括阻塞、非阻塞）； channel中读写操作总是借助于buffer来完成的，而流可以直接读写；  这里首先给出一个简单的FileChannel的示例程序，让大家对channel、buffer的使用有个大致的了解。\n// 打开文件并获取FileChannel RandomAccessFile aFile = new RandomAccessFile(\u0026quot;data/nio-data.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel inChannel = aFile.getChannel(); // 创建一个字节buffer ByteBuffer buf = ByteBuffer.allocate(48); // 读取文件内容到buffer int bytesRead = inChannel.read(buf); while (bytesRead != -1) { System.out.println(\u0026quot;Read \u0026quot; + bytesRead); // 切换buffer读写模式，从写到读 buf.flip(); // 打印buffer中的内容 while(buf.hasRemaining()){ System.out.print((char) buf.get()); } // 清空buffer继续读文件 buf.clear(); bytesRead = inChannel.read(buf); } // 关闭文件 aFile.close();  上面这个示例程序简单介绍了FileChannel \u0026amp; ByteBuffer的使用方式，其他的几个Channel \u0026amp; Buffer实现的使用方式与此有些类似，我们后面再展开。\n这里有个比较关键的点是Buffer的读写模式切换，例子程序中buffer一开始处于写模式，所以我们才能从channel中读取数据存储到buffer中，而后我们想查看buffer中的内容，这个时候首先需要将buffer从写模式切换为读模式，然后才能将其中的内容读取并显示出来。\n读者可能要问为什么buffer要切换读写模式，这里先简单说一下，buffer的底层是借助一个数组来实现的，其通过几个比较关键的位置索引变量来跟踪当前读写位置索引position、最大可读写位置索引limit、最大容量capacity，因为只有一个数组，要想支持读写两种模式的同时不致出现混乱，读写操作之前就需要改变上述pos、max、capacity这3个位置索引变量的语义和值，因此要调用buffer.flip()方法。\n当我们读取了buffer中的数据时，需要调用buffer.clear()来清空所有的buffer中数据，或者调用buffer.compact()来清空已经读取的数据，没有读取的数据则继续留在buffer中，并且数据会被移动到buffer中数组的起始位置，当我们继续向buffer中写数据时数据会追加在未读取数据的后面。\n总结一下buffer的使用过程，主要包括如下4步：\n 写数据到buffer中； 调用buffer.flip()将buffer从写模式切换为读模式； 从buffer中读取出数据； 调用buffer.clear()清空数据或者buffer.compact()清空以读取数据；   备注：\n这里的flip方法是为了能够正确读取写入模式下写入的数据，调用该方法修改position、limit变量后可以保证这一点。我们不调用这个方法也可以读取数据，但是会读取到错误的数据，切记，Java并不会在我们“忘记”调用flip方法时给出警告或者错误，需要程序开发人员自己来掌控。\n对于写操作也是一样的，调用clear或compact方法可以保证有可用空间来存储即将要写入的数据，当“忘记”调用该方法时也可以写入(buffer未满)，但是浪费了buffer存储空间，只能写入少量数据。\nflip、clear、compact，以及后面见要见到的mark、reset方法，都只是修改影响读写位置的position、limit的值而已，没有什么神秘的。\n 这么讲可能仍然有点抽象，后面会结合示意图进行进一步描述。\n4 NIO Buffer # NIO底层是借助一个数组来实现的，使用同一个数组实现了读、写两种不同的操作模式。为了支持读写操作，Buffer实现中提供了3个非常重要的变量position、limit、capacity来跟踪数组的读写指针（实际上是位置索引）。\n在不同的操作模式（读、写模式）下，这里的position、limit、capacity拥有不同的语义，如下图所示。\n 写模式下：  position，代表当前可继续写入的位置索引，[0,position)为已写入数据范围； limit，代表当前可写入的最大位置索引，limit=capacity，[position,limit)为可写数据范围； capacity，代表当前buffer最大容量，；   读模式下：  position，代表当前可继续读取的位置索引； limit，代表当前可读取的最大位置索引，[position,limit)为可读取数据范围； capacity，代表当前buffer最大容量，[limit,capacity)为未写入数据范围；    4.1 capacity # capacity代表了buffer的最大容量，其值为最多可存储的元素数量而非占用的字节数量，这个不难理解，每一种数据类型都使用与之对应的数组来作为存储用的基础设施。\n4.2 position # 写模式下，position初始值为0，然后每写入一个元素到buffer中之后position会+1指向底层数组的下一个存储位置。写模式下position最大值为capacity-1。\n当从写模式切换到读模式的时候，position会被重置为0，limit会被重置为写模式下position的值，这样就意味着只可以读取到写模式下写入到数组中的数据而不会访问越界。当读取数据时先读取position位置处的元素，然后position+1指向底层数组的下一个存储位置。\n4.3 limit # 写模式下，limit表示最多可以写入多少个元素，limit=capacity；而在读模式下，limit表示最多可以读取多少个元素，limit=buffer.flip()前写模式下的position。\n4.4 常用方法 # 下面对Buffer中常用的方法进行一下简要总结。\n4.4.1 创建buffer # allocate方法用于创建一个指定容量的buffer对象，下面分别创建一个48字节容量的ByteBuffer和一个1024字符容量的CharBuffer。\nByteBuffer buf = ByteBuffer.allocate(48); CharBuffer buf = CharBuffer.allocate(1024);  4.4.2 写数据到buffer # 向buffer中写入数据，有两种方法，一种是通过channel.read(buffer)来将channel中的数据写入到buffer中，另一种是通过buffer.put(el)方法及其各种变体来将对应类型的元素el写入到buffer中。\nint bytesRead = inChannel.read(buf); // read from channel into buffer. buf.put(127); // ...  4.4.3 切换buffer为读模式 # buffer.flip()方法将buffer从写模式切换为读模式，调用flip之后将把limit设置为position的值，然后再见position设置为0，使得可以读取[0,limit)范围下的数据，也就是写模式下写入的数据，通过limit的控制避免数组访问越界的可能。\n4.4.4 从buffer中读取数据 # 从buffer中读取数据，也有两种方式，一种是通过channel.write(buffer)将buffer中的数据读取出来写入到channel中，另一种是通过buffer.get()方法及其各种变体来将对应类型的元素读取出来。\nint bytesWritten = inChannel.write(buf); // read from buffer into channel buf.get(); // ...  4.4.5 rewind读取索引 # buffer.rewind()方法会将读索引变量position重设为0，但是limit保持不变，这样可以重新从头开始读取buffer中的数据。\n4.4.6 清空buffer备用 # 当buffer中的数据读取出来之后，需要清空buffer中的数据用于后续的数据写入操作。\n如果确定数据已经读取完毕，这个时候可以调用buffer.clear()方法，这个方法将把position设为0，将limit设置为capacity，这意味着调用了clear方法之后buffer中的所有已存储数据都不在可读，因为已经没有位置变量可以帮助我们读取它们了。\n如果数据没有读取完毕，剩下的数据还是希望继续读，但是现在要先写入某些数据，此时可以执行buffer.compact()方法，该方法将把buffer中未读取的数据拷贝到底层数组的前面，并将position设为0，将limit设置为未读取数据的元素数量。\n4.4.7 mark \u0026amp; reset # buffer.mark()可以标记当前的position位置，后面当position改变之后可以通过buffer.reset()将position重置为调用mark方法时标记的位置。\n这里mark()、reset()在读写模式下都可以使用，mark的实现方式就是通过一个mark变量记录下当前的position位置，reset方法就是将position设置为mark记录的值。\n为了避免读写模式切换时mark()、reset()被乱用，这里buffer.reset()的时候会首先检查当前的mark值是否有效，如果mark值小于0则认为是一个错误，会抛出异常，那么什么情况下mark值会为负值呢？当执行buffer.flip()操作的时候会将mark值重置为-1，这样就避免了读写模式切换后之前的mark可能被错误reset的情况，避免了可能的访问越界问题。\n4.4.8 buffer内容比较 # buffer内容比较主要有两个方法，一个是比较两个buffer是否相等buf1.equals(buf2)，如果两个buf的类型相同，并且两个buf中剩余元素数量相同，并且两个buf中剩余的元素在对应position处都equals都返回true，那么这两个buf1.equals(buf2)才会返回true，否则返回false。\nbuffer内容比较的另一个方法是通过buf1.compareTo(buf2)，当满足以下条件时，认为buf1\u0026lt;buf2，如果两个buf类型相同，并且buf1中的前i-1个元素与buf2中的前i-1个元素对应位置都完全相等，但是buf1中的第i个元素比buf2中的第i个元素小，那么就认为buf1\u0026lt;buf2成立；或者buf1中的所有元素与buf2中对应位置的元素都完全相等，但是buf2还有更多的元素，这个时候也认为buf1\u0026lt;buf2。buf1\u0026gt;buf2的逻辑与之恰好相反，buf1.equals(buf2)的逻辑前面已经提过。\n 备注：\n当buf1\u0026lt;buf2时，buf1.compareTo(buf2)会返回一个负数；\n当buf1==buf2时，buf1.compareTo(buf2)会返回0；\n当buf1\u0026gt;buf2时，buf1.compareTo(buf2)会返回一个正数；\n 5 NIO Scatter \u0026amp; Gather # NIO中支持分散读、聚集写，glibc中也提供了类似的库函数，NIO中的分散读指的是从一个channel中读取数据到多个buffer中，聚集写指的是将多个buffer中的数据写入channel中。\n当我们需要传输的数据可以分开几个固定部分来处理的时候，分散读、聚集写是非常有用的，例如当我们传输协议数据包的时候，希望将协议包头、协议包体分开，这个时候使用分散读、聚集写就是非常有用的，因为包头往往都是固定尺寸的，从channel中先读取固定数量的字节填满包头对应的buffer，再见剩下的数据读到包体对应的buffer中，这是一个很自然的过程。组包时聚集写也是一样的道理。\n5.1 Scatter # 下面是分散读的一个示意图，图中展示了从一个channel中读取数据写入多个buffer的过程。\n对应的示例代码如下所示：\nByteBuffer header = ByteBuffer.allocate(128); ByteBuffer body = ByteBuffer.allocate(1024); ByteBuffer[] bufferArray = { header, body }; channel.read(bufferArray);  首先创建了两个buffer，假定包头是固定128字节，包体最大1024字节，然后又创建了一个ByteBuffer数组，并将其作为参数传递给channel.read()方法，read方法会按照bufferArray中的元素顺序依次进行数据写操作，当填充满第一个buffer后就继续写第二个buffer，以此类推。\n 注意如果包头尺寸不固定，那么分散读就不是很适用了。\n 5.2 Gather # 下面是聚集写的一个示意图，图中展示了从多个buffer中读取数据并写入同一个channel的过程。\n对应的示例代码如下所示：\nByteBuffer header = ByteBuffer.allocate(128); ByteBuffer body = ByteBuffer.allocate(1024); ByteBuffer[] bufferArray = { header, body }; channel.write(bufferArray);  首先也是创建两个buffer，假定包头是固定128字节，包体最大1024字节，然后用这两个buffer创建一个buffer数组，并作为channel.write()的参数，write方法按照bufferArray中buffer出现顺序依次将其内容写入channel，先将第一个buffer的内容写入到channel，再见第二个buffer内容写入到channel，以此类推。\n6 NIO Channel间数据传输 # 在Java NIO中也可以通过一个channel向另一个channel进行数据传输，但是并不是所有的channel实现都支持，这里重点说一下FileChannel，这个类有两个重要方法transferFrom(\u0026hellip;)和transferTo(\u0026hellip;)，前者可以从另一个channel读取数据，后者可以将当前channel中的数据写入到另一个channel。\n下面看一个FileChannel.transferFrom(\u0026hellip;)的应用示例。\nRandomAccessFile fromFile = new RandomAccessFile(\u0026quot;fromFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\u0026quot;toFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); toChannel.transferFrom(fromChannel, position, count);  下面再看一个FileChannel.transferTo(\u0026hellip;)的应用示例。\nRandomAccessFile fromFile = new RandomAccessFile(\u0026quot;fromFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\u0026quot;toFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); fromChannel.transferTo(position, count, toChannel);  FileChannel.transferFrom(\u0026hellip;)方法也可以读取其他类型channel中的数据，FileChannel.transferTo(\u0026hellip;)方法也可以将FileChannel中的数据写入到其他类型的channel中。\n7 NIO Selector # NIO中的selector是一个非常关键的组件，可以用它来监视多个多个channel上的io事件，例如入连接请求、数据可读、数据可写等，这意味着可以用一个线程来处理多个channel，可以获得不错的并发处理性能。\n7.1 为什么使用Selector？ # 使用selector可以只用一个线程来处理多个channel上的io事件，无须创建多个线程来处理多个channel，减少创建线程的数量可以避免操作系统在多个线程之间进行切换所引入的负载。\n既然提到了线程切换所引入的负载，这里就对Java线程调度的内容展开描述一下，介绍一下Java线程、LWP进程、KLT线程之间的关系，也描述一下创建、切换过程中的代价，帮助更好地理解。然后我们再介绍一下面对不同的任务，对于多进程、多线程该如何选择。最后我们再继续介绍这里的selector。\n7.1.1 Java线程、LWP进程、KLT线程，它们之间是什么关系？ # Linux下Hotspot JVM采用的线程模型是基于“用户级线程+KLT线程”实现的，并且是一对一的，即一个Java Thread都会映射到一个Linux内核线程，线程调度利用了Linux的线程调度能力。\n这里有必要提一下Linux内核对线程提供的支持，Linux内核本身是没有什么线程的，其在设计之初就是面向进程的，最开始进程是资源分配的基本单位，也是任务调度的基本单位。但是后面发现进程创建、销毁、切换的开销比较大，如果了解过内核创建进程的实现的话就会明白这里的开销指的都是什么。\n当线程思想开始出现之后，Linux当然也不会汲取精华，为了支持线程机制，Linux内核中引入了轻量级进程(LWP，Light Weight Process)的概念，这里的“轻量级”体现在什么地方呢？如果了解过内核创建进程过程中clone及其某些特殊选项的话，就会明白创建轻量级进程比创建一个普通的进程轻量在什么地方了，简言之就是轻量级进程创建的时候共享父进程所有的资源，只是增加资源对应的引用计数，但是不会重新分配，不同于fork。\n轻量级进程也是进程，那么线程相对于进程有什么区别呢？线程不是资源分配的基本单位，只是任务调度的基本单位，对比一下linux 0.11以及2.0.40中struct task_struct结构体的定义就可以感受到任务调度的基本单位从进程变为线程这一过程。在0.11里面task_struct结构体中的tss（任务状态段，保存硬件上下文信息）为struct tss_struct类型，这一类型是面向进程的，而0.2.40里面tss是struct thread_struct类型，这一类型是面向线程的。而不管是普通进程还是轻量级进程，它们的task_struct定义中都包括一个struct thread_struct tss，用于任务调度过程。\nLinux下的KLT线程其实并不是什么真正的线程，其强调的是一种面向线程的任务切换能力。Java中的线程逻辑上是从属于java进程的，在Linux平台下实现时Java主线程被映射为一个普通的进程，而其他Java线程被映射为系统进程clone出来的轻量级进程LWP，这里clone出来的LWP的tgid（线程组id）与普通进程（父进程）是相同的，因为逻辑上它们从属于同一个线程组。普通进程跟轻量级进程在任务切换时所需要执行的除tss保存、还原之外的附加工作是不一样的，进程的附加工作更重（可能会涉及到虚拟内存等的处理），切换效率更低。\n任务切换过程中涉及到的内容说起来可能就几个关键点，但是如果想把细节讲清楚，需要结合软硬件变迁的历史、各种可能的情景来描述，请原谅我还掌握的还不够，这里就先点到为止。\n讲了这么多，看上去好像是要大肆宣扬使用Java多线程编程，这里不是，只是想到了实现进程、线程所需要付出的代价，多线程确实比多进程更加轻量，但也并非多线程一定比多进程好，要看实际的应用场景。\n7.1.2 面对不同任务，多进程、多线程的选择？ # 我们开发的程序往往可以归为3类：\n 计算密集型（CPU敏感型） IO密集型（计算负载小，网络IO多） 用户交互型（代码逻辑在计算、网络IO之间切换，非固定偏向某一种）  对于计算密集型的任务，即便开多个Java线程也不会得到很好的并发效果，简言之这个Java线程不会让度CPU，为什么这么说呢？以单CPU单核为例，一个时刻只会调度一个Java线程执行，因为这个线程忙于计算，不会因为阻塞让度CPU（阻塞时内核通常会将对应的LWP设为不可中断等待直到IO完成才会将其设为就绪重新参与进程调度），这样其他的Java线程基本得不到调度的机会，除非该线程对应的LWP时间片到切换到执行其他Java线程的LWP才可以。假如所有的线程都是计算密集型，这样的多线程计算效率要远低于多进程计算！多CPU或者多核情况下，虽然可以通过在其他CPU或者核心调度多个Java线程，但也无济于事！\n对于IO密集型的任务，应该开多个Java线程来代替多个进程，IO一般多指网络IO，IO完成需要一定的时间，不可能IO一发起就立即成功结束，所以使用阻塞型IO进程一定会经历阻塞、唤醒的过程。对于阻塞型IO，映射到LWP之后，进入阻塞型系统调用，Linux内核会将LWP状态设置为不可中断等待状态，在IO完成内核重新修改LWP状态为就绪态之前，LWP无法参与进程调度，对应的Java线程也无法执行，这期间CPU就会被让出来供其他LWP选择执行剩余的Java线程，这种情况下多个Java线程可以提高并发效率。\n这里可能有人问为什么一个Java线程阻塞了，对应的Java进程却没有阻塞？JVM中Java线程只是维护了线程应有的某些属性信息，并非真正的线程实体，一个Java进程准确地说是一个JVM实例，也不是一个通俗意义上的进程。一个JVM实例实际上包括一个Java主线程对应的普通进程，同时还包括了很多的调度Java线程用的LWP以及用于执行JVM特殊任务（如GC）的LWP。一个Java线程的阻塞，只是阻塞选择并执行该线程的LWP，对于其他Java线程不会构成影响。这里选择Java多线程模型比多Java进程模型要好多了，后者更消耗资源，任务调度上也获得不了什么优势。\n 备注：\n关于Java线程创建、调度以及多进程、多线程如何选择的内容就先介绍到这里，下面回到本章selector上来。\n 前面我们提到了在不同的任务下对多进程、多线程的选择，对于IO密集型的任务，其实因为计算时间比较短，绝大部分时间是在执行IO处理，如果我们能够采用IO事件驱动的方式来对IO进行处理的话（比如处理连接建立、读写数据），使用单一线程也可以获得不错的系统吞吐量，也能减轻多线程切换的负载。\n下图是一个单线程借助selector对3个channel进行管理的示意图。\n7.2 创建Selector # 通过一个简单的方法调用，就可以创建一个selector对象。\nSelector selector = Selector.open();  7.3 向Selector中注册Channel # 要想通过selector来访问channel，首先要将关心的channel及其事件向selector进行注册，注册的方法如下所示。\n// 通过selector访问channel，channel必须是非阻塞模式 channel.configureBlocking(false); // param1, channel必须是可以设置为non-blocking // param2，关心的事件有4钟，Connect、Accept、Read、Write SelectionKey key = channel.register(selector, SelectionKey.OP_READ);  FileChannel因为无法切换为非阻塞模式，所以无法将其注册到selector，也就无法通过selector对FileChannel进行访问。SocketChannel可以注册到selector，实际上一般多是用selector来处理SocketChannel上的IO事件。\n对于channel.register方法的第二个参数，是要注册的感兴趣的事件类型，主要有4种：\n Connect，表示一个SocketChannel连接到另一个server成功； Accept，表示一个ServerSocketChannel接收一个入连接请求成功； Read，表示channel中有数据到达，可以进行读取； Write，表示channel中有空闲位置，可以写入数据；  当channel中发生了上述事件时，我们称该channel上的对应事件就绪，例如Read事件就绪，或者说是Read Ready。\n7.4 SelectionKey # 当我们调用channel.register()时，该函数返回一个SelectionKey对象，通常这个对象可以获取到注册时的channel、selector、感兴趣的事件集合interestingSet、就绪事件集合readySet，以及一个可选的attach对象。\n7.4.1 感兴趣事件集合interesting set # 下面是一个通过selectionkey来获取注册时提供的interesting set的代码示例。\nint interestSet = selectionKey.interestOps(); boolean isInterestedInAccept = interestSet \u0026amp; SelectionKey.OP_ACCEPT; boolean isInterestedInConnect = interestSet \u0026amp; SelectionKey.OP_CONNECT; boolean isInterestedInRead = interestSet \u0026amp; SelectionKey.OP_READ; boolean isInterestedInWrite = interestSet \u0026amp; SelectionKey.OP_WRITE;  7.4.2 就绪事件集合ready set # 下面是一个通过selectionkey来获取ready set的代码示例。\nint readySet = selectionKey.readyOps();  为了测试到底有哪些事件就绪，是connect、accept？还是read、write？还是没有？可以采用与8.4.1总相同的“AND”操作来对对应的事件bit进行测试，以发现到底有哪些事件就绪。另外selectionkey提供了4个方法可以用于测试某个事件是否就绪，这4个方法是：\nselectionKey.isAcceptable(); selectionKey.isConnectable(); selectionKey.isReadable(); selectionKey.isWritable();  7.4.3 channel + selector # 通过selectionkey获取channel、selector是通过对应的getter方法，如下所示：\nChannel channel = selectionKey.channel(); Selector selector = selectionKey.selector();  7.4.4 attach object # 可以通过selectionkey来设置一个attach对象，这个对象可以用来识别一个channel，也可以用于向channel提供附加信息。比如我们可以将channel对应的buffer作为这里的attach对象。设置attach对象、获取attach对象的方法如下所示。\nselectionKey.attach(theObject); Object attachedObj = selectionKey.attachment();  注册channel到selector时，如果attach对象已存在，也可在注册的时候指定attach对象。\nSelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject);  7.4.5 selector选择事件就绪的Channel # 将channel注册到selector之后，可以通过selector中的select方法来选择出有感兴趣事件就绪的channel，以便对其进行处理。\n这里的select方法有3个不同的变体：\nint select(); // 阻塞在此处直到有感兴趣的channel就绪 int select(long timeout); // 阻塞在此处最多timeout秒 int selectNow(); // 不阻塞在调用处，没有就绪channel立即返回  这几个select方法的返回值表示上一次调用select方法之后又有新事件就绪的channel的数量（类似于epoll的ET_TRIGGER方式）。例如向selector注册了两个channel，第一次调用select时假如有一个channel就绪，那么select返回值为1。假如下次调用select时又有一个channel有时间就绪，那么select返回值为1。假如第一次调用select后的channel就绪事件没有进行处理的话，那么现在就有两个事件就绪的channel等待处理，但是第二次select的时候只返回1而不是2。如果理解epoll的ET_TRIGGER方式的话，这里应该不难理解。\n7.4.6 selectedKeys() # 一旦select返回，并且确实存在事件就绪的channel的话，可以通过selectedKeys()方法来访问这些就绪的channel并执行相应的处理动作。selectedKeys()返回一个集合，集合中的SelectionKey关联的channel均存在就绪事件。下面是方法selectedKeys()的方法声明。\nSet\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys();  由于可能为不同的channel上关联了不同的selectionkey类型（connect、accept、read、write），当我们遍历所有的selectionkey时需要检查对应的selectionkey的类型，以便执行与connect、accept、read、write相对应的处理动作。下面是一个操作示例。\nSet\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); // 注意根据不同的事件类型，对key.channel()进行适当的类型转换 if(key.isAcceptable()) { ServerSocketChannel chl = (ServerSocketChannel)key.channel(); ... } else if (key.isConnectable()) { SocketChannel chl = (SocketChannel)key.channel(); ... } else if (key.isReadable()) { SocketChannel chl = (SocketChannel)key.channel(); ... } else if (key.isWritable()) { SocketChannel chl = (SocketChannel)key.channel(); ... } // - 需要从selectedKeys集合中手动移除处理完毕的SelectionKey // - 下次调用selectedKeys()时若事件就绪，会重新将其加入selectedKeys集合中 keyIterator.remove(); }  7.4.7 wakeup # 如果一个线程调用了selector.select()方法并且阻塞在这个方法调用处的话，可以通过在另一个线程将其“唤醒”，唤醒的方式就是在这个不同的线程中调用selector.wakeup()方法。\n假如一个线程调用了wakeup方法，并且当前没有线程因为调用select方法而阻塞在方法调用处的话，那么下次某个线程调用select方法时假如没有事件就绪的channel，这个线程将立即被“唤醒”，即不会阻塞在方法调用处。这与selector的实现细节有关系，这里不过多展开。\n7.4.8 close # 当我们不再需要使用selector对channel进行处理的时候，可以通过selector.close()方法来关闭selector，该selector将同时使注册的所有的selectionKey实例失效，但是呢，这里的close方法并不会关闭注册时的channel对象，如果不需要对channel进行处理了，需要手动处理channel的关闭操作。\n8 FileChannel # FileChannel是连接到文件的channel，可以通过FileChannel对文件进行读写，它是标准IO读写文件的另一种替代方案。\nFileChannel不能设置为non-blocking模式，只能工作在blocking模式下。\n8.1 打开一个FileChannel # 只能通过文件输入输出流或者RandomAccessFile来打开FileChannel，不能直接打开，下面是通过RandomAccessFile打开FileChannel的示例。\nRandomAccessFile aFile = new RandomAccessFile(\u0026quot;data/nio-data.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel inChannel = aFile.getChannel();  8.2 通过FileChannel读取数据 # 通过FileChannel读取数据主要分为两步，首先分配一个buffer，然后将channel中的数据读取到并存储到buffer中，下面是一个读取FileChannel的示例。\nByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buf);  如果read返回-1，表示EOF，End Of File，即到达了文件末尾。\n8.3 向FileChannel写入数据 # 向FileChannel中写数据主要包括下面几步，首先要有一个待写入的数据，然后分配一个buffer并将数据写入buffer中，最后再调用channel.write(buffer)方法将buffer中数据写入channel。下面是一个操作示例。\nString newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); // buffer一开始为write模式，调用channel.write()之前需要flip切换为读模式 buf.flip(); // 不能保证channel.write()方法一次会读取buffer中多少数据，因此要循环处理 while(buf.hasRemaining()) { channel.write(buf); }  8.4 关闭FileChannel # 当FileChannel使用完毕之后，必须关闭，避免句柄泄露的问题。\nchannel.close();  8.5 FileChannel中文件位置 # 类似于fseek类的相关操作，FileChannel也提供了在文件中进行位置定位的能力，主要是通过position这几个方法。\nlong pos = channel.position(); // 获取当前在channel中的位置 channel.position(pos+123); // 在channel中定位到当前位置之后123偏移量处  如果pos+123超过了channel的实际尺寸的话，channel.read(\u0026hellip;)的时候将返回-1。\n8.6 FileChannel Size # 获取FileChannel关联的文件的尺寸，可以通过channel.size()方法。\nlong fileSize = channel.size();  8.7 FileChannel Truncate # 如果将文件截断为指定的尺寸，并丢弃超出部分的内容，可以通过channel.truncate(\u0026hellip;)方法。\nchannel.truncate(1024);  8.8 FileChannel Force # 类似于sync操作，FileChannel也提供了将文件在内存中的数据同步到磁盘的操作，即通过channel.force()方法，另外呢，channel.force(true)还可以将文件的元数据信息同步到磁盘，比如将文件权限信息等同步到磁盘。\n 备注：\n操作系统一般都是将文件内容读取到指定的缓冲块中，文件元数据信息也是会被加载到i节点对应的缓冲块中，当进程对文件本身进行操作时，为了提高性能，操作系统一般不会立即将文件内容、元数据信息的修改同步到磁盘，而是将改写后的数据存储在这里的缓冲块中（缓冲块其实是内核中的一段特殊内存区域），过一段时间之后，内核会自动将这里的数据同步到磁盘（Linux 0.11中是通过update进程来负责完成缓冲块写回磁盘的工作）。\n当时某些情景下，进程希望立即将某些信息写回磁盘，就可以通过这里的force方法来完成。\n 9 NIO SocketChannel # SocketChannel是对Tcp网络套接字的一种抽象，有两种创建SocketChannel的方式，一种是通过连接到远程的某个Tcp Server来创建一个SocketChannel，一种是通过ServerSocketChannel监听到入连接请求时创建一个SocketChannel。\n9.1 创建SocketChannel # 下面是一个通过连接到Tcp Server来创建SocketChannel的示例：\nSocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(\u0026quot;http://jenkov.com\u0026quot;, 80));  9.2 关闭SocketChannel # 关闭socketchannel的方式就是调用close方法。\nsocketChannel.close();   备注：\n资源的释放是非常重要的，我经历过一次因为没有关闭tcp连接导致进程打开的fd达到系统上限，进而导致tcp server拒绝服务的一次事故，直接拖垮了现网\n 9.3 从SocketChannel读取数据 # 从socketchannel读取数据可以通过channel.read()方法及其变体来操作。\nByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = socketChannel.read(buf);  9.4 写数据到SocketChannel # 写数据到socketchannel可以通过channel.write()方法及其变体来操作。\nString newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); buf.flip(); while(buf.hasRemaining()) { channel.write(buf); }  9.5 Non-blocking模式 # 可以将socketchannel设置为非阻塞模式，然后以非阻塞的方式来进行connect、read、write操作，当然也可以通过selector基于事件驱动的方式来对channel进行更好地处理。这里先看下非阻塞方式下的connect、read、write。\n9.5.1 connect # 非阻塞模式下connect调用可能在连接成功建立之前就返回了，为了判断连接是否建立成功，需要通过finishConnect方法来判断连接是否成功建立。\nsocketChannel.configureBlocking(false); socketChannel.connect(new InetSocketAddress(\u0026quot;http://jenkov.com\u0026quot;, 80)); while(! socketChannel.finishConnect() ){ //wait, or do something else... }  9.5.2 read # 在非阻塞模式下read，可能不会返回任何数据，需要对返回值进行判断，如果返回值\u0026gt;=0都是有效的读状态，应该在循环中继续进行read操作。如果返回值为-1（EOF），表示对端Tcp连接关闭，此时应该关闭channel。这里就不给出代码示例了。\n9.5.3 write # 在非阻塞模式下write，可能不会立刻写入任何数据，也需要在循环中进行write操作，直到数据全部写入成功。前面已经给出了类似的write示例代码，这里就不再重复给出代码示例了。\n 备注：\n也可以通过selector注册多个非阻塞的socketchannel，然后通过selector基于事件驱动的方式来对socketchannel上的io事件进行处理，后面会继续对此进行描述。\n 10 NIO ServerSocketChannel # serversocketchannel可以用于监听入tcp连接请求，并返回建立的tcp连接对应的socketchannel。\n下面是一个简单的应用示例。\n// 创建一个serversocketchannel ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 绑定监听端口 serverSocketChannel.socket().bind(new InetSocketAddress(9999)); while(true){ // 监听tcp入连接请求 SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel... } // 关闭serversocketchannel serverSocketChannel.close();  我们也可以使用非阻塞的方式来使用serversocketchannel，如下所示。\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9999)); // 设置为非阻塞模式 serverSocketChannel.configureBlocking(false); while(true){ SocketChannel socketChannel = serverSocketChannel.accept(); // accept在连接建立之前返回，返回null if(socketChannel != null) { //do something with socketChannel... } } serverSocketChannel.close();  其实我们也可以将serversocketchannel的accept事件注册到selector，然后用selector使用基于事件驱动的方式来对tcp入连接请求进行处理。后面会进一步进行介绍。\n11 NIO Non-blocking Server # 截止到现在，尽管已经对NIO中的selector、channel、buffer进行了介绍，我们也了解了它们的基本使用方法，但是要想设计一个non-blocking io的server还是有较大的难度的。non-blocking io实现的server相比于blocking io实现的server存在一些很有挑战性的地方，这里将针对这些挑战提出一些解决方法。\n从网上找一些关于non-blocking io实现server的方式也是比较困难的，相关的描述也并不是很细致，因此这里的解决方法是根据作者个人的一些工作经验和想法提出的。如果你有好的建议，也可以自己进行实现、测试。\n这里的设计思路是围绕着Java NIO来进行的，其实这里的设计思路同样可以用于其他的编程语言中，只要对应的语言提供了类似selector这样的事件驱动IO处理的API即可，比如可以使用c、c++语言来基于epoll实现。\n11.1 NON-Blocking Server - Github Repo # 这里根据本文提供的非阻塞io server的设计思路，作者对其进行了一个实现，项目的源代码也已经托管在了github上，可以从这里下载到：Non-Blocking IO Server。\n11.2 NON-Blocking IO Pipelines # 非阻塞io流水线模型是通过多个模块构成的职责链来处理非阻塞io，包括非阻塞的read、write操作，下图是一个简化版（只有一个component）的非阻塞io流水线的示意图。\n这里的component通过使用一个selector来检查什么时候可以从channel读取数据，然后读取数据之后执行处理生成某些结果信息，并将结果信息输出到channel。\n一个流水线模型并不总是既读取数据又写数据，某些情况下可能只会读取数据，某些情况下可能只会写入数据。上图中这个简化版的流水线模型示意图只有一个component，通常一个流水线有多长取决于这个流水线要执行什么样的任务处理。一个非阻塞io流水线也可能会同时读取多个channel中的数据，并不一定是只读一个channel，比如可能读取多个SocketChannel中的数据。对于流水线的输出操作也是一样的情况。上图中的控制流也是简化的，数据读取操作是由component发起的，而不是由channel push消息到selector再发送到component……\n11.2 NON-Blocking vs Blocking IO Pipelines # 这里对非阻塞io流水线模型和阻塞io流水线模型进行一下分析、对比。这两种流水线模型的最大区别在于对channel中数据的读取方式，这里的channel无非也就是读写socket或者file。\n如下图所示，io流水线中往往是通过一个Message Reader来读取Stream中的数据，并将数据解析为一个或者多个Message，然后进行再交给其他component进行处理。\n对于阻塞型io，这里的Stream可以通过InputStream等类似接口进行数据read操作，read操作将会被阻塞，直到有数据到达read才返回。阻塞型io场景下MessageReader的实现是比较简单的，因为InputStream的read操作直到读取了指定数据量的数据后才会返回，MessageReader不需要处理没有数据到达或者只有部分数据（read读取的数据小于一个完整的Message）到达的特殊情况。\n类似地，阻塞型io，这里的MessageWriter实现也比较简单，因为write操作总是将指定数据量的数据写入到OutputStream才会返回，不需要处理没有输入写入或者只写了部分数据的特殊情况。\n 备注：\n非阻塞型io需要针对MessageReader可能读取不到数据、读取到部分数据的情况进行处理，也需要对MessageWriter没有写数据或者只写了部分数据的特殊情况进行处理，这涉及到很多细节上的处理，增加了MessageReader、MessageWriter的实现难度。\n 11.3 Blocking IO Pipelines Drawbacks # 虽然前面提到阻塞型io流水线便于简化MessageReader、MessageWriter的实现难度，但是阻塞型io流水线也存在比较明显的劣势，这里就对其存在的问题进行简要描述。\n阻塞型io流水线中，对于一个特定的InputStream的数据读取操作，一般要开一个专门的线程进行数据读取操作，因为如果使用当前线程进行数据读取操作的话将会阻塞当前线程，线程将无法继续执行其他处理。\n如果一个server是基于阻塞型io流水线实现，那么每当一个tcp入连接请求到达，server就建一个对应的tcp连接，对于连接上接收到的数据需要执行read操作，那么需要为每个tcp连接创建一个线程专门用于读取其InputStream上的数据。如果server要处理的并发量只是几十上百的话，那么这种设计方式也不会造成什么危害。但是假如server面对的是成百万上千万的并发量的话，这种设计是难以平行扩展的。在32位系统上，一个Java Thread的线程栈大约占320KB内存，在64位系统上，大约要占用1MB内存，计算一下100w个线程的线程栈总容量，大约为1TB内存！这还只是线程栈的大小，还没有计算线程需要处理请求所需要的堆空间等的内存空间。\n为了减少创建线程的数量，有些解决方案是借助于线程池的方式来避免无限制地创建线程。线程池指定允许创建线程的最小、最大数量。每当有tcp入连接请求到达的时候，主线程创建一个连接，并将这个连接丢到一个阻塞队列中，然后线程池中的线程来从这个阻塞队列中取出要处理的tcp连接，并获取连接对应的InputStream然后进行数据读取操作。这里的设计可以用下面的示意图来表示，图中最左边的多个Stream代表多个tcp连接上的InputStream，将多个Stream组合在一起的方框则代表保存tcp连接的阻塞队列。\n但是这种基于线程池来希望避免无限制创建线程的想法也是站不住脚的，因为假如有太多请求比较耗时，长时间占用线程或者数据read、write阻塞线程，更极端一点，很可能线程池中的所有线程都被阻塞了，那么server为了不出现DoS（Denial of Service）那它可能会执行在线程池继续创建线程的动作以对新的请求进行响应，这一过程将持续到线程池中线程数量达到最大阈值，假如最大值为100w，那么占用内存还是会超过1TB！而如果不继续创建线程，因为线程都阻塞了，也无法继续响应新的请求。\n所以，基于阻塞型io流水线的架构可能实现MessageReader、MessageWriter比较简单，但是真的不利于server的平行扩容，难以有效应对高并发的场景，如果事务处理时间有比较长的话，系统吞吐量将会严重下降，甚至于可能会出现拒绝服务。\n11.4 Basic Non-blocking IO Pipeline Design # 前面提到了阻塞型io流水线的优缺点，为了解决阻塞性io流水线的弊端，可以采用非阻塞型io流水线技术提供另一种读取数据的实现方法。\n非阻塞型io中可以通过一个MessageReader来读取源自多个stream的数据，前提是要将stream对应的channel设置为非阻塞工作模式。非阻塞io流水线下，MessageReader读取数据操作可能返回0或者正数，如果返回0表示没有读取到数据，如果返回正值，则表示成功读取的数据数量。\n某个tcp连接上如果没有数据到达，那么前就不应该分配线程对连接上的数据执行处理。NIO Channel里面对于这些非io事件就绪的连接是不会返回的，只返回我们关心的发生了某些特定事件的channel，然后对channel进行read操作，这样效率还是比较高的。\n这种基于非阻塞io流水线模型的示意图如下。\n11.5 Reading Partial Messages # 当从一个SeletableChannel中读取数据时并不清楚读取到的数据是否是一个完整的消息，这里读取到的数据Data Block可能不足一个完整的Message，可能刚好是一个完整的Message，当然也可能包括了一个完整的Message和另一部分或完整或不完整的Message数据，如下图所示。\n在处理不完整消息数据的时候面临着两个挑战：\n 如何检测在数据块里面是否包括了一个完整的Message； 在完整的Message数据到达之前，对部分到达的数据应该做如何处理；  为了检测消息数据的完整性，需要提供一个Message Reader来检查数据块中是否至少包括一个完整的Message对应的数据。如果这个数据块中包括了一个或者多个完整的Message，这些完整的Message可以发送到流水线中进行后续处理任务。从数据块中检查Message完整性的工作要不停地重复，所以这部分处理要尽可能高效。\n当数据块中出现了一个Message的不完整数据，这个数据可能出现在一个或者多个完整Message数据之后，也可能单独出现，在Message的剩余数据到达之前需要将这部分数据先临时保存起来，以便后续数据到达之后将其拼接为一个完整的Message。\n检测Message数据完整性和存储Message的不完整数据的工作，都是由Message Reader来完成的，为了避免不同的channel上到达的Message数据混淆在一起，我们为每个channel分配一个单独的Message Reader。Message Reader示意图如下所示。\n一旦从selector获取到一个可以进行读操作的channel实例，与之关联的Message Reader就开始工作，从channel中读取数据并将其组装成一个个完整的Message，完整的Message将被丢到流水线执行后续处理工作。\n当然了，Message Reader将读取到的数据如何组装成一个个完整的Message，这个是与定义的应用层协议相关的，Message Reader必须要知道Message的格式。如果要将server实现做成一个支持多种协议的，最好能借助Message Reader插件的形式来完成，可以通常Message Reader工厂模式，通过指定具体的配置参数来获取协议对应的Message Reader。\n11.6 Storing Partial Messages # 前面已经指出了存储不完整的Message数据也是Message Reader的工作，这里我们说明一下如何实现Message Reader存储不完整Message数据。\n在设计实现方案时有这么两个点需要关注：\n 希望能够尽可能少地拷贝消息，拷贝次数、拷贝数据越多，效率越差； 希望能够将属于同一个Message的数据在内存中连续存储，方便解析；  为每个Message Reader分配一个独立的Buffer # 很明显，到达的不完整的Message数据需要被临时存储在某种形式的buffer中，最直接的就是每个Message Reader里面开一个buffer来存储。但是这里的buffer多大合适呢？它需要能够存储下最大尺寸的Message，假如这个最大的Message是1MB的话，假如有100w并发访问，一个tcp连接对应一个channel，一个channel对应一个Message Reader，一个Reader对应一个buffer，假如将buffer开到最大Message的尺寸1MB，这个时候大约需要100w*1MB=1TB的内存，而如果Message尺寸继续增大呢？16MB或者128MB呢？\n这种设计方案存在个巨大的缺陷，现实中的内存很难达到这个容量。\n容量可调整的Buffers # 再想一种方案，我们可以设计一个容量可调整的buffer在Message Reader中使用，这个buffer呢一开始容量比较小，等到有较大的Message到达的时候自动扩展buffer的容量。这样的话每个tcp连接就不会固定占用1MB的buffer了，每个连接仅占用获取下一个完整Message所需要的buffer空间。\n实现容量可调整的buffers的实现方法有多种，各有优劣，这里就介绍几个常用的实现方法。\n通过“拷贝”操作实现Buffer容量调整 # 这里的思路是开始的时候设置buffer为一个较小的容量，例如4KB，当一个正在接收的Message大小超过了这个buffer时，假设Message大小为4.1KB，这个时候就申请一个更大的buffer，例如8KB，然后将已经接收的数据从4KB的buffer拷贝到8KB的buffer。\n这种方式的优点是，可以保证同一个Message的数据在内存中是连续的，这样解析这个Message的时候就会变得很简单（各个协议字段是挨着的，访问各个协议字段时逻辑更简单）。\n这种方式的缺点是，尺寸较大的Message会导致很多的数据拷贝动作。\n为了减少数据拷贝的次数，可以对server请求进行抓包分析，如果大多数的请求Message都小于4KB，那么buffer的起始容量可以设置为4KB。再延伸一下，假如后续抓包分析到有些请求Message尺寸会超过4KB，分析后发现这些都是传输的文件，进一步分析发现这些文件大部分都是小于128KB的，那么这个时候可以考虑将128KB设为buffer的调整后尺寸。再延伸一下，假如后续发现也有些请求Message是超过128KB的，但是这些请求并没有明显的模式表明其最大尺寸，这个时候可以指定一个最大阈值，例如256KB，来作为buffer的最大调整尺寸。\n通过对server中请求Message的分析后，我们得出了3个不同容量的buffer来实现调整buffer容量的目的，一定程度上减少了数据拷贝的次数。\n 对于小于4KB的Message不需要执行拷贝动作，假如Message都小于4KB，100w连接只需要大约4GB的内存，这个容量还是可接受的（2015年数据）； 对于大于4KB小于128KB的Message，之前存储在4KB buffer中的数据需要被拷贝到128KB的buffer中，然后后续到达的数据直接存储到128KB的buffer中即可，因此数据拷贝次数为1； 对于大于128KB的Message，其最初是被存储到4KB buffer中的，后面读取的时候发现数据存不下了，就将其拷贝到128KB的buffer中（拷贝了一次），然后后续读取的时候发现128KB的buffer也不够用了，就需要再将其拷贝到MaxKB buffer中（拷贝了一次），后续再到达的数据直接写入MaxKB buffer中，共执行了两次拷贝动作。  考虑到大于4KB的Message是少量的，因此内存占用应该不是太大的问题，数据拷贝次数也应该是可以接受的。\n当一个Message被构建成功之后，为接收Message数据所分配的大容量的buffer应该予以释放。这样一来，对应的channel上的Message Reader中的buffer又从最小的4KB buffer开始。这种方式保证了各个连接只占用必要容量的内存，使得可以有更多连接同时执行消息处理任务。\n作者曾经实现了一个容量可调整的Array，采用的实现方式与这里的相同，感兴趣的话可以查看一下，链接地址为Resizable Arrays。教程里面给出了github上托管的repo地址。\n通过“追加”操作实现Buffer容量调整 # 另一种调整buffer容量的方式，我们可以创建这样一个buffer，让它包括多个数组（普通buffer都是只包括一个数组），当我们需要调整buffer容量的时候就再额外申请一个数组并将其加入到这个buffer中，向buffer中写更多数据时就可以写入到新加入的数组中。\n这里也可以细分为两种方式。一种是在buffer内部增加一个列表，列表维持一系列数组的引用，当buffer需要扩大容量时，就分配新数组加到这个数组列表里面；另一种是分配一系列的共享同一数组的slices，然后buffer中维持一个列表来记录这些slices。这两种方式类似，但是也确实有点区别，其中第二种方式看上去要更好一点。\n通过追加的方式来扩容buffer，这种方式的缺点是数据不是存储在同一个连续的地址空间中，这使得Message的解析工作更加困难，解析器必须对多个数组内的数据进行检查才能确定Message所包含的所有数据。这种方式比较难处理。\nTLV编码的Message # 一些协议消息Message采用的是TLV格式，TLV即Type、Length、Value。意思是说这样的Message数据首先会存储消息的总长度，这样我们就能立即知道需要分配多少内存空间才能容纳Message的数据。\nTLV编码格式使得内存管理更简单了，很容易就知道需要多少内存空间来容纳Message数据，不会向前面说的resize buffer时存在的内存空间浪费的情况。\nTLV编码格式的缺点是，我们在Message数据完整到达之前就知道了消息的总长度，并且为其一次性分配了内存空间，这其实又浪费了内存的使用效率。如果有很多的慢速tcp连接，并且它们发送的都是比较大的Message，那么可能会导致Message处理之前就大量占据了内存，很可能导致服务没有足够内存来处理其他事务最后拒绝服务。\n解决这个问题可以对Message的消息格式进行一下改进，即让这个Message中的每个字段都编码成TLV格式的，然后一个字段一个字段地来读取，检测长度、分配内存、解析，最后再构建出完整的Message，这样可以避免因为一次性分配全部内存带来的弊端。但是如果字段值确实比较大，仍然会存在类似的内存分配的问题。\n再一种解决思路是给待接收的Message设置一个定时器，例如每个Message的接收时间设置为10~15s。当一个Message数据部分到达，剩余数据没有在定时器设置的时间阈值之内到达，那么则当做超时事件处理，Message Reader可以放弃对这个Message的处理，或者直接关闭这个Message Reader对应的channel，服务就可以腾出资源去处理其他事务。这种方式一定程度上可以避免偶然到达的很多比较大的Message，但是仍然会出现服务无响应的情况。恶意的DoS攻击可能会导致服务器的内存被完全耗尽。\nTLV编码存在多种不同的变体，按照TLV的定义它应该首先指定类型，然后是长度，再然后是数据本身。也有的TLV编码不这样，比如先指定长度，然后再指定类型，最后是数据本身，这种也称为LTV编码，也就是Length、Type、Value，这仍然是LTV的一种变体。LTV比TLV更有优势，以为它将长度放在最前面，更利于程序感知到Message数据的长度。\nTLV编码能让程序尽快感知到Message的长度便于程序为其分配内存，HTTP 1.1之所以采用TLV编码格式也是有这样的考虑。HTTP 2.0里面采用LTV编码格式，完善了HTTP 1.1采用TLV编码所带来的一些问题。作者在设计实现自己的项目VStack.co project的时候也是出于同样的考虑而采用了LTV编码。\n11.7 Writing Partial Messages # 在非阻塞IO流水线中写数据也是一个不小的挑战，当我们调用channel.write(buffer)的时候，如果channel是以非阻塞方式工作的，这种情况下我们没办法保证buffer中的数据是否全部写入到channel了，write方法会返回写入的字节数量，通过这个字节数量来跟踪数据到底有没有写、有没有写完。\n为了对可能的写出部分Message数据的情况进行更好地管理，我们为每个channel都分配一个Message Writers实例，在每个Message Writer实例内部来跟踪当前正在写的Message已经写出了多少字节，从而判断Message的数据是否已经写完。\n某些情况下，可能有多个Message等待被写入到channel中，但是Message Writer不能一次性将所有的Message数据全部写入，因此这里等待被写入到channel中的Message必须“排队”，即我们需要维护一个Message队列，然后将Message Writer按照先进先出的顺序来将队列中的Message写入到channel中。\nMessage Writer的工作示意图如下所示。\nMessage Writer之前可能将部分Message的数据写入到了channel中，这种情况下Message Writer需要被定时或者时不时地多调用几次以将同一个Message的剩余数据写入到channel中。\n如果有很多的tcp连接，也就意味着很多的channel，也就意味着需要分配很多个Message Writer实例。假设我们要支持100w并发连接请求，意味着要分配100w个Message Writer，检查100w个Message Writer是否可以执行写操作（检查channel是否可写、是否有Message等待写入channel）是非常耗时的。首先可能有很多个Message Writer没有需要写入的Message；另一个，并不是所有的channel都处于数据可写的状态。我们不应该浪费过多时间在无用的操作上面，例如尝试向一个不太可能处于可写状态的channel写入数据。\n前面我们提到，可以通过selector来轮询多个channel是否事件就绪，这里当然也可以使用。但是呢，将所有的100w个channel注册到一个selector轮询也是代价比较高的，这样做不仅没必要，也不应该。假如大多数连接都处于空闲状态，现在有100w连接，假设我们将这个100w个channel全部注册到了selector然后使用select()来轮询事件，那么select返回的写操作就绪状态的channel将会非常多（前面已假设了大多数连接处于空闲），这个时候需要逐个检查各个channel上的Message Writer是否有Message等待被写入。\n 备注：\nselect返回很多事件就绪的channel绝对不是一个好事情，是否IO事件就绪的情景没有进行更细粒度地划分？\n 这里对IO情景做一个小的优化，我们肯定是要轮询channel是否写就绪，但是什么时候才需要判断channel的状态呢？只有Message Writer有Message要写入的时候才会判断。所以我们需要轮询Message Writer是否有Message要写入channel，如果有的话，我们再将对应的channel注册到selector，然后通过selector检查channel是否写就绪。一旦Message Writer将一个Messag的数据全部写入到了channel，那么当前一次写操作就完成了，这个时候应该将channel从selector中取消注册，等到有Message要写的时候再注册到selector，这样可以避免selector轮询太多没Message要写入的channel所引发的性能下降问题。\n总结一下，就是可以概括为两步：\n 当一个Message被写入到的Message Writer的Message队列的时候，将Message Writer对应的channel注册到selector（如果还没有注册的话）； 服务空闲的时候通过selector.select()来筛选出写就绪的channel，然后调用对应的Message Writer将当前需要写入的Message数据写入channel。如果Message数据被全部写入，则将channel从selector取消注册。  11.8 Putting it All Together # 一个非阻塞模式的服务可能需要多次检查接收到的数据是否构成了一个完整的请求Message，进而检查是否收到了多个完整的请求Message，只读取一次数据、检查一次数据是不够的。\n类似地，非阻塞模式的服务也需要多次检查同一个Message的全部数据是否全部写出了，同时也需要检查是否还有其他Message要写出。如果检测到有Message数据要写出，那么服务需要检查相关的channel是否写就绪。只在Messge入Message Writer的写队列时检查一次是不够的，因为Message可能会被部分写出，这种情况下需要多次写操作。\n最后稍微概括一下，一个非阻塞模式的服务大致需要3个流水线来协作运行：\n 数据读取流水线，对建立起的tcp连接上的请求数据进行读取； 事务处理流水线，对已经接收到的完整Message进行事务处理； 数据输出流水线，检查是否有Message数据要写出到建立起的连接；  这3个流水线在一个循环体中重复执行，可能有必要对其执行过程进行优化。例如，如果没有Messge等待写出可以选择跳过数据输出流水线的逻辑。或者，如果没有接收到新的完整的Message，也可以跳过事务处理流水线的部分逻辑。\n下图是该教程所阐述的一个非阻塞模式下服务的工作过程示意图。\n如果看了这里的教程之后依然觉得有些困惑或者感觉有点复杂的话，可以查看一下作者的一个nio server的实现，github java-nio-server。阅读这里的代码将有助于加深自己对java nio server的理解。\n这里的java-nio-server的示意图如下所示。\n这里的server实现中主要包括两个线程：\n 线程Accepter Thread用来从ServerSocketChannel中建立连接获取SocketChannel； 线程Processor Thread负责从SocketChannel中读取请求并处理，然后将处理结果输出到SocketChannel完成响应过程。Processor Thread线程是在一个循环中执行3条流水线（前面我们提到过有3条流水线），完成请求读取构建请求Message，并对请求Message进行处理得到响应Message，最后将响应Message返回给请求方；  12 NIO DatagramChannel # DatagramChannel是对Udp网络套接字的一种抽象。因为UDP是无连接协议，不能像读写SocketChannel一样来操作DatagramChannel，在SocketChannel中我们读取的是请求消息的面向数据块的数据，而在DatagramChannel中我们读取的是用户数据报。说的更准确一点是tcp、udp之间的差异。\n12.1 打开一个DatagramChannel # 下面是如何打开一个DatagramChannel的示例代码。\nDatagramChannel channel = DatagramChannel.open(); channel.socket().bind(new InetSocketAddress(9999));  示例中我们创建了一个监听本地9999/udp端口的DatagramChannel。\n12.2 接收数据 # 下面是如何从一个DatagramChannel接收数据的示例代码。\nByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); channel.receive(buf);  DatagramChannel.receive()方法将接收到的用户数据报写入指定的buffer。如果接收到的用户数据报比较大，并且已经超过了接收缓存buffer的大小，那么这里的receive方法会直接丢弃超出的部分，这样buffer中的数据实际上就是不完整的了。\n12.3 发送数据 # 下面是如何向一个DatagramChannel发送数据的示例代码。\nString newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); buf.flip(); int bytesSent = channel.send(buf, new InetSocketAddress(\u0026quot;jenkov.com\u0026quot;, 80));  示例代码中将向站点“jenkov.com”的80/udp端口发送一个字符串，由于目的主机上不存在监听这个端口的服务，所以什么也不会发生。示例代码在发送数据之后也不会收到任何关于用户数据报发送是否成功的通知，因为UDP本身就是不可靠数据传输协议。\n12.4 连接到特定地址 # 我们使用DatagramChannel的时候也可以将本地的socket连接到远程某个主机监听的udp socket上。因为UDP是无连接协议，所以这里的connect操作并不会创建一个类似于TCP中的连接，这里的connect操作只是将DatagramChannel的对端地址设置为待connect到的地址，之后这个DatagramChannel就只能接收这个对端peer发送来的用户数据报，而不能接收其它地址发送过来的用户数据报。\n 备注：\nLinux C编程时也会碰到类似的问题，“udp socket connect作用”甚至被设置成面试题目。\n关于unconnected、connected udp socket之间的差异性，我特地在网上搜索了一篇文章，这篇文章比较详细地介绍了二者之间的差异性以及各自不同的适用场景，例如dns客户端需要connected udp socket的场景（dns客户端只有一个域名解析主机地址），或者server端需要connect的场景（TFTP），或者二者都需要connect的场景。当然也存在不能使用connected udp socket的情景，这里就不展开说了。\n详细内容可以参考这里的总结，链接地址为unconnected/connected-udp-socket diff。\n 好了，下面看一下连接到特定主机地址、端口的示例代码。\nchannel.connect(new InetSocketAddress(\u0026quot;jenkov.com\u0026quot;, 80));  一旦udp socket connect成功之后就可以通过read、write方法来进行数据的读取和写入操作了，此时read、write操作就跟以前在其他channel三的read、write操作很相似了。DatagramChannel不需要保证数据的传输。下面是数据读写的示例代码。\nint bytesRead = channel.read(buf); int bytesWritten = channel.write(buf);  13 NIO Pipe # Java NIO Pipe是一种两个线程之间的单向数据传输的通道，它包括一个source channel和一个sink channel。读取数据时需要从source channel中读取，写入数据时需要向sink channel中写入。\n下图是一个Pipe的工作示意图。\n13.1 创建一个Pipe # 可以通过Pipe.open()方法来打开一个Pipe，也就是创建了一个Pipe。\nPipe pipe = Pipe.open();  13.2 向Pipe中写入数据 # 写数据到Pipe时，需要将数据写入到Pipe的sink channel。\n// 获取Pipe中的sink channel端 Pipe.SinkChannel sinkChannel = pipe.sink(); // 写数据到sink channel String newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); buf.flip(); while(buf.hasRemaining()) { sinkChannel.write(buf); }  13.3 从Pipe中读取数据 # 从Pipe读取数据时，需要从Pipe的source channel中进行读取。\n// 获取Pipe中的source channel端 Pipe.SourceChannel sourceChannel = pipe.source(); // 从source channel读取数据 ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buf);  14 NIO vs IO # 学习Java NIO和IO相关API时，先要搞明白什么时候应该选择Java NIO什么时候选择Java IO。这里讲描述一下Java NIO和IO的区别、适用场景，以及它们对软件设计、编码带来的影响。\n14.1 NIO和IO之间的主要区别 # 下表中对NIO和IO之间的主要区别进行了总结，本节会详细描述每一个区别。\n   IO NIO     面向流（stream） 面向数据块（buffer）   阻塞IO 非阻塞IO + selector    14.1 Stream Oriented vs Buffer Oriented # NIO和NIO第一个较大不同就是IO是面向流（stream）的，而NIO是面向数据块（buffer）的。什么意思呢？\n面向流的IO，从流中一次只可以读取一个字节，如何对读取到的字节进行处理是由程序决定，这些读取到的字节不会被cache到某个地方。这意味着不能在流中前后移动，如果需要在流中实现前后移动的目的的话，需要将流中的数据先cache起来。\n面向数据块的NIO与IO有些不同。数据首先被读取到数据块buffer中，然后我们对buffer中的数据进行处理。因为数据已经被cache到buffer中了，我们可以达到前后移动读位置的目的，此外也给我们数据处理时更好的灵活性。当然了，这种方式还是要求我们数据处理前检查是否一个完整的Message到达了或者被全部写出了。\n14.2 阻塞IO和非阻塞IO # Java IO的流操作是阻塞的，当一个线程执行read、write操作时，线程会被阻塞，知道read、write操作完成才会被唤醒，在唤醒之前线程无法执行其他任何处理。\nJava NIO的非阻塞模式使得一个线程执行io处理的时候不会阻塞当前线程到io完成，如果io操作没有完成也会立即返回，例如read操作时没有数据可读就返回读取了0个数据，线程可以执行其他处理然后过段事件之后再继续执行io任务。io相关的api不阻塞线程意味着线程可以在某个channel未就绪时去处理其他channel上的io任务，可以提高并发访问性能。\n14.3 Selectors # Java NIO中的选择器selector允许一个线程对多个channel上的io事件就绪状态进行监视，例如监视channel上有数据可读、channel上可以写入数据等等。\n14.3 选择NIO或IO对程序设计的影响 # 不管是选择NIO还是选择IO都会影响到程序设计，主要包括3点：\n 使用NIO或者IO的相关API； 数据出来； 处理数据的线程数量；  14.3.1 API Calls # NIO、IO二者对应的API是不同的，NIO多是结合buffer、channel、selector进行操作的，而IO多是基于stream进行操作的。\n14.3.2 数据处理 # 选择NIO和IO，对数据处理的方式也会造成较大影响。\n以读取数据为例，当选择IO API时我们一般是从InputStream中或者一个Reader中读取数据。假如有现在这样一个文件：\nName: Anna Age: 25 Email: anna@mailserver.com Phone: 1234567890  我们一般会像下面这样来处理上述文件内容：\nInputStream input = ... ; // get the InputStream from the client socket BufferedReader reader = new BufferedReader(new InputStreamReader(input)); String nameLine = reader.readLine(); String ageLine = reader.readLine(); String emailLine = reader.readLine(); String phoneLine = reader.readLine();  通过看程序执行到了哪行代码我们就可以判断当前文件处理的进度。例如，当第一个reader.readLine()方法执行结束后，就意味着程序一定是完整地读取完了“Name: Anne”这行，并且这个调用会在完整读取这行数据之后才会返回，这就是我们可以根据程序执行的位置来推测文件处理进度的根本原因。对后面各行数据的处理方式也是一样的。处理逻辑参考下图。\n一个采用了NIO的程序，其数据处理方式存在一些不同。下面是一个简化版的示例。\nByteBuffer buffer = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buffer);  上面第二行代码是从inChannel中读取数据到buffer，但是当这个inChannel返回时你并不知道这个buffer中到底被写入了多少数据，这使得数据处理变得困难。\n设想一下，假如inChannel.read(buffer)返回时buffer中只被写入了半行的数据，例如只写入了“Name: An”，还有几个字符没有写入，那么这种情况下我们是否要处理这种不完整的数据呢？当然不处理了，我们需要等到至少这一行数据完整到达之后才应该对其进行处理，不然解析一个不完整的、无效的数据也没什么用处。\n那么我们如何知道buffer中恰好包括了完整的一行数据呢？无法得知。我们只能通过重复地检查来发现buffer中是否包括了至少一行完整的数据（可能是半行、一行、不到两行……）。这使得数据处理逻辑变得有些复杂。下面是一个简单的示例。\nByteBuffer buffer = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buffer); // 简化版，认为buffer满为数据处理可以开始的标识 while(! bufferFull(bytesRead) ) { bytesRead = inChannel.read(buffer); } // 处理数据 processData(buffer);  上述简化版示例代码中判断是否满的while(\u0026hellip;)执行逻辑示意图如下所示。\n14.3.3 总结 # NIO使得我们可以借助selector对很多的channel（网络连接或者文件）进行管理，使用的线程数量也少，不足之处在于增加了数据处理的难度，至少比标准IO模式下的数据处理要复杂多了，主要是麻烦在read partial message、write partial message、buffer resize这几个点上。\n如果需要同时处理成千上万的连接，这些连接上只是发送很少量的数据，例如一个聊天服务器，这种情境下使用NIO来实现应该能获得更高的性能，因为连接上收发的数据量都比较小，基于NIO来实现的话可以尽量减少r处理ead partial message、write partial message的代价。这种情况下可以采用一个线程管理多个连接的设计思路，这个线程通过selector监视并处理多个连接上的io事件。如下图所示。\n但是假如服务中有不少连接上的流量比较大，比如可能是在传输文件，这种情况下可能使用Java IO来实现会更好一点，因为如果采用NIO的话，这里的大流量连接上的数据处理就会变得更加复杂，因为服务要不停地处理read partial message、write partial message的情况。这种情况下采用一个线程负责建立入连接请求，然后将建立的连接丢给线程池处理的思路比较靠谱。如下图所示。\n15 NIO Path # Java NIO 2中增加了一种新的接口，java.nio.file.Path，通过它可以来定义一个绝对路径或者相对路径，这里的路径指的是文件在文件系统中的路径信息。\n这部分内容，本人认为并不是特别重要，所以在此不详细展开，只给出简短的示例代码，感兴趣的话可以执行google。\n创建一个Path示例。\nimport java.nio.file.Path; import java.nio.file.Paths; public class PathExample { public static void main(String[] args) { Path path = Paths.get(\u0026quot;/home/jakobjenkov/myfile.txt\u0026quot;); } }  创建一个绝对路径示例。\nPath path = Paths.get(\u0026quot;/home/jakobjenkov/myfile.txt\u0026quot;);  创建一个相对路径示例。\nPath projects = Paths.get(\u0026quot;d:\\\\data\u0026quot;, \u0026quot;projects\u0026quot;); Path file = Paths.get(\u0026quot;d:\\\\data\u0026quot;, \u0026quot;projects\\\\a-project\\\\myfile.txt\u0026quot;);  normalize一个Path，指的是从路径中移除“.”、“..”这样的符号。\nString originalPath = \u0026quot;d:\\\\data\\\\projects\\\\a-project\\\\..\\\\another-project\u0026quot;; Path path1 = Paths.get(originalPath); System.out.println(\u0026quot;path1 = \u0026quot; + path1); Path path2 = path1.normalize(); System.out.println(\u0026quot;path2 = \u0026quot; + path2);  16 NIO Files # Java NIO中引入了一个java.nio.file.Files类，它提供了很多的用于文件操作的方法，这里讲对某些常用方法进行介绍，读者朋友如果发现有些想要的功能或者方法这里没有提到，建议查阅一下JavaDoc确认是否支持。\n这里的Files类一般是配合java.nio.file.Path来使用的，Path前面因介绍过了，这里不再展开。\n16.1 检查文件是否存在 # 通过Files.exist(Path path, new LinkOption[]{\u0026hellip;})来检查指定的path是否存在，path可以是文件在文件系统中的绝对路径或者相对路径，因此可以起到检查文件是否存在的目的。示例代码如下。\nPath path = Paths.get(\u0026quot;data/logging.properties\u0026quot;); boolean pathExists = Files.exists(path, new LinkOption[]{ LinkOption.NOFOLLOW_LINKS});  16.2 创建目录 # 创建目录可以通过Files.createDirectory(Path path)来完成，示例代码如下。\nPath path = Paths.get(\u0026quot;data/subdir\u0026quot;); try { Path newDir = Files.createDirectory(path); } catch(FileAlreadyExistsException e){ // the directory already exists. } catch (IOException e) { //something else went wrong e.printStackTrace(); }  16.3 文件拷贝 # 文件拷贝可以通过Files.copy(Path sourcePath, Path destPath)来完成，示例代码如下。\nPath sourcePath = Paths.get(\u0026quot;data/logging.properties\u0026quot;); Path destinationPath = Paths.get(\u0026quot;data/logging-copy.properties\u0026quot;); try { Files.copy(sourcePath, destinationPath); } catch(FileAlreadyExistsException e) { //destination file already exists } catch (IOException e) { //something else went wrong e.printStackTrace(); }  16.4 覆盖文件 # 通过文件拷贝操作，其实也可以起到覆盖文件的作用，示例代码如下。\n// logging.properties和logging-copy.properties均为已经存在的文件 Path sourcePath = Paths.get(\u0026quot;data/logging.properties\u0026quot;); Path destinationPath = Paths.get(\u0026quot;data/logging-copy.properties\u0026quot;); try { Files.copy(sourcePath, destinationPath, StandardCopyOption.REPLACE_EXISTING); } catch(FileAlreadyExistsException e) { //destination file already exists } catch (IOException e) { //something else went wrong e.printStackTrace(); }  16.5 文件移动 # 文件移动通过Files.move(Path sourcePath, Path destPath)来实现，示例代码如下。\nPath sourcePath = Paths.get(\u0026quot;data/logging-copy.properties\u0026quot;); Path destinationPath = Paths.get(\u0026quot;data/subdir/logging-moved.properties\u0026quot;); try { Files.move(sourcePath, destinationPath, StandardCopyOption.REPLACE_EXISTING); } catch (IOException e) { //moving file failed. e.printStackTrace(); }  16.6 文件删除 # 文件删除可以通过Files.delete(Path path)来实现，示例代码如下。\nPath path = Paths.get(\u0026quot;data/subdir/logging-moved.properties\u0026quot;); try { Files.delete(path); } catch (IOException e) { //deleting file failed e.printStackTrace(); }  16.7 递归遍历目录 # 递归遍历目录可以通过Files.walkFileTree(Path dirPath, FileVisitor vistor)来实现，示例代码如下。\n// FileVistor声明了遍历时的几个关键函数 public interface FileVisitor { public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException; public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException; public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException; public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException; } // 调用walkFileTree时需要传入一个实现了上述接口方法的实例对象，但是有时候没有 // 必要全部自己实现一遍，其实SimpleFileVisitor中已经实现了上述的全部接口，但是 // 在某种情况下可能需要自己实现一个FileVisitor。 // 递归遍历目录 Files.walkFileTree(path, new FileVisitor\u0026lt;Path\u0026gt;() { @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException { System.out.println(\u0026quot;pre visit dir:\u0026quot; + dir); return FileVisitResult.CONTINUE; } @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { System.out.println(\u0026quot;visit file: \u0026quot; + file); return FileVisitResult.CONTINUE; } @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException { System.out.println(\u0026quot;visit file failed: \u0026quot; + file); return FileVisitResult.CONTINUE; } @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException { System.out.println(\u0026quot;post visit directory: \u0026quot; + dir); return FileVisitResult.CONTINUE; } });  上述代码不难看懂，这里对FileVisitResult中的枚举变量进行一下说明：\n CONTINUE，继续遍历； TERMINATE，停止遍历； SKIP_SIBLINGS，继续遍历，遍历的时候跳过当前文件的siblings（兄弟）； SKIP__SUBTREE，继续遍历，遍历的时候跳过当前文件的subtree（子树）；  16.8 文件搜索 # 结合Files.walkFileTree()和文件信息比较可以实现文件搜索，示例代码如下。\nPath rootPath = Paths.get(\u0026quot;data\u0026quot;); String fileToFind = File.separator + \u0026quot;README.txt\u0026quot;; try { Files.walkFileTree(rootPath, new SimpleFileVisitor\u0026lt;Path\u0026gt;() { @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { String fileString = file.toAbsolutePath().toString(); //System.out.println(\u0026quot;pathString = \u0026quot; + fileString); if(fileString.endsWith(fileToFind)){ System.out.println(\u0026quot;file found at path: \u0026quot; + file.toAbsolutePath()); return FileVisitResult.TERMINATE; } return FileVisitResult.CONTINUE; } }); } catch(IOException e){ e.printStackTrace(); }  16.9 递归删除目录下文件 # 结合walkFileTree()和delete可以实现递归删除目录下文件，示例代码如下。\nPath rootPath = Paths.get(\u0026quot;data/to-delete\u0026quot;); try { Files.walkFileTree(rootPath, new SimpleFileVisitor\u0026lt;Path\u0026gt;() { @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { System.out.println(\u0026quot;delete file: \u0026quot; + file.toString()); Files.delete(file); return FileVisitResult.CONTINUE; } @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException { Files.delete(dir); System.out.println(\u0026quot;delete dir: \u0026quot; + dir.toString()); return FileVisitResult.CONTINUE; } }); } catch(IOException e){ e.printStackTrace(); }  16.10 其他方法 # java.nio.file.Files中还包括了很多的非常有用的方法，这里无法一一列举出来，感兴趣的读者可以查看JavaDoc进行了解。\n17 NIO AsynchronousFileChannel # Java7中增加了AsynchronousFileChannel，使得我们可以异步地读写文件。\n17.1 创建一个AsynchronousFileChannel # 创建异步filechannel的示例代码如下。\nPath path = Paths.get(\u0026quot;data/test.xml\u0026quot;); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ);  17.2 通过Future对象来异步读取数据 # 示例代码如下所示。\n// 创建一个异步filechannel AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(1024); long position = 0; // 首先通过异步filechannel获取一个Future对象备用 Future\u0026lt;Integer\u0026gt; operation = fileChannel.read(buffer, position); // 等数据读取完成(阻塞在这里的调用点，但是LWP进程不会阻塞) while(!operation.isDone()); buffer.flip(); byte[] data = new byte[buffer.limit()]; buffer.get(data); System.out.println(new String(data)); buffer.clear();  17.3 异步数据读完成后执行CompletionHandler # 示例代码如下所示。\nfileChannel.read(buffer, position, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { // 数据读取完成后会执行这个回调函数 @Override public void completed(Integer result, ByteBuffer attachment) { System.out.println(\u0026quot;result = \u0026quot; + result); attachment.flip(); byte[] data = new byte[attachment.limit()]; attachment.get(data); System.out.println(new String(data)); attachment.clear(); } @Override public void failed(Throwable exc, ByteBuffer attachment) { } });  17.4 通过Future对象来异步写入数据 # 示例代码如下所示。\nPath path = Paths.get(\u0026quot;data/test-write.txt\u0026quot;); // 创建异步filechannel AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.WRITE); ByteBuffer buffer = ByteBuffer.allocate(1024); long position = 0; buffer.put(\u0026quot;test data\u0026quot;.getBytes()); buffer.flip(); // 获得Future对象备用 Future\u0026lt;Integer\u0026gt; operation = fileChannel.write(buffer, position); buffer.clear(); // 阻塞在调用点而非阻塞线程（或LWP进程） while(!operation.isDone()); System.out.println(\u0026quot;Write done\u0026quot;);  17.5 异步写入数据完成后执行CompletionHandler # 示例代码如下所示。\nPath path = Paths.get(\u0026quot;data/test-write.txt\u0026quot;); if(!Files.exists(path)){ Files.createFile(path); } // 创建一个异步filechannel AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.WRITE); ByteBuffer buffer = ByteBuffer.allocate(1024); long position = 0; buffer.put(\u0026quot;test data\u0026quot;.getBytes()); buffer.flip(); fileChannel.write(buffer, position, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { // 数据写入完成后执行这里的回调函数 @Override public void completed(Integer result, ByteBuffer attachment) { System.out.println(\u0026quot;bytes written: \u0026quot; + result); } // 数据写入失败后执行这里的回调函数 @Override public void failed(Throwable exc, ByteBuffer attachment) { System.out.println(\u0026quot;Write failed\u0026quot;); exc.printStackTrace(); } });  参考内容 # 1 http://tutorials.jenkov.com/java-nio/index.html\n2 https://github.com/jjenkov/java-nio-server\n"}),a.add({id:448,href:"/tags/nio/",title:"nio",description:"",content:""}),a.add({id:449,href:"/tags/ant/",title:"ant",description:"",content:""}),a.add({id:450,href:"/blog/2017-04-01-%E5%AD%A6%E4%B9%A0apache-ant/",title:"学习Apache Ant",description:"Apache Ant是Java工程中比较常用的一个依赖管理、构建工具，本文总结了Ant相关的一些基础知识。",content:"Apache Ant是由Apache开发的基于Java的构建工具，本文对tutorialspoint上面的Apache Ant教程进行简要总结。\n1 为什么需要这样一个构建工具？ # Ant是Another Neat Tool的缩写形式，为什么需要这样一个工具呢？跟它的名字一样，就是希望我们开发人员的工作能够更加neat！\n开发人员有些琐碎的、重复性的工作，包括：编译代码、打包可执行程序、部署程序到测试服务器、测试改变、拷贝代码到不同的地方。Ant可以帮助我们自动化上面列举的这几个步骤，简化我们的工作。\nAnt是tomcat的作者开发出来的，最初适用于构建tomcat的，并且作为tomcat的一部分，之所以开发它是为了弥补当初Apache Make工具（没有在apache项目列表中搜索到该项目）的不足之处，2000年的时候Ant从tomcat项目中独立出来作为一个独立的项目开发。\n至于Apache Ant的优势具体在哪，这个我们最后在给出来，目的是让大家结合自身工作经历，根据Apache Ant的功能自己主动去发现它的优势。\n2 Ant build.xml # Ant的构建脚本默认是build.xml，也可以用其他的文件名。build.xml里面通常包括tag ，这里name指定了工程的名字，default是默认名字，basedir指定了工程的根目录。另外还包括多个tag ，其中name指定了目标动作的名字，例如compile、package、clean等等，它们之间存在某种依赖关系，可以通过depends指定。例如package依赖clean、compile，就可以指定depends=\u0026ldquo;clean,package\u0026rdquo;，注意依赖先后顺序，不要写成depends=\u0026ldquo;package,clean\u0026rdquo;。\n示例1：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;Hello World Project\u0026quot; default=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;target name=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;echo\u0026gt;Hello World - Welcome to Apache Ant!\u0026lt;/echo\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  示例2：\n\u0026lt;target name=\u0026quot;deploy\u0026quot; depends=\u0026quot;package\u0026quot;\u0026gt; .... \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;package\u0026quot; depends=\u0026quot;clean,compile\u0026quot;\u0026gt; .... \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;clean\u0026quot; \u0026gt; .... \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;compile\u0026quot; \u0026gt; .... \u0026lt;/target\u0026gt;  build.xml里面可以使用ant预先定义的一些变量，例如：\n   property desc     ant.file The full location of the build file.   ant.version The version of the Apache Ant installation.   basedir The basedir of the build, as specified in the basedir attribute of the project element.   ant.java.version The version of the JDK that is used by Ant.   ant.project.name The name of the project, as specified in the name atrribute of the project element.   ant.project.default-target The default target of the current project.   ant.project.invoked-targets Comma separated list of the targets that were invoked in the current project.   ant.core.lib The full location of the Ant jar file.   ant.home The home directory of Ant installation.   ant.library.dir The home directory for Ant library files - typically ANT_HOME/lib folder.    示例1：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;Hello World Project\u0026quot; default=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;sitename\u0026quot; value=\u0026quot;www.tutorialspoint.com\u0026quot;/\u0026gt; \u0026lt;target name=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;echo\u0026gt;Apache Ant version is ${ant.version} - You are at ${sitename} \u0026lt;/echo\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  这样ant构建过程中会输出当前ant使用的版本以及站点名称，其中ant.version是ant的预定义变量，sitename是我们自己定义的变量。\n3 Ant build.properties # 像上线这样在build.xml里面创建自定义变量的方式，如果自定义变量少的话还可以，当面对一个大型的工程有很多自定义变量的时候，直接在build.xml里面定义变量就困难了，那怎么办呢？ 我们可以在一个单独的属性配置文件中对需要用到的自定义属性进行配置，然后在build.xml里面进行引用。这个默认的属性配置文件是build.properties。\n示例1：\nbuild.xml：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;Hello World Project\u0026quot; default=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;property file=\u0026quot;build.properties\u0026quot;/\u0026gt; \u0026lt;target name=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;echo\u0026gt;Apache Ant version is ${ant.version} - You are at ${sitename} \u0026lt;/echo\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  这个文件里面引用了一个自定义变量，我们将其定义在build.properties里面。\nbuild.properties：\n# The Site Name sitename=www.tutorialspoint.com buildversion=3.3.2  4 Ant Data Types # 不要将这里的数据类型跟编程语言中的数据类型混为一谈，这里说要描述的Ant提供的数据类型代表了Ant提供的一种service。\nfileset类型代表了一系列文件集合，通过它可以包括某些文件或者排除某些文件，包括、排除文件是通过模式匹配的方式来实现。\n示例1：\n\u0026lt;fileset dir=\u0026quot;${src}\u0026quot; casesensitive=\u0026quot;yes\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.java\u0026quot;/\u0026gt; \u0026lt;exclude name=\u0026quot;**/*Stub*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt;  这个例子中创建了一个fileset，它指向了源代码目录${src}，这里匹配文件模式的时候大小写敏感，并且包括src目录下以及任意子目录下的java文件，并排除Stub文件。\npatternset类型代表了一些列的pattern集合，通过它可以指定一些include用的pattern或者exclude用的pattern。这里我们队实例1进行一下改造，即示例2。\n示例2：\n\u0026lt;patternset id=\u0026quot;java.files.without.stubs\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;src/**/*.java\u0026quot;/\u0026gt; \u0026lt;exclude name=\u0026quot;src/**/*Stub*\u0026quot;/\u0026gt; \u0026lt;/patternset\u0026gt; \u0026lt;fileset dir=\u0026quot;${src}\u0026quot; casesensitive=\u0026quot;yes\u0026quot;\u0026gt; \u0026lt;patternset refid=\u0026quot;java.files.without.stubs\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt;  通过patternset来指定pattern模式的方式有个好处，一个是更加直观，还有一个就是便于被复用。另外这里的pattern中可以使用的匹配符号包括：\n   character desc     ? 可以匹配任意当个字符   * 可以匹配0个或者多个字符   ** 可以匹配当前目录或者任意多级子目录（递归地哦）    filelist类型与fileset有点类似但是又有不同。相同点是都是用于指定一个文件集合，不同点是fileset是通过pattern匹配的方式来完成包括、排除，而filelist是必须通过指定具体的文件名字，不能使用pattern进行匹配。\n示例3：\n\u0026lt;filelist id=\u0026quot;config.files\u0026quot; dir=\u0026quot;${webapp.src.folder}\u0026quot;\u0026gt; \u0026lt;file name=\u0026quot;applicationConfig.xml\u0026quot;/\u0026gt; \u0026lt;file name=\u0026quot;faces-config.xml\u0026quot;/\u0026gt; \u0026lt;file name=\u0026quot;web.xml\u0026quot;/\u0026gt; \u0026lt;file name=\u0026quot;portlet.xml\u0026quot;/\u0026gt; \u0026lt;/filelist\u0026gt;  上面这里定义了一个文件列表，包括了所指定的这些文件。\nfilterset类型往往用于筛选满足指定条件的文件，例如在copy任务中与fileset相结合拷贝指定版本的文件，看下这里的示例吧。\n示例1：\n\u0026lt;copy todir=\u0026quot;${output.dir}\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${releasenotes.dir}\u0026quot; includes=\u0026quot;**/*.txt\u0026quot;/\u0026gt; \u0026lt;filterset\u0026gt; \u0026lt;filter token=\u0026quot;VERSION\u0026quot; value=\u0026quot;${current.version}\u0026quot;/\u0026gt; \u0026lt;/filterset\u0026gt; \u0026lt;/copy\u0026gt;  上面这个动作是要fileset中指定的发行笔记文件拷贝到输出目录${output.dir}中，但是呢，这里拷贝的时候只拷贝特定版本的发行笔记，只有与filter中匹配的版本才会被拷贝。\npath数据类型用于指定classpath，它有个好处就是可以对多个可能的classpath entries通过具体的系统指定的分隔符进行连接，例如在windows下面通过分号进行连接，但是在linux下面通过冒号进行连接。\n示例1：\n\u0026lt;path id=\u0026quot;build.classpath.jar\u0026quot;\u0026gt; \u0026lt;pathelement path=\u0026quot;${env.J2EE_HOME}/${j2ee.jar}\u0026quot;/\u0026gt; \u0026lt;fileset dir=\u0026quot;lib\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/path\u0026gt;  上面这个示例就是将${J2EE_HOME}/${j2ee.jar}中的所有*.jar都看做是一个classpath entry，然后用系统对应的classpath分隔符进行连接，最终构成一个完整的classpath。\n5 Ant的一个简单构建示例 # 下面看一个Ant构建的完整示例，首先要创建一个工程，工程结构如下：\n+---db // 数据库脚本目录 +---src // 源代码目录 . +---faxapp . +---dao . +---entity . +---util . +---web +---war // 资源目录 +---images // - 图片 +---js // - js +---META-INF // - 其他 +---styles // - css文件 +---WEB-INF +---classes // - 编译输出classes文件 +---jsp // - 编写的jsp文件 +---lib // - 应用的jar包  对应的build.xml文件如下：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;fax\u0026quot; basedir=\u0026quot;.\u0026quot; default=\u0026quot;build\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;src.dir\u0026quot; value=\u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;web.dir\u0026quot; value=\u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;build.dir\u0026quot; value=\u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;name\u0026quot; value=\u0026quot;fax\u0026quot;/\u0026gt; \u0026lt;path id=\u0026quot;master-classpath\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}/WEB-INF/lib\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;pathelement path=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;target name=\u0026quot;build\u0026quot; description=\u0026quot;Compile source tree java files\u0026quot;\u0026gt; \u0026lt;mkdir dir=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;javac destdir=\u0026quot;${build.dir}\u0026quot; source=\u0026quot;1.5\u0026quot; target=\u0026quot;1.5\u0026quot;\u0026gt; \u0026lt;src path=\u0026quot;${src.dir}\u0026quot;/\u0026gt; \u0026lt;classpath refid=\u0026quot;master-classpath\u0026quot;/\u0026gt; \u0026lt;/javac\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;clean\u0026quot; description=\u0026quot;Clean output directories\u0026quot;\u0026gt; \u0026lt;delete\u0026gt; \u0026lt;fileset dir=\u0026quot;${build.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.class\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/delete\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  对于上面build.xml中用到的自定义属性，还需要创建对应的属性文件build.properties：\n\u0026lt;property name=\u0026quot;src.dir\u0026quot; value=\u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;web.dir\u0026quot; value=\u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;build.dir\u0026quot; value=\u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt;  6 Ant构建文档 # Ant可以为工程生成文档，这个是利用javadoc命令行工具来对某些包某些类某些访问类型修饰符对应的成员或者方法根据源代码中添加的javadoc注释来生成项目API文档。下面是一个示例。\n示例1：\n\u0026lt;target name = \u0026quot;generate-javadoc\u0026quot;\u0026gt; \u0026lt;javadoc packagenames=\u0026quot;faxapp.*\u0026quot; sourcepath=\u0026quot;${src.dir}\u0026quot; destdir = \u0026quot;doc\u0026quot; version = \u0026quot;true\u0026quot; windowtitle = \u0026quot;Fax Application\u0026quot;\u0026gt; \u0026lt;doctitle\u0026gt;\u0026lt;![CDATA[= Fax Application =]]\u0026gt;\u0026lt;/doctitle\u0026gt; \u0026lt;bottom\u0026gt; \u0026lt;![CDATA[Copyright © 2011. All Rights Reserved.]]\u0026gt; \u0026lt;/bottom\u0026gt; \u0026lt;group title = \u0026quot;util packages\u0026quot; packages = \u0026quot;faxapp.util.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;web packages\u0026quot; packages = \u0026quot;faxapp.web.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;data packages\u0026quot; packages = \u0026quot;faxapp.entity.*:faxapp.dao.*\u0026quot;/\u0026gt; \u0026lt;/javadoc\u0026gt; \u0026lt;echo message = \u0026quot;java doc has been generated!\u0026quot; /\u0026gt; \u0026lt;/target\u0026gt;  7 Ant构建jar包 # Ant将classes达成jar包示例，例如将faxapp/util下面的除Test.class之外的所有文件达成一个jar包${web.dir}/lib/util.jar。\n示例1：\n\u0026lt;jar destfile = \u0026quot;${web.dir}/lib/util.jar\u0026quot; basedir = \u0026quot;${build.dir}/classes\u0026quot; includes = \u0026quot;faxapp/util/**\u0026quot; excludes = \u0026quot;**/Test.class\u0026quot; /\u0026gt;  如果是希望将util.jar打包成一个可以执行的jar文件的话，需要为其指定main-class，这里可以通过添加manifest来完成。\n示例2：\n\u0026lt;jar destfile = \u0026quot;${web.dir}/lib/util.jar\u0026quot; basedir = \u0026quot;${build.dir}/classes\u0026quot; includes = \u0026quot;faxapp/util/**\u0026quot; excludes = \u0026quot;**/Test.class\u0026quot;\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;attribute name = \u0026quot;Main-Class\u0026quot; value = \u0026quot;com.tutorialspoint.util.FaxUtil\u0026quot;/\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/jar\u0026gt;  最后呢，将上述jar翻到一个target里面：\n\u0026lt;target name=\u0026quot;build-jar\u0026quot;\u0026gt; \u0026lt;jar destfile=\u0026quot;${web.dir}/lib/util.jar\u0026quot; basedir=\u0026quot;${build.dir}/classes\u0026quot; includes=\u0026quot;faxapp/util/**\u0026quot; excludes=\u0026quot;**/Test.class\u0026quot;\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;attribute name=\u0026quot;Main-Class\u0026quot; value=\u0026quot;com.tutorialspoint.util.FaxUtil\u0026quot;/\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/jar\u0026gt; \u0026lt;/target\u0026gt;  8 Ant构建war包 # 除了上面提到的构建jar包之外，Ant也可以用来构建war包，我们这里只给出一个详细的war包构建配置文件，不再详细展开。\n示例1：\n\u0026lt;target name=\u0026quot;build-war\u0026quot;\u0026gt; \u0026lt;war destfile=\u0026quot;fax.war\u0026quot; webxml=\u0026quot;${web.dir}/web.xml\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}/WebContent\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;lib dir=\u0026quot;thirdpartyjars\u0026quot;\u0026gt; \u0026lt;exclude name=\u0026quot;portlet.jar\u0026quot;/\u0026gt; \u0026lt;/lib\u0026gt; \u0026lt;classes dir=\u0026quot;${build.dir}/web\u0026quot;/\u0026gt; \u0026lt;/war\u0026gt; \u0026lt;/target\u0026gt;  9 Ant的一个完整build.xml配置 # 这里给出了一个综合配置示例，对前面说描述的内容进行了一下综合。\n\u0026lt;?xml version = \u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name = \u0026quot;fax\u0026quot; basedir = \u0026quot;.\u0026quot; default = \u0026quot;usage\u0026quot;\u0026gt; \u0026lt;property file = \u0026quot;build.properties\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;src.dir\u0026quot; value = \u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;web.dir\u0026quot; value = \u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;javadoc.dir\u0026quot; value = \u0026quot;doc\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;build.dir\u0026quot; value = \u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;name\u0026quot; value = \u0026quot;fax\u0026quot;/\u0026gt; \u0026lt;path id = \u0026quot;master-classpath\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;${web.dir}/WEB-INF/lib\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;pathelement path = \u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;target name = \u0026quot;javadoc\u0026quot;\u0026gt; \u0026lt;javadoc packagenames = \u0026quot;faxapp.*\u0026quot; sourcepath = \u0026quot;${src.dir}\u0026quot; destdir = \u0026quot;doc\u0026quot; version = \u0026quot;true\u0026quot; windowtitle = \u0026quot;Fax Application\u0026quot;\u0026gt; \u0026lt;doctitle\u0026gt;\u0026lt;![CDATA[\u0026lt;h1\u0026gt; = Fax Application = \u0026lt;/h1\u0026gt;]]\u0026gt; \u0026lt;/doctitle\u0026gt; \u0026lt;bottom\u0026gt;\u0026lt;![CDATA[Copyright © 2011. All Rights Reserved.]]\u0026gt; \u0026lt;/bottom\u0026gt; \u0026lt;group title = \u0026quot;util packages\u0026quot; packages = \u0026quot;faxapp.util.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;web packages\u0026quot; packages = \u0026quot;faxapp.web.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;data packages\u0026quot; packages = \u0026quot;faxapp.entity.*:faxapp.dao.*\u0026quot;/\u0026gt; \u0026lt;/javadoc\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;usage\u0026quot;\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;${name} build file\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;-----------------------------------\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;Available targets are:\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;deploy --\u0026gt; Deploy application as directory\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;deploywar --\u0026gt; Deploy application as a WAR file\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;build\u0026quot; description = \u0026quot;Compile main source tree java files\u0026quot;\u0026gt; \u0026lt;mkdir dir = \u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;javac destdir = \u0026quot;${build.dir}\u0026quot; source = \u0026quot;1.5\u0026quot; target = \u0026quot;1.5\u0026quot; debug = \u0026quot;true\u0026quot; deprecation = \u0026quot;false\u0026quot; optimize = \u0026quot;false\u0026quot; failonerror = \u0026quot;true\u0026quot;\u0026gt; \u0026lt;src path = \u0026quot;${src.dir}\u0026quot;/\u0026gt; \u0026lt;classpath refid = \u0026quot;master-classpath\u0026quot;/\u0026gt; \u0026lt;/javac\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;deploy\u0026quot; depends = \u0026quot;build\u0026quot; description = \u0026quot;Deploy application\u0026quot;\u0026gt; \u0026lt;copy todir = \u0026quot;${deploy.path}/${name}\u0026quot; preservelastmodified = \u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;deploywar\u0026quot; depends = \u0026quot;build\u0026quot; description = \u0026quot;Deploy application as a WAR file\u0026quot;\u0026gt; \u0026lt;war destfile = \u0026quot;${name}.war\u0026quot; webxml = \u0026quot;${web.dir}/WEB-INF/web.xml\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/war\u0026gt; \u0026lt;copy todir = \u0026quot;${deploy.path}\u0026quot; preservelastmodified = \u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;.\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;*.war\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;clean\u0026quot; description = \u0026quot;Clean output directories\u0026quot;\u0026gt; \u0026lt;delete\u0026gt; \u0026lt;fileset dir = \u0026quot;${build.dir}\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;**/*.class\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/delete\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  10 Ant的一个更完整配置示例 # 这里针对war包与tomcat的结合给出一个配置示例。\nbuild.properties：\n# Ant properties for building the springapp appserver.home=c:\\\\install\\\\apache-tomcat-7.0.19 # for Tomcat 5 use $appserver.home}/server/lib # for Tomcat 6 use $appserver.home}/lib appserver.lib=${appserver.home}/lib deploy.path=${appserver.home}/webapps tomcat.manager.url=http://www.tutorialspoint.com:8080/manager tomcat.manager.username=tutorialspoint tomcat.manager.password=secret  build.xml:\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;fax\u0026quot; basedir=\u0026quot;.\u0026quot; default=\u0026quot;usage\u0026quot;\u0026gt; \u0026lt;property file=\u0026quot;build.properties\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;src.dir\u0026quot; value=\u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;web.dir\u0026quot; value=\u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;javadoc.dir\u0026quot; value=\u0026quot;doc\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;build.dir\u0026quot; value=\u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;name\u0026quot; value=\u0026quot;fax\u0026quot;/\u0026gt; \u0026lt;path id=\u0026quot;master-classpath\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}/WEB-INF/lib\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;pathelement path=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;target name=\u0026quot;javadoc\u0026quot;\u0026gt; \u0026lt;javadoc packagenames=\u0026quot;faxapp.*\u0026quot; sourcepath=\u0026quot;${src.dir}\u0026quot; destdir=\u0026quot;doc\u0026quot; version=\u0026quot;true\u0026quot; windowtitle=\u0026quot;Fax Application\u0026quot;\u0026gt; \u0026lt;doctitle\u0026gt;\u0026lt;![CDATA[\u0026lt;h1\u0026gt;= Fax Application = \u0026lt;/h1\u0026gt;]]\u0026gt;\u0026lt;/doctitle\u0026gt; \u0026lt;bottom\u0026gt;\u0026lt;![CDATA[Copyright © 2011. All Rights Reserved.]]\u0026gt;\u0026lt;/bottom\u0026gt; \u0026lt;group title=\u0026quot;util packages\u0026quot; packages=\u0026quot;faxapp.util.*\u0026quot;/\u0026gt; \u0026lt;group title=\u0026quot;web packages\u0026quot; packages=\u0026quot;faxapp.web.*\u0026quot;/\u0026gt; \u0026lt;group title=\u0026quot;data packages\u0026quot; packages=\u0026quot;faxapp.entity.*:faxapp.dao.*\u0026quot;/\u0026gt; \u0026lt;/javadoc\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;usage\u0026quot;\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;${name} build file\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;-----------------------------------\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;Available targets are:\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;deploy --\u0026gt; Deploy application as directory\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;deploywar --\u0026gt; Deploy application as a WAR file\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;build\u0026quot; description=\u0026quot;Compile main source tree java files\u0026quot;\u0026gt; \u0026lt;mkdir dir=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;javac destdir=\u0026quot;${build.dir}\u0026quot; source=\u0026quot;1.5\u0026quot; target=\u0026quot;1.5\u0026quot; debug=\u0026quot;true\u0026quot; deprecation=\u0026quot;false\u0026quot; optimize=\u0026quot;false\u0026quot; failonerror=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;src path=\u0026quot;${src.dir}\u0026quot;/\u0026gt; \u0026lt;classpath refid=\u0026quot;master-classpath\u0026quot;/\u0026gt; \u0026lt;/javac\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;deploy\u0026quot; depends=\u0026quot;build\u0026quot; description=\u0026quot;Deploy application\u0026quot;\u0026gt; \u0026lt;copy todir=\u0026quot;${deploy.path}/${name}\u0026quot; preservelastmodified=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;deploywar\u0026quot; depends=\u0026quot;build\u0026quot; description=\u0026quot;Deploy application as a WAR file\u0026quot;\u0026gt; \u0026lt;war destfile=\u0026quot;${name}.war\u0026quot; webxml=\u0026quot;${web.dir}/WEB-INF/web.xml\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/war\u0026gt; \u0026lt;copy todir=\u0026quot;${deploy.path}\u0026quot; preservelastmodified=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;.\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;*.war\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;clean\u0026quot; description=\u0026quot;Clean output directories\u0026quot;\u0026gt; \u0026lt;delete\u0026gt; \u0026lt;fileset dir=\u0026quot;${build.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.class\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/delete\u0026gt; \u0026lt;/target\u0026gt;  war包相关的定义已经全部给出了，这里还需要给出tomcat相关的部分定义，还是在build.xml里面。\n\u0026lt;!-- ============================================================ --\u0026gt; \u0026lt;!-- Tomcat tasks --\u0026gt; \u0026lt;!-- ============================================================ --\u0026gt; \u0026lt;path id=\u0026quot;catalina-ant-classpath\u0026quot;\u0026gt; \u0026lt;!-- We need the Catalina jars for Tomcat --\u0026gt; \u0026lt;!-- * for other app servers - check the docs --\u0026gt; \u0026lt;fileset dir=\u0026quot;${appserver.lib}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;catalina-ant.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;taskdef name=\u0026quot;install\u0026quot; classname=\u0026quot;org.apache.catalina.ant.InstallTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;reload\u0026quot; classname=\u0026quot;org.apache.catalina.ant.ReloadTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;list\u0026quot; classname=\u0026quot;org.apache.catalina.ant.ListTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;start\u0026quot; classname=\u0026quot;org.apache.catalina.ant.StartTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;stop\u0026quot; classname=\u0026quot;org.apache.catalina.ant.StopTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;target name=\u0026quot;reload\u0026quot; description=\u0026quot;Reload application in Tomcat\u0026quot;\u0026gt; \u0026lt;reload url=\u0026quot;${tomcat.manager.url}\u0026quot;username=\u0026quot;${tomcat.manager.username}\u0026quot; password=\u0026quot;${tomcat.manager.password}\u0026quot; path=\u0026quot;/${name}\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  下面对tomcat相关的几个targe他进行一下描述：\n   task desc     InstallTask Installs a web application. Class Name: org.apache.catalina.ant.InstallTask   ReloadTask Reload a web application. Class Name: org.apache.catalina.ant.ReloadTask   ListTask Lists all web applications. Class Name: org.apache.catalina.ant.ListTask   StartTask Starts a web application. Class Name: org.apache.catalina.ant.StartTask   StopTask Stops a web application. Class Name: org.apache.catalina.ant.StopTask   ReloadTask Reloads a web application without stopping. Class Name: org.apache.catalina.ant.ReloadTask    11 Ant执行程序 # 下面给出一个Ant传递参数并执行程序的配置示例。\njava类：\npublic class NotifyAdministrator { public static void main(String[] args) { String email = args[0]; notifyAdministratorviaEmail(email); System.out.println(\u0026quot;Administrator \u0026quot;+email+\u0026quot; has been notified\u0026quot;); } public static void notifyAdministratorviaEmail(String email { //...... } }  build.xml配置文件如下：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;sample\u0026quot; basedir=\u0026quot;.\u0026quot; default=\u0026quot;notify\u0026quot;\u0026gt; \u0026lt;target name=\u0026quot;notify\u0026quot;\u0026gt; \u0026lt;java fork=\u0026quot;true\u0026quot; failonerror=\u0026quot;yes\u0026quot; classname=\u0026quot;NotifyAdministrator\u0026quot;\u0026gt; \u0026lt;arg line=\u0026quot;admin@test.com\u0026quot;/\u0026gt; \u0026lt;/java\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  12 扩展Ant # Ant中有一些自定义的task，但是我们也可以自己定义task并在target中使用，下面是一个示例。\njava代码：\npackage com.tutorialspoint.ant; import org.apache.tools.ant.Task; import org.apache.tools.ant.Project; import org.apache.tools.ant.BuildException; public class MyTask extends Task { String message; public void execute() throws BuildException { log(\u0026quot;Message: \u0026quot; + message, Project.MSG_INFO); } public void setMessage(String message) { this.message= message; } }  build.xml：\n\u0026lt;target name=\u0026quot;custom\u0026quot;\u0026gt; \u0026lt;taskdef name=\u0026quot;custom\u0026quot; classname=\u0026quot;com.tutorialspoint.ant.MyTask\u0026quot; /\u0026gt; \u0026lt;custom message=\u0026quot;Hello World!\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt;  13 在IDE中使用Ant # 在IDE中使用Ant也是一种不错的选择，目前的主流开发工具Eclipse和Idea都继承了Ant构建插件，开发人员可以根据自己的情况选择使用。\n参考内容：\n[1] TutorialsPoint: Learn Apache Ant\n"}),a.add({id:451,href:"/tags/context/",title:"context",description:"",content:""}),a.add({id:452,href:"/tags/jmp_buf/",title:"jmp_buf",description:"",content:""}),a.add({id:453,href:"/blog/2017-03-27-jmp_bufsetjmplongjmp/",title:"jmp_buf \u0026 setjmp \u0026 longjmp",description:"最近在看spp \u0026 libco源码，他们实现协程上下文切换的过程中，都或多或少借鉴了jmp_buf的设计，用以保存协程执行时的现场。协程切换的时候保存当前协程的现场，然后恢复待调度协程的现场。理解是很容易理解，但是总感觉还是有点浅尝辄止了，于是就抽点时间看了下jmp_buf、setjmp、longjmp相关的代码，大体理了下思路。",content:"最近在看spp \u0026amp; libco源码，他们实现协程上下文切换的过程中，都或多或少借鉴了jmp_buf的设计，用以保存协程执行时的现场。协程切换的时候保存当前协程的现场，然后恢复待调度协程的现场。理解是很容易理解，但是总感觉还是有点浅尝辄止了，于是就抽点时间看了下jmp_buf、setjmp、longjmp相关的代码，大体理了下思路。\n学习整理了一下关于jmp_buf \u0026amp; setjmp \u0026amp; longjmp的内容。\nlinux 4.0内核中jmp_buf这个结构体用于记录硬件上下文信息，可以用于函数内、函数外跳转，goto只能实现函数内跳转。先来看下这个结构体的定义吧，i386架构的处理器与x86_64架构的处理器，对应的jmp_buf结构体定义稍微有些不同，这个很容易理解，寄存器位宽、数量等都有些不同。\ni386架构：\n// 处理器架构：i386 // - Linux/arch/x86/um/shared/sysdep/archsetjmp_32.h struct __jmp_buf { unsigned int __ebx; // 通用数据寄存器之一 unsigned int __esp; // 栈指针寄存器(进程栈空间由高地址向低地址方向增长) unsigned int __ebp; // 基址指针寄存器(记录了当前栈帧的起始地址(进入一个函数后首先执行的便是push %ebp; mov %esp, %ebp)) unsigned int __esi; // 源变址寄存器 unsigned int __edi; // 目的编制寄存器 unsigned int __eip; // 指令指针寄存器(程序计数器PC=CS:IP,二者结合起来确定下一条待执行的机器指令地址) }; typedef struct __jmp_buf jmp_buf[1];  x86_64架构：\n// 处理器架构：x86_64 // - Linux/arch/x86/um/shared/sysdep/archsetjmp_64.h struct __jmp_buf { unsigned long __rbx; // 通用数据寄存器之一 unsigned long __rsp; // 栈指针寄存器 unsigned long __rbp; // 基址指针寄存器 unsigned long __r12; unsigned long __r13; unsigned long __r14; unsigned long __r15; unsigned long __rip; }; typedef struct __jmp_buf jmp_buf[1];  但是呢，glibc里面重新定义了这个类型，这里面还对信号掩码进行了考虑。\nstruct __jmp_buf_tag { /* NOTE: The machine-dependent definitions of `__sigsetjmp' assume that a `jmp_buf' begins with a `__jmp_buf' and that `__mask_was_saved' follows it. Do not move these members or add others before it. */ __jmp_buf __jmpbuf; /* Calling environment. */ int __mask_was_saved; /* Saved the signal mask? */ __sigset_t __saved_mask; /* Saved signal mask. */ }; typedef struct __jmp_buf_tag jmp_buf[1];  这个__jmp_buf_tag主要就是用于记录下当前的进程的硬件上下文信息、信号掩码信息，保存操作是通过setjmp来完成的，而在执行过程中caller1-\u0026gt;\u0026hellip; -\u0026gt;caller${i}-\u0026gt; \u0026hellip; -\u0026gt;callerN中如果希望跳转到在caller${i}中的某个位置时(该位置已经通过__jmp_buf_tag进行了保存)，通过调用longjmp来将指定__jmp_buf_tag变体中保存的硬件上下文信息还原到处理器的各个寄存器中，并将进程信号掩码信息也进行还原，之后机器会回到caller${i}中调用setjmp的下一行代码处开始执行。 glibc在此基础上针对c和c++分别实现了setjmp和longjmp，c下只保存硬件上下文信息，c++中除此之外还保存信号掩码信息，注意是有区别的。\nsetjmp：\n// __BEGIN_NAMESPACE_STD是一个宏，表示namespace std { __BEGIN_NAMESPACE_STD // STD这个命名空间内是既保存硬件上下文信息，也保存信号掩码 typedef struct __jmp_buf_tag jmp_buf[1]; extern int _setjmp(struct __jmp_buf_tag __env[1]) __THROWNL; #define setjmp(env) _setjmp(env) __END_NAMESPACE_STD // __END_NAMESPACE_STD是一个宏，表示} // c下这个保存硬件上下文信息，并且保存__savemask指定的信号掩码 extern int __sigsetjmp (struct __jmp_buf_tag __env[1], int __savemask) __THROWNL; // c下这个只保存硬件上下文信息 extern int _setjmp (struct __jmp_buf_tag __env[1]) __THROWNL; // c下setjmp只保存硬件上下文信息 #define setjmp(env) _setjmp (env)`  longjmp:\ntypedef struct __jmp_buf_tag sigjmp_buf[1]; void __libc_siglongjmp (sigjmp_buf env, int val) { /* Perform any cleanups needed by the frames being unwound. */ _longjmp_unwind (env, val); if (env[0].__mask_was_saved) /* Restore the saved signal mask. */ (void) __sigprocmask (SIG_SETMASK, \u0026amp;env[0].__saved_mask, (sigset_t *) NULL); /* Call the machine-dependent function to restore machine state. */ __longjmp (env[0].__jmpbuf, val ?: 1); } // 如果没有定义这个宏__libc_siglongjmp则执行下面这些别名创建操作 // 什么情况下会定义这个宏呢？先不管，不影响整体的理解！fixme!!! #ifndef __libc_siglongjmp strong_alias (__libc_siglongjmp, __libc_longjmp) libc_hidden_def (__libc_longjmp) weak_alias (__libc_siglongjmp, _longjmp) weak_alias (__libc_siglongjmp, longjmp) weak_alias (__libc_siglongjmp, siglongjmp) #endif  这里对上面几个特殊的宏进行一下说明(以weak_alias为例，其他几个类似的处理方式)：\n// weak_alias(a,b)就是创建一个与a的别名b /* Define ALIASNAME as a weak alias for NAME. If weak aliases are not available, this defines a strong alias.*/ #define weak_alias(name, aliasname) _weak_alias (name, aliasname) #define _weak_alias(name, aliasname) \\ extern __typeof (name) aliasname __attribute__ ((weak, alias (#name)));  现在整体流程已经大体清楚了，现在来看下setjmp以及longjmp的实现：\n setjmp就不需要说了吧，也就是通过gcc扩展的内联汇编取出需要的寄存器的值，甚至是取出当前进程的task_struct中的信号掩码信息，然后保存到jmp_buf中； longjmp就是将参数中指定的jmp_buf取出来并进行还原，还原处理器的硬件上下文信息，还原进程的信号掩码信息，这里我们来说一下;  下面看下几个关键的函数。\n  第一个函数，_longjmp_unwind，这个是在执行实际的jmp之前先对unwind操作所经过的现有栈帧执行一定的处理动作，不过我看默认的/gnu/glibc/setjmp/jmp-unwind.c中没有做任何处理，可能需要用户自己hook一下？为啥要处理这里的栈帧呢，可能有必要可能没必要，只要jmp回去了，从栈低地址回到了高地址之后，之前低地址的栈也就全部作废了，因为栈又要从当前位置开始向低地址增长，之前生成的低地址栈空间会被覆盖。\n  第二个函数，_sigprocmask，这个是执行还原jmp_buf中的信号掩码信息的。\n  static void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset) { if (signal_pending(tsk) \u0026amp;\u0026amp; !thread_group_empty(tsk)) { sigset_t newblocked; /* A set of now blocked but previously unblocked signals. */ sigandnsets(\u0026amp;newblocked, newset, ¤t-\u0026gt;blocked); retarget_shared_pending(tsk, \u0026amp;newblocked); } tsk-\u0026gt;blocked = *newset; recalc_sigpending(); }  文件/gnu/glibc/sysdeps/unix/sysv/linux/x86_64/sigprocmask.c\n这个是glibc中定义的信号掩码处理函数，最终会通过系统调用进入内核来处理，因为毕竟要修改进程pcb中的某些状态字段，只有内核才具备此权限。\n/* Get and/or change the set of blocked signals. */ int __sigprocmask (int how, const sigset_t *set, sigset_t *oset) { /* XXX The size argument hopefully will have to be changed to the real size of the user-level sigset_t. */ return INLINE_SYSCALL (rt_sigprocmask, 4, how, set, oset, _NSIG / 8); } weak_alias (__sigprocmask, sigprocmask)  内核中的信号掩码处理函数，及根据操作类型来决定对进程信号掩码做何种处理，这里毫无疑问应该是set操作。\nint sigprocmask(int how, sigset_t *set, sigset_t *oldset) { struct task_struct *tsk = current; sigset_t newset; /* Lockless, only current can change -\u0026gt;blocked, never from irq */ if (oldset) *oldset = tsk-\u0026gt;blocked; switch (how) { case SIG_BLOCK: sigorsets(\u0026amp;newset, \u0026amp;tsk-\u0026gt;blocked, set); break; case SIG_UNBLOCK: sigandnsets(\u0026amp;newset, \u0026amp;tsk-\u0026gt;blocked, set); break; case SIG_SETMASK: newset = *set; break; default: return -EINVAL; } __set_current_blocked(\u0026amp;newset); return 0; }  获取当前进程的任务结构体，对其中的sighand加锁然后开始信号相关的设置操作，也就是屏蔽newset中指定的信号。\nvoid __set_current_blocked(const sigset_t *newset) { struct task_struct *tsk = current; spin_lock_irq(\u0026amp;tsk-\u0026gt;sighand-\u0026gt;siglock); __set_task_blocked(tsk, newset); spin_unlock_irq(\u0026amp;tsk-\u0026gt;sighand-\u0026gt;siglock); }  更新当前进程任务结构体task_struct中的信号掩码信息，至于更新的过程中做了何种处理，这里先暂时不做详细介绍了，感兴趣的话可以自己查看下源码。\n 第三个函数执行实际的jmp动作，也就是还原硬件上下文信息：  /* Jump to the position specified by ENV, causing the setjmp call there to return VAL, or 1 if VAL is 0. void __longjmp (__jmp_buf env, int val). */ .text ENTRY(__longjmp) /* Restore registers. */ mov (JB_RSP*8)(%rdi),%R8_LP mov (JB_RBP*8)(%rdi),%R9_LP mov (JB_PC*8)(%rdi),%RDX_LP #ifdef PTR_DEMANGLE PTR_DEMANGLE (%R8_LP) PTR_DEMANGLE (%R9_LP) PTR_DEMANGLE (%RDX_LP) #ifdef __ILP32__ /* We ignored the high bits of the %rbp value because only the low bits are mangled. But we cannot presume that %rbp is being used as a pointer and truncate it, so recover the high bits. */ movl (JB_RBP*8 + 4)(%rdi), %eax shlq 2, %rax orq %rax, %r9 # endif #endif LIBC_PROBE (longjmp, 3, LP_SIZE@%RDI_LP, -4@%esi, LP_SIZE@%RDX_LP) /* We add unwind information for the target here. */ cfi_def_cfa(%rdi, 0) cfi_register(%rsp,%r8) cfi_register(%rbp,%r9) cfi_register(%rip,%rdx) cfi_offset(%rbx,JB_RBX*8) cfi_offset(%r12,JB_R12*8) cfi_offset(%r13,JB_R13*8) cfi_offset(%r14,JB_R14*8) cfi_offset(%r15,JB_R15*8) movq (JB_RBX*8)(%rdi),%rbx movq (JB_R12*8)(%rdi),%r12 movq (JB_R13*8)(%rdi),%r13 movq (JB_R14*8)(%rdi),%r14 movq (JB_R15*8)(%rdi),%r15 /* Set return value for setjmp. */ mov %esi, %eax mov %R8_LP,%RSP_LP movq %r9,%rbp LIBC_PROBE (longjmp_target, 3, LP_SIZE@%RDI_LP, -4@%eax, LP_SIZE@%RDX_LP) jmpq *%rdx END (__longjmp)  上面的代码在文件/gnu/glibc/sysdeps/x86_64/__longjmp.S中，通过.text中的汇编代码来执行还原硬件上下文的操作，上面的代码中还用到了两个宏：\n/* Define an entry point visible from C. */ #define ENTRY(name) \\ .globl C_SYMBOL_NAME(name); \\ .type C_SYMBOL_NAME(name),@function; \\ .align ALIGNARG(4); \\ C_LABEL(name) \\ cfi_startproc; \\ CALL_MCOUNT #undef END #define END(name) \\ cfi_endproc; \\ ASM_SIZE_DIRECTIVE(name)  这两个宏就比较巧了，ENTRY其实直接定义了一个在c中具有可见性的函数name，在我们这个情境下就是__longjmp，然后就直接追加上前面还原硬件上下文的汇编代码作为函数体，最后通过END结束函数体。\n注意这里的代码__longjmp其实是个用户态中的函数，并非是内核来处理的。这样这个函数执行完成之后，下面就会自动回到setjmp语句的下一行语句处执行。\nsetjmp、longjmp的大致实现过程就介绍到这里，介可能有些地方描述不到位或者有错误，也请大家能给我指出来。\n"}),a.add({id:454,href:"/tags/longjmp/",title:"longjmp",description:"",content:""}),a.add({id:455,href:"/tags/setjmp/",title:"setjmp",description:"",content:""}),a.add({id:456,href:"/blog/2017-02-09-protobuf%E7%BC%96%E8%A7%A3%E7%A0%81/",title:"Protobuf编解码",description:"开发过程中学习学习的一点protobuf编解码的知识，以及对遇到的一些编解码相关问题的总结。",content:" img { width: 680px; padding-bottom: 1rem; }  开发过程中学习学习的一点protobuf编解码的知识，以及对遇到的一些编解码相关问题的总结。\n1.pb数据类型 # protobuf对message进行编码时，是将message中的各个成员按照key、value组合成一个字节流，这里的key并不是属性的名字，而是varint(tag\u0026laquo;3 | datatype)，其低3位表示字段类型，类型描述见下图。\n当protobuf对一个字节流进行解码的时候，对于那些它不认识的字段会直接跳过，对字节流反串行化操作的代码主要是依赖于各个Message子类的MergePartialFromCodedStream方法实现，常用的ParseFromString或者ParseFromArray方法最终都是调用该方法来完成反串行化任务。MergePartialFromCodedStream方法中包括了对unknown tag的处理，这部分代码都是protoc自动插入的，所以每个Message子类的对未知tag的处理方式也是一样的，下面通过一个简单的proto文件进行说明。\n文件名：T.proto\npackage kn.feeds; enum FeedType { TYPE_RECORD_LIVE = 1; TYPE_RECORD_VIDEO = 2; //TYPE_RECORD_DAYMOMENT = 3; }; message Feed { optional string name = 1; optional int32 time = 2; optional FeedType type = 3; };  使用protobuf --cpp_out=. T.proto进行处理，生成的T.pb.cc中kn::feeds::Feed::MergePartialFromCodedStream方法的源码如下图所示，其中对不相关代码进行了折叠。switch(....GetFieldNumber(tag))获取到了tag的编号并进行分别处理，如果是一个unknown tag则进入default处理分支，一般情况下是执行DO_(\u0026hellip;)将这个unknown tag保存到一个unknown_fields vector中。\n文件名：T.pb.cc，见下图：\n如果新需求中要求改造旧有的pb协议，例如在message中新追加了一些字段，旧代码在进行反串行化的时候并不会读取到新追加的字段，协议改造对旧有服务是不会产生不良影响的。\n另外，大家一般习惯于使用optional对字段进行修饰，这里就optional字段值是否设置对数据传输的影响也进行一下说明：\n 对于message中定义的optional类型的字段field，A给B发消息时，如果A没有显示设置field的值，那么B收到的字节流里面不会包括field字段的信息，B会自动使用proto文件中定义的该字段的默认值。 而当A显示设置字段field的值与默认值相同时，传输给B的字节流里面会包括field字段的信息。设置和不设置optional字段对于串行化数据的编码、传输是不同的。   PS：对于pb2而言，上述描述是正确的。对于pb3的情况，对编码及网络传输数据量又进行了优化，所有的0值都不会在编码时进行编码。如果系统中涉及到pb2、pb3共用，且存在使用pb2的代码中通过判断字段值是否为nil来做特殊逻辑，这里就容易引入问题。而如果全部是pb3协议则不需要考虑这种兼容问题。\n 2.varint \u0026amp; zigzag编解码 # 前面列出了protobuf数据类型编码规则，当tag低3位为0时表示varint类型，对于有符号类型、无符号类型其实差别还是挺大的。\n 对于无符号整数类型我们使用varint编码，如果给一个无符号类型赋一个负值，那么最终得到的值为一个很大的无符号数值； 对于有符号整数类型我们使用zigzag编码。怎么说呢，感觉zigzag也属于varint编码，但是比较特殊而已，仅用来对有符号整数进行编码。  无符号整数varint编解码规则 # - 每个字节的最高有效位（msb）表示是否还有其他字节；\n- 将各个字节从原来的顺序逆序排列一遍；\n- 丢掉各个字节的msb，并将其连接起来；\n- 按照二进制格式解码数据；\n这里其实描述的更像是如何理解一个varint编码，属于解码，但是这样看了之后也会很容易理解varint编码过程是如何进行的。\n有符号整数zigzag编解码规则 # 0被编码为0，-1被编码为1，1被编码为2，-2被编码为3，2被编码为4……以此类推。\n优点：\n这两种编码方式的优点是编解码规则简单，容易实现；占用字节数量少，减少网络传输代价（绝对值小的数字使用更少的字节进行编码，绝对值大的数字可以使用适当多的编码，而并不是限定为定长的16、32、64位）。\n3.non-varint编解码 # tag低3位为1时表示是使用固定的64位来编码一个数字，这里的数字类型仅限于double和fixed64、sfixed64。\n4.string编解码 # string在编码的时候首先是一个varint编码的长度值（字节数量），然后后面跟着的是字符串对应的各个字节。\n下图是一个编码字符串的示例，“testing”被编码成了如下字节流。\n5.嵌入式类型编解码 # 与字符串编解码方式是一致的，一个对象A被嵌到对象B中，也是先写一个varint表示A串行化后的字节流长度，然后再写字节流。\n6.optional \u0026amp; repeated类型编解码 # 对于repeated元素类型，proto2里面是多key存储的，即列表中每一个元素都是使用的相同的key；在proto3里面与此不同，列表中所有的元素共用同一个key。\n其实呢，proto2里面对于repeated类型增加了一个配置选项packed=true也可以达到proto3中的编码效果，proto2中packed属性默认为false；proto3中默认使用packed=true。那么是如何实现这种packed效果的呢？首先写入list中所有元素的直接数量，然后呢逐一对每个元素进行编码，varint中如果msb为0表示当前字节是对应元素的最后一个字节了，下面的字节属于下一个元素。\n7.字段顺序 # 官方文档中的表述是，尽管在proto文件定义的时候可以任意指定字段编号（不能重复编号），但还是建议按顺序对字段编号，这有利于protobuf的parsers采用一些依赖于字段按序编号时的优化方法以增加编解码速度。\n我编写了下面两个proto文件，分别使用protoc进行处理得到输出的头文件、源文件。第一种定义方式不按字段出现顺序进行编号，这么做并非不可，但是这种方式容易引发错误，非常不利于后期的扩展，因为不按顺序对字段编号，当字段数量比较多并且希望增加一个新的字段时可能都不知道该用哪个数字来对其编号了。\nmessage man { optional int32 age = 3; // 字段不按顺序编号 optional int32 sex = 1; optional string name = 2; }; message man { // 字段按顺序编号 optional int32 age = 1; optional int32 sex = 2; optional string name = 3; };  protoc分别对其进行处理后得到的**“头文件”**对比如下，左侧的是“字段不按顺序编号”的，右侧的是“字段”按顺序编号的：\n从上述生成的代码来看，字段值是否已经设置has_${field}方法以及设置有值set_has_${field}的方法，都是使用字段在message中出现的顺序编号对位图进行位与运算的，而不是按照我们手动指定的tag编号去进行位操作的。\n PS: 当时测试的时候应该是protoc v2.5.0，现在protoc已经到了v3.19.1，对比生成的代码发现，这里hasbits的设置与之前又不同了，即不是声明顺序，也不是tag编号，可能是采用了新的规则？这里不确定，简单搜索了下这里hasbits的设置也有些优化手段，可能是因为采用这些优化手段引起的。\nTODO 以后再补充hasbits设置相关的内容。\n 之后又对比了一下生成的**“源文件”**的差异，发现在串行化message信息时使用的字段对应的key还是按照我们指定的tag数值去设置的，如下图所示，左侧是不按序编号情况下对字段age=3进行设置的情况，通过字符串“age\\030\\003”我们知道age对应的key是3；右侧是按序编号情况下对字段age=1进行设置的情况，通过字符串“age\\030\\001”我们知道age对应的key是1（key值对应着pb中指定的field tag编号）。\n当然了反串行化的时候肯定也是按照这样的原则去做的，这样就能保证通信双方的数据视角是完全一致的，至于前面hasbits的逻辑都是通信一方自己的事情，protoc内置实现如何调整对通信双方没有影响，影响的只是自己根据访问对应字段的效率问题。\n总结：尽量按照字段在message中出现顺序进行编号，容易维护、扩展，别没事自讨苦吃，如果字段数量多了又不按序编号，那么新增一个字段的时候都不知道该用哪个编号了。\nx.其他方面 # protobuf的其他内容这里就暂时先不介绍了，有描述不清或者错误的地方还请指正。protobuf这种自描述性超强的消息格式获得了广泛的运用，也被诸多RPC框架用作IDL来指导代码生成，其在编解码效率、数据量方面都有不错的benchmark数据，是当今非常流行的消息格式。\nprotobuf当然也不是唯一一种流行的消息格式，在某些对资源更敏感的游戏场景，flatbuffers也是一种被非常青睐的消息交换格式。还有thrift、xml、json等等诸多格式，它们都有各自的一些适用场景，并非取代与被取代的关系，而是被问题场景选择与被选择的关系。感兴趣的可以更深入了解下。\ny.问题案例 # 最后总结两个初入职场不久遇到的pb问题，这两个问题是我工作中真实遇到的，这里一并记录下，也对其中与pb相关的其他知识点进行一下总结。\n问题1 # 客户端希望协议中新增一种短视频类型，服务端需要读取出短视频类型并进行存储，但是服务端未能成功接收到客户端提交的新的短视频类型。\n问题背景：\n客户端、后台定义好了协议，客户端要求提交一种新的短视频类型“日迹短视频”类型，于是后台在FeedType这个枚举类型里面增加了第3个字段DAY_MOMENT，然后呢，客户端重新编译该pb、后台重新编译该pb、各自开发，后来联调一切正常……\n过了一段时间呢？另一个后台开发同学不知道proto已经被更新了，他只更新了检出的feeds写服务的代码，并没有更新检出的公共目录feeds/proto下的proto文件，自然也就没有将新的日迹短视频类型这个枚举字段编译到代码中去，就这样发布出去了……\n后面客户端同学发现，明明提交的是日迹短视频类型（type=3），后台查询返回的却是普通的短视频类型（type=1），非常不解，检查后台feeds写代码后发现完全是将客户端提交的type直接写到tmem、db的，并没有做任何改动……\n造成这个问题的原因已经是很明白了，就是proto文件没有更新，新增加的枚举字段没有编译进去，但是代码在执行的时候到底发生了什么呢？带着这个问题我扒了一下代码终于理清了这背后的原因。\n首先其他的后台开发人员没有更新检出的proto文件，导致其个人目录下编译出的代码中缺少“日迹短视频字段”，当客户端提交短视频类型FeedType type=3的时候，3被编码为varint(3)；服务端枚举类型只有两个可枚举值1、2没有3，那么服务端收到请求后通过Feed feed; feed.ParseFromString或者feed.ParseFromArray方法反串行化后，读取出来的值feed.type()是多少呢？这里也不卖关子了，feed.type()返回的是1而不是3。下面就说一下为什么这里返回的竟然是1。\n以图1中的T.proto为例，其生成的T.pb.h中包含了如下对FeedType枚举值的检查，当我们执行set_type()方法或者MergeParitalFromCodedStream或者DebugString()的时候，是会对枚举值的有效性进行检查的，检查枚举值有效性的方法就是下图中的FeedType_IsValid()方法。该方法是在enum FeedType中的TYPE_RECORD_DAYMOMENT未被注释掉的情况下生成的，所以switch里面认为case 1、2、3都是有效的；当注释掉TYPE_RECORD_DAYMOMENT生成的switch中就只有case 1、2。无效的枚举值该函数返回false，所以除了case里面出现过的枚举值，其他的都是错误的。\n枚举值有效性检查：\n这里的方法FeedType_IsValid()会在某些断言assert()中被调用，如果程序中没有定义宏NDEBUG，那么一旦调用了该方法的assert()被执行将直接导致程序退出。但是在现网中肯定是不允许程序就因为收到了一个非法的枚举值就“挂掉”的，那么protobuf中对这种非法的枚举值必然会提供一种处理方法，这个方法是什么呢？\n当收到一个pb串行化数据之后，我们希望对其反串行化得到一个自定义的Message对象实例，通常的反串行化方法是调用Message对象实例的ParseFromString或者ParseFromArray方法来完成，这两个方法都调用了一个非常关键的方法：MergePartialFromCodedStream，该方法是基类Message的方法，但是会被Message子类中的方法覆盖，因为如何反串行化数据肯定是由子类中包括的成员来决定的，每个子类都应该提供对应的反串行化实现，这部分代码是protoc自动插入的。以图1中的message Feed为例，protoc处理后生成的T.pb.cc中的MergePartialFromCodedStream方法如下图所示。\nMergePartialFromCodedStream:\n上图是release版本中read tag时读取到tag=3枚举类型FeedType type字段时的相关代码，因为枚举类型也是varint类型，所以会首先检查读取到的tag是否是一个varint类型，如果不是则将其加入unknown_fields vector；如果是则继续检查字段值是否是一个有效的枚举值，如果是则将其强制类型转换成FeedType，并更新调用者Feed对象的成员type；如果不是一个有效的枚举值则将其添加到unknown_fields这个vector中，这个时候调用者Feed对象的成员type并没有被更新，依然是使用的旧值，那么这里的旧值是什么呢？\n在c、c++中枚举类型变量的默认值为0，但是在protobuf中，一个枚举类型变量的默认值为枚举值中的第一个，我们这里的FeedType type枚举变量可枚举的第一个值为1，所以最终FeedType type的值在Feed feed; feed.ParseFromArray(\u0026hellip;rec_pb_data\u0026hellip;)之后不是3而是1。\n……\n上述就是ilive_feeds_write_svr在收到短视频类型为3时写入tmem短视频类型却为1这个问题的原因！\n这里只是加深了对protobuf处理过程的理解，并非造成问题的根源，根源应该从代码管理方面找。\n PS：pb中对枚举值的使用建议，强烈将对应的0值定义为Invalid/Unknown，正常取值从1开始取，用0值表示无意义的枚举值，以解决pb枚举潜在的各种“坑”，这个很重要，我做项目的经历已经清晰地表明了它可能给您的项目带来的风险。\n 问题2 # 问题二：直播场景，用户在房间内发送聊天信息，请求中包含了一个房间id字段roomid，表示用户在哪个房间中发言，但是服务端接收到客户端提交的roomid是错误的。\n问题描述：\n客户端、后台定义好了proto文件，如下所示：\nmessage XXXReq { optional uint32 anyfield = 1; optional uint32 roomid = 2; }; message XXXRsp { optional uint32 roomid = 1; optional ustring json = 2; }; rpc XXX(XXXReq) return (XXXRsp);  但是呢，后来由于协议变动发现XXXReq中的字段anyfield没有用，就删掉吧，于是后台就改成了：\nmessage XXXReq { optional uint32 roomid = 1; };  但是呢，客户端那边只是删掉了第一个字段，改成了：\nmessage XXXReq { optional uint32 roomid = 2; };  后台并不知道客户端是这么改的……一段时间之后，后台同学发现客户端同学提交过来的参数roomid似乎是有问题的，什么问题呢？同一个用户进入now主播房间后发言，每次发言请求提交的roomid都应该是主播自己的roomid，应该是固定的，但是后台同学发现打印出来的请求中的roomid却是变化的，这是什么问题？\n其实这里经过问题1的分析之后也很容易理解了，后台根本就没有读取到客户端设置的tag=2的roomid，后台只是使用了XXXReq req中的默认的roomid值，这个变量又没有进行初始化，roomid中的值是随机值，肯定是会变化的、是错误的。\n"}),a.add({id:457,href:"/tags/varint/",title:"varint",description:"",content:""}),a.add({id:458,href:"/tags/zigzag/",title:"zigzag",description:"",content:""}),a.add({id:459,href:"/blog/2021-04-19-go-sync.mutex%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"",description:"终于来到了go语言相关的设计实现，go中sync.Mutex的设计有很多设计方面的考虑。\n我们看下对应的加锁解锁部分，对应的源码 see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L72\n首先，了解下锁的定义，我们看到里面有个state字段，这个字段表示的是锁的状态，为0表示锁是解锁状态，其他状态可以参考下源码中的定义。\n// A Mutex is a mutual exclusion lcok. // The zero value for a Mutex is an unlocked mutex. // // A Mutex must not be copied after first use. type Mutext struct { state	int32 sema	uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota )  下面看下加解锁实现，多注意下state相关的逻辑，比较容易好理解。\nmutex.Lock() # fastpath # 首先，会执行fastpath，会尝试CAS加锁一次，如果没有很多锁竞争，且锁处于未加锁状态（state=0），大概率会加锁成功（state=1）成功返回。\n如果fastpath加锁失败了，比如尝试加锁前state != 0：",content:"终于来到了go语言相关的设计实现，go中sync.Mutex的设计有很多设计方面的考虑。\n我们看下对应的加锁解锁部分，对应的源码 see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L72\n首先，了解下锁的定义，我们看到里面有个state字段，这个字段表示的是锁的状态，为0表示锁是解锁状态，其他状态可以参考下源码中的定义。\n// A Mutex is a mutual exclusion lcok. // The zero value for a Mutex is an unlocked mutex. // // A Mutex must not be copied after first use. type Mutext struct { state	int32 sema	uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota )  下面看下加解锁实现，多注意下state相关的逻辑，比较容易好理解。\nmutex.Lock() # fastpath # 首先，会执行fastpath，会尝试CAS加锁一次，如果没有很多锁竞争，且锁处于未加锁状态（state=0），大概率会加锁成功（state=1）成功返回。\n如果fastpath加锁失败了，比如尝试加锁前state != 0：\n  state可能为1\n此时，表示锁已经被锁定，新goroutine尝试加锁请求失败，这种很好理解；\n  state != 0，但也不是1（mutexLocked）\n这种情况就比较特殊了，涉及到go的一些锁优化，拿个例子来说一下。比如state有可能为4（mutexStarving），即它确实处于解锁状态(state\u0026amp;mutexLocked=0)，但却处于starvation模式下，这说明之前有尝试加锁的goroutine很久没有拿到锁了，所以将当前锁的模式从normal修改为了starvation。\n为了避免调度延迟过大，go会优先受理部分goroutine的加锁请求，所以，这种情况新加入抢锁的goroutine也是不能拿到锁的。\n  OK，有了这个大致的了解之后，我们继续看加锁失败后的处理路径，继续执行slowpath。\n// Lock locks m. // If the lock is already in use, the calling goroutine // blocks until the mutex is available. func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. if atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // Slow path (outlined so that the fast path can be inlined) m.lockSlow() }  slowpath # 这部分就有很多优化措施了，感兴趣的可以阅读这里的源码，我们先尝试总结下。\nsee https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L84\nfunc (m *Mutex) lockSlow() { ... old := m.state for { // Don't spin in starvation mode, ownership is handed off to waiters // so we won't be able to acquire the mutex anyway. if old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { // Active spinning makes sense. // Try to set mutexWoken flag to inform Unlock // to not wake other blocked goroutines. if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state continue } ... } ... }  加锁失败后，失败原因有多种，要么是锁已经被锁定了，要么是处于饥饿模式。对应的处理方式也不一样，所以开头先判断下。\n如果old\u0026amp;(mutexLocked|mutexStarvig) == mutexLocked为true，则表示之前加锁的失败原因是，锁已经被锁定了。那怎么办呢？难道要让goroutine立即去睡觉觉？goroutine睡着后再被唤醒参与调度这个开销和线程比是小，但是还是有的嘛，能不能再尝试几次，避免过早睡眠？当然可以。\n那就让当前goroutine自旋+重新加锁几次试试，就是这里的runtime_canSpin(iter)来控制能否自旋了。\n// Active spinning for sync.Mutex. //go:linkname sync_runtime_canSpin sync.runtime_canSpin //go:nosplit func sync_runtime_canSpin(i int) bool { // sync.Mutex is cooperative, so we are conservative with spinning. // Spin only few times and only if running on a multicore machine and // GOMAXPROCS\u0026gt;1 and there is at least one other running P and local runq is empty. // As opposed to runtime mutex we don't do passive spinning here, // because there can be work on global runq or on other Ps. if i \u0026gt;= active_spin || ncpu \u0026lt;= 1 || gomaxprocs \u0026lt;= int32(sched.npidle+sched.nmspinning)+1 { return false } if p := getg().m.p.ptr(); !runqempty(p) { return false } return true }  最多自旋4次，当然还有其他要求，就是必须运行在多核机器上，并且GOMAXPROCS\u0026gt;1，并且至少有另外一个正在运行的P且其runq为空。大家可以想一下为什么？如果不这么限制，那谁来释放锁呢，当前goroutine大概率自旋无效，也优化不了什么。\n这些条件满足时，检查当前g运行的P上runq是否为空，如果为空才允许自旋，为什么？会影响到runq中的goroutine的调度执行吧。\n最后再看lockSlow中的代码逻辑：\nfunc (m *Mutex) lockSlow() { ... old := m.state for { if old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { // Active spinning makes sense. // Try to set mutexWoken flag to inform Unlock // to not wake other blocked goroutines. if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state continue } ... } ... }  大家看刚开加锁失败后awoke=false, 并且假定old=mutexLocked，old\u0026raquo;mutexWaiterShift这个写法，让人猜测m.state中还存储了waiter相关的信息，然后尝试将m.state设置上mutexWoken，awoke=true，没看出这是在干啥。\n然后runtime_doSpin开始空转CPU，可以理解成一个for循环从30减到0，结束。这么做无非就是想等其他goroutine把锁释放掉。\nconst ( active_spin_cnt = 30 ) //go:linkname sync_runtime_doSpin sync.runtime_doSpin //go:nosplit func sync_runtime_doSpin() { procyield(active_spin_cnt) } func procyield(cycles uint32) TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL	cycles+0(FP), AX again: PAUSE SUBL	$1, AX JNZ	again RET  然后iter++，表示自旋次数+1（最多4次），更新锁状态，注意此时mutexWoken设置了，现在可以猜测下mutexWoken表示啥了，它表示的是mutex有没有唤醒协程来抢锁。\n自旋之后continue，进入循环体的下一次循环，继续检查锁的状态：\n 如果锁依旧被锁定，且当前可以继续自旋，则继续自旋； 如果锁依旧被锁定，且当前超过了自旋次数，则执行下面的逻辑； 如果锁被解锁了，则也执行下面的逻辑；  下面的new表示当前代码执行完后锁的状态，有这么几种情况：\n 锁还没被释放，锁必然处于锁定状态，new\u0026amp;mutexLocked==1； 锁已经被释放，锁如果处于normal模式，当前goroutine必抢锁成功，所以new|=mutexLocked也很好理解； 锁已经被释放，锁如果处于starvation模式，当前goroutine抢锁失败，入队等待，但是这个锁将直接递交给等待队列中的第一个waiter，不用这个waiter被唤醒后抢锁，所以其new|=mutexLocked没什么疑问了；  继续看waiter标志位相关的设置：检查old状态，如果仍是锁定或者饿死状态，则直接将new中设置mutexWaiter标记。干嘛用的，表示有waiter在等待锁释放啊。\n继续看starvation标志位相关的设置：如果发现锁之前的状态就是饥饿模式了，并且没有被锁定，那么锁的最新状态还是饥饿模式（new|=mutexStarving岂不是多余？）\nfunc (m *Mutex) lockSlow() { ... old := m.state for { new := old // Don't try to acquire starving mutex, new arriving goroutines must queue. if old\u0026amp;mutexStarving == 0 { new |= mutexLocked } if old\u0026amp;(mutexLocked|mutexStarving) != 0 { new += 1 \u0026lt;\u0026lt; mutexWaiterShift } // The current goroutine switches mutex to starvation mode. // But if the mutex is currently unlocked, don't do the switch. // Unlock expects that starving mutex has waiters, which will not // be true in this case. if starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 { new |= mutexStarving } ... } .... }  继续看，如果当前mutex已经有被唤醒的goroutine尝试抢锁，那么new里面mutexWoken应该为1，如果为0是一种不一致状态，报错。然后从new中清除这一标记位，也需mutexwoken代表的就是当前goroutine吧，一次唤醒一个嘛。\nfunc (m *Mutex) lockSlow() { ... old := m.state for { new := old ... if awoke { // The goroutine has been woken from sleep, // so we need to reset the flag in either case. if new\u0026amp;mutexWoken == 0 { throw(\u0026quot;sync: inconsistent mutex state\u0026quot;) } new \u0026amp;^= mutexWoken } ... } ... }  继续看，CAS更新下锁状态m.state，注意此时new里面设置了locked（starvation可能有也可能没有）。\n继续检查，如果之前锁状态不是锁定状态、不是饥饿状态，那么现在肯定就是锁定成功了，退出循环结束加锁过程。\n如果发现waitStartTime不为0，说明之前已经有几轮循环来尝试过获得锁了，现在要算一下当前这次加锁操作总共等待了多久了。\nfunc (m *Mutex) lockSlow() { var waitStartTime int64 ... old := m.state for { new := old ... if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { if old\u0026amp;(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // If we were already waiting before, queue at the front of the queue. queueLifo := waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } ... } ... } ... }  现在来算一下当前goroutine加锁等待了多久了，这个时间很好算，直接拿当前时间减去第第一次开始的时间就算出来了，runtime_nanotime()-waitStartTime()，并且发现，如果这个时间超过阈值1ms，就会将starving设为true，意味着mutex将被设置为饥饿模式，当然如果以前就是饥饿模式，现在肯定也是饥饿模式了。\n另外注意queueLifo的值，如果是新抢锁的goroutine，那么为false，调用runtime_Semacquire时会将该goroutine假如到队列的末尾排队，如果是之前唤醒过的goroutine，则会将其添加到队列的对首，如果锁变成了饥饿模式且被释放了，则直接交给对首的goroutine执行。\n这个函数runtime_semacquiremutex，还挺关键的：\n信号量semaroot好理解，它是地址addr处对应的信号量，本身内部维护了一个等待信号量的sudog（等待执行的g）列表，对mutex而言就是等待抢锁的goroutines/waiters列表。\nmutex里面为什么要加一个字段sema，其实就是为了间接具备这样一种能力，维护一个\u0026amp;sema的信号量，维护一个因为抢锁而阻塞的goroutine列表，以方便在锁被释放的时候，再把它们唤醒。\n看下这个函数是怎么实现的吧，它调用了semacquire1这个函数，这个函数内部就是获得\u0026amp;addr处对应的信号量，然后尝试对semaroot.lock加锁，这个锁是一个runtime.mutex，\n我擦，我发现这个函数里面调用了semacquire1(\u0026hellip;)，这个函数里面调用了lockWithRank，lockWithRank调用了lock2()，lock2内部使用了Linux系统调用futex这个能够把线程挂起的重量级锁！\n打脸，前面总结说sync.Mutex没有使用futex，哇擦！\nm.sema这个变量表示的是一个信号量，但是这个信号量是用来通知啥的呢？这个信号量对应的有一个等待队列的，如果lifo为true，则表示将当前的goroutine对应的后续sudog放入队列的头部，这样方便饿死模式下直接将mutex的拥有权交给这个对首的waiter，避免其等锁等太久。\n 如果拿到了这个信号量就立即返回了； 如果拿不到这个信号量就要做后面的处理了；  可能有多个并发的goroutine来抢锁的情况，可能之前已经有没抢到阻塞的goroutine了，这里先找一个阻塞的goroutine，获得信号量地址对应的一个数据结构，记为semaroot，这个维护了mutex上因为抢锁失败而等待的goroutine（waiters）队列。\n对这个semaroot.lock的加锁操作，用了自旋、CAS、futex，为啥用futex呢？这不相当于sync.Mutex间接用了futex嘛！那如果加锁失败不是直接阻塞线程了吗！\n 这种情况下好的情况是几个线程自旋一下抢到sync.Mutex.sema，大概率会成功，但是锁竞争严重的时候还是会失败，怎么办总不能一直自旋不干活啊，注意了，这里调用了  func (m *Mutex) lockSlow() { ... old := m.state for { new := old ... if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { ... queueLifo := waitStartTime != 0 ... runtime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1) starving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state if old\u0026amp;mutexStarving != 0 { // If this goroutine was woken and mutex is in starvation mode, // ownership was handed off to us but mutex is in somewhat // inconsistent state: mutexLocked is not set and we are still // accounted as waiter. Fix that. if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { throw(\u0026quot;sync: inconsistent mutex state\u0026quot;) } delta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift) if !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { // Exit starvation mode. // Critical to do it here and consider wait time. // Starvation mode is so inefficient, that two goroutines // can go lock-step infinitely once they switch mutex // to starvation mode. delta -= mutexStarving } atomic.AddInt32(\u0026amp;m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } ... }  sync.Mutex里面的锁实现，不使用futex，即当Lock失败时，不会导致调用的进程线程被阻塞，而只是将当前goroutine阻塞，go runtime scheduler仍然可以在当前线程上调度执行其他的goroutine，等锁被Unlock时，就有机会再唤醒之前Lock失败的goroutine执行。\n另外，go sync.Mutex做了很多优化，大致总结一下。sync.Mutex有两种工作模式：normal mode 和 starvation mode，两种模式对执行Lock、Unlock的goroutine会产生不同的影响。\n  normal mode\n该模式下，waiters（goroutines）会按照加锁申请进入一个FIFO的队列，一个被唤醒的waiter不一定能够立即持有锁，它要和所有新的发起加锁请求的goroutines竞争。新到达的goroutines通常有一个优势——它们已经在CPU上运行了，并且有很多，所以一个刚被唤醒的waiter大概率会竞争锁失败。\n这种情况下，这个失败的waiter会被加入到这个FIFO队列的对首，如果一个waiter竞争锁超过1ms还没有成功，就会将mutex从normal mode切换为startvation mode。\n  starvation mode\n该模式下，当一个goroutine释放锁时，锁的拥有者立即从该goroutine转交给对首的waiter。新到达的goroutines不会尝试获得锁，尽管它能观察到锁好像被释放掉了。这种模式下，新到达的goroutines会追加到FIFO的队列的末尾。\n  当一个waiter收到一个mutex的拥有者权限时，它会检查，如果：1）它是这个锁竞争等待队列中的最后一个waiter；或者 2）它的加锁等待时间小于1ms，此时将把mutex从starvation mode切换为normal mode。\nmutex.Unlock() # fastpath # 先尝试CAS去掉加锁标志位，其实返回的是锁的新状态，如果之前状态是locked，现在unlocked去掉了这个标志位，如果新状态state==0，表示没什么其他要处理的了，直接返回就可以了，反之，则说明锁可能被设置了其他的状态，如前面提到的锁的normal、starvation mode，还需要进入slowpath进一步处理。\n// Unlock unlocks m. // It is a run-time error if m is not locked on entry to Unlock. // // A locked Mutex is not associated with a particular goroutine. // It is allowed for one goroutine to lock a Mutex and then // arrange for another goroutine to unlock it. func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. new := atomic.AddInt32(\u0026amp;m.state, -mutexLocked) if new != 0 { // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) } }  slowpath # 锁的状态不只是有持有、未持有这几种，那看来这里是要处理其他几种锁状态的情况了。\nconst ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota )  继续看源码，首先做个检查，当前goroutine调用Unlock之前是否有持有这把锁，很好比较，只要检查 (new+mutexLocked) \u0026amp; mutexLocked 下便知道。\nQA：如果当前goroutine没有持有过锁，前面fastpath中却去掉了锁标志位，走到这里检查发现之前没有持有锁，这是很严重的问题，直接throw了，也没什么善后的，直接退出啦，程序员自己抓紧改bug吧，继续跑也会造成bug！\n然后这里面主要是这个函数runtime_Semrelease：\n 如果是正常模式，这个函数从对头取出一个sudog（等待锁的goroutine），然后将其丢入runq等待被调度； 如果是饥饿模式，这个函数从头取出一个sudog（等待锁的goroutine），然后将其丢入runq，并立即让出CPU，相当于让这个sudog尽可能快地被执行到。  func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026amp;mutexLocked == 0 { throw(\u0026quot;sync: unlock of unlocked mutex\u0026quot;) } if new\u0026amp;mutexStarving == 0 { old := new for { // If there are no waiters or a goroutine has already // been woken or grabbed the lock, no need to wake anyone. // In starvation mode ownership is directly handed off from unlocking // goroutine to the next waiter. We are not part of this chain, // since we did not observe mutexStarving when we unlocked the mutex above. // So get off the way. if old\u0026gt;\u0026gt;mutexWaiterShift == 0 || old\u0026amp;(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // Grab the right to wake someone. new = (old - 1\u0026lt;\u0026lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { runtime_Semrelease(\u0026amp;m.sema, false, 1) return } old = m.state } } else { // Starving mode: handoff mutex ownership to the next waiter, and yield // our time slice so that the next waiter can start to run immediately. // Note: mutexLocked is not set, the waiter will set it after wakeup. // But mutex is still considered locked if mutexStarving is set, // so new coming goroutines won't acquire it. runtime_Semrelease(\u0026amp;m.sema, true, 1) } }  # "}),a.add({id:460,href:"/blog/08%E9%87%8D%E8%A6%81%E7%9A%84%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E4%B8%8B/",title:"08重要的集群参数配置",description:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101763",content:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101763\n"}),a.add({id:461,href:"/blog/09%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E5%88%86%E5%8C%BA%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/",title:"09生产者消息分区原理剖析",description:"kafka中数据组织 #  主题 topic 分区 partition（一个topic下可有多个partitions，每个partition都有副本replicas） 消息 message（同一个partition内的消息是有序的）  ",content:"kafka中数据组织 #  主题 topic 分区 partition（一个topic下可有多个partitions，每个partition都有副本replicas） 消息 message（同一个partition内的消息是有序的）  "}),a.add({id:462,href:"/tags/c/cpp/",title:"c/cpp",description:"",content:""}),a.add({id:463,href:"/tags/desktop/",title:"desktop",description:"",content:""}),a.add({id:464,href:"/tags/go/ast/",title:"go/ast",description:"",content:""}),a.add({id:465,href:"/tags/grub/",title:"grub",description:"",content:""}),a.add({id:466,href:"/tags/plymouth/",title:"plymouth",description:"",content:""}),a.add({id:467,href:"/blog/2017-03-13-%E8%81%8A%E8%81%8A%E4%BC%B4%E6%88%91%E5%A4%9A%E5%B9%B4%E7%9A%84%E8%80%81%E5%8F%8Blinux/",title:"聊聊伴我多年的老友，Linux",description:"使用Linux已经快10年了，从大三开始到研究生毕业，Linux作为了我的主力操作系统，Windows几乎没有再怎么使用过（曾经我Windows玩的也很溜的）。这么多年，Linux让我重新认识了桌面环境的效率，也让我认识了定制化的自由，还有它简单却精妙绝伦的设计。也是时间来聊聊这位老友了。",content:"1 邂逅Linux # 初次接触Linux操作系统是在什么时候？想想～～\n高三毕业后买了第一台电脑，一台清华同方的台式机，随机赠送的光盘里面有一张操作系 统光盘“家电下乡Linux适农版”……那是我第一次接触并运行Linux，但那时的我并没有意识 到，放在我面前的是一个即将深深地吸引我并要在多年的职业生涯中去不断锤炼的存在。\n大一、大二这两年，我或多或少地接触到了Linux，但是并没有产生多大兴趣，直到有一 天我激怒了一个同学。当时他正在摆弄Ubuntu，错误地GRUB配置导致系统引导失败，着急 的他在QQ空间发了一条状态，意思就是大神求救之类的。当时我回了一个字“水”。他看后 很生气，系统都启动不了了能不着急吗？于是呢，就言辞激烈地“回敬”了我几句……\n事后我想，Linux有这么复杂吗？于是我开始试图取了解Linux，当然这只是个引子，后面 陆陆续续看到有不少同学都在使用各种Linux的发行版，我才决定认真去了解、学习一下 Linux，没想到这竟是一条不归路……\n LiveCD \u0026amp; RemasterSys \u0026amp; dump \u0026amp; restore GRUB 2 \u0026amp; Customize Boot Menu to bootstrap Multiple OS Plymouth Tweak KDE/GNOME/Unity Appearance (Colors \u0026amp; Themes) Linux Commandline Techs \u0026amp; Administration Unix/Linux Programming Linux Kernel 0.11 Linux Kernel 2.4 Keep going along the roadmap to Linux World!  上面大体上是我初识、折腾、学习、应用、研究Linux的过程，而且这个过程在相当长一 段事时间内还将一直向前延伸下去。与其说对Linux感兴趣，不如说是好奇心驱使，还有 很多疑问没有揭开，这里当然不只是Linux操作系统内核本身。\n我这个博客所要描述的东西可能就比较杂了，这里面我会穿插着记录很多东西～与其说是 博客，不如说是我自己的一个学习笔记了，但是我这个人比较喜欢分享，但有不想那么刻 意，所以我就把它丢在这，谁看见了找到点自己感兴趣的东西，也算是种缘分。\n2 LiveCD \u0026amp; RemasterSys \u0026amp; dump \u0026amp; restore # 2.1 LiveCD # 在学习Linux过程中，会有体验不同Linux发行版这样的需求的，这个时候你有不想频繁地安装系统来解决。LiveCD就是发行版厂商针对用户的这种需求推出的一个玩意，用户可以插入光盘到光驱、BIOS引导从光驱启动来体验。\n可能吧，时间让你明白，Linux最吸引人的地方，并不是有很多的发行版供你换来换去，而是内在的自由。最后，你还是会深度使用某一个发行版并安定下来，而那些各种各样的桌面环境也会有点选择困难。Ubuntu-\u0026gt;Debian-\u0026gt;Fedora-\u0026gt;OpenSuSE-\u0026gt;RHEL-\u0026gt;CentOS-\u0026gt;\u0026hellip;Fedora! Unity-\u0026gt;GNOME3-\u0026gt;GNOME2-\u0026gt;KDE-\u0026gt;\u0026hellip;-\u0026gt;KDE! 我已经坚守在Fedora/CentOS+KDE很多年了，适合自己的就是最好的！\nLiveCD不仅可以帮助我们预先体验Linux发行版，也可以用来安装Linux发行版、修复系统问题。带着一张LiveCD或者Bootable USB Installer，就好像随身携带了一个移动版的操作系统。还是很方便、很酷的一件事情。\nUNetBootin等类似的将USB变身成可引导的Bootable Linux Installer的工具，也是必不可少的工具。\n2.2 RemasterSys # 当你深度使用了一段时间之后，会发现不管是配置文件，还是GUI，还是软件列表\u0026hellip;都已经被自己深度定制化过了，这个时候就很自然会去想系统备份的事情，以免准备多台设备办公时能遍历地迁移备份，或者在设备系统出现问题时能够便捷地还原的问题。\n当你了解了Linux定制化意味着什么的时候，你就应该能体会到定制化背后意味着的工作量、投入的时间，你不会愿意再从安装开始重新定制化了， 没有规划的人才将这种重复性劳动当做是习惯。我为什么不能将现在的完整的系统做成一个初始的可安装的系统呢？\n虽然这要花费的时间、存储可能会大一点，但是适当精简下软件列表、用户文件，完全可以控制在一个合理的范围内，按市面上常见的DVD存储容量来看，完全是hold得住的。而且DVD是真的便宜，存放时间也更长久。\nRemasterSys就是为了满足这样的需求而设计出来的，它就可以把我们当前运行的系统重新做成一个可安装的系统，安装完成后就是现在的样子。但是原作者可能很久没有再更新了吧，在我了解到这款系统工具时，它已经接近失修的边缘了。Sad\n2.3 dump \u0026amp; restore # 慢慢地意识到，所谓的定制都是私人潜意识里面的思想固化，总有不适合他人应用场景的时候，除非你有能力自己给自己定制。最简单的东西，就是最好用的、最靠谱的。一段时间下来，我发现dump \u0026amp; restore就是逼近完美的选择。它专注于转储、恢复操作，非常原始。\ndd最原始直接读写存储设备原始数据，甚至都不理解你的文件系统，但是它缺少一点灵活性。\ndump允许我们在文件系统之上做一些选择，如选择备份哪些目录、文件等等，dump备份的时候会同时备份文件的属性信息，整个打包成一个文件，后续备份恢复的时候你也可以通过restore选择恢复哪些文件到文件系统。\n刚开始的时候，可能觉得全是命令行操作，好复杂？万一出错了怎么办？Linux强大的地方就是命令行操作，习惯了之后就真的爱上了。dump \u0026amp; restore是目前我觉得比较好用的，虽然看上去不像macOS timemachine那样方便，但是它真的算得上最灵活的。\n3 GRUB 2 \u0026amp; Customize Boot Menu to bootstrap Multiple OS # 4 Plymouth # 5 Tweak KDE/GNOME/Unity Appearance (Colors \u0026amp; Themes) # 6 Linux Commandline Techs \u0026amp; Administration # 7 Unix/Linux Programming # 8 Linux Kernel 0.11 # 9 Linux Kernel 2.4 # 10 Keep going along the roadmap to Linux World! # "}),search.addEventListener('input',b,!0);function b(){var b,e;const d=5;b=this.value,e=a.search(b,{limit:d,enrich:!0});const c=new Map;for(const a of e.flatMap(a=>a.result)){if(c.has(a.doc.href))continue;c.set(a.doc.href,a.doc)}if(suggestions.innerHTML="",suggestions.classList.remove('d-none'),c.size===0&&b){const a=document.createElement('div');a.innerHTML=`No results for "<strong>${b}</strong>"`,a.classList.add("suggestion__no-results"),suggestions.appendChild(a);return}for(const[h,a]of c){const f=document.createElement('div');suggestions.appendChild(f);const b=document.createElement('a');b.href=h,f.appendChild(b);const g=document.createElement('span');g.textContent=a.title,g.classList.add("suggestion__title"),b.appendChild(g);const e=document.createElement('span');if(a.description.length>128?e.textContent=a.description.substring(0,128)+"...read more":e.textContent=a.description,e.classList.add("suggestion__description"),b.appendChild(e),suggestions.appendChild(f),suggestions.childElementCount==d)break}}})()