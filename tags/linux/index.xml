<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>linux on</title><link>/tags/linux/</link><description>Recent content in linux on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Fri, 08 Sep 2023 16:30:30 +0800</lastBuildDate><atom:link href="/tags/linux/index.xml" rel="self" type="application/rss+xml"/><item><title>Linux性能问题排查60s</title><link>/blog/2023-09-08-linux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A560s/</link><pubDate>Fri, 08 Sep 2023 16:30:30 +0800</pubDate><guid>/blog/2023-09-08-linux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A560s/</guid><description>简介 # 最近在阅读Gregg大佬著作《BPF Performance Tools》，其中一小节作者提到了其在Netflix工程团队中践行的一个性能排查checklist，当遇到Linux性能问题时，前60s往往是借助这个checklist来进行排查，如果有必要，缩小范围后再借助其他工具进行进一步排查。我觉得这个简短的checklist还挺实用的，特地摘录出来分享下。
问题背景 # 这个checklist可以用来指导排查任意Linux性能问题，当我们知道有台机器性能（疑似）有问题时，我们就可以登录这台机器，按照这个checklist来进行前60s的快速分析。这也是Gregg自己以及Netflix工程团队实践中总结出来的。
对于很多刚入行后台开发的同学而言，我觉得这个还是比较有价值的，应该在日常工作中不断实践、不断加深对性能影响因素的理解。有位技术扎实的同事曾经这样说，一切都是可计算的、可量化的，比如判断对特定工作负载瓶颈是什么，cpu、内存、网卡？链路长短，网络延迟，然后大致的系统吞吐量是什么样的？他大致就能推算出来。
其实，Jeff Dean曾经在论文里给出过一些开发人员应该知晓的latency数据：
L1 cache reference ......................... 0.5 ns Branch mispredict ............................ 5 ns L2 cache reference ........................... 7 ns Mutex lock/unlock ........................... 25 ns Main memory reference ...................... 100 ns Compress 1K bytes with Zippy ............. 3,000 ns = 3 µs Send 2K bytes over 1 Gbps network ....... 20,000 ns = 20 µs SSD random read ........................ 150,000 ns = 150 µs Read 1 MB sequentially from memory .</description></item><item><title>压测之接口lo的妙用</title><link>/blog/2023-04-14-%E5%8E%8B%E6%B5%8B%E4%B9%8B%E6%8E%A5%E5%8F%A3lo%E7%9A%84%E5%A6%99%E7%94%A8/</link><pubDate>Fri, 14 Apr 2023 03:10:08 +0000</pubDate><guid>/blog/2023-04-14-%E5%8E%8B%E6%B5%8B%E4%B9%8B%E6%8E%A5%E5%8F%A3lo%E7%9A%84%E5%A6%99%E7%94%A8/</guid><description>问题背景 # 前一篇文章介绍了本地开发机压测时如何为每个待压测分配CPU资源（其实是taskset进行绑核，由于没有其他负载可以近似为分配CPU资源），本文继续介绍下如何让压测变得更真实一点，那就是网络IO这块，在本地通信时往往使用的是loopback接口，但是loopback并不是一个真实的网卡设备，它基本没有什么硬件网卡设备的传输速率的限制，也没有网络传输过程中的传输延迟。
这样的话，我们在压测的时候，网络方面的开销就几乎体现不出来，比如说，你想看下在4g网络下客户端、服务器之间网络通信数据包多大时打开数据压缩更有价值……
在我的测试过程中我希望能尽可能简化测试工作的同时，也能保证该有的环境的真实性，于是就有了本文对loopback接口的一点探索。
认识本地lo # Linux中的Loopback接口是一个虚拟网络接口，允许在同一主机上运行的应用程序之间通信。它通常被称为“lo”接口，具有IP地址127.0.0.1。
Loopback接口在内核中使用Loopback驱动程序实现，创建一个虚拟网络接口，并将所有传入的数据转发到本地协议栈。当一个应用程序将数据发送到loopback接口时，数据会被回送到协议栈，并像从另一个网络接口到达一样转发。 在Linux中，Loopback接口的一个重要用例是用于测试和调试网络应用程序。通过通过Loopback接口发送和接收数据，应用程序可以模拟网络流量，而不实际发送或接收来自物理或虚拟网络接口的数据。
Loopback接口还由一些网络协议使用，例如Kubernetes kube-proxy IPVS，OSPF和其他需要在同一主机上的进程之间通信的网络相关软件。
总之，Linux中的Loopback接口是一个虚拟网络接口，为在同一主机上运行的应用程序提供了一种通信通道。它在内核中使用Loopback驱动程序实现，并且在测试、调试和网络相关软件中具有许多实际用例。
认识netem # 在 Linux 中，ip 命令中的 netem 是一个网络模拟工具。它允许您对网络连接进行各种修改，例如，添加延迟、丢包以及增加噪声等，以便在网络环境下测试应用程序的性能和稳定性。使用 netem 工具，您可以模拟各种不同的网络条件，包括高延迟、高带宽和低带宽等，以便更好地测试和优化应用程序在各种网络条件下的行为。
Netem 已经成为 Linux 网络模拟和测试工具的标准选择之一，同时也是在诸如交换机、路由器和 WAN 加速器等网络设备上进行隔离测试和仿真时的一个有用工具。通过使用 netem，您可以更好地了解您的应用程序在不同网络条件下的行为，并且能够更好地进行演示和培训。
利用本地lo # 如何使用netem让本地loopback接口更好地模拟真实网络情况呢？下面就来简单说一下。
启用netem # 首先，需要启用内核模块netem：
sudo yum install -y kmod sudo modprobe sch_netem 模拟网络延迟 # 然后，如果loopback接口的每次的收、发操作模拟一定的网络延迟：
sudo yum install iproute-tc or sudo yum install iproute sudo tc qdisc add dev lo root netem delay 1ms 这样的话就相当于一个rtt增加了2ms，为了验证这个，你可以在执行上述模拟前后，分别看下ping localhost的延迟。</description></item><item><title>压测之taskset的妙用</title><link>/blog/2023-04-13-%E5%8E%8B%E6%B5%8B%E4%B9%8Btaskset%E7%9A%84%E5%A6%99%E7%94%A8/</link><pubDate>Thu, 13 Apr 2023 03:22:15 +0800</pubDate><guid>/blog/2023-04-13-%E5%8E%8B%E6%B5%8B%E4%B9%8Btaskset%E7%9A%84%E5%A6%99%E7%94%A8/</guid><description>问题背景 # 想测试下gRPC框架的性能，设计了如下服务拓扑来对gRPC框架各组件、特性、参数配置下的性能进行探索。
压力源程序 perfclient ---请求-&amp;gt; perfserver1 ---请求-&amp;gt; perfserver2 压力源程序perfclient会并发发送请求给服务perfserver1，perfserver1则会继续请求perfserver2，然后perfserver2回包给perfserver1，perfserver1收到响应后内部完成处理逻辑后继续回包给perfclient。
perfclient每隔一段时间会打印下请求的请求量、成功量、失败量，以及qps、耗时信息。需要注意的事，这里再统计耗时信息的时候，除了avg、min、max耗时，还需要percentile(or quantile）百分位耗时，后者更具有说服力。
现在呢？遇到点问题，正常我需要将上述压力源程序、被压测服务perfserver1、perfserver2尽力部署到不同的机器上，让它们之间避免相互影响，同时部署的机器上也应该注意没有其他负载会干扰到我们的测试，但是问题来了：
可能有机器，但是部署起来太麻烦了，可能每调整下测试点就要要操作多台机器 可能有机器，但是云平台存在超卖的情况，母机负载大影响到了虚拟机负载稳定性 可能有机器，但是ci/cd流水线执行耗时太久了 可能没机器，只有一台本地开发机 有没有什么其他简单好用的办法呢？我觉得有，资源隔离下啊。
认识taskset # taskset，是linux下用来进行绑核设置的一个工具，我们可以借助它对上述不同的3个进程的cpu资源进行限定，如压力源程序perfclient需要能多生成些请求，我们给它分配7~10 4个cpu core，perfserver1负载会稍微比perfserver2高点，但如果是纯echo的话也多不了读少，给perfserver1分配2个cpu core，给perfserver2也分2个。
taskset -a -p 7,8,9,10 `pidof perfclient` taskset -a -p 3,4 `pidof perfserver1` taskset -a -p 5,6 `pidof perfserver2` 这样上述几个进程就被分别设置到了不同的cpu cores上执行，意味着当他们把cpu跑满时，他们能抗的负载大致就是这个比例。
解释下选项-a：
taskset如果不指定选项-a，则知会对当前进程名对应的主进程进行绑核设置，不会对进程中的其他线程进行设置，当然也不会对后续新创建的线程进行设置。
加了-a，taskset就会对执行命令时，该进程pid下的所有线程进行统一的绑核设置，但是如果后续创建了新线程，新线程不会被绑核。
那么如果一个程序是多线程程序，且线程数不是固定的，会在以后新创建、销毁动态变化的，这种该怎么解决呢？
go天然多线程 # go程序天然是多线程程序，那应该如何进行绑核设置呢？如果只是为了限制进程使用的cpu资源，直接使用runtime.GOMAXPROC(x)进行设置不行吗？不行！
该函数只是说限制同时在运行的线程数，并没有像taskset那样将线程绑到核上，这意味着这些go程序线程的执行有可能会在cpu core上迁移，这样的话通过top命令查看cpu core负载情况，就不好判断哪个core的负载是因为哪个进程引起的…对吧。
另一个问题，go程序的GMP调度模型会在必要时自动创建新的线程出来，用来执行goroutines，这里问题就来了，我需要动态感知当前进程下的所有线程。go语言或者标准库都没有提供线程层面的东西来获取，那我们怎么获取呢？
go如何绑核 # Linux下面每个进程都有一个pid，对应的虚拟文件系统/proc//tasks下面就是该进程pid下的所有线程信息。理论上可以定时获取里面的pid，然后再去taskset -p绑核，或者说go启动一个协程定时调用下taskset -a -p &amp;lt;pid&amp;gt;，可以简洁明了搞定。</description></item><item><title>Linux内核学习资料</title><link>/blog/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/</link><pubDate>Sat, 02 Jul 2022 14:39:04 +0800</pubDate><guid>/blog/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/</guid><description>现在学习Linux操作系统的人越来越多了，进一步学习Kernel的人也越来越多了，经常有人问起有没有质量好的、获得大家认可的学习资料论坛，尤其是对于学习内核的新手而言，能否获得这些好的学习资料还是很重要的。因为经常有人问起这个问题，所以在Linux源码随附的文档中，有专门一篇文档kernel-docs.rst专门整理罗列了适合大家学习Linux内核的文档、在线资源、出版书籍等，并逐一做了简要的描述。注意到其中有些资料是和具体内核模块相关的，如网络协议栈、中断子系统等，也适合有针对性地、深入地去学习。
本文剩余内容来自Linux内核文档 kernel-docs.rst，整理在此方便查阅参考。
Docs at the Linux Kernel tree # The Sphinx books should be built with make {htmldocs | pdfdocs | epubdocs}.
* Name: **linux/Documentation** :Author: Many. :Location: Documentation/ :Keywords: text files, Sphinx. :Description: Documentation that comes with the kernel sources, inside the Documentation directory. Some pages from this document (including this document itself) have been moved there, and might be more up to date than the web version. On-line docs # * Title: **Linux Kernel Mailing List Glossary** :Author: various :URL: https://kernelnewbies.</description></item><item><title>mac/win下linux c/c++开发</title><link>/blog/2022-06-28-linux-cc-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/</link><pubDate>Tue, 28 Jun 2022 23:08:51 +0800</pubDate><guid>/blog/2022-06-28-linux-cc-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/</guid><description>问题背景 # 我们很多人主力操作系统是macOS或者Windows，用Linux作为主力操作系统的少吧，不过之前确实有连续7年多是用Fedora作为主力操作系统 :)
现在很多人开发人员使用MacBook Pro作为自己的开发机，大厂标配，我们很多后台呢，开发的程序一般最后还是要跑在Linux系统上的，尤其是c/c++开发涉及到这里的跨平台开发的问题，很多开发人员用着非常原始的方式在开发，开发体验比较差。
借这个契机，我调研了下现在比较好的一些开发方式，总结分享下。
先定一个要实现的小目标：
能基于IDE进行开发，比如VSCode; 另外，编译构建必须能够 vscode: add dockerfile to workspace # 在vscode中cmd+p，输入add dockerfile to workspace并执行，此时会选择基础镜像，如面向c++开发的基础镜像，此时会生成默认的dockerfile。 然后在dockerfile选中后点击右键，选择build image，此时就完成镜像构建了，该默认dockerfile默认是一个编译镜像，里面包含了编译构建产物。 直接运行上述镜像默认就是运行程序，运行的方式可以在docker explorer里面找到镜像，右键菜单中选择Run，或者命令行执行。 这个镜像只是用来编译构建、测试运行的，还不能满足我们开发阶段的需求，因为开发阶段需要考虑头文件、库的搜索问题。
解决思路：
至少要构建一个支持开发的镜像，如c/c++镜像； 启动这个镜像，并将当前工程以volume的形式挂在到容器中，或者在容器中clone下来这个项目。提交代码要注意随时提交； 开发通过vscode remote连接到vscode server进行开发，其实是本地vscode通过ssh连接传输vscode server软件包到容器中并安装启动； 如果开发镜像支持类似WebIDE的方式进行开发，也可以代替3这种方式，只是一些本地vscode的快捷配置等可能不是很好同步。 docker desktop: New Dev environment # Docker Desktop的这种实现方式，就是上面提到的2\3这几步的组合，基本满足我们希望实现的目标了（支持开发容器Mount local directory或者容器中Clone git repository）。
这种方式也有不足，就是假设后续有人要接手这个项目，或者有人和你协作，你怎么办呢？ 我们可以直接提交一个镜像push到registry，他只要能拉代码，又能拉镜像就基本能还原之前的开发环境。
但是我为什么非要push一个镜像上去呢（包括自定义的基础镜像、开发阶段的分享镜像）？ 如果不push镜像而docker destop默认的开发镜像调整了或者我希望定制一个统一的怎么办？
Docker Desktop创建新的开发镜像的时候有一种方式，允许指定一个基础镜像，但是这个基础镜像要push到远程registry。代码会被clone到这个 容器内部，我们就通过vscode remote进行开发即可。
尽管vscode鼓励非Linux用户尽量通过这种方式，因为fs操作更快，但是还是有点不方便，因为这数据卷相当于额外浪费一份存储，考虑到之前已经克隆过的情况下。 有没有办法既能自定义基础镜像，又能挂载本地磁盘目录为数据卷的方式来解决呢？可以，请看方式3。
vscode: Remote-Containers # vscode中Command Pallete中Remote-Containers: Add Development Container Configuration Files，执行这个我们可以为工程指定一个配置文件.</description></item><item><title>Linux桌面发行版分享</title><link>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E5%88%86%E4%BA%AB/</link><pubDate>Sun, 26 Jun 2022 16:37:16 +0800</pubDate><guid>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E5%88%86%E4%BA%AB/</guid><description>Linux桌面发行版分享 # 这是一篇写在2016年的文章一直在我的个人笔记里，感觉当时很多想法今天依然成立，所以拿出来继续分享下。某些信息可能已经有过时，相关的部分我在备注里进行了标注，
0.体验Linux发行版 # 今天安装了Ubuntu 16.04 LTS，本来准备一直用Fedora的，但是我的笔记本上安装的还是 Fedora 21版本，但是当前最新的已经更新到了Fedora 24,今天刚刚发布了Beta版本。此 前我对Fedora 23 GA以及Fedora 24 Alpha版本进行了简单的测试，实在是不喜欢KDE 5！
怎么说呢，其实看上去KDE 5挺漂亮的，应该将来也会有不错的发展，但是考虑到KDE 5刚 出来的时间还不够长，其中很多在KDE 4里面方便实用的功能在KDE 5中还没有被开发出来 ，而我又是一个倾向于“工欲善其事，必先利其器”的同学，让我这样把一个未充分完善好 的桌面环境当做自己的主力系统，我实在难以接受！对于GNOME 3，我就不做任何评论了 ，我宁可用Ubuntu Unity也不用GNOME 3！
可能有人说，没必要一直跟着更新啊，继续实用Fedora 21也可以啊！？此话当然不假， 可是一个失去后续更新支持的版本，我想还是要继续跟进新版本要更好。其实我现在配置 的已经相当棒了，有的软件源里面的程序存在某些小问题，瑕不掩瑜的，我也对其源代码 进行了部分修改，以为自己所用，因为这部分工作还是相当多、相当细的，如果继续跟进 新的发行版，而软件源里面的软件包可能还没有修改过来，或者不符合我的需要，又要进 行重复性的工作，我觉得这个工作量还是蛮大的，至少现在我没有那么充足的时间。
Fedora发行版每6个月更新一次，CentOS 7可以支持10年，我本来也计划使用CentOS的， 但是CentOS对稳定性的追求，也使得很多软件包不能被加入其软件源，有些我很喜欢的工 具，安装、配置起来就会比较麻烦，dpkg、alien、rpmrebuild甚至修改源代码这些可能 都要用到，以配置出一个趁手的系统环境。半年前，我在另一台三星的笔记本安装了 CentOS 7，配置完成之后，堪称完美，那个时候时间多啊，折腾的时间也挺长的；现在时 间没有那么充裕了，我在这台thinkpad上安装了CentOS 7.2，前后也就折腾了一天，不打 算折腾了。
最后，我选择了Ubuntu 16.04 LTS版本，可以支持5年，而我本身也想重新比较一下 Ubuntu、Fedora这两大发行版，为什么呢？因为对这两款发行版，我都有向当长的使用时 间，现在也积累了很多的经验，前不久我碰巧又看到了一个各大发行版性能对比的文章， 其中Debian系列的性能要明显优于RHEL系列，原因我暂时也不是特别清楚，这也是激发我 重新选择Ubuntu的原因之一。我希望在使用过程中，重新比较一下Ubuntu和Fedora这两大发行版的差异，例如包管理工具的差异、软件包中的配置文件的差异、系统管理方面的差 异，此外呢，我也希望能够对其性能上的差异进行一下更深的认识。
1.系统安装过程 # 系统安装过程，应该说是驾轻就熟了，下载一个Ubuntu 16.04 LTS的ISO文件，然后使用 Unetbootin制作一个可以引导系统安装的U盘。U盘要格式化成FAT32格式，且要根据需要 预留一定的存储空间，以供安装过程中释放文件使用，如果预留空间不足，可能导致安装 失败。
制作完成安装U盘之后，插入电脑，关闭BIOS中的UEFI引导模式，然后从USB HDD启动安装即可。安装的时候手动分区，最好能够把那些第三方软件包给安装上，这样省的后续安装 ，省心。我是深有体会，之前安装音频、视频播放器的时候，安装解码库浪费了很多时间 。安装过程中有个别地方需要设置一下，例如用户名、密码、语言、地区、时间等等的。
注意，Ubuntu在安装过程中不会对root用户的密码进行设置，并且默认将新建的用户加入 wheel组中！但是在Fedora安装过程中，会对root密码进行设置，然后再创建一个新用户 ，并允许选择是否将该用户加入wheel组中，还可以指定uid、gid等。这是一个区别，需 要注意一下，安装完成之后，需要通过“passwd root”对密码进行重新设定。</description></item><item><title>聊聊伴我多年的老友，Linux</title><link>/blog/2017-03-13-%E8%81%8A%E8%81%8A%E4%BC%B4%E6%88%91%E5%A4%9A%E5%B9%B4%E7%9A%84%E8%80%81%E5%8F%8Blinux/</link><pubDate>Mon, 13 Mar 2017 21:00:00 +0800</pubDate><guid>/blog/2017-03-13-%E8%81%8A%E8%81%8A%E4%BC%B4%E6%88%91%E5%A4%9A%E5%B9%B4%E7%9A%84%E8%80%81%E5%8F%8Blinux/</guid><description>1 邂逅Linux # 初次接触Linux操作系统是在什么时候？想想～～
高三毕业后买了第一台电脑，一台清华同方的台式机，随机赠送的光盘里面有一张操作系 统光盘“家电下乡Linux适农版”……那是我第一次接触并运行Linux，但那时的我并没有意识 到，放在我面前的是一个即将深深地吸引我并要在多年的职业生涯中去不断锤炼的存在。
大一、大二这两年，我或多或少地接触到了Linux，但是并没有产生多大兴趣，直到有一 天我激怒了一个同学。当时他正在摆弄Ubuntu，错误地GRUB配置导致系统引导失败，着急 的他在QQ空间发了一条状态，意思就是大神求救之类的。当时我回了一个字“水”。他看后 很生气，系统都启动不了了能不着急吗？于是呢，就言辞激烈地“回敬”了我几句……
事后我想，Linux有这么复杂吗？于是我开始试图取了解Linux，当然这只是个引子，后面 陆陆续续看到有不少同学都在使用各种Linux的发行版，我才决定认真去了解、学习一下 Linux，没想到这竟是一条不归路……
LiveCD &amp;amp; RemasterSys &amp;amp; dump &amp;amp; restore GRUB 2 &amp;amp; Customize Boot Menu to bootstrap Multiple OS Plymouth Tweak KDE/GNOME/Unity Appearance (Colors &amp;amp; Themes) Linux Commandline Techs &amp;amp; Administration Unix/Linux Programming Linux Kernel 0.11 Linux Kernel 2.4 Keep going along the roadmap to Linux World! 上面大体上是我初识、折腾、学习、应用、研究Linux的过程，而且这个过程在相当长一 段事时间内还将一直向前延伸下去。与其说对Linux感兴趣，不如说是好奇心驱使，还有 很多疑问没有揭开，这里当然不只是Linux操作系统内核本身。
我这个博客所要描述的东西可能就比较杂了，这里面我会穿插着记录很多东西～与其说是 博客，不如说是我自己的一个学习笔记了，但是我这个人比较喜欢分享，但有不想那么刻 意，所以我就把它丢在这，谁看见了找到点自己感兴趣的东西，也算是种缘分。
2 LiveCD &amp;amp; RemasterSys &amp;amp; dump &amp;amp; restore # 2.</description></item><item><title>Linux桌面发行版分享</title><link>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E4%BD%93%E9%AA%8C/</link><pubDate>Sat, 07 May 2016 00:23:47 +0800</pubDate><guid>/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E4%BD%93%E9%AA%8C/</guid><description>Linux桌面发行版分享 # 这是一篇写在2016年的文章一直在我的个人笔记里，感觉当时很多想法今天依然成立，所 以拿出来继续分享下。某些信息可能已经有过时，相关的部分我在备注里进行了标注，
0.体验Linux发行版 # 今天安装了Ubuntu 16.04 LTS，本来准备一直用Fedora的，但是我的笔记本上安装的还是 Fedora 21版本，但是当前最新的已经更新到了Fedora 24,今天刚刚发布了Beta版本。此 前我对Fedora 23 GA以及Fedora 24 Alpha版本进行了简单的测试，实在是不喜欢KDE 5！
怎么说呢，其实看上去KDE 5挺漂亮的，应该将来也会有不错的发展，但是考虑到KDE 5刚 出来的时间还不够长，其中很多在KDE 4里面方便实用的功能在KDE 5中还没有被开发出来 ，而我又是一个倾向于“工欲善其事，必先利其器”的同学，让我这样把一个未充分完善好 的桌面环境当做自己的主力系统，我实在难以接受！对于GNOME 3，我就不做任何评论了 ，我宁可用Ubuntu Unity也不用GNOME 3！
可能有人说，没必要一直跟着更新啊，继续实用Fedora 21也可以啊！？此话当然不假， 可是一个失去后续更新支持的版本，我想还是要继续跟进新版本要更好。其实我现在配置 的已经相当棒了，有的软件源里面的程序存在某些小问题，瑕不掩瑜的，我也对其源代码 进行了部分修改，以为自己所用，因为这部分工作还是相当多、相当细的，如果继续跟进 新的发行版，而软件源里面的软件包可能还没有修改过来，或者不符合我的需要，又要进 行重复性的工作，我觉得这个工作量还是蛮大的，至少现在我没有那么充足的时间。
Fedora发行版每6个月更新一次，CentOS 7可以支持10年，我本来也计划使用CentOS的， 但是CentOS对稳定性的追求，也使得很多软件包不能被加入其软件源，有些我很喜欢的工 具，安装、配置起来就会比较麻烦，dpkg、alien、rpmrebuild甚至修改源代码这些可能 都要用到，以配置出一个趁手的系统环境。半年前，我在另一台三星的笔记本安装了 CentOS 7，配置完成之后，堪称完美，那个时候时间多啊，折腾的时间也挺长的；现在时 间没有那么充裕了，我在这台thinkpad上安装了CentOS 7.2，前后也就折腾了一天，不打 算折腾了。
最后，我选择了Ubuntu 16.04 LTS版本，可以支持5年，而我本身也想重新比较一下 Ubuntu、Fedora这两大发行版，为什么呢？因为对这两款发行版，我都有向当长的使用时 间，现在也积累了很多的经验，前不久我碰巧又看到了一个各大发行版性能对比的文章， 其中Debian系列的性能要明显优于RHEL系列，原因我暂时也不是特别清楚，这也是激发我 重新选择Ubuntu的原因之一。我希望在使用过程中，重新比较一下Ubuntu和Fedora这两大 发行版的差异，例如包管理工具的差异、软件包中的配置文件的差异、系统管理方面的差 异，此外呢，我也希望能够对其性能上的差异进行一下更深的认识。
1.系统安装过程 # 系统安装过程，应该说是驾轻就熟了，下载一个Ubuntu 16.04 LTS的ISO文件，然后使用 Unetbootin制作一个可以引导系统安装的U盘。U盘要格式化成FAT32格式，且要根据需要 预留一定的存储空间，以供安装过程中释放文件使用，如果预留空间不足，可能导致安装 失败。
制作完成安装U盘之后，插入电脑，关闭BIOS中的UEFI引导模式，然后从USB HDD启动安装 即可。安装的时候手动分区，最好能够把那些第三方软件包给安装上，这样省的后续安装 ，省心。我是深有体会，之前安装音频、视频播放器的时候，安装解码库浪费了很多时间 。安装过程中有个别地方需要设置一下，例如用户名、密码、语言、地区、时间等等的。
注意，Ubuntu在安装过程中不会对root用户的密码进行设置，并且默认将新建的用户加入 wheel组中！但是在Fedora安装过程中，会对root密码进行设置，然后再创建一个新用户 ，并允许选择是否将该用户加入wheel组中，还可以指定uid、gid等。这是一个区别，需 要注意一下，安装完成之后，需要通过“passwd root”对密码进行重新设定。</description></item><item><title>Linux内核文档索引</title><link>/blog/2014-10-24-linux%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3%E7%B4%A2%E5%BC%95/</link><pubDate>Fri, 24 Oct 2014 00:10:00 +0800</pubDate><guid>/blog/2014-10-24-linux%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3%E7%B4%A2%E5%BC%95/</guid><description>迁移自 hitzhangjie/Study 项目下的内容，本文是看内核源码时对文档的一个阅读、内容总结。
============================================================================= Fri Sep 18 12:23:06 CST 2014 # Documentation/
[1] zorro.txt zorro bus ii\iiioZorro II is the name of the general purpose expansion bus used by the Amiga 2000 computer. The bus is mainly a buffered extension of the Motorola 68000 bus, with support for bus mastering DMA. The expansion slots use a 100-pin connector and the card form factor is the same as the IBM PC. Zorro II cards implement the Autoconfig protocol for automatic address space assignment (designed before, yet similar to, Plug and Play on the PC).</description></item><item><title>Linux内联汇编基础</title><link>/blog/2014-10-01-linux%E5%86%85%E8%81%94%E6%B1%87%E7%BC%96%E5%9F%BA%E7%A1%80/</link><pubDate>Wed, 01 Oct 2014 00:16:34 +0800</pubDate><guid>/blog/2014-10-01-linux%E5%86%85%E8%81%94%E6%B1%87%E7%BC%96%E5%9F%BA%E7%A1%80/</guid><description>迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是阅读内核源码《Linux内核源码情景分析》时对内联汇编的一些总结。
1.full template __asm__(assembler template :output operands /* optional */ :input operands /* optional */ :list of clobbered registers /* optional */ ); 2.x86 registers eax,ebx,ecx,edx edi,esi ebp,esp eip eflags 3.linux代码中很多地方都使用了这种形式的汇编语言，嵌入汇编程序的格式如下： __asm__ __volatile__ ( asm statements : outputs : inputs : registers-modified ); asm statements是一组AT&amp;amp;T格式的汇编语言语句，每个语句一行，由\n分隔各行。所有的语句都被包裹在一对双引号内。其中使用的寄存器前面要加两个%%做前缀(%n表示参数,n:数字)；转移指令多是局部转移，因此多使用数字标号。 inputs指明程序的输入参数，每个输入参数都括在一对圆括号内，各参数用逗号分开。每个参数前加一个用双引号括起来的标志，告诉编译器把该参数装入到何处。 可用的标志有： “g”：让编译器决定如何装入它； “a”：装入到ax/eax； “b”：装入到bx/ebx； “c”：装入到cx/ecx； “d”：装入到dx/edx； “D”：装入到di/edi； “S”：装入到si/esi； “q”：a、b、c、d寄存器等； “r”：任一通用寄存器； “i”：整立即数； “I”：0-31 之间的立即数（用于32位移位指令）； “J”：0-63 之间的立即数（用于64 位移位指令）； “N”：0-255 ，之间的立即数（用于out 指令）； “n”：立即数，有些系统不支持除字以外的立即数，这些系统应该使用“n”而不是“i”； “p”：有效内存地址； “m”：内存变量； “o”：操作数为内存变量，但是其寻址方式是偏移量类型，也即是基址寻址，或者是基址加变址寻址； “V”：操作数为内存变量，但寻址方式不是偏移量类型； “,”：操作数为内存变量，但寻址方式为自动增量； “X”：操作数可以是任何类型； “f”：浮点数； “t”：第一个浮点寄存器； “u”：第二个浮点寄存器； “G”：标准的80387； % ：浮点常数,该操作数可以和下一个操作数交换位置； “=”：输出； “+”：既是输入又是输出； “&amp;amp;”：改变其值之前写,分配一个独立的寄存器,使得函数返回值和该变量不因为重复使用同一个寄存器,出现数据覆盖； “%”：与下一个操作数之间可互换； “#”：忽略其后的字符，直到逗号； “*”：当优先选择寄存器时，忽略下面的字符； “0”~“9”：指定一个操作数，它既做输入又做输出。通常用“g”； outputs指明程序的输出位置，通常是变量。每个输出变量都括在一对圆括号内，各个输出变量间用逗号隔开。每个输出变量前加一个标志，告诉编译器从何处输出。 可用的标志与输入参数用的标志相同，只是前面加“=”。如“=g”。输出操作数必须是左值，而且必须是只写的。如果一个操作数即做输出又做输 入，那么必须将它们分开：一个只写操作数，一个输入操作数。输入操作数前加一个数字限制（0~9），指出输出操作数的序号，告诉编译器它们必须在同一个物 理位置。两个操作数可以是同一个表达式，也可以是不同的表达式。 registers-modified告诉编译器程序中将要修改的寄存器。每个寄存器都用双引号括起来，并用逗号隔开。如“ax”。如果汇编程 序中引用了某个特定的硬件寄存器，就应该在此处列出这些寄存器，以告诉编译器这些寄存器的值被改变了。如果汇编程序中用某种不可预测的方式修改了内存，应 该在此处加上“memory”。这样以来，在整个汇编程序中，编译器就不会把它的值缓存在寄存器中了。 如: “cc”：你使用的指令会改变CPU的条件寄存器cc； “memory”：你使用的指令会修改内存； __volatile__是可选的，它防止编译器修改该段汇编语句（重排序、重组、删除等）。 输入参数和输出变量按顺序编号，先输出后输入，编号从0开始。程序中用编号代表输入参数和输出变量（加%做前缀）。 输入、输出、寄存器部分都可有可无。如有，顺序不能变；如无，应保留“：”，除非不引起二意性。 看一个在C语言中使用at&amp;amp;t的嵌入汇编程序的例子，c语言中的3个int变量，一般会是三个内存地址。每个操作数的长度则要根据操作系统和编译器来决定，一般32位操作系统为32位，则每个操作数占用4个字节： int i=0, j=1, k=0; __asm__ __volatile__(&amp;quot; pushl %%eax\n //asm statement movl %1, %%eax\n //asm statement addl %2, %%eax\n //asm statement movl %%eax, %0\n //.</description></item></channel></rss>