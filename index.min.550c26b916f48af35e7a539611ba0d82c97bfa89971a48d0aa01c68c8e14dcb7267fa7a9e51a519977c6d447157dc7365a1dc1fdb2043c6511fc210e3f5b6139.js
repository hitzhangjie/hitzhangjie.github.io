var suggestions=document.getElementById('suggestions'),search=document.getElementById('search');search!==null&&document.addEventListener('keydown',inputFocus);function inputFocus(a){a.ctrlKey&&a.key==='/'&&(a.preventDefault(),search.focus()),a.key==='Escape'&&(search.blur(),suggestions.classList.add('d-none'))}document.addEventListener('click',function(a){var b=suggestions.contains(a.target);b||suggestions.classList.add('d-none')}),document.addEventListener('keydown',suggestionFocus);function suggestionFocus(c){const d=suggestions.classList.contains('d-none');if(d)return;const a=[...suggestions.querySelectorAll('a')];if(a.length===0)return;const b=a.indexOf(document.activeElement);if(c.key==="ArrowUp"){c.preventDefault();const d=b>0?b-1:0;a[d].focus()}else if(c.key==="ArrowDown"){c.preventDefault();const d=b+1<a.length?b+1:b;a[d].focus()}}(function(){var a=new FlexSearch.Document({tokenize:function(a){return a.split(/\W+/).concat(a.replace(/[\x00-\x7F]/g,'').split('')).filter(a=>!!a)},cache:100,document:{id:'id',store:["href","title","description"],index:["title","description","content"]}});a.add({id:0,href:"/categories/",title:"Categories",description:"",content:""}),a.add({id:1,href:"/tags/cfs/",title:"cfs",description:"",content:""}),a.add({id:2,href:"/tags/fair/",title:"fair",description:"",content:""}),a.add({id:3,href:"/tags/gmp/",title:"gmp",description:"",content:""}),a.add({id:4,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A68/",title:"Linux任务调度(8): 任务越多调度就越频繁吗",description:"前面几篇文章介绍了Linux下调度器的演进过程，也对CFS调度器的大致工作原理进行了介绍，也从源码层面进行了深度剖析。本文继续探讨个项目中服务混部的困扰，当线程数多了之后，线程切换频率会上升吗？",content:"Linux任务调度(8): 任务越多调度就越频繁吗 # 本文将讲述一个曾经困扰在我们项目组心头的关于go进程混部时的担忧，以及由此引出的多进程混部时的隔离性问题。比如，个别程序不健壮创建大量进程，是否会推高上下文切换次数导致无谓的CPU开销的问题。我们将结合工具perf、bpftrace来深入观察并分析，以加深了对真实负载场景下任务调度的深层理解。\nGo运行时引发的思考 # 一个线上问题 # 对CFS的深入思考，一个直接原因是因为go程序中GOMAXPROCS设置不合理，母机上有128个CPU核心，但是虚拟化技术下容器里分配的只有2个cpus。\n此时go进程检测到GOMAXPROCS=128（go不会自动感知到实际上只分配了2个cpus），此时runtime会误认为最多可以创建128个P（GMP中的P，Processor），后果就是进程中最多会创建128个P。比如随着goroutines增多如果当前P处理不过来，就会激活更多的空闲P，对应的创建更多的线程M并轮询绑定的P上的的localrunq、全局的globalrunq以及定时器事件、网络IO事件就绪的goroutines并调度。这里的轮询操作就会导致较高的CPU开销，容易导致CPU throttling（节流）从而导致程序性能下降。\nGMP调度是如何初始化的 # go运行时是这样创建GMP的\n 进程启动的时候会根据GOMAXPROCS先创建出对应数量的P，详见 schedinit()-\u0026gt;procresize()，但是还是没有创建M个这么多线程的； 上述创建出来的一堆P，除了当前g.m.p是在用状态，其他都是idle状态；M也不会预先创建出来，而是根据设计负载情况动态去创建、去激活P去执行的； 具体来说就是当创建一堆goroutines后，这些goroutine会先往 p.runq放，放不下了就会考虑 injectglist(...)，这个其实就是放到全局队列 sched.runq，放的时候：  如果当前M有关联一个P，就先放 npidle个G到 sched.runq，并且启动 npdile个M去激活 npdile个P，去尝试从goroutine抢G然后执行。然后剩下的放到 p.runq； 如果当前M没有关联一个P，这种情况下怎么会发生呢（有多种情况可能会发生，比如GC、系统调用阻塞、初始化阶段等）？这种情况下会全部放到 sched.runq，然后启动最多npidle个（即 min(goroutineQSize, npdile)）个M去激活P并执行；    简单总结就是：“如果短时间内创建大量goroutines，当前p.runq full（或者M解绑了P）就会往sched.runq放。然后会启动最多npidle个M去抢P激活，然后workstealing的方式从sched.runq抢goroutines执行。”\n如果这种情况一旦出现了，这些大量创建出来的M，后续无goroutines执行时，也会不断地执行一些轮询 p.runq、sched.runq、netpoller、stealing、timer事件，这个无谓的轮询过程中就容易推高CPU占用。而实际的 --cpus 配额很少，就更容易达到CPU配额限制，进而被虚拟化管理软件给节流（CPU throttling），进而导致程序性能出现整体性的下降 (程序正常逻辑还没怎么执行，全被这些多出来的M轮询消耗掉了)。\n一时负载高创建的M能退出吗 # 那有没有办法，让这些创建出来的大量M退出呢？创建出来的M退出只有一种办法，runtime.LockOSThread()，这种情况下，goroutine会和M绑定，goroutine执行完毕退出时，M也会被销毁。但是正常情况下是不会调用这个函数的（调试器tracer会调用该函数），所以多创建出来的M不会退出，进而就导致了这里的问题。\n实际上，go程序中解决这个问题，很简单，读取下cgroups的cpu配额即可。可以直接 import _ \u0026quot;github.com/uber-go/automaxprocs\u0026quot; 来解决。\n更多任务会导致更频繁上下文切换吗 # 上面go运行时错误设置GOMAXPROCS导致过多P、M创建出来导致了轮询的CPU开销，这个点我们已经明确了，并且了解到了对应的解决方案。\n我们还有一个顾虑：\n1）同一个机器上，有多个进程，其中一个go进程因为上述原因创建了大量的线程，CFS调度器任务切换频率会不会也被推高？我们都知道上下文切换有开销。 2）同一个机器上，如果有多个进程，如果我想避免某个进程对其他进程的影响，或者某个用户下的所有进程对其他用户下的进程的影响？该如何做。\n这几个问题，其实就是我深入研究CFS调度器的根本原因，因为我像搞明白混部的影响及问题边界，这对保证服务乃至系统的可用性至关重要。当然你可以不混部来绕过这些弯弯绕绕的细节。\n让我来尝试会大下上面两个问题，其中2）我们已经知道了，CFS可以通过组调度来解决这类问题，但是不会自动构建不同用户的任务组，一个进程包括多个线程也不会作为一个任务组进行限制，可以理解成系统默认有更多线程有更多处理能力，除非你们的系统管理员显示设置。\nOK, 那现在，我们只需要搞清楚1），如果任务数增多会导致上下文切换更频率吗？\n假设CFS的设计实现果真如此，那这就是个巨大的风险点。现代Linux系统可以创建非常多的任务出来。现代Linux系统不是早些年的时候由CS 13bits索引范围限制了GDT/LDT表长度了，2^13/2=4096个进程（每个进程占GDT表的2项），早期版本最多支持这么多个任务。但是后面Linux版本对此做了修改，解除了这里的限制。每个处理器核心只在GDT中记录它当前运行的任务的表项信息，而任务队列则交给每个处理器核心的cfs_rq，可以创建的任务数量不再受CS 13bits索引、GDT/LDT表长度限制了。Linux系统可以支持的任务数只受限于pid_max、内核配置项、系统资源了。\n而如果随着任务数增多，上下文切换频率就变高，这样大量的CPU资源会被浪费在上下文切换上。所以调度器是绝对不会这样实现的，这种设计太蠢了。如果任务数很多，我们可以接受不饿死的前提下、允许一定的调度延时、允许降低一定的交互性，但是不能降低系统调度的吞吐量、不能导致CPU资源巨大浪费、完全不可用。\n所以我们的判断应该是，No！更多任务不会导致更频繁的上下文切换！这里的更多任务是指的非常多任务，而不是说从1到2，从2到4，从4到8，从8到16，从16到32这种程度，我们讨论的是从128到256，从1024到2048，从2048到4096这种程度。\n谨慎评估下上下文切换频率 # 根据前面的介绍，任务切换 __schedule(preempt)的时机有3个，任务阻塞主动让出CPU、任务抢占、任务唤醒被重新加入run-queue。结合我们下面的测试用例，任务阻塞到被唤醒，我们创建的线程不会主动阻塞，只会被抢占，所以我们只需要分析任务抢占这个路径即可，scheduler_tick()-\u0026gt;task_tick()-\u0026gt;check_preempt_tick()，这里面会检查当前任务是否应该被抢占，发生抢占才会发生上下文切换。\n但是： 1）其他任务可能会涉及到阻塞、唤醒，也会涉及到奖励、惩罚导致的动态优先级、动态时间片调整。 2）我们创建的线程也是系统的一部分，它的时间片也会因为其他进程动态优先级变化而变化。 3）而且即使我们确定了任务的执行时间片，抢占检测时，只要有vruntime比它小一个时间片的，就可以被抢占，不一定执行完自己的时间片。\n所以要说我们的程序一秒钟会上下文切换多少次？因为整个系统是动态的，真的没那么好推算。\n那我们能否先简化下这个量化模型，姑且认为： 1）所有任务的静态优先级（nice值）相同，也都不是交互式任务（动态优先级都是0），最终他们优先级一样； 2）最终从优先级转换为的权重也应该一样； 3）那么这样计算出的动态时间片也应该一样； Ok，那时间片长度是如何计算的？sched_slice来计算动态时间片，大致计算方式是:\n u64 slice = __sched_period(cfs_rq-\u0026gt;nr_running + !se-\u0026gt;on_rq); slice = __calc_delta(slice, se-\u0026gt;load.weight, load);  第1步__sched_period计算的是调度周期：1）nr_running\u0026lt;=8时，固定6ms；2）nr_running\u0026gt;8时，等于nr_running0.75ms； 第2步 __calc_delta按当前任务贡献的全局权重来瓜分调度周期，作为该任务的时间片； 每个任务的时间片 = nr_running3ms * (1/nr_running)=3ms，对吗？ 那上下文切换频率 = 1000ms/3ms = 333.3 次/s，对吗？\n这个值，可能过于理想了，如果是写个cfs调度算法，输入是一堆优先级完全相同的任务，可能抛出来结果是这样的，但是真实系统中存在各种IO任务（交互式任务）、不同优先级任务、任务创建销毁等情况，这些都会反过来影响调度，所以实际测试跑出来的结果可能与这里的分析差的非常远。我们还是实测下，然后从测试结果来反推、来理解下吧。\n实际测试下 # 测试环境说明:\n注意在Linux v5.13版本，调度器内核参数位置作了修改，sysctl -a看不到调度器相关的参数了。实际上是做了调整，以前的 kernel.sched_xxx 相关参数被移动到了 /sys/kernel/debug/sched/ 下面，比如 kernel.sched_latency_ns 对应的就是 /sys/kernel/debug/sched/latency_ns。\n另外几个关键配置的默认值也做了修改，在内核版本 v5.12中:\nkernel.sched_latency_ns = 6000000 // 6ms kernel.sched_min_granularity_ns = 750000 // 0.75ms  从v5.13开始：\nkernel.sched_latency_ns = 24000000 // 24ms kernel.sched_min_granularity_ns = 3000000 // 3ms  我用来测试的版本是v5.15，配置值同v5.13：\n$ uname -r 5.15.90.1-microsoft-standard-WSL2+  测试步骤：\n 我们写个工具测试下，thread_test.c：  #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;pthread.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; // Thread function void *thread_func(void *arg) { long long i = 0; while (1) { i++; // Simple increment operation } return NULL; } int main(int argc, char *argv[]) { if (argc != 2) { printf(\u0026quot;Usage: %s -n \u0026lt;thread_count\u0026gt;\\n\u0026quot;, argv[0]); return 1; } int thread_count = atoi(argv[1] + 2); // Skip \u0026quot;-n\u0026quot; if (thread_count \u0026lt;= 0) { printf(\u0026quot;Invalid thread count: %d\\n\u0026quot;, thread_count); return 1; } pthread_t *threads = malloc(thread_count * sizeof(pthread_t)); if (!threads) { perror(\u0026quot;Failed to allocate memory for threads\u0026quot;); return 1; } printf(\u0026quot;Creating %d threads...\\n\u0026quot;, thread_count); // Create threads for (int i = 0; i \u0026lt; thread_count; i++) { if (pthread_create(\u0026amp;threads[i], NULL, thread_func, NULL) != 0) { perror(\u0026quot;Failed to create thread\u0026quot;); free(threads); return 1; } } printf(\u0026quot;Threads created. Press Ctrl+C to exit...\\n\u0026quot;); // Wait indefinitely (or until Ctrl+C) while (1) { sleep(1); } // This code is unreachable but included for completeness free(threads); return 0; }  编译构建：gcc -o thread_test thread_test.c -lpthread。 然后为了避免其他机器进程的影响，我们使用docker来隔离下环境，然后在docker容器里观察该进程下所有线程的上下文切换次数：  shell1:\n# 先创建容器，分配一个cpu减少多核负载均衡影响 docker run --name linux101 --rm -it -v .:/workspace --cpus=1 --cap-add SYS_ADMIN hitzhangjie/linux101:latest /bin/bash # 启动进程 cd /workspace ./thread_test -n1 #逐渐增大到2,3,4,5,8,16,32,64,128,256,512,1024,2048,4096等分别观察  shell2:\n# 先进入容器 docker exec linux101 -it /bin/bash` # perf观察，每1s输出一次结果 yum install perf perf stat -e context-switches -I 1000 -p `pidof thread_test`  逐渐增大thread_test -n\u0026lt;?\u0026gt;的参数值，观察线程数增大时，perf观察到的上下文切换频率的变化。  预期结果:\n我推测单处理器核心上下文切换频率最高=1000ms/3ms=333.3次/s，而且我判断这个频率可能与创建的线程数没有太大关系，因为我前面做了两个重要的问题简化：\n 简化1：假定系统中所有任务的优先级都相同 简化2：任务数nr_running超过1，那么调度周期sched_latency=nr_running*3ms，假定所有任务权重相同，那么权重占总权重的比例相同，那么每个任务得到的动态时间片相同，恒为3ms左右； 简化3：当任务执行抢占逻辑检查时，vruntime更小的任务继续等待，直到当前任务运行完时间片，实际上不用等到执行完就可以切换。  OK，带着这个预期的结果，我们跑下测试看看，看看是不是与我们想象中一样。\n9.001905387 168 context-switches \u0026lt;= 16 threads, 168 次/s 10.099542009 184 context-switches 11.099730077 164 context-switches ... 4.299515329 372 context-switches \u0026lt;= 64 threads, 372 次/s 5.399359483 387 context-switches 6.499338791 380 context-switches ... 7.699145120 458 context-switches \u0026lt;= 256 threads, 458 次/s 8.798950683 418 context-switches 9.899027530 447 context-switches ... 157.899086597 551 context-switches \u0026lt;= 512 threads，598/(159-157) = 299 次/s 159.000687239 598 context-switches 160.100710621 507 context-switches ... 56.603350232 6,854 context-switches \u0026lt;= 2048 threads, 6991/(71-56)=466 次/s 71.400023708 6,991 context-switches 83.700729604 6,418 context-switches ...  实际测试结果，我们预测的333次/s和真实情况有较大偏差，说明我们之前的一些判断是有问题的，真实系统中不能忽略的因素就不能忽略。我们之前试图简化系统中的任务优先级、交互式任务的奖励与惩罚、任务抢占时执行时间小于任务时间片等的一系列做法，在真实负载的系统中是错误的，是违背真实情况的。如果我们是是写一个cfs的单测，输入是优先级相同的任务数量，那结果可能会和我们的分析接近，但是真实系统中完全不一样\n但是这里的测试结果表明，尽管随着任务数增加，上下文切换次数也增加（从16个线程涨到2k个，上下文切换次数多了2倍），但是好的结果是，有上涨，但并不是线性上涨的，更不是数量级上的变化。这样其实是可以接受的。\n使用bpf来跟踪下任务执行时间 # 但是我们不满足于上述测试，我们想通过bpftrace跟踪下随着线程数增加，我们测试程序中创建出来的线程参与调度时获得的实际执行时间是多少，从而更好帮助我们理解，真实负载系统中的调度是什么样子的，我们忽略那些任务优先级、交互式任务的奖励与惩罚、任务抢占时的执行时间小于时间片等的一系列做法，是有多么“粗暴” :)\n ps: 注意：\n1）这里分析的是任务的实际执行时间，非动态时间片sched_slice，抢占发生时不一定用完时间片。\n2）bpftrace跟踪sched_switch统计执行时间比较方便，比跟踪sched_slice算时间片方便。\n bpftrace收集sched_switch事件然后统计可以做到这点，我们现在写一个bpftrace脚本，sched_trace.bt：\n#!/usr/bin/env bpftrace BEGIN { printf(\u0026quot;Tracing CFS scheduler... Hit Ctrl-C to end.\\n\u0026quot;); @last_switch = nsecs; } // 跟踪进程切换事件 tracepoint:sched:sched_switch { $prev_pid = args-\u0026gt;prev_pid; $next_pid = args-\u0026gt;next_pid; $prev_prio = args-\u0026gt;prev_prio; $next_prio = args-\u0026gt;next_prio; $prev_comm = args-\u0026gt;prev_comm; $next_comm = args-\u0026gt;next_comm; // 计算两次切换之间的时间间隔（实际运行时间） $delta = nsecs - @last_switch; @last_switch = nsecs; // 只关注 thread_test 相关的线程 if (strncmp($prev_comm, \u0026quot;thread_test\u0026quot;, 10) == 0 \u0026amp;\u0026amp; strncmp($next_comm, \u0026quot;thread_test\u0026quot;, 10) == 0) { // 记录运行时间分布（单位：微秒） @runtime_us = hist($delta / 1000); // 记录超过理论时间片(3ms)的次数 if ($delta \u0026gt; 3000000) { @long_runtime++; } // 打印详细信息 printf(\u0026quot;switch: %s(%d) -\u0026gt; %s(%d), runtime: %d us\\n\u0026quot;, $prev_comm, $prev_pid, $next_comm, $next_pid, $delta / 1000); } } // 跟踪唤醒事件 tracepoint:sched:sched_wakeup { $pid = args-\u0026gt;pid; $comm = args-\u0026gt;comm; if (strncmp($comm, \u0026quot;thread_test\u0026quot;, 10) == 0) { @wakeups[$comm]++; } } END { clear(@last_switch); printf(\u0026quot;\\nRuntime distribution (microseconds):\\n\u0026quot;); print(@runtime_us); printf(\u0026quot;\\nLong runtime (\u0026gt;3ms) count: %d\\n\u0026quot;, @long_runtime); printf(\u0026quot;\\nWakeup counts per thread:\\n\u0026quot;); print(@wakeups); }  然后在docker宿主机上执行 bpftrace sched_trace.bt，注意使用root权限。\n128 threads时：\n[0] 281 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@| [1] 128 |@@@@@@@@@@@@@@@@@@@@@@@ | [2, 4) 88 |@@@@@@@@@@@@@@@@ | [4, 8) 33 |@@@@@@ | [8, 16) 71 |@@@@@@@@@@@@@ | [16, 32) 79 |@@@@@@@@@@@@@@ | [32, 64) 80 |@@@@@@@@@@@@@@ | [64, 128) 165 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ | [128, 256) 161 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ | [256, 512) 121 |@@@@@@@@@@@@@@@@@@@@@@ | [512, 1K) 28 |@@@@@ | ...  256 ~ 512 threads:\n\u0026lt;skip\u0026gt;  1024 threads时：\n@runtime_us: [0] 605 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@| [1] 206 |@@@@@@@@@@@@@@@@@ | [2, 4) 29 |@@ | [4, 8) 15 |@ | [8, 16) 15 |@ | [16, 32) 18 |@ | [32, 64) 29 |@@ | [64, 128) 29 |@@ | [128, 256) 26 |@@ | [256, 512) 43 |@@@ | [512, 1K) 6 | | [1K, 2K) 0 | | ...  2048threads：\n@runtime_us: [0] 591 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@| [1] 216 |@@@@@@@@@@@@@@@@@@@ | [2, 4) 37 |@@@ | [4, 8) 20 |@ | [8, 16) 8 | | [16, 32) 12 |@ | [32, 64) 25 |@@ | [64, 128) 38 |@@@ | [128, 256) 15 |@ | [256, 512) 22 |@ | [512, 1K) 2 | |  4096threads：\n[0] 718 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@| [1] 263 |@@@@@@@@@@@@@@@@@@@ | [2, 4) 60 |@@@@ | [4, 8) 17 |@ | [8, 16) 12 | | [16, 32) 16 |@ | [32, 64) 43 |@@@ | [64, 128) 56 |@@@@ | [128, 256) 16 |@ | [256, 512) 49 |@@@ | [512, 1K) 4 | | [1K, 2K) 0 | |  So \u0026hellip; 实际上算出来的动态时间片，跟我们想象的完全不一样:\n 它并没有尽可能逼近那个所谓的最小值3ms，实际上时间片要小的多； 从几十个任务增加到几百个任务，每个任务的动态时间片确实是减少的趋势。128个任务时甚至还有1ms的时间片，1k个任务时大部分任务的时间片缩到了10微秒以下； 从1k个任务增加到4k个任务，每个任务的动态时间片并没有继续明显减少了。1k个任务到4k个任务，任务的时间片没有明显减少了，大部分都是10微秒以下；  我们通过bpf工具观察到了这个现象，并没第一时间从源码层面分析出，呃呃任务的时间片还可以这么短。有可能变量kernel.sched_min_granularity_ns将我们的思路引入歧途了。\n分析误区 # 我们分析下推测严重失误的原因，因为我们前面做了几个重要的问题简化，这里的简化在真实系统负载中是不可以简化的：\n 简化1：假定系统中所有任务的优先级都相同，实际上不可能 误区1：对动态优先级认识不足 1）即使我们top中看到有些进程的nice值相同，也不能认为后面运行中它们的优先级一直相同。 2）nice只是确定了一个静态优先级，运行时调度器会根据进程是否是交互式任务进行奖励和触发，动态优先级会不同。 3）静态优先级相同，动态优先级不同，最终优先级还是不同。 4）优先级不同，导致权重不同，会影响任务分得的时间片大小。 简化1会错误估计时间片大小，进而错误估计上下文切换频率。 简化2：任务数nr_running超过1，那么调度周期sched_latency=nr_running3ms，假定所有任务权重相同，那么权重占总权重的比例相同，那么每个任务得到的动态时间片相同，恒为3ms左右； 误区3：低估了系统中高优先级进程的影响 1）系统中存在其他高优先级进程 2）高优先级进程获得的权重要大，对于的vruntime可能小的多 3）实际执行后，其他高优先级进程贡献的负载，要比当前测试进程多的多 4）实际上我们这里创建的线程的时间片=nr_runningload/totalload，实际上分得的时间片可能会少的可怜，甚至连kernel.sched_min_granularity_ns=3ms都不到，可能是微妙级别的，后面的bpf跟踪证明了这点。 简化2导致低估了优先级的影响，高估了测试线程时间片长度，而高优先级进程时间片可能很长，上下文切换次数不一定高。 比如就不能只拿微妙级别的时间片来做除法，1000ms/1us=10^6，很可能高优先级进程的存在降低了整体的上下文切换次数。 简化3：当任务执行抢占逻辑检查时，vruntime更小的任务继续等待，直到当前任务运行完时间片，实际上不用等到执行完就可以切换。 误区3：这个假设不准确， 1）假定此时cfs_rq上存在vruntime更小的任务t 2）且此时当前任务vruntime-min_vruntime \u0026gt; 当前任务的ideal_time 3）那么当前任务此时没有用光时间片，也需要进行任务抢占 简化3会导致低估了上下文切换的次数。  经验教训 # OK，那我们最后来总结下，其实我们想知道的无非就是当创建大量任务时（上1000之后），调度器层面会不会随着任务数增加导致更加频繁的上下文切换，过于频繁的上下文切换会浪费CPU资源，程序也不能得到很好的执行。对，我们担心的主要是这个。其实从前面perf、bpftrace的跟踪结果显示，当任务数量达到一定数量后，继续增加的话，动态时间片、上下文切换次数，都不会有明显的上涨了，这是一个可以接受的结果，恰恰说明了Linux CFS调度器的吞吐能力。\n本文总结 # 本文讲述了困扰在我们项目心头的关于go进程混部时的一些担忧，以及由此引出思考。通过对CFS调度器的内部工作原理的深入学习，以及结合perf、bpftrace对真实负载下任务调度的观测，我们分析了为什么实际测试结果与我们预期相去甚远的原因，加深了对真实负载场景下任务调度的理解。\nOK，希望大家读完后，能够有所感悟吧！\n"}),a.add({id:5,href:"/categories/linux%E5%86%85%E6%A0%B8/",title:"linux内核",description:"",content:""}),a.add({id:6,href:"/tags/scheduler/",title:"scheduler",description:"",content:""}),a.add({id:7,href:"/tags/",title:"Tags",description:"",content:""}),a.add({id:8,href:"/tags/vruntime/",title:"vruntime",description:"",content:""}),a.add({id:9,href:"/books/design-patterns/",title:"Go语言设计模式实战",description:"设计模式，强调的是在软件开发过程中解决复杂问题时的一种可复用的方法，而且这些方法是经过实践检验的。理解问题复杂度的变化过程，并在恰当的阶段选择合适的设计模式，可以解决眼前问题的同时，保证后续软件的可扩展性和可维护性。",content:"2022年4月份开始，鉴于团队成员在工程实践方面存在的问题，我写了一些设计模式方面的demos让大家借鉴，目的很简单，就是训练开发人员复用经得起实践检验的解决方案来解决工程复杂度逐渐扩大的问题。\n 实际上，我们做很多事情，都是为了降低解决问题的复杂度。解决问题的途径当然不止一种，但是我们要懂得权衡、降低解决问题的复杂度，这应该是有追求的开发人员的共识。\n现在，我在示例代码的基础上，系统性整理了设计模式的问题背景、模式核心要素、代码示例，便有了这个Go设计模式实战文集：\n 《Design Patterns in Go》 《Go设计模式实战》  欢迎阅读，如果您在阅读过程中发现有错误、疏漏、建议，不要犹豫，请给我提issue。\n"}),a.add({id:10,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A67v2/",title:"Linux任务调度(7): CFS调度器源码分析1",description:"前面几篇文章介绍了Linux下调度器的演进过程，也对CFS调度器的大致工作原理进行了介绍，但是还是只停留在思想层面，本文在CFS源码层面进行深入分析，帮助大家更深刻地理解CFS调度器的实现细节。本文最后继续探讨几个比较实际的问题，当线程数多了之后，线程切换频率会上升吗？会导致CPU占用率上升吗？调度器又如何平衡多cpu多核上的负载。",content:"Linux任务调度(7): CFS调度器源码分析 # 前面几篇文章介绍了Linux下调度器的演进过程，也对CFS调度器的大致工作原理进行了介绍，本文在CFS源码层面进行深入分析，帮助大家更深刻地理解CFS调度器的实现细节。Linux从开始引入CFS调度器到现在，已经发展了近20年的时间。在这一段时间里，CFS调度器经历了多次演进，我们选择相对比较新的版本 v5.12 版本内核为例进行说明。现在主流云厂商提供的Linux发行版内核都还有这个版本，我们的分析仍然具有一定的时效性方面的价值。OK，我们开始。\n核心概念及源码分析 # 对“公平”的理解 # CFS的目标是为所有任务提供公平的CPU时间分配，这里要先好好理解下 “公平” 的含义：\n1）如果多个任务具有相同的优先级，那么它们理应获得相同的调度机会； 2）如果多个任务优先级有高低之分，那么它们在调度上要有对应的体现，优先级高的要获得更多的调度机会； 3）要防止高优先级任务始终霸占CPU，导致低优先级任务饿死（starvation）； 4）对于响应式任务、非响应式任务，要有必要的奖励和惩罚机制，以改善用户体验； 5）要有能力在用户层级、任务组层级、具体任务层级，建立这种“公平性”； 6）这种公平性在多CPU核心上，除了100%保证单CPU核心上的公平，也需要考虑负载均衡和任务迁移，尽力去做到多CPU核心上的整体调度的相对公平；\n这是我对CFS中“公平性”的理解，接下来我们将结合CFS的源码来分析是如何做到的，让大家知其然知其所以然。\n核心数据结构 #  被调度的具体任务，或者用户组、任务组，它们都用可调度实体来抽象表示，即 sched_entity； struct sched_entity { /* For load-balancing: */ struct load_weight load; struct rb_node run_node; struct list_head	group_node; unsigned int on_rq; u64 exec_start; u64 sum_exec_runtime; u64 vruntime; u64 prev_sum_exec_runtime; u64 nr_migrations; struct sched_statistics exec_statistics; #ifdef CONFIG_FAIR_GROUP_SCHED int depth; struct sched_entity *parent; /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; /* rq \u0026quot;owned\u0026quot; by this entity/group: */ struct cfs_rq *my_q; /* cached value of my_q-\u0026gt;h_nr_running */ unsigned long runnable_weight; #endif #ifdef CONFIG_SMP /* * Per entity load average tracking. * * Put into separate cache line so it does not * collide with read-mostly values above. */ struct sched_avg avg; #endif }    2）每个处理器独立维护一个任务队列cfs_rq，避免1个全局队列的方式导致竞争问题：\n/* CFS-related fields in a runqueue */ struct cfs_rq { struct load_weight load; unsigned int nr_running; unsigned int h_nr_running; /* SCHED_{NORMAL,BATCH,IDLE} */ unsigned int idle_h_nr_running; /* SCHED_IDLE */ u64 exec_clock; u64 min_vruntime; ... struct rb_root_cached tasks_timeline; /* 维护任务的vruntime的rbtree */ /* * 'curr' points to currently running entity on this cfs_rq. * It is set to NULL otherwise (i.e when none are currently running). */ struct sched_entity *curr; struct sched_entity *next; struct sched_entity *last; struct sched_entity *skip; ... /* * CFS load tracking */ struct sched_avg avg; ... // 组调度相关的内容，暂时忽略 #ifdef CONFIG_FAIR_GROUP_SCHED ... #endif /* CONFIG_FAIR_GROUP_SCHED */ };  内核为每个处理器维护一个任务队列cfs_rq, cfs_rq中通过指针成员next,last建立了一个双向链表，方便调度器遍历任务列表。\n 调度器为了能够快速找到任务队列cfs_rq中下一个vruntime最小的可运行任务，构建了1个rbtree：\n/* CFS-related fields in a runqueue */ struct cfs_rq { ... struct rb_root_cached tasks_timeline; /* 维护任务的vruntime的rbtree */ struct sched_entity *curr; ... } /* * Leftmost-cached rbtrees. * * We do not cache the rightmost node based on footprint * size vs number of potential users that could benefit * from O(1) rb_last(). Just not worth it, users that want * this feature can always implement the logic explicitly. * Furthermore, users that want to cache both pointers may * find it a bit asymmetric, but that's ok. */ struct rb_root_cached { struct rb_root rb_root; struct rb_node *rb_leftmost; };  红黑树的更新逻辑这里暂时按下不提，我们先关注核心逻辑，如果此时运行中的任务curr被抢占，那么下一个执行的就是cfs_rq.tasks_timeline-\u0026gt;rb_leftmost。 在介绍调度器抢占逻辑时，我们会看到这部分的更多的源码细节。OK，理解cfs的核心数据结构大致就是这些，篇幅原因我们暂时移除了支持组调度相关的部分。\n  调度粒度 # 前面核心数据结构部分，我们介绍了sched_entity，从这里可以引申出一个重要概念，调度粒度。\nstruct sched_entity { /* For load-balancing: */ struct load_weight load; struct rb_node run_node; struct list_head group_node; unsigned int on_rq; ... #ifdef CONFIG_FAIR_GROUP_SCHED int depth; struct sched_entity *parent; /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; /* rq \u0026quot;owned\u0026quot; by this entity/group: */ struct cfs_rq *my_q; /* cached value of my_q-\u0026gt;h_nr_running */ unsigned long runnable_weight; #endif ... }  sched_entity，可以表示：\n 具体的1个任务； 任务组，此时sched_entity.cfs_rq表示当前任务组从属于哪个任务队列，并且sched_entity.my_q表示当前任务组包含的任务队列； 现在你明白了：  调度器cfs_rq中的某个任务可以是一个“任务组”， 该任务组内包含了自己的任务队列，任务组内的任务也是按照CFS vruntime进行调度， 同时该任务组的vruntime是由其my_q中的所有可调度实体的vruntime求和计算而来，该任务组与其所在的cfs_rq中的其他调度实体按照CFS vruntime进行调度。   用户组是任务组的一种特殊应用形式，本质还是任务组这样的组调度；  关于组调度的实现源码，篇幅原因，本文中可能不涉及，但是看罢此文，我相信读者已经可以自己去阅读源码了。如果有时间我会再写一篇文章讲述组调度的细节。\n任务的优先级 # 在前面介绍的楼梯调度算法、旋转楼梯调度算法，提到了多优先级队列来实现“公平性”对于“任务优先级”的理解。看上去它确实也是种解决办法，但是它真的很难被建模、量化然后说它到底好还是不好？任务在active、expire队列中挪来挪去，或者从高优先级队列挪到低优先级队列，真的是最优雅的解决办法吗？首先，理解起来它就不是那么简单，尽管我在信息流图文、视频链路处理过程中也使用过类似的方法来解决业务中的资源调度问题，但是我确实不认为那就是最好的解决方案。\nCFS调度器的设计，核心思想更简单易懂，且非常容易比建模、量化评估： 1）任务的优先级，包括了初始的静态优先级(nice，从-20到19)和动态优先级(priority，根据是否响应式任务动态调整)； 2）调度器执行调度时，会检查任务列表中的任务是否是响应式任务，并调整其对应的动态优先级（奖励 or 惩罚，-5到+5）； 3）任务的最终优先级 = 静态优先级 + 动态优先级； 4）任务的优先级会被映射为一种“权重”，表示它在总的CPU执行时间里的一种占比，显然优先级越高对应的权重也应该越大；\n虚拟运行时间 # 调度器执行调度时，很重要的一部操作就是迅速找到下一个被调度的可运行任务。Linux v0.01版本中找到下一个可运行任务的复杂度是O(n)，O(1)调度器是O(1)，CFS调度器是O(log(n))。 CFS调度器建立了一个红黑树（RBTree），树种每个节点表示一个任务，任务中包含了一个属性 vruntime。\nvruntime是一个虚拟运行时间: vruntime = 实际执行时间 / weight\n 实际执行时间，就是任务被调度到CPU上执行的总时间； 2）处理器时钟中断定时触发，时钟中断服务程序此时会更新当前运行中的任务的实际执行时间，并更新vruntime； 时钟中断服务入口 scheduler_tick(preempt): \\-\u0026gt; scheduler_tick() \\-\u0026gt; task_tick(rq, cur, 0) \\-\u0026gt; task_tick_fair(rq, cur, 0) \\-\u0026gt; foreach se in cfs_rq: entity_tick(cfs_rq, se, queued) \\-\u0026gt; update_curr(cfs_rq) \\-\u0026gt; curr-\u0026gt;sum_exec_runtime += delta_exec; \\-\u0026gt; curr-\u0026gt;vruntime += calc_delta_fair(delta_exec, curr); /* * delta /= w */ static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se) { if (unlikely(se-\u0026gt;load.weight != NICE_0_LOAD)) delta = __calc_delta(delta, NICE_0_LOAD, \u0026amp;se-\u0026gt;load); return delta; }    3）weight则是由前面提到的任务优先级，通过查表映射而来得到的权重值； vruntime的实际计算式为：\nvirtual runtime = (real runtime) * (NICE_0_LOAD) / (weight of the process)    其中virtual runtime指的就是vruntime;\n  real runtime指的是cpu上的实际执行时间;\n  NICE_0_LOAD表示nice==0时的默认权重（1024）;\n  而weight of the process指的是由进程的实际优先级从映射表映射而来的权重;\n完整的映射表可以参考：\n  const int sched_prio_to_weight[40] = { /* -20 */ 88761, 71755, 56483, 46273, 36291, /* -15 */ 29154, 23254, 18705, 14949, 11916, /* -10 */ 9548, 7620, 6100, 4904, 3906, /* -5 */ 3121, 2501, 1991, 1586, 1277, /* 0 */ 1024, 820, 655, 526, 423, /* 5 */ 335, 272, 215, 172, 137, /* 10 */ 110, 87, 70, 56, 45, /* 15 */ 36, 29, 23, 18, 15, };  当一个任务被调度执行时，时钟中断会定时触发，对应的时钟中断通过1）中代码序列会不断更新任务的实际执行时间和 vruntime，陷入阻塞状态的任务不会占用CPU，这里的时间也不会增加。\nps：sched_entity可以表示具体任务，也可以表示任务组、用户组（用户组是任务组的一种特殊应用方式），而vruntime是定义在sched_entity中的，对于组调度而言，计算vruntime的时候就是递归计算其包含的所有任务的vruntime，汇总起来。\n调度周期 # sched_latency，直译过来应该是调度延迟，但是理解成调度周期更好理解一点，它表示什么呢？ 1）任意一个可运行任务先后两次调度之间的时间差上限； 2）在这个时限内所有可运行任务都必须完成一次调度；\nsched_latency，强调的是多久的时间窗口内所有运行任务可以都被调度一轮，它不等于任务执行时的时间片sched_slice。在传统调度器实现中，时间片是固定的，在CFS中不是的，时间片是动态计算的，后面会提到。\n我们看下调度周期的相关计算逻辑：\n/* * Targeted preemption latency for CPU-bound tasks: * * NOTE: this latency value is not the same as the concept of * 'timeslice length' - timeslices in CFS are of variable length * and have no persistent notion like in traditional, time-slice * based scheduling concepts. * * (to see the precise effective timeslice length of your workload, * run vmstat and monitor the context-switches (cs) field) * * (default: 6ms * (1 + ilog(ncpus)), units: nanoseconds) */ unsigned int sysctl_sched_latency	= 6000000ULL; /* * Minimal preemption granularity for CPU-bound tasks: * * (default: 0.75 msec * (1 + ilog(ncpus)), units: nanoseconds) */ unsigned int sysctl_sched_min_granularity	= 750000ULL; /* * This value is kept at sysctl_sched_latency/sysctl_sched_min_granularity */ static unsigned int sched_nr_latency = 8; * The idea is to set a period in which each task runs once. * * When there are too many tasks (sched_nr_latency) we have to stretch * this period because otherwise the slices get too small. * * p = (nr \u0026lt;= nl) ? l : l*nr/nl */ static u64 __sched_period(unsigned long nr_running) { if (unlikely(nr_running \u0026gt; sched_nr_latency)) return nr_running * sysctl_sched_min_granularity; else return sysctl_sched_latency; }  不难看出:\n 当可运行任务数\u0026lt;=8时，调度周期sched_latency=6ms； 当\u0026gt;8时，调度周期sched_latency=可运行任务数*0.75ms，超过8个时就大于6ms。  这里的调度延迟和下面的动态时间片的计算有关系，注意看。\n时间片 # 调度器中包含“时间片”这个设计，主要有两个目的： 1）为了避免进程频繁切换，必须要让任务执行一段时间后再切换，否则每次系统调用返回、时钟中断服务检测到vruntime最小时都会立即触发触发，开销极大； 2）为了避免进程长时间霸占CPU，有些进程不进行IO或者其他可能阻塞性的处理，就不会主动让出CPU，时钟中断服务每隔一段时间触发调度器进行检查，如果任务运行时间片就要强制抢占；\n不同调度器实现都肯定需要考虑“时间片”的设计，不同于传统的基于固定时间片大小的调度器实现，CFS中的任务时间片是动态计算的，详见 sched_slice(...)。\n/* * We calculate the wall-time slice from the period by taking a part * proportional to the weight. * * s = p*P[w/rw] */ static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se) { // if nr_running\u0026lt;=8, slice=6ms; else slice=nr_running*0.75ms u64 slice = __sched_period(cfs_rq-\u0026gt;nr_running + !se-\u0026gt;on_rq); for_each_sched_entity(se) { struct load_weight *load; struct load_weight lw; cfs_rq = cfs_rq_of(se); load = \u0026amp;cfs_rq-\u0026gt;load; if (unlikely(!se-\u0026gt;on_rq)) { // total load on this cfs_rq, sum(load-per-task) lw = cfs_rq-\u0026gt;load; update_load_add(\u0026amp;lw, se-\u0026gt;load.weight); load = \u0026amp;lw; } // slice = delta_exec * weight / lw.weight // or // (delta_exec * (weight * lw-\u0026gt;inv_weight)) \u0026gt;\u0026gt; WMULT_SHIFT slice = __calc_delta(slice, se-\u0026gt;load.weight, load); } return slice; }  首先根据可运行任务数量计算出一个调度周期，然后根据过去每个任务执行贡献的负载/总负载，按比例划分调度周期得到该任务的动态时间片。\n ps: 这里的概念“负载”，就是占据CPU的时间，不是top中的loadavg的负载概念。\n 能不能确定动态时间片的一个上下界呢？接着往下看你就知道了。\n调度节拍 # 检查任务是否需要切换，有这么几个时机:\n 时钟中断服务程序触发scheduler_tick(void)，如果检查逻辑发现需要触发会设置对应的标记位TIF_NEED_RESCHED； 任务执行到阻塞型系统调用时，任务需要阻塞执行、不可被调度，此时会主动让出CPU，如mutex, semaphore, waitqueue； 任务执行系统调用返回时，一般也会做个检查 （在看linux v0.01源码时就是会检查的，合理，推测后续版本也是这样的）；  这里的调度节拍，强调的更多的是硬件时钟中断触发时钟中断服务程序，进入这里的scheduler_tick执行任务切换逻辑:\n 更新任务执行时间、vruntime； 抢占逻辑check_preempty_check里检查任务执行时间是否已经超过时间片，超过则寻找下一个待调度任务，设置标志位TIF_NEED_RESCHED返回； 等待调度器__schedule(preempt)执行实际的任务切换逻辑。  时钟中断服务入口 scheduler_tick(preempt): \\-\u0026gt; scheduler_tick() \\-\u0026gt; task_tick(rq, cur, 0) \\-\u0026gt; task_tick_fair(rq, cur, 0) \\-\u0026gt; foreach se in cfs_rq: entity_tick(cfs_rq, se, queued) \\-\u0026gt; update_curr(cfs_rq) \\-\u0026gt; curr-\u0026gt;sum_exec_runtime += delta_exec; \\-\u0026gt; curr-\u0026gt;vruntime += calc_delta_fair(delta_exec, curr); \\-\u0026gt; check_preempt_tick(cfs_rq, curr) // Preempt the current task with a newly woken task if needed: static void check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr) { ... }  任务抢占 # 当前正在执行的任务，在时钟中断到来时schedule_tick函数被执行，它里面会检查当前任务是否应该被抢占，如果需要被抢占，则会调用resched_cur 来标记任务的一些抢占标记为。检查当前任务是否运行足够久应该被抢占的函数，前面我们已经分析过了，就是check_preempt_tick函数。\n/* * Preempt the current task with a newly woken task if needed */ static void check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr) { unsigned long ideal_runtime, delta_exec; struct sched_entity *se; s64 delta; ideal_runtime = sched_slice(cfs_rq, curr); delta_exec = curr-\u0026gt;sum_exec_runtime - curr-\u0026gt;prev_sum_exec_runtime; if (delta_exec \u0026gt; ideal_runtime) { resched_curr(rq_of(cfs_rq)); ... return; } /* * Ensure that a task that missed wakeup preemption by a * narrow margin doesn't have to wait for a full slice. * This also mitigates buddy induced latencies under load. */ if (delta_exec \u0026lt; sysctl_sched_min_granularity) return; se = __pick_first_entity(cfs_rq); delta = curr-\u0026gt;vruntime - se-\u0026gt;vruntime; if (delta \u0026lt; 0) return; if (delta \u0026gt; ideal_runtime) resched_curr(rq_of(cfs_rq)); } /* * resched_curr - mark rq's current task 'to be rescheduled now'. * * On UP this means the setting of the need_resched flag, on SMP it * might also involve a cross-CPU call to trigger the scheduler on * the target CPU. */ void resched_curr(struct rq *rq) { ... if (test_tsk_need_resched(curr)) return; cpu = cpu_of(rq); if (cpu == smp_processor_id()) { set_tsk_need_resched(curr); set_preempt_need_resched(); return; } if (set_nr_and_not_polling(curr)) smp_send_reschedule(cpu); else trace_sched_wake_idle_without_ipi(cpu); }  总结下 check_preempt_tick 的检查逻辑：\n 如果运行足够久了，超过了sched_slice返回的时间片（时间配额），则直接标记为抢占然后返回 如果运行任务时间很短，没有超过动态时间片，并且还不到最小的0.75ms，那么无需抢占、继续执行 如果运行时间不太短，虽然不到动态时间片大小，但是超过了0.75ms，可以检测下是否需要被抢占 则从当前cpu的cfs_rq（任务队列）中取出vruntime最小的一个se，进行比较。  如果当前任务的vruntime更小，则不能被抢占，当前任务继续执行； 如果当前任务的vruntime更大 (delta=curr.vruntime-se.vruntime，delta\u0026gt;0)  delta\u0026lt;=ideal_time，从全局来看有比我更应该优先调度的，但是也没等太久，让我再执行一会，一会就让出CPU； delta\u0026gt;ideal_time，从全局来有比我更应该优先调度的，且已经等了比较久时间了；      进一步的说明:\n 任务的静态优先级以及CFS对交互式任务的奖励、惩罚带来的动态优先级调整，会直接影响到权重的计算，进而影响到理想时间片ideal_time的计算，尽管 sysctl_sched_min_granularity = 0.75ms，我们初看源码容易误认为时间片最少0.75ms，不是的，由于优先级、权重的影响，实际计算出来的ideal_time可能只有几到几十微秒。详见我们后面的bpftrace的测试。 如果任务优先级比较高，实际计算的理想时间片比较大，比如大于0.75ms，在执行时间不足ideal_time时会执行到此分支。如果不足0.75ms则继续执行，这是考虑到当前任务优先级较高，为了体现公平应该尽可能多执行一会。 3）\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;大于0.75ms，执行时间上不足ideal_time但是超过了0.75ms，达到了一个最小粒度，此时也够意思了，为了进一步的“公平性”，此时会要求检查“抢占”逻辑。  理想情况下，还是需要执行完ideal_time后再切换，才能体现公平是不是？确实。\n那为什么现在就要执行检测呢？因为系统中随时可能会插入高优先级进程、考虑交互性程序的奖励、非交互性程序的处罚以及避免饿死问题。“公平”不仅要看过去、现在，也要看将来，不仅要看局部，也要看整体。So……此时在执行时间已经超过了最小粒度0.75ms的前提下，额外检查下是否需要被抢占十分合理，更何况是一个已经“等”了我一会的任务呢？\n ps: 从这里可以看出，cfs并不是立即选一个vruntime更小的任务来立即执行，即使下一个任务的vruntime比当前任务小，当前任务也会尽量拖着再执行一会，要么等到执行完理想的时间片（这样最公平），要么拖到下一个任务再等我一会，这样我执行时间更接近理想时间片。\n 任务切换 # schedule_tick(...) 只是时钟中断服务触发检查“是否需要抢占当前任务“，如果需要就设置标记位并返回。 我们知道此时当前任务还是在执行中的，顶多被设置了个抢占标记位而已，那么调度器什么时候执行了真正的切换呢？在 __schedule(preempt)这个调度器逻辑中。\n/* * __schedule() is the main scheduler function. * * The main means of driving the scheduler and thus entering this function are: * * 1. Explicit blocking: mutex, semaphore, waitqueue, etc. * * 2. TIF_NEED_RESCHED flag is checked on interrupt and userspace return * paths. For example, see arch/x86/entry_64.S. * * To drive preemption between tasks, the scheduler sets the flag in timer * interrupt handler scheduler_tick(). * * 3. Wakeups don't really cause entry into schedule(). They add a * task to the run-queue and that's it. * * Now, if the new task added to the run-queue preempts the current * task, then the wakeup sets TIF_NEED_RESCHED and schedule() gets * called on the nearest possible occasion: */ static void __sched notrace __schedule(bool preempt) { struct task_struct *prev, *next; unsigned long *switch_count; unsigned long prev_state; struct rq_flags rf; struct rq *rq; int cpu; cpu = smp_processor_id(); rq = cpu_rq(cpu); prev = rq-\u0026gt;curr; ... // 寻找下一个可执行任务 next = pick_next_task(rq, prev, \u0026amp;rf); // 清理旧任务的抢占标记位 clear_tsk_need_resched(prev); clear_preempt_need_resched(); // 如果next!=prev，更新上下文切换计数器，并执行上下文切换 // 如果next==prev，说明当前runq上没有其他任务，需要检查下负载均衡了 if (likely(prev != next)) { rq-\u0026gt;nr_switches++; // ptrace时间上报，用于bpftrace分析 trace_sched_switch(preempt, prev, next); // 执行上下文切换，从prev到next，切换完就开始执行next这个任务了 rq = context_switch(rq, prev, next, \u0026amp;rf); } else { rq-\u0026gt;clock_update_flags \u0026amp;= ~(RQCF_ACT_SKIP|RQCF_REQ_SKIP); // 负载均衡相关的操作，rq.lock dropped之后会执行balance_callbacks rq_unpin_lock(rq, \u0026amp;rf); __balance_callbacks(rq); raw_spin_unlock_irq(\u0026amp;rq-\u0026gt;lock); } }  __schedule(preempt) 函数非常长，我们删减了不是很相关的代码，只看下任务切换的核心逻辑： 1）这个函数什么时候会被执行到呢？注释提到了有几个时机，任务阻塞主动让出CPU、任务被抢占、任务被唤醒任务重新加入run-queue； 我们刚才提到的任务抢占就会导致进入这个函数处理。 2）cfs调度器通过pick_next_task(\u0026hellip;)从rq中找到下一个vruntime最小的任务； 3）清理之前设置的抢占标记位，更新抢占计数器； 4）执行上下文切换 context_switch，执行新任务逻辑； 5）再释放掉rq上的锁后，会执行负载均衡逻辑（work-sharing mode）；\n这就是大致的任务抢占、任务切换、负载均衡的核心逻辑。\n负载均衡 # see: __balance_callbacks(rq)，因为我们了解go workstealing相关的迁移负载的做法，对linux cfs调度器做到负载均衡的思路并不十分好奇， 我们这里只是简单总结下负载均衡的核心思路，细节直接跳过。\n1）这里笼统地说下cfs调度器负载均衡的时机，以及考虑因素。\n负载均衡的时机，负载均衡通常在以下几种情况下触发：\n 周期性负载均衡：调度器会定期检查各个CPU的负载，并在必要时进行任务迁移。 任务唤醒：当一个任务从睡眠状态被唤醒时，调度器会检查当前CPU的负载情况，并可能将任务分配到负载较轻的CPU。 任务创建：当一个新任务被创建时，调度器会选择一个负载较轻的CPU来运行该任务。  任务迁移的考虑因素，在决定是否迁移任务时，调度器会考虑多个因素，包括：\n CPU负载：调度器会比较各个CPU的负载，选择负载较轻的CPU进行任务迁移。 任务的vruntime：调度器会比较任务的vruntime，选择合适的任务进行迁移。 任务的亲和性：某些任务可能对特定的CPU有亲和性（例如，缓存亲和性），调度器会尽量避免迁移这些任务。  2）CPU1上的P1的vruntime比CPU2上的P2的vruntime更小，CPU1负载高，会将P1迁迁移到CPU2上吗？\n假设有两个CPU（CPU1和CPU2），每个CPU有自己的调度队列和红黑树：\n CPU1上的任务P1的vruntime较大，暂时不被CPU1调度。 CPU2上的任务P2的vruntime最小，但P1的vruntime比P2更小。  在这种情况下，是否会将P1迁移到CPU2取决于负载均衡机制的具体实现和当前系统的负载情况：\n 如果CPU1的负载较高，而CPU2的负载较低，负载均衡机制可能会将P1迁移到CPU2，以平衡负载。 如果CPU1和CPU2的负载相对均衡，调度器可能不会进行任务迁移，因为任务迁移本身也有一定的开销。  如果您对负载均衡的细节感兴趣，可以看下相关的代码。\n组调度 # 组调度，一个任务组是组，一个用户组是一个特殊的任务组的应用场景。前面介绍核心数据结构时，特别提了sched_entity中如何借助字段my_q来表示该任务组包含的任务队列，组内的任务也是按照CFS调度器算法进行调度。而这个任务组又作为一个调度实体从属于更上层的“组”，被CFS调度算法调度。\n这里的“组调度”，在Linux的设计实现中： 1）需要有一个能力来灵活的定义组，然后灵活地在这个组中添加任务，灵活地建立一个sched_entity的树形结构。cgroups就是用来干这个事情的。 在cgroups中增加配置项来影响调度，如cpu.shares表示这个调度组的CPU开销的配额。 2) 对应地cfs调度器需要读取cgroups这里的这些配置项，来感知到有哪些任务组，每个任务组的配置是啥样的，进而整合成sched_entity的树形结构，让树形结构中的每个调度实体（任务、组）被CFS调度器调度。\nOK，篇幅原因本文不打算继续介绍组调度相关的内容，读到这里了解了CFS关键的处理过程后，大家可以自行查看组调度相关的设计实现了。或者等我有时间时再补一篇文章，专门介绍组调度的源码分析。\n本文总结 # 本文详细介绍了CFS调度器的核心概念、核心数据结构以及关键操作流程的源码级分析，相信读者对CFS调度器的工作原理也有了更加全面的认识。下一篇文章我们将讲述了一个曾经困扰在我们项目组心头的关于go进程混部时的一些担忧，以及由此引出的多进程混部时的隔离性问题，个别程序实现不健壮创建大量进程是否会推高上下文切换次数导致无谓的CPU开销的问题。我们将结合工具perf、bpftrace来深入观察并分析，以加深了对真实负载场景下任务调度的深层理解。\nOK，欢迎点赞关注我，我们继续一起学习。\n"}),a.add({id:11,href:"/tags/settings/",title:"settings",description:"",content:""}),a.add({id:12,href:"/tags/sync/",title:"sync",description:"",content:""}),a.add({id:13,href:"/tags/vscode/",title:"vscode",description:"",content:""}),a.add({id:14,href:"/categories/vscode/",title:"vscode",description:"",content:""}),a.add({id:15,href:"/blog/2024-04-14-%E5%B8%B8%E8%A7%84%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%90%8C%E6%AD%A5%E8%AF%B4%E6%98%8E/",title:"vscode-常规配置以及同步说明",description:"前言 # 我经常在项目开发过程中针对不同项目，甚至是相同项目的不同模块阶段，频繁调整配置以满足当时的需要，我觉得能够快速调整vscode配置满足开发人员需要，是一项必备技能。\n这里就简单总结下vscode配置调整过程中，一些比较有价值的信息。\n搜索配置项 #  搜索修改过的配置项，可以按照 \u0026ldquo;@modified\u0026quot;进行过滤， 搜索指定插件的话，可以按照\u0026rdquo;@ext:\u0026ldquo;进行过滤  设置优先级 # 配置项可以在不同的设置范围内进行覆盖。在下面的列表中，后面的范围会覆盖前面的范围：\n 默认设置 - 这个范围代表未配置的默认设置值。 用户设置 - 对所有的 VS Code 实例全局适用。 远程设置 - 适用于用户打开的远程机器。 工作区设置 - 适用于打开的文件夹或工作区。 工作区文件夹设置 - 适用于多根工作区的特定文件夹。 特定语言的默认设置 - 这些是由扩展提供的特定语言的默认值。 特定语言的用户设置 - 与用户设置相同，但特定于某种语言。 特定语言的远程设置 - 与远程设置相同，但特定于某种语言。 特定语言的工作区设置 - 与工作区设置相同，但特定于某种语言。 特定语言的工作区文件夹设置 - 与工作区文件夹设置相同，但特定于某种语言。 策略设置 - 由系统管理员设置，这些值始终会覆盖其他设置值。  跨设备同步 # Settings Sync功能，之前使用IDEA系列产品时，一来一个Settings Repository及插件来做这个事情，VSCode就方便多了，直接支持用户维度下的多份的同步，比如分别为macOS、Linux、Windows分别自定义一份配置。\n同步的内容也很丰富：\n 常规设置项 view tasks snippets shortcuts 甚至是UI状态都可以  而且可以精确控制每一个配置项是否参与同步，这个就很有用，比如要读本地机器的文件，但是文件路径在参与同步的设备上不同，那么该配置项就可以“取消设置同步”。\n重置配置 #  当该乱某个配置项时，可以选择齿轮按钮，点击弹出菜单然后选择“reset this setting”，或者从settings.",content:"前言 # 我经常在项目开发过程中针对不同项目，甚至是相同项目的不同模块阶段，频繁调整配置以满足当时的需要，我觉得能够快速调整vscode配置满足开发人员需要，是一项必备技能。\n这里就简单总结下vscode配置调整过程中，一些比较有价值的信息。\n搜索配置项 #  搜索修改过的配置项，可以按照 \u0026ldquo;@modified\u0026quot;进行过滤， 搜索指定插件的话，可以按照\u0026rdquo;@ext:\u0026ldquo;进行过滤  设置优先级 # 配置项可以在不同的设置范围内进行覆盖。在下面的列表中，后面的范围会覆盖前面的范围：\n 默认设置 - 这个范围代表未配置的默认设置值。 用户设置 - 对所有的 VS Code 实例全局适用。 远程设置 - 适用于用户打开的远程机器。 工作区设置 - 适用于打开的文件夹或工作区。 工作区文件夹设置 - 适用于多根工作区的特定文件夹。 特定语言的默认设置 - 这些是由扩展提供的特定语言的默认值。 特定语言的用户设置 - 与用户设置相同，但特定于某种语言。 特定语言的远程设置 - 与远程设置相同，但特定于某种语言。 特定语言的工作区设置 - 与工作区设置相同，但特定于某种语言。 特定语言的工作区文件夹设置 - 与工作区文件夹设置相同，但特定于某种语言。 策略设置 - 由系统管理员设置，这些值始终会覆盖其他设置值。  跨设备同步 # Settings Sync功能，之前使用IDEA系列产品时，一来一个Settings Repository及插件来做这个事情，VSCode就方便多了，直接支持用户维度下的多份的同步，比如分别为macOS、Linux、Windows分别自定义一份配置。\n同步的内容也很丰富：\n 常规设置项 view tasks snippets shortcuts 甚至是UI状态都可以  而且可以精确控制每一个配置项是否参与同步，这个就很有用，比如要读本地机器的文件，但是文件路径在参与同步的设备上不同，那么该配置项就可以“取消设置同步”。\n重置配置 #  当该乱某个配置项时，可以选择齿轮按钮，点击弹出菜单然后选择“reset this setting”，或者从settings.json中直接删除该配置项 可以直接在command pallete里选择 \u0026ldquo;reset settings\u0026rdquo; 命令，也可以直接将settings.json中内容全部删除   ps: settings.json文件，user level对应的配置文件路径为：\n Windows %APPDATA%\\Code\\User\\settings.json macOS $HOME/Library/Application\\ Support/Code/User/settings.json Linux $HOME/.config/Code/User/settings.json  workspace层级的就在工程目录下的.vscode/ 目录下。\n 如果对经常调整的配置项进行修改，可能通过settings.json进行调节还会更方便些，但是调整后记得通过json插件对内容进行下按properties排序、格式化，方便后续维护，以及跨设备同步时解决冲突。\n彻底卸载vscode #  一个是卸载程序 一个是清空数据，包括本文提到的这些用户层级的配置信息。如果不卸载程序，删除这个.vscode数据目录，等效于重置配置了  修改主题 themes # 这里的主题，其实可以细分为如下几块：\n 代码颜色主题（color themes） 文件图标主题（file icon themes）  颜色主题是大家经常使用的，比如dark theme、light theme的切换，vscode虽然自带了一些主题，但是众口难调，因此有很多第三方提供的颜色主题。目前为止我把stars数很多的都试了下，最后呢？\n推荐直接安装这个主题库就可以了，https://marketplace.visualstudio.com/items?itemName=lakshits11.best-themes-redefined，它基本包含了所有最佳表现的主题。\nps: 文件图标主题，平时用的少写，但是建议选些比较主流的，这在和团队成员走读代码、浏览工程时可能会帮助打点。选一个好的文件主题是由帮助的，特别是和那些设计糟糕的比。\n修改字体 #  字体的选择 字号的大小 是否允许加粗、高亮、倾斜 是否允许连字（font lignatures）  vscode中的UI字体、终端字体、编辑器字体等都是可以调节的，有一个不错的插件：https://marketplace.visualstudio.com/items?itemName=evan-buss.font-switcher，它简化了字体切换。\n对于编程来说，mono字体基本是必须的，大家可以按需选择合适的字体、喜欢的字体、辨识度高、眼睛舒服的字体。\n对于连字功能，我是比较抵触的，尽管看上去表意更清楚，我希望它能更简单点，尤其是在golang编译器不允许 c/c++ if a = b  写法的情况下。\n本文总结 # vscode的配置调整是开发人员在使用过程中经常用到的，即便是在同一个工程下也可能会因为当时所关注内容的不同对其进行调整，了解这些配置基础以及跨设备同步，是一个必备技能了。\n参考内容 #  Get Started - Settings, https://code.visualstudio.com/docs/getstarted/settings Get Started - Themes, https://code.visualstudio.com/docs/getstarted/themes  "}),a.add({id:16,href:"/tags/multiroot/",title:"multiroot",description:"",content:""}),a.add({id:17,href:"/tags/projectscope/",title:"projectscope",description:"",content:""}),a.add({id:18,href:"/blog/2024-04-14-%E8%B0%83%E6%95%B4%E9%85%8D%E7%BD%AE%E4%BB%A5%E4%BF%9D%E6%8C%81%E4%B8%93%E6%B3%A8/",title:"vscode-调整配置以保持专注",description:"项目采用的微服务架构+monorepo进行代代码组织，每个微服务一个子目录，当然也有很多scripts、tools、ci/cd配置、配置文件管理、外部依赖等等。业务开发的时候，其实你很想只关心某些范围，而忽略掉不相关的范围，以让自己保持专注的同时提升检索、开发的效率。本文总结描述下vscode开发过程中这方面的一点心得。",content:"前言 # 保持专注、减少外界干扰，首要的是培养内在的专注力，而不是依赖工具。回想起我前几年的一些经历：\n 我的 MacBook Pro Touch Bar 经常闪烁，几乎刺痛了我的双眼。最终发现是硬件故障，我曾看到一个网友的解决方法，简直让我笑掉大牙。他直接用黑色胶带把 Touch Bar 给封住了。 后来我购买了一款防眩光、防窥的屏幕膜，但它稍微有些厚度，导致关闭屏幕时无法完全贴合。我开始寻找更轻薄、更便携的替代品，直到一个“老手”给了我建议：“简单点，直接将屏幕膜撕下来放在配套袋子里。”  为何提及这两个例子呢？其实是想说，现阶段虽然有很多创新产品，但未必完美。与其花大量时间寻找“完美”，不如早日认识到自己深处发展历程中的某个时刻、转而采用更经济更有效的解决方案。\n但是，尽管产品成品不完美，但我们依然可以尽己所能让它接近我们期望的那样。就比如使用vscode进行开发时，我希望它能在不同规模的项目中能够帮助开发者保持专注。\n问题背景 # 项目采用的微服务架构+monorepo进行代代码组织，每个微服务一个子目录，当然也有很多scripts、tools、ci/cd配置、配置文件管理、外部依赖等等。业务开发的时候，其实你很想只关心某些范围，而忽略掉不相关的范围，以让自己保持专注的同时提升检索、开发的效率。\n为了保持专注，不同产品中有不同的设计，比如KDE中的activity，IDEA中的projectscope，Typora中有打字机模式……就不扯远了，我们只看看vscode中能做到什么程度，来让开发者保持更好的专注度。\n配置方式 # 忽略掉不关心的文件: files.exclude # vscode中支持在explorer、代码搜索操作中忽略某些文件夹、文件，这个是通过配置一些忽略规则来实现的。\n规则配置说明，详见：see: https://code.visualstudio.com/docs/editor/glob-patterns\n如果代码库是monorepo管理的，使用git进行版本控制（没有针对大仓的权限控制、拉取等进行特殊优化），那拉取下来后文件数量会很多，但是在我们对全局进行了了解之后，以后大部分功能开发过程中，你很可能希望能聚焦于其中某些部分，而非全部。不管是explorer中查看，还是代码搜索时检索，还是提交日志检查，你都希望能尽可能聚焦。所以是有必要隐藏某些不紧密相干的内容的。\n忽略gitignore中文件: explorer.excludeGitIgnore # gitignore中通常会忽略一些文件，大多数时候这些文件也是一些不需要在explorer中显示的，所以vscode也增加了这样一个配置项，允许忽略.gitignore中忽略的文件。\n严格来说，是vscode会读取gitignore中的配置，但是对其中某些规则的解析上并不完全等同于git。\n举个例子，下述配置项通常用来忽略linux上的编译构建生成的二进制程序，但是如果vscode读取后就会忽略所有内容，并不完全等价于git忽略的内容。\n* !*.* !*/  不要watch不关心的目录：files.watcherExclude # vscode会通过filesystem watch特性来监视某些文件内容的修改情况，以便及时reload最新内容，但是这也是由性能开销的，如果某些路径下的变更不是自己关心的，可以考虑忽略。至少在显示打开、强制reload window时还是会加载最新内容的。\n通过 project scope # IDEA系列的IDE产品中，有一个非常有用的特性，project scope。\n前面提到的两种方式，控制的事工程全局层面，哪些文件可显示、隐藏出来。而project scope则是概念上对工程的划分。\n比如用户登录流程、用户匹配流程、对局结束流程、DS管理流程，这些不同关键链路上的服务列表，它们有重叠的，也有各自特有的。用project scope进行管理就非常方便了。\n你可以创建不同的project scopes，然后每个scope控制好要显示、隐藏的文件，当希望从某个关键业务流程切换到另一个关键业务流程的开发时，只需要切换project scope就可以了。\n很遗憾的是，vscode原生不支持project scope，但是有些作者通过vscode extension的方式来实现了project scope，实现方式就是在进行scope切换时，自动帮用户设置好files.exclude。\n通过 workspace # vscode支持workspace，以及multi-root workspace，意思是你可以将多个独立的工程组织在一个workspace中，在一个workspace中也可以控制显示、隐藏的文件。\nworkspace是不同于project scope的另一种特性，可以针对同一个project配置多个workspace分别设置好隐藏、显示规则，可以近似实现project scope的功能。 multi-root workspace还可以将多个不相干的projects组合在一个workspace里面，比如我有些个人兴趣驱动的电子书，调试器相关的、RPC框架相关的、Go语言设计实现相关的，我就可以将这几个独立的工程编排为一个workspace。\n$ cat ~/.workspaces/iwrite.code-workspace { \u0026quot;folders\u0026quot;: [ { \u0026quot;name\u0026quot;: \u0026quot;📕gorpc@ebook\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;../gorpc101/gorpc101\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;📗debug@ebook\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;../debugger101/golang-debugger-book\u0026quot; }, { \u0026quot;name\u0026quot;: \u0026quot;📘golang@ebook\u0026quot;, \u0026quot;path\u0026quot;: \u0026quot;../github/go-internals/content/docs\u0026quot; }, ], \u0026quot;settings\u0026quot;: { \u0026quot;files.exclude\u0026quot;: { } } }  本文总结 # 简单总结了项目采用monorepo+vscode进行开发的情况下，开发者可以通过哪些配置来让自己更聚焦于关心的内容，避免自己的精力淹没在巨量的文件和代码中。谈不上什么高大上的经验，一点日常功能开发中积累的心得而已。\n"}),a.add({id:19,href:"/tags/workspace/",title:"workspace",description:"",content:""}),a.add({id:20,href:"/tags/c100k/",title:"c100k",description:"",content:""}),a.add({id:21,href:"/tags/c10k/",title:"c10k",description:"",content:""}),a.add({id:22,href:"/tags/c10m/",title:"c10m",description:"",content:""}),a.add({id:23,href:"/blog/2024-01-06-%E8%A7%A3%E5%86%B3c10kc100kc10m%E9%97%AE%E9%A2%98/",title:"解决c10k c100k c10m问题",description:"今天整理资料时，无意中重新碰到了c10k这个话题，然后联想到了c10m问题。虽然c10k问题大家已经看过类似文章了，但是c10m问题系统性总结的却不多。今天刚好看了个相关的分享，顺便整理下。",content:"问题背景 # c10k, c100k甚至c10m，这些问题大家已经不再陌生，聊起来可能显得有点枯燥？新技术层出不穷，至少我自己对这些问题有了些新的认识，需要更新沉淀下我的“小宇宙”。\nc10k问题, 1999, 1Gbps Ethernet #  The C10k problem is the problem of optimizing network sockets to handle a large number of clients at the same time.[1] The name C10k is a numeronym for concurrently handling ten thousand connections.[2] Handling many concurrent connections is a different problem from handling many requests per second: the latter requires high throughput (processing them quickly), while the former does not have to be fast, but requires efficient scheduling of connections.\n 就是说，c10k解决的是1w连接的高效调度处理问题，而非请求吞吐量问题。\n The problem of socket server optimisation has been studied because a number of factors must be considered to allow a web server to support many clients. This can involve a combination of operating system constraints and web server software limitations. According to the scope of services to be made available and the capabilities of the operating system as well as hardware considerations such as multi-processing capabilities, a multi-threading model or a single threading model can be preferred. Concurrently with this aspect, which involves considerations regarding memory management (usually operating system related), strategies implied relate to the very diverse aspects of I/O management.\n 性能制约瓶颈 # 要让服务支持大量客户端连接，受到操作系统、服务本身实现等的多种限制：\n 操作系统  允许进程打开的最大fd数量，通常较小，需通过ulimit -n设置 默认进程、线程栈大小，偏大且进程数、线程数多的话，容易OOM 那个时代有些可观存在的限制：  glibc2.1以下版本使用16-bit数字记录句柄数，仅支持32767个 有的系统使用16位记录进程ID、现成ID，so可能创建不了太多进程、线程 有的系统预分配了太大的thread-local存储，比如1MB，假设虚地址空间2GB，那么最多创建2000个线程   内核本身存在问题  select、poll、epoll的改进 thundering herd（惊群）问题     服务实现  网络IO管理机制，同步、异步 服务采用的并发处理模型（ppc、tpc、cpc） 框架实现  zero-copy问题，了解收一个网络包的旅程，从网卡端口、驱动中buffer、内核协议栈、应用程序缓冲区，可借助系统调用来减少拷贝开销，推荐常见的零拷贝技术 使用writev避免发送小包，writev+iovec（scatter、gather分散读、聚集写） 使用TCP_CORK避免发送小包，将多个小包合并达到MSS后发送, see TCP_CORK 过载保护机制，过载时拒绝新连接，降低错误率。如使用IO ready的客户端数量来作为负载评估指标   caching技术   硬件能力  CPU 内存 网卡    解决c10k问题 # 我们就只关注服务实现过程中与之相关的部分。如果对网络编程、网络框架有清晰认识的话，一定对连接管理以及不同的编程模型有所认识。简单总结下了，不同连接管理方式对应着不同的编程模型：\n PPC（per process per connection），这类代表就是早期的Apache服务器，每个客户端入连接，都是fork一个cgi进程进行处理，进程是资源分配的单位，分配、进程调度的开销要大的多，性能差很容易理解。好处是进程隔离性强，一个进程崩了不影响其他进程； TPC（per thread per connection），每个客户端入连接，都创建一个独立的线程来对其进行处理，包括网络IO、事件处理。多线程模型相比多进程模型要好一些，操作系统的写时复制（copy on write）能避免不必要的资源分配，线程上下文切换也更加轻量。但在Linux下线程依然是轻量级进程（LWP），大量线程切换时的上下文开销依然不可忽视； CPC（per coroutine per connection），请求的处理不只是网络IO、syscall也有一些程序层面的同步，进程、线程级别的同步机制重、开销大，有没有更加轻量化的实现来最大化CPU资源利用率呢？比如当前代码执行序列现在要等待某个事件完成需要在执行上挂起，但是并不是IO或者阻塞性系统调用，线程能否先去处理其他请求，必要时再把当前位置的代码唤醒呢，而不是阻塞整个线程或者只能创建新线程来承载更多请求呢？可以，这就是协程方案（coroutine）；  说到这里，就不得不提下为什么要多个进程、多个线程，为了并发提高资源利用率。程序执行操作时，有些操作会阻塞程序执行导致其让出CPU，比如进行网络IO处理，或者执行一些其他的阻塞型的syscalls。\n针对网络IO处理，大家应该了解过同步阻塞、同步非阻塞、异步IO，我们就直说当前最成熟的、顶大梁的方案，同步非阻塞。Linux下通过epoll可以实现同步非阻塞IO，实现高效地IO事件处理。\n这种情况下，其实一定程度上可以将服务器程序中的线程分为两类：\n 连接IO事件管理线程 请求处理线程 请求处理协程  比如cpu是8c的，可以分配8个线程专门负责连接事件管理，连接上IO事件就绪后读取请求转发给请求处理线程处理，响应也由请求处理线程发送给IO处理线程，IO处理线程负责回包，数据的传递可以通过无锁内存队列来传递。IO处理线程可以指定一个线程池大小，允许最少空闲线程数（待命）、最大线程数，不能没有限制否则可能影响稳定性甚至OOM挂掉，服务器应该优先保证服务的健壮性，保证对上游承诺的SLA指标。\n腾讯曾经有一个服务器编程框架SPP就是大致这么解决的，它虽然是多进程架构，但是思路差不多：sppproxy单进程单线程负责连接管理，sppworker进程（多个，一般是单线程+协程方案）负责进行请求处理，它们之间通过共享内存队列传递数据。\n通过这种方式可以有效解决c10k问题，c10k问题也不再是个难以解决的问题！\n参考文中 the c10k problem给出了一些当时解决此类问题的示例：\n select based servers /dev/poll based servers epoll-based servers kqueue-based servers rtsig based servers thread-based servers in-kernel servers 把服务器实现搬进了内核中 :)  如果感觉陌生，不妨先读读我前些年总结的Linux常见IO模型。\n解决c10m问题, 2010, 10Gbps Ethernet #  我们直接无视了c100k问题，其实可能没有这种提法，毕竟它和c10k只是10倍的差距，不是什么大的挑战，而c10m和c10k比是1000倍的差距，可能工程师们还是喜欢2^10这样的倍数关系，这样才算的上挑战吧。\n ok，c10k相比c10m是上个10年的事情，那么到了2010年，大家是如何解决c10m问题的呢？要单机支持1000w并发连接数，即便是现在2024年，让一个工程师把个中技术讲个明白，也可以拿个不错的offer了吧 :)\nThe c10m problem! 依靠内核是不能胜任这个问题的，内核恰恰是问题所在！\n除了解决c10k的哪些可借鉴之处，这里整理了 Robert David Graham 2013 年分享中的一些要点 c10m: defending the Internet at scale。\n  packet scaling：内核提供的收包机制太重了，自定义网卡驱动，接管对网卡的管理，将收到的包直接递交给应用程序缓冲区，而不是传给内核协议栈，像这样的实现包括：\n PF_RING Netmap Intel DPDK  ps：现在有了一种相比较之下更好的技术，基于eBPF的高性能网络。\n  multi-core scaling\nspinlock,mutex,critical section,semaphores?\n no waiting un-synchonization  core local data ring buffers RCU (read-copy-update)   atomics  cmpxchg lock add   lockfree data structures thread models  pipeline worker   taskset thread affinity    CPU and memory\n  co-locate data\n  don\u0026rsquo;t: data structures all over memory connected via pointers\n  do: all the data together in one chunk of memory\nps：每次follow一个pointer都是一个cache miss，考虑访存延迟! 假设你的数据是A-\u0026gt;B-\u0026gt;C-\u0026gt;D，4个cache miss，如过组织成A|B|C|D，那么就可以减少到4次cache miss。\n    compress data\n bit-fields instead of large integers indexes (1, 2 bytes) instead of pointers (8 bytes) get rid of padding in data structures    cache efficient data structures\nB+ tree over Binary Search Tree, etc. 减少访存次数\n  NUMA\ndouble the main memory access time\n  memory pools\n per object per thread per socket defend against resource exhaustion    hyper-threading\nthreads \u0026gt; cores, 一个thread阻塞了其他thread可以继续跑，充分利用cpu\n  linux bootparam\n hugepages      ps：这里纯粹是听分享整理的，内容不是很详实。待过几天时间宽裕后再继续完善。\n本文小结 # 我们可以联想下自己使用的一些编程语言、服务框架、部署机器等等，覆盖了上述哪些要点，或者又引入了哪些其他没提到的方案，是否能胜任c10k、c10m问题。当然对于一个普通后台微服务（可能前段有lb、gateway拦着）也不会管理这么多连接，但是可以想一想，如果直接对接clients，能不能抗的住，如果抗不住问题会出现在哪里，如果能扛得住又是因为什么 :) 权当学习一下。\n参考文献 #  c10k, https://en.wikipedia.org/wiki/C10k_problem the c10k problem, http://www.kegel.com/c10k.html 2million connections by single box, https://web.archive.org/web/20140501234954/https://blog.whatsapp.com/196/1-million-is-so-2011 TCP_NODELAY and TCP_CORK, https://stackoverflow.com/a/19995579 常见零拷贝技术, https://www.hitzhangjie.pro/blog/2021-09-09-%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9B%B6%E6%8B%B7%E8%B4%9D%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/ Linux常见IO模型, https://www.hitzhangjie.pro/blog/2017-05-02-linux-common-io-model/ 解决c10m问题, http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html c10m: defend the Internet at scale, https://www.youtube.com/watch?v=73XNtI0w7jA  "}),a.add({id:24,href:"/tags/bpf/",title:"bpf",description:"",content:""}),a.add({id:25,href:"/tags/dwarf/",title:"dwarf",description:"",content:""}),a.add({id:26,href:"/tags/ebpf/",title:"ebpf",description:"",content:""}),a.add({id:27,href:"/categories/ebpf%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5/",title:"ebpf原理及实践",description:"",content:""}),a.add({id:28,href:"/tags/ftrace/",title:"ftrace",description:"",content:""}),a.add({id:29,href:"/tags/gofuncgraph/",title:"gofuncgraph",description:"",content:""}),a.add({id:30,href:"/tags/trace/",title:"trace",description:"",content:""}),a.add({id:31,href:"/tags/uftrace/",title:"uftrace",description:"",content:""}),a.add({id:32,href:"/blog/2023-12-12-%E8%A7%82%E6%B5%8Bgo%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8go-ftrace%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"观测Go函数调用：go-ftrace 设计实现",description:"go-ftrace 是一个基于Linux bpf(2) 实现的函数调用跟踪、耗时统计工具，功能类似内核工具 ftrace(1) 。go-ftrace主要解决的是如何无侵入式地实现对go程序用户态代码的跟踪、耗时分析。本文介绍下go-trace的设计实现。",content:" img { width: 680px; padding-bottom: 1rem; }  前言 # 不久前在团队内部做了点eBPF相关的技术分享，过程中介绍了下eBPF的诞生以及在安全、高性能网络、可观测性、tracing\u0026amp;profiling等领域的实践以及巨大潜力。另外，在我们项目开发测试过程中，也希望对go程序的性能有更好的把控，所以对“上帝视角”的追求是会上瘾的，所以我们也探索了下如何基于eBPF技术对go程序进行无侵入式地观测。\n分享过程中也演示了下我现阶段开发的go函数调用可观测性工具。下面是我的分享PPT，感兴趣的话可以打开阅读：eBPF原理及应用分享，欢迎一起学习交流。\n基础知识 # 本文重点不在于eBPF扫盲，但是如果有eBPF的基础的话，再看本文对go-ftrace的介绍会事半功倍。所以如果对eBPF没什么了解，可以先看看我的分享PPT，或者其他资料，知道个大概。\ngo-ftrace主要是对go程序中的函数调用进行跟踪并统计其耗时信息，也可以获取函数调用过程中的参数信息，这样结合起来，你可以看到不同输入下的处理耗时的差异。\n我们在前一篇文章里介绍了如何使用go-ftrace来跟踪go程序中的某些函数，甚至获取其执行过程中的函数参数信息。本文来详细介绍下go-ftrace的设计实现。\n内核视角 # 自打1993年bpf（berkeley packet filter）技术出现以来，这种CFG-based（control flow graph）的字节码指令集+虚拟机的方案就取代了当时的Tree-based cspf （cmu/standford packet filter）方案，而后几年在Linux内核中引入了bpf，定位是用来做些tcpdump之类的包过滤分析，在后来Linux内核中引入了kprobe技术，允许用户在内核模块中通过kprobe跟踪内核中的一些函数来进行观测、分析，此后的很多年，bpf技术一直在改进，逐渐演化成一个独立的eBPF子系统，kprobe、uprobe也可以直接回调eBPF程序，使得整个Linux内核变得可编程，而且是安全的。\n从跟踪角度来看，有静态跟踪、动态跟踪两种方式，静态跟踪主要是Linux内核中的一些tracepoints，动态跟踪主要是借助kprobe、uprobe技术。如果你阅读过我之前写的调试器的书籍（还未100%完成），你肯定会对“指令patch”技术有所了解，其实kprobe、uprobe技术的工作原理也是借助指令patch。\n 当我们通过系统调用bpf通知内核在指令地址pc处添加一个kprobe或者uprobe时，内核会将对应地址处的指令（有可能是多个字节）用一个一字节指令Int 3 (0xcc)代替，并在内核数据结构中记录下原指令内容，以及这个地址处是否是一个kprobe、uprobe。 当内核执行到这个指令0xcc时，它会触发一个异常，进而会执行Linux内核中断服务程序对其进行处理，内核会检查这个地址pc处是否有相关的kprobe、uprobe，有的话就跳过去执行，每个kprobe、uprobe实际上包含了prehandler、原指令、posthandler。先执行prehandler，如果返回码ok则继续执行原指令，再执行posthandler；如果prehandler返回错误码，那就不往后执行了，通过这个办法也可以拦截某些系统调用，如seccomp-bpf技术。  大致就是这样的一个过程，仔细深究的话kprobe、uprobe工作起来稍微有点差异。\n 注册kprobe你只需要告诉内核一个符号即可，比如一个系统调用名，内核会自己计算出这个符号对应的指令地址； 而注册一个uprobe的话，举个例子，go main.main函数，内核是不认识这个符号的，它也不知道main.main的地址该如何计算出来，就需要我们自己先算出来它的地址（实际上是相对于ELF文件开头的偏移量），然后再传给内核；  调试知识 # 那么针对不同的编程语言写的程序，如何指定一个符号来计算出对应的指令地址呢？这就是挑战点之一，不过在调试领域这个问题早就已经解决了，我们可以借鉴下来解决计算指定函数名的指令地址的问题。\nDWARF，是一种调试信息标准，目前是使用最广泛的调试信息格式。其实有多种调试信息格式，但是从对不同编程语言、不同特性、数据编解码效率的优势来看，它确实更胜一筹，所以现在主流编程语言生成的调试信息基本都是支持DWARF或者优先考虑DWARF。\n以go语言为例，当我们执行go build编译一个可执行程序时，以ELF binary文件为例，编译器、链接器会生成一些.[z]debug_开头的sections，这些sections中的数据就是调试信息。\n常见的ELF sections及其存储的内容如下:\n  .debug_abbrev, 存储.debug_info中使用的缩写信息；\n  .debug_arranges, 存储一个加速访问的查询表，通过内存地址查询对应编译单元信息；\n  .debug_frame, 存储调用栈帧信息；\n  .debug_info, 存储核心DWARF数据，包含了描述变量、代码等的DIEs；\n  .debug_line, 存储行号表程序 (程序指令由行号表状态机执行，执行后构建出完整的行号表)\n  .debug_loc, 存储location描述信息；\n  .debug_macinfo, 存储宏相关描述信息；\n  .debug_pubnames, 存储一个加速访问的查询表，通过名称查询全局对象和函数；\n  .debug_pubtypes, 存储一个加速访问的查询表，通过名称查询全局类型；\n  .debug_ranges, 存储DIEs中引用的address ranges；\n  .debug_str, 存储.debug_info中引用的字符串表，也是通过偏移量来引用；\n  .debug_types, 存储描述数据类型相关的DIEs；\n  以我们的go-ftrace为例，我们想跟踪某个函数的执行，就得先通过函数名找到对应的地址，怎么找呢？就是借助前面提到的这些.debug_ sections。简单说就是我们可以通过这些不同的调试信息构建起对go源码层面的全局视图，并且能在源码和内存表示（包括指令地址）之间建立起一种映射关系。\n这样我们就可以知道每个函数的第一条指令地址是多少，然后告诉内核分别在函数进入、退出的位置设置uprobes，然后我们为函数进入、返回这两类uprobes分别编写对应的eBPF回调函数。在进入的时候记录下此时的时间戳，在退出的时候也记录下时间戳，然后就可以计算耗时信息。\n尽管不了解DWARF也不妨碍阅读理解本文的大意，但如果想能定制化go-ftrace这样的工具，不了解DWARF是基本不可能做到的。如果你想了解这方面内容，建议阅读DWARF文档，或者阅读我的电子书golang-debugger-book 里关于DWARF的相关章节。目前DWARF v5出来不久，v5的特性使用还没有那么广泛，v4应用最广泛。\n设计目标 # 假定存在如下go代码，逻辑很简单，循环doSomething。为了演示trace跟踪时也能跟踪目标函数内部对其他函数的调用，示例代码中添加了add、add1、add2、add3，为了展示对函数执行耗时的统计，在不同函数内部加了sleep来模拟各函数的执行耗时。为了避免内联优化对DWARF分析函数位置的影响，我们在上述函数前面加了//go:noinline。\nps: 随着go编译工具链对内联函数生成的DWARF信息的优化，后续应该也可以去掉内联，现在加上最稳妥。\nfunc main() { for { doSomething() } } func doSomething() { add(1, 2) ... time.Sleep(time.Second) } //go:noinline func add(a, b int) int { fmt.Printf(\u0026quot;add: %d + %d\\n\u0026quot;, a, b) return add1(a, b) } //go:noinline func add1(a, b int) int { fmt.Printf(\u0026quot;add1: %d + %d\\n\u0026quot;, a, b) time.Sleep(time.Millisecond * 100) return add2(a, b) } //go:noinline func add2(a, b int) int { time.Sleep(time.Millisecond * 200) return add3(a, b) } //go:noinline func add3(a, b int) int { fmt.Printf(\u0026quot;add3: %d + %d\\n\u0026quot;, a, b) time.Sleep(time.Millisecond * 300) return a + b }  然后希望执行 ftrace -u main.add* ./main时，函数调用跟踪及耗时统计可以达到这样的效果，能展示函数执行进入、退出的时间戳、耗时，函数调用发生的位置，甚至函数实参信息。\n实现过程 # 下面按照程序执行流程，对流程中涉及到的技术细节进行下详细介绍。\n解析启动参数 # 为了更方便使用POSIX风格的命令行选项参数（长选项、短选项），这里还是使用的spf13/cobra来开发这个程序，原作者用的另外一个库，但是我使用起来感觉不太方便，所以这部分进行了重写，也方便我后续扩展其他功能。\n主要参数有这几个：\n// 是否排除vendor/定义的函数 rootCmd.Flags().BoolP(\u0026quot;exclude-vendor\u0026quot;, \u0026quot;x\u0026quot;, true, \u0026quot;exclude vendor\u0026quot;) // 指定要跟踪的函数名匹配模式 rootCmd.Flags().StringSliceP(\u0026quot;uprobe-wildcards\u0026quot;, \u0026quot;u\u0026quot;, nil, \u0026quot;wildcards for code to add uprobes\u0026quot;) // 将参数-u设置为必填参数 rootCmd.MarkFlagRequired(\u0026quot;uprobe-wildcards\u0026quot;)  当我们执行命令时就可以像下面这样使用：\n# 跟踪binary中main包下所有的函数、方法，而且可以多次使用-u指定多个匹配模式 ftrace [-u|--uprobe-wildcards] main.* \u0026lt;binary\u0026gt; # 也可以指定-x来排除vendor下定义的函数、方法 ftrace -u github.com/* [-x|--exclude-vendor] \u0026lt;binary\u0026gt; # 也可以自定参数来描述如何获取指定函数的参数信息 ftrace -u main.Add \u0026lt;binary\u0026gt; 'main.Add(p1=expr1:type1, p2=expr2:type2)'  spf13/cobra是一个很好用的命令行工具开发框架，感兴趣的可以了解不再赘述。大致知道为什么我们选择它就可以：支持POSIX风格选项解析（长选项、短选项）、方便扩展命令、选项、自动生成help信息、自动生成shell补全脚本。\n匹配函数获取 # 以我们指定的main.*这个匹配表达式为例，我们如何找到所有匹配的函数名呢？我们是拿不到源代码信息的，我们能拿到的只有已经编译构件号的go二进制程序。其实编译器、链接器已经生成了一些.symtab, .strtab，我们的函数名就存在于这些section中，并且对于一个Symbol，除了名字，还记录了这个符号表示的对象类型，比如“函数”。\n看下下面的示例代码：获取所有函数命名形如 main.*的函数。\n// 首先打开一个elf文件，其中的.symtab, .strtab没有被stripped f, err := elf.Open(\u0026quot;testdata/helloworld\u0026quot;) // 取出所有的symbols syms, err := f.Symbols() var funcs []string for _, s := range syms { // 如果不是函数类型跳过 if elf.ST_TYPE(s.Info) == elf.STT_FUNC { continue } // 如果命名不匹配main.*跳过 if !strings.Contains(s.Name, \u0026quot;main.\u0026quot;) { continue } // 记录下函数名 funcs.append(funcs, s.Name) }  在go-ftrace里面，为了实现方便组合使用了go-delve/delve下的DWARF相关package，以及标准库debug/elf，原理和上面是一致的。这样下来我们就获得了所有匹配模式main.*的待跟踪函数列表。\n函数地址转换 # 有了这些带跟踪的函数名列表之后，我们希望程序执行时进入、退出函数时能生成一个事件并回调自定义的回调函数，回调函数里我们分别统计开始执行时间、介绍执行时间，这样就能计算出这个函数的耗时信息。\n要想在函数进入、退出时产生回调特定函数，就要利用到eBPF+uprobe了，我们用eBPF写uprobe的回调函数，再通过bpf系统调用通知内核将某个uprobe和eBPF程序attach起来之前，我们得先创建uprobe。在创建uprobe之前，我们得先知道每个待跟踪函数的入口指令的地址，以及返回指令的地址，这里的地址后面用pc(程序计数器)代替。\nps: 学过组成原理的话，应该了解到pc=cs:ip，其实就是下条待执行指令的地址，但是我们这里用pc代指了函数入口指令地址、返回指令地址。\n函数入口添加uprobe # 获得函数入口指令地址，也并不困难，下面是获取入口指令地址、offset（相对于ELF文件开始位置）的示例代码：\nsym, err := elf.ResolveSymbol(funcname) if err != nil { return nil, err } // 函数入口偏移量 entOffset, err := elf.FuncOffset(funcname) if err != nil { return nil, err } uprobes = append(uprobes, Uprobe{ Funcname: funcname, Location: AtEntry, Address: sym.Value, // 指令地址 AbsOffset: entOffset, // 相对偏移量 RelOffset: 0,	// 相对入口指令偏移量，当然是0 })  那elf.FuncOffset(funcname)是如何实现的呢？\n// 返回函数定义在ELF文件中的偏移量 func (e *ELF) FuncOffset(name string) (offset uint64, err error) { sym, err := e.ResolveSymbol(name) if err != nil { return } section := e.Section(\u0026quot;.text\u0026quot;) return sym.Value - section.Addr + section.Offset, nil }  有几个地方要说明下：\n symbol.Value：符号表示的对象（变量、类型、函数等）在进程虚地址空间中的地址； section.Addr：如果不为0表示会被加载到内存，它表示该section第一字节在进程虚地址空间中的地址； section.Offset：表示该section第一字节在ELF文件中的偏移量；  所以 sym.Value - section.Addr + section.Offset表示该符号在ELF文件中的偏移量。这可能和我们预期的“虚拟内存地址pc”有点偏差。或者说，当执行系统bpf系统调用设置uprobe时，我们实际传入的位置信息：\n 是一个相对于ELF文件开头的偏移量呢？ 还是一个相对于.text section开头的偏移量呢？ 还是一个虚拟内存地址呢？  go-ftrace执行bpf操作是利用了cilium/bpf工程提供的封装，``github.com/cilium/ebpf/link.Uprobe|Uretprobe()，这几个函数也是允许指定symbol，那前面获取这些符号地址有啥作用呢？是这样的，Uprobe、Uretprobe只能处理非共享库、且语言是CC++之类的场景，如果是共享库或者是其他语言的，需通过UprobeOptions{Offset: \u0026hellip;}`来说明uprobe位置（ELF文件中指令相对于文件开头的偏移量）。\n所以你看我前面计算了很多AbsOffset偏移量（相对于ELF文件开头），最终就是利用这些偏移量来设置的。如果进一步了解下cilium使用的系统调用perf_event_open，会了解的更清楚。perf_event_open，该系统调用允许接受一个perf_event_attr的参数来设置kprobe、uprobe。\n $ man 2 perf_event_open\n\u0026hellip;\nkprobe_func, uprobe_path, kprobe_addr, and probe_offset\nThese fields describe the kprobe/uprobe for dynamic PMUs kprobe and uprobe.\n For kprobe: use kprobe_func and probe_offset, or use kprobe_addr and leave kprobe_func as NULL. For uprobe: use uprobe_path and probe_offset.   再看cilium中对此系统调用的使用过程，看下它是怎么设置perf_event_attr参数的：\nfunc pmuProbe(typ probeType, args probeArgs) (*perfEvent, error) { ... var ( attr unix.PerfEventAttr sp unsafe.Pointer ) switch typ { case kprobeType: ... case uprobeType: sp, err = unsafeStringPtr(args.path) if err != nil { return nil, err } ... attr = unix.PerfEventAttr{ Size: unix.PERF_ATTR_SIZE_VER1, Type: uint32(et), // PMU event type read from sysfs Ext1: uint64(uintptr(sp)), // Uprobe path（二进制文件） Ext2: args.offset, // Uprobe offset （相对于ELF文件） ... } } rawFd, err := unix.PerfEventOpen(\u0026amp;attr, args.pid, 0, -1, unix.PERF_FLAG_FD_CLOEXEC) ... }  通过man perf_event_open查看attr结构体定义，实际上上述代码中Ext1、Ext2分别对应uprobe_path和probe_offset，刚好对上。uprobe_path实际上就是我们的二进制程序的路径信息，而probe_offset就是要设置uprobe的指令处在ELF文件中的偏移量信息。\n之后，内核会读取并解析uprobe_path对应ELF文件的headers信息，计算probe_offset处指令对应的uprobe地址，然后注册uprobe。\n ps：不禁要问，内核为什么不直接要一个逻辑地址来描述uprobe的位置呢？考虑下来可能就是为了一致性、简单性、可理解性。用逻辑地址可以吗？实现肯定能实现，但是看到这种参数开发者要去理解地址映射逻辑、加载逻辑，至少会去“仔细”确认这些信息吧。内核中其他系统调用在处理类似场景时可能也是更倾向于使用offset，应该也有一致性的考虑。先知道这个就行了。\n 函数返回前添加uprobe # 函数返回时比较特殊，它可能存在多个返回语句，这个也比较好理解。多个返回语句，也就是多条返回指令，每个返回指令地址处都应该添加uprobe。\n// 函数返回指令偏移量 retOffsets, err := elf.FuncRetOffsets(funcname) for _, retOffset := range retOffsets { uprobes = append(uprobes, Uprobe{ Funcname: funcname, Location: AtRet, //Address: AbsOffset: retOffset, // 返回指令的偏移量（相对于ELF文件） RelOffset: retOffset - entOffset, // 返回指令的偏移量（相对函数入口） }) } // FuncRetOffsets returns the offsets of RET instructions of function `name` in ELF file // // Note: there may be multiple RET instructions in a function, so we return a slice of offsets func (e *ELF) FuncRetOffsets(name string) (offsets []uint64, err error) { insts, _, offset, err := e.FuncInstructions(name) if err != nil { return } for _, inst := range insts { if inst.Op == x86asm.RET { offsets = append(offsets, offset) } offset += uint64(inst.Len) } return }  注意到，在设置函数入口的uprobe时，我们是设置了Uprobe.Address字段的，但是设置函数退出的uprobe时却没有，为什么呢？\n 在注册uprobe时，确实只需要指令地址相对于ELF文件的偏移量（前面已解释过）； 在设置函数入口Uprobe.Address，主要是为了用来设置eBPF maps中的配置信息，如我们跟踪的某个函数是否需要获取参数之类的，而这之需要设置函数入口处的uprobe就够了，函数返回处的uprobe就不需要再计算并设置其地址信息了。  DWARF中函数的lowpc、highpc的指令地址，这个地址是指令的逻辑地址，上述实现FuncRetOffset(name string)中做了从逻辑地址向ELF文件开头的偏移量的转换。\n ps：函数的lowpc实际上是函数被编译后第一条指令的逻辑地址，highpc是最后一条指令的逻辑地址。函数定义在DWARF中是以DIE（Debugging Information Entry）的形式存储在.[z]debug_info中的，对于描述函数的DIE，其Tag会表明它是一个TagSubprogram（函数），同时它会包含相关的AttrLowpc、AttrHighpc来描述函数包含的指令集合的逻辑地址范围。了解这写些就可以了，不再继续展开。\n 参数寻址规则 # 如果我们需要获取函数的参数信息，该怎么办？很简单，其实只要知道参数在内存中的起始地址，以及数据类型信息就可以了。这样我们就可以按照指定的数据类型的大小从内存读取一定数量的bytes，然后再将其解析成对应的数据类型即可。\nps：当然这里的参数也可能是一个寄存器中的立即数，这样就简单了很多。\n这里的寻址规则，我们可以自己设计一个，比如借鉴下计算机组成原理的有效地址（EA，Effective Address）的寻址方式的写法，这里我们为了实现起来简单，又便于理解，自己设计了一种写法。\n// 基本写法 functionName(argument1=(expr1):type1, argument2=(expr2):type2, argument3=(expr3):type3)   argument1~3: 这是我们为要捕获的参数自定义的一个标识符名 expr1~3: 这是参数值实际存储的有效地址，必须先从有效地址处读取数据，然后才能解析成期望类型（也可能是一个寄存器立即数） type1~3: 这是参数值对应的数据类型，\u0026rsquo;s|u' for 整数, \u0026lsquo;c\u0026rsquo; for 字符串  s64 表示64位 有符号整数 u64 表示64位 无符号整数 c64 表示共8字节的字符串    以这个为例，我们解释下它的含义：\nmain.(*Student).String(s.name=(*+0(%ax)):c64, s.name.len=(+8(%ax)):s64, s.age=(+16(%ax)):s64)  其中main.(*Student).String()的定义如下：\n// go代码Student定义 type Student { name string age int }  实际上pahole分析出的它的内存布局：\n$ ../scripts/offsets.py --bin ./main --expr 'main.Student' struct main.Student { struct string name; /* 0 16 */ int age; /* 16 8 */ /* size: 24, cachelines: 1, members: 2 */ /* last cacheline: 24 bytes */ };  对于String()方法，其第一个参数是其接收器类型main.(*Student)，它的起始地址将通过AX寄存器传递，在规则中我们使用%ax代表物理寄存器RAX or EAX，然后呢Student.age相对于Student对象起始的偏移量是16字节，所以规则 s.age=(+16(%ax)):s64指出了age的有效地址+16(%ax)，以及数据类型s64。规则中的()只起到分组、增强可读性的作用，并不像计算机组成原理中那样用来取数据（取寄存器或者内存单元中的数据）。\n类似地，对Student.name我们也可以这样分析，只不过对于string类型比较特殊：\n$ ../scripts/offsets.py --bin ./main --expr 'main.Student-\u0026gt;name' Member(name='name', type='string', is_pointer=False, offset=0) struct string { uint8 *str; /* 0 8 */ int len; /* 8 8 */ /* size: 16, cachelines: 1, members: 2 */ /* last cacheline: 16 bytes */ };  string本身就是一个struct来表述的，它底层数组的起始地址，以及长度信息。其实main.Student的起始地址就是main.Student.name.str成员的起始地址，但是这里的str是一个指针，可以理解成它指向一个长度为len的byte数组。main.Student.name.str成员的起始地址并不是EA，*(main.Student.name.str)才是EA，所以规则里s.name=(*+0(%ax)):c64读者应该看懂了吧。获取name字符串长度的操作s.name.len=(+8(%ax)):s64也不难明白了。\nps：有时候传参是通过寄存器传递的立即数，这种规则就更简单了，比如your_arg=(%si):u64。这里些的比较简短，如果你想详细了解，可以阅读这里的FetchArgRule 获取参数的规则。\n协程执行过程 # OK，读到这里的都是技术细节控 :) 现在我们知道怎么在函数入口、退出时设置uprobe了，也知道怎么通过寻址规则来获取任意参数的信息了。我们先把任务做的简单点，假设我们只统计函数耗时信息，我们应该怎么做呢？\nfunc main() { add() } func add() { add1() }  上述函数在执行时，我们希望统计成这样：\ntimestamp1 main.main { args... timestamp2 main.add { args... timestamp3 main.add1 args... timestamp4 timecost1 } main.add1 end timestamp5 timecost2 } main.add end timestamp6 timecost3 } main.main end  要知道，main.add、main.add1 函数可能在任意goroutine中被调用，那么我们汇总上述函数调用过程中的耗时时就必须意识到，我们要针对每个goroutine单独统计它执行过程中的函数栈帧的expand、shrink问题：\n 函数调用进入，新建一个栈帧 函数调用返回、栈帧销毁  比如我们分析一个函数main.main，我们就会将main.main这个位置作为一个根，在其下发起的新的函数调用、返回都伴随着在根下新建节点、移除节点的过程，当每个节点新建、移除时我们就收集到了一连串的事件（uprobe、uretprobe事件被触发，对应的时间戳被记录下来），然后最后连根main.main也返回时，就意味着我们观测的对象已经执行结束了，我们已经收集全了所有的信息，现在是时候打印出上述收集到的执行信息了。\n所以，其实我们可以用一个栈（stack）来记录每个goroutine上的信息函数调用、函数返回的事件信息，当栈空时就可以打印收集到的执行信息，并清空这些信息。后续goroutine仍然有可能再次执行这个函数，这个栈又会增长、缩减、被打印执行信息，直到这个goroutine退出时，我们就可以从eBPF maps中删除这个goroutine对应的栈数据结构。\n大致实现过程就是这样的，那很重要的一点就是，我们必须获取到goroutine的唯一标志goid，这样我们才能在eBPF maps中为每个goroutine创建与之关联的stack。\n获取协程goid # 先说事实，goid是存储在runtime.g这个结构体中的成员，而runtime.g的地址是存储在线程局部存储（Thread Local Storage，TLS）中的。\n那么，如果我们知道TLS在虚拟内存空间中的存储位置，并且知道runtime.g在TLS block中的偏移量信息，那么我们就能读取出runtime.g的地址。如果我们再知道goid相对于包含它的结构体runtime.g的offset，那么我们也就可以继续读取出goid的值。\n如何获取TLS地址 # TLS地址在现代处理器中一般是有专门的寄存器来存的，比如FS寄存器。以Linux为例，这个寄存器的数据会存储在task_struct-\u0026gt;thread (thread_struct) -\u0026gt; fsbase字段中：\n 获取指定任务task_struct在eBPF程序中是很简单的事情，仅需要调用函数bpf_get_current_task即可； 然后通过offsetof，我们可以轻易获取到thread成员相对于task_struct的偏移量，这里的thread_task是个结构体； 然后继续获取fsbase相对于thread_task的偏移量，这样就可以获取出fsbase的值；  简言之最终的fsbase相对于task_struct的偏移量就是这样：\n// offset of `task_struct-\u0026gt;thread_struct-\u0026gt;fsbase`, `fsbase` contains the TLS // offset. On Linux register `FS` is used to load the TLS base address. #define fsbase_off (offsetof(struct task_struct, thread) + offsetof(struct thread_struct, fsbase))  然后这样就可以读取到TLS的地址了：\n__u64 tls_base, g_addr, goid; struct task_struct *task = (struct task_struct *)bpf_get_current_task(); bpf_probe_read_kernel(\u0026amp;tls_base, sizeof(tls_base), (void *)task + fsbase_off);  如何获取runtime.g在TLS中偏移量 # 要想准确获取runtime.g在TLS block中的offset，还是有一点复杂的，因为这里牵扯到了不同链接方式、不同平台的差异性，对于纯go程序而言就比较简单，runtime.g相对于TLS块的偏移量是-8。\nps：您可以阅读下面代码了解下在非纯go等情景下，偏移量是如何计算的。\n// FindGOffset returns the runtime.g offset // // see: github.com/go-delve/delve/proc/bininfo.go:setGStructOffsetElf, // // it summarizes how to get the runtime.g offset: // This is a bit arcane. Essentially: // - If the program is pure Go, it can do whatever it wants, and puts the G // pointer at %fs-8 on 64 bit. // - %Gs is the index of private storage in GDT on 32 bit, and puts the G // pointer at -4(tls). // - Otherwise, Go asks the external linker to place the G pointer by // emitting runtime.tlsg, a TLS symbol, which is relocated to the chosen // offset in libc's TLS block. // - On ARM64 (but really, any architecture other than i386 and x86_64) the // offset is calculated using runtime.tls_g and the formula is different. // // well, this is a bit hard to master all this kind of history. // but, we can show respect to the contributors. func (e *ELF) FindGOffset() (offset int64, err error) { _, symnames, err := e.Symbols() if err != nil { return } // When external linking, runtime.tlsg stores offsets of TLS base address // to the thread base address. tlsg, ok := symnames[\u0026quot;runtime.tlsg\u0026quot;] tls := e.Prog(elf.PT_TLS) if ok \u0026amp;\u0026amp; tls != nil { // runtime.tlsg is a symbol, its symbol.Value is the offset to the // beginning of the that TLS block. // // FS register is the offsets which points to the end of the TLS block, // this block's size is memsz long. // // so, offsets where runtime.g stored = FS + runtime.tlsg.Value - memsz memsz := tls.Memsz + (-tls.Vaddr-tls.Memsz)\u0026amp;(tls.Align-1) return int64(^(memsz) + 1 + tlsg.Value), nil } // While inner linking, it's a fixed value -8 ... at least on x86+linux. return -8, nil }  这样，我们就可以进一步读取到runtime.g的地址信息：\nbpf_probe_read_user(\u0026amp;g_addr, sizeof(g_addr), (void *)(tls_base + CONFIG.g_offset));  获取goid的偏移量 # 因为runtime.g的源码是公开的，要确定goid的偏移量的话，易如反掌，也可以通过前面介绍的pahole工具自动分析下。假定这个偏移量是goid_offset的话。\n最终我们就可以读取出goid的值：\nbpf_probe_read_user(\u0026amp;goid, sizeof(goid), (void *)(g_addr + CONFIG.goid_offset));  有了goid之后，我们就可以用它做eBPF maps中的goroutine的key，来记录每个协程关联的一些事件统计数据。\n加载BPF程序 # 前面讲了如何获取函数定义入口的指令地址、返回指令的指令地址相对ELF文件的偏移量问题。并且也提到了Linux系统调用perf_event_open的参数perf_event_attr如何来设置uprobe的位置信息（uprobe需要通过uprobe_path、probe_offset）。但是在注册uprobe时，我们不光要指定待跟踪的位置信息，还需要指定当程序执行到这个位置时，应该如何反应。所以在本小节之后我们还要描述下自定义的uprobe的回调函数的内容，也就是我们eBPF程序。\n这里我们先不管eBPF程序怎么写，先描述下eBPF程序的加载，加载过程归根究底是利用了系统调用bpf(2)来完成，此时只是提交给内核一个eBPF程序，该程序已经通过clang -target=bpf编译成了bpf字节码指令，提交给内核后eBPF子系统中的验证器开始工作，它会检查该eBPF程序是否符合要求，比如是否很复杂、是否有无穷或者次数很多的循环、是否有内存越界等行为，只有符合要求的程序才会通过验证并加载。eBPF子系统还会调用JIT编译期将bpf字节码指令进一步转换为native指令，使其执行效率接近原生指令效率。\n接下来，我们就看下go-ftrace里面是如何加载eBPF程序的，它没有直接调用bpf系统调用，而是使用了cilium/bpf中对该系统调用的封装。\n// load bpf programme and setup bpf programme config if err = t.bpf.Load(uprobes, bpf.LoadOptions{ GoidOffset: goidOffset, GOffset: gOffset, }); err != nil { return }  这个过程中具体做了哪些事情呢？\n// Load 加载这个bpf程序 func (b *BPF) Load(uprobes []uprobe.Uprobe, opts LoadOptions) (err error) { // 加载bpf程序，这部分是用C语言写的，然后clang编译成-target bpf的字节码程序，扩展名为*.o， // 这个*.o文件也是ELF文件头的 spec, err := LoadGoftrace() if err != nil { return err } b.objs = \u0026amp;GoftraceObjects{} ... // 是否要获取参数：遍历所有uprobes，检查有没有要获取参数的，有就更新为true fetchArgs := false // 返回一个bpf配置，并将cfg写入eBPF maps，作为运行在内核态的bpf程序要读取的配置 cfg := b.BpfConfig(fetchArgs, opts.GoidOffset, opts.GOffset) if err = spec.RewriteConstants(map[string]interface{}{\u0026quot;CONFIG\u0026quot;: cfg}); err != nil { return } // 继续加载*.o中的bpf程序和maps if err = spec.LoadAndAssign(b.objs, \u0026amp;ebpf.CollectionOptions{ Programs: ebpf.ProgramOptions{LogSize: ebpf.DefaultVerifierLogSize * 4}, }); err != nil { return } // 遍历所有uprobes中的参数获取规则，将其写入bpf maps配置arg_rules_map中， // - key就是函数入口地址， // - val就是该函数的多个参数获取的规则描述配置 for _, uprobe := range uprobes { if len(uprobe.FetchArgs) \u0026gt; 0 { if err = b.setArgRules(uprobe.Address, uprobe.FetchArgs); err != nil { return } } ... } return }  主要是这里的LoadAndAssign函数，我们用C写的bpf程序部分是运行在内核态中的，它被clang编译为-target bpf的字节码程序，在C程序中通过一些特定的编译器扩展允许指定编译器、链接器将特定的函数编译后写入特定的ELF section中。\nSEC(\u0026quot;uprobe/ent\u0026quot;) int ent(struct pt_regs *ctx) { __u32 key = 0; struct event *e = bpf_map_lookup_elem(\u0026amp;event_stack, \u0026amp;key); if (!e) return 0; __builtin_memset(e, 0, sizeof(*e)); ... } SEC(\u0026quot;uprobe/ret\u0026quot;) int ret(struct pt_regs *ctx) { __u32 key = 0; struct event *e = bpf_map_lookup_elem(\u0026amp;event_stack, \u0026amp;key); if (!e) return 0; __builtin_memset(e, 0, sizeof(*e)); ... }  #define SEC(name) \\ _Pragma(\u0026quot;GCC diagnostic push\u0026quot;)	\\ _Pragma(\u0026quot;GCC diagnostic ignored \\\u0026quot;-Wignored-attributes\\\u0026quot;\u0026quot;)	\\ __attribute__((section(name), used))	\\ _Pragma(\u0026quot;GCC diagnostic pop\u0026quot;)	 比如上面的程序在被clang -target bpf编译为*.o文件后，尝试用readelf读取sections定义：\n$ readelf -S goftrace_bpfel_x86.o There are 31 section headers, starting at offset 0xc0a90: Section Headers: [Nr] Name Type Address Offset Size EntSize Flags Link Info Align ... [ 3] uprobe/ent PROGBITS 0000000000000000 00000040 0000000000000c48 0000000000000000 AX 0 0 8 [ 5] uprobe/ret PROGBITS 0000000000000000 00000c88 0000000000000200 0000000000000000 AX 0 0 8 ...  Load过程中就会遍历并记录下上述特殊的sections的内容，每一个section的内容都是一个*ebpf.Program，也就是SEC(name)这里的name函数期望的eBPF回调程序。\nps：除了加载这些bpf程序到内核，它也会加载定义的一些bpf maps数据结构，如用到的hash、queue、stack、array，这些数据结构可能会用来充当配置，也可能用来存储执行结果，实现用户态、内核态的数据交互。这些maps数据结构定义，编译后会统一放在maps这个ELF section中。\n以函数参数的获取规则为例，arg_rules_map 是一个hash，kv存储结构，k就是函数入口地址，v就是对一个函数的参数获取规则。arg_rules_map通过SEC(\u0026ldquo;maps\u0026rdquo;)来修饰，编译后会记录在ELF maps section中，这里的加载逻辑就是告诉内核给创建一个这样的结构备用。然后通过b.setArgRules(uprobe.Address, uprobe.FetchArgs)来填充数据。\nstruct bpf_map_def SEC(\u0026quot;maps\u0026quot;) arg_rules_map = { .type = BPF_MAP_TYPE_HASH, .key_size = sizeof(__u64), .value_size = sizeof(struct arg_rules), .max_entries = 100, };  关联BPF程序 # attach eBPF程序，这里翻译为了“关联”，可能不太贴切……关联的过程就简单了，只需要通过系统调用来将函数入口地址、返回地址，与对应的eBPF程序关联起来即可。\nup, err := ex.Uprobe(\u0026quot;\u0026quot;, prog, \u0026amp;link.UprobeOptions{Offset: up.AbsOffset}) if err != nil { return err }  其中prog就是section中的回调程序，然后后面的link.UprobeOptions.Offset就是函数入口地址相对ELF文件开头的偏移量，这几个参数传给系统调用，就可以完成uprobe和eBPF程序的关联。\n生成事件信息 # 还记得这张图吗，我们前面讲的都是ftrace工具的用户态部分，包括如何确定要跟踪的函数、确定函数进入退出的uprobes、将内核态部分加载到内核，并将uprobes与bpf程序关联起来。\n我们还没有讲内核态部分的逻辑是怎么实现的？接下来我们就需要看看每个回调函数是如何写的，它们怎么记录事件的，然后用户态程序部分怎么轮询事件的。\n截止到目前为止，大部分的eBPF程序内核态部分都是通过C语言来写的，当然Rust可以使用Aya来写，其他语言只能用C写完内核态部分后再使用编译器编译为eBPF字节码，然后通过系统调用load、attach。我们这里也是使用C语言来写。\n这部分的设计实现，参考了go调试器go-delve/delve中的设计实现，为什么调试器也会用到eBPF呢？因为调试器中也有tracepoint之类的设计，当执行到某个地方时打印一下，eBPF就很合适。部分代码也是摘取自go-delve/delve，言归正传说下这里的实现。\n函数入口事件 # 当一个函数调用发生时，首先触发的是uprobe/ent，对应的函数定义如下，这个函数最终编译后会存储在ELF文件的section uprobe/ent中，然后Load、Attach的时候将uprobe的ip和这段prog attach起来。等函数调用发生时，就会回调这里的函数。\n看下这个函数的逻辑，大致逻辑就是，生成一个新的事件event，其中记录下来goid、ip、类型、时间戳，这样就能描述谁（goid）在什么时间（time_ns）调用（ENTRY）了什么函数（ip）。bp、caller bp、caller ip可以帮助我们进一步确定一些其他信息，后面再解释。\nSEC(\u0026quot;uprobe/ent\u0026quot;) int ent(struct pt_regs *ctx) { // event_stack是一个BPF_MAP_TYPE_PERCPU_ARRAY，每个CPU都有一个独立的数组来记录其事件信息， // event_stack用来传递每个CPU上的事件信息，这里的key==0，因为event_stack是一个栈，对于任意 // key对应的元素总是存在，这意味着它会创建一个新的event。 __u32 key = 0; struct event *e = bpf_map_lookup_elem(\u0026amp;event_stack, \u0026amp;key); if (!e) return 0; __builtin_memset(e, 0, sizeof(*e)); // 获取当前cpu上的线程正在执行的协程的goid，并将该goid与事件e关联起来，表示事件e是由goid标识 // 的协程触发的，同时也将当前的ip（函数入口地址）与事件e关联起来。 // ... 这里可能有点好奇，这里的事件e到底是个什么东西？ e-\u0026gt;goid = get_goid(); e-\u0026gt;ip = ctx-\u0026gt;ip; // ip表示触发uprobe对应的函数入口地址，这里通过hash结构should_trace_rip查询该函数是否应该被 // 跟踪，这个hash的写入是在bpf.(*BPF).Load(urpobes, opts)方法中设置的，根据uprobe来设置某 // 个rip是否应该被跟踪 ... 这一步疑似有些多余，因为不跟踪压根不会走到这里 // // 如果当前函数不该被跟踪，并且当前goid也没有过记录，就返回 if (!bpf_map_lookup_elem(\u0026amp;should_trace_rip, \u0026amp;e-\u0026gt;ip)) { if (!bpf_map_lookup_elem(\u0026amp;should_trace_goid, \u0026amp;e-\u0026gt;goid)) return 0; } // 如果当前函数要被跟踪，但是当前goid没被跟踪过，则应该追踪它 else if (!bpf_map_lookup_elem(\u0026amp;should_trace_goid, \u0026amp;e-\u0026gt;goid)) { __u64 should_trace = true; bpf_map_update_elem(\u0026amp;should_trace_goid, \u0026amp;e-\u0026gt;goid, \u0026amp;should_trace, BPF_ANY); } // 记录下当前事件的信息：是进入函数类型、进入事件戳ns、栈基址、调用方栈基址 e-\u0026gt;location = ENTPOINT; e-\u0026gt;time_ns = bpf_ktime_get_ns(); e-\u0026gt;bp = ctx-\u0026gt;sp - 8; e-\u0026gt;caller_bp = ctx-\u0026gt;bp; // 记录发起当前函数调用位置的ip，此时sp指向的位置是caller的返回地址（不了解可以看下函数调用过程 // 中的栈增长过程，压参数、压返回地址、压caller bp、减小rsp分配栈空间） // see: https://hitzhangjie.gitbook.io/libmill/basics/stack-memory void *ra; ra = (void *)ctx-\u0026gt;sp; bpf_probe_read_user(\u0026amp;e-\u0026gt;caller_ip, sizeof(e-\u0026gt;caller_ip), ra); // 按需获取参数信息 if (!CONFIG.fetch_args) goto cont; fetch_args(ctx, e-\u0026gt;goid, e-\u0026gt;ip); cont: // 将上述事件放到栈 event_queue 中，BPF_EXIST表示如果栈慢了则移除最老的元素腾空间 return bpf_map_push_elem(\u0026amp;event_queue, e, BPF_EXIST); }  函数返回事件 # 与函数调用进入相对应的就是函数返回事件，其对应的eBPF处理程序如下：\nSEC(\u0026quot;uprobe/ret\u0026quot;) int ret(struct pt_regs *ctx) { // 生成1个新的事件，用来记录当前函数退出的信息 __u32 key = 0; struct event *e = bpf_map_lookup_elem(\u0026amp;event_stack, \u0026amp;key); if (!e) return 0; __builtin_memset(e, 0, sizeof(*e)); // 记录执行该函数的goid e-\u0026gt;goid = get_goid(); if (!bpf_map_lookup_elem(\u0026amp;should_trace_goid, \u0026amp;e-\u0026gt;goid)) return 0; // 记录：事件类型（函数退出）、当前ret指令的指令地址、此时的时间戳ns e-\u0026gt;location = RETPOINT; e-\u0026gt;ip = ctx-\u0026gt;ip; e-\u0026gt;time_ns = bpf_ktime_get_ns(); // 将当前事件记录到栈中，如果栈满则移除最旧的元素腾空间 return bpf_map_push_elem(\u0026amp;event_queue, e, BPF_EXIST); }  协程退出事件 # 当1个协程退出时，就从是否应该跟踪的配置should_trace_goid里删除当前goid，goroutine有自己的生命周期，要及时清理资源，内核对bpf程序要求很苛刻。\nSEC(\u0026quot;uprobe/goroutine_exit\u0026quot;) int goroutine_exit(struct pt_regs *ctx) { __u64 goid = get_goid(); bpf_map_delete_elem(\u0026amp;should_trace_goid, \u0026amp;goid); return 0; }  如果一个goroutine退出了，意味着其过去记录的所有函数调用都正常返回了，events栈也是空的，没啥要特殊处理的，这里仅需要从map里删掉这个goid对应的key、value即可，节省空间。\n其他考虑 # 为什么uprobe/ent会有这么奇葩的判断呢？如果当前函数没被跟踪，为什么不直接返回呢？却去判断当前goid应不应该被追踪？可能会有这种极端情况，当我们准备取消跟踪时，此时会更新map里的配置告诉我们的eBPF程序这些函数不要继续追踪了。\n那么这里的判断就有意义，它可以避免之前某个goroutine上记录的函数调用链不完整的问题。\nif (!bpf_map_lookup_elem(\u0026amp;should_trace_rip, \u0026amp;e-\u0026gt;ip)) { if (!bpf_map_lookup_elem(\u0026amp;should_trace_goid, \u0026amp;e-\u0026gt;goid)) return 0; }  如何获取参数 # 前面描述了如何描述一个参数的寻址规则，根据具体的EA（Effective Address）或者寄存器中的立即数去读取对应的数据并解析成对应数据类型的工作，其实也是在这个内核态部分去完成的，主要就是靠这两个函数调用：\n  bpf_probe_read_kernel，读取寄存器信息\n  bpf_probe_read_user，读取内存信息\n  如果你对调试器中读取进程内存信息有过了解的话，一定对syscall ptrace的类似操作（PTRACE_PEEK_DATA/PTRACE_POKE_DATA）不陌生，那么理解这里的操作就很容易。无非就是内核提供的工具函数，帮助读取进程上下文中的特定寄存器的值，读取进程地址空间中特定内存位置的信息，仅此而已。\n其他的就是对上述寻址规则的利用，我们的有效地址最终会被拆解为一系列的操作：寄存器操作、内存操作1、内存操作2、……，每一步操作都是通过上面的两个工具函数之一来完成，最终读取到想要的参数。\n详细实现如下，读取到的函数参数信息，将被记录到对应的参数队列中，等着后续打印过程中去读取、展示。\n// 从寄存器中读取参数信息 static __always_inline void fetch_args_from_reg(struct pt_regs *ctx, struct arg_data *data, struct arg_rule *rule) { read_reg(ctx, rule-\u0026gt;reg, (__u64 *)\u0026amp;data-\u0026gt;data); bpf_map_push_elem(\u0026amp;arg_queue, data, BPF_EXIST); return; } // 从内存中读取参数信息 static __always_inline void fetch_args_from_memory(struct pt_regs *ctx, struct arg_data *data, struct arg_rule *rule) { // first read the address from register (well, it maybe a immediate value) __u64 addr = 0; read_reg(ctx, rule-\u0026gt;reg, \u0026amp;addr); // then do other addressing rules for (int i = 0; i \u0026lt; 8 \u0026amp;\u0026amp; i \u0026lt; rule-\u0026gt;length; i++) { // if expr = *+8(+2(%eax)), for *+8 part, we need to dereference the address if (rule-\u0026gt;dereference[i] == 1) { bpf_probe_read_user(\u0026amp;addr, sizeof(addr), (void *)addr + rule-\u0026gt;offsets[i]); } // if the rule is +2 part, then we just add the offset to the address else { addr += rule-\u0026gt;offsets[i]; } } // finally, we got the EA (effective address), then read the data from it, // make sure the data size is not larger than MAX_DATA_SIZE bpf_probe_read_user(\u0026amp;data-\u0026gt;data, rule-\u0026gt;size \u0026lt; MAX_DATA_SIZE ? rule-\u0026gt;size : MAX_DATA_SIZE, (void *)addr); // put the read data into the queue bpf_map_push_elem(\u0026amp;arg_queue, data, BPF_EXIST); return; } // read register `reg` data from `ctx` into `regval` static __always_inline void read_reg(struct pt_regs *ctx, __u8 reg, __u64 *regval) { switch (reg) { case 0: bpf_probe_read_kernel(regval, sizeof(ctx-\u0026gt;ax), \u0026amp;ctx-\u0026gt;ax); break; case 1: bpf_probe_read_kernel(regval, sizeof(ctx-\u0026gt;dx), \u0026amp;ctx-\u0026gt;dx); break; ... case 15: bpf_probe_read_kernel(regval, sizeof(ctx-\u0026gt;r15), \u0026amp;ctx-\u0026gt;r15); break; } return; }  轮询事件信息 # 接下来了解下用户态部分如何读取上面内核态部分记录下来的events信息，这个就很简单了，bpf提供了对应的函数来轮询ebpf maps中的events，读取到之后决定打印还是不打印就可以了。这个地方没有什么特别要注意的，感兴趣可以看下这部分代码。\nctx, stop := signal.NotifyContext(context.Background(), os.Interrupt) defer stop() // create eventmanager to poll events, prepare the callstack and print eventManager, err := eventmanager.New(uprobes, t.drilldown, t.elf, t.bpf.PollArg(ctx)) if err != nil { return } for event := range t.bpf.PollEvents(ctx) { if err = eventManager.Handle(event); err != nil { return } } return eventManager.PrintRemaining()  打印函数耗时 # 怎么将事件信息打印出来，同一个函数可能在多个goroutine中调用，我们记录goroutine上的函数调用、退出时，是每个goroutine（goid唯一标识）单独有一个events stack，需要一个合适的时机将goroutine上的完整events stack打印出来。\n当轮询到新事件时，要么是函数调用的进入事件，要么是函数调用的退出事件：\n 如果是函数进入事件，无需特殊处理； 如果是函数退出事件，就需要判断下，当前goroutine跟踪到的所有函数级联调用，这个event的到来是不是表示topmost的函数调用已经执行结束了？如果是，那就可以考虑将当前goid对应的events全部打印出来，并清空events stack等着后续收集、打印。  for event := range t.bpf.PollEvents(ctx) { if err = eventManager.Handle(event); err != nil { return } }  // Handle handles the event func (m *EventManager) Handle(event bpf.GoftraceEvent) (err error) { m.Add(event) log.Debugf(\u0026quot;added event: %+v\u0026quot;, event) // CloseStack判断当前event是否是topmost函数调用的返回事件 if m.CloseStack(event) { // 打印整个调用栈信息，这个就是根据event中记录的信息，打印源码层面的函数名、文件位置、时间戳、耗时信息 if err = m.PrintStack(event.Goid); err != nil { return err } m.ClearStack(event) } return } // PrintStack print the callstack of a traced function func (m *EventManager) PrintStack(goid uint64) (err error) { ... for _, event := range m.goEvents[goid] { syms, offset, err := m.elf.ResolveAddress(event.Ip) switch event.Location { case 0: // entpoint startTimeStack = append(startTimeStack, event.TimeNs) callChain, err := m.SprintCallChain(event) ... if filename, line, err := m.elf.LineInfoForPc(event.CallerIp); err == nil { lineInfo = fmt.Sprintf(\u0026quot;%s:%d\u0026quot;, filename, line) } fmt.Printf(\u0026quot;%s %s %s %s(%s) { %s %s\\n\u0026quot;, color.YellowString(t), placeholder, indent, color.RedString(event.uprobe.Funcname), color.MagentaString(event.argString), color.GreenString(callChain), color.CyanString(lineInfo)) case 1: // retpoint ... if filename, line, err := m.elf.LineInfoForPc(event.Ip); err == nil { lineInfo = fmt.Sprintf(\u0026quot;%s:%d\u0026quot;, filename, line) } elapsed := event.TimeNs - startTimeStack[len(startTimeStack)-1] ... } } return }  更好地下钻分析 # 简单实现 # 比如main.main-\u0026gt;main.add-\u0026gt;main.add1，uprobes指定了main.main, main.add, main.add1，假设此时主协程执行main.main-\u0026gt;main.add-\u0026gt;main.add1，但是另一个协程执行main.add1，这种情况下如果要实现只输出main.main-\u0026gt;main.add-\u0026gt;main.add1的路径，而忽略掉只执行main.add1的路径，该怎么做呢？\n其实可以在打印过程中做文章，如果上面的条件也成立（topmost函数执行结束了），只要额外再判断当前events stack的栈底元素是不是--drilldown funcname指定的函数就可以了，是的话就打印。\n一点展望 # 如果要实现源码层面的更好的下钻分析，离不开对源代码的理解，可行的方案是，借助go build中写入二进制程序中的版本控制信息，去拉取对应的源代码，然后进一步通过AST分析去分析出有哪些函数调用，然后让用户去勾选，勾选上的自动完成对其uprobe的注册、attach，这样就能实现更好地下钻分析。\n后续有时间时，将继续在这方面做一点尝试。\n"}),a.add({id:33,href:"/tags/clang/",title:"clang",description:"",content:""}),a.add({id:34,href:"/blog/2023-11-22-ebpf%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/",title:"eBPF开发环境搭建",description:"eBPF开发环境，如果你是一个eBPF方面的新手的话，一定碰到过各种各样奇怪的环境设置问题。本文总结下开发过程中遇到的一些问题，仅供大家参考。",content:"问题背景 # 如果读者朋友使用的是Linux机器，而且系统是Ubuntu这些社区比较活跃的发行版，那么你遇到问题的时候，一般可以比较快地解决，或者很少遇到这种被他人反复才坑已经修复的问题。所以本篇文章并不一定适合你，不过看看也说不定有其他方面收获。\n我使用的开发环境如下：\n 处理器：i9 13900K (x86_64) 操作系统：Windows 11 WSL版本：v2 Linux发行版：RedHat 8.5 Linux内核版本：5.15.90.1-microsoft-standard-WSL2+  2023年9月份已经在阅读lizrice的learning-ebpf一书了，并且自己还跑了下书中的用例，并对测试时遇到的环境设置问题进行了解决，但是隔了一段时间，因为执行了 yum update吧，clang、llvm、kernel-headers、bcc相关包，它们之间的依赖没有明显问题，但是整合到一起编译构建、运行ebpf程序的时候，开始报错。\n于是2023.11.21日这天花费了大量时间来重新解决eBPF的开发环境设置问题，先记录下，供大家以及自己日后参考。\n环境设置 # 内核配置 # 1、git clone https://github.com/kernel-newbies/WSL2-Linux-Kernel\n2、cd WSL2-Linux-Kernel \u0026amp;\u0026amp; git checkout linux-msft-wsl-5.15.90.1\n​ 选择版本5.15.90.1，与lizrice/learning-ebpf中推荐版本5.15.x.y尽可能对齐\n3、执行 make config 配置编译构建选项\n​ 直接使用这里的.config ，这个已经是配置好了必要的ebpf选项的配置了\n4、执行 make -j8 进行内核构建，内核输出到了vmlinuz文件\n5、执行 sudo make headers_install 进行内核头文件安装\n工具链配置 # 1、sudo yum install clang clang-devel llvm llvm-devel\n​ 注意llvm不同版本兼容性有些问题，可能在低版本上编译ok升级后反而失败了，\n​ 我就是遇到的这样的坑，原本bcc 0.26可以在llvm 16上编过，升级到llvm 17失败\n2、不使用yum源中的bcc 0.25.0，有bug未修复，直接从源码安装\n​ git clone https://github.com/iovisor/bcc iovisor_bcc\n​ cd iovisor_bcc \u0026amp;\u0026amp; mkdir build \u0026amp;\u0026amp; cd build\n​ cmake -DENABLE_LLVM_SHARED=1 ../\n​ 有可能会遇到一些不严重的warning或者提示，最好都解决下：\n​ sudo yum install zip xz-devel libffi-devel libdebuginfod-client-devel \u0026hellip;\n​ 继续执行编译构建：\n​ sudo make install -j8\n​ 此时python包、二进制工具、man手册都已经安装好了，可以在install_manifest\u0026hellip;..txt文件中看详情。\n3、也可以继续安装bpftool以及libbpf，这些都可以从源码安装：\n​ cd iovisor_bcc/libbpf-tools/bpftool/src \u0026amp;\u0026amp; sudo make install\n​ cd iovisor_bcc/libbpf-tools/bpftool/libbpf \u0026amp;\u0026amp; sudo make install\nbpf程序跑侧 # 1、cd lizrice/learning-ebpf/chapter2\n2、sudo ./hello.py\n​ sudo ./hello-tail.py\n用chapter 2的demo跑侧下，没有问题，继续把其他几个chapter的跑侧下。\n本文小结 # 本文总结了下Windows WSL + eBPF程序开发过程中的快速环境设置，这么操作下来可以规避大多数棘手的问题。不妨收藏一下作为eBPF环境设置的checklist，遇到问题就从头来一遍 :)\n"}),a.add({id:35,href:"/tags/kernel/",title:"kernel",description:"",content:""}),a.add({id:36,href:"/tags/llvm/",title:"llvm",description:"",content:""}),a.add({id:37,href:"/tags/wsl/",title:"wsl",description:"",content:""}),a.add({id:38,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A66/",title:"Linux任务调度(6): CFS不是银弹",description:"本文介绍下Linux调度器的演进过程，对其中有代表性的调度器实现进行分析总结。作为任务调度器系列文集中的一篇，本文介绍一个CFS调度器的挑战者BFS，Brain Fucker Scheduler。",content:"演进过程 # 首先，再次回顾下下Linux进程调度器的一个发展历史：\n v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n))  前一篇文章中我们介绍了完全公平调度器CFS（Completely Fair Scheduler)，我们介绍了它的核心思想，并结合我们之前的几个顾虑给出了在CFS调度器下如何来解决顾虑的问题。CFS自从诞生以来，一直是Linux内核的默认调度器实现。它也先后经历了多次演进，如前文提到的对sched_entity的抽象改进以实现对组调度（group scheduling)的支持。看上去CFS已经是非常好的调度器实现了，事实上CFS也不是银弹。\n没有银弹 # 尽管Torvalds、Ingo等人坚持希望在内核中维护一个通用的调度器实现，来支撑不同的场景。这个理想很丰满，但是从实践上来看，确实在某些领域CFS的表现仍然并不是很令人满意。\n比如在个人桌面场景下，也不需要NUMA、也不要求在4096个处理器上具有良好扩展性，有没有比CFS更合适的调度器实现方案呢？那么在移动设备中呢？在其他更广泛的应用场景下呢？我们真的需要一个以一当十的CFS scheduler吗？还是需要一个个更适应各自领域的专用的scheduler？\nBFS调度器 # 2009年，Con Kolivas 又带着他的新版本调度器实现方案BFS回归了内核开发社区，BFS是Brain Fucker Scheduler的简称，挑衅意味浓厚，这与其主张的希望为Linux kernel在不同场景下允许提供多样化的scheduler方案相关，而Torvalds、Ingo等人主张用一个通用的scheduler统领各种场景。\n有些开发者进行了测试，在桌面场景下，BFS比CFS的效果好很多，但是因为理念的问题，BFS当时也被认为不会被合入内核，但是确实引发了广泛的关于scheduler的讨论。如今已经是2023年，Linux kernel仍然是采用CFS作为调度器，内核主线代码并没有BFS的身影。\n关于BFS scheduler的设计，您可以通过阅读这篇文章来了解：BFS cpu scheduler v0.304 stable release。\nBFS设计实现的内容，感兴趣的读者可以自行搜索，本文就不展开了。这里只是想跟大家强调，调度场景的多样性，以及内核大佬们对于CFS的不满以及孜孜不倦的探索。\nCon Kolivas的方向是对的，内核应该有这种机制来支持用户选择对应的调度器实现以适应不同场景。\n在论文BFS vs. CFS - scheduler comparison的摘要部分，作者也清晰表达了这种看法：\n Our results indicate that scheduler performance varies dramatically according to hardware and workload, and as a result we strongly encourage Linux distributions to take an increased level of responsibility for selecting appropriate default schedulers that best suit the intended usage of the system.\n 尽管BFS不支持NUMA场景，不支持需要扩展到4096个处理器的场景，但是不妨碍它可以在桌面、终端中表现更过CFS。没有银弹这种思想，已经基本被大家所接受了，合理质疑是应该保持的。我也很乐于见到更适用的调度器能带来更好的桌面交互体验。\nbpf扩展 (sched_ext) # 还是相同的原因，CFS并不是银弹，在某些场景下还是希望能够亲自干预调度器的行为。2021年社区有篇文章讨论了如何使用bpf扩展来控制调度器的调度行为，Controlling the CPU scheduler with BPF。\n有意思的是，之前Linus Torvalds和Ingo都坚持想通过一个大一统的调度器来解决所有问题，而CK反复建议、提供相应的调度器实现来建议朝这个可扩展的方向走，但是始终没有达成共识。而sched_ext这种可扩展的思路最后却被合入了内核主线。\n我们不要阴谋论，从技术的层面来考虑的话，可能通过bpf扩展的方式确实是一种更合适的实现方式吧，至少对Linux维护者而言。bpf-based sched_ext，它提供了可扩展的方式，同时也没有增加额外的维护多个不同调度器实现的负担，至少bpf扩展的方式完全将“谁来维护扩展出来的多个版本的调度器”这个负担撇的一干二净了。可以肯定的是，Con Kolivas的这个想法是正确的，他与内核维护人员关系紧张，但是我更愿意相信不同的技术方案不同维护人员的看法不同，Torvalds、Ingo有他们自己的坚持。\n本文小结 # 本文简单介绍了BFS调度器以及bpf-based调度器扩展sched_ext，前者是对CFS大一统的策略的一种挑衅，后者则最终成为了CFS调度能力的bpf扩展，能够让我们在运行时干预调度器的行为。从中我们可以感受到的是，不同调度场景的多样性，以及对特定场景优化的调度器的诉求。我们将再接下来合适的时候进一步介绍sched_ext这个调度器扩展的细节，再介绍它之前，我们可能需要先介绍下bpf子系统，大家才方便理解它。OK，本文到此结束，欢迎关注我并点赞转发！\n参考文献 #  BFS cpu scheduler v0.304 stable release BFS vs. CFS - scheduler comparison Controlling the CPU scheduler with BPF sched_ext: a BPF-extensible scheduler class BPF Opens Door to Linux Extensible Scheduling (Maybe with Rust!) Sched Ext: The pluggable Linux Scheduler Linux Torvalds Merging Extensible Scheduler \u0026lsquo;sched_ext\u0026rsquo; in Linux 6.11  "}),a.add({id:39,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A65/",title:"Linux任务调度(5): CFS调度器",description:"本文介绍下Linux调度器的演进过程，对其中有代表性的调度器实现进行分析总结。作为任务调度器系列文集中的一篇，本文重点介绍v2.6.23开始引入的CFS调度器，CFS调度器后续也进行了一系列的优化，包括支持组调度等，目前Linux内核已经来到了v6.0.0+，调度器实现依然是CFS。这个完全公平调度器是如何保证公平的呢？本文将一探究竟。",content:"演进过程 # 首先，再次回顾下下Linux进程调度器的一个发展历史：\n v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n))  前一篇文章中我们介绍了v0.01版本中的调度器实现，复杂度为O(n)，在v0.01内核实现中写死了最多可调度的任务数量，只能算作是一个toy！随着从v0.01~v2.4.x版本中的优化，能调度的任务数量也上来了，但是复杂度还是O(n)。O(1)调度器对其进行了优化，但是其启发式算法来识别、奖惩交互性的逻辑难以建模、理解、维护、优化。RSDL调度器相比O(1)调度器有了很大的改进，但是Con Kolivas和Torvalds、Ingo等人有不同看法，最终迟迟未能合入内核主线。最后，在此前探索优化基础上，CFS诞生了并成为了运行至今的调度器解决方案。\n问题背景 # 对Linux调度器做过点了解的话，应该都听说过“完全公平调度器”这个术语吧。完全公平调度器(Complete Fair Scheduler, 简称CFS)。CFS从v2.6.23到现在v6.0.0+久经沙场考验，它一定是有些过人之处，才能在多用户多任务、服务器、桌面、虚拟机、容器化乃至云原生领域都表现还不错。\n业务在项目部署上的实践，让我产生了对Linux scheduler设计实现的一些思考。事情是这样的，项目是采用的微服务架构，但是在初期项目部署时节约成本、减少机器管理、服务部署的复杂度，项目采用了1台机器混部多个微服务的形式。这就不得不思考，如果其中一个服务进程占用CPU过多的话，对其他进程会不会造成影响。肯定会，但是如何隔离这种影响。\n混部的坑 # 对于采用了k8s容器化部署的项目而言，一般就不会遇到这样的困扰，因为容器运行时已经做了比较好的资源隔离，包括CPU、内存等等，混部的话就有一定的挑战，尤其是像go这种支持协程、本身也是多线程而且支持GC的程序。\n go本身就是多线程程序，用来支持多处理器多核上的goroutine调度执行，支持GC，轮询网络IO事件、轮询定时器事件等； go本身支持协程，协程的调度、最终执行依赖于多线程，尽管可以限制GOMAXPROCS（P的数量，限制同时运行的M数量）； go支持GC，但是对于程序上限没有硬限制（有别于Java等），只有软限制，内存占用居高不下容易导致OOM； 其他；  内存分配控制 # 对于go程序混部，有一定的挑战，综合投入产出比，可以考虑根据服务的重要程度、吞吐量、响应时间等要求给与不同的设置。以内存为例，混部服务GOMEMLIMIT上限尽量不要高于总可用内存的70%，留一点buffer给系统服务、个别服务超额分配的情况。Go GC中的MarkAssit机制实际上会要求申请分配内存的goroutine在GC期间参与一定的扫描，既加速了垃圾的扫描进度，也延缓了内存的分配速度，通过这种手段来保持堆大小尽可能维持着平衡。如果打开了GOMEMLIMIT，请求负载超过预期时会导致堆内存占用超过软限制时，并且无法通过GC降到GOMEMLIMIT以下。此时会导致Go GC的death spirals，CPU会消耗在GC上高达50%，严重影响进程的处理性能。而且，如果多个进程都遇到类似问题，内存占用会超过预设的70%，有OOM的风险。\n这是对内存进行的控制，那么对CPU呢？实际上在对请求负载、内存消耗、物理资源不具备充足的掌控的时候，不建议大范围混部Go服务，因为上述影响可能会导致影响面扩大。\nCPU分配控制 # 对于计算密集型任务，如果涉及到混部，为了分配CPU资源可能会考虑通过taskset进行绑核，实际上对于IO密集型任务也未尝不可，但是收益有多少呢？作者此前曾经在压测中做过这方面的一点尝试，将不同服务绑定在不同核上，这是我的一个单机用于压测的探索，实际真正线上服务，这种方案不一定真的可取。资源分配要取决于真实的负载情况才合理，不能简单的cpu 1,2,3,4给服务1，cpu 5,6给服务2，cpu 7给3，cpu 8给4这样。这样的粒度太糙了，而且预期的资源配给可能跟真实的负载相差很多。\n与其瞎琢磨，瞎测试，不如多了解下CFS调度器让内核自己来解决。CFS调度器其实可以比较好地解决这个问题，不同服务可能创建了不同数量的线程、协程来应对匹配的请求负载，CFS调度器尽可能保证每个线程调度的公平（CFS调度的目标实际上是更抽象的sched_entity，这里用“线程”先简化问题范畴），从而让服务获得应该和负载匹配的cpu执行时间。\n调度实现顾虑 # 看似通过上述设置，即使是混部，也可以工作的很好，嗯，但是我还是有顾虑。俗话说“无规矩不成方圆”，如果大家都守规矩、不犯错，可能也没写这篇文章的必要了。或者说，写这篇文章主要是想探讨下，研发规范、平台能力如何避免让这些不守规矩、爱犯错的人犯错。《波斯王子》里老国王对儿子说，“一个伟大的人，不仅自己要尽量不犯错，也要阻止他人犯错”。\nCFS调度器设计实现上能否彻底解决我的顾虑呢？\n1、如果机器混部有不同用户1、用户2的服务，用户1的进程数（线程数）特别多，如果不加控制手段，用户1会挤占用户2的资源；\n2、如果用户1混部了多个服务1、2、3，如果服务3实现有问题，创建了大量线程，服务3会挤占服务1、2的资源；\n3、还有种情况，每个服务可能对应着一个进程组，如果某个服务创建大量进程、线程，从而挤占了其他服务的资源怎么办；\n其实这些问题，都属于调度器层面对于“公平性”的考虑范畴，只是它们有不同的层次：线程级别，用户级别，组级别。\nCFS调度器随着第一个patch以及后续的很多次优化，可以解决上述不同层级的“公平性”问题，这就是“组调度(CFS group scheduling)”，我们在后面介绍。\nCFS调度器 # 在学习RSDL调度器中我们也了解了它是如何保证和体现调度的公平性的，那么CFS调度器又是如何做的呢？一起来看下。\n公平性建模 # 抽象vruntime # 在我看来，抛开道德、协作争议等问题不谈，我认为CFS调度器比Con Kolivas提出的RSDL调度器对公平性的建模上更胜一筹，因为它非常容易理解、容易实现，能够比较简单地论证这个算法能否比较好的工作。\nCFS调度器，提出了vruntime（虚拟运行时间）的概念，CFS调度器的宗旨就是力图维持所有进程的vruntime都尽可能相同，通过这种方式来尽可能保证每个被调度实体都执行了相同的虚拟运行时间。\n之所以强调是虚拟运行时间，而非是实际执行时间，是因为“公平性”还必须体现出优先级的概念，即简单说：\n虚拟运行时间 = 实际执行时间 / 优先级对应的权重  优先级高的权重也大，优先级低的权重小。实际执行时间相同的两个不同优先级进程p1、p2，其中优先级低的虚拟运行时间偏大，优先级高的虚拟运行时间偏小。虚拟运行时间越小的，会被优先调度，也就意味着高优先级的进程会获得更多调度机会。\nvruntime的实际计算式为：\nvirtual runtime = (real runtime) * (NICE_0_LOAD) / (weight of the process)   其中virtual runtime指的就是vruntime; real runtime指的是cpu上的实际执行时间; NICE_0_LOAD表示nice==0时的默认权重（1024）; 而weight of the process指的是由进程的实际优先级从映射表映射而来的权重;  完整的映射表可以参考：\nconst int sched_prio_to_weight[40] = { /* -20 */ 88761, 71755, 56483, 46273, 36291, /* -15 */ 29154, 23254, 18705, 14949, 11916, /* -10 */ 9548, 7620, 6100, 4904, 3906, /* -5 */ 3121, 2501, 1991, 1586, 1277, /* 0 */ 1024, 820, 655, 526, 423, /* 5 */ 335, 272, 215, 172, 137, /* 10 */ 110, 87, 70, 56, 45, /* 15 */ 36, 29, 23, 18, 15, };  这样的话，可以直观感受到：\n 如果一个进程优先级为默认值（nice==0），那么其权重为1024，那么其virtual runtime 完全等于其 real runtime； 如果一个进程优先级越高，意味着其权重大，执行相同的real runtime，其对应的vruntime偏小，此后仍然更容易被调度； 如果一个进程优先级越低，意味着权重越小，执行相同的real runtime，其对应的vruntime偏大，此后会被冷落优先调度其他vruntime更小的实体；  CFS对公平性的建模，是非常容易理解的，而且实现上也更简单、易论证检查器有效性。\n抽象sched_entity # 另外，如果要对不同用户先进行公平调度，然后再对用户下的任务进行公平调度；如果要对不同的任务组先进行公平调度，再对组内的任务进行公平调度；再或者说不同的会话先进行公平调度，再对会话内启动的进程进行公平调度呢……如何建模并解决这种场景。\nCFS将以往调度的对象从具体的一个线程（thread或者lwp），抽象为了一个任务调度实体sched_entity，你可以用它来实现上述提出的几个刁钻的场景，在不同用户之间实现公平，在不同任务组之间实现公平，在不同会话之间实现公平。\n而它也可以建模多层级结构下的调度的公平性，如 不同用户-\u0026gt;不同会话-\u0026gt;不同任务组-\u0026gt;不同线程的各级调度均保证公平。实际上在Linux 2.6.24还是Linux 2.6.30的CFS补丁中确实有一个选项，CONFIG_FAIR_USER_SCHED=y，编译构建时设置为打开，那么CFS调度器会自动在不同用户层级下进行公平调度。但是后续又移除了这个编译选项，感兴趣的可以继续看下这两篇内容：\n [Patch] sched: CONFIG_FAIR_USER_SCHED: auto adjust users weights CONFIG_FAIR_USER_SCHED oficial replacement  实际上有了sched_entity这层抽象设计，赋予了CFS调度器组调度的能力，组调度也可以实现上述所有提及的场景，实现多层级的调度时的公平性。比如让系统管理员为不同用户设置不同的组调度，然后将用户创建的进程全部放到这个组中，多个用户对应的组各自的cpu.shares相同，这样就可以实现多用户之间调度的公平性，疯狂创建进程、线程的用户并不会获得更多的cpu执行时间。\n ps：一个有趣的功能，Linux内核提供了autogroup的特性，新session创建时会自动创建一个task group并将session中创建的任务放到这个相同的task group用于cfs公平调度。\n 阻塞唤醒后抢占 # 阻塞后唤醒后，查看是否要调度另一个任务，此时会将当前进程的vruntime设置为：\nvruntime = max(p.old_vruntime, global.min_vruntime-sched_latency)  如果阻塞比较久的话, global.min_vruntime表示当前正在被调度的进程的vruntime，sched_latency是个时间常量，这样的话min_vruntime-sched_latency至少比当前应该正在执行的那个进程的vruntime要小，就会导致那个进程被当前恢复的进程抢占（preempted），从IO中恢复的进程会被奖励，和MLFQ类似的思路，让阻塞的任务赶紧恢复执行。\n被更高优进程抢占 # cfs调度器中没有固定大小的timeslice时间片的概念了，一个任务执行到什么时候会发生切换，完全依赖于是否仍旧被判定为“最不公平”，只要不是了，scheduler工作的时候就会切换其他进程执行。\n但是要注意控制vruntime变化的粒度，以避免频繁发生任务切换导致不必要的开销。\n设计实现 # 这里有几篇文章介绍了CFS调度器的源码层面的分析，包括运行队列的核心数据结构、CFS相关的核心字段，以及vruntime的计算更新逻辑，以及新创建1个进程时或者调度其他进程时CFS是如何选择并更新vruntime的。\n Grade: good Implementation of the Linux kernel CFS scheduler Grade: excellent, Linux CFS and task group  类似O(1)那样，每个cpu维护独立的数据结构（rbtree），避免锁竞争，也存在需要负载均衡的问题。\n ps: 关于CFS调度器下线程切换频率、负载均衡的一点其他思考，详见 任务调度(7)\n 伴随着CFS的patch，也一并提交了一个可插拔的模块化调度器实现，可以插入自定义的调度器实现，这个之前是Con Kolivas一直给Torvalds和Ingo等人建议的，但是他俩更倾向于使用一个默认的支持通用场景的内核，但是实际情况是没有银弹，没有一个调度器能够胜任各种设备类型、应用场景。这也是为什么CFS看似稳定以后，仍然有些人在桌面环境下表达了对Linux调度交互性的不满，Con Kolivas更是在2009年左右又提出了新的调度器算法Brain Fucker Scheduler。\nOK，我们不牵扯太多设计实现的细节了，上面两篇文章由浅入深，写的很好，我实在没必要再重新总结一遍，OK，我们来测试下如何使用CFS来做些控制。\n在执行下面的测试之前，我们还需要了解下如何组调度扩展如何使用：\n group scheduling extension enable group scheduling by cpu.shares  其实cgroups下面的一些配置项，恰恰是CFS调度器工作时可以读取的一些参数，比如bandwidth、latency、shares等。这里我们简单总结下吧，读者可以按需去加深了解下。\n 2.2.1 核心概念 - 调度实体\n2.2.2 核心概念 - 调度类\n 看完这些后，会发现cpu.shares, cpu.fair_period_us, cpu.fair_quota_us都是cfs调度器的一些参数，用来控制：\n  cpu.fair_period_us，cfs不需要为进程指定时间片，完全依赖虚拟时间vruntime来保证公平性，除了公平调度，cfs还需要保证每隔一段时间至少执行任务一次，这就是调度周期。有个概念，调度延迟，指同一个schedentity前后两次调度的时间间隔。调度周期就是要保证这个schedentity的调度延迟小于调度周期，简言之就是调度周期内至少要执行一次。see: https://s3.shizhz.me/linux-sched/cfs-sched/logic-period\n  cpu.fair_quota_us，cfs调度器需要能限制任务在一个调度周期内的执行时间，这个值可以不限制，但是最大就是上面fair_period_us的值，这个很好理解。\\\nsee: https://s3.shizhz.me/linux-sched/cfs-sched/bandwidth,\nsee: https://s3.shizhz.me/linux-sched/cfs-sched/bandwidth-time\n  cpu.shares，控制的是不同控制组的调度权重，如果cpu.shares=1024, 下面有10个进程，那么就是102410=10240,其他调度组也是这么计算，如果其他调度组也是1024，但是是5个进程，那么就是10245=10240/2，意味着前一个调度组将获得两倍于后者的执行时间。see: https://s3.shizhz.me/linux-sched/cfs-sched/group-weight\n  cfs组调度其实是控制组cgroups对cpu资源进行控制的基石，它们都依赖sched_entity，最开始调度器针对的对象是task_struct，后面为了更好的对公平性（多个用户之间，多个任务组之间）进行建模，就抽象出了sched_entity，它非常灵活了，cgroups /sys/fs/cgroup/cpu只不过是在这个的基础上构建来的更便利的一个可以提供给用户进行操作的接口。sched_entity代指的是用户（用户组其实任务组的一个特例），也可以是自定义的一组进程（比如我还把同一个进程的线程编为一组），也可以是单个进程。\nCFS的测试 # 测试1：单线程程序，测试cgroups cpu.shares影响调度 # 首先要构造一个测试场景：有不少的的进程需要调度，调度器切换时会发现存在待调度的多个进程在竞争，所以调度器就要需要做选择来执行。\n测试机是1 cpu 8 cores，测试过程如下：\n  起1个是单线程的c程序，for循环打印\n  起1个是多线程的go程序，for起多个goroutine，每个goroutine循环打印\n  nohup启动c程序2次、nohup启动go程序8次，\n这样，至少启动了2+8个线程，超过机器cpu cores，这样可以断定进程调度的时候有调度竞争，这样cpu.shares的作用才能体现出来嘛\n  然后/sys/fs/cgroup/cpu下创建两个taskgroup\n god1，god1/tasks中放入其中1个c程序的pid，然后cpu.shares中从默认值1024设为1 god2，god2/tasks中放入另一个c程序的pid，然后cpu.shares中从默认值1024设为10240 atop观察进程执行时间……虽然不满足1:10240的倍数关系，但是可以明显看到影响到了对这两个c程序的调度，cpu.shares=1的组的c程序，片上执行时间明显少很多（ps：至于为何不满足1:10240关系，这涉及到cpu.shares对cfs调度的影响了，先放放）。    测试2：多线程程序，测试cgroups cpu.shares影响调度 # 对于go这个多线程程序而言呢，我只将进程pid加入到tasks里面可以吗？比如创建cgroup perf3，然后将下面的cpu.shares设为1，然后将父进程pid放进去，发现并不会影响整个进程的片上执行时间，或者说影响很小。\n其实这里的tasks中的id都是进程id，而线程也是进程（lwp），你得把所有线程的id都加进去才可以。当全部加进去之后，效果就出来了。\n这里的测试只是将某个go进程下的线程的调度机会调低了，比如我可以这样调进程A的，然后也可以这样调进程B的，这样来实现A、B进程整体调度的相对公平。\nps：A创建1000个线程，B创建10个线程，要实现A、B的公平，可以这样做：A创建控制组gp-a, 然后将cpu.shares设置为1024/1000，B创建控制组gp-b，将cpu.shares设置为1024/10，这样可以实现A、B调度的整体公平……到这里还是猜测，可以继续测试下。\n测试3：继续测试 # 写一个多线程c程序：\n 起8个线程、加主线程9个，循环打印……控制组cpu.shares=50，线程全加入控制组 起4个线程、加主线程5个，循环打印……控制组cpu.shares=500，线程全加入控制组  这样的情况下两个进程整体调度的片上时间能持平。\n但是测试下来发现，根据“cpu.shares=1024/线程数”，这种方式是不科学的，算出来的值不能让进程A、B实现片上时间持平……可能还没抓到问题的核心？\n继续看下cpu.cfs_quota_us，至少效果上是我要找的东西，这个配额相当于一个上限，可以直接实现我们的目标。能够轻松实现A、B两个线程数不同的进程在整体调度上片上执行时间达到一个持平的状态，实现对进程调度公平性的探索。\nps：但是我只是想让A、B进程持平，却不想给它们加什么配额上限，这样会让cpu无法跑满，有点浪费……似乎我需要的是一个类似控制组之间的权重的东西？\n能相对公平，同时又能充分利用cpu空闲资源来调度，只是说要尽量公平调度A、B进程。\n等等，是我忽略了配置项的实际意义：\n cpu.cfs_period_us，单位微秒，表示多久为当前调度组更新可用执行时间 cpu.cfs_quota_us，单位微秒，表示一个period内该调度组下的任务最多执行多久 cpu.shares，表示当前调度组与其他调度组相比，他们之间调度的一个权重  那么我们可以直接不修改cpu.shares，A、B两个调度组cg-a cg-b的cpu.shares都是1024，意味着他们都有相同概率被调度到，但是它们下面的诸多线程，可以通过cpu.cfs_period_us、cpu.cfs_quota_us来控制，只要这3个值相同，表示他们被调度的概率相同、定期申请cpu资源的周期相同、周期内可以消耗的上限也相同，假设他们确实有干活的线程……那么A、B进程整体调度执行的时间就是持平的了！而且cpu资源也能得到充分利用，完美！\n通过调节这里的cpu.cfs_quota_us/cpu.cfs_period_us可以精确控制进程实际执行时间占比。\n ps：现在设置了上面两个配置项后，cpu.shares就没啥效果了，调大调低都没作用。\n 如果按上面提示，取消quota设置，只设置cpu.shares，如果启动mt_thread 2个实例，分别设置他们的shares，确实他们cpu执行片上时间的比例基本和cpu.shares的比例近似，只能说这个比例差不多，但不是相等，还是有点差值的。\n ps: 使用cgroup v2的cpu.weight可以做到吗？\nsee：如何在wsl2中启用cgroup v2？How to enable cgroup v2 in WSL2?\ncgroup v2中提供了权重，难道能帮助我更轻松的实现这个目标吗？\n 本文小结 # 本文首先介绍了作者在业务实践中遇到的一点问题，进而引出了对Linux调度机制公平性的思考，然后介绍了CFS调度器的对公平性的建模，我们介绍了vruntime（虚拟运行时间）的由来以及计算更新方式，也介绍了group scheduling（组调度）对于用户、任务组的公平性的支持。也介绍了cgroups如何提供了一个用户友好的接口来方便地发挥组调度的能力（而且支持多层级），意味着你可以轻松实现“用户-\u0026gt;会话-\u0026gt;任务组-\u0026gt;任务”多层级的公平性调度支持。\n最后回到作者最初心头萦绕的那些问题，我们写了一些测试程序、跑了一些测试来验证CFS调度器中cpu.shares、cpu.cfs_period_us、cpu.cfs_quota_us对调度的一些影响和作用，我们也测试并得出了一些有价值的结论，比如：\n 多线程程序A、B，它们线程数不同，我们该如何保证A、B进程层面的调度公平性，而不是默认的线程层面的调度公平性。 以及如何保证用户层面的调度公平。   其实这篇论文，也是想探讨我提出的这些问题， https://www.cs.mtsu.edu/~waderholdt/6450/papers/cfs.pdf，…. In the 17th revision of CFS, the scheduler includes scheduling entities (group, container, tasks, users, etc) patch [5], which are used to implement group-fair and user-fair scheduling……论文作者提出的是，process fair scheduler而非linux cfs默认的thread fair scheduler。\n 其实解决user fairness、group fairness的问题呢？都是通过这个sched_entity来实现的，cfs只提供基础能力不限制如何对任务进行分组，你要分组的话随便你自己怎么组织（CFS早期实现确实有支持user fairness的编译选项，但后面又移除了）。\n写了这么多，读到这里的都是对细节很专注的人，也感谢大家的阅读分享。\n参考文献 #  cfs group scheduling linux核心概念\u0026quot;调度实体\u0026quot; linux核心概念\u0026quot;调度类\u0026quot; digging into linux scheduler brain fucker scheduler group scheduling extension  "}),a.add({id:40,href:"/tags/interactivity/",title:"interactivity",description:"",content:""}),a.add({id:41,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A63/",title:"Linux任务调度(3): O(1)调度器",description:"本文介绍下Linux O(1)调度器，O(1)调度器解决了过去的Linux v0.01版本调度器复杂度为O(n)的问题，也通过度量进程的交互性、静态优先级来确定动态优先级，从而进一步确定其时间片大小，通过这些来改善交互性。虽然它已经被CFS调度器代替，但是它的设计思想仍有值得我们借鉴学习的地方。考虑到调度器要解决的核心问题、对程序可交互性的量化、实现上的复杂度，O(1)调度器对初学者而言是很好的学习材料。",content:"演进过程 # 首先，再次回顾下下Linux进程调度器的一个发展历史：\n v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n))  前一篇文章中我们介绍了v0.01版本中的调度器实现，复杂度为O(n)，在v0.01内核实现中写死了最多可调度的任务数量，只能算作是一个toy！随着从v0.01~v2.4.x版本中的优化，能调度的任务数量也上来了，但是复杂度还是O(n)。\nO(1)调度器简介 # 为了解决此前调度器调度一个进程复杂度为O(n)的问题，O(1)调度器就这么来了。\nO(1)调度器，也被称为“常数时间调度器”，是为了解决Linux中早期调度算法的局限性而引入的。其目标是提高调度器的效率和可扩展性，特别是对于具有大量进程的系统。\n传统的调度算法，如轮转调度（roundrobin）或基于优先级的调度器，其时间复杂度随着进程数量的增加呈线性增长。这意味着随着进程数量的增加，调度开销也会增加，导致性能下降。\nO(1)调度器旨在提供常数时间的调度，无论进程数量如何。O(1)调度器显著减少了调度开销，并提高了整体系统性能。它成为Linux内核的默认调度器多年，直到后续版本中被完全公平调度器（CFS）取代。\n重点攻坚问题 # O(1)调度器并不只是解决从O(n)到O(1)这一个问题，它还涉及到其他一些很有价值和挑战的问题：\n 实现完全的O(1)调度：新调度器中的每个算法都能在常数时间内完成，无论运行的进程数量如何。 实现完美的SMP可扩展性：每个处理器都有自己的锁和独立的运行队列。 实现改进的SMP亲和性：尝试将任务分组到特定的CPU上，并继续在那里运行它们。只有在运行队列大小不平衡时才将任务从一个CPU迁移到另一个CPU。 提供良好的交互性能：即使在系统负载较大的情况下，系统也应立即响应并调度交互式任务。 提供公平性：任何进程都不应在合理的时间内被剥夺时间片。同样，任何进程都不应获得不公平的高时间片。 针对只有一个或两个可运行进程的常见情况进行优化，同时能够很好地适应具有多个处理器且每个处理器上有许多进程的情况。  The Big Picture # 下图简要展示了O(1)调度器的核心数据结构，以及调度一个任务执行时大致的工作过程。\n1）本质上O(1)调度器也是一个支持多优先级的多级反馈队列，结构组织上也是从高优先级到低优先级，每个优先级都有一个队列，其中保存该优先级的任务。2）调度时从高优先级到低优先级队列逐个检查，优先调度高优先级进程来执行，保证公平性。3）同时通过优先级确定其时间片，时间片执行完后就继续调度其他低优先级进程继续执行，避免饿死。4）不同进程的交互性不一样，调度器会给予不同的奖励和惩罚，表现就是动态优先级的差异，根据动态优先级计算出的时间片长短的差异。\n工作原理剖析 # 如何调度1个任务 # 1、O(1)调度器会为每个CPU创建一个运行队列（分active和expired）和单独的spinlock（尽量减少操作时锁竞争）。\n2、每个运行队列都会根据优先级组织成多级队列的形式，每个优先级从高到低都有对应的一个保存任务的queue，保存属于该优先级级别的进程。\n3、而进程启动时都有设置静态优先级（nice值），调度器将其放入对应优先级的队列中。在运行过程中调度器也会根据进程优先级、是否是交互程序、执行时间、睡眠时间等计算其动态优先级。调整优先级后将其放入对应优先级的任务队列中。\n4、当一个进程的状态发生变化时，如开始执行IO操作从Task_RUNNING变为TASK_UNINTERRUPTIBLE状态时，或者说它的优先级发生变化时，调度器会根据其优先级将其放入相应的运行队列中。\n5、调度器寻找下一个可执行的进程时，始终首先从高优先级队列开始检查是否有可运行的进程，从而体现公平性。为了高效地识别出可运行的最高优先级的可运行进程，O(1)调度器使用位图（bitmap）来跟踪每个优先级对应的任务队列的状态。位图 bitmap[priorityLevel]==true指示运行队列中某个特定优先级级别的任务列表中是否包含任何可运行的进程。这使得调度器能够快速识别出哪个高级别的队列中具有可运行的进程。\n ps：对位图进行查找从而找到对应的最高优先级的队列的这个操作，可以通过一些特殊的指令来加速，比如：x86 bsfl, PPC cntlzw，其他架构下也有对应的指令。\n 6、确定了最高优先级运行队列后，调度器选择该运行队列中的第一个进程，并安排其执行。每个队列都有一个指向第一个进程的队首指针，可以迅速确定可运行的第一个进程。被调度的进程，会从运行队列中移除，并且调度器更新位图以反映运行队列状态的变化。\n7、通过使用这种方法，O(1)调度器实现了常数时间的调度操作。无论系统中的进程或任务数量如何，找到最高优先级任务和调度任务的时间复杂度保持不变。这使得高效且可扩展的调度成为现实，使其适用于具有大量进程的系统。\n任务在队列中移动 # O(1)调度器使用的runqueue是个支持优先级的多级任务队列，本质上还是个多级反馈队列。意味着其优先级会被调整，任务会在多个队列中移来移去，这也是为了解决公平性、交互性方面的问题。\n1、如果一个进程P刚开始处于最高优先级队列中，它的时间片为T，如果P被调度了，其执行一段时间后，假设时钟中断来，调度器需要检查是否应该调度另一个进程时。\n 如果发现P仍然是当前最高优先级的进程，且其时间片没有用完，那么会继续执行P； 如果发现有更高优先级的进程等着被调度，且支持抢占的话，那么P可能会被抢占；  2、实际上P在执行的过程中，它的优先级是会被动态调整的，比如它做了些IO类的操作：\n 执行IO密集型操作，恢复后时间片T没耗光，内核会认为这是一个响应式任务，会奖励它，优先级会被调高； 执行IO密集型操作，恢复后时间片T耗光，会认为这不是一个响应式任务，会惩罚它，优先级被调低或者没变化； 执行CPU密集型操作，会认为这不是一个响应式任务，会惩罚它，优先级被调低或者没变化；  3、当其优先级调整后，它就会被移动到对应优先级的任务队列中，等待下一轮被调度。\n ps：时间片只有在运行时才会被计数、扣减，陷入IO等待的任务是不会被扣减时间片的。、\n为什么将IO完成后还剩余时间片的看做是响应式任务、而剩余时间片为0的就不是呢？执行完IO后，如果此时没有时间片了，因为IO时不消耗时间片，时间片用光只能说还需要更多的CPU时间做CPU密集型任务，所以这不是一个响应式任务。响应式任务的特点就是有明显的IO操作带来的延迟，但是一旦IO完成就能靠很少的CPU时间完成处理。\n 避免进程被饿死 # 当某个进程的时间片耗尽时，它会被从active移动到expire中。active、expire是数据结构完全相同的多级运行队列，见下面的prio_array，加入到新队列之前会重新设定它的优先级、时间片，但是expire中的不会参与调度。当active中没有可调度的进程时，就会将active、expire直接交换，这样又开始了下一轮的调度。\nstruct runqueue { spinlock_t lock; /* spin lock that protects this runqueue */ unsigned long nr_running; /* number of runnable tasks */ unsigned long nr_switches; /* context switch count */ unsigned long expired_timestamp; /* time of last array swap */ unsigned long nr_uninterruptible; /* uninterruptible tasks */ unsigned long long timestamp_last_tick; /* last scheduler tick */ struct task_struct *curr; /* currently running task */ struct task_struct *idle; /* this processor's idle task */ struct mm_struct *prev_mm; /* mm_struct of last ran task */ struct prio_array *active; /* active priority array */ struct prio_array *expired; /* the expired priority array */ struct prio_array arrays[2]; /* the actual priority arrays */ struct task_struct *migration_thread; /* migration thread */ struct list_head migration_queue; /* migration queue*/ atomic_t nr_iowait; /* number of tasks waiting on I/O */ }; struct prio_array { int nr_active; /* number of tasks in the queues */ unsigned long bitmap[BITMAP_SIZE]; /* priority bitmap */ struct list_head queue[MAX_PRIO]; /* priority queues */ };  这个办法也避免了高优先级进程把低优先级进程饿死的问题，因为高优先级进程不管其优先级多高，它们的时间片总会有用完的时刻，这个时刻一到，active中低优先级的进程就可以被调度了。而当active中没有可调度进程时，active、expire交换，又触发了下一轮全新的调度。\n ps：active、expire交换的实现方式，这样做和只维护一个active队列、等所有进程时间片为0时逐个重新计算优先级、时间片相比，效率更高。\n 负载均衡问题 # 每个CPU都有一个独立的运行队列，调度器会在合适的时候做些负载均衡的操作，以使得各个CPU的运行队列相对平衡。这里的迁移也是有要求的，会考虑CPU affinity、cache、任务优先级、任务状态等来决定应该迁移哪些进程。一般会先从最忙的一个CPU的runqueue中拿一部分到当前CPU的runqueue中，什么叫忙呢？1个CPU的runqueue如果比某个CPU runqueue的任务数量多25%+，就认为存在不平衡，需要迁移一部分任务到负载低的CPU上调度，但是迁移也要满足上面说的条件，不然收益不高。\n动、静优先级 # 前面提到为了改善交互性（interactivity），调度器会对交互式任务进行奖励，而对非交互式任务不进行奖励或者还要惩罚。先抛个问题，怎么识别一个任务是不是具有交互性的任务呢？\n让我们先区分下静态优先级和动态优先级：\n 进程有一个初始优先级，称为nice值，它就是静态优先级。这个值的范围是从-20到+19，默认值为零。+19是最低优先级，-20是最高优先级。这个值存储在进程的task_struct的 static_prio成员中，这个变量被称为静态优先级。 调度器则根据存储在 prio中的动态优先级来做出决策。动态优先级是根据“静态优先级”和“任务的交互性”计算得出的。  度量任务交互性 # 这个“交互性”的度量是一个很关键的步骤，那么怎么度量呢？能准确反映一个任务是I/O密集型还是计算密集型，一个指示性的指标就是任务的睡眠时间：\n  如果一个任务大部分时间都在睡眠，那么它是I/O密集型的。\n  如果一个任务在可运行状态的时间比睡眠时间更长，那么它肯定不是交互式的。\n ps: 这一点可以推广到极端情况：几乎所有时间都在睡眠的任务完全是I/O密集型的，而几乎所有时间都在可运行状态的任务完全是计算密集型的。\n   Linux O(1)调度器会持续跟踪进程在睡眠状态和可运行状态下的时间消耗，这个值记录在task_struct的sleep_avg成员中。进而根据task_struct中存储的sleep_avg值来计算进程的交互性。\n 当一个进程从睡眠状态唤醒时，sleep_avg值会增加； 而进程在可运行、运行状态下，每次定时器滴答时，sleep_avg值会减少。  所以这个度量指标既考虑了进程的睡眠时间，也考虑了进程的执行时间，它的最终值偏大则说明具有交互性，反之则不具有交互性。较高的sleep_avg值表示进程更多时间处于睡眠状态，表明它更可能是I/O密集型和交互式的。相反，较低的sleep_avg值表示进程更多时间处于可运行状态，表明它更可能是计算密集型和不太交互式的。\n计算动态优先级 # effective_prio()函数根据sleep_avg值在-5到+5之间进行加减操作，计算出动态优先级。\neffective_prio()，该方法从任务的nice值开始，根据任务的交互性计算出一个范围在-5到+5之间的奖励或惩罚。例如，一个非常交互式的任务，其nice值为10，可以具有动态优先级为5。相反，一个稍微占用处理器的任务，其nice值为10，可以具有动态优先级为12。在某种理论上的I/O与处理器使用的平衡点上，只有稍微交互的任务不会获得奖励或惩罚，它们的动态优先级等于它们的nice值。\n通过这种方式，根据sleep_avg值调整动态优先级，调度器可以给予交互式任务更高的优先级和更长的时间片，使其更具响应性。这种方法有助于平衡I/O密集型和处理器密集型任务的调度，确保系统的公平性和响应性。\n ps：see https://web.cse.ohio-state.edu/~champion.17/2431/04-SchedulingLinux.pdf page12，这里提到计算动态优先级、时间片的时机是在进程的时间片用光之后，这个时候才会重新计算。\n 计算时间片大小 # 如何通过优先级计算时间片大小呢？\n时间片的计算是简单的缩放操作，优先级越高的任务在每轮执行中获得的时间片越多。最高优先级任务（nice值为-20）获得的最大时间片为800毫秒。即使是最低优先级的任务（nice值为+19），也至少获得最小时间片MIN_TIMESLICE，它要么是5毫秒，要么是一个定时器滴答，取两者中较大的值。具有默认优先级（nice值为0）的任务获得100毫秒的时间片。\n时间片重新计算的时机，是在时间片用光后，在将其从active队列挪到expire队列之前，完成计算的。\n ps：see https://web.cse.ohio-state.edu/~champion.17/2431/04-SchedulingLinux.pdf page12，这里提到计算动态优先级、时间片的时机是在进程的时间片用光之后，这个时候才会重新计算。另外，通过page11也可以了解到，进程的时间片大小是从优先级映射过来的。\n 多关照交互性任务 # 另外，调度器为交互式任务提供了一个额外的辅助功能，如果一个任务足够交互式，在它的时间片用尽时，它不会被插入到过期数组中，而是重新插入到活动数组中，这样它可以被调度地更加及时、频繁。\nstruct task_struct *task; struct runqueue *rq; task = current; rq = this_rq(); if (!--task-\u0026gt;time_slice) { if (!TASK_INTERACTIVE(task) || EXPIRED_STARVING(rq)) enqueue_task(task, rq-\u0026gt;expired); else enqueue_task(task, rq-\u0026gt;active); }  设计存在的问题 # 该方案并非尽善尽美，下面是被指出的最大的问题：\n 关于“交互性”的度量以及改善调度的代码，变的很复杂、很难理解，它是不是正常工作很难简单说yes or no； 不出意外地，这个调度器本身也很难建模，但是能建模，对于确信该调度算法是否能正确地工作不可或缺。  本文小结 # 本文介绍了Linux O(1)调度器设计实现，该调度器作为更早期版本的替代方案，最终也被后来的CFS替代了。尽管如此，我们学习了解O(1)调度器的时候，还是可以学习到一些很有价值的设计考量。另外，通过了解O(1)调度器的设计实现，我们对调度中的一些至关重要的衡量指标也理解更深刻了。\n后续我还会继续总结下Linux CFS调度器的设计实现，欢迎阅读交流！\n 任务迁移主要有两种方式，work-sharing vs. work-stealing。当创建一个新任务时，调度器尝试迁移部分任务到其他处理器，这种就是work-sharing的方式。另一种方式是，比较空闲的处理器执行时会主动从其他负载高的处理器任务队列中迁移一部分过来，这种就是work-stealing的方式。Linux调度器O(1)、CFS都是work-sharing的模式。Go运行时GMP调度也是采用的work-stealing的设计。大道至简，操作系统和语言运行时层面的任务调度，有些类似的设计但不完全相同，能工模型、巧匠窃意！\n 参考文献 #  Linux O(1) scheduler, https://litux.nl/mirror/kerneldevelopment/0672327201/ch04lev1sec2.html Scheduling in Linux: O(n), O(1) Scheduler,https://www.youtube.com/watch?v=vF3KKMI3_1s Linux Scheduling, https://web.cse.ohio-state.edu/~champion.17/2431/04-SchedulingLinux.pdf A Scheduling Story, https://ops-class.org/slides/2017-03-03-schedulingstory/  "}),a.add({id:42,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A64/",title:"Linux任务调度(4): O(1)后的探索优化",description:"O(1)调度器解决了O(n)调度器存在的调度下一个任务的瓶颈问题，但O(1)调度器也并非完美，难以对O(1)调度器进行建模并对其效果进行量化。在O(1)之后，内核开发人员依然做了不少探索，CFS调度器是一个更好的解决方案，但是在CFS出现之前还有几个比较火的调度器解决方案，本文我们就来了解下这个探索历程。",content:"演进过程 # 首先，再次回顾下下Linux进程调度器的一个发展历史：\n v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n))  O(1)调度器解决了O(n)调度器存在的调度下一个任务的瓶颈问题，但O(1)调度器也并非完美，难以对O(1)调度器进行建模并对其效果进行量化。在O(1)之后，内核开发人员依然做了不少探索，CFS调度器是一个更好的解决方案，但是在CFS出现之前还有几个比较火的调度器解决方案，本文我们就来了解下这个探索历程。\n前面已经介绍了O(n), O(1)调度器，本文我们来了解下CFS解决方案诞生之前的相关探索。\nO(1)调度器的问题 # 随着 2.6.0 版本的临近，一些开发人员担心 CPU 调度程序的问题会让这个稳定版本系列垮台。交互性能差、NUMA 系统支持不佳等等的抱怨很常见。随着时间的推移，大部分问题都已得到解决，大量的交互工作和域调度程序已经解决了大部分问题。近年来，有关调度程序的投诉相对较少。\n然而，2.6 调度程序的复杂性仍然困扰着一些人。尤其是交互性工作，添加了大量非常晦涩的代码。调度程序竭尽全力尝试识别交互式任务并相应地提高其优先级。这个过程涉及到许多奇怪的计算，很难理解，更不用说改进了。\n比CFS更早的探索 # 楼梯调度器 # 内核开发人员 Con Kolivas 于2004年提出了 “楼梯调度算法(Starecase Deadline Scheduler)”。Con Kolivas 参与了大部分交互工作，他发布了“楼梯调度程序”补丁的新版本，该补丁旨在大大简化调度程序，同时提高交互响应；它删除了 498 行代码，同时添加了不到 200 行代码。删除的大部分内容是“黑魔法”交互计算；它全部被一个相对简单的、基于等级的方案所取代。\n楼梯调度程序为每个 CPU 设置一个多优先级运行队列。最初，每个进程按照其基本优先级确定的等级进入运行队列；然后调度程序可以以常见的方式找到并运行最高优先级的进程。到目前为止，与O(1)相比没有太大变化。\n在当前的O(1)调度程序中，用完其时间片的进程将被移至单独的“过期”运行队列（expire runqueue）；它们在那里一直等待，直到活跃运行队列（active runqueue）中的其余进程也用完它们的时间片（或被阻塞），此时二者交换后才能被调度。\n而楼梯调度程序中删除了expired runqueue这个设计，时间片用光的进程，其优先级将被调低，并据此重新计算一个时间片，然后将其放回到新优先级对应的队列中。因此，它可以继续运行，但优先级较低。当它耗尽这个时间片时，它再次向下移动，一直这样重复。\n当其从最低优先级队列掉出来时，它的优先级、时间片可以被重置并重新放入runqueue，但是其优先级比原来初始优先级低一级、时间片+1。\n ps：当时内核社区还不愿意在稳定系列中进行另一次重大调度程序更改，很多人希望看到 2.6 真正稳定下来。然而，这个补丁似乎值得考虑，因为它简化了内核的复杂部分。\n 旋转楼梯调度器 # 2007年，Con Kolivas继续提出了 “旋转楼梯截止时间调度器(Rotating Staircase Deadline Scheduler, RSDL)”，旋转楼梯调度器，是对楼梯调度器的增强，为什么呢？我个人认为，旋转楼梯调度器更好的建模了优先级、公平性、响应性、解决饿死等的问题，它更好理解和维护。\n简而言之，CPU调度似乎是一项无法完美解决的工作。尽管开发者不断优化调度算法，但总会有某些类型的工作负载得不到很好的调度服务，特别是对交互型任务要求响应迅速的用户。现在的调度器为了提高交互式进程的响应,已经发展出了非常复杂的优化手段。但复杂的代码也带来维护困难，而用户对响应时间的抱怨仍未止息。CPU调度需要持续改进，才能更好平衡不同类型任务的需要。\nCon Kolivas长期致力于改进交互性的工作，RSDL调度器试图通过相对简单的设计来提供良好的交互响应、完全的公平性和有界的延迟。这项工作吸收了Con早期楼梯调度器(2004年6月报道过)的思想,但实现方法上有明显不同。\n与许多调度器一样，RSDL维护一个优先级数组，如上图所示。\n 在每个级别上都有一个要求以该优先级运行的进程列表，每个进程在该优先级上都拥有一个执行时间配额。最高优先级的进程优先被调度，调度器使用典型的轮转算法在它们之间进行切换。 当一个进程在给定优先级上的配额用完时，它会被降至下一优先级，并获得一个新的配额。因此该进程可以继续运行，但只能在高优先级进程都运行过后。随着进程在这楼梯结构中下降，它们必须越来越多地与低优先级进程竞争，这些低优先级进程一直在低级别队列上耐心等待。最终结果是，即使是最低优先级的进程，最终也能获得至少一点CPU时间，实现公平性。 这个调度器的一个有趣特性是,每个优先级都有自己的配额。一旦最高优先级用完了配额，无论这些进程是否用完了自己的CPU时间配额，所有在这一级运行的进程都会被推到下一更低的级别。通过这种“次要旋转”机制，等待在较低优先级的进程只需要在有界时间内等待，之后所有其他进程就会运行在它们这一级。因此任何等待运行的进程的最大延迟是有界的，并且可以通过计算确定，这个调度器不会出现饥饿。 当进程用完它们的时间后，它们会被移动到另一个数组，称为“过期”数组。在那里，它们的优先级被重置。过期数组中的进程不运行，直到在当前活动数组中不再有进程会被调度。此时，会发生“主要旋转”，活动数组和过期数组交换，整个进程调度序列从头开始重新启动。  与O(1)调度器对比的话，O(1)调度器通过跟踪每个进程睡眠事件来确定是否是交互任务然后再决定是否奖励它们。RSDL放弃了所有这些。相反，进入睡眠的进程在较高优先级运行时应该不会使用完它们的时间配额。这样和那些CPU密集型容易耗光时间片的比，它们自然处于有利地位。如果一个进程在主要旋转期间睡眠，它的优先级、时间片配额会被加回到当前运行队列的对应等级的队列中。因此，即使其他高优先级进程在此期间一直在运行并通过次要旋转被降到更低优先级，该进程也仍能以高优先级运行。\n所有这些合起来就进一步改善了程序的交互性。\n ps：RSDL调度器确实建模上更容易理解了，而且据不少内核开发人员反馈这个实现方案效果确实不错，之前O(1)调度器存在的问题，打上这个RSDL调度器的补丁后就消失了，大家呼声很高。但是由于Torvalds、Ingo等人坚持没有证明其有效性Con Kolivas对此也表达了质疑，最终吧RSDL调度器没有进入内核主线。\n CFS调度器诞生 # 调度器主要维护人人员Ingo，借鉴了RSDL算法对于公平性的建模，提出了 Complete Fair Scheduler （CFS，完全公平调度器），通过虚拟运行时间vruntime来建模调度的公平性，同样也可以解决公平性、饿死、交互性问题。并且Ingo还实现了一个支持可插拔自定义调度器实现的方案，而这些都是之前Con Kolivas极力主张并遭到Torvalds和Ingo反对并拒绝掉的。Con Kolivas对此感觉到很愤怒，于是他最终下决定离开了内核开发社区。\n ps：可以了解下对ck的访谈，了解下他为什么离开内核开发社区：https://geek.digit.in/community/threads/why-i-quit-kernel-developer-con-kolivas.81361/。\n 我们这里不搞那些阴谋论哈，说实话，个人感觉CFS中通过vruntime量化统计并表征公平性的建模更容易理解并被接受。我们将在下面的小节中重点介绍CFS相关的知识。\nCK，BFS又来了 # Con Kolivas消失了一段时间，直到后面2009年他又回到了Linux社区提出了 Brain Fucker Scheduler（BFS），业内很多开发人员反映将CFS切换到BFS之后，其在桌面上的交互响应、用户体验有不错的改善、提升，但是时至今日因为这样那样的原因BFS仍然是没有进入Linux内核主线的，它的宿命可能像RSDL一样，但是它的思路可能是对的，Linux没法提供一个通用的调度器来同时最佳适应服务器、桌面、移动设备、嵌入式设备，即使是CFS也无法胜任，内核应该允许在不同场景下采用适应性更好的调度器实现。但是Torvalds、Ingo更倾向于提供一个通用的解决方案。\n本文小结 # 本文介绍了O(1)调度器存在的问题，以及为调度器设计实现所努力钻研的Con Kolivas提出的几个经典调度算法“楼梯截止时间调度器”、“旋转楼梯截止时间调度器”的设计及实现，从中我们也了解了其中的一些对公平性、饿死问题、交互性问题的处理方法，也对方案建模、论证方案有效性了解了点相关知识。\n篇幅原因，将另外开一篇文章重点介绍CFS的设计实现以及实际用法，怎么调度器还有什么花活吗？如果你感兴趣，不妨一起来学习下。\n参考文献 #  The staircase Scheduler,https://lwn.net/Articles/87729/  "}),a.add({id:43,href:"/tags/nice/",title:'nice"',description:"",content:""}),a.add({id:44,href:"/tags/o1/",title:"O(1)",description:"",content:""}),a.add({id:45,href:"/tags/priority/",title:"priority",description:"",content:""}),a.add({id:46,href:"/tags/rsdl/",title:"rsdl",description:"",content:""}),a.add({id:47,href:"/tags/timeslice/",title:"timeslice",description:"",content:""}),a.add({id:48,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A62/",title:"Linux任务调度(2): v0.01",description:"本文介绍下Linux调度器的演进过程，对其中有代表性的调度器实现进行分析总结。作为任务调度器系列文集中的一篇，本文重点介绍最早的内核版本v0.01中的调度器实现。",content:"演进过程 # 首先，简要描述下Linux进程调度器的一个发展历史：\n v0.01~v2.4.x: the very first scheduler，复杂度O(n) v2.6.0~v2.6.22: O(1) scheduler，复杂度O(1) v2.6.23~: Completely Fair Scheduler (CFS)，复杂度O(log(n))  可能会有点好奇，只有这么几种吗？这是出现在内核源码树中的实现方案，研究探索过程中，涌现出的实现方案多的多，前一篇文章任务调度(1)中就提到过很多种方案，感兴趣可以了解下。本文只重点介绍内核源码树中真实出现过的调度器实现方案。\n最早的版本 v0.01 # v0.01是最早的Linux内核版本。它的进程调度器只有20行代码，非常简单。作为对比，最新的Linux内核由数万行代码组成。\n在v0.01中，所有的任务都由一个数组表示。这个数组不仅是所有任务的列表，还是运行队列。这个数组的长度是64。这意味着这个版本中的任务数最多为64个。在这个数组中，空的条目用NULL表示。\n调度器的时间片是150毫秒。当前任务是否用尽了它的时间片是由一个称为间隔定时器的硬件检测的。间隔定时器每10毫秒中断一次CPU，然后调度器注册的处理程序被调用。这个函数减少当前任务的时间片，如果时间片变为零，调度器就会在运行队列中调度下一个可运行的任务。\n在这个版本之后，时间片的值和定时器中断的间隔都发生了变化。然而，为了简单起见，本文不会逐一解释这些变化。\n ps：进程切换的时机，v0.01里面是在系统调用返回前、时钟中断服务程序中检测是否需要进行进程切换。时钟中断处理时会递减当前进程的剩余时间片，为0后就会调度其他进程执行。\n 以下是Linux v0.01的进程调度器的调度算法：\n 逆序遍历运行队列，找到剩余时间片最大且大于0的进程，调度该进程； 如果没找到可调度的进程，调度器会重置所有任务的剩余时间片。对于可运行任务，调度器将给与150ms的时间片；对于仍处于休眠状态的任务，调度器在该任务剩余时间片的基础上额外增加剩余时间片的一半（也就是t=t*1.5）。 后者的原因是为了让之前休眠任务被唤醒后能尽快被调度，以提高交互性。  我将用图示来展示上述算法的流程。\n初始状态如下所示，时间片的单位是10毫秒：\n首先，调度器以逆序遍历运行队列。在这里，t4被跳过，因为它正在休眠。此外，t2也被跳过，因为该条目为空。在遍历整个任务数组后，它发现t1的时间片是所有可运行任务中最大的。调度器调度t1运行，直到t1用光剩余的时间片。\n调度器继续遍历，发现接下来t0是可运行的、剩余时间片最大的，于是调度t0运行直到时间片用光。在逆序遍历的过程中，如果发现了多个任务的剩余时间片同时为最大，那么选择第一个扫描到的进程执行。\n最终所有的可运行的进程都被调度执行了，并且时间片全部用光变为0：\n然后调度器会重置runqueue中所有可运行进程的时间片，比如150ms，也就是timeslice=150ms/10ms=15，对于睡眠状态的t4为了能让其从睡眠中恢复后尽快被调度以改善交互性，它的时间片等于=15+12/2=15+6=21。\n当t4从睡眠中恢复时，t4的剩余时间片就是最大的了，但是调度器不一定就立即会调度它，因为调度的发生是在固定的时机才会触发，比如时钟中断处理程序发现当前进程时间片耗光了，或者当前进程要睡眠、退出或者执行其他系统调用需要让出CPU时。\n ps：其实，在内核代码里面写法是这样的，就是说：最开始的时间片15是由优先级（nice值）确定的，counter\u0026raquo;1对应的就是睡眠进程的时间片除以2的操作。\nvoid schedule(void) { ... (*p)-\u0026gt;counter = ((*p)-\u0026gt;counter \u0026gt;\u0026gt; 1) + (*p)-\u0026gt;priority; ... }  如果你对这部分的源码实现感兴趣可以参考：https://github.com/hitzhangjie/linux-0.0.1-learning/blob/master/linux-0.0.1/kernel/sched.c#L82。\n 本文小结 # 本文简单介绍了Linux内核调度器在演进过程中主要的实现版本，并先介绍了最最最早期的一个版本，也就是linux kernel v0.0.1版本中的调度器版本，真的是非常简单。但是这里面已经有了进程优先级、交互性的一些考量。毕竟是一个玩具版本，后面的版本中也对这个调度器做了一些改进。到了v2.6.0的时候引入了O(1)调度器，再后来v2.6.23引入了对公平性支持更好的CFS调度器，并且不断完善中。\n接下来，会写几篇文章，再继续介绍下O(1)调度器和CFS调度器，欢迎阅读交流。\n参考文献 #  Linux Scheduler History, https://ops-class.org/slides/2017-03-03-schedulingstory/ Linux Scheduler: the very first schedulerhttps://dev.to/satorutakeuchi/a-brief-history-of-the-linux-kernel-s-process-scheduler-the-very-first-scheduler-v0-01-9e4 v0.0.1内核源码解析，https://github.com/hitzhangjie/linux-0.0.1-learning/blob/master/linux-0.0.1/kernel/sched.c#L82  "}),a.add({id:49,href:"/tags/roundrobin/",title:"roundrobin",description:"",content:""}),a.add({id:50,href:"/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A61/",title:"Linux任务调度(1)",description:"任务调度是计算机通识课程中的必讲内容，我印象中还有相关的大作业让学生自己实现一个简单的进程调度功能，当然并不是直接在操作系统中去实现，而是用户态模拟进程的状态切换及过程中涉及到的调度逻辑。那为什么工作多年对这个认识也比较深入了，反而又准备写这样跟调度器相关的一个内容呢？因为调度器确实比较有意思，而且我敢说我们并没有挖掘出调度器的所有潜力，多数时候我们只是用了内核提供的默认的调度能力，还是有些可以挖掘来优化服务质量的地方，于是有此文。",content:"背景 # 任务调度是计算机通识课程中的必讲内容，我印象中还有相关的大作业让学生自己实现一个简单的进程调度功能，当然并不是直接在操作系统中去实现，而是用户态模拟进程的状态切换及过程中涉及到的调度逻辑。那为什么工作多年对这个认识也比较深入了，反而又准备写这样跟调度器相关的一个内容呢？因为调度器确实比较有意思，而且我敢说我们并没有挖掘出“调度”的所有潜力，多数时候我们只是用了内核提供的默认的调度能力，还是有些可以挖掘来优化服务质量的地方，于是有此文。\n ps：联想到当年操作系统老师布置的题目，我写了个demo然后上去讲，情商有点低，讲完还说老师出的题目不太好，老师有点小肚鸡肠直接让我下来，我脸皮也是厚，当时愣是没下来还大声问同学们有没有问题，笑死 :) 至于为什么说还没有挖掘出“调度”的潜力，调度粒度上可以是进程、线程层面，也可以是更细粒度的协程层面，为了更尽可能地压榨CPU提高执行效率，就得在追求并发处理的同时尽可能降低调度引入的开销。\n 一个导火索 # 先抛个有趣的问题，是这样的：一个go线上服务，与其他一些服务混部在16核32GB的机器上，没有用户请求的情况下CPU开销到了6%，而其他同类服务仅有1%不到的CPU。 perf top可以看到进程主要是在做go runtime work-stealing的事情，大致如下所示吧：\nSamples: 800 of event 'cpu-clock:uhpppH', 4000 Hz, Event count (approx.): 125918164 lost: 0/0 drop: 0/0 Overhead Shared Symbol 30.08% main [.] runtime.stealWork 5.76% main [.] runtime.futex.abi0 5.37% main [.] runtime.findRunnable 4.79% [vdso] [.] __vdso_clock_gettime ...  runtime.stealwork频繁被采样到，说明：1）该服务进程中实际上没有多少goroutines需要被调度执行，但是 2）scheduler却在频繁地执行调度器的唤醒。那为什么呢？如果你对GMP的理解不停留于表面的GMP八股，你应该会思考过go runtime scheduler的调度时机这个问题。\nM要先检查有没有等待timers定时器触发的goroutine，从localp.runq取可调度的goroutine, 没有则检查sched.globq，还需要检查netpoller，没有则stealWorker from 其他P。如果你了解这些细节，你很容易能锁定问题源头。因为服务进程没有实际的请求需要处理，直接可以排除poll localp.runq, sched.globq, netpoller的可能影响，那就只有timers定时器这一种可能了。\n带着这些去了解，最后发现，是因为用到的kv数据库的gosdk用到了一个触发非常频繁的定时器，1ms触发一次。至于为什么是1ms，这是一个查询表中所有记录的loadall操作，服务器会分批多次返回数据，gosdk里1ms触发一次是为了更即时检查还有没有后续数据需要传送给客户端。尽管是符合设计预期，但是实现上没有按需启停该timer，导致即使在没有loadall请求的情况下，timer频繁触发导致了不必要的CPU开销。\n ps: 调度的过程就是这样的一个死循环，“执行-\u0026gt;等待资源-\u0026gt;让出-\u0026gt;执行下一个”的过程，schedule()-\u0026gt;findRunnable()-\u0026gt;execute()-\u0026gt;schedule()，这里的1ms定时器频繁触发，就是findRunnable()的时候，先找到了它，它无活可干，很快让出，下一次findRunable的时候，timers、localp.runq、sched.runq、netpoller均无可调度的goroutines，则stealWorker这个工作量更大的任务，所以推高了CPU占用。\n如果将该gosdk内部的定时器触发间隔从1ms调整为1s，CPU开销立马从6%下降为0.3%上下。另外，vsdo_clock_gettime是通过rdtsc优化后的，即使1ms调用一次，相比于gettimeofday这个开销也不是大。以前用过一个框架频繁调用gettimeofday开销很大。\n 引出大问题 # 个别混部的服务CPU开销高，会不会影响同机上的其他服务呢？这就令人警惕了。尽管上述案例并不个严重问题，timers引入的开销也是一个固定的开销，不会因为用户请求量增大就导致CPU开销上涨。但是我们要考虑更全面点，不能因小失大，让小问题扩散造成更严重的系统性问题。\n 万一某个用户1创建了大量进程、线程，而另外一个用户2创建了少量进程、线程，操作系统会如何调度用户1的任务以及用户2的任务呢？会保证调度时用户层级的公平性吗？ 万一某个用户下启动了不少服务进程，但是其中一个进程有bug导致了大量的线程创建，那操作系统有能力保证相同用户下不同进程的公平性吗？比如整体来看优先级相同的A进程和B进程，尽管他们线程数不同，但是从进程视角来看它们应该获得接近的执行时间。 万一某个用户启动了一组多媒体进程，同时又启动了一组编译测试进程，如何人为地赋予这两组进程在 “组” 级别的公平性。即多媒体这个组的进程数量，可能于编译测试组的进程数量不同，但是组1获得的总执行时间和组2持平。   考虑这些问题的原因，是因为我们的测试环境大量使用了混部方案（当然我们可以不采用混部，但是必须搞清楚其复杂性和解决措施）：\n 混部情况下进程之间容易相互影响，如果一台机器大量占用CPU资源（恶意创建更多进程、线程），会不会影响到其他进程的正常执行呢，这个是肯定的。 那如果我们不混部呢？不混部可以绕过这个问题的影响。但是项目实践中，尤其是测试环境存在混部的必要性，来提高机器资源利用率，减少开发人员和运维人员管理机器、部署服务的复杂度。   我们要思考的是，操作系统任务调度层面（schedulers）提供了哪些能力来帮助我们解决这些问题。\n任务调度器 # 现在终于可以言归正传了，针对上面提及的各类担忧，Linux schedulers提供了终极解决方案！\n在接下来的几篇文章里，我们将详细介绍下Linux schedulers是如何演进和变化的，主要内容包括：\n 调度器历史 多级队列 MLQ 多级反馈队列 MLFQ O(1)调度器 RSDL调度器 lwn RSDL调度器 cuteOS RSDL调度器 wiki ck离开内核团队的原因 CFS调度器 #组调度扩展 CFS调度器+cgroups BFS调度器  然后我们在介绍完这些调度器基本内容后，我们再通过demo来手把手演示下CFS调度器的工作效果。\n本文总结 # 本文从线上问题出发，引出了一个在日常混部服务的过程中的对系统稳定性的担忧，最后回到操作系统调度器本身来应对这个挑战。我们列举了调度器目前曾经出现过的那些具有代表性的Linux schedulers实现，接下来将会介绍给大家。在阅读完后续内容后，你会明白Linux中是如何解决这一系列问题的。同时你也会大致明白如今云计算中的虚拟化技术大致是如何运转起来的。\n"}),a.add({id:51,href:"/tags/json/",title:"json",description:"",content:""}),a.add({id:52,href:"/tags/jsonpb/",title:"jsonpb",description:"",content:""}),a.add({id:53,href:"/blog/2023-08-23-json%E5%BA%93%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94%E5%8F%8A%E5%AE%9E%E7%8E%B0%E6%8E%A2%E7%A9%B6/",title:"JSON库性能对比及实现探究",description:"JSON是一种轻量级的数据交换格式，易于阅读、解析、生成，应用十分广泛。如今在微服务通信中，JSON也是一种常见的序列化手段，比如json-rpc或者gRPC json、pb互转。因为读写场景的不同，对JSON序列化、反序列化（或者解析）的关注点也不一样，一个通用的JSON库不一定能满足性能要求，可以看到有非常多的JSON第三方库频频向标准库发起挑战。本文将从JSON解析的不同场景入手，来说明这些场景下对JSON生成、解析的一些诉求，以及对性能方面的考量，进一步介绍下业界在这方面一些优秀的实践。",content:"本文背景 # JSON是一种轻量级的数据交换格式，易于阅读、解析、生成，应用十分广泛。如今在微服务通信中，JSON也是一种常见的序列化手段，比如json-rpc或者gRPC json、pb互转。因为读写场景的不同，对JSON序列化、反序列化（或者解析）的关注点也不一样，一个通用的JSON库不一定能满足性能要求，可以看到有非常多的JSON第三方库频频向标准库发起挑战。本文将从JSON解析的不同场景入手，来说明这些场景下对JSON生成、解析的一些诉求，以及对性能方面的考量，进一步介绍下业界在这方面一些优秀的实践。\n回顾JSON标准 # rfc8259是目前JSON事实上的标准https://datatracker.ietf.org/doc/html/rfc8259，一个合法的JSON value必须是一个object、array、number、string，或者以下字面量false、true、null。该规范定义了JSON grammar来说明如何表示上述数据。\nrfc8259标准明确提出，如果JSON数据不是在一个封闭系统中使用，在不同系统中进行交换时，字符集应该明确使用UTF-8编码。旧的JSON标准并没有指出这点，但是为了保证不同系统的正常交互，大多数系统使用的正是UTF-8编码。标准还指出在编码时不应该在头部添加BOM字符（Byte Order Mark，U+FEFE），一些JSON解析器为了尽可能保证互操作性可能会忽略被错误添加的BOM字符，而不是报错。\n ps：rfc8259中还提及使用Unicode字符，Unicode是一种字符编码标准，定义了字符的唯一码点，而UTF-8是Unicode的一种可变长的具体编码方案，以对ASCII进行向后兼容。\n JSON 解析器（parser）将JSON文本转换为另一种表示形式，比如go结构体struct。JSON 解析器必须接受所有符合 JSON grammar的文本，可以接受非 JSON 形式或其他扩展（比如vscode .devcontainer定义中支持注释）。解析器实现可能会对其文本的长度进行限制，也可以对数据的最大嵌套深度进行限制，也可以对数值的范围、精度进行限制。\n ps：\u0026ldquo;A JSON parser MAY accept non-JSON forms or extensions.\u0026rdquo; 这句话的意思是，JSON解析器可以接受非JSON形式或扩展。也就是说，解析器可以容忍一些不符合严格JSON语法的文本，或者支持一些扩展的语法或功能。这给了解析器一定的灵活性，使其能够处理一些非标准的JSON文本或具有扩展功能的JSON文本。这样做是为了在实际应用中提供更大的灵活性和兼容性，以满足不同的需求和场景。\n JSON生成器（generator）用于生成JSON文本，生成的文本必须严格符合JSON grammar。比如json.Marshal(v)将v这个数据类型序列化成JSON文本，当然还有json.MarshalIndent(v, \u0026quot;\u0026quot;, \u0026quot;\\\\t\u0026quot;)，会在name前面增加一些缩进，tab、空格等空白字符在标准中也是允许的。\n**小结：通过rfc8259我们了解了JSON是用来做什么的，有效的JSON数据是什么样的，为了互操作性、灵活性JSON的解析器、生成器又可以怎么做。**下面我们将介绍一些应用场景，从一般到特殊，对应的也会对标准库实现提出一些挑战，然后进一步介绍一些业界的实践、优化。\n从标准库开始 # go标准库中提供了对JSON编码、解析的支持，最常用的两个函数就是json.Marshal、json.Unmarshal。标准库的设计实现，对大多数数据类型、普通的编码解析场景、易用性方面提供了很不错的支持。\n在指出标准库在哪些场景下会表现欠佳之前，需要先了解下标准库在编码、解析过程中的一些实现策略、细节。\n这里简单总结一下：\n  标准库json.Marshal的过程，使用了大量的反射操作，比如确定map k、v的类型信息，struct字段的类型信息，匿名嵌套及字段的可见性分析，struct jsontag规则处理，而且是通过反射递归展开json.Marshal(v)中v的类型信息，才能知道如何encode，最后才是根据v及其内部各个组成部分对应的typeEncoder来完成encode输出。encode的过程中虽然它使用了一些caching（缓存）、pooling（池化）技术，但是前面的反射开销确实是比较大的，尤其是数据类型复杂、数据量比较大的时候。\n想了解详细过程的话，可以参考这篇总结，会对这个过程中的开销有更清晰的认识：https://www.notion.so/hitzhangjie/JSON-d278399b8092470985cbc423830115fb?pvs=4\n  标准库json.Unmarshal的过程，和json.Marshal的过程相比，其中涉及到的一些要点大差不差，这里就不展开了。\n  see: https://sourcegraph.com/github.com/golang/go@go1.19.10/-/tree/src/encoding/json\n ps：反射的开销主要在哪里？\nreflection trades performance for very dynamic and flexible code by pushing work from compile time to runtime. The runtime costs include indirect calls, type inspection, value conversions, and dynamic dispatch. But used judiciously, these costs can be worth it for certain programs.\n 我的个人看法是，标准库作为一种支持更广泛场景下的实现，使用反射并不是一件坏事，它牺牲了一定的性能来保证了运行时的更大的灵活性，而不用像某些三方库一样去做一些极致的优化，比如bytedance/sonic只支持amd64架构。\nWell，但是当我们知道自己要做什么时，还是可以去做一些更加“极致”的优化的。比如bytedance团队知道自己用的是什么类型的机器，借助SIMD等一系列优化，单是JSON相关的序列化、反序列化优化带来的收益，性能提升了、CPU开销下降了，算下来为公司节省了几十万核，这种优化就是很值得的。\n下面就带着这种“优化”的思路去看看“不同场景”下该如何优化来达到期望的效果。\n细说业界实践 # 先列举几个不错的第三方实现。\n   project repository functions     fastjson https://github.com/valyala/fastjson parser   jsonparser https://github.com/buger/jsonparser parser   jsoniter https://github.com/simon-engledew/jsoniter parser   simdjson https://github.com/simdjson/simdjson parser   simdjson-go https://github.com/minio/simdjson-go parser   rapidjson https://github.com/Tencent/rapidjson parser   easyjson https://github.com/mailru/easyjson parser+generator   json-iterator/go https://github.com/json-iterator/go parser+generator   bytedance/sonic https://github.com/bytedance/sonic parser+generator   segmentio/encodin https://github.com/segmentio/encoding parser+generator   goccy/go-json https://github.com/goccy/go-json parser+generator    fastjson # fastjson parse+get操作，和标准库encoding/json的unmarshal相比，效率是后者的15x，see benchmark。\nfastjson实现上消除了reflection，解析过程中也完全不需要schema，也不需要像其他某些三方库一样通过code generate来生成schema，它是怎么做的呢？\n 它解析JSON文本的过程，非常暴力直接，跳过空白字符直接对JSON value按照object、array、string、number、true、false、null进行解析，解析完后并不做任何“类型转换”的操作。比如object内部的字段名和值直接作为一个kvpairs数组存起来，并不关心它的类型是什么样的。 当真正去获取某个字段值时，调用方就知道类型是什么了，此时调用对应的GetInt或者GetString等包含类型信息的helper函数，函数内部将对应的string转换为具体的类型。  通过上面这种方法，彻底消除了反射。虽然parse+get的效率比标准库unmarshal效率高，但是还是要看具体场景，是否用起来方便，是否真的care性能。\n另外，fastjson虽然提供了快速的解析操作，但是没有提供快速的编码操作，尽管它提供了value.MarshalTo方法，但是这个并不是大家日常编码时需要的将任意类型编码为JSON文本的操作。\n关于快速的编码操作，fastjson建议通过valyala/quicktemplate来执行快速编码。我看了下，它实际上是通过模板引擎来完成这个编码操作，但是要业务开发针对要marshal的自定义类型写好对应的go模板，有这个功夫，我还不如将自定义类型实现Marshaler接口了，干嘛非得用模板呢？同样可以避免大量反射，还不用调试go模板。\njsonparser # 只支持parser，号称效率是标准库encoding/json的10x，那么它为什么这么快呢？没fastjson快 😆\n 它不依赖于encoding/json、reflection或interface{}，唯一真正的包依赖是bytes。 它在字节级别上操作JSON payload，为您提供指向原始数据结构的指针：无需内存分配。 没有自动类型转换，默认一切都是[]byte，但它提供了值类型，您可以通过helper函数自行转换。 它不解析完整的记录，只解析您指定的键。可以通过jsonpath来访问JSON中嵌套在内部的元素信息。  看下来，它的实现思路和fastjson类似。\njsoniter # 这个库的实现思路是，避免解析完整的JSON文本，而是遍历JSON数据的过程中path和指定的jsonpath匹配时才开始将当前path对应的jsonvalue进行decode。\n在这个遍历过程中没有使用反射，也没有decode不必要的value，前面的几个实现方案是解析了对应的value的，尽管只是kvpairs的形式，不过开销也不大。\n实际decode感兴趣的部分时还是使用了标准库encoding/json.Decoder的实现，这里面哈还是会走到反射部分。所以很难说这个库实现性能有多高。如果是数据量比较大，只解析其中部分数据时还是优势的。\nimport ( \u0026quot;encoding/json\u0026quot; \u0026quot;github.com/simon-engledew/jsoniter\u0026quot; ) func main() { var found any matcher := jsoniter.Matcher(\u0026quot;some\u0026quot;, 0, \u0026quot;nested\u0026quot;, \u0026quot;structure\u0026quot;) // .some[0].nested.structure d := json.NewDecoder(os.Stdin) err := jsoniter.Iterate(d, func(path []json.Token) error { if matcher(path) { return d.Decode(\u0026amp;found) // decode感兴趣的部分数据 } return nil }) }  simdjson(-go) # simdjson是C++版本的实现，simdjson-go是用go重写后的版本，整体实现思路差不多，所以合在一起说了。simdjson是Daniel Lemire 和 Geoff Langdale实现的一个JSON解析库，它广泛使用了SIMD指令操作来获得高效的JSON解析操作，号称解析1GB JSON数据只需要1秒钟。\nsimdjson-go是使用go语言重写后的版本，它的性能大概是c++版本实现的40%~60%，是标准库性能的10x。\n ps：大名鼎鼎的clickhouse就使用了simdjson，可以在这里看到更多使用simdjson的知名项目https://github.com/simdjson/simdjson#real-world-usage。\n 那么simdjson或者simdjson-go为什么会在解析的时候有这么高的性能呢？最主要的技术已经在名字中了，SIMD？\n2019年QCon大会上Daniel Lemire做了一个分享 Parsing JSON Really Quickly: Lessons Learned，其中提到了JSON解析过程中的主要任务，以及在实现时可能会遇到的一些挑战。作者还发表过一篇论文 Parsing Gigabytes of JSON per Second，感兴趣也可以看下。\nJSON解析中的主要任务 #  读取完整的JSON内容 检查是否是一个有效的JSON 检查Unicode编码 解析number 构建JSON DOM（document-object-model）  实现JSON解析时要注意 #   考虑分支预测失效的影响，避免难以预测的分支\n分享中给出了一个示例代码，无判断分支时每次迭代3cycle，加了奇偶判断分支每次迭代增加到了15cycle，通过branchless programming消除奇偶判断分支每次迭代重新回到了4cycle。为什么会给这个例子，因为在JSON解析时需要对字符{}[]:,\u0026ldquo;等进行分类，而分类是基于相等判断的，需要在设计实现时避免分支判断。\n  使用更宽字长，避免1个字节1个字节处理，很慢\n  如果可能（硬件支持的话），使用SIMD\n目前在大多数现代主流ARM、x64处理器上都支持SIMD，最初Pentium支持SIMD是为了更好地对多媒体（声音）进行处理，现代处理器增加了位宽更大的寄存器（128-bit、256-bit、512-bit），也增加了一些高效的指令，比如一次性做32个表查询。那这个和JSON解析有什么关系呢？JSON解析中需要对字符进行分类，如分类成{}[]:,\u0026quot;，通过巧妙的表设计，可以一次性对很多字符进行分类，而且代码还能避免不必要的分支预测。\n老的x64（Intel、AMD）平台可以用SSE2\u0026hellip;SSE4.2（128-bit），主流的x64（Intel、AMD）可以用AVX、AVX2（256-bit），最新的x64（Intel）可以用AVX-512（512-bit），其他平台可以自行检索下。\n  避免内存（对象）分配，这个很好理解了\nJSON解析库解析过程中解析出的object、array等最终都会转换成一个个的内存对象，如何合理地减少或者避免内存分配，就很重要，尤其是JSON数据量比较大的时候这个内存开销问题就会比较明显。对于支持GC的语言，因为GC也会导致CPU开销。\n  对解析性能做benchmark，并进行合理的优化\n比如在后续不停的优化、维护过程中，需要注意做好benchmark，一旦发现性能下降，就应该当做BUG来跟进。\n  从0到1实现simdjson # 分享最后给出了几个examples，分别介绍了SIMD技术在UTF-8编码检测、字符分类、检测转义字符（检测、移除转义字符、确定字符串范围）的应用，并不是那么好理解，建议多看几遍分享好好体会下，看了也不一定能理解那些branchless programming的写法，分享人明确指出这些玩意是经过lots of hard work总结出来的计算式。\n到这里，整个JSON文档的结构就可以非常高效地解析出来，没有任何分支判断。分享最后提到了将字符串转换为number时的一点复杂性、计算开销。man 3 strtod，strtod是一个库函数实现将字符串转换为浮点数double的逻辑，性能的话：吞吐量90MB/s、每个字节耗时38cycles、每个浮点数转换大约有10次分支预测失败。在simdjson作者看来这个转换太慢了，所以自己实现了相关的转换逻辑。\n最后，不同平台有不同SIMD指令及对应的实现细节，simdjson会检测当前平台，并通过runtime dispatch选择使用匹配的实现代码。将上述这些思路放在一起，就是simdjson的全部核心思想了。\nsimdjson的benchmark数据显示，其性能吊打yyjson、rapidjson、json for m. c++等其他json parser。但是它只支持parser，不支持generator，后面再介绍go标准库encoding/json的平替方案 bytedance/sonic 时我们会继续详细介绍下sonic的一些优化思路，当然SIMD相关的部分就可以省略掉了。\n小结：读者可能看到这里，可能恍然大悟，也可能仍旧一头雾水，感觉让自己迷惑的东西越来越多了？那是正常的，懂的越多之后会发现自己不懂的也越来越多。作者个人水平有限，也不打算在此补充更多SIMD的内容，读者感兴趣的话可以自行去学习。\nrapidjson # rapidjson虽然号称支持parser+generator，肯定是支持parser的，但是对于generator的支持是比较有限的，它和前面的个别JSON库有点类似，就是你得parse完后再修改再将这部分解析后的DOM生成为JSON数据。和我们日常应用时理解的将自定义数据结构、类型编码为JSON数据是有差异的。鉴于此，前面表格里没有将其归为parser+generator这一类。\n从simdjson的benchmark数据来看，虽然其性能吊打rapidjson，但是从实现思路上来看，rapidjson其实也是考虑使用了SIMD技术（仅限于SSE, SSE4.2？）来加速的，但是可能没有simdjson做的完善。\n下面是rapidjson项目介绍中，主要提到下面几点：\n  支持SAX和DOM两种风格的API；\n  它的性能近似strlen()，也支持SSE/SSE4.2加速；\n  不依赖外部库Boost，也不依赖STL；\n  内存友好，对于大多数32/64位机器，每个JSON值占用精确的16字节（不包括字符串）。默认情况下，它使用快速内存分配器，并且解析器在解析过程中紧凑地分配内存；\n  对Unicode支持友好。它内部支持UTF-8、UTF-16、UTF-32（LE和BE）以及它们的检测、验证和转码；\n  对性能方面的优化细节，我们就不再想想展开看了，毕竟是被simdjson吊打了 😆\neasyjson # easyjson提供了一个代码生成工具，它分析指定包中的struct定义并为之生成json.Marshaler接口的实现方法（MarshalJSON、UnmarshalJSON），代码生成工具代码生成阶段用到反射来获得待编码元素的类型，但是生成代码中就完全消除反射操作了，因此性能也会比较高。\n据提供的benchmark测试显示，性能能达到标准库的4~5x。由于它需要用代码生成来额外生成代码，为了方便生成代码，可以在类型定义上增加//go:generate，构建时先执行go generate ./...再执行go build。\n但是它毕竟要额外生成代码，但是也有可能某些情况下，生成工具不知道如何生成代码，比如 interface{}。\njson-iterator/go # json-iterator/go是另一个标准库encoding/json的平替，默认配置下它的编码、解析性能已经是标准库的好几倍，还可以配置成高性能模式，如允许使用6digits来编码float允许损失精度。\n那么这个库做了哪些优化呢？作为一个标准库的平替，应该可以多给些关注，看下它的benchmark数据：\n   ns/op allocation bytes allocation times      std decode 35510 ns/op 1960 B/op 99 allocs/op   easyjson decode 8499 ns/op 160 B/op 4 allocs/op   jsoniter decode 5623 ns/op 160 B/op 3 allocs/op   std encode 2213 ns/op 712 B/op 5 allocs/op   easyjson encode 883 ns/op 576 B/op 3 allocs/op   jsoniter encode 837 ns/op 384 B/op 4 allocs/op    那它是如何做的呢？看代码的结构的话，别说，bytedance/sonic跟这个还有点像……ok，回来继续看。\nsee：https://sourcegraph.com/github.com/json-iterator/go@71ac16282d122fdd1e3a6d3e7f79b79b4cc3b50e/-/blob/config.go?L296:26\u0026amp;popover=pinned\nsee：https://sourcegraph.com/github.com/json-iterator/go@71ac16282d122fdd1e3a6d3e7f79b79b4cc3b50e/-/blob/reflect.go?L87:23-87:31\n看了下，和segmentio/encoding/json有点类似，尽可能消除反射逻辑、缓存技术、池化技术之类的优化。但是这里的测试应该没有那么充分，它的性能应该和segmentio/encoding/json差不多了太多。\nbytedance/sonic # 该JSON库支持parser+generator，可以作为go标准库encoding/json的平替，API方面和标准库提供的接口一样也比较友好，对JSON标准的支持层面也OK。支持和标准库对齐的默认配置、对齐标准库模式、快速模式等，不同的模式有不同的控制选项来决定是否跳过一些排序、转义之类的操作。\nsonic可以作为go标准库encoding/json的一个平替（至少在amd64平台上是可以），不仅如此，它还号称是在全场景中表现优异。开发者提到，此前很难找到支持全场景、并且在支持全场景中性能均保持top3的json库，这也是开发者最终开发bytedance/sonic的一个起因。\nbytedance/sonic有一篇非常不错的介绍性文章，see: 基于 JIT 技术的开源全场景高性能 JSON 库。其中提到了所谓的全场景的概念：\n 泛型（generic）编解码：JSON 没有对应的 schema，只能依据自描述语义将读取到的 value 解释为对应语言的运行时对象，例如：JSON object 转化为 Go any, interface{}, map[string]interface{}； 定型（binding）编解码：JSON 有对应的 schema（Go strcut），可以同时结合模型定义与 JSON 语法，将读取到的 value 绑定到对应的模型字段上去，同时完成数据解析与校验； 查找（get）\u0026amp; 修改（set） ：指定某种规则的查找路径（一般是 key 与 index 的集合），只对需要的那部分 JSON value 进行查找或者修改。  读者可以将前面的一些json库的应用场景与上面提到的情景进行下对应，总结下某些场景下的一些优化手段。对于sonic而言，它在改进性能方面，有哪些比较亮眼的地方呢？\n bytedance/sonic: A blazingly fast JSON serializing \u0026amp; deserializing library, accelerated by JIT (just-in-time compiling) and SIMD (single-instruction-multiple-data).\n 先简要说下sonic针对不同场景的大致优化思路，根据笔者认为的idea重要性程度做个排序：\n  simd并行处理：在对json中字符进行分类、字符串转义、编解码、确定字符串范围、校验等方面，使用SIMD进行数据级并行处理，这个在simdjson中已经有明确的效果了。另外，开发者发现对于较短的json数据使用SIMD得不偿失，所以会综合json数据长度来决定是走标量或向量处理的方式。\n  jit编解码函数：定性编解码，标准库中会通过反射来递归获取schema中不同成员的encoder func，然后在进行序列化、反序列化时会以函数调用的形式来逐个调用上述func。sonic开发者发现这里的函数调用开销很大，尤其是旧版本的go函数参数传递方式比较低效。他们通过JIT将需要用到的encoder funcs组合成一个函数体，省去了函数调用的开销。\n  llvm编译优化：go编译器对编译优化做的没llvm好，clang中已经集成了llvm，为了利用llvm的优化能力，有一些核心函数是用c编写的，然后再通过clang进行编译生成优化后的汇编，然后这部分汇编go编译器是不认识的，sonic开发者又提供了一个asm2asm的工具将这些汇编转换为plan9汇编，最终由go编译器编译。\n  缓存优化：上述encoder funcs是可以缓存处理的，但是缓存的东西不多、直接使用sync.Map来缓存时发现性能比较差，所以开发者使用RCU机制实现了一个缓存。\n  内存分配优化：对于json中一些不需要转义处理的字符串，可以避免拷贝字符串，也考虑了一些其他的池化技术。\n  热点代码路径：尽量消除反射。\n  其他，避免重复解析，；\n  sonic的性能优化，主要源自SIMD和JIT，它的优势在介绍simdjson的时候重点介绍过了，这里就不再展开。\n另外说到全场景，sonic API层面也做了比较好的支持，像范型编解码、定性编解码大家用的比较多了，不再赘述。对于按需查找\u0026amp;修改这种场景，sonic也支持了指定jsonpath来按需获取需要的那部分数据，如root, _ := sonic.GetFromString(jsondata, paths...)：\n 如果这个root是基本数据类型，那就可以通过root.Int(), root.Bool(), ...等函数直接取到值， 如果这个root是object类型，  没有schema时，可以通过root.Map()将其转换为一个map； 有schema时，可以通过root.Raw()拿到原始字符串数据后再去unmarshal；    ps：我们可以通过root对数据进行修改，然后可以再Marshal为json。\n为了更好地支持对json数据进行操作，sonic提供了一个新的数据容器ast.Node，它是对json进行解析后生成的，比如对某个jsonpath对应的数据解析后生成的，好处是继续查找其下面的字段时，不用对之前的jsonpath进行重复解析。另外，它是一个比any或者map更好用的数据容器。\nsegmentio/encoding # 内部实现使用了一些unsafe操作（无类型代码、指针运算等等）来尽可能避免使用反射，使用反射通常是序列化过程中CPU占用高、内存开销大的重要原因。这个包致力于实现零不必要的动态内存分配，并且热点代码路径中尽量避免使用反射包。\n以json.Marshal(v)为例，来看下做了哪些优化？\n 构建encoderCache sync.Map的时候，它没有使用reflect.Type来作为key，而是使用了typeid(reflect.Type)，实际上是一个实现类型的地址，通过这种方式减轻了后续查询type对应的encoder的开销； map的keys是否排序，提供了一个选项进行控制，而不是像标准库那样有各种各样的排序，排序前获得map中的所有key、value还是通过反射的，所以这个排序的前置准备以及排序本身都有开销的，不能忽略； struct的fields排序也省略掉了，这个把struct及其内部嵌套struct通过反射获取index信息进行排序的逻辑也比较啰嗦，这里也省掉了； html转义也是可以控制的，这个和标准库一样都有选项进行控制，算不上什么明显优化；  所以，segmentio/encoding/json库是通过消除一些不必要的反射以及其他一些优化技术来改善了解析、编码的性能，可以作为标准库的平替。实测其性能是优于标准库的，但是没有sonic好。\ngoccy/go-json # 这个库是后来发现的，它和bytedance/sonic在全场景支持方面有的一拼，泛型编解码、定性编解码、按需查找、流式都支持，按需修改不支持。goccy/go-json也是可以直接作为标准库的平替的，它做了哪些方面的优化呢，这个在其项目README里面有比较清晰的介绍。\n主要包括如下这些优化：\n  buffer复用：https://github.com/goccy/go-json/#buffer-reuse\n  移除反射：https://github.com/goccy/go-json/#elimination-of-reflection\n  encoder部分\n  避免Marshal参数逃逸：https://github.com/goccy/go-json/#do-not-escape-arguments-of-marshal\n  预编译的操作码序列进行编码：https://github.com/goccy/go-json/#encoding-using-opcode-sequence\n这点上也是为了消除大量的函数调用开销，和bytedance/sonic中使用JIT构造编解码函数的目的是一样的。\n  上述操作码序列优化：https://github.com/goccy/go-json/#opcode-sequence-optimization\n  递归调用JMP代替CALL：https://github.com/goccy/go-json/#change-recursive-call-from-call-to-jmp\n  根据typeptr查信息，从map到slice：https://github.com/goccy/go-json/#dispatch-by-typeptr-from-map-to-slice\n    decoder部分：\n 根据typeptr查信息，从map到slice：https://github.com/goccy/go-json/#dispatch-by-typeptr-from-map-to-slice-1 更快的结束符检测：https://github.com/goccy/go-json/#faster-termination-character-inspection-using-nul-character 边界检查移除：https://github.com/goccy/go-json/#use-boundary-check-elimination 使用bitmap检测struct字段是否存在：https://github.com/goccy/go-json/#checking-the-existence-of-fields-of-struct-using-bitmaps    其他未列出的优化：https://github.com/goccy/go-json/#others\n  评价下的话：这个库在有schema的时候，性能和bytedance/sonic有一拼，更好或者逊色一点，但是无schema的时候比bytedance/sonic要逊色不少，比标准库好一点点。\n本文总结 # 本文首先介绍了下JSON标准，介绍了下JSON parser+generator在标准范围内的一些腾挪空间，然后我们列举了当前性能比较有优势的一些JSON库实现，并对它们属于parser、generator进行了分类，也指出了哪些库可以作为go标准库的平替方案。我们还比较详细地分析了各个JSON库的优化思路，其中重点介绍了simdjson这个被大量优秀开源项目使用的实现，以及针对go语言的bytedance/sonic这个在字节广泛使用的实现。从中我们认识到，JSON的使用场景比较多样化，泛型模式、有固定schema的模式、按需解析的模式，甚至还有对齐进行修改后再序列化的诉求，要实现一个支持全场景的方案本身就不简单，而且还要做到sonic开发者团队说的那样全场景top3的程度。\n目前，从效果上来看，sonic确实做的不错，但是它受限于amd64平台，继续支持其他平台可能并非sonic开发者能支持的，所以goccy/go-json的方案也值得借鉴下，虽然其在泛型模式下表现一般，但是其在有schema模式下已经可以实现和bytedance/sonic JIT优化后的差不多的效果了，看来goccy/go-json也可以有进一步优化战胜bytedance/sonic的空间\n参考文献 #  JSON, https://en.wikipedia.org/wiki/JSON Introducing JSON, https://www.json.org/json-en.html The JavaScript Object Notation Data Interchange Format, https://datatracker.ietf.org/doc/html/rfc8259 Parsing Gigabytes of JSON per Second, https://r.jordan.im/download/technology/langdale2019.pdf Parsing JSON Really Quickly: Lessons Learned, https://www.youtube.com/watch?v=wlvKAT7SZIQ rapidjson, https://github.com/Tencent/rapidjson rapidjson features, https://github.com/Tencent/rapidjson/blob/master/doc/features.md bytesonic/json, https://segmentfault.com/a/1190000044004731 goccy/go-json, https://github.com/goccy/go-json benchmark, https://github.com/hitzhangjie/codemaster/blob/master/serialization/json_benchmark  "}),a.add({id:54,href:"/tags/reflection/",title:"reflection",description:"",content:""}),a.add({id:55,href:"/tags/serialization/",title:"serialization",description:"",content:""}),a.add({id:56,href:"/tags/simd/",title:"simd",description:"",content:""}),a.add({id:57,href:"/blog/2023-09-25-%E8%A7%82%E6%B5%8Bgo%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8go-ftrace/",title:"观测Go应用函数调用：go-ftrace",description:"go-ftrace 是一个基于Linux bpf(2) 实现的函数调用跟踪、耗时统计工具，功能类似内核工具 ftrace(1) 。go-ftrace主要解决的是如何无侵入式地实现对go程序用户态代码的跟踪、耗时分析。本文介绍下go-trace的使用。",content:"go-ftrace # go-ftrace 是一个基于Linux bpf(2) 的类似内核工具 ftrace(1) 的函数调用跟踪、耗时统计工具，它主要是面向go应用程序的。\n限制: 因为设计实现的原因，当前go-ftrace只支持满足如下限制条件的go程序跟踪、统计：\n Linux内核：支持 bpf(2) 和 uprobe 的Linux内核 处理器架构: x86-64架构（little-endian字节序） 二进制程序：只能是go ELF可执行程序（非PIE模式），未剔除符号表.symtab，未剔除调试信息.(z)debug_info，  使用方式 # 项目中提供了测试程序 examples/main.go ，可以执行如下几种测试来了解go-ftrace的使用:\n示例1: 跟踪一个自定义函数 main.add: ftrace -u main.add ./main 示例2: 跟踪所有的匹配函数 main.add*: ftrace -u 'main.add*' ./main 示例3: 跟踪多个模式匹配的函数 main.add* 或 main.minus*: ftrace -u 'main.add*' -u 'main.minus*' ./main 示例4: 跟踪一个自定义函数 \u0026quot;main.add 以及 内置函数 runtime.chan*: ftrace -u 'main.add' -u 'runtime.chan*' ./main 示例5: 跟踪一个自定义类型的方法: ftrace -u 'main.(*Student).String ./main 示例6: 跟踪一个自定义类型的方法，并试图提取关心的参数: ftrace -u 'main.(*Student).String' ./main \\ 'main.(*Student).String(s.name=(*+0(%ax)):c64, s.name.len=(+8(%ax)):s64, s.age=(+16(%ax)):s64)'  示例目录下同时提供了一个 examples/Makefile, 你也可以执行 make \u0026lt;target\u0026gt; 来快速执行对应的命令（对应上面示例）来进行测试.\nps: 你可以在启动被测试程序 ./main 之前或者之后启动 ftrace，两种方式都可以正常工作，这主要是跟ebpf程序的加载、触发机制有关。\n安装方法 # 方式1 # 首先编译安装到 $GOBIN 或者 $GOPATH/bin，注意将 $GOBIN，$GOPATH/bin 设置到程序搜索路径 PATH 中。\ngo install github.com/hitzhangjie/go-ftrace/cmd/ftrace@latest  bpf tool require special permission, so we need run ftrace as root, like sudo ftrace ..., and we must make sure ftrace is searchable by sudo, so link it to the searchpath by sudo\nbpf程序的加载、执行需要特殊的权限，为了方便测试，我们先使用 sudo 来执行 sudo ftrace ...，由于 sudo 对安全性有要求， 为了执行 sudo ftrace 时能正常搜索到 ftrace，现在还需要添加个软链到 /usr/sbin/。\nsudo ln -s ~/go/bin/ftrace /usr/sbin/  经过这些设置后，就可以通过 sudo ftrace ... 对程序进行跟踪了:\nsudo ftrace -u 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire' ./a.out  方式2 # 为了简化安装，项目根目录下也提供了一个 Makefile 文件，可以执行 make \u0026amp;\u0026amp; make install 来完成安装。\n使用案例 # 你可以将其用于go程序的函数调用关系的跟踪，以及耗时相关的统计观测。\n以下面的示例代码为例（详见 examples/main.go），说明下工具的使用、执行效果：\nfunc main() { for { doSomething() } } ... func doSomething() { add(1, 2) minus(1, 2) s := \u0026amp;Student{\u0026quot;zhang\u0026quot;, 100} fmt.Printf(\u0026quot;student: %s\\n\u0026quot;, s) time.Sleep(time.Second) }  如果我们要观察函数 doSomething 执行过程中的函数调用关系，以及耗时情况，我们可以这样做：\nsudo ftrace -u 'main.*' -u 'fmt.Print*' ./main \\ 'main.(*Student).String(s.name=(*+0(%ax)):c64, s.name.len=(+8(%ax)):s64, s.age=(+16(%ax)):s64)'  ftrace 将输出如下信息，从中可以看到：\n 函数启动、停止时的绝对时间 函数执行的耗时信息，单位“秒(s)” 函数定义所在的源码位置 函数被发起调用时的位置 函数指令数据末尾的偏移量 想获取的函数参数信息  $ sudo ftrace -u 'main.*' -u 'fmt.Print*' ./main 'main.(*Student).String(s.name=(*+0(%ax)):c64, s.name.len=(+8(%ax)):s64, s.age=(+16(%ax)):s64)' WARN[0000] skip main.main, failed to get ret offsets: no ret offsets found 14 uprobes, large number of uprobes (\u0026gt;1000) need long time for attaching and detaching, continue? [Y/n] \u0026gt;\u0026gt;\u0026gt; press `y` to continue y add arg rule at 47cc40: {Type:1 Reg:0 Size:8 Length:1 Offsets:[0 0 0 0 0 0 0 0] Deference:[1 0 0 0 0 0 0 0]} add arg rule at 47cc40: {Type:1 Reg:0 Size:8 Length:1 Offsets:[8 0 0 0 0 0 0 0] Deference:[0 0 0 0 0 0 0 0]} add arg rule at 47cc40: {Type:1 Reg:0 Size:8 Length:1 Offsets:[16 0 0 0 0 0 0 0] Deference:[0 0 0 0 0 0 0 0]} INFO[0002] start tracing ... 23 17:10:59.0888 main.doSomething() { main.main+15 /home/zhangjie/github/go-ftrace/examples/main.go:10 23 17:10:59.0888 main.add() { main.doSomething+37 /home/zhangjie/github/go-ftrace/examples/main.go:15 23 17:10:59.0888 main.add1() { main.add+149 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:10:59.0888 main.add3() { main.add1+149 /home/zhangjie/github/go-ftrace/examples/main.go:40 23 17:10:59.0888 000.0000 } main.add3+148 /home/zhangjie/github/go-ftrace/examples/main.go:46 23 17:10:59.0888 000.0000 } main.add1+154 /home/zhangjie/github/go-ftrace/examples/main.go:33 23 17:10:59.0888 000.0000 } main.add+154 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:10:59.0888 main.minus() { main.doSomething+52 /home/zhangjie/github/go-ftrace/examples/main.go:16 23 17:10:59.0888 000.0000 } main.minus+3 /home/zhangjie/github/go-ftrace/examples/main.go:51 23 17:10:59.0888 main.(*Student).String(s.name=zhang\u0026lt;ni, s.name.len=5, s.age=100) { fmt.(*pp).handleMethods+690 /opt/go/src/fmt/print.go:673 23 17:10:59.0888 000.0000 } main.(*Student).String+138 /home/zhangjie/github/go-ftrace/examples/main.go:64 23 17:11:00.0889 001.0002 } main.doSomething+180 /home/zhangjie/github/go-ftrace/examples/main.go:22 23 17:11:00.0890 main.doSomething() { main.main+15 /home/zhangjie/github/go-ftrace/examples/main.go:10 23 17:11:00.0890 main.add() { main.doSomething+37 /home/zhangjie/github/go-ftrace/examples/main.go:15 23 17:11:00.0890 main.add1() { main.add+149 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:11:00.0890 main.add3() { main.add1+149 /home/zhangjie/github/go-ftrace/examples/main.go:40 23 17:11:00.0890 000.0000 } main.add3+148 /home/zhangjie/github/go-ftrace/examples/main.go:46 23 17:11:00.0890 000.0000 } main.add1+154 /home/zhangjie/github/go-ftrace/examples/main.go:33 23 17:11:00.0890 000.0001 } main.add+154 /home/zhangjie/github/go-ftrace/examples/main.go:27 23 17:11:00.0890 main.minus() { main.doSomething+52 /home/zhangjie/github/go-ftrace/examples/main.go:16 23 17:11:00.0890 000.0000 } main.minus+3 /home/zhangjie/github/go-ftrace/examples/main.go:51 23 17:11:00.0891 main.(*Student).String(s.name=zhang\u0026lt;ni, s.name.len=5, s.age=100) { fmt.(*pp).handleMethods+690 /opt/go/src/fmt/print.go:673 23 17:11:00.0891 000.0000 } main.(*Student).String+138 /home/zhangjie/github/go-ftrace/examples/main.go:64 23 17:11:01.0895 001.0005 } main.doSomething+180 /home/zhangjie/github/go-ftrace/examples/main.go:22 ... \u0026gt;\u0026gt;\u0026gt; press `Ctrl+C` to quit. INFO[0007] start detaching detaching 16/16  致谢 # 该项目fork自 jschwinger233/gofuncgraph, 在此基础上做了一些优化、bugfix相关的工作来改善工具的易用性、健壮性。\n感谢原作者的贡献!\nps：如果你对C/C++/Rust/Python相关的ftrace工具感兴趣的话，可以了解下 namhyung/uftrace，如果你对内核的ftrace工具感兴趣，可以了解下 kernel ftrace。\n"}),a.add({id:58,href:"/blog/2023-09-15-ebpf%E6%A1%88%E4%BE%8B%E5%8F%8A%E5%88%86%E6%9E%90gofuncgraph/",title:"eBPF案例及分析：gofuncgraph",description:"可观测性（observability）是这几年开始被频繁提及的一个词，特别是在微服务领域可观测性已经成为了微服务治理的一项关键的平台化技术手段，在CNCF孵化的项目中我们看到Opentelemetry如火如荼的发展背后也逐渐出现了一些成熟的解决方案。在腾讯内部也有类似天机阁、蓝鲸、wxg等不同的解决方案。这些往往配合框架解决了微服务RPC层面 的可观测性问题，实际上借助eBPF这项革命性技术，我们还可以做更多。",content:"前言 # 可观测性（observability）是这几年开始被频繁提及的一个词，特别是在微服务领域可观测性已经成为了微服务治理的一项关键的平台化技术手段，在CNCF孵化的项目中我们看到Opentelemetry如火如荼的发展背后也逐渐出现了一些成熟的解决方案。在腾讯内部也有类似天机阁、蓝鲸、wxg等不同的解决方案。这些往往配合框架解决了微服务RPC层面 的可观测性问题，实际上借助eBPF这项革命性技术，我们还可以做更多。\n背景 # 不久前，在做一个关于序列化方面的优化工作，先说下项目情况：项目中使用的go框架采用了pb+protoc-gen-gogofast来生成桩代码，RPC通信的时候使用pb序列化。另外呢，为了方便开发人员查看pb message对应的log信息，项目的日志库使用了pbjson将pb message格式化为json后输出到log，RPC interceptor也会使用相同的方式序列化req、rsp后将其上报到链路跟踪系统。\n大致就是这样一个问题，当时对比了pbjson序列化、stdlib encoding/json序列化，segmentio/encoding/json序列化，以及bytedance/sonic序列化。哈哈，这个顺序其实就是由慢到快的一个顺序，bytedance/sonic凭借优化反射、simd等技术“遥遥领先”其他集中方案。除了benchmark的手段，我还想看看上线前后的一些详细的优化效果，比如不同包大小（比如按1KB分桶）的序列化耗时（纳秒）分布。\n摆在我面前有两个办法：\n 改源码，统计下序列化前后的执行耗时，然后打log，写个工具分析下log； 改源码，统计下序列化前后的执行耗时，然后上报到监控，看看统计直方图；  其实都可以，但是我有点懒，我既不想去改源码（更不用说改很多）去写log、报监控，分析完了还需要再把这堆代码删掉。改完代码我还需要编译、发布，我们每次编译发布流程都要10min左右，我很不想去干这些事。\n总之我既想要灵活的分析工具（能灵活指定函数名称），又不侵入业务代码，调研之后发现有开发者实现了这样的工具，jschwinger233/gofuncgraph，它借鉴了内核函数图跟踪工具ftrace的设计，执行效果大致如下。借助funcgraph，很快解决了我的问题。\n工具介绍 # gofuncgraph是借鉴了Linux内核函数图工具ftrace（function tracer）的功能，然后为go程序开发的一个函数图工具，如上图所示，你可以指定要跟踪的函数的匹配模式，然后该工具会将程序中匹配的函数名全部作为uprobe去注册，并注册上对应的回调处理函数。\n处理函数中会根据是进入函数、退出函数来生成一些这样的events，每个event都有时间，这样就可以准确统计出函数的执行耗时了。然后利用调用栈信息，也可以绘制出函数调用图。最终输出上述函数图。\n 一个小插曲，help: how to use gofuncgraph，最开始我以为是要用这个工具去启动个程序才可以执行测试，是我理解有误。和作者沟通过程中，作者提到之前阅读过我写的调试器相关的电子书，并说质量很高。大家互相分享互相学习，挺好的。现在我也来学习作者的gofuncgraph，除了学习ebpf程序的写法外，我也想了解下为什么调试器的知识会用在这个程序里。\n 剖析实现 # 本节先介绍该工具的用户界面设计实现，然后再介绍其内部的工作逻辑，工作逻辑中会层层深入把必要的DWARF、eBPF、编译链接加载等相关的关键内容都逐一介绍下。\n为了后续方便自己学习、维护、定制，我fork了作者的项目并做了一些优化、重构，如使用spf13/cobra来代替了原先的命令行框架，spf13/cobra支持长、短选项，对用户更友好。另外也对项目代码进行了一些可读性方面的优化。后续介绍将继续我修改的这个版本介绍 hitzhangjie/gofuncgraph (dev)。\n命令行界面 # 执行 gofuncgraph help 查看帮助信息，简要介绍了它的用途，你可以执行gofuncgraph --help来查看更完整的帮助信息。\n简要帮助信息：\n$ ./gofuncgraph bpf(2)-based ftrace(1)-like function graph tracer for Go! for now, only support following cases: - OS: Linux (always little endian) - arch: x86-64 - binary: go ELF executable built with non-stripped non-PIE mode Usage: gofuncgraph [-u wildcards|-x|-d] \u0026lt;binary\u0026gt; [fetch] [flags] Flags: -d, --debug enable debug logging -x, --exclude-vendor exclude vendor (default true) -h, --help help for gofuncgraph -t, --toggle Help message for toggle -u, --uprobe-wildcards strings wildcards for code to add uprobes  详细帮助信息：\n$ ./gofuncgraph --help gofuncgraph is a bpf(2)-based ftrace(1)-like function graph tracer for Go! here're some tracing examples: 1 trace a specific function in etcd client \u0026quot;go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire\u0026quot; gofuncgraph --uprobe-wildcards 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire' ./binary 2 trace all functions in etcd client gofuncgraph --uprobe-wildcards 'go.etcd.io/etcd/client/v3/*' ./binary 3 trace a specific function and include runtime.chan* builtins gofuncgraph -u 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire' -u 'runtime.chan*' ./binary 4 trace a specific function with some arguemnts gofuncgraph -u 'go.etcd.io/etcd/client/v3/concurrency.(*Mutex).tryAcquire(pfx=+0(+8(%ax)):c512, n_pfx=+16(%ax):u64, m.s.id=16(0(%ax)):u64 )' ./binary Usage: gofuncgraph [-u wildcards|-x|-d] \u0026lt;binary\u0026gt; [fetch] [flags] Flags: -d, --debug enable debug logging -x, --exclude-vendor exclude vendor (default true) -h, --help help for gofuncgraph -t, --toggle Help message for toggle -u, --uprobe-wildcards strings wildcards for code to add uprobes  这里使用spf13/cobra来组织程序cmd、选项管理、帮助信息查看，说下参数设计吧：\n -d，主要是为了gofuncgraph执行时打印更多的调试信息 -x，主要是为了将vendor包中定义的函数给排除掉 -h，查看详细帮助信息 -u，指定要添加uprobe探针的用户态函数名的匹配模式，支持多个，支持同时获取函数参数信息，-u是必填选项。  如何自定义帮助信息，可以改写rootCmd.Short和rootCmd.Long，这样就可以了。\n如果提前熟悉spf13/cobra的话，要实现上述功能就很简单、敲一会键盘就搞定。\n查找待跟踪函数 #  加载elf文件构造elf.File对象 遍历elf.symtab中的每个symbol 检查sym中 ST_TYPE==函数类型的symbol 检查symbol.Name是否匹配 --uprobe-wildcards|-u来决定是否要跟踪 检查命令行参数中的fetch中的函数名。如果指定了函数名那么最终就只输出该函数的信息，反之就输出\u0026ndash;uprobe-wildcards匹配的所有的函数信息。  到这里，要跟踪的函数已经基本确定下来了。\n执行uprobe注册 #   检查命令行参数中的fetch中的函数参数读取规则（实际上是和上一步同时完成的）。生成参数值提取的规则，实际上寄存器操作、栈操作的序列，这个序列能得到一个内存有效地址。读取该地址处的、指定数据类型大小的数据，就相当于读取出了参数值。\n  将筛选出来的函数名、入口地址、返回地址等封装下交给uprobe去注册。咦，怎么没有像BCC+Python那样显示注册handler呢？作者是用Cilium来开发的，Cilium有自己的类似注解的宏，它是能知道添加uprobe时如何知道handler的。\n  执行uprobe回调 #  当对应的uprobe被触发就会执行注册的回调函数，也是用C语言实现的。 作者将其编译为ebpf后（格式为*.o）通过//go:embed嵌入到go中的[]byte全局变量中，然后再将其提交到ebpf子系统。 回调函数就是将收到的通知转换为一个处理事件event，里面包含了一些区分是进入函数、退出函数的标识，以及时间戳、goid、ip等寄存器信息，交给个chan去处理。  处理uprobe回调 #  有个eventmanager不断地poll其中的event并进行处理，也就是说去根据这个去计算每个函数的调用栈、每个函数的执行开始时间、结束时间信息。 最后再显示到命令行输出界面上。  本文小结 # 至此就介绍了gofuncgraph的工作原理。gofuncgraph输出的函数调用栈信息，要通过DWARF .debug_frame来确定调用栈信息，所以这里又是一个DWARF的使用场景。\n"}),a.add({id:59,href:"/tags/observability/",title:"observability",description:"",content:""}),a.add({id:60,href:"/tags/bcc/",title:"bcc",description:"",content:""}),a.add({id:61,href:"/blog/2023-09-15-ebpf_bcc%E6%A1%86%E6%9E%B6helloworld/",title:"eBPF BCC框架：helloworld",description:"目前写eBPF程序的话，一般要通过C语言来写，python、golang写的都是用户态的部分，涉及到内核部分的操作都是要借助C语言来写，然后通过编译器将C部分编译成字节码，用户态部分只是借助bpf()系统调用将字节码程序提交给了eBPF子系统去运行。本文就结合BCC框架+Python来写一个简单的helloworld，来熟悉下ebpf程序的写法。",content:"怎么写eBPF程序 # 目前写eBPF程序的话，一般要通过C语言来写，python、golang写的都是用户态的部分，涉及到内核部分的操作都是要借助C语言来写，然后通过编译器将C部分编译成字节码，用户态部分只是借助bpf()系统调用将字节码程序提交给了eBPF子系统去运行。\n实际上任何高级语言都可以写用户态部分，但是写内核态部分的eBPF程序需要写C语言，编译器会将C语言部分编译成target=ebpf的字节码，所以现在有很多框架比如BCC+python以及Cilium+golang等，都是对eBPF字节码操作、系统调用操作的一些封装。\nps：如果你是用Rust的话，那么确实可以直接写eBPF程序，不用依靠C，一般常用的是Rust aya这个框架。\n从0开始写eBPF程序 # 前面多次提到了eBPF程序编写、执行的大致过程，但是介绍的还是太粗略了，也不打算在这么几个简单的总结性文档中，把细节都介绍清楚。\n我们可以先看下，如果手把手从0开始写eBPF程序，大致需要经历哪些操作，看图：\n需要被简化的一些操作：\n 用C语言先写eBPF程序，然后使用编译器（如clang）将其编译为target为bpf的字节码程序，然后通过系统调用将其提交给eBPF子系统执行。这一步如果没有BCC这样的框架封装下的话，那么操作起来就有一点啰嗦。 还有你编译eBPF程序时要用到的很多头文件之类的设置，可能就比较麻烦。 还有eBPF程序执行时，那些结果存储到不同的数据结构，和不同语言的类型系统如何对接，如何方便的读取，全部自己从0开始搞也很麻烦。 其他的；  所以现在有BCC、Cilium、Aya这样的一些eBPF框架来简化这一些工作，我们可以先从BCC开始，这个项目比较早、成熟，用的人也多，也被集成到了Linux YUM源中，可以直接安装bcc、bcc-tools包来尝鲜。\n从helloworld开始 # 现在就开始使用BCC来写几个helloworld，让大家了解下一个简单的eBPF程序大致是如何写的，熟悉下其结构，后面虽然不一定自己写，但是了解已有的这些工具的实现细节，以及如何调整来满足自己需要，还是有帮助的。\nfile: helloworld.py\n#!/usr/bin/python3 from bcc import BPF program = r\u0026quot;\u0026quot;\u0026quot; int hello(void *ctx) { bpf_trace_printk(\u0026quot;Hello World!\u0026quot;); return 0; } \u0026quot;\u0026quot;\u0026quot; b = BPF(text=program) syscall = b.get_syscall_fnname(\u0026quot;execve\u0026quot;) b.attach_kprobe(event=syscall, fn_name=\u0026quot;hello\u0026quot;) b.trace_print()  分析下其结构：\n 导入bcc中的bpf program是一段c语言程序，b = BPF(text=program)，我们执行这个脚本时bcc框架会自动将其编译为字节码 它定义了一个hello函数，bpf_trace_printk会向ebpf子系统中的一个临时文件或者什么数据结构中打印hello world字符串 syscall = b.get_syscall_fnname是获得exeve函数调用的一个hook point b.attach_kprobe是在execve这个系统调用入口处通过kprobe系统调用创建一个探针，当执行到这里时会触发trap，内核会回调函数hello去执行，这里的hello就是上面C语言中定义的函数 b.trace_print会从取出前面打印的hello world字符串取出来打印出来。  这就是一个极简的helloworld的示例，当我们执行它时，它就会跟踪所有的execve的系统调用，每次触发这个系统调用时，就会打印上述helloworld字符串信息。\nps：执行ebpf程序时，需要使用root权限。\n执行上述示例 # ebpf程序运行需要用到debugfs，这个需要先挂载下，然后再执行，会看到打印很多helloworld：\nroot $ sudo mount -t debugfs debugfs /sys/kernel/debug root $ ./helloworld.py b' \u0026lt;...\u0026gt;-14182 [004] d...1 89191.905245: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14184 [001] d...1 89191.913364: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14183 [005] d...1 89191.913975: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14185 [005] d...1 89193.942389: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14187 [002] d...1 89193.951579: bpf_trace_printk: Hello World!' b' \u0026lt;...\u0026gt;-14186 [001] d...1 89193.952179: bpf_trace_printk: Hello World!'  系统中很多地方都会执行系统调用execve，比如执行shell命令ls，shell会先创建子shell然后execve替换text为ls的text（指令），所以这里也是会触发打印helloworld。\n本文小结 # 本文介绍了下ebpf程序开发的一个大致过程，以及结合BCC+Python给了一个简单的helloworld的实例，这个实例过于简单但是能让读者知道大致的过程。后面会结合一个具体的案例gofuncgraph来详细介绍ebpf程序开发。\n"}),a.add({id:62,href:"/blog/2023-09-15-ebpf%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5%E4%BB%80%E4%B9%88%E6%98%AFebpf/",title:"eBPF原理及实践：什么是eBPF",description:"eBPF是一项革命性的内核技术，它允许开发人员编写自定义的代码，然后被内核动态加载后执行，以此来改变内核的执行行为。它的这个特点能够帮助实现高性能网络、更好的可观测性、更细致的安全分析工具。本文先介绍下ebpf是什么，也是作者学习过程中的一点总结。",content:"eBPF是一项革命性的内核技术，它允许开发人员编写自定义的代码，然后被内核动态加载后执行，以此来改变内核的执行行为。它的这个特点能够帮助实现高性能网络、更好的可观测性、更细致的安全分析工具。\neBPF的前身：bpf # 1、eBPF的前身是bpf（BSD Packet Filter），最早它在1993年论文中有Lawrence Berkeley National Laboratory的Steven McCanne和Van Jacobson提出，它是一种类似字节码虚拟机的东西，有自己的指令集，你可以通过它来编写程序然后交给这个小的虚拟机去执行，这个指令集非常像汇编。比如你可以用它来写包过滤的逻辑（接受或者拒绝一个网络分组）。在这篇论文中可以找到其他一些更加复杂的示例程序，论文名：The BSD Packet Filter: A New Architecture for User-level Packet Capture。\n2、1997年，Linux内核版本2.1.75首次引入了BPF，BPF也就开始成为了Berkeley Packet Filter的简称，主要用在tcpdump这些工具中来实现高效的网络包的跟踪。\n3、时间快进到2012年，Linux内核版本3.5中引入了seccomp-bpf，它能够控制是否允许用户态应用程序执行系统调用，举个例子，我们启动一个docker容器，如果不添加特殊的选项控制，在docker容器内部去调试程序的时候是执行不了的，因为Linux系统中程序调试需要利用系统调用ptrace，但是ptrace往往都是被默认不允许的，发挥作用的就是seccomp-bpf，这里有一篇文章介绍了seccomp+ptrace调试原理的文章：https://zhuanlan.zhihu.com/p/606317619。seccomp-bpf是首次开始将bpf从包过滤这个范畴开始向其他范畴扩展。到今天发展到eBPF这个阶段，其实与最早的“包过滤”已经没有多大关系了。\n从BPF到eBPF # 随着BPF在Linux内核中的演进，到了2014年，从版本3.18开始可以使用eBPF将来称呼这项技术，全程就是extended BPF，这包含了几个比较明显的改变：\n BPF指令级对64位机器做了高度的优化，解释器也基本上重写了； eBPF中增加了maps，BPF程序执行时可以访问它记录一些数据，这些数据可以在BPF程序间共享，也可以允许用户态程序访问它获取结果； 增加了bpf()系统调用，用户态程序通过它可以和eBPF程序进行交互，比如加载到内核、从内核卸载、访问maps数据等； 增加了bpf_这样的一些helper函数； 增加了eBPF程序验证器，验证安全的程序才可以被执行；  这是eBPF首次正式放出，但是不是结束，此后就开始了它的快速发展之路。\neBPF到生产系统 # 这里介绍下eBPF技术演进过程中的一些关键事件：\n 2005年Linux中就引入了特性kprobe，它允许在任意指令地址处设置trap，当执行到此处时允许回调用户自定义的函数。开发人员可以编写内核模块，将其中的函数设置为kprobe的回调以执行调试。 ps: 调试器一般也是使用这种指令patch的方式，区别在于kprobe回调函数是内核处理的，而调试器tracee执行时触发断点是内核通过信号通知tracer由tracer来执行的。 2015年的时候允许将eBPF程序连接到kprobe，kprobe可以回调eBPF程序了，这使得在Linux中tracing变得简单，为了更好的追踪Linux内核网络栈的各类事件，Linux中开始增加各种hooks允许eBPF程序进行更细致的观测。 2016年，Netflix的工程师Gregg大佬公开了他和团队在eBPF基础上的大量性能观测工具及实践，让基础设施、运维领域认识到了eBPF在这方面的巨大潜力。 2017年，Facebook开源了Katran这个基于eBPF的高性能L4负载均衡器，也是这一年，Liz Rice这位女强人对此也产生了浓厚的兴趣，并开始研究。 ps: Liz Rice 经常做些技术方面的分享，目前是 the chief open source officer with eBPF specialists at Isovalent, 也是 the Cilium cloud native networking, security and observability project 的创建者. 2018年，Netflix、Meta的几个工程师为Linux eBPF做了大量贡献，使得eBPF成为了Linux内核的一个独立子系统，同年BTF（bpf type format）成为了ebpf的格式类型，使得ebpf程序更加兼容。 2020年，Linux内核支持了LSM BPF允许将eBPF程序和Linux安全模型LSM（Linux Security Model）连接起来，这意味着eBPF的用途又进一步清晰了、扩大了，就是安全工具、网络、可观测性。 近些年，更是有越来越多的项目诞生，cilium、aya等等，很多开发者都对此做出了贡献，业界的实践也越来越多、越来越成熟。  起名有点难 # 到现在的话，ebpf中的字母e已经没有太大意义了，它已经不仅仅是对bpf的扩展了，它成为了一个独立的子系统。现在提起ebpf的时候，有些人也会用bpf来称呼。但是在Linux内核中，包括操作ebpf程序的系统调用bpf()以及相关的helper函数bpf_xxx，都是直接以bpf来称呼的，这说明Linux内核开发人员已经认可了bpf来代指ebpf，它的含义已经变了，直接代指这个子系统了。但是在Linux内核社区外，还有些人会使用ebpf来称呼，比如ebpf.io这类站点。\neBPF诞生崛起的原因 # 前面的介绍，让大家知道了ebpf演进过程中的一些关键事件，不禁要问为什么它会诞生？或者说它有哪些优点？\n关心点：内核系统调用 # 大家对Linux内核可能比较陌生，但是对操作系统应该不陌生，毕竟大学都学过。用户程序在执行某些操作时，离不开操作系统的支持，操作系统充当的就是用户程序、硬件之间的一个服务人员，用户程序和服务人员之间传话的窗口就是syscall（系统调用）。\n通常用户程序，并不会直接使用系统调用，或者说直接调用的场景比较少，大家一般是通过标准库或者其他库函数的方式来间接使用系统调用。以golang为例，所有网络层面的系统调用都被封装到了标准库net中。\n系统调用，比大家的认识可能要复杂些，它包括阻塞性系统调用、非阻塞性系统调用，不同系统调用对程序执行的影响是不一样的，所以go为什么是一门工程化很好的语言，就是它在运行时层面屏蔽了这些，即使某个线程因为系统调用阻塞了，程序还可以继续跑。\n因为系统调用如此重要，开发人员会想知道程序中到底在执行哪些系统调用，此时就会借助strace之类的一些工具来跟踪、统计系统调用的执行情况，这样我们能更好了解程序的执行情况。\n困难点：内核增加功能 # Linux内核的代码规模已经达到了3kw+了，相当大的规模了，如果自己不是Linux内核开发人员或者说对感兴趣的模块不是不熟悉，你很难去修改它的。即使你修改了还要考虑另一个问题，你可能只解决了在你这个情景下、平台下的问题，但是Linux内核是一个通用操作系统，意味着我们的修改可能不一定能解决其他情景、平台下的问题。往往你修改个东西，要经过社区、Torvalds的同意才行，这个周期会非常常。根据统计，Linux内核社区贡献的所有patches也就只有1/3能够进入主线。\n即使进入了这个主线，可能已经过去一段时间了，你还要考虑发行版的问题，因为我们大部分开发人员、企业使用的都是某个发行版，发行版使用的内核版本又不一样了，什么时候主线代码被发行版使用了发布了，你才能考虑升级机器上的操作系统。这里就又过去一段时间了。\n也就是说，即使你发现内核代码有缺陷，或者想做功能扩展，即使你很有能力开发内核代码（大部分开发估计并不擅长还是需要多年沉淀才行），即使被合入主线、被发行版使用、机器也顺利升级了，但是时间不等人，这种方式满足不了需求方快速变化的需要。\n困难点：内核模块扩展 # 内核开发人员可以考虑通过内核模块的方式（但是开发内核模块也比较困难），来代替直接修改内核代码贡献到上游这个方式，这个路子更敏捷更快，时间成本大大缩短。\n内核模块也可以动态加载、卸载，不需要升级系统时停止机器。\n但是内核模块的安全性一直是大家比较担心的：\n 它运行在特权用户级别， 这个模块经过大家充分CR吗，有漏洞吗，会给攻击吗 这个作者值得信任吗 这个模块万一有bug会影响到整机稳定性吗  大家对于内核模块的使用慎之又慎，eBPF通过验证器来尽可能保证字节码程序的安全性，至少不会影响到内核本身的健壮性。又可以独立开发的方式来增强内核功能、快速响应需求变化，相比之下就有很大的吸引力。\n优势：eBPF程序动态加载 # ebpf程序支持动态加载、移除，不需要升级内核来获得要扩展的特性，也不需要重启机器来应用这些特性，这对于进行性能方面的观测、实现并应用安全工具就非常好。\n优势：eBPF程序的高性能 # ebpf程序（可能用c写、用rust写），写完的ebpf程序会被编译器编译为target为ebpf的字节码程序，被ebpf子系统加载后会被JIT（即时编译器）编译为机器指令，执行的是机器指令。\nebpf程序最终执行时，可以最小化用户态、内核态的频繁切换、减少上下文切换的开销，数据记录在ebpf maps，用户程序要获取数据就从ebpf maps中取。\n所以ebpf程序的性能是比较高的。\n优势：云原生领域 # 在云原生领域，ebpf这种对业务代码无侵入、无需编排配置的方式，使得它在可观测性等方面具有很大的优势。\n之前大伙也是一般通过sidecar（边车）模式来增强pod的功能，比如logging、trcacing等，servicemesh也会通过sidecar实现network的能力，sidecar有它的灵活性和优势，但是也有它的局限性：\n 添加sidecar时，要使其生效（如果一开始忘了加），pod必须整个重启； 需要修改k8s的编排配置的yaml来增加这个sidecar，尽管这个过程功过鼠标勾勾点点就可以、配置是自动化的，但是如果不小心勾选错误还是不会被织入这个sidecar； pod内如果有多个容器，有可能是需要指定启动顺序的，否则可能会发生竞态条件或者故障发生，这样的话也意味着pod启动更慢； servicemesh中通过sidecar来实现network的功能，所有的网络流量都需要经过一个pod中网络代理容器的中转，这增加了传输延迟，影响网络性能；  这些问题也确实是sidecar模式的一些问题，幸运的是ebpf作为一种平台能力，就可以比较好的解决这些问题。\n本文小结 # 这里介绍了什么是ebpf，包括它的前身、演进的一些关键过程，以及相对于传统的方式，当我们希望做些可观测性、内核功能增强、缺陷修复时相比修改主线内核、写内核模块所具有的一些优势。然后，如果能将ebpf作为一种平台能力进行建设，这将使得在可观测性、安全工具、网络性能优化方面做出一些比较大的效果，不管你的机器是裸金属机器、虚拟机，还是容器化应用，它都能统统搞定，而且不需要你侵入业务代码、部署配置也不需要重启机器、pod。\n"}),a.add({id:63,href:"/tags/avx/",title:"avx",description:"",content:""}),a.add({id:64,href:"/tags/avx2/",title:"avx2",description:"",content:""}),a.add({id:65,href:"/tags/checklist/",title:"checklist",description:"",content:""}),a.add({id:66,href:"/tags/linux/",title:"linux",description:"",content:""}),a.add({id:67,href:"/blog/2023-09-08-linux%E6%80%A7%E8%83%BD%E9%97%AE%E9%A2%98%E6%8E%92%E6%9F%A560s/",title:"Linux性能问题排查60s",description:"最近再阅读Gregg大佬著作《BPF Performance Tools》，其中一小节作者提到了其在Netflix工程团队中践行的一个性能排查checklist，当遇到Linux性能问题时，前60s往往是借助这个checklist来进行排查，如果有必要，缩小范围后再借助其他工具进行进一步排查。我觉得这个简短的checklist还挺实用的，特地摘录出来分享下。",content:"简介 # 最近在阅读Gregg大佬著作《BPF Performance Tools》，其中一小节作者提到了其在Netflix工程团队中践行的一个性能排查checklist，当遇到Linux性能问题时，前60s往往是借助这个checklist来进行排查，如果有必要，缩小范围后再借助其他工具进行进一步排查。我觉得这个简短的checklist还挺实用的，特地摘录出来分享下。\n问题背景 # 这个checklist可以用来指导排查任意Linux性能问题，当我们知道有台机器性能（疑似）有问题时，我们就可以登录这台机器，按照这个checklist来进行前60s的快速分析。这也是Gregg自己以及Netflix工程团队实践中总结出来的。\n对于很多刚入行后台开发的同学而言，我觉得这个还是比较有价值的，应该在日常工作中不断实践、不断加深对性能影响因素的理解。有位技术扎实的同事曾经这样说，一切都是可计算的、可量化的，比如判断对特定工作负载瓶颈是什么，cpu、内存、网卡？链路长短，网络延迟，然后大致的系统吞吐量是什么样的？他大致就能推算出来。\n其实，Jeff Dean曾经在论文里给出过一些开发人员应该知晓的latency数据：\nL1 cache reference ......................... 0.5 ns Branch mispredict ............................ 5 ns L2 cache reference ........................... 7 ns Mutex lock/unlock ........................... 25 ns Main memory reference ...................... 100 ns Compress 1K bytes with Zippy ............. 3,000 ns = 3 µs Send 2K bytes over 1 Gbps network ....... 20,000 ns = 20 µs SSD random read ........................ 150,000 ns = 150 µs Read 1 MB sequentially from memory ..... 250,000 ns = 250 µs Round trip within same datacenter ...... 500,000 ns = 0.5 ms Read 1 MB sequentially from SSD* ..... 1,000,000 ns = 1 ms Disk seek ........................... 10,000,000 ns = 10 ms Read 1 MB sequentially from disk .... 20,000,000 ns = 20 ms Send packet CA-\u0026gt;Netherlands-\u0026gt;CA .... 150,000,000 ns = 150 ms  有开发者将上述数据进行了可视化，以方便从视觉上更直观的感受差别：\n如果一直关注性能领域，实践一段时间后就大约能摸到门道了，还是很有帮助的。当我们遇到性能方面的问题后，经验会帮助我们更快速地认识到哪些地方可能出了问题，排查反而可能只是印证思路的过程。\n我们今天重点讨论对于任意Linux性能问题（可能也不是熟悉的系统），应该如何排查的问题，尤其是最开始的60s应该如何快速定位缩小问题域。\nLinux 60s分析 # 这个checklist不是一个大杂烩，不是列举一堆工具，它是工程团队沉淀的经验。\n uptime dmesg | tail vmstat 1 mpstat -P ALL 1 pidstat 1 iostat -xz 1 free -m sar -n DEV 1 sar -n TCP,ETCP 1 top  下面一个个解释下其输出的含义，以及可以帮助确定哪些问题。\nuptime # $ uptime 17:07:46 up 18:27, 0 users, load average: 0.08, 0.02, 0.01  uptime可以查看机器上线时间、平均负载的变化，看性能问题主要是看平均负载的变化。load average有3个值，从左到右分别表示最近1min、5min、10min的负载变化，因此可以看出最近一段时间的负载是上升、下降还是持平。\n如果看到15min负载是比较高的，但是最近1min负载比较低或者正常，说明负载已经降下来了，我们登录机器太晚了。一般企业会考虑容错，出问题的机器会被自动剔除掉。如果需要进一步分析，就需要借助其他办法来排查了，比如时光机atop或其他性能观测平台。\n 负载，指的是待调度执行的进程数（包括可运行和陷入不可中断睡眠的进程）。因此，如果数值超过cpu核数时就可能意味着cpu饱和了。\n dmesg | tail # 如果进程使用内存超过限制，或者机器整体内存紧张而oom killer选中了该进程被kill掉的话，其log信息会写入系统日志中，可以直接cat /var/log/messages查看，也可以通过dmesg来查看。\n对于一个拥有64GB机器的我来说，想要轻松复现一个oom kill的demo，还需要思考下。ulimit -v, ulimit -m, control group限定内存大小，不知道为何，这几个方法并不会直接导致oom killer介入并杀死进程，跟它们之间的工作机制有关系，暂不讨论。\n启动一个容器 docker run -it --rm -m 100m golang:latest /bin/bash，里面写一个go，通过选项-m 100m限定了容器中所有进程的最大内存上限。启动后写一个go程序，循环分配内存并提交，如：\nfunc main() { for { b := make([]byte, 1\u0026lt;\u0026lt;20) b[0] = 1 } }  编译并关闭GC运行：\n$ GOGC=off ./app` Killed  容器就是普通进程，只不过是通过Linux namespaces+controlgroup等进行了一些列的隔离、控制，在宿主机上运行dmesg | tail就可以看到进程被kill的信息。\n$ dmesg | tail [69826.948539] [ 23658] 0 23658 3594 754 69632 344 0 bash [69826.948799] [ 23882] 0 23882 1260354 22707 8851456 25101 0 main [69826.949060] [ 23908] 0 23908 14443 619 147456 134 0 top [69826.949335] oom-kill:constraint=CONSTRAINT_MEMCG,nodemask=(null),cpuset=93a579dd93754105f6650187e2ba12e40911e028bd01ce85e24277e59166e3c8,mems_allowed=0,oom_memcg=/docker/93a579dd93754105f6650187e2ba12e40911e028bd01ce85e24277e59166e3c8,task_memcg=/docker/93a579dd93754105f6650187e2ba12e40911e028bd01ce85e24277e59166e3c8,task=main,pid=23882,uid=0 [69826.950308] Memory cgroup out of memory: Killed process 23882 (main) total-vm:5041416kB, anon-rss:90828kB, file-rss:0kB, shmem-rss:0kB, UID:0 pgtables:8644kB oom_score_adj:0 [70504.061676] docker0: port 1(veth791efaa) entered disabled state [70504.062119] veth39cc165: renamed from eth0 [70504.195179] docker0: port 1(veth791efaa) entered disabled state [70504.197296] device veth791efaa left promiscuous mode [70504.197814] docker0: port 1(veth791efaa) entered disabled state  对于有些进程跑着跑着不见了，可以优先考虑是不是oom kill了，dmesg就是个好办法，它能输出进程被kill时的一些信息，如内存使用量之类的。\n Linux如何选定一个进程进行oom kill可以详细了解下这背后的决策过程，不完全不严谨的可借鉴的总结就是，整机内存紧张，如果某个进程运行时间不久但是占用内存高，其oom score分值就越大，越大的越容易被kill。时光机atop也可以看到进程被kill的信息。\n vmstat 1 # zhangjie@PC-GeniusStation gotest $ vmstat 1 procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 0 0 2476 26154180 577756 4476564 0 0 2 9 3 11 0 0 100 0 0 0 0 2476 26154184 577756 4476564 0 0 0 0 28 766 0 0 100 0 0 0 0 2476 26154184 577756 4476564 0 0 0 52 21 738 0 0 100 0 0  vmstat表示虚拟内存统计细腻系，参数1表示1s钟打印一次统计信息。比较有参考价值的几列数据：\n  r：正在运行的进程数+可运行等待执行的进程数，不包含等待IO的进程数，这个值比top和uptime总的load average更能反映CPU的饱和情况，因为它不包含IO进程，这样如果这个值比真实CPU核数多的话，那就说明CPU饱和了。\n  free：空闲内存数量，单位KB，使用free -m可以以mb为单位显示。\n  si, so：swap-in、swap-out数量（换入、换出次数），如果这些值不是0，意味着内存不足了，因为换入、换出仅在内存不足时才会发生。注意这里的换入换出是虚拟内存层面的。以前RAM比较小，经常有交换区的概念，现在RAM更大更便宜了，用的就比较少了。比如以前4GB内存+320GB硬盘配置下经常建个4GB大小的swapfile，现在我机器光RAM就是64GB 😄\nps：磁盘数据加载到内存，先是触发pagefault，然后内存控制器捕获异常后交给内核进行pages加载，也有叫法叫换入。注意这些术语所指的区别。\n  us, sy, id, wa, st：这几个是将cpu时间进行了细化，分别表示用户态、内核态、空闲时间，以及io等待时间，被某些虚拟机或者Xen等虚拟化技术抢走的时间。\n  通过这里的数据可以看出大部分时间都是消耗在us（用户态），要进一步分析，就需要借助其他工具、方法，如go tool pprof对程序进行分析，可以通过cpu火焰图观察到不同代码时间占用情况。\nmpstat -P ALL 1 # $ mpstat -P ALL 1 Average: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle Average: all 3.14 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 96.86 Average: 0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 Average: 1 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 ... Average: 22 100.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ... Average: 30 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00 Average: 31 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 100.00  mpstat能够输出所有CPU核心的耗时，而且它当这个耗时在不同状态下的时间占比进行了区分，比如usr,sys,iowait,irq,soft,steal。\n在上图中，我们看到有个核心core-22的user占比为100%，说明很可能存在一个单线程程序存在cpu瓶颈。\n假设，iowait时间占比较高，就要考虑disk io是否存在瓶颈；如果sys时间占比过高，则可以借助syscall、kernel tracing、cpu profiling工具进行进一步分析。\npidstat 1 # Linux 5.15.90.1-microsoft-standard-WSL2+ (PC-GeniusStation) 09/08/2023 _x86_64_ (32 CPU) 06:45:10 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:11 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:12 PM 1000 11479 1.00 0.00 0.00 0.00 1.00 22 pidstat 06:45:12 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:13 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:14 PM 1000 11480 65.00 0.00 0.00 0.00 65.00 22 main 06:45:14 PM UID PID %usr %system %guest %wait %CPU CPU Command 06:45:15 PM 1000 11480 100.00 0.00 0.00 0.00 100.00 22 main  pidstat能显示每个进程的cpu使用情况，也会将cpu使用时间细化成user,system,guest,wait，和top不同的是，它显示的是随着时间推移进程cpu使用率情况发生变化的信息，不变化的就不输出了。\n上面这个例子显示有个pid=11480的进程，它的cpu使用率逐渐从1%上升了65%，又上升到了100%。因为这里我写了一个死循环的程序来测试。\niostat -xz 1 # $ iostat -xz 1 Linux 5.15.90.1-microsoft-standard-WSL2+ (PC-GeniusStation) 09/08/2023 _x86_64_ (32 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.04 0.00 0.03 0.00 0.00 99.93 Device r/s w/s rkB/s wkB/s rrqm/s wrqm/s %rrqm %wrqm r_await w_await aqu-sz rareq-sz wareq-sz svctm %util loop0 0.04 0.00 3.30 0.00 0.00 0.00 0.00 0.00 0.79 0.00 0.00 92.27 0.00 0.29 0.00 loop1 0.02 0.00 1.60 0.00 0.00 0.00 0.00 0.00 0.21 0.00 0.00 70.95 0.00 0.42 0.00 loop2 0.06 0.00 4.02 0.00 0.00 0.00 0.00 0.00 0.23 0.00 0.00 71.93 0.00 0.37 0.00 sda 0.02 0.00 0.99 0.00 0.01 0.00 28.05 0.00 0.16 0.00 0.00 64.08 0.00 0.66 0.00 sdc 1.85 0.49 30.38 18.33 0.35 1.62 15.84 76.73 0.14 5.17 0.00 16.40 37.28 0.67 0.16 sdb 0.01 0.01 0.07 1.46 0.00 0.36 26.15 97.29 1.01 1.35 0.00 8.56 147.50 2.96 0.01 sdd 0.01 0.24 0.61 245.70 0.00 0.06 4.82 20.85 0.31 0.81 0.00 51.18 1010.66 4.47 0.11 sde 0.42 0.09 14.12 1.02 0.16 0.16 27.21 64.33 0.17 5.39 0.00 33.34 11.27 0.25 0.01 avg-cpu: %user %nice %system %iowait %steal %idle 3.12 0.00 0.00 0.00 0.00 96.88  这个工具显示的事存储设备的IO统计信息，输出的信息有点多、有换行的情况，其中值得关注的列：\n r/s, w/s, rkB/s, wkB/s：表示每s读请求数、写请求数、读数据量KB、写数据量KB。磁盘IO导致的性能问题，从这些很容易看出是读还是写导致的。 await：平均IO等待时间，包括请求IO排队时间+IO服务时间，总之就是程序感受到的IO等待时间。如果该值比平均时间大的话，那么可能就有可能是设备IO饱和、设备出问题的征兆。 avgqu-sz：发送给IO设备的平均请求数量，如果这个值明显大于1，就很可能表示是设备饱和的情况（但是有些设备，比如虚拟设备，它后面可能对应着多个磁盘，这个时候是因为并发请求多个磁盘，大于1是正常的）。 util：设备利用率，表示设备繁忙程度，1s内设备有多长时间在执行IO任务，不是表示设备容量使用百分比。如果这个值超过60%就要警惕可能会导致比较差的性能，100%则表示设备饱和。  free -m # $ free -m total used free shared buff/cache available Mem: 31964 1479 24351 5 6134 30030 Swap: 8192 2 8189  这个工具大家应该比较熟，它能显示内存总量、已使用量、空闲内存的情况，几个大家可能不熟悉的提一下。\n  shared表示tmpfs的内存占用量，通常比较小，一般/run, /sys, /tmp, /dev/shm虚拟文件系统会使用tmpfs。\n  buff/cache表示kernel使用的buffer、cache大小，这部分内存在需要时可以回收给应用程序使用的，内核使用它们主要是为了改善性能。\n ps：free命令输出中的buff/cache列显示的是被内核缓冲区和页面缓存所占用的内存量，它主要包括以下几类信息的缓存:\n  磁盘块缓存(disk cache):对磁盘IO进行缓存,避免每次从磁盘读取数据。这部分是文件系统对磁盘内容的缓存。\n  inode和dentry缓存:文件系统元数据的缓存,如文件名、索引节点数据等。避免查找元数据时总是访问磁盘。\n  目录缓存:目录文件内容。\n  进程执行代码的缓存:已执行的代码可以被缓存复用。\n  页面缓存:文件 mmap 到内存的页面缓存。\n  网络缓冲区:网络数据通过socket接收时的缓冲区。\n  键值对缓存:一些数据结构如散列表的缓存。\n  其他数据结构缓存:例如进程信息、文件描述符。\n  所以简单说,buff/cache列主要反映了内核对文件系统、磁盘内容、网络数据、元数据等各类数据的缓存占用内存量。这些缓存可以加速访问速度。\n   total=used+free+shared+buff/cache，available是一个估计值，表示当前有多少内存供应用程序使用。\n  sar -n DEV 1 # $ sar -n DEV 1 Linux 5.15.90.1-microsoft-standard-WSL2+ (PC-GeniusStation) 09/08/2023 _x86_64_ (32 CPU) 07:32:46 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 07:32:47 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:47 PM eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:47 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 07:32:48 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:48 PM eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:48 PM IFACE rxpck/s txpck/s rxkB/s txkB/s rxcmp/s txcmp/s rxmcst/s %ifutil 07:32:49 PM lo 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07:32:49 PM eth0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00  sar工具有很多统计模式，网络、磁盘、cpu等等，这里是用来查看网络相关的数据。通过rxkB/s、txkB/s可以查看到网络收发速率，可以评估是否达到了网卡的瓶颈。\nsar -n TCP,ETCP 1 # $ sar -n TCP,ETCP 1 07:35:03 PM active/s passive/s iseg/s oseg/s 07:35:04 PM 0.00 0.00 0.00 0.00 07:35:03 PM atmptf/s estres/s retrans/s isegerr/s orsts/s 07:35:04 PM 0.00 0.00 0.00 0.00 0.00 07:35:04 PM active/s passive/s iseg/s oseg/s 07:35:05 PM 1.00 0.00 2.00 3.00 07:35:04 PM atmptf/s estres/s retrans/s isegerr/s orsts/s 07:35:05 PM 0.00 0.00 0.00 0.00 0.00  这里使用sar来查看TCP连接、TCP错误相关的数据，有这么几列：\n active/s：表示每s本地主动发起的tcp连接数量； passive/s：表示每s本地被动接受建立的tcp连接数量； retrans/s：表示每妙tcp重传次数；  主动连接数和被动连接数有助于对工作负载进行区分，重传表示存在网络问题或者远程主机问题。\ntop # $ top top - 19:42:37 up 21:02, 0 users, load average: 0.00, 0.03, 0.32 Tasks: 15 total, 1 running, 14 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.2 sy, 0.0 ni, 99.8 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 31964.6 total, 24348.5 free, 1479.7 used, 6136.4 buff/cache MiB Swap: 8192.0 total, 8189.6 free, 2.4 used. 30030.2 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 2324 1712 1600 S 0.0 0.0 0:00.01 init(OracleLinu 4 root 20 0 3392 456 68 S 0.0 0.0 0:19.65 init 960 root 20 0 2340 112 0 S 0.0 0.0 0:00.00 SessionLeader 961 root 20 0 2340 120 0 S 0.0 0.0 0:00.00 Relay(962) 962 root 20 0 732512 27996 15856 S 0.0 0.1 0:02.83 docker-desktop- 979 root 20 0 2340 120 0 S 0.0 0.0 0:00.00 Relay(980) 980 zhangjie 20 0 769360 44228 27924 S 0.0 0.1 0:05.90 docker 1066 root 20 0 2340 112 0 S 0.0 0.0 0:00.00 SessionLeader 1067 root 20 0 2340 120 0 S 0.0 0.0 0:00.03 Relay(1068) 1068 zhangjie 20 0 22736 8288 3376 S 0.0 0.0 0:00.07 bash 15621 root 20 0 2340 112 0 S 0.0 0.0 0:00.00 SessionLeader 15622 root 20 0 2340 120 0 S 0.0 0.0 0:00.00 Relay(15623) 15623 zhangjie 20 0 22604 8096 3288 S 0.0 0.0 0:00.02 bash 16263 zhangjie 20 0 55416 4216 3588 R 0.0 0.0 0:00.00 top 18683 root 20 0 2348 120 0 S 0.0 0.0 0:00.83 Relay(18684)  top可以一次性显示性能相关的负载情况、cpu、内存相关的数据。到这里，top显示的很多数据，在前面提及的工具中我们已经见过了，但是运行top来二次确认下系统、进程数据也是有用的。\ntop有几个比较实用的操作，可能大家不清楚的，也提一下：\n h，按下h唤出帮助菜单； c，显示完整的cmd，包含路径几参数信息 shift+m，按内存占用情况对进程列表进行排序 e，切换内存占用量的单位，kb、m、g O，自定义key=value进行过滤，如COMMAND=bash 1，显示每个处理器核心的负载信息 top -p  -H，可以显示每个进程下的线程信息  那，先执行top行不行呢，当然可以，实际上要定位到问题源头，你可能要把上述工具都跑一下，问题排查的过程就是一步步缩小问题范围的过程。\n在理解上，我们可以接受这样的一系列工具，去逐个执行下看看情况，但是在实践中，我们还是希望有更好用的工具，比如atop，它能在同一个程序中展示上述工具所能显示的所有数据（atop也会调用上述工具，比如sar）。\nLinux atop # atop被称作是Linux下的时光机，是因为它能定时借助sar等系列工具收集、统计、记录下系统的一些运行信息，比如某个时刻的负载情况、cpu、内存、网络、设备io等等的情况，甚至连oom kill这样的事件都会记录下来。\n至于它为什么被称为时光机，是因为它真的是时光机：\n atop -r path-to/hhmmss.log，每天的运行时数据都会记录在一个日志文件里，你可以加载当天、过去的日志数据，来查看当时发生了什么； t: 可以将时间往后拨，按t一次，就会快进1min； shift+t：可以将时间往前拨，按shift+t一次，就会倒退1min； b：seek到指定时间对应的数据，如b 20230908 12:00，那么就查看12点以后的数据； \u0026hellip; h：查看帮助菜单；  atop大而全，确实是一个让人喜欢的工具，但是它输出的信息太多，有可能让新手蒙圈，现在AI非常给力，可以直接让AI解释每个数据项的含义。\n 有了atop，你就不用担心“坏了，我没及时登机器，现场丢了”。\n 进一步分析排查 # 上述工具，并不是排查问题、解决问题的全部，是排查问题时的前60s的排查建议，我觉得这个checklist还是比较中肯的。\n当我们确定了问题大约在哪个范围之后，你就可以继续深入排查，以go开发为例：\n 比如是内存使用问题，就可以通过go tool pprof进行内存相关的采样、go tool trace查看内存GC MMU信息，进一步确定内存高占用的原因； 比如是cpu使用问题，就可以通过go tool pprof进行cpu采样，查看下热点代码路径； 如果是sys占用高问题，也可以查看是不是存在大量的syscall之类的； 如果是网络、磁盘IO、kernel……  当我们缩小问题范围后，就需要借助合适的工具进一步排查，这个过程可能是层层深入的过程，甚至于没有现成的工具供你使用。换言之，大佬们给我们传递的始终是方法学、解决问题的模式，具体到不同的问题本身还是要case by case的分析。\n有可能大佬们沉淀了一些工具给我们使用，比如本书《BPF Performance Tools》中介绍的BCC包中的大量基于ebpf的分析工具。但是仍然有可能你需要自己开发工具，现在基于ebpf你可以做的、探查的更深入、更多。\n本文总结 # 本文介绍了Gregg《BPF Performance Tools》中提及的Netflix工程团队Linux性能问题排查60s checklist，介绍了下其checklist中提及的工具及适用范围，也介绍了下作者本人工作期间常用的Linux时光机atop，最后引出了ebpf这个当前在可观测性领域大火的技术。\n后面有机会的话，也会就ebpf在可观测性领域的应用、开发实践进行介绍 😃\n"}),a.add({id:68,href:"/tags/perforamence/",title:"perforamence",description:"",content:""}),a.add({id:69,href:"/blog/2023-10-13-simd%E6%95%B0%E6%8D%AE%E7%BA%A7%E5%B9%B6%E8%A1%8C%E5%A4%84%E7%90%86/",title:"SIMD数据级并行处理",description:"在了解业界高性能JSON编解码库的过程中，看到一些基于SIMD进行效率优化的方案，于是对SIMD的工作原理、应用场景以及使用方法产生了想进一步学习的冲动。于是便有了本文的一点对SIMD的浅显的学习、总结。",content:" Q: 那，接下来需要看下下面几个问题：什么是SIMD呢？SIMD最初是用来解决什么问题的呢？SIMD在JSON编码、解析中可以用来做什么呢？simdjson正确使用SIMD还需要注意些什么呢？\n What\u0026rsquo;s SIMD # SIMD(Single Instruction Multiple Data) 是一种并行计算技术,可以同时对多个数据执行相同的操作。使用 SIMD 的主要目的是为了提升计算性能。\n目前在大多数现代主流ARM、x64处理器上都支持SIMD，最初Pentium支持SIMD是为了更好地对多媒体（声音）进行处理，现代处理器增加了位宽更大的寄存器（128-bit、256-bit、512-bit），也增加了一些高效的指令。\n老的x64（Intel、AMD）平台可以用SSE2\u0026hellip;SSE4.2（128-bit），主流的x64（Intel、AMD）可以用AVX、AVX2（256-bit），最新的x64（Intel）可以用AVX-512（512-bit），其他平台可以自行检索下。\n ps: 并行处理按照发生的粒度，可以划分为：任务并行（多核），指令并行（超标量流水线），数据并行（simd、vector、gpu）。\n SIMD适用场景 # 适合使用 SIMD 的情况包括:\n 需要对大批量数据执行相同的数学运算或逻辑运算,如向量、矩阵运算、图像处理等。 需要对多媒体数据如音频、视频等进行处理,如编码、解码、滤波、变换等。 在数据库、科学计算、金融分析等需要处理大量数值计算的场景。 游戏开发中的物理模拟、人工智能等也可以使用 SIMD。  使用 SIMD 的好处有:\n 提高计算并行度,单次指令处理更多数据。 减少指令数,降低指令调度开销。 更高效利用处理器内部执行单元。 数据级并行,更易映射到多核架构。  一些常见使用 SIMD 的例子:\n 图像处理:模糊、锐化、色彩空间转换等算法可以用SIMD加速。 信号处理:FFT、FIR/IIR 滤波等用SIMD实现。 科学计算:向量矩阵运算都可以用 SIMD 优化。 数据压缩/解压:如音频视频编解码中的 SIMD 优化。 数据库操作:聚集函数、关系运算可用 SIMD 实现。 机器学习:神经网络中矩阵乘法、激活函数计算等使用 SIMD。  总之,SIMD 非常适合数据并行的场景,使用它可以显著提升计算性能。编译器和开发者都可以通过自动向量化和手动优化,利用 SIMD 使程序运行更快。\nSIMD新手入门 # 这里以对两个数组进行求和为例，如果使用C来进行编码的话，基本逻辑应该是这样：\nint nums1[LENGTH] = {1, 2, 3, 4, 5, 6, 7, 8}; int nums2[LENGTH] = {1, 1, 1, 1, 1, 1, 1, 1}; int result[LENGTH] = {0}; for (int i=0; i\u0026lt;LENGTH; i++) { result[i] = nums1[i] + nums2[i]; }  现在，我们考虑使用SSE、AVX2分别对其进行处理。\n./add_2arrays_sse128.c:用SSE添加两个数组：\n#include \u0026lt;xmmintrin.h\u0026gt; // Need this in order to be able to use the SSE \u0026quot;intrinsics\u0026quot; (which provide access to instructions without writing assembly) #include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { float a[4], b[4], result[4]; // a and b: input, result: output __m128 va, vb, vresult; // these vars will \u0026quot;point\u0026quot; to SIMD registers // initialize arrays (just {0,1,2,3}) for (int i = 0; i \u0026lt; 4; i++) { a[i] = (float)i; b[i] = (float)i; } // load arrays into SIMD registers va = _mm_loadu_ps(a); // https://software.intel.com/en-us/node/524260 vb = _mm_loadu_ps(b); // same // add them together vresult = _mm_add_ps(va, vb); // store contents of SIMD register into memory _mm_storeu_ps(result, vresult); // https://software.intel.com/en-us/node/524262 // print out result for (int i = 0; i \u0026lt; 4; i++) { printf(\u0026quot;%f\\n\u0026quot;, result[i]); } }  ./add_2arrays_avx256.c:用AVX2添加两个数组:\n在使用AVX2指令之前,我们必须对齐数组,否则会发生\u0026rsquo;段错误'。而且必须提供编译选项'-mavx2'。 AVX2支持在更先进和更新的CPU上,所以AVX2在gcc中默认是不启用的。\n#include \u0026lt;immintrin.h\u0026gt; // Need this in order to be able to use the AVX \u0026quot;intrinsics\u0026quot; (which provide access to instructions without writing assembly) #include \u0026lt;stdio.h\u0026gt; int main(int argc, char **argv) { float a[8] __attribute__ ((aligned (32))); // Intel documentation states that we need 32-byte alignment to use _mm256_load_ps/_mm256_store_ps float b[8] __attribute__ ((aligned (32))); // GCC's syntax makes this look harder than it is: https://gcc.gnu.org/onlinedocs/gcc-6.4.0/gcc/Common-Variable-Attributes.html#Common-Variable-Attributes float result[8] __attribute__ ((aligned (32))); __m256 va, vb, vresult; // __m256 is a 256-bit datatype, so it can hold 8 32-bit floats // initialize arrays (just {0,1,2,3,4,5,6,7}) for (int i = 0; i \u0026lt; 8; i++) { a[i] = (float)i; b[i] = (float)i; } // load arrays into SIMD registers va = _mm256_load_ps(a); // https://software.intel.com/en-us/node/694474 vb = _mm256_load_ps(b); // same // add them together vresult = _mm256_add_ps(va, vb); // https://software.intel.com/en-us/node/523406 // store contents of SIMD register into memory _mm256_store_ps(result, vresult); // https://software.intel.com/en-us/node/694665 // print out result for (int i = 0; i \u0026lt; 8; i++) { printf(\u0026quot;%f\\n\u0026quot;, result[i]); } return 0; }  你可以gcc编译后尝试运行一下，但是为了更好地比较出这几种方式的性能差异，我们还是需要多执行几次，我们来写个benchmark测试。\n./bench_add_2arrays.c，（不使用SIMD）将两个数组计算向量和1000w次：\n#include \u0026lt;stdio.h\u0026gt; #define TIMES 10000000 #define LENGTH 8 int main(int argc, char *argv[]) { for (int k=0; k\u0026lt;TIMES; k++) { int nums1[LENGTH] = {1, 2, 3, 4, 5, 6, 7, 8}; int nums2[LENGTH] = {1, 1, 1, 1, 1, 1, 1, 1}; int result[LENGTH] = {0}; for (int i=0; i\u0026lt;LENGTH; i++) { result[i] = nums1[i] + nums2[i]; } } return 0; }  ./bench_add_2arrays_avx2.c，使用AVX2将两个数组计算向量和1000w次：\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;immintrin.h\u0026gt; #define TIMES 10000000 #define LENGTH 8 #define i256 __m256i #define avx256_set32 _mm256_set_epi32 #define avx256_add _mm256_add_epi32 int main(int argc, char *argv[]) { for (int k=0; k\u0026lt;TIMES; k++) { i256 first = avx256_set32(1, 2, 3, 4, 5, 6, 7, 8); i256 second = avx256_set32(1, 1, 1, 1, 1, 1, 1, 1); i256 result = avx256_add(first ,second); /* int *value = (int*)\u0026amp;result; for (int i=0; i\u0026lt;LENGTH; i++) { printf(\u0026quot;%d \u0026quot;, value[i]); } printf(\u0026quot;\\n\u0026quot;); */ } return 0; }  实际测试结果表明，AVX2的运行速度是普通方法的2倍：\n$ time ./bench_add_2arrays real 0m0.092s user 0m0.092s sys 0m0.000s $ $ time ./bench_add_2arrays_avx2 real 0m0.036s user 0m0.036s sys 0m0.000s  如果应用程序中类似操作很多，通过SIMD进行加速会获得明显的性能提升。\n阅读更多 # 本文简单介绍了SIMD是什么，以及它有哪些应用场景，然后给出了一个求向量和问题中SIMD的应用示例，让读者直观感受了下SIMD的效率优势。但是并非所有计算场景都可以很容易联想到能通过simd来优化，需要巧妙地设计才能应用simd，比如simdjson中通过巧妙地查询表设计对字符进行分类、识别字符串位置等等。\n本文讲的内容实际上非常浅显，读者可以搜索更多的simd应用场景来加深对simd的认识。\n参考文献 #   Practical SIMD Programming, http://www.cs.uu.nl/docs/vakken/magr/2017-2018/files/SIMD%20Tutorial.pdf\n  C SIMD AVX2 Example, https://github.com/jean553/c-simd-avx2-example\n  Intel® Intrinsics Guide, https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#expand=91,555\u0026amp;techs=AVX2\n  Crunching Numbers with AVX and AVX2, https://www.codeproject.com/Articles/874396/Crunching-Numbers-with-AVX-and-AVX\n This article describes the datatypes and naming conventions, and how different intrinsics functions works.\n   http://ftp.cvut.cz/kernel/people/geoff/cell/ps3-linux-docs/CellProgrammingTutorial/BasicsOfSIMDProgramming.html\n This article is also very helpful.\n   "}),a.add({id:70,href:"/tags/sse/",title:"sse",description:"",content:""}),a.add({id:71,href:"/tags/sse2/",title:"sse2",description:"",content:""}),a.add({id:72,href:"/tags/tools/",title:"tools",description:"",content:""}),a.add({id:73,href:"/tags/littles-law/",title:"little's law",description:"",content:""}),a.add({id:74,href:"/blog/2023-04-18-netflix%E8%87%AA%E9%80%82%E5%BA%94%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4/",title:"Netflix自适应过载保护算法",description:"前面一篇文章介绍了排队论的知识，介绍了负载、RPS、Latency之间的关系，也介绍了传统的过载保护算法、分布式频控的过载保护算法，以及近些年Netflix、微信公开的基于Little's Law改进的过载保护算法。本文只讨论负载的评估，以及如何更好地实现scalable的过载保护算法，本文主要是基于Netflix公开的Netflix/concurrency-limits进行讨论。",content:"思路简介 # Netflix/concurrency-limits，基于Java实现的，star 2.9k+，也有go语言的第三方实现platinummonkey/go-concurrency-limits。\n平时大家评估服务负载、容量、最佳qps是如何做的，往往是先压测看服务能抗多少qps，然后请求方取个75%*qps作为一个阈值，然后请求方通过令牌桶、漏洞之类的来进行控制。但是对于很多个节点、需要动态扩缩容场景，这个固定值很快就会失效……当然有分布式频控的搞法……netflix的思路是与其将重点放在如何告知客户端设置qps，还不如让客户端能根据rtt自动算出下阶段的最大请求量来，这个是借鉴了little’s law以及tcp的拥塞控制。\n 它这里vegas算法估计的limit是这么算的 L * (1-minRTT/sampleRTT)， 然后还有个gradient2优化，来平滑下  详细设计 # 这个库提供了很多的limiter实现：\n  fixed，固定值，并发请求的时刻量不能超过这个fixedlimiter的值，这个值不变\n  aimd，基于loss的，请求成功就加性增，遇到失败就乘性减\n  windowed，基于滑动窗口实现的，每个窗口期内有一个limiter（成员delegate）,可以是前面提到的fixed、aimd等limiter\n  vegas，是基于测量的rtt的，另外也会考虑丢包。它实际上是确定了这么几个负载阶段：请求没有排队、请求有少量排队、请求有多一点排队、请求有很多排队。每次采样后会更新最新的limit，更新时会首先根据当前minRTT和sampleRTT以及当前limit来算一下接下里的queueSize，然后检查queueSize处于上面哪个阶段，然后使用对数操作进行平滑对当前的limit进行增大、缩小的调整。\n  gradient，它这里和vegas的实现思想上是一致的，只是对于inflight*2≥estimatedLimit时的处理逻辑不一样，vegas是将排队严重情况分成了几个阶段用不同的函数来调整limit，gradient是用了一个“梯度”的方法来调整，大致上是当前estimatedLimit * gradient + queueSize…这个算法的平滑处理能理解，但是不是那么“想象“象其效果。\n仔细看下，多揣摩几遍还是可以想象的出来的 😂\n  gradient2，它这里是对gradient的一个优化，什么优化呢？gradient是基于测量minRTT的，这会有个问题，minRTT还是比较敏感的，对于测量tcp的包（因为通常都会分片、分片大小往往都是确定的）没啥问题还挺好的。\n但是使用minRTT来测量RPC就不是特别好，因为RPC请求，不同接口的请求可能大小变化挺大的，即使是相同接口的请求可能变化也比较明显的。所以使用avgRTT要比minRTT更友好些，不至于limit的“抖动”，可能会导致过度的load shedding，造成不必要的请求被拦截。\n然后这里的avgRTT怎么算呢？从开始到现在的请求RTT的平均值？这里其实用的一个指数平均，一方面有平均值的作用能避免minRTT的上述问题；另一方面，使用的指数平均，0.8longtermRTT + 0.2sampleRTT，这样也能尽可能反映当前时刻的负载信息。\n另外这里的tolerance=2.0是说，如果遇到sampleRTT=tolerance*longtermRTT时，可以容忍这么长耗时的请求而不降低limit，仍然可以按照原速率发送，如果超了tolerance下的设置，那么梯度gradient就会小于1.0，此时limit就会被调低。limit调低时也会被smooth参数进一步平滑下。\n当从过载中恢复时，因为longtermRTT也被搞大了，如果不加处理，可能会有较长一段时间才能恢复到≤sampleRTT，这会有个问题，如果不能尽快恢复longtermRTT，则有可能持续增加发包速率再次导致过载。为了尽快恢复longtermRTT到正常值让发包速率处于steady状态，会判断longrtt / shortrtt\u0026gt;2时会给longrtt*0.95尽快调低longrtt。\n  调查总结 # 总结一下，vegas、gradient都是基于minRTT进行测量的，对于RPC场景而言可能并非最佳选择。相比之下gradient2是基于longtermRTT指数平均代替了minRTT，对RPC场景适应性可能更好。\n除了RTT，它们都考虑了负载steady、overload情况下的不同阶段以及调整策略（主要是increase limit、decrease limit时如何做到平滑）。可以测试下gradient2先有个直观认识。\n一点后话 # 当你的系统是一个大型的分布式系统，集群也需要动态扩缩容，系统中的负载类型不同，同一个服务的不同接口处理耗时不同，即便是相同接口不同请求处理耗时也有明显不同，这个时候常规的基于“请求配额”的传统过载保护机制是不怎么有效的。\n最初有这种想法，是在看点做内容处理链路的时候，注意到有些服务是计算密集型的（如OCR模块），有些是IO密集型的，有些图文发表请求里面只有一张图片，有的有多张图片，有的文章比较短，有的文章比较长，这都会影响你的系统负载、处理耗时，如何科学的评估负载进而确定合理的请求配额，是一件比较困难的事情。\n后面开始思考如何评估“负载”这样的问题，可能会想CPU使用率、内存使用率高、IO利用率高、网卡利用率高，实际上不同workload类型对资源的使用情况不同，这些指标高还真不一定就是负载高。如果涉及到具体语言，可能会去想Java、Go GC STW问题……\n预期纠结这些，不如更高屋建瓴地站在宏观角度看看，如果负载高了会发生什么？系统负载开始变高之后，是可以把其当做一个黑盒通过外部观测来观察出来的。Netflix的过载保护算法正是从这里触发，看似简单的实现，但是并不是不着边际。整个网络世界得以正常运转的TCP拥塞控制也是建立在RTT、Loss观测基础上的，Netflix也将其Vegas Limiter命名成了Vegas，正是因为它借鉴了TCP vegas拥塞控制算法（TCP Reno的替代算法）。\n"}),a.add({id:75,href:"/tags/overload-control/",title:"overload control",description:"",content:""}),a.add({id:76,href:"/tags/%E6%8E%92%E9%98%9F%E8%AE%BA/",title:"排队论",description:"",content:""}),a.add({id:77,href:"/tags/%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4/",title:"过载保护",description:"",content:""}),a.add({id:78,href:"/tags/ip-link/",title:"ip link",description:"",content:""}),a.add({id:79,href:"/tags/loopback/",title:"loopback",description:"",content:""}),a.add({id:80,href:"/tags/netem/",title:"netem",description:"",content:""}),a.add({id:81,href:"/blog/2023-04-14-%E5%8E%8B%E6%B5%8B%E4%B9%8B%E6%8E%A5%E5%8F%A3lo%E7%9A%84%E5%A6%99%E7%94%A8/",title:"压测之接口lo的妙用",description:"loopback接口大家都清楚，大致最初的认识就是可以通过localhost或者127.0.0.1来访问它，用来测试下网络协议栈是否能正常工作，如ping localhost，或者用来完成本地的服务器开发测试。但是由于它是一个虚拟接口，很多真实NIC存在的一些约束它是没有的，比如传输速率等，再比如网络中的传输时延等……本文结合笔者在日常开发中的一点实践，来进一步讨论下对loopback的妙用。",content:"问题背景 # 前一篇文章介绍了本地开发机压测时如何为每个待压测分配CPU资源（其实是taskset进行绑核，由于没有其他负载可以近似为分配CPU资源），本文继续介绍下如何让压测变得更真实一点，那就是网络IO这块，在本地通信时往往使用的是loopback接口，但是loopback并不是一个真实的网卡设备，它基本没有什么硬件网卡设备的传输速率的限制，也没有网络传输过程中的传输延迟。\n这样的话，我们在压测的时候，网络方面的开销就几乎体现不出来，比如说，你想看下在4g网络下客户端、服务器之间网络通信数据包多大时打开数据压缩更有价值……\n在我的测试过程中我希望能尽可能简化测试工作的同时，也能保证该有的环境的真实性，于是就有了本文对loopback接口的一点探索。\n认识本地lo # Linux中的Loopback接口是一个虚拟网络接口，允许在同一主机上运行的应用程序之间通信。它通常被称为“lo”接口，具有IP地址127.0.0.1。\nLoopback接口在内核中使用Loopback驱动程序实现，创建一个虚拟网络接口，并将所有传入的数据转发到本地协议栈。当一个应用程序将数据发送到loopback接口时，数据会被回送到协议栈，并像从另一个网络接口到达一样转发。 在Linux中，Loopback接口的一个重要用例是用于测试和调试网络应用程序。通过通过Loopback接口发送和接收数据，应用程序可以模拟网络流量，而不实际发送或接收来自物理或虚拟网络接口的数据。\nLoopback接口还由一些网络协议使用，例如Kubernetes kube-proxy IPVS，OSPF和其他需要在同一主机上的进程之间通信的网络相关软件。\n总之，Linux中的Loopback接口是一个虚拟网络接口，为在同一主机上运行的应用程序提供了一种通信通道。它在内核中使用Loopback驱动程序实现，并且在测试、调试和网络相关软件中具有许多实际用例。\n认识netem # 在 Linux 中，ip 命令中的 netem 是一个网络模拟工具。它允许您对网络连接进行各种修改，例如，添加延迟、丢包以及增加噪声等，以便在网络环境下测试应用程序的性能和稳定性。使用 netem 工具，您可以模拟各种不同的网络条件，包括高延迟、高带宽和低带宽等，以便更好地测试和优化应用程序在各种网络条件下的行为。\nNetem 已经成为 Linux 网络模拟和测试工具的标准选择之一，同时也是在诸如交换机、路由器和 WAN 加速器等网络设备上进行隔离测试和仿真时的一个有用工具。通过使用 netem，您可以更好地了解您的应用程序在不同网络条件下的行为，并且能够更好地进行演示和培训。\n利用本地lo # 如何使用netem让本地loopback接口更好地模拟真实网络情况呢？下面就来简单说一下。\n启用netem # 首先，需要启用内核模块netem：\nsudo yum install -y kmod sudo modprobe sch_netem  模拟网络延迟 # 然后，如果loopback接口的每次的收、发操作模拟一定的网络延迟：\nsudo yum install iproute-tc or sudo yum install iproute sudo tc qdisc add dev lo root netem delay 1ms  这样的话就相当于一个rtt增加了2ms，为了验证这个，你可以在执行上述模拟前后，分别看下ping localhost的延迟。\n模拟之前ping测试延迟：\nsh-4.2# ping localhost PING localhost (127.0.0.1) 56(84) bytes of data. 64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.033 ms 64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.090 ms 64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.047 ms ^C --- localhost ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2035ms rtt min/avg/max/mdev = 0.033/0.056/0.090/0.025 ms  模拟之后ping测试延迟：\nsh-4.2# sudo tc qdisc add dev lo root netem delay 1ms sh-4.2# ping localhost PING localhost (127.0.0.1) 56(84) bytes of data. 64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=2.04 ms 64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=2.04 ms 64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=2.17 ms ^C --- localhost ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 2002ms rtt min/avg/max/mdev = 2.040/2.087/2.175/0.072 ms  ping包括数据发出去、收到回包两个动作，每个动作都引入了1ms的延迟，rtt增加2ms。\n模拟千兆网卡 # 然后，如果loopback接口传输数据时希望有一定的网卡传输速率限制：\nbash-4.2# sudo tc qdisc add dev lo root netem rate 1000mbit  然后你可以使用iperf来测试下是否真的是千兆网卡的传输速率，iperf起个server：\nbash-4.2# iperf -s  然后再iperf起个client，观察二者的输出统计：\nsh-4.2# iperf -c localhost ------------------------------------------------------------ Client connecting to localhost, TCP port 5001 TCP window size: 4.00 MByte (default) ------------------------------------------------------------ [ 3] local 127.0.0.1 port 37004 connected with 127.0.0.1 port 5001 [ ID] Interval Transfer Bandwidth [ 3] 0.0-10.0 sec 1.16 GBytes 999 Mbits/sec  可以看到是999Mbit/sec，非常接近千兆网卡的传输速率了，全双工发送接受都是千兆。\n模拟MTU # 对了，正常TCP发包考虑到链路层封帧限制，还需要考虑mtu。\n先看下lo默认的mtu设置是多少，65536，这个在真实网络中不会这么大的，比如eth0这个网卡对应的mtu只有1500：\nsh-4.2# ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc netem state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 ... 10: eth0@if11: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 0a:0b:0c:0d:0e:0f brd ff:ff:ff:ff:ff:ff link-netnsid 0  好，现在来模拟下mtu等于1500：\nsh-4.2# ip link set dev lo mtu 1500 sh-4.2# ip link 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 1500 qdisc netem state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00  可以看到lo的mtu已经设置为1500了，这也会影响到后续的包的模拟发送接收。但是如果只是通过简单的ping localhost测试，是不会看出啥明显影响的。我们可能会预期mtu小了，难道帧多了上述增加的delay每个帧的延迟加起来不就变多了嘛？这跟delay工作的层次有关系，它是在网络层这层工作的。\n也就意味着如果网络层的包，因为mtu比较小拆了很多分片出来，到达网络层后增加的延迟会明显增加的。这里暂时不用做到这么细，只需要关注网络层的整体请求、响应延迟即可。\n同时模拟多种 # 当然，可以同时模拟多种行为，千兆网卡的传输速率限制+每次收发增加1ms传输延迟：\nsh-4.2# ip link set dev lo mtu 1500 sh-4.2# sudo tc qdisc add dev lo root netem delay 1ms rate 1000mbit  重置模拟状态 # 当我们想重置对lo的修改时，就一切恢复到正常的默认状态了：\nsh-4.2# sudo tc qdisc del dev lo root  本文小结 # 本文从个人开发角度、方便测试角度、还原网络“真实”情况角度出发，了解了下如何更好地利用lo网络模拟千兆网卡、网络传输延迟，实际测试下来比较符合预期，是一种本地开发过程中的有效手段。\n本文主要是针对开发测试期间来考虑，要了解线上环境的最终测试情况，就是要做上线前压测、容量评估等工作。\n两码事，都是应该做的，不过掌握了这个办法，本地1台开发机可以利用的有声有色。\n"}),a.add({id:82,href:"/tags/perftest/",title:"perftest",description:"",content:""}),a.add({id:83,href:"/tags/taskset/",title:"taskset",description:"",content:""}),a.add({id:84,href:"/blog/2023-04-13-%E5%8E%8B%E6%B5%8B%E4%B9%8Btaskset%E7%9A%84%E5%A6%99%E7%94%A8/",title:"压测之taskset的妙用",description:"执行压测，通常要尽量避免其他因素的干扰，有条件的话会搭建专门的压测集群。但是在开发阶段如果希望对现阶段实现进行快速压测，将相关服务部署到压测环境是没那么方便的，至少每次部署要花费的时间是会比较久的。但是在本地开发机压测，又会遇到资源竞争、相互影响的问题……taskset绑核可以解决这里的一部分问题。",content:"问题背景 # 想测试下gRPC框架的性能，设计了如下服务拓扑来对gRPC框架各组件、特性、参数配置下的性能进行探索。\n压力源程序 perfclient ---请求-\u0026gt; perfserver1 ---请求-\u0026gt; perfserver2  压力源程序perfclient会并发发送请求给服务perfserver1，perfserver1则会继续请求perfserver2，然后perfserver2回包给perfserver1，perfserver1收到响应后内部完成处理逻辑后继续回包给perfclient。\nperfclient每隔一段时间会打印下请求的请求量、成功量、失败量，以及qps、耗时信息。需要注意的事，这里再统计耗时信息的时候，除了avg、min、max耗时，还需要percentile(or quantile）百分位耗时，后者更具有说服力。\n现在呢？遇到点问题，正常我需要将上述压力源程序、被压测服务perfserver1、perfserver2尽力部署到不同的机器上，让它们之间避免相互影响，同时部署的机器上也应该注意没有其他负载会干扰到我们的测试，但是问题来了：\n 可能有机器，但是部署起来太麻烦了，可能每调整下测试点就要要操作多台机器 可能有机器，但是云平台存在超卖的情况，母机负载大影响到了虚拟机负载稳定性 可能有机器，但是ci/cd流水线执行耗时太久了 可能没机器，只有一台本地开发机  有没有什么其他简单好用的办法呢？我觉得有，资源隔离下啊。\n认识taskset # taskset，是linux下用来进行绑核设置的一个工具，我们可以借助它对上述不同的3个进程的cpu资源进行限定，如压力源程序perfclient需要能多生成些请求，我们给它分配7~10 4个cpu core，perfserver1负载会稍微比perfserver2高点，但如果是纯echo的话也多不了读少，给perfserver1分配2个cpu core，给perfserver2也分2个。\ntaskset -a -p 7,8,9,10 `pidof perfclient` taskset -a -p 3,4 `pidof perfserver1` taskset -a -p 5,6 `pidof perfserver2`  这样上述几个进程就被分别设置到了不同的cpu cores上执行，意味着当他们把cpu跑满时，他们能抗的负载大致就是这个比例。\n解释下选项-a：\n  taskset如果不指定选项-a，则知会对当前进程名对应的主进程进行绑核设置，不会对进程中的其他线程进行设置，当然也不会对后续新创建的线程进行设置。\n  加了-a，taskset就会对执行命令时，该进程pid下的所有线程进行统一的绑核设置，但是如果后续创建了新线程，新线程不会被绑核。\n  那么如果一个程序是多线程程序，且线程数不是固定的，会在以后新创建、销毁动态变化的，这种该怎么解决呢？\ngo天然多线程 # go程序天然是多线程程序，那应该如何进行绑核设置呢？如果只是为了限制进程使用的cpu资源，直接使用runtime.GOMAXPROC(x)进行设置不行吗？不行！\n该函数只是说限制同时在运行的线程数，并没有像taskset那样将线程绑到核上，这意味着这些go程序线程的执行有可能会在cpu core上迁移，这样的话通过top命令查看cpu core负载情况，就不好判断哪个core的负载是因为哪个进程引起的…对吧。\n另一个问题，go程序的GMP调度模型会在必要时自动创建新的线程出来，用来执行goroutines，这里问题就来了，我需要动态感知当前进程下的所有线程。go语言或者标准库都没有提供线程层面的东西来获取，那我们怎么获取呢？\ngo如何绑核 # Linux下面每个进程都有一个pid，对应的虚拟文件系统/proc//tasks下面就是该进程pid下的所有线程信息。理论上可以定时获取里面的pid，然后再去taskset -p绑核，或者说go启动一个协程定时调用下taskset -a -p \u0026lt;pid\u0026gt;，可以简洁明了搞定。\n这样就可以搞定绑核设置：\nfor { cmd := exec.Command(\u0026quot;taskset\u0026quot;, \u0026quot;-a\u0026quot;, \u0026quot;-p 1,2,3,4\u0026quot;, os.Getpid()) cmd.Run() time.Sleep(time.Second*5) }  测试结果 # 执行top命令后，可以press 1，然后可以看到具体每个cpu core上的负载。在压测的时候就简单多了，因为进程下线程被绑核到特定的几个cpu core了，所以可以看对应core的负载来归一化当前服务的负载信息。\n这里就不过多展开了，避免不必要的信息泄露。\n"}),a.add({id:85,href:"/tags/latency/",title:"latency",description:"",content:""}),a.add({id:86,href:"/tags/load/",title:"load",description:"",content:""}),a.add({id:87,href:"/tags/qps/",title:"qps",description:"",content:""}),a.add({id:88,href:"/blog/2023-04-12-%E4%BB%8E%E6%8E%92%E9%98%9F%E8%AE%BA%E5%88%B0%E8%BF%87%E8%BD%BD%E4%BF%9D%E6%8A%A4%E7%AE%97%E6%B3%95/",title:"从排队论到过载保护算法",description:"本文从排队论开始解释，详细介绍了Little's Law排队论模型以及如何将其迁移到在线服务领域，并就服务负载的评估、过载保护算法、适应大规模分布式系统的过载保护算法进行了思考和总结。",content:"排队论简介 # 排队论的精髓是通过数学模型和分析方法来研究排队系统的性能和行为。排队系统是指由一些服务设施和一些顾客组成的系统，顾客需要排队等待服务。排队论的目标是研究如何优化排队系统的性能，以提高服务质量和效率。\n排队论的核心是建立数学模型来描述排队系统的行为。这些模型通常基于随机过程和概率论，用于描述顾客到达的随机性、服务时间的随机性以及服务设施的数量和性能等因素。通过分析这些模型，可以得出排队系统的性能指标，如平均等待时间、平均逗留时间、系统利用率等等。\n排队论的应用非常广泛，涉及到许多领域，如交通运输、通信网络、制造业、医疗保健等等。在这些领域中，排队论可以用来优化资源利用、提高服务质量、降低成本等等。\n总之，排队论的精髓是通过数学模型和分析方法来研究排队系统的性能和行为，以优化系统的性能和效率。\n公式及应用 # 排队论是一个非常广泛的领域，其中涉及到许多不同的理论公式和应用。以下是一些常见的排队论理论公式和计算机系统中的应用：\n Little\u0026rsquo;s Law：L = λW，其中L表示系统中平均顾客数，λ表示到达率，W表示平均逗留时间。这个公式表明，系统中平均顾客数等于到达率乘以平均逗留时间。在计算机系统中，这个公式可以用来计算系统中的平均并发请求数，以及系统的响应时间和吞吐量。 Kendall\u0026rsquo;s Notation：A/B/C/K/N，其中A表示到达过程的类型，B表示服务时间的分布类型，C表示服务设施的数量，K表示服务设施的排队规则，N表示系统容量。这个符号表示了排队系统的基本特征，可以用来描述和比较不同的排队系统。 M/M/1队列：这是一个经典的排队模型，其中到达过程和服务时间都是指数分布，服务设施数量为1。这个模型可以用来计算系统的平均等待时间、平均逗留时间、系统利用率等指标。在计算机系统中，这个模型可以用来分析单个服务器的性能。 M/M/m队列：这是一个扩展的M/M/1队列模型，其中服务设施数量为m。这个模型可以用来计算系统的平均等待时间、平均逗留时间、系统利用率等指标。在计算机系统中，这个模型可以用来分析多个服务器的性能。 网络队列模型：这是一个用于分析计算机网络性能的排队模型，其中网络节点被建模为队列，数据包被建模为顾客。这个模型可以用来计算网络的吞吐量、延迟、丢包率等指标。 负载均衡算法：这是一种用于优化计算机系统性能的算法，通过将负载均衡地分配到多个服务器上，以提高系统的吞吐量和可靠性。排队论可以用来分析负载均衡算法的性能和效率。  这些理论公式和应用只是排队论中的一部分，排队论还涉及到许多其他的理论和应用，如排队网络、排队模拟、排队优化等等。\n浅谈Little\u0026rsquo;s Law # 简要说明 # Little\u0026rsquo;s Law是一个基本的排队论原理，它描述了在一个稳定的系统中，平均顾客数、平均等待时间和平均服务率之间的关系。该原理最初由美国数学家John Little在1961年提出，被广泛应用于各种排队系统的性能分析和优化。\nLittle\u0026rsquo;s Law的问题背景是排队系统，例如银行、超市、餐厅等等。在这些系统中，顾客到达、等待和离开的过程构成了一个排队模型。Little\u0026rsquo;s Law的目的是通过分析这个模型，来解决如何优化排队系统的问题。\nLittle\u0026rsquo;s Law的核心公式是：L = λW，其中L表示平均顾客数，λ表示平均到达率，W表示平均等待时间。这个公式告诉我们，如果我们知道了平均到达速率和平均等待时间，就可以计算出平均顾客数。反之亦然，如果我们知道了平均顾客数和平均等待时间，就可以计算出平均到达速率。这个公式可以帮助我们更好地理解排队系统的性能，并且指导我们如何优化排队系统。\n应用案例 # 以下是一些应用Little\u0026rsquo;s Law的案例：\n 在一个银行分行，平均每小时有100名顾客到达，平均等待时间为10分钟，那么该分行的平均顾客数是多少？根据Little\u0026rsquo;s Law，L = λW = 100 * 10 / 60 = 16.67，因此该分行的平均顾客数为16.67人。 一家餐厅想要提高服务质量，他们决定增加服务员的数量。根据Little\u0026rsquo;s Law，如果他们想要减少平均等待时间，他们需要增加服务员的数量，以提高服务率。如果他们想要减少平均顾客数，他们需要减少到达率，例如通过减少广告宣传或者提高价格等方式。  在线服务领域 # 理解little\u0026rsquo;s law # 将其应用到我们熟悉的在线服务领域的话，可以达到稳态的前提下，调整下相关参数：\n 队列平均长度可视为同时被服务的请求个数，即服务并发度Concurrency， 队列人数到达(速)率可视为服务吞吐Throughput， 平均服务时间可视为服务平均处理延迟Latency（可细分为等待延迟+处理延迟），  这样可以得到另一个版本的Little\u0026rsquo;s Law，Concurrency=Throughput * Latency。\n简单理解下这里的公式。假设请求都是单线程处理，每个请求只会占用一个cpu core，则服务并发度Concurrency就是cpu core的个数；每个请求的处理平均时间为Latency（单位为秒），则1秒内一个cpu core可以处理的请求数为 1/Latency；因此，1秒内可处理的总请求个数也就可以确定：Throughput = Concurrency * (1/ Latency)，进一步就可以得到公式：Concurrency = Throughput * Latency……所以，还是好理解的。\n利用这个公式，我们可以进一步去分析计算机系统处理请求时的吞吐量、处理时延、并发处理能力之间的关系。\n 有时候我们队计算机进行系统性能优化，也会对某任务的某一部分进行改善，如何评估改善后任务的整体性能极限呢？可以通过Amdahl\u0026rsquo;s Law来分析，详见 Wikipedia Amdahl\u0026rsquo;s Law，不展开了。\n 那我们如何具体来使用它来评估系统处理请求时的吞吐量、处理时延、并发处理能力之间的关系呢？有没有什么实际案例可供借鉴下。\n工程应关注什么 # 首先，工程上我们往往会通过调整服务配置，对服务进行不同测试，比如性能测试、负载测试、压力测试、稳定性测试等。\n  性能测试，以系统设计初期规划的性能指标为预期目标，对系统不断施加压力，验证系 统在资源可接受范围内，是否能达到性能预期。\n  负载测试，对系统不断地增加并发请求，以增加系统压力，直到系统的某项或多项性能 指标达到安全临界值。当并发请求数量超过安全临界值之后，系统吞吐量不升反降。\n  压力测试，超过安全负载的情况下，对系统继续施加压力，直到系统崩溃或不能再处理 任何请求，以此获得系统最大压力承受能力。\n  稳定性测试，被测试系统在特定硬件、软件、网络环境条件下，给系统加载一定业务压力， 运行一段较长时间，以此检测系统是否稳定。\n  通过这些测试，来确定不同负载下（cpu、内存、IO等）服务能够支持的吞吐量Throughput（QPS）、处理延迟Latency（p90、p95、p99耗时、平均处理耗时）。\n真实的测试场景下涉及到软硬件、网络、其他组件影响等等比较复杂的因素，用Little\u0026rsquo;s Law、Amdahl\u0026rsquo;s Law很难进行精准的分析，但是可以用来推断下理论值、极限值。\n尽管真实环境中，不能直接用它来直接预测服务的负载、吞吐量、平均耗时等指标值，但是仍然可以使用它来指导具体的过载保护算法的设计。\n负载的评估 # 这里思考下，负载与RPS、处理时长之间的关系。根据排队论模型：Little\u0026rsquo;s Law L = λW，类比到计算机系统，L表示系统中任意时刻需要处理的请求数，λ表示每秒到达的请求数量，W表示请求的平均处理时长。\n随着λ从0逐渐增大：\n 当λ较小时，平均处理时长不会随着每秒请求量的增长有明显增加； 随着λ继续增大，系统中资源竞争逐渐加剧，比如抢锁、内存分配、协程调度、GC等问题开始表现出来，平均处理时长会略有增加，系统中任意时刻的处理请求数也会增加；  这个很好理解，但是难以精确的建模，比如针对内存负载、cpu负载、调度开销、GC开销做一个复杂的公式，模型训练也存在过拟合的问题，我们设计的公式可能也会 可能设计出的公式对某种workload比较合适，但是换一种就不一定行，如果只考虑我们后台微服务场景，也可以设计一套这样的负载计算公式（类似trpc-overload-control） 或者我们把问题简化下，把服务本身当做一个黑盒，管你内部发生了什么呢，只从外部观测角度来衡量负载高还是低，那就是Little\u0026rsquo;s Law指导下的做法，比如：Netflix自适应限流过载保护、微信基于排队时延的过载保护   λ继续增大，导致L超过了系统规划的容量，这个时候，就处理不了了  请求可能会有请求队列放不下的问题，这个就会丢弃请求， 或者处理超时，排队时延+处理时延，排队明显更久了，竞争也会加剧处理时延    对于过载保护，更适合基于一些能反映系统负载、服务负载情况的指标来评估负载信息：\n 系统负载，  cpu利用率高往往会被认为是负载高，确实是；但举个极端case如计算型负载，只要请求量不超过cpu cores很多就不能认为是过载； ram利用率高往往会被认为是负载高，也确实是；但是ram利用率多高算高呢？实际观察系统可用内存+可用buff加起来确实不是很大，这个时候认为过载可能也不见得正确，而且GC的触发也依赖内存分配动作的触发（定时只是兜底）；   服务负载：  由于机器可能会混部多个服务，这里用服务负载来特指某个服务的负载，用来和系统负载区分下 服务负载准确说应该是服务资源的配额限制，如内存软限制，其负载信息也会通过GC导致的CPU开销反映到系统负载上 协程调度的间隔、GC Pause耗时可能受系统负载影响，但也受服务本身影响，这些指标通过观测系统负载不一定能观测到，但是通过服务自身的运行时监控能观测到   当做黑盒  观察系统的吞吐量变化、处理耗时变化（client端、server端），真实情况可能会受网络抖动影响，但是网络（拥塞等）也确实是需要考虑的    总的来说，为了更合理地评估服务的过载保护算法，我们不能单纯看系统负载，也不能单独看服务负载，也不能完全当做黑盒来看，需要综合来评估下。\n这里提的是负载的评估，还没有提及过载保护算法，过载保护可以在客户端做，也可以在服务器做，也可以两边都做各有侧重点。\n过载保护算法 # 传统做法 # 通常会将负载作为一个相对固定的值，比如CPU单核85%作为一个参考点，测试期间压力源发送的请求系统负载稳定在这个值，然后观察Throughtput、Latency的关系变化。注意此时85%的负载下，响应时间Latency不一定是最好的，但是吞吐量可能是更大的，要注意根据SLA（承诺的响应时间、QPS等）来为客户分配合理的资源。或者我们将其压测到过载，然后取此时QPS的一个75%左右作为一个相对合理的QPS值，并在客户端通过漏桶、令牌桶等算法来强制执行这个最大频率上限。\n但是对于大型分布式系统，这个配置值很快就会过期，QPS可能偏小导致后端服务不能充分利用资源，或者QPS过大导致后端服务过载。\n分布式限频 # 为了解决这个问题，我们也会引入分布式限频，后端节点定期上报负载、可承载请求给频控服务，客户端定期从频控服务获取最新的配额（一般客户端请求量大，会通过先消费后上报，与频控服务来完成同步）。\n但是这样需要额外引入一个频控服务，它设计实现的不好也容易成为系统瓶颈。\n自适应过载保护 # 我们应该考虑并发请求，而不是考虑RPS、CPU、内存、磁盘或网络等限制。Little\u0026rsquo;s Law 很好地涵盖了这种关系，其中 Limit = Average RPS * Average Latency。\nLittle\u0026rsquo;s Law，它其实可以指导我们简化过载保护算法的设计，我们可以不用围绕CPU、内存、磁盘或网络情况来设计华而不实、过度复杂、又不能充分覆盖不同负载场景的负载计算的算法，仅通过观察请求成功率、失败率、响应时间就可以预测出系统接下来大致能支持的一个负载。简单理解，latency增加还好，如果成功率下降了，适当调低rps，反之调高。\n不需要引入其他分布式频控服务，也不需要设计复杂的负载计算的算法，借鉴最具有说服力的服务成功率、失败率、响应时间就可以动态调整接下来的请求速率，实现起来简单，部署时伸缩性、不同负载适应性更好。\n 相关的尝试：\n1、netflix在自己的视频处理链路中引入了这种算法，我们在之前业务腾讯看点的内容处理链路中也有类似的实践，gRPC中也有类似tcp拥塞窗口控制的机制。netflix设计实现了一个基于Java的库 Netflix/concurrency-limits，2.9k stars，有开发者用go重写了一遍 platinummonkey/go-concurrency-limits, 91 stars。\n2、微信在过载保护算法dagor中，将请求排队时长作为重点参考指标，参考文献Overload Control for Scaling WeChat Microservices，中文翻译见 微信过载保护的实现原理。\n 这里的几种案例都是基于Little\u0026rsquo;s Law出发的实践，都是大型项目中的真实实践，对于大规模分布式系统、动态扩缩容、链路动态变化场景下的适应性效果比较好。\n本文总结 # 本文简单是在实践过程中，对排队论、little\u0026rsquo;s Law、服务负载评估、过载保护算法的一点思考和认识，将相关的理论、实践简单总结下。我认为Little\u0026rsquo;s Law模型，以及以及在此基础之上的netflix、微信的过载保护实践，恰恰是抓住了问题的重点，所以能以更简洁优雅的做法来妥善的解决这个由来已久又被广泛讨论的问题。\n"}),a.add({id:89,href:"/tags/fuzztest/",title:"fuzztest",description:"",content:""}),a.add({id:90,href:"/tags/go-test-fuzz/",title:"go test -fuzz",description:"",content:""}),a.add({id:91,href:"/tags/gofuzz/",title:"gofuzz",description:"",content:""}),a.add({id:92,href:"/tags/overflow/",title:"overflow",description:"",content:""}),a.add({id:93,href:"/blog/2023-03-03-%E6%A3%80%E6%B5%8B%E5%B9%B6%E8%A7%A3%E5%86%B3%E8%AE%A1%E7%AE%97%E6%BA%A2%E5%87%BA%E9%97%AE%E9%A2%98/",title:"检测并解决数值计算溢出问题",description:"数值计算溢出是一个很严重的问题，可能学习计算机组成原理时，或者做些活动类的与金币、钱、经验值等相关的项目时，会特别注意一下。在普通业务服务代码中比较少见到处理类似问题的实践，当然它不一定引发错误……近期项目中遇到了这类问题，也趁机总结一下。",content:"问题背景 # 数据类型是个好东西，类型定义了一种数据组成以及允许在其上进行的操作。 数据类型是个好东西，它定义了一种最基础的“安全”，类型安全。\n我们在进行数值运算时，有可能会“超出”类型本身的值域，但是受限于位宽限制，进而表现为“上溢出”。以a+b为例：\n 如果a、b都是有符号数，且其符号相同，有可能超过最大值、最小值而在值域空间中轮转； 两个正数相加，结果却是负数；两个负数相加，结果却是正数. 如果a、b都是无符号数，也有可能超过最大值而在值域空间中轮转。  这个很容易理解，今天我们想看下如何解决此类问题。\n如何解决溢出问题 # 升级32位到64位？ # 这通常是第一反应，它可能是有效的，也可能无效。\n 有效：如果输入int32 a、b是有明确约束保证的，比如任意一个都必须在[-1*1\u0026laquo;31,(1\u0026laquo;31)-1]， a+b可能对int32可能会溢出，但是如果提升成int64则可以解决问题，前提有这样的约束保证； 无效：没有任何输入约束做保证，只是简单提升成int64 a、b是没有用的，极端情况，a=b=1\u0026laquo;36-1， a+b很明显就溢出了，这种就需要其他方法做保证。  设计上应该有上限？ # 在设计上就要有这方面的“数据”上的“安全”的意识，比如：\n 玩家每赛季的经验应该是有上限的，满经验后就提示玩家满经验，后续就不给加了； 比如用uint32表示经验值，那么加之前先测一下是否发生了溢出(v=orig+delta, 如果v小于任意一个则溢出) 这很好理解，正常情况下，v应该大于orig、delta，就是逻辑反嘛。 ps：不好理解？把值域想象成一个转盘，delta不可能让v在值域范围内“环绕 (wraparound)”/“转到”orig，反之orig也不能让v转到delta。 如果发生了溢出，则直接将v=maxUint32完事，多出来的就扔掉，提示玩家满经验。 或者，这里的满经验不一定要maxUint32，可以是认为设计好的一个小值，比如99999； 如果输入有约束，比较小比如int8 a, int8 b，那么至少可以保证 if a+b \u0026gt; 99999 then v=999999 是ok的， 也不会触及累积量v达到uint32最大值的情况。可能这种情况比较理想化了。  检查是否发生溢出？ # 言归正传，还是要有办法来比较可靠地检查运算结果a+b是否发生了溢出？\n 可以用大数计算来避免溢出，比如golang里面的math/big包。 比如int32 a,b相加，按int c=a+b的方式，c有可能是个溢出后的错误结果。 但是如果用大数计算，位宽充足可以算出正确结果，只要将其和maxInt32比较下即可知道是否发生了溢出。 如果确实发生了溢出，应该如何处理，如fallback到满经验值不再加经验。 也可以不用大数计算，通过一些有趣的副作用也可以知道是否发生了溢出。 比如在x86汇编中，可以通过 test OF,OF 来判断是否发生了溢出。 高级语言中，就没那么直接，比如go，得借助一些其他办法来判断，这就是这个math_test.go要测试的东西。  代码测试：运算时检测溢出 # 测试代码，请移步：https://github.com/hitzhangjie/codemaster/blob/master/math/math_test.go。\nmath_test.go中定义了两个函数safeSignedAdd、safeUnsignedAdd来对有符号数、无符号数加法进行安全的计算：\n 如果发生了溢出则返回错误，方便调用方处理； 如果没发生错误则返回两数之和；  我们想检测下如何更好地发现一些造成溢出的边界条件，我们使用go fuzztest来帮助发现潜在的问题。 我们设置了边界附近的值作为seed scorpus，这样方便go fuzztest引擎使用mutator微调输入参数时能够覆盖到边界条件。\n其实也可以使用go fuzztest的随机构造输入的模式，但是这样往往需要执行更多的时间才有助于发现问题。 ps：改天再写篇文章详细介绍下go fuzztest内部是如何工作的。\n这里看起来我们是为了使用go fuzztest而使用fuzztest，比如你怎么精心构造这样的seed scorpus的？其实不是为了用而用。\n 当我们设计实现一个函数时，脑海中应该知道输入是啥、输出是啥，过程中的极端case是啥，那你就有了一个输入的值域范围， 或者说不同的参数组合有几种特殊的情况，可以多次调用 f.Seed(v1,v2,\u0026hellip;)，来将这些参数作为一个seed scorpus， 以方便后续模糊测试引擎微调这些参数来覆盖特殊分支。 你不一定要精心构造出一定能触发异常边界的seed scorpus，你可以设置个大概的值，然后交给模糊测试引擎去做剩下的工作， 假定一个参数是uint32类型，你设置的seed参数设置的是n，那么这个n最终会在[n-100,n+100]的范围内变化，当然下界、 上界要在uint32范围内，每个参数都会这样变化。所以你的seed scorpus不一定刚好触发边界。 模糊测试运行过程中，如果它发现某个输入发生了错误（t.Errorf标记的），或者此输入导致代码覆盖率提升了（给每条语句插桩）， 那么就会将当前输入作为一个新的seed scorpus存起来，在其基础上微调参数执行。 最终我们尽可能地覆盖了更多的代码，并尽力去发现可能存在的边界异常。但是确实不能保证一定能找到问题。  随机模式的话，输入参数随机意味着逼近边界异常处需要更多的测试用例，可能耗时很长才能发现，但是也不一定能发现。\n测试覆盖：模糊测试!=漫无目的的测试 # 在执行uint32上溢出模糊测试时，我专门设计了一个seed scorpus，如下所示：\nf.Add(uint32(0xffffffff-1000), uint32(0))  此输入下，mutator无能为力，执行了几分钟也发现不了问题，如果知道mutator原理的就很容易明白为什么。\n$ go test -v -count=1 -fuzz=Fuzz_overflow_uint32 -run=^$ === FUZZ Fuzz_overflow_uint32 fuzz: elapsed: 0s, gathering baseline coverage: 0/1 completed fuzz: elapsed: 0s, gathering baseline coverage: 1/1 completed, now fuzzing with 16 workers fuzz: elapsed: 3s, execs: 767120 (255688/sec), new interesting: 1 (total: 2) fuzz: elapsed: 6s, execs: 1551732 (261545/sec), new interesting: 1 (total: 2) fuzz: elapsed: 9s, execs: 2352907 (267067/sec), new interesting: 1 (total: 2) fuzz: elapsed: 12s, execs: 3148542 (265216/sec), new interesting: 1 (total: 2) fuzz: elapsed: 15s, execs: 3945075 (265509/sec), new interesting: 1 (total: 2) fuzz: elapsed: 18s, execs: 4751252 (268643/sec), new interesting: 1 (total: 2) fuzz: elapsed: 21s, execs: 5550572 (266165/sec), new interesting: 1 (total: 2) fuzz: elapsed: 24s, execs: 6352445 (267419/sec), new interesting: 1 (total: 2) ...................................................................... fuzz: elapsed: 2m33s, execs: 40082850 (257913/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m36s, execs: 40876146 (264475/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m39s, execs: 41660462 (261389/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m42s, execs: 42442111 (260618/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m45s, execs: 43234687 (264132/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m48s, execs: 43994959 (253473/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m51s, execs: 44772385 (258989/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m54s, execs: 45562731 (263543/sec), new interesting: 1 (total: 2) fuzz: elapsed: 2m57s, execs: 46340129 (259039/sec), new interesting: 1 (total: 2) ^C  然后，进一步可以纠正下错误的测试思想，模糊测试!=漫无目的的测试，seed scorpus matters!\n当我们设计上有章法，测试时关注边界，自然知道seed scorpus该如何设置，比如我们改成：\nf.Add(uint32(0xffffffff), uint32(0))  继续执行测试，很快就发现了边界case，代码中我们加了模糊测试的次数，发现第9轮它便发现了问题。\ngo test -v -count=1 -fuzz=Fuzz_overflow_uint32 -run=^$ === FUZZ Fuzz_overflow_uint32 fuzz: elapsed: 0s, gathering baseline coverage: 0/1 completed fuzz: elapsed: 0s, gathering baseline coverage: 1/1 completed, now fuzzing with 16 workers fuzz: elapsed: 0s, execs: 9 (383/sec), new interesting: 0 (total: 1) --- FAIL: Fuzz_overflow_uint32 (0.02s) --- FAIL: Fuzz_overflow_uint32 (0.00s) math_test.go:31: iter-9 4294967198 + 118 = 20, err: overflow Failing input written to testdata/fuzz/Fuzz_overflow_uint32/a6532fa5f002651bb1003d5aedbea9bb5716a6d2a8fe7afff0b5252599a6d59b To re-run: go test -run=Fuzz_overflow_uint32/a6532fa5f002651bb1003d5aedbea9bb5716a6d2a8fe7afff0b5252599a6d59b FAIL exit status 1 FAIL github.com/hitzhangjie/codemaster/math 0.026s  小结 # 总结了下如何解决数值计算时的溢出问题，从编码上、从策略上，以及介绍了如何使用go fuzztest来更好地发现潜在的问题。 关于模糊测试的一点想法，模糊测试 != 漫无目的的测试，seed scorpus的选择和设置很有价值。后面有时间会写下go模糊测试的工作原理。\nps：对于溢出问题、环绕问题，go的类型系统都存在。在编译时，如果发生溢出，编译器会直接抛出错误，比如“constant ??? overflows uint32”；如果是运行时溢出，则会出现环绕（wraparound），此时就需要显示检查并避免环绕了。\n"}),a.add({id:94,href:"/tags/lang/",title:"-lang",description:"",content:""}),a.add({id:95,href:"/tags/gcflags/",title:"gcflags",description:"",content:""}),a.add({id:96,href:"/tags/go/",title:"go",description:"",content:""}),a.add({id:97,href:"/blog/2022-11-24-how-go.mod-works/",title:"how go.mod works?",description:"go.mod里面的版本号是如何影响go编译器检查的？之前整理过，今天项目中有遇到个类似的问题，就顺便再整理记录下。",content:"go.mod/go.sum内容 # go.mod里面包含的信息包括：\n 当前module构建要求的最小go版本 依赖的module及校验和信息 为了方便本地开发测试的一些replace信息  这里不讨论vendor相关的modules.txt中的内容。\n最小go版本号 # 我们举个例子来描述下。\n  如果当前module的go.mod是go 1.16，等价于编译的时候go build -gcflags \u0026lsquo;-lang=1.16\u0026rsquo; / go tool compile -lang=1.16。\n  假设我们现在安装的go版本是go1.19。\n  这种情况下执行编译测试：\n  如果我们用了范型（go1.18开始支持），go编译器编译时会检查， 本来go1.19肯定能编译1.18的范型代码，但是它会报错出来，因为go.mod里声明的go版本，是当前项目支持的最小go版本，有可能别人不是1.19而是1.15,1.17，所以要报错提示下\n我们还没有用那些1.16.5以后的新特性非得要新版本的go来编，所以之前能正常编。\n  如果我们安装的go1.15，go.mod里面的1.16高了，也会先尝试编译，编过了就编过了，编不过就报错最小版本是1.16.5 比如机器上现在是1.19，可以go.mod改成1.20正常编过\n  如果因为-lang编译导致的编不过，如果go.mod里面的版本比当前安装的版本高，还会打印出来 module requires go 1.21，提示安装新版本\n  依赖信息 # 依赖的module，除了指明importPath，还要指明version，才能完整指明一个依赖。这个应该没什么疑问，所以大家都会提交go.mod文件。\n再说下校验和，有什么用呢？防止包内容被篡改。有些同学因为什么原因导致校验和经常冲突，需要解决冲突，所以直接不提交go.sum文件了，这是十分错误的。\n有同学可能会觉得这些繁琐的步骤很荒唐，其实并不是，可重复的制品构建，是一门非常重要的工程上的保证手段，为了达到此目的，甚至还有封闭构建、构建容器等其他方法来提供进一步的保证。\n本文小结 # 本文简单记录了下go.mod/go.sum相关的知识点，可能对刚接触这块的同学比较有价值 :)\n"}),a.add({id:98,href:"/tags/module/",title:"module",description:"",content:""}),a.add({id:99,href:"/tags/consmark/",title:"consMark",description:"",content:""}),a.add({id:100,href:"/tags/garbagecollector/",title:"GarbageCollector",description:"",content:""}),a.add({id:101,href:"/tags/gc/",title:"GC",description:"",content:""}),a.add({id:102,href:"/blog/2022-11-20-go%E5%A6%82%E4%BD%95%E8%A7%A6%E5%8F%91%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/",title:"go如何触发垃圾回收的",description:"go触发GC有这么几个时机，内存分配时触发mallogc，定时触发sysmon，手动触发runtime.GC、debug.FreeOSMemory，其中内存分配时触发是go是重中之重，go runtime以此来平衡好内存分配、内存回收的节奏以让内存占用维持在一个合适的水准。本文对内存分配过程中触发GC的一些设计考量进行了总结梳理。",content:"前言 # go触发GC有这么几个时机，内存分配时触发mallogc，定时触发sysmon，手动触发runtime.GC、debug.FreeOSMemory，其中内存分配时触发是go是重中之重，go runtime以此来平衡好内存分配、内存回收的节奏以让内存占用维持在一个合适的水准。本文对内存分配过程中触发GC的一些设计考量进行了总结梳理。\n应该听过“mark assist” # gc过程中mutator分配内存时可能会被搞去做assistg,去辅助扫描标记一些对象是否该回收的工作,当我的辅助标记内存数量减去要申请的内存数,如果为负数时,相当于我申请的比辅助标记的多,相当于欠债了,这个时候我就得去做些辅助标记的工作 gcAssistBytes:\n 然后根据当前内存使用情况\\扫描情况\\下次GC的heapgoal,计算出我应该辅助标记多少,才能保证达到堆大小时GC标记工作恰好能完成,让我去干活 这个时候干活之前会先检查下bgMarkWorker因为扫描工作贡献的信用分,然后我可以借用这个信用分来偿还债务,以减少扫描工作,或者完全避免扫描工作 如果依旧欠债,那就干活呗,后面会执行到gcDrainN,去执行一些标记类的工作  这些标记类的工作从何而来呢,比如写屏障记录下来的一些需要去扫描的对象 执行完了这个扫描之后,这个assistG.gcAssistBytes就会加上扫描的字节数,相当于攒的一点信用分   干完这些之后,才允许你申请内存\\分配对象,哈哈哈!  goroutine可以去做些mark assist之类的工作的前提是，GC已经进入了GCMark阶段，那内存分配期间GC是什么如何被触发的呢？\nGC什么情况下被触发的 # 关于什么时候触发GC，严谨一点，内存分配期间何时触发的GC，这里不考虑sysmon触发、手动runtime.GC()触发，ok。\nGOGC\\GOMEMLIMIT\\heapGoal # 我们应该都这样的认识阶段，通过GOGC、GOMEMLIMIT可以计算出下次GC时的heapGoal，等堆内存占用达到这个heapGoal时会触发GC。\n但是严格来讲，理解成接下来内存占用达到heapGoal才触发GC，是不正确的。\n引入GC Trigger #  为了触发GC，还有一个概念，叫GC trigger，它的值heapGoal要小些，在GCOff阶段，内存分配过程中会检查当前heapLive大小是否超过了这个trigger，是则启动gc（gcStart） 那个协程来负责检查是否启动gc，可以理解成所有的协程，协程如果是申请大内存（\u0026gt;32K）则一定会做上述检查，小内存为了效率则不一定每次检查，当如果申请小内存（tiny or small）如果过程中span不足发生了refill也会做上述检查（shouldhelpgc） 当启动了GC之后，接下来goroutines如果涉及到内存分配，就会转入markAssist阶段，要分配多少，先要干一定量的标记扫描的活才行（内存debt/assist设计） 那么heapGoal干嘛用的呢，前面提到的内存debt/assist设计，就是为了在当前堆大小达到heapGoal时尽量完成内存的标记扫描，将markbits改成allocbits，未使用的就可以复用或者等下个GC cycle阶段回收  所以从GC trigger到heapGoal，这中间是有一些考量的，如果只认为GC heapGoal控制GC的触发，其实是认识不到位的。ps：可能在这这个提案 GC pacer redesign 实现之前确实是根据heapGoal来触发的，但是这会导致内存的不受限制的增长。\nGC Trigger计算 # 那么这个GC trigger是如何计算的呢？\n 首先它不能比heapGoal小很多，那可能会导致GC启动过早，写屏障打开后程序latency会上升，而且如果内存分配比较快GC一直触发运行，期间分配的对象会一直标记为black，Rss会上升 也不能过晚触发，可能导致标记扫描阶段assistG的工作量过大，latency会比较明显，而且会堆大小增长会超出预期。  至于如何计算的，可以先看下上面这个提案中关于GC trigger的设计，然后翻下源码瞧瞧……额，还是简单总结下吧：\n 明确下目标，GC trigger是用来确定何时触发GC的一个值，当内存分配导致堆大小变化时会检查当前heapLive\u0026gt;trigger来决定是否触发GC（申请大内存必检查，申请小内存为了效率一般不检查，但在span不足refill后检查） GC trigger如何计算出来的：  首先根据GOGC、GOMEMLIMIT算出下次GC的heapGoal， 然后根据minTrigger=heapMarked+(heapGoal-heapMarked)*0.7， 然后maxTrigger=heapMarked+(heapGoal-heapMarked)*.0.95，如果堆比较小就用这里算出的值意味着总有一个buffer来赶在内存占用达到heapGoal之前启动GC。如果堆比较大但是有没有多少扫描工作，就用heapGoal-defaultHeapMinimum(4MB)来作为maxTrigger，这也是一种优化。 ps: 这里的heapMarked表示上轮GC标记结束时堆大小。这两个值，相当于确定了一个候选的触发GC的heapLive范围，最终trigger值一定要大于等于minTrigger，一定要小于等于maxTrigger。   确定trigger：  确定runway，根据上轮GC过程记录的consMark（程序分配内存、扫描内存量的比值）、实际的扫描内存的量（heap+stack+global）以及并发标记执行阶段mutator:collector的CPU执行时间的比值3:1，可以大致算出下一轮GC期间内存使用量能涨到多少，这个源码中选了个词叫runway，意思是我们内存使用量能走多远。 很明显如果这个值如果大于heapGoal说明我们很可能会让堆占用走高，此时需要更激进地触发GC，所以此时的trigger就选下界minTrigger。 如果这个值比比heapGoal小，那就用goal-runway作为trigger，但是这个值表示的时啥？如果这个值比minTrigger小就用minTrigger。 前面还算了个最大trigger，如果这里的trigger值比maxTrigger还大，那trigger要改成maxTrigger。    Put it together # OK，现在知道了trigger值是怎么详细计算的了，好，我们继续串一下：\n 如果当前没有触发GC，当前goroutine正在执行内存分配  根据当前内存分配的量来确定是否shouldhelpgc（\u0026gt;32K一定为true，反之则要根据是否有span不足refill）  如果否就分配完内存该干嘛干嘛去就完了 如果需要辅助gc，首先先计算下当前trigger（上面详细描述了如何计算的），然后比较下当前heapLive、trigger的大小  如果heapLive \u0026lt; trigger，不用触发GC，该干嘛干嘛 如果heapLive \u0026gt; trigger，发起GC，即调用gcStart()，这里其实是发起一轮完整的GC，等它完成后再返回来该干嘛干嘛       当有其他goroutine发起了GC，进入GCMark阶段后gcBlackenEnabled=1表示其他mutator要把新分配对象标记为黑，可以理解成当前进入GC阶段了  每一个goroutine都要维护一个账本，自己分配了多少内存，自己辅助标记了多少内存 如果自己分配的内存没有超过辅助标记的内存，gcAssistBytes\u0026gt;0，没欠债该干嘛干嘛去 如果自己分配的内存超过自己辅助标记的内存，表示自己欠债了，欠债了怎么办？就得还债，还债就得去辅助标记内存，这就是我们说的markAssist  如果我要分配npages的内存，那么要辅助扫描多少内存呢，这个运行时有个计算规则，总的目标是在GC发起后、内存占用达到heapGoal之前我能把所有的内存扫描完 确定了要扫描多少内存后，就可以去干活了？等等，当前goroutine欠的债，也可以先找大佬帮还一下，这就是bgMarkWorker攒的credit（bytes），如果一次还不完，欠多少就是多少，自己去扫描就完了 ps: 这样有个好处，当前goroutine可以不用引入扫描内存的开销就可以继续干自己该干的事情。   这个阶段会更新当前goroutine的这个账本，如果当前GC Cycle内它还有动作，就可以继续拿来秋后算账    当一轮GC Cycle结束时，go runtime会将当前的gcMarkBits作为gcAllocBits，意思就是这些没有被标记的内存都可以在后续分配内存对象时复用了，实在没用的就可以还给操作系统了。\n本文小结 # 实际上内存分配器和垃圾回收器，这两个之间并不是割裂的关系，而是互相协作的两个组件，这里就只是介绍了内存分配过程中的主要逻辑，忽略了垃圾回收中的部分，也忽略了内存多层级组织的内容（mheap-\u0026gt;arena-\u0026gt;pages, mheap-\u0026gt;mcentral-\u0026gt;mspan-\u0026gt;p.mcache）。\n这篇文章总结的就是mallogc期间go runtime的一些考量，有时间在总结分享下go垃圾回收的部分。\n"}),a.add({id:103,href:"/tags/heapgoal/",title:"heapGoal",description:"",content:""}),a.add({id:104,href:"/tags/markassist/",title:"markAssist",description:"",content:""}),a.add({id:105,href:"/tags/runway/",title:"runway",description:"",content:""}),a.add({id:106,href:"/tags/trigger/",title:"trigger",description:"",content:""}),a.add({id:107,href:"/tags/dictionary/",title:"dictionary",description:"",content:""}),a.add({id:108,href:"/tags/gcshape/",title:"gcshape",description:"",content:""}),a.add({id:109,href:"/tags/generics/",title:"generics",description:"",content:""}),a.add({id:110,href:"/blog/2022-11-10-go1.18%E6%B3%9B%E5%9E%8B%E6%94%AF%E6%8C%81/",title:"go1.18泛型支持",description:"go1.18支持了泛型编程，很久之前就研究过它的设计实现原理，但是对于其如何编写泛型代码及注意事项，并没有仔细去看过。借着项目升级go1.19的机会，公共库中有些代码可以通过泛型来优化下，这里就学习过程中认为比较重要的泛型知识点做个梳理、总结。",content:"go1.18 泛型支持 # 关于泛型编程 # 首先什么是泛型呢？ # Generic programming is a style of computer programming in which algorithms are written in terms of types to-be-specified-later that are then instantiated when needed for specific types provided as parameters.\n泛型编程有啥好处呢？ #  cleaner code and simpler API (not always) improve code exectution performance (not always)  没有泛型的日子 # 如何应付的 # go1.18之前苦于没有范型编程，开发人员一般会这么做：\n go编译器对内置类型有一定的范型支持，比如new、make、len、cap go支持reflection和interace，通过这两个一定程度上可以模拟范型的能力 go支持//go:generate，通过自定义工具可以生成一些“重复”代码  痛点依然在 # 即便是通过反射、interface来模拟也把风险从编译时类型安全推到了运行时检查部分，生成代码也会有大量重复性代码……所以痛点依然存在。\ngo1.18中终于解决了这个问题，虽然现在来看还没那么尽善尽美，但是总算在路上了。\ngo泛型知识点 # go1.19当前范型设计实现，也还没完全实现提案type parameters proposal，这个提案也并非未来go泛型实现的天花板，会一步步完善。尽管还不尽善尽美，但是将来go泛型编程应该有较大的应用场景。现在有些库已经在用泛型重写了。\n自定义泛型： # 1.18支持了自定义范型（customized generics），这个提法是为了与内置的泛型支持区分开。所说的内置泛型，指的是类似new、make、len、cap这样的一些函数，或者map[k]v这样的数据结构类型，这些有泛型的思想和支持。\n但是我们所说的泛型主要是指自定义的泛型类型、函数、方法。\n基础知识： #  泛型类型 type Lockable[T any] 泛型方法 func(l *Lockable[T]) Do(f func(*T)) {…} 泛型函数 func Equal[T comprable](a, b T) bool { return a == b} 如果类型参数列表中有多个，如[a any, b, c, _ comparable]，它们的顺序没有影响的  接口表示： #  tilde form：~T，波浪号+类型，表示类型集合，表示所有underlying type为T的类型 term form：T1 | T2 | …. | Tn，类型的联合  接口嵌套： #   1.18之前接口内可以嵌入任意数量函数、任意类型名（只要类型名为接口名即可）\n  1.18中放松了嵌入类型名的限制，可以是\n 任意类型的字面量，只要不是类型参数名即可，比如string、其他接口名 无名接口定义 tilde形式 term形式  而类型参数的constraint其实就是interaface，这里的增强大大增强了constraint描述的范畴，如所有的int、uint、float，或者string\n  下面是些合法的接口定义\ntype L interface { Run() error Stop() } type M interface { L Step() error } type N interface { M interface{ Resume() } ~map[int]bool ~[]byte | string } type O interface { Pause() N string int64 | ~chan int | any }  在一个接口A中嵌入另一个接口B，相当于把B递归的展开把方法全部作为A的方法，比如接口0相当于这样，其中的不是方法名的部分，~map[int]bool…int64|~chan int|any，可以看做不同的term union form。\n注意interface { int; uint } 表示底层类型同时是int和uint的，而interface{int | uint}表示底层类型或者是int或或uint的，是两种完全不同的概念。\ntype O interface { Run() error Stop() Step() error Pause() Resume() ~map[int]bool ~[]byte | string string int64 | ~chan int | any }    如果constraint中只包含一个元素，而且它是type element，那么可以省略外层的interface{}，比如[T interface{~int}]可以简化为[T ~int]\n  但是上述简化，有时也会遇到解析问题，比如[T *int]，这里表示的是啥意思呢？是underlying type为 int的范型类型？还是把int当做一个常量解释为一个Tint这么大的数组？现在确实是当做数组的。编译器当然可以解决这个问题，但是得做些额外的处理，后面可能会优化吧。\nweired，那现在如何化解这个问题？\n 可以用完整形式，用interface裹起来 在最后加一个逗号结尾[T *int,]，类型参数列表最后允许加逗号的，换行的话也要用逗号连接  我擦，就不要用这种破坏可读性的方式来写，直接用interface{}包起来！\n在看个奇葩的[A int, B *A]，我擦这里的A到底是啥？I don’t know！\n 尽管类型参数的constraint是一个接口，但是不代表类型参数就可以像普通接口变量那样可以有动态值、可以断言，我们把它理解成一个类型、把constraint理解成一种限制就可以了，不要总想着它是一个接口值的变量（实际上也不是）。    类型参数作用域： #  参考这里：http://localhost:55556/generics/555-type-constraints-and-parameters.html#:~:text=Go specification says,of the type. 举个例子：type G[S ~[]E, E int] struct{}，这里的E后面有作为了S的声明，对于函数、方法也是类似的。就是说一个类型参数（比如E）的作用域从这个类型、函数、方法定义开始就有效，直到定义结束。所以这里的E是有效的，对于S它自然要找E在哪定义的，怎么找，在当前scope里面找，因为specification这么定义的，它当然在这个scope里找定义了。跟从左往右、从右往左这种表面上的顺序无关。  类型参数实例化、类型推导： #  其实包括泛型类型中的类型参数实例化，和泛型函数、泛型方法中的类型参数实例化  实例化时参数列表省略问题： #  泛型类型中：省略类型参数列表不能省略，要写完整的 泛型函数、泛型方法：当可以推断时，可以部分省略或完全省略  实例化时传递的实参问题： #  基本接口类型any、error可以作为类型参数的实例化参数。 如果一个类型参数A的constraint满足另一个类型参数B的constraint，那么可以传递A的实例化作为B对应的类型参数的实例化参数  类型参数上的操作 #   看这里吧：http://localhost:55556/generics/777-operations-on-values-of-type-parameter-types.html，实在是费解，这么多特殊规则，谁能记得住怎么写\n  有些操作是有效的，有些则是无效的。通俗地说，某个操作是否有效，要看其对类型参数对constraint所表示的type set中每个类型是否都有效，都有效才算是有效的。\n  go自定义泛型不是通过c++模版那样重复生成代码实现的，这也是和代码生成的不同之处。有一条principle rule就是：在go里面，每个有类型的表达式计算都必须有一个指定的类型，这里的类型可以是普通类型，也可以是类型参数。这条原则很关键，比方说typeset包含多个候选类型参数值，函数体里对值的操作表达式对应的类型需要有一个核心类型来表示。比如下面这个：\n// 如果T是chan int，那么从c读到的是int，如果T是chan bool，那么从c读初的是bool， // 一个是int，一个是bool，不能统一到同一个类型，这就叫core type missing， // 此时定义一个类型参数作个衔接就可以了。 func read[T chan int|chan bool](c T) { _ = \u0026lt;-c } // 改成这样就可以了 func read[T chan E, E int|bool](c T) { _ = \u0026lt;-c }  这里的限制多写写可能会更好理解，多看多学吧，理解go泛型还真有点费解，哈哈哈 🙂\n  go泛型技术细节 # go1.18中的generics（范型）实现思路：\n stenciling（蜡印）这种方式会为范型函数的每种用到的类型参数实例化一个函数，这种好处是会减少函数调用开销，缺点是会导致binary尺寸过大，也可能会导致一些当前无法预见的问题。 dictionary（字典）这种方式不会像stenciling那样为每个类型参数实例化一个，而是就生成一个函数实例，但是多给它传入一个dictionary指针参数，这个指针参数里包含了实际用到的类型参数（parameterized type）对应的具体类型参数（concrete type），有了这个信息就能知道实参的size、alignment等信息，这样在安排内存、栈帧、函数参数、返回值的时候就知道该如何组织了，后续的就没什么复杂的了。这种方式的一个问题，是需要考虑如何优化调用的性能开销。 gcshape，它描述的是在内存allocator、garbage collector视角看起来描述信息长得类似的type，这种type相同的可以实例化一个，这样的话可能有多次实例化，就暗含了stenciling的思想，虽然还是多了传字典，但是省了因为底层type不一样时所要做的额外工作。  本文小结 # 本文简单总结了go泛型编程的一些知识点、注意事项，以及简要介绍了go泛型的设计实现原理。内容没有展开太多，感兴趣的可以参考文章末了列出的参考文献。\n参考内容 #   泛型编程：https://en.wikipedia.org/wiki/Generic_programming\n  初识go泛型：http://localhost:55556/generics/444-first-look-of-custom-generics.html\n  类型参数限制：http://localhost:55556/generics/555-type-constraints-and-parameters.html\n  类型参数实例化：http://localhost:55556/generics/666-generic-instantiations-and-type-argument-inferences.html\n  对类型参数值的操作：http://localhost:55556/generics/777-operations-on-values-of-type-parameter-types.html\n  go泛型目前的状态：http://localhost:55556/generics/888-the-status-quo-of-go-custom-generics.html\n  go1.18 generics设计实现:https://github.com/golang/proposal/blob/master/design/generics-implementation-dictionaries-go1.18.md\n  "}),a.add({id:111,href:"/tags/stenciling/",title:"stenciling",description:"",content:""}),a.add({id:112,href:"/tags/ballast/",title:"ballast",description:"",content:""}),a.add({id:113,href:"/tags/gc-tuner/",title:"GC tuner",description:"",content:""}),a.add({id:114,href:"/tags/gogc/",title:"GOGC",description:"",content:""}),a.add({id:115,href:"/tags/gomemlimit/",title:"GOMEMLIMIT",description:"",content:""}),a.add({id:116,href:"/blog/2022-11-10-go%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E8%B0%83%E4%BC%98/",title:"go垃圾回收调优",description:"go1.19支持了内存软限制，这个内存调优带来了一种新的解决方案。在项目实践中，我们也从压舱石方案切换成了GOMEMLIMIT的方案，过程中遇到的问题、思考，也梳理分享下吧。",content:"相关背景 # 在go1.19之前，go程序内存调优的方式主要是通过环境变量GOGC（或者debug.SetGCPercent(?)）来控制，\n它的效果是影响go runtime计算nextGC heapGoal的大小：\n 较早的版本计算方式为：heapGoal = heapMarked + (heapMarked) * GOGC / 100， 后续go迭代时发现非堆内存也是有影响的，于是go1.18完善了下 heapGoal = heapMarked + (heapMarked + GCROOTs) * GOGC/100，这里的GCROOTS=(gstacks+globals)  GC pacer的目的就是为了根据上述公式计算下次GC的heapGoal，然后在必要时（比如malloc时）决定是否要GC。\n默认初始heapGoal大小为4MB，如果靠GOGC来控制的话，会比较频繁触发GC，对绝大多数server程序而言频繁GC占比较多CPU，程序整体吞吐、响应延迟会受一定影响。\n所以业界一般会通过两种方式来调优：\n ballast，利用一块不用的大内存（比如1GB），来推高下次GC的heapGoal，通过这种方式来降低GC频率 GC tuner，动态设置GOGC，定义一个对象为其设置finalizer，每轮GC结束时触发它并检查当前进程当前的内存占用情况，并与允许的最大内存占用进行比较，并计算出达到最大内存占用才触发GC时GOGC应该设定的值（其思路和go1.19 GOMEMLIMIT类似）  项目以前的方案 # 项目以前使用的是go1.16.5，这个版本中也只有GOGC一个控制GC的选项，使用的是ballast的方案：\n 在服务初始化阶段去初始化一个大内存而推高下次GC时的heapGoal 不同程序可能对内存需求不同，配置文件中允许自定义ballast大小，默认为1GB  包括业界在内都是介绍了ballast如何使用：\n 全局变量声明，垃圾回收器会认为其在整个进程生命周期内reachable 局部变量声明，通过runtime.KeepAlive(\u0026hellip;)来欺骗垃圾回收器这之前对象reachable  但是，好像只看到了一派祥和，我们使用时却遇到了Rss占用问题。\n问题1：ballast占物理内存 # 在测试环境（很多套测试环境）都有比较大概率发现服务在几乎空闲时，物理内存占用竟然高达1.1g…这很不符合常理。\n  通过pprof跟踪内存分配，发现内存分配比较大的路径就是这个压舱石（pprof mem采样是看的虚拟内存）。\n  然后top、pmap等跟踪可疑进程发现其确实存在1GB左右的anon区域，且该区域为dirty**（其实gdb把内存dump一看全是0，就很容易联想到类似对象分配后memset的操作）**。\n  根据了解的go GC、内存分配器相关的知识，了解到go向操作系统申请内存时通过mmap的方式，释放内存是通过madvise+MADV_DONTNEED/MADV_FREE的方式。\n  go1.12的时候改成了FREE默认代替DONTNEED，这两个选项是有区别的，详细的可以看下man手册（man 2 madvise），FREE的效率更好一点，但是也有一些不好的副作用。\n  go1.16之后linux下又恢复成了DONTNEED，因为FREE不会立即让进程的RSS降下来，会误导很多监控、开发运维人员\n  内存分配器为了提高分配效率、GC效率会进行一定的组织，这些概念大家应该有听说过，mheap、spanClass、mcentral、mspan、markbits、allocbits，还有p.mcache。\n smallSize\u0026lt;=32K的分配，走p.mcache（tinySize的更特殊一点，略） largeSize\u0026gt;32K的分配，直接走mheap  这些对象不管是从p.mcache-\u0026gt;mcentral-\u0026gt;arena-\u0026gt;mheap路径来分配的，还是从mheap直接分配的，最终都是建立在从操作系统申请来的page里的，而这些page是由page allocator申请的。即使是很大的对象，最终也是以存在span描述的区域里的。\n一个span可以很多pages，而在里面分配一个对象时，这些page是可以复用的，如果之前其中一个page用过了，但是现在申请一个更大的对象，之前这个旧的page也是所需pages中的一个，那么分配器会先清零memclr\u0026hellip;这段内存区域，这样在操作系统看来就是要真正分配内存，并且因为写了0，那就是全为dirty。\nps：可能我们以为我mmap新申请的内存页面，不写不也是0，为什么不只写之前复用过的page呢？嗯，道理归道理，现在的分配器实现就是这么干的，详见allocNeedsZero(base, npages)这个函数。\n结论：就是通过ballast这种方案初始化有点tricky，在更大范围的应用中不是很可靠：\n 虽然通过一些尽早分配的办法可以避免上述问题，但是不太可靠。因为不确定哪天import了一个包，里面干了些内存分配比较多的操作，说不定影响到ballast占物理内存。 另外ballast这种方案不可移植，它是否占内存与特定平台也有一定关系，并不总是说mmap了一段内存过来不读写就不占内存，windows下的分配就是立即分配。  问题2：可能引发OOM问题 # 本来是想通过ballast来在程序内存负载低时尽量减少GC活动，但是当内存负载高了之后，还是希望它能多清理下GC的，如果清理不及时就容易OOM。特别是混部场景下，这种问题就更明显。\n我们可以在内存占用较高时，把GOGC设置的小一点来频繁的触发GC，来缓解这个问题。但是如果项目已经是使用的GOGC=100+ballast方案的话可能就不是很好调节，因为下次GC的heapGoal已经被推高了。\n如果一开始就采用动态设置GOGC的方式，就更容易实施，比如uber的GC Tuner。在内存占用离上限（uber容器部署时通常取可用物理资源的70%）比较大时就用更大的GOGC（大于100），随着内存占用变高，GOGC也越来越小，通过更频繁的GC来尽可能避免OOM。\n项目现在的方案 # 社区呼吁go能提供内存软限制，目标就是内存占用在达到限制前尽量减少GC活动，当内存占用高了（甚至超了）限制就更及时地GC，以让内存占用保持在一个合理的限制内。\n这个想法其实就和大家最初使用压舱石的初衷比较接近了，也可以用这个方案GOMEMLIMIT/GOGC组合来达到此效果（关掉GOGC=off，指定软限制GOMEMLIMIT）。\nuber的动态GC Tuner的思路和软限制大致类似，不过go1.19为了支持软限制还是做了不少工作的，包括内存使用较高时能够更加激进GC（gcStart）、更加激进地归还内存给操作系统（scavenge）。\n详细了解下GOMEMLIMIT # 和GOGC类似，我们也可以通过环境变量GOMEMLIMIT来指定软限制，也可以通过debug.SetMemoryLimit(?)来设置。\n背景部分我们提到了GOGC如何影响下次GC时heapGoal的计算，GOMEMLIMIT也是通过影响下次GC时的heapGoal计算来发挥作用的，并且是各自根据GOGC、GOMEMLIMIT计算。\ngoal = memoryLimit // p0 - (mappedReady - heapFree - heapAlloc) // p1 - max(mappedReady - memoryLimit, 0) // p2 - memoryLimitHeapGoalHeadroom // p3  解释下：\n  p0：memoryLimit：就是指定的软限制\n  p1：noheap overheads\n  p2：超出限制的部分\n  p3：1mb的headroom（留点buffer）\n  那这里的goal和GOGC算出的goal，以哪个为准呢？可以简单理解为以小的为准，真实情况是有一点点微调，可以不关注。这样当内存占用达到这个goal时，就会触发GC了。\n项目推荐的GC设置 # 首先，要理解GOMEMLIMIT的初衷，它是一个软限制，意思是允许的进程可用内存上限。当进程使用内存少时它可以减少GC来让mutator拥有更多的CPU时间来干活，当进程占用内存高时它可以更频繁GC来回收内存，避免OOM。\n虽然它可以在小内存占用时减少GC频率，但是开发者应该意识到它和ballast还是有差别的。ballast是啥，压舱石的初衷是小内存占用时减少GC频率，但是对内存使用上限并没有控制。\n因此参考ballast的大小为1GB来设置GOMEMLIMIT为1GB或者2GB是没有道理的，我们应该根据实际部署情况来界定各个进程允许的资源使用上限来确定GOMEMLIMIT的值：\n 比如没有混部，per container per service或per host per service，那么可以用70%的内存资源作为软限制值，这样GC频率控制比较好，又留了较多的buffer给系统中其他服务，这也是uber容器化部署的一个经验值。 再比如有混布，一台机器部署了10个服务，那每个进程允许的软限制值肯定不能继续用机器内存的70%这个值，应该划分的更小，比如平均下7%，或者针对不同进程的实际情况在服务配置文件中进行指定。  另外由于go支持通过读取环境变量GOGC、GOMEMLIMIT的方式来在一开始gcinit的时候进行设置，所以我们应该遵循这样的原则，这两个变量都应该独立遵守下面的原则：\n 环境变量配置优先级最高，这样符合go使用习惯 环境变量未指定时，读取配置文件中的自定义值 如果配置文件没指定，则使用默认值  软限制实践的过程 # 最开始确实是直接GOMEMLIMIT=1gb+GOGC=off这样来设置的，但是测试过程中发现，这个方案是有问题的。有经验的开发人员可能已经意识到问题在哪里了：\n  ballast方案中，我们并不会GOGC=off直接关闭GC，这样虽然ballast推高了下次GC的阈值，但是sysmon还是能做到每隔两分钟（2min）强制GC一次的（forced GC）。所以如测试环境下观察的那样，大多数进程实际占用物理内存并不多，因为GC回收内存了；\n  而在我们GOMEMLIMIT+GOGC=off组合情况下，因为GOGC被关闭了，此时sysmon即使过了2min这个间隔期，也不会去触发forced GC（这个从源码中一看便知）。这样问题就来了，当内存占用小于1GB时基本上不会触发GC，因为非堆内存占用很少，按照GOMEMLIMIT计算出的下次的heapGoal跟GOMEMLIMIT差不多，所以基本上不会触发GC，这就会导致各个进程占用物理内存接近软限制，而如果混部的go进程多的话，就很容易导致机器内存占用率过高。\nps：我们是一台物理机部署了70个微服务，内存缓慢增长到了1gb作用。\n  那我们应该如何进一步解决这个问题呢？解决问题前，首先要搞清楚我们追求什么。\n  在进程内存占用很少时，尽量不触发GC，或者不要频繁GC；\n这个问题可以归结于GOGC=off+GOMEMLIMIT设多大的问题\n  在进程内存占用较多时，要触发GC来回收内存，不要因为达到容器、虚拟机、物理机等分配的资源限制（cgroup来控制）被OS给OOM kill掉；\n这个问题可以归结于GOMEMLIMIT上限设多大合适的问题\n  进程steady状态时占用内存不要停留在GOMEMLIMIT附近，以避免频繁GC对服务性能产生不良影响、抖动；\n这个问题可以归结于服务负载均衡、监控问题，超过软限制即超出预期处理能力，需要告警并扩容\n  这就是我们一步步得出前面go1.19 GC推荐设置的过程和思考。\nps：在升级go1.19并调整GC设置后，项目压测发现这个性能提升也是比较明显的，提升了1.2~1.3倍，能提升多少其实和具体项目处理逻辑相关，就不多展开了。\n还有一个问题，加了软限制后是否内存占用一定小于软限制值？\n  首先，不一定。\n  其次，这要看在特定负载下的内存分配、标记清除速率。通常可以根据GC cycle结束时collector扫描的内存量、分配内存和标记内存的比率、mutator:collector的cpu时间占比75%:25%，key算出下个GC Cycle中大致能分配的内存量。这个值也是一个触发GC的参考值，通过这个能够让内存分配、回收保持一定的稳态。\n  当内存分配时，g可以被要求作为assistG去清理一定量的内存，然后再执行分配，清理和分配的内存量差不多，通过这个也能让进程内存占用保持一定的稳态。\n  scavenge清理内存时现在也会参考这个软限制值，去释放内存给OS，这也是一个可以保持内存占用处于稳态的方法。\n  感兴趣的可以读下这块的源码，太多细节的东西，已经不能随意找到博客、文章给解答了 :)\n关于GC Tuner # 关于动态GC调优，uber有一个实现方案，根据其公开的技术文章 Uber\u0026rsquo;s Engineering Manages to Cut 70k CPUs by Tuning GO GC，大致是一个动态设置GOGC来让进程占用物理内存尽量不要超过设定的内存占用百分比的一个东西，从这个意义上来说，它的作用和GOMEMLIMIT很类似。github上有个参考实现，详见 GC Tuner。\n但是如前面所说，go1.19在支持软限制方面，除了内存占用较高时更频繁地触发GC（gcStart），也会更频繁地进行内存释放归还给操作系统（scavenge），效果会更好。所以已经升级到go1.19的项目建议使用软限制代替GC Tuner。\n既然是动态调优，可能意味着更大的可定制型，也不排除大家后面能搞出更优秀的GC Tuner来，怎么调优就不是本文要讨论的了。\n相关的注意事项 # 其实不管是通过以前GOGC这个唯一控制项，还是现在GOGC+GOMEMLIMIT组合的方式，开发人员都应该对自身服务性能、资源占用有个清晰的认识。这就是说，在必要的部署机型下做压测应该常态化，这样才能在服务部署运维时有更清晰的认识，内存占用多少算是正常、不正常，负载多高应该选择扩容、缩容。\n现在很多都已经容器化部署了，但是对于扩缩容依赖的CPU、MEM阈值要有认识。容器化部署隔离性好一点，如果存在混部，那对这里GOMEMLIMIT=?+GOGC=off还会有更好的认识，因为GC不及时可能导致混部的其他服务申请不到内存资源。\n不管用那种GC调优，对服务自身的认识都是每一个开发人员所应该关注、提高的。\n"}),a.add({id:117,href:"/tags/%E5%B7%A5%E4%BD%9C/",title:"工作",description:"",content:""}),a.add({id:118,href:"/tags/%E6%84%9F%E6%82%9F/",title:"感悟",description:"",content:""}),a.add({id:119,href:"/tags/%E8%85%BE%E8%AE%AF/",title:"腾讯",description:"",content:""}),a.add({id:120,href:"/tags/%E8%A3%81%E5%91%98/",title:"裁员",description:"",content:""}),a.add({id:121,href:"/blog/2022-10-01-%E8%A3%81%E5%91%98%E5%B8%A6%E7%BB%99%E6%88%91%E7%9A%84%E6%80%9D%E8%80%83/",title:"裁员带给我的思考",description:"沸沸扬扬的大公司裁员事件沸沸扬扬，矜矜业业、努力工作的我怎能想到这事也会降到我头上，我也有过短暂的困惑期，但是思考之后也就释然了。事情已经过去快4个月了，最终也会渐渐淡忘那段不愉快的时间，但是教训、反思不应该忘记。趁此国庆假期有时间就整理一下。",content:"本文简介 # 今天是国庆节，没抢到合适的高铁票去武汉，今天索性在深圳休息一天再走。回头看今年各互联网大厂大范围裁员的事情，看法也更全面了许多，就不讨论那些企业家有没有责任感的事情，就从家庭、个体工作生活角度谈下自己的一点看法。\n裁员事件 # 听到一点风声 # 从2019.7之后，我一直在从事PCG微服务框架的支持工作，我们会每两周开一次PMC迭代例会同步下规划及进展，有一次会议上，我们评估各语言版本微服务框架今年可能新增的实例数的时候，大家按照过去21年的新增趋势评估，结果有个领导说我们太乐观了，说今年PCG有很多业务要面临下线。\n开始看到瞄头 # 这是我当时听到的最早的“小道消息”了，但是没有当回事。后面过了一阵子，突然听说各大厂开始裁员了，但是各种消息、公关消息夹杂在一起，事情没发生在自己身边，也没觉得有多大影响。后面就听说同“幸福线（信服线）”隔壁几个中心开始裁员了，后面还是开例会的时候，有个子项目trpc-dart负责人说他们那边人员变动比较大，暂时没人力支持需求开发了。我当时开始想这么严重么，后面陆续开始关注这方面消息，涉及到的人是比较多。\n我也难逃此劫 # 再后面，就直接裁到我们这边了，先是组里面的工作年限短的收到毕业通知，裁完一波后，据说裁了很多人没降什么成本，于是开始裁高T、裁组长…后面就到我头上了。\n其实，我们技术总监等其他同事有跟我通过气，意思就是说裁到后面实在没办法了，当时收到消息的时候，虽然有点难过，但是很快就释然了。难过是因为自己好歹也为业务技术支撑、为公司微服务框架做了不少贡献，结果因为业务不景气、为了降“成本”就把工资高（贡献也多啊）的老员工直接裁掉，虽然说赔偿比较良心，但是你懂得心理上还是不认同这种粗暴的裁员方式的，那时候真的准备离开腾讯了。\n我的看法 # 业务调整是迟早的事 # 业务不景气已经不是一天两天了，只不过以前公司在各方面压力比较小，像这些不挣钱的业务也就这样活下来了，还养活了一部分人。\n只是心理上难接受些 # 像我是一毕业就SP进入了腾讯，6年时间先后做了几个业务，也做了些公线支持的工作，框架、规范、工具、培训分享等，内心对公司的归属感是很强的，这次简单粗暴的大范围裁员，让人感觉这些年算是瞎了眼。公司确实是家好公司，但真的不见得每个人都优秀。行业可能竞争比较激烈，可能业务发展遇到了瓶颈，但是你能感觉到有些领导在犯错，光嘴说的好听，动作搞的很大，但是树立一个个山头、做的事实少、能有高价值产出的就更少，业务也没有好的起色。\n整体形势差换工作难 # 已经是山头、嫡系林立的丛林社会了，这种情况下即便是想留下有能力的员工也近乎不可能，谁来评判呢。而且这个时候，领导们只想留下自己的嫡系，而非有能力的员工。有能力的员工，自然不用担心找不到工作机会，理论上是这样，前提是得有这么多就业岗位。今年大形势不好，很多公司都在裁员，最后这被裁的一两万同事要到外面去找机会，大厂普遍裁员，没这么多机会，很多同事只能去第二梯队的企业（业务不一定不行哈）。\n我旁边的一些同事，从接到通知就开始准备找工作，等到lastday离职哪天，有的也还没有拿到offer，当然最后他们找到offer了，但是这确实能看出来就业形式比较差。\n对公司不再有归属感 # 这种事情发生之后，咱也不哭不闹，不过是看清了这个丛林社会中，谁也靠不住，公司再好它也不是家，自己首先要考虑的还是家庭、家人、自己，摆工作的重要性往后放放。工作上，没了你随便找个人就能代替，再说了，就算是没人代替你大不了短期内工作没法推进了，但是依旧还可以维持。说白了，自己对公司业务来说没那么重要。没必要掏心掏肺的，为了点鸡毛蒜皮的小事牺牲自己那么多精力去忠心耿耿地工作，影响到家人就更蠢了。\n现在对腾讯已经没有任何“家”的感觉了，也不在KM上讨论问题了，公司内发生的事情也不再关心了，公司外的形象也不想去维护了，努力做好自己分内的事，拿钱干活。但是努力做好本职工作、提升自己、提供更好的产品服务，这个目标不能打折，程序员的自我修养。\n要明白来工作是为啥 # 人活着，时间精力有限，心里能装的东西有限，归根结底，我们还是要多体验些美好的东西，少为这些乱七八糟的事情浪费心神。裁员就裁员，要么活水去好的业务团队，无论学习、沉淀、挣钱都还有保障，要么出去找更好的机会。我来腾讯不就是为了来锻炼长经验的吗，多挣点钱更好。\n还是要坚持自己的想法，提升技术的同时，多看看有哪些小成本的试错机会能致富的，比如羊了个羊这样的小游戏，搞一个成功了，说不定就财务自由了，即便是没这么成功，多几种收入来源也是不错的。\n本文小结 # 最后，祝愿所有一起奋斗过的小伙伴们保重身体，找到合适的工作机会。\n"}),a.add({id:122,href:"/tags/chubby/",title:"chubby",description:"",content:""}),a.add({id:123,href:"/tags/distributed-lock/",title:"distributed lock",description:"",content:""}),a.add({id:124,href:"/tags/redlock/",title:"redlock",description:"",content:""}),a.add({id:125,href:"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/",title:"分布式锁",description:"",content:""}),a.add({id:126,href:"/blog/2022-09-25-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E6%96%B9%E6%A1%88%E7%9A%84%E6%80%9D%E8%80%83/",title:"分布式锁方案的思考",description:"微服务架构中分布式锁是一项比较常用的技术，但是并不是每个用过分布式锁的开发都正确认识了分布式锁。本文对分布式锁要解决的问题、实现技术进行了讨论，并对可用性更高的场景对锁服务设计实现提供了两个思路。",content:"问题背景 # 在微服务架构下，经常面临一些事务性处理需要考虑一致性的场景，笔者工作过程中，很多场景最终都采取了可用性优先、数据最终一致的方案。最后我们可能也会结合一些对账之类的手段来发现异常并修复不一致的数据。\n归根结底，是因为微服务架构下上述事务性处理方案没有保证刚性事务的ACID原则，其弱化了对A、C的控制，OK，这种方案并非不可接受的，只要业务场景适用即可。这里还有一点就是I（Isolation）的原则，如何保证微服务架构下事务处理的隔离性呢？\n分布式锁，就是大家常用的方案，只不过关于对分布式锁的认识，可能大家认识的程度并没有自己认为的那么到位。\n常见方案分类 # 分布式锁，归根究底是为了保证任务的排他性执行。但是为了排他性执行的初衷却可能是不同的，所以我们接下来会先按照要解决问题进行分类。然后呢，考虑到可用性、正确性，实现分布式锁的具体方法也是不同的，然后我们也可以按照实现方式进行分类。\n按解决问题分类 #  解决效率类问题：为了避免资源浪费，如每天统计下业务下所有服务接口成功率数据，这类定时任务也是多机部署的避免单点问题，但是只要一台机器执行就行了，属于解决效率类问题。没有必要多台机器执行，但是即便都执行了也没啥影响，只是后面执行的覆盖掉前面的执行了，仅此而已。 解决正确性问题：任务必须排他性执行，如果并发执行则存在正确性问题。比如用户购买游戏道具时需要读取玩家金币数、扣金币、写回，这里涉及到典型的Read、Modify、Write的问题，如果这个操作时序不是排他性的，就掺杂着重置、送礼等各种可能修改金币的操作时序，则会导致正确性问题。  按实现方式分类 #  基于缓存实现：比如利用redis、memcache等实现，分布式缓存一般提供了get、set的能力，允许给key、value指定版本、排他性、过期时间属性，来实现分布式锁。 基于共识算法实现：比如etcd、zk这类底层有raft、zab共识算法支撑的组件，借助他们可以比较可靠的实现分布式锁，至少能保证分配锁时不会导致client错误持有锁。  在实际实现、使用分布式锁时，我们多数时候是冲着正确性去的，但是方案本身其实是不完备的，但是我们却将其当做了“正确的”。\n常见方案介绍 # 基于redis单机版 # 比较常见的就是单机版的redis实现版本，如下所示：\n# 加锁操作 SET resource_name my_random_value NX PX 30000 # 解锁操作 if redis.call(\u0026quot;get\u0026quot;,KEYS[1]) == ARGV[1] then return redis.call(\u0026quot;del\u0026quot;,KEYS[1]) else return 0 end  实际情况是单机版redis存在单点问题，为了解决这个问题，通常又会给redis master挂个slave来备份数据，但是redis的备份机制是异步的，所以仍然存在主备切换时丢失锁数据而导致的错误加锁情况，解决不了正确性。\n基于redis集群版 # 集群版的redis，用的比较多的是redlock算法。redlock算法主要是解决单点故障问题，它的主要思想是，假设集群中有N个（建议值5）master节点，这些master节点及其replicas各自维护一些不相干的keyslots。加锁时，client先获取本地时间，然后串行地向N个节点发起请求，是串行的。\n至于详细的实现，redis官网上有这些推荐实现的github repo链接，可以自己去找找看。\n其实这个算法也解决不了网络波动、分区极端场景下，依然会导致client错误持有锁的情况，比如1、2、3、4、5个节点，一开始网络正常client1持有了1、2、3上的锁，后面网络波动导致client只能访问3、4、5，并且3发生了主备切换而备份上缺少数据，client依然能在3、4、5上获得相同锁。\n 尽管redlock算法提出了一些可以缓解正确性被破坏的想法，但是仍然不能保证分配锁时的正确性。\n 基于etcd实现 # etcd本身是基于raft算法实现的副本的状态复制，是有可靠的共识理论支撑的工程实现，另外etcd号称其raft算法实现有着比paxos算法更好的性能（这个没求证，多数情况下paxos算法可能性能更优点，也不一定非得有master节点），感兴趣的可以自行了解。\n基于etcd的分布式锁实现，已经内置在etcd中了，直接使用即可。\n因为示例代码的篇幅原因、go.mod设置等，我们就不在这里占用太多篇幅了，感兴趣的可以直接查看这里的示例代码：https://github.com/hitzhangjie/codemaster/blob/master/distlock/main.go。\n思考下 # 我们从解决效率问题的分布式锁，到解决正确性问题的分布式锁，对锁分配正确性的要求提升了一档，关于其实现方案，也从基于redis、redis集群版的方案，也过渡到了基于raft算法的etcd实现（其他的基于paxos、zab共识算法的类似就不介绍了），我们解决了锁服务分配锁时的正确性问题，但是这样就能保证任务排他性执行了吗？\n不能！client在使用锁的时候，可能会出现如下情况：\n client出现了崩溃、逻辑bug，导致锁没有被正确地释放掉，如果锁没有过期时间，将导致其他client加锁时出现死锁； client加锁时设置过期时间，但是过期时间可能设置的过短，锁过期被etcd清理然后又重新分配给了其他client，然后旧client还以为自己别锁保护的临界区内还可以肆意妄为，导致并发执行错误； client加锁时设置了合理的过期时间，但是自身因为其他原因出现了一定时间阻塞，恢复后继续执行，但是锁实际已经过期被释放； client执行操作时锁确实是有效的，但是在其发起对下游的请求后，下游继续处理期间锁过期，其他client持有了锁并发继续执行操作；  看到没，即便是锁分配是正确的，client使用锁时依然无法100%保证正确性，这个问题能100%解决吗？不能，但是可以尽可能缓解，比如合理设置锁过期时间，比如请求方调用下游服务时，把锁信息带给下游让下游能够去锁服务校验锁有效性。\ngoogle chubby # chubby是谷歌内部的专用的锁服务，没有对外部开源，但是通过其发表的论文，开源社区实现了zookeeper。这里只简单介绍下chubby的核心思想。\n 易用性：以锁服务api的形式方便业务接入 容错设计：  副本机制：锁服务节点，加解锁操作通过 paxos复制到副本。避免节点故障数据丢失问题，同时paxos复制保证了数据的同步准确性； 锁过期机制：锁服务分配的锁都是有过期时间的，过期的锁会被清理掉。避免client锁持有者因为逻辑错误、崩溃、阻塞等导致锁长期未释放导致的死锁问题； 锁清理机制：client锁持有者有可能出现崩溃，锁服务和client之间维持着一个会话，当检测到对端不可用时，锁服务会主动清理该client申请添加成功的锁。避免相关的锁不能及时被释放（不必等到锁过期，chubby锁是粗粒度锁，可长达几个小时）； 锁序号机制：只有client、server、锁服务全部参与进来，才能尽可能保证任务执行的排他性，锁服务可以保证锁分配的正确性，但是毕竟是建议性锁，client应该尽可能在锁有效期内完成所有操作，而下游server应该在执行操作前校验client传递的持有锁信息的有效性，校验是在server和锁服务之间完成的，这里的锁信息主要指的就是锁的序号（类似版本号的玩意）； 持久化机制：每个节点挂掉后可能恢复，恢复后它的数据是全部丢失还是可以恢复回来？一般是要借助合适的存储手段对这些数据进行存储，然后节点后恢复可以快速恢复。chubby是如何做的，感兴趣的可以自己查下。    我们看到google chubby确实考虑的比较周全，但是它也有自身的局限性。它适合用来做粗粒度的锁服务，比如锁持有时间长达几十分钟、几个小时这种，对于细粒度锁，比如小于1s，这种就不太合适了，为什么这么说呢？\nchubby是基于paxos来做的，paxos能保证状态复制的正确性，是基于多轮rpc通信来保证的，而rpc有网络通信开销，对于延迟敏感的处理路径，业务不一定能接受这个开销。而且chubby是有主节点的（paxos本身支持无主节点，但是代价是更多的消息交换），有主节点瓶颈的。因此，google内部也是将其用作粗粒度锁的，比如一些分布式系统的选主。\n如何方案选型 # 业务中如果希望引入分布式锁，选型的时候可以思考下自己到底是解决哪类问题？\n 如果是为了解决效率类问题，直接用redis方案就挺不错的，考虑到单点问题可以挂个slave，也没啥问题； 如果是为了解决正确性问题，也可以用redis redlock方案，但是要明白其可能存在的风险，业务能否接受； 如果对正确性非常重视，对于并发写冲突的情况完全不可接受，反而可以接受一些可用性损失，那我建议直接用etcd、zk等方案更合适； 如果业务更追求可用性，同时尽最大可能保证正确性，那也不妨考虑redis redlock，如果也不想引入额外组件增加运维工作量，也不妨考虑自研一个分布式锁；  自研分布式锁 # 方案1：和业务紧密结合的经济使用方案 # 现在只想优先保证业务可用性前提下，尽最大程度保证正确性。可以考虑如下方案，结合下图进行一下简单说明：\nclient（上游服务）访问一个下游逻辑服务时，如果uid相同的话，为了尽可能并发对同一个用户的数据做并发RMW操作时出错，需要分布式锁进行排他性控制。\n分布式锁的分配，可以考虑etcd来分配保证锁分配的正确性，但是之前考虑到etcd也是基于共识算法的，其大概率也不适合做细粒度锁支持，另外其failover时间一般是要10~20s左右的，如果业务中请求量很大，这么长时间不可用是不可接受的。\n我们可以进行这样的优化：\n 锁分配还是由etcd来分配，但是我分配的是一把大锁，什么意思呢？ 当某个uid1请求到来，client1希望请求logicsvr集群做某种操作时，这里client1通过一致性hash的方式，将uid=uid1请求发到节点logicsvr1处理，logicsvr1现在要rmw uid1的数据，为了保证排他性执行的正确性，它向etcd申请加锁，这个锁有效期比较长，比如1h，以后所有uid1的请求都会通过一致性发送到logicsvr1来处理，因为这个锁一直被logicsvr1持有着，不会有其他logicsvr和它并发rmw，但是？ 当client1请求发生路由漂移，请求发到了不是logicsvr1而是logicsvr3之后，logicsvr3发现自己没有锁，怎么办，肯定是要先申请加锁，此时etcd告诉它锁已经存在了不能加锁，etcd主节点的读操作效率是可以的，所以这种路由漂移情境下量也不会很多，对etcd加锁请求的开销是不用太担心的。  此时logicsvr3知道锁当前是logicsvr1持有，它可以转发请求给logicsvr1去处理； 大多数情况下转发过去logicsvr1会处理成功，因为此时只是路由漂移导致的，并不是logicsvr1挂掉了； 如果logicsvr1挂掉了，etcd也会清理掉起持有的锁，此时logicsvr3加锁成功，自己做处理就可以了；    这个方法可以应对：\n  正常情况下的排他性执行问题，避免了每个操作都申请锁的开销；\n  异常情况之一，logicsvr扩缩容等其他原因导致的路由漂移时的排他性执行问题；\n  这个方法解决不了：\n 如果logicsvr内部发生了网络波动，导致内部节点间转发等出现问题，就会退化为全部向etcd申请加锁的情况，可能会导致链路处理latency上升，etcd负载加重。  方案2：稍微通用点的分布式锁方案 # 再一种方案，就更容易想到些，我们可以基于多数派投票的方式来完成复制，每当申请加锁时，我们直接在当前locksvr加完锁后，同步地复制到其他locksvr实例节点，多数成功才认为成功并返回给client（如果失败可以异步地发起清理）。\n这种缺点就是每个locksvr节点相当于复制了完整的锁数据，且集群中消息量会比较多。\n那我们可以用一致性hash复制的方法来完成复制，比如locksvr收到请求lock(uid1)之后，可以拿这几个做key：uid1:0、uid1:1、uid1:2，分别计算一致性hash对应的节点，假设为locksvr1、locksvr3、locksvr5，那么写入即可，多数成功就认为成功。\n当然考虑到并发写入时有助于减少latency，也可以把这个请求加锁、复制锁的操作全部由locksvr来发起，那最大延迟就取决于响应最慢的哪个locksvr节点。\n这个方法可以应付：\n 锁方案比较通用，不用在logicsvr内部写那些加锁后判断锁持有者、转发请求给锁持有者处理的特殊逻辑； 大部分正常场景可以应付； locksvr本身内部的扩缩容、故障导致的路由漂移，可以应付（除非uid1对应的所有写入节点全挂掉了）； 锁数据存储全部是内存内计算，性能应该是没问题的； 也不需要引入额外的什么组件；  总结 # 最终需要什么样的方案，还是取决于实际的业务场景，没有什么方案可以以不变应万变。\n参考内容 # [0] 如何实现分布式锁, https://martin.kleppmann.com/2016/02/08/how-to-do-distributed-locking.html\n[1] 分布式锁需要各参与者参与, https://hazelcast.com/blog/long-live-distributed-locks/\n[2] 谷歌锁服务chubby论文, https://github.com/hitzhangjie/distributed-system-series/blob/master/papers/distributed%20lock%20-%20chubby.pdf\n[3] 伸缩性更好的层级chubby, https://github.com/hitzhangjie/distributed-system-series/blob/master/papers/distributed%20lock%20-%20hierarchical%20chubby.pdf\n[4] etcd实现分布式锁, https://medium.com/@felipedutratine/distributed-lock-with-etcd-in-go-d21e7df145bc\n[5] redis分布式锁redlock, https://redis.io/docs/reference/patterns/distributed-locks/\n[6] 分布式锁jepsen验证框架, https://github.com/dist-sys-dev/jepsen\n[7] 根据论文实现的chubby, https://github.com/dist-sys-dev/chubby\n[8] 层级chubby实现, https://github.com/dist-sys-dev/Hierarchical-Chubby\n"}),a.add({id:127,href:"/tags/consistent-hash/",title:"consistent hash",description:"",content:""}),a.add({id:128,href:"/tags/consistent-hash-with-bounded-load/",title:"consistent hash with bounded load",description:"",content:""}),a.add({id:129,href:"/tags/hash/",title:"hash",description:"",content:""}),a.add({id:130,href:"/tags/jump-consistent-hash/",title:"jump consistent hash",description:"",content:""}),a.add({id:131,href:"/tags/loadbalance/",title:"loadbalance",description:"",content:""}),a.add({id:132,href:"/tags/multi-probe-consistent-hash/",title:"multi-probe consistent hash",description:"",content:""}),a.add({id:133,href:"/tags/rendezvous-hash/",title:"rendezvous hash",description:"",content:""}),a.add({id:134,href:"/blog/2022-08-06-%E4%B8%80%E8%87%B4%E6%80%A7hash%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E6%96%B9%E6%A1%88%E7%9A%84%E6%80%9D%E8%80%83/",title:"一致性hash负载均衡方案的思考",description:"本文从一致性hash负载均衡策略触发，深入了解了下不同的方案变体，最后针对普适应更好的一致性hash方案、go-zero实现、实践中的引用改进进行了探索介绍。",content:"常见的负载均衡策略 # 客户端完成被调服务的服务发现后，获得了一批实例节点列表，现在要借助合适的负载均衡算法来选择一个实例完成请求处理。\n常见的负载均衡算法包括：\n 轮询：每一次网络请求按照顺序发放给下节点列表中的下一个节点，这种情况适用于节点配置相同并且平均服务请求相对均衡的情况 加权轮询：考虑了不同节点的硬件配置情况，如节点a、b、c性能有低到高，权重设置为1、3、6，则按照权重分配10%、30%、60%的请求给到节点，这种可以避免高性能机器负载低、避免性能差机器过载 随机：随机选择一个节点来处理请求，这种在请求量比较大的情况下能达到相对均衡的分布，同样适用于机器配置相同的情况 加权随机：考虑了不同节点的硬件配置情况，类似加权轮询，只不过选择下一个节点时是基于随机选择，而非轮询的方式 余数hash：根据某个key对节点数做取模运算，比如节点数为n，根据请求中的m = uid % n，表示用节点列表中第m个节点来作为服务节点。当key分布范围比较广能达到相对均衡，选择key字段的时候要考虑下key分布情况。使用hash的场景，一般是因为后端节点有状态可复用（或者希望借此减少并发冲突），但真实环境中，节点故障是常态，尤其是在容器化部署场景下自动化扩缩容，hash会导致集群中所有节点状态无法被复用。一般会用一致性hash代替hash。 一致性hash：一致性hash是对hash的优化，一致性这里强调的就是节点加入、离开后尽量保证大多数请求仍然能路由到该路由的节点，而不是新加入的节点，同时为了避免新加入、离开节点导致的负载不均衡问题，引入了虚拟节点的概念，每个物理节点都对应着hash环上一定数量的虚拟节点，这些节点混在一起，能实现各个节点负载的相对均衡。节点数量该选择多少呢？一个比较直观的认识是可能虚拟节点越多越均衡，但是数量过多也会有开销，这与虚拟节点的hash计算、存储有关系，本文后面讨论。 按响应速度：有些负载均衡设备，会根据与后端服务节点间的ping延时来选择一个响应时间最短的。类似的也可以根据client、server之间的ping延时或者请求处理响应时间来选择。 按最少连接数：对于某些请求处理时间比较长的场景，如ftp传输等，一个tcp连接存在的时间可能比较长，连接数比较多的可能代表该节点负载比较重，因此会开率选择连接数比较少的来提供服务。 其他  负载均衡算法有很多，之所以这么多也是因为应用场景的差异，根据合适的场景选择适用的负载均衡算法。\n调研一致性hash策略及其可替代方案 # 对一致性hash方案及其可替代方案进行调研、对比。\n余数hash # 余数hash，简单讲就是那个key去算出hash值，然后对节点数量取模，m = hash(key) % n，用节点列表中的第m个节点去做请求处理。 如果节点数变化非常不频繁，或者说key remapping（rebalancing）过程中带来的开销不大、影响不大，那用余数hash也无所谓。\n但是现实场景中，比如一些有状态服务，如果remapp后映射到了与先前不同的节点，或者容器化部署时节点数经常变更，不满足适用余数hash的条件。\n比较常见的对策，就是采用一致性hash。\n一致性hash # 简要介绍 # 一致性hash能够缓解节点加入、离开时rebalancing导致的一些hash节点改变的问题，在以下场景中就更有优势：\n  服务是有状态的，这样大多数路由仍然能路由到原来的节点，状态可以复用；\n  即使服务不是有状态的，将原来路由到节点n的请求及其后续请求继续路由到该节点，也可能存在更好的局部性处理（locality），\n 举个例子（可能不很恰当哈）： 比如有个个人展示页要展示头像昵称、最近游戏记录，假设之前有个什么客户端请求uid=xxx的请求路由到了节点n拉取过了昵称头像并cache，后面该展示页也路由到该节点的话就可以复用该cache。\n   假设key空间中值数量为k，节点数为n，那么当发生remapping时，笼统估算有k/n不命中原来的节点。\n关于实现 # 关于一致性hash的实现：\n 构建一个一致性hash环，一个数组就可以实现 选定节点的key，如ip，hash(key)，然后再hash环上对应位置存储该节点信息，考虑到hash环大小需要适当取模 考虑到各节点的负载平衡，引入虚节点，每个物理节点对应为k各虚节点（k多大？），各个虚节点的hash值计算就分不同方法：  key多大？兼顾计算效率和负载均衡性，因为节点数提前无法预估，可能要选择一个更好的经验值 引入k个hash函数，hash1(key), hash2(key), hash3(key)\u0026hellip;.hashK(key)，分别设置到hash环上 针对key，构造key_1, key_2, key_3..，keyK，使用同一个hash函数分别计算上述key的hash，并在hash环上设置其节点信息 TODO 这里的计算方式的选择，虚节点数多大（过少还是会不均衡），过大计算效率慢（多次计算hash），另外多个hash还是构造多个key也可能会影响到负载的均衡性，需要针对性的测试。   现在有个请求，比如用玩家userid作key，hash(key)得到值之后，因为一致性hash环是个首尾相接的有序数组实现的，可通过二分查找（查找第一个大于等于该hash(key) )的节点，复杂度O(logn)  一致性hash，对于带权重的也能支持到：比如a机器比b机器性能高一倍，希望其处理两倍于b的请求，那么就可以让a机器的虚节点多一倍。但是如果管理的节点数量成千上万之后，hash环上存储这些虚节点的开销就不能忽略了。\n一致性hash替代方案：Rendezvous hashing # Rendezvous hashing，也叫Highest Random Weight hashing。它比一致性hash提出来早一年，用了一种不同的方式来解决余数hash中key remapping的问题，也能实现一致性hash中 “需要remmap的keys数量=k/n” 的这种效果。\n它是怎么做的呢？将请求key和机器节点的key（比如ip），合在一起做hash（不像一致性hash那样分开做hash），然后选择hash值最大的那个机器节点。\ntype router struct { endpoints []*Endpoint } func (r *router) Get(key string) *Endpoint { var ep *Endpoint hashVal := -INF for _, e := range r.endpoints { h = hash(key, e) if h \u0026gt; hashVal { ep = e hashVal = h } } return ep }  这种方案的最大问题是O(n)的计算复杂度，一致性hash是O(logn)查找复杂度，不过如果节点数不是很多的话，这个开销可以接受。\nps：测试了下，rendezvous hash到各个节点一次记load+1，那么100w请求时，各节点load负载标准差387，最大、最小节点负载占总负载（100w）比例为1/1000。\ngo-zero实现的经典的一致性hash算法，虚节点数量100个，默认的hash函数（不一致哈），100w请求时，各节点负载标准差1w+，最大、最小节点负载占总负载（100w）比例为5/100。\n一致性hash变体：jump consistent hash # 相比传统的环形一致性哈希，空间复杂度更低，根本无内存占用，而且算法非常简洁，C++的实现不到10行代码就可以搞定。\nint32_t JumpConsistentHash(uint64_t key, int32_t num_buckets) { int64_t b = -1, j = 0; while (j \u0026lt; num_buckets) { b = j; key = key * 2862933555777941757ULL + 1; j = (b + 1) * (double(1LL \u0026lt;\u0026lt; 31) / double(key \u0026gt;\u0026gt; 33) + 1); } return b; }  但是jump consistent hash存在它的局限性，使用场景受限：\n 服务器名不是任意的，而是按照数字递增，它更适合应用于数据存储场景，如随着时间增长、数据量变化有创建出更多的shards之类的场景。 jump consistent hash只能在节点列表末端增加、删除节点，不能从中间任意删除节点，所以才说它适合用于存储类场景，比如数据容量大了，我们增加一个shard，或者说一个中间的shard崩溃了我们通过replicas复制来应对等。  在rpc场景下，后面任意一个节点都可能故障，我们需要从节点列表中删除任意一个节点的灵活性，所以说jump consistent hash不适用。\n一致性hash变体：consistent hash with bounded load # 这里的bounded load是啥意思呢？也是为了保证集群中各个节点的负载相对均衡，怎么做到呢，一个简单的思路就是：返回一个可以处理这个key的负载还ok的节点。\n1. 返回一个能处理这个key的节点，怎么理解呢？\n还是根据经典一致性hash的思路，计算key的hash从一致性hash环上找到第一个\u0026gt;=这个hash的虚节点，然后找到对应的物理节点信息。按经典一致性hash算法，此时就准备返回了。但是这里的方案变体还有其他事情要考量。\nps：在这个方案变体，一致性是要考虑的，但是负载均匀也是要考虑的，而且重视程度更重。经典一致性hash算法中，无论我们怎么设置虚节点数量、选择hash函数，包括给性能高的物理节点分配更多看似合理的虚节点等等。总有可能会出现负载不均衡的情况，负载均衡是一个理想值。我们在跑测试的时候也可以看到节点的最大、最小负载（hash一次load+1）相差很明显。怎么针对负载做优化呢？\n2、如何做到负载相对均匀?\n假设我们规定，返回一个节点时更新这个节点的load（load+1）、同时更新总的totalload，这样我们就能计算各个节点的avg load。如果第一步中待返回的load超过了avg load，我们就不返回该节点，而是从当前hash环当前虚节点位置继续向下遍历，直到找到下一个负载小于avg load的节点。\n有没有两全其美的方案？\n简单对比下，经典的一致性hash 及 jump一致性hash：\n ring-based consistent hash，以较大内存为代价，提供了增删任意node的灵活性，但是呢它的负载不够均衡。经典的实现里各个节点的负载是有偏差的，这给我们进行系统容量评估带来了些挑战，除非我们把虚节点加大，比如1000、2000。 jump consistent hash，以极低的内存消耗，提供了高效的负载均衡，负载均衡均匀性也比较好，但是损失的是灵活增删节点的灵活性，这导致它在存储类shards路由场景中比较适用，其他场景则不适用。  那有没有两全其美的方案呢？（实际上没有）\n Multi-Probe Consistent Hash（简写为MPCH），就是为了解决这里的问题的，也是google提出的。  优点：它支持O(n)的空间复杂度（胜过ring-based一致性hash），支持O(1)的插入、删除时间复杂度（胜过jump一致性hash），支持增删任意节点（胜过jump一致性hash） 缺点：它的查询复杂度下降了，假设我们追求的均匀性，比方说负载的peak-to-mean为1.05%，那么需要做21轮hash（有公式可以算，略）， 达到相同负载偏差，ring-based一致性hash需要700*ln(n)，n为100个节点时hash环存储时就要1m内存。   Maglev Hash方案，Maglev是google的网络负载均衡器，内部也用了一致性hash方案，我们简称maglev hash方案。maglev在google类似我司tgw这层，通过vip转发外部数据包给内部服务器时，希望尽量复用以前的tcpconn并在后端节点变化时做最少机器迁移：  优点：和ring-based一致性hash和rendezvous hash方案比，有不错的低内存开销、查询速度 缺点：maglev hash依赖一张查询表，当后端节点出现失败时构建这个查询表开销比较大，这也限制了后端节点的最大数量。    我们期望的完美的hash方案应该是什么样的?\n调研了这些hash方案后，我们希望有这样的完美的hash方案：\n Only 1/n percent of the keys would be remapped on average where n is the number of nodes. A O(n) space complexity where n is the number of nodes. A O(1) time complexity per insertion/removal of a node and per key lookup. A minimal standard deviation to make sure that a node is not overloaded compared to another one. It would allow associating a weight to a node to cope with different node sizing. It would allow arbitrary nodes name (not numbered sequentially) to support both load balancing and sharding.  但是实际情况是，没有这样完美的hash方案!\n Rendezvous has a linear time complexity per lookup. Ring consistent hash has a poor minimal standard deviation without the concept of virtual nodes. With virtual nodes, is space complexity is O(n*v) with n the number of nodes and v the number of virtual nodes per node. Jump consistent hash does not have a constant time complexity and it does not support arbitrary nodes name. Multi-Probe Consistent Hash也存在问题，虽然空间、时间、灵活性不错，但是查询效率大大下降了  其实还有很多hash方案，它们都极力去平衡“一致性”和“均匀性”，但是实际情况就是没有完美的可以适用于所有场景的方案，下面是个hash方案的对比（展示了随着shards数增加查询的耗时 nanoseconds）：\n除了单次查询耗时，其实还需要考虑内存开销、构建开销、插入删除节点开销、最大支持节点数等，没有完美的方案。\n所以，我们只能结合实际场景进行各种“权衡”，这也是为什么一致性hash方案尽管负载偏差比较差，但是它目前仍然应用范围比较广的原因，因为它对大多数场景都还ok。\n## 负载均衡最大努力交付\n现在回到我们现在的mesh框架的负载均衡场景，我们再重新评估下我们关切的点：\n 节点选择的一致性 节点负载的均匀性 尽最大努力交付  现在只考虑ring-based一致性hash方案，它好理解、适用范围更广，而且可以结合ring值域、key值域、虚节点数、hash函数选择来做些优化来满足需要：\n 一致性：根据理论值如果节点数n，那么新加入一个节点最多迁移1/n 均匀性：通过增加虚节点数量，hash函数也比较好，那么也可以改善均匀性，且能在我们接受范围内，ring占用的内存空间在可接受范围内 尽最大努力交付：如果选中的一个节点，是一个失败的节点，我们可以借助重试（replication），使用hash环选择第2个或更多个节点出来供使用，howto?  ring-based一致性hash，最大努力交付howto？\n 比如，hash出的一个节点，是一个失败的节点，直接取hash环上这个节点的下一个节点（不能是相同的物理节点），这种好实现点，虚节点记录下在环上的位置即可 比如，借鉴一些存储系统replication的思路，允许取出多个节点  参考资料 # 参考文献： #  介绍一致性hash，https://itnext.io/introducing-consistent-hashing-9a289769052e redezvous hash，https://medium.com/i0exception/rendezvous-hashing-8c00e2fb58b0 经典一致性hash算法paper：Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web jump一致性hash算法paper：A Fast, Minimal Memory, Consistent Hash Algorithm jump一致性hash算法paper推导：https://zhuanlan.zhihu.com/p/104124045 一致性hash算法tradeoff：https://dgryski.medium.com/consistent-hashing-algorithmic-tradeoffs-ef6b8e2fcae8 Multi-Probe一致性hash算法：https://arxiv.org/abs/1505.00062 一致性hash方案tradeoffs：https://itnext.io/introducing-consistent-hashing-9a289769052e Maglev hash方案，https://blog.acolyer.org/2016/03/21/maglev-a-fast-and-reliable-software-network-load-balancer/  实际应用： #  dapr采用了google consistent hash with bounded load, https://cloud.tencent.com/developer/article/1799300?from=article.detail.1340095 go-zero rpc框架采用了经典的一致性hash算法 twitter eventbus采用了rendezvous hash (最大随机权重hash） memcache client采用了jump consistent hash, https://sourcegraph.com/github.com/grafana/loki/-/blob/pkg/storage/chunk/cache/memcached_client.go?L100 go-redis client默认采用了rendezvous hash，https://sourcegraph.com/github.com/go-redis/redis@v8/-/blob/ring.go?L39  影响一致性hash评估结果的因素 # 我们主要关注负载均衡算法的 ”一致性“、”均匀性“ 这两点，我们的测试也围绕着这两点展开。为了使得测试更有价值，更有可信度，需要说明下接下来的测试方案。\n影响各负载均衡算法测试结果的，可能有以下几点：\n  服务物理节点数，固定为10\n 涉及到一致性hash算法及其变体时，我们会分别对比虚节点数为5、10、20、50、100、1000时的数量（直观理解，虚节点越多越均匀，内存开销可能越大） jump一致性hash，虚节点数量对内存没影响，但是该算法使用场景受限于节点只add不减少的场景（如只增加shards的存储场景） rendezvous hash，非一致性hash，没有虚节点概念，但是时间复杂度从一致性hash的O(logn)变为O(n)，当节点数很多时开销不可忽视    待测试的userid数量足够多（将userid mapping到物理节点上去处理），要远多于节点数，比如100w\n  待测试的userid生成算法是否均匀，go标准库rand.Int()默认的source是均匀的，我们用这个方法来生成userid\n  各基于hash的负载均衡算法采用的hash函数是否一致，在从key计算hash value时，不一致的hash函数可能会导致分布不均匀，这样会导致难以评估各类负载均衡算法本身的差异性 可以把常见实现的代码clone下来，统一调节下hash函数来验证下，控制变量下。\n  一致性hash算法中，虚节点对应的hash value的计算，为了平衡负载均匀和开销，通常虚节点数量n可调整，这种情况下就没法按照经典一致性hash算法中那样提供n个hash函数了 一般是对物理节点host做下处理，比如加前缀1、2、3或者后缀9、10、11后表示虚节点，然后再用同一个hash函数做计算。 这种做法是否能让各个虚节点在ring上分布均匀呢？这个跟hash函数有关，但是直观感受是不见得能均匀。\n  用户userid在采用与hash(host)时相同的hash函数，userid的值域与其hash值，是否能在hash环上均匀分布呢？直观感受是，不见得。\n  上述这些都是影响我们评估算法质量的影响因素，在进行测试对比时要多关注。\n另外，关于“一致性”方面，通过算法本身的理论描述是可以给出一个理论值的：\n 一致性hash，假设k个key，n个nodes，那么节点加入、离开后，需要remapping的key大约为k/n（均衡的前提下） 一致性hash with bounded load，这个虽然负载比较均衡，但是直观感受是“一致性”不如经典的“一致性hash”，因为它会在负载偏高时选择下一个节点 jump consistent hash，这个算法只考虑存储场景data shards增加的情况，我们可以先延迟测试这个 rendezvous hash，理论上来说，只要新加入的节点host不会导致hash(userid, host)最大，就对原来的userid没影响，但是有多少userid会受影响呢？待理解  但是实际使用时到底怎么样，就跟key本身以及hash函数选择的优劣很有关系了。\n一致性hash实际测试结果 #  选择一个一致性hash实现，比如采用go-zero的一致性hash实现 测试一致性，这个有算法理论支撑，我们其实可以不用测试 测试均匀性，这个有必要亲自测试下 修改以支持最大努力交付，比如失败之后该如何重试，以go-zero中定义的一致性hash环为例：  先计算key从consistenthash.keys找到下一个虚节点的hashvalue，然后从ring[hashvalue]得到nodes，遍历这些nodes看是否有可用节点 上面不成，直接索引值+1顺着consistenthash.keys找下一个索引位置的hashvalue，再从ring[hashvalue]得到nodes，遍历看是否有可用节点， 如果转了一圈了还没有合适的，就应该退出了，当然也可以限制最大重试次数 另外要注意，之前遍历到的失败的节点，下次从虚节点找到对应物理节点时，应检查物理节点是否是已经排除过的，是的话就没必要重试了。    go-zero中一致性hash实现源码阅读 # 定义 # type ConsistentHash struct { hashFunc Func replicas int keys []uint64 ring map[uint64][]interface{} nodes map[string]lang.PlaceholderType lock sync.RWMutex }   hashFunc是自定义的hash函数 replicas表示每个物理节点对应的虚节点数量 keys其实就是一致性hash环的表示，记录了虚节点对应的hash值，有序 ring其实是hash值到一组虚节点的映射，它其实是为了解决hash冲突来的  准确地说，keys+ring构成了一致性hash环，查找hash(key)对应的虚节点时，先在keys中找到\u0026gt;=hash(key)的虚节点对应的hash值， 然后，通过hash值到ring中找对应的虚节点 因为可能有冲突，所以map[k]v这里的v是一个slice   nodes中记录了当前添加了哪些物理节点，但是这里的map[k]v，k是节点描述信息，可以简单理解成node.String()，v是struct{}  这个一致性hash的设计还是不错的。\nAdd/AddWithReplicas/AddWithWeight # 添加新节点的时候，大致就是这几个函数，逻辑是什么呢？\n 先获取待添加节点的一个描述信息，如String()，然后记录到nodes中，表示记录了这个节点 然后呢，根据设置的虚节点数量，for循环，每次在描述信息后面添加数字后缀，计算hash，然后记录到keys、ring里面 前面提过了，keys+ring共同构成了一致性hash环  Get # 根据key获取节点的时候呢？\n 先计算key的hash，然后从keys中找第一个\u0026gt;=hash(key)的位置，这个位置对应的hash即为候选虚节点的hash， 然后通过虚节点的hash去ring里面找，ring里面是个slice，是为了解决散列冲突的， 怎么从这个slice中取呢，重新hash一次，从这个slice里面选一个  继续优化 # ring-based一致性hash的均匀性还可以继续优化，比如从hash函数的选择方面，虚节点数量的选择方面。\n以下是10个物理节点，均匀的100w userid，在不同虚节点数量、hash函数选择情况下的测试情况：\ncase: replicas:50+hash:murmur3.Sum64 标准方差: 14628.560790453721 max: 126737 min: 76395 (max-min)/times: 0.050342 peak/mean: 1.26737 case: replicas:100+hash:murmur3.Sum64 标准方差: 14555.295022774357 max: 127129 min: 76438 (max-min)/times: 0.050691 peak/mean: 1.27129 * case: replicas:200+hash:murmur3.Sum64 标准方差: 6902.00454940447 max: 110178 min: 85121 (max-min)/times: 0.025057 peak/mean: 1.10178 case: replicas:500+hash:murmur3.Sum64 标准方差: 2285.3205902017335 max: 105277 min: 97136 (max-min)/times: 0.008141 peak/mean: 1.05277 case: replicas:1000+hash:murmur3.Sum64 标准方差: 2069.765928794848 max: 104603 min: 97606 (max-min)/times: 0.006997 peak/mean: 1.04603 case: replicas:2000+hash:murmur3.Sum64 标准方差: 2618.900303562547 max: 104628 min: 94870 (max-min)/times: 0.009758 peak/mean: 1.04628 case: replicas:50+hash:xxhash.Sum64 标准方差: 8627.559643375409 max: 119229 min: 91110 (max-min)/times: 0.028119 peak/mean: 1.19229 case: replicas:100+hash:xxhash.Sum64 标准方差: 8918.29840272235 max: 120236 min: 90692 (max-min)/times: 0.029544 peak/mean: 1.20236 * case: replicas:200+hash:xxhash.Sum64 标准方差: 5913.828556865679 max: 111947 min: 89811 (max-min)/times: 0.022136 peak/mean: 1.11947 case: replicas:500+hash:xxhash.Sum64 标准方差: 4256.551350565384 max: 107631 min: 93326 (max-min)/times: 0.014305 peak/mean: 1.07631 case: replicas:1000+hash:xxhash.Sum64 标准方差: 3148.5766943176086 max: 106134 min: 95150 (max-min)/times: 0.010984 peak/mean: 1.06134 case: replicas:2000+hash:xxhash.Sum64 标准方差: 1664.1786562746202 max: 103375 min: 96885 (max-min)/times: 0.00649 peak/mean: 1.03375 case: replicas:100+hash:crc32.ChecksumIEEE 标准方差: 16188.201024202783 max: 121890 min: 69629 (max-min)/times: 0.052261 peak/mean: 1.2189 case: replicas:200+hash:crc32.ChecksumIEEE 标准方差: 11440.727826497754 max: 126050 min: 82970 (max-min)/times: 0.04308 peak/mean: 1.2605 * case: replicas:500+hash:crc32.ChecksumIEEE 标准方差: 17259.726985094523 max: 130659 min: 69507 (max-min)/times: 0.061152 peak/mean: 1.30659 case: replicas:1000+hash:crc32.ChecksumIEEE 标准方差: 21791.261533009052 max: 137256 min: 72892 (max-min)/times: 0.064364 peak/mean: 1.37256 case: replicas:2000+hash:crc32.ChecksumIEEE 标准方差: 12953.256825987819 max: 120299 min: 73664 (max-min)/times: 0.046635 peak/mean: 1.20299  不难看出： xxhash的均匀性首先比较好，在100个虚节点（这个一般是比较常用的经验值）时，最大最小负载偏差2.9%，peak/mean比为1.20\n总结 # 本文从一致性hash负载均衡策略触发，深入了解了下不同的方案变体，最后针对普适应更好的一致性hash方案、go-zero实现、实践中的引用改进进行了探索介绍。\n"}),a.add({id:135,href:"/tags/kmemcheck/",title:"kmemcheck",description:"",content:""}),a.add({id:136,href:"/tags/kmemleak/",title:"kmemleak",description:"",content:""}),a.add({id:137,href:"/blog/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%86%85%E5%AD%98%E9%97%AE%E9%A2%98%E6%A3%80%E6%9F%A5/",title:"内核中的内存检查工具",description:"kmemcheck.txt # kmemcheck用于内核的未初始化内存的动态检测，它工作在内核态，与工作在用户态的 memcheck实现机制不同。虽然kmemcheck不如memcheck精确，但是已经足够使用的了。此外，kmemcheck会使用更多的内存，增加系统负载，仅适合用于内核的调试。\nkmemleak.txt # kmemleak是一个工作在内核态，用于检测内核中内存泄漏的工具，与工作在用户态的内存泄漏检测工具memcheck加参数\u0026ndash;leak-check工作时效果类似。\n为了加深对内存管理的理解，应该查看下这两个工具的源代码。",content:"kmemcheck.txt # kmemcheck用于内核的未初始化内存的动态检测，它工作在内核态，与工作在用户态的 memcheck实现机制不同。虽然kmemcheck不如memcheck精确，但是已经足够使用的了。此外，kmemcheck会使用更多的内存，增加系统负载，仅适合用于内核的调试。\nkmemleak.txt # kmemleak是一个工作在内核态，用于检测内核中内存泄漏的工具，与工作在用户态的内存泄漏检测工具memcheck加参数\u0026ndash;leak-check工作时效果类似。\n为了加深对内存管理的理解，应该查看下这两个工具的源代码。\n"}),a.add({id:138,href:"/tags/jprobe/",title:"jprobe",description:"",content:""}),a.add({id:139,href:"/tags/kprobe/",title:"kprobe",description:"",content:""}),a.add({id:140,href:"/tags/rprobe/",title:"rprobe",description:"",content:""}),a.add({id:141,href:"/blog/%E5%86%85%E6%A0%B8%E6%8E%A2%E9%92%88/",title:"内核探针kprobe工作原理",description:"内核为方便调试引入了内核探针，主要有3种，kprobe/jprobe/rprobe，我们重点关注kprobe的工作原理，这个理解了，其他几种探针工作原理很容易就能脑补出来。",content:"内核探针 # 内核中用来方便调试的探针（probe）主要有以下几种：\n kprobe，可以对任意指令地址处安装探针 jprobe，可以对函数入口地址处安装探针，方便获取参数信息 rprobe，或者称为retprobe，顾名思义，主要用来观察retvalue  这几种探针的实现原理大同小异，详细的工作原理可以参考 kprobes.rst。\nkprobe工作原理 # 联想下调试器中断点的工作方式，kprobe可以通过断点的形式来实现：\n 记录目标地址addr处的原始一字节指令 将目标地址处的指令替换为0xcc（int3就是软件断点），并注册该地址处对应的kprobe，kprobe应该包含了pre_handler/post_handler int3对应的中断服务处理程序中，有一段代码是要执行对应的kprobe的pre_handler； 将原addr处的一字节指令恢复，然后改成singlestep执行完下条指令； 执行完这个函数中的所有指令，执行完返回后继续执行post_handler 然后直接continue  我说的这个过程不一定精确，但是大致可以这么实现。这种方法可能效率会有点低下，kprobes.rst中也有些优化的思路，我这里没有仔细去看。\n我感兴趣的就是，内核里面的kprobe和调试器中的大致跟踪tracee执行过程，很类似。\n相同点：都是通过指令patch的方式\n不同点：\n kprobe是利用了int3指令触发trap服务程序走到了kprobe的处理逻辑去执行pre_handler/post_handler， 而调试器是tracee执行到断点时触发trap服务程序走到了通知tracer继续控制tracee这个逻辑。  总结 # 简要总结了下kprobe这种内核探针的工作原理。\n"}),a.add({id:142,href:"/tags/destructor/",title:"destructor",description:"",content:""}),a.add({id:143,href:"/tags/kobject/",title:"kobject",description:"",content:""}),a.add({id:144,href:"/tags/kref/",title:"kref",description:"",content:""}),a.add({id:145,href:"/blog/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86kobject%E4%B8%8Ekref/",title:"kref引用计数与kobject对象管理",description:"看完kref/kobject这几篇文档，更深地明白了一个道理，“能工模型，巧匠窃意”、“无招胜有招”，编程思想和编程工具是相辅相成的，前者帮助完善后者，后者便于更简单地推广前者。纵使是c语言这样的过程式编程语言，在牛人手里也可以提炼面向对象的精髓来建构更复杂的软件世界。",content:"kref # kref可以为你自定义的结构体提供一个引用计数器，kobject也可以实 现该功能，但是kobject比较复杂，如果只是提供一个简单的引用计数器的话，应该使用 kref而不是kobject。\nkref可以嵌入在我们定义的结构体struct中，当我们初始化一个结构体时通过kref_init对其进行初始化（引用计数为1），当我们引用这个struct时需要通过kref_get来增加其引用计数，而当我们不再引用这个struct时，我们可以通过kref_put来减少引用计数，同时还可以提供一个data_release的函数，当引用计数为0时该函数就会执行。\nkref非常类似于c++中的智能指针的功能，gcc编译期对c语言也增加了一些类似的属性扩展，允许在变量作用域结束时执行注册的函数。可见，自定义类型中通过恰当地使用kref，我们就可以实现近似上述c++智能指针等高阶玩法。\nsee kref.rst\nkobject # kobject又是什么呢，在面向对象领域中，对象有继承关系，派生对象需要实现抽象基类的方法，对象在没有被引用时也应该被自动销毁（联想c++析构函数）等。面向对象的那些思想在内核里面又是怎么样一种表现形式。\n无招胜有招，c虽然是过程式编程语言，但是其依然可以写出面向对象的代码来对完成对大型软件项目的设计构建。\n我们一般将kobject嵌入自定义的类型struct中来使用，同时还有对应的一个ktype：\n kobject，具备了引用计数功能，通过kobject_init/get/put操作可以对引用计数进行操作，另外kobject还有parent指针用来构建对象间的层级关系； ktype，用来描述每个kobject对象引用计数减为0时应该对这个包含kobject成员的struct类型执行何种操作，比如如何清理、释放之类的；  ps：kset可以看做是一个集合，用来管理一系列的kobject，使用场景见kobject.rst。\nsee kobject.rst\n总结 # 看完这几篇文档，更深地明白了一个道理，“能工模型，巧匠窃意”、“无招胜有招”，编程思想和编程工具是相辅相成的，前者帮助完善后者，后者便于更简单地推广前者。纵使是c语言这样的过程式编程语言，在牛人手里也可以提炼面向对象的精髓来建构更复杂的软件世界。\n"}),a.add({id:146,href:"/tags/refcount/",title:"refcount",description:"",content:""}),a.add({id:147,href:"/tags/smartpointer/",title:"smartpointer",description:"",content:""}),a.add({id:148,href:"/tags/books/",title:"books",description:"",content:""}),a.add({id:149,href:"/tags/docs/",title:"docs",description:"",content:""}),a.add({id:150,href:"/blog/%E5%AD%A6%E4%B9%A0%E8%B5%84%E6%96%99/",title:"Linux内核学习资料",description:"现在学习Linux操作系统的人越来越多了，进一步学习Kernel的人也越来越多了，经常有人问起有没有质量好的、获得大家认可的学习资料论坛，尤其是对于学习内核的新手而言，能否获得这些好的学习资料还是很重要的。因为经常有人问起这个问题，所以在Linux源码随附的文档中，有专门一篇文档kernel-docs.rst专门整理罗列了适合大家学习Linux内核的文档、在线资源、出版书籍等，并逐一做了简要的描述。注意到其中有些资料是和具体内核模块相关的，如网络协议栈、中断子系统等，也适合有针对性地、深入地去学习。",content:"现在学习Linux操作系统的人越来越多了，进一步学习Kernel的人也越来越多了，经常有人问起有没有质量好的、获得大家认可的学习资料论坛，尤其是对于学习内核的新手而言，能否获得这些好的学习资料还是很重要的。因为经常有人问起这个问题，所以在Linux源码随附的文档中，有专门一篇文档kernel-docs.rst专门整理罗列了适合大家学习Linux内核的文档、在线资源、出版书籍等，并逐一做了简要的描述。注意到其中有些资料是和具体内核模块相关的，如网络协议栈、中断子系统等，也适合有针对性地、深入地去学习。\n本文剩余内容来自Linux内核文档 kernel-docs.rst，整理在此方便查阅参考。\nDocs at the Linux Kernel tree # The Sphinx books should be built with make {htmldocs | pdfdocs | epubdocs}.\n* Name: **linux/Documentation** :Author: Many. :Location: Documentation/ :Keywords: text files, Sphinx. :Description: Documentation that comes with the kernel sources, inside the Documentation directory. Some pages from this document (including this document itself) have been moved there, and might be more up to date than the web version.  On-line docs # * Title: **Linux Kernel Mailing List Glossary** :Author: various :URL: https://kernelnewbies.org/KernelGlossary :Date: rolling version :Keywords: glossary, terms, linux-kernel. :Description: From the introduction: \u0026quot;This glossary is intended as a brief description of some of the acronyms and terms you may hear during discussion of the Linux kernel\u0026quot;. * Title: **Tracing the Way of Data in a TCP Connection through the Linux Kernel** :Author: Richard Sailer :URL: https://archive.org/details/linux_kernel_data_flow_short_paper :Date: 2016 :Keywords: Linux Kernel Networking, TCP, tracing, ftrace :Description: A seminar paper explaining ftrace and how to use it for understanding linux kernel internals, illustrated at tracing the way of a TCP packet through the kernel. :Abstract: *This short paper outlines the usage of ftrace a tracing framework as a tool to understand a running Linux system. Having obtained a trace-log a kernel hacker can read and understand source code more determined and with context. In a detailed example this approach is demonstrated in tracing and the way of data in a TCP Connection through the kernel. Finally this trace-log is used as base for more a exact conceptual exploration and description of the Linux TCP/IP implementation.* * Title: **On submitting kernel Patches** :Author: Andi Kleen :URL: http://halobates.de/on-submitting-kernel-patches.pdf :Date: 2008 :Keywords: patches, review process, types of submissions, basic rules, case studies :Description: This paper gives several experience values on what types of patches there are and how likely they get merged. :Abstract: [...]. This paper examines some common problems for submitting larger changes and some strategies to avoid problems. * Title: **Linux Device Drivers, Third Edition** :Author: Jonathan Corbet, Alessandro Rubini, Greg Kroah-Hartman :URL: https://lwn.net/Kernel/LDD3/ :Date: 2005 :Description: A 600-page book covering the (2.6.10) driver programming API and kernel hacking in general. Available under the Creative Commons Attribution-ShareAlike 2.0 license. :note: You can also :ref:`purchase a copy from O'Reilly or elsewhere \u0026lt;ldd3_published\u0026gt;`. * Title: **Writing an ALSA Driver** :Author: Takashi Iwai \u0026lt;tiwai@suse.de\u0026gt; :URL: http://www.alsa-project.org/~iwai/writing-an-alsa-driver/index.html :Date: 2005 :Keywords: ALSA, sound, soundcard, driver, lowlevel, hardware. :Description: Advanced Linux Sound Architecture for developers, both at kernel and user-level sides. ALSA is the Linux kernel sound architecture in the 2.6 kernel version. * Title: **Linux PCMCIA Programmer's Guide** :Author: David Hinds. :URL: http://pcmcia-cs.sourceforge.net/ftp/doc/PCMCIA-PROG.html :Date: 2003 :Keywords: PCMCIA. :Description: \u0026quot;This document describes how to write kernel device drivers for the Linux PCMCIA Card Services interface. It also describes how to write user-mode utilities for communicating with Card Services. * Title: **The Linux Kernel Module Programming Guide** :Author: Peter Jay Salzman, Michael Burian, Ori Pomerantz, Bob Mottram, Jim Huang. :URL: https://sysprog21.github.io/lkmpg/ :Date: 2021 :Keywords: modules, GPL book, /proc, ioctls, system calls, interrupt handlers . :Description: A very nice GPL book on the topic of modules programming. Lots of examples. Currently the new version is being actively maintained at https://github.com/sysprog21/lkmpg. * Title: **Global spinlock list and usage** :Author: Rick Lindsley. :URL: http://lse.sourceforge.net/lockhier/global-spin-lock :Date: 2001 :Keywords: spinlock. :Description: This is an attempt to document both the existence and usage of the spinlocks in the Linux 2.4.5 kernel. Comprehensive list of spinlocks showing when they are used, which functions access them, how each lock is acquired, under what conditions it is held, whether interrupts can occur or not while it is held... * Title: **A Linux vm README** :Author: Kanoj Sarcar. :URL: http://kos.enix.org/pub/linux-vmm.html :Date: 2001 :Keywords: virtual memory, mm, pgd, vma, page, page flags, page cache, swap cache, kswapd. :Description: Telegraphic, short descriptions and definitions relating the Linux virtual memory implementation. * Title: **Video4linux Drivers, Part 1: Video-Capture Device** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/406 :Date: 2000 :Keywords: video4linux, driver, video capture, capture devices, camera driver. :Description: The title says it all. * Title: **Video4linux Drivers, Part 2: Video-capture Devices** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/429 :Date: 2000 :Keywords: video4linux, driver, video capture, capture devices, camera driver, control, query capabilities, capability, facility. :Description: The title says it all. * Title: **Linux IP Networking. A Guide to the Implementation and Modification of the Linux Protocol Stack.** :Author: Glenn Herrin. :URL: http://www.cs.unh.edu/cnrg/gherrin :Date: 2000 :Keywords: network, networking, protocol, IP, UDP, TCP, connection, socket, receiving, transmitting, forwarding, routing, packets, modules, /proc, sk_buff, FIB, tags. :Description: Excellent paper devoted to the Linux IP Networking, explaining anything from the kernel's to the user space configuration tools' code. Very good to get a general overview of the kernel networking implementation and understand all steps packets follow from the time they are received at the network device till they are delivered to applications. The studied kernel code is from 2.2.14 version. Provides code for a working packet dropper example. * Title: **How To Make Sure Your Driver Will Work On The Power Macintosh** :Author: Paul Mackerras. :URL: http://www.linux-mag.com/id/261 :Date: 1999 :Keywords: Mac, Power Macintosh, porting, drivers, compatibility. :Description: The title says it all. * Title: **An Introduction to SCSI Drivers** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/284 :Date: 1999 :Keywords: SCSI, device, driver. :Description: The title says it all. * Title: **Advanced SCSI Drivers And Other Tales** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/307 :Date: 1999 :Keywords: SCSI, device, driver, advanced. :Description: The title says it all. * Title: **Writing Linux Mouse Drivers** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/330 :Date: 1999 :Keywords: mouse, driver, gpm. :Description: The title says it all. * Title: **More on Mouse Drivers** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/356 :Date: 1999 :Keywords: mouse, driver, gpm, races, asynchronous I/O. :Description: The title still says it all. * Title: **Writing Video4linux Radio Driver** :Author: Alan Cox. :URL: http://www.linux-mag.com/id/381 :Date: 1999 :Keywords: video4linux, driver, radio, radio devices. :Description: The title says it all. * Title: **I/O Event Handling Under Linux** :Author: Richard Gooch. :URL: https://web.mit.edu/~yandros/doc/io-events.html :Date: 1999 :Keywords: IO, I/O, select(2), poll(2), FDs, aio_read(2), readiness event queues. :Description: From the Introduction: \u0026quot;I/O Event handling is about how your Operating System allows you to manage a large number of open files (file descriptors in UNIX/POSIX, or FDs) in your application. You want the OS to notify you when FDs become active (have data ready to be read or are ready for writing). Ideally you want a mechanism that is scalable. This means a large number of inactive FDs cost very little in memory and CPU time to manage\u0026quot;. * Title: **(nearly) Complete Linux Loadable Kernel Modules. The definitive guide for hackers, virus coders and system administrators.** :Author: pragmatic/THC. :URL: http://packetstormsecurity.org/docs/hack/LKM_HACKING.html :Date: 1999 :Keywords: syscalls, intercept, hide, abuse, symbol table. :Description: Interesting paper on how to abuse the Linux kernel in order to intercept and modify syscalls, make files/directories/processes invisible, become root, hijack ttys, write kernel modules based virus... and solutions for admins to avoid all those abuses. :Notes: For 2.0.x kernels. Gives guidances to port it to 2.2.x kernels. * Name: **Linux Virtual File System** :Author: Peter J. Braam. :URL: http://www.coda.cs.cmu.edu/doc/talks/linuxvfs/ :Date: 1998 :Keywords: slides, VFS, inode, superblock, dentry, dcache. :Description: Set of slides, presumably from a presentation on the Linux VFS layer. Covers version 2.1.x, with dentries and the dcache. * Title: **The Venus kernel interface** :Author: Peter J. Braam. :URL: http://www.coda.cs.cmu.edu/doc/html/kernel-venus-protocol.html :Date: 1998 :Keywords: coda, filesystem, venus, cache manager. :Description: \u0026quot;This document describes the communication between Venus and kernel level file system code needed for the operation of the Coda filesystem. This version document is meant to describe the current interface (version 1.0) as well as improvements we envisage\u0026quot;. * Title: **Design and Implementation of the Second Extended Filesystem** :Author: Rémy Card, Theodore Ts'o, Stephen Tweedie. :URL: https://web.mit.edu/tytso/www/linux/ext2intro.html :Date: 1998 :Keywords: ext2, linux fs history, inode, directory, link, devices, VFS, physical structure, performance, benchmarks, ext2fs library, ext2fs tools, e2fsck. :Description: Paper written by three of the top ext2 hackers. Covers Linux filesystems history, ext2 motivation, ext2 features, design, physical structure on disk, performance, benchmarks, e2fsck's passes description... A must read! :Notes: This paper was first published in the Proceedings of the First Dutch International Symposium on Linux, ISBN 90-367-0385-9. * Title: **The Linux RAID-1, 4, 5 Code** :Author: Ingo Molnar, Gadi Oxman and Miguel de Icaza. :URL: http://www.linuxjournal.com/article.php?sid=2391 :Date: 1997 :Keywords: RAID, MD driver. :Description: Linux Journal Kernel Korner article. :Abstract: *A description of the implementation of the RAID-1, RAID-4 and RAID-5 personalities of the MD device driver in the Linux kernel, providing users with high performance and reliable, secondary-storage capability using software*. * Title: **Linux Kernel Hackers' Guide** :Author: Michael K. Johnson. :URL: https://www.tldp.org/LDP/khg/HyperNews/get/khg.html :Date: 1997 :Keywords: device drivers, files, VFS, kernel interface, character vs block devices, hardware interrupts, scsi, DMA, access to user memory, memory allocation, timers. :Description: A guide designed to help you get up to speed on the concepts that are not intuitively obvious, and to document the internal structures of Linux. * Title: **Dynamic Kernels: Modularized Device Drivers** :Author: Alessandro Rubini. :URL: http://www.linuxjournal.com/article.php?sid=1219 :Date: 1996 :Keywords: device driver, module, loading/unloading modules, allocating resources. :Description: Linux Journal Kernel Korner article. :Abstract: *This is the first of a series of four articles co-authored by Alessandro Rubini and Georg Zezchwitz which present a practical approach to writing Linux device drivers as kernel loadable modules. This installment presents an introduction to the topic, preparing the reader to understand next month's installment*. * Title: **Dynamic Kernels: Discovery** :Author: Alessandro Rubini. :URL: http://www.linuxjournal.com/article.php?sid=1220 :Date: 1996 :Keywords: character driver, init_module, clean_up module, autodetection, mayor number, minor number, file operations, open(), close(). :Description: Linux Journal Kernel Korner article. :Abstract: *This article, the second of four, introduces part of the actual code to create custom module implementing a character device driver. It describes the code for module initialization and cleanup, as well as the open() and close() system calls*. * Title: **The Devil's in the Details** :Author: Georg v. Zezschwitz and Alessandro Rubini. :URL: http://www.linuxjournal.com/article.php?sid=1221 :Date: 1996 :Keywords: read(), write(), select(), ioctl(), blocking/non blocking mode, interrupt handler. :Description: Linux Journal Kernel Korner article. :Abstract: *This article, the third of four on writing character device drivers, introduces concepts of reading, writing, and using ioctl-calls*. * Title: **Dissecting Interrupts and Browsing DMA** :Author: Alessandro Rubini and Georg v. Zezschwitz. :URL: https://www.linuxjournal.com/article.php?sid=1222 :Date: 1996 :Keywords: interrupts, irqs, DMA, bottom halves, task queues. :Description: Linux Journal Kernel Korner article. :Abstract: *This is the fourth in a series of articles about writing character device drivers as loadable kernel modules. This month, we further investigate the field of interrupt handling. Though it is conceptually simple, practical limitations and constraints make this an ''interesting'' part of device driver writing, and several different facilities have been provided for different situations. We also investigate the complex topic of DMA*. * Title: **Device Drivers Concluded** :Author: Georg v. Zezschwitz. :URL: https://www.linuxjournal.com/article.php?sid=1287 :Date: 1996 :Keywords: address spaces, pages, pagination, page management, demand loading, swapping, memory protection, memory mapping, mmap, virtual memory areas (VMAs), vremap, PCI. :Description: Finally, the above turned out into a five articles series. This latest one's introduction reads: \u0026quot;This is the last of five articles about character device drivers. In this final section, Georg deals with memory mapping devices, beginning with an overall description of the Linux memory management concepts\u0026quot;. * Title: **Network Buffers And Memory Management** :Author: Alan Cox. :URL: https://www.linuxjournal.com/article.php?sid=1312 :Date: 1996 :Keywords: sk_buffs, network devices, protocol/link layer variables, network devices flags, transmit, receive, configuration, multicast. :Description: Linux Journal Kernel Korner. :Abstract: *Writing a network device driver for Linux is fundamentally simple---most of the complexity (other than talking to the hardware) involves managing network packets in memory*. * Title: **Analysis of the Ext2fs structure** :Author: Louis-Dominique Dubeau. :URL: https://teaching.csse.uwa.edu.au/units/CITS2002/fs-ext2/ :Date: 1994 :Keywords: ext2, filesystem, ext2fs. :Description: Description of ext2's blocks, directories, inodes, bitmaps, invariants...  Published books # * Title: **Linux Treiber entwickeln** :Author: Jürgen Quade, Eva-Katharina Kunst :Publisher: dpunkt.verlag :Date: Oct 2015 (4th edition) :Pages: 688 :ISBN: 978-3-86490-288-8 :Note: German. The third edition from 2011 is much cheaper and still quite up-to-date. * Title: **Linux Kernel Networking: Implementation and Theory** :Author: Rami Rosen :Publisher: Apress :Date: December 22, 2013 :Pages: 648 :ISBN: 978-1430261964 * Title: **Embedded Linux Primer: A practical Real-World Approach, 2nd Edition** :Author: Christopher Hallinan :Publisher: Pearson :Date: November, 2010 :Pages: 656 :ISBN: 978-0137017836 * Title: **Linux Kernel Development, 3rd Edition** :Author: Robert Love :Publisher: Addison-Wesley :Date: July, 2010 :Pages: 440 :ISBN: 978-0672329463 * Title: **Essential Linux Device Drivers** :Author: Sreekrishnan Venkateswaran :Published: Prentice Hall :Date: April, 2008 :Pages: 744 :ISBN: 978-0132396554 * Title: **Linux Device Drivers, 3rd Edition** :Authors: Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman :Publisher: O'Reilly \u0026amp; Associates :Date: 2005 :Pages: 636 :ISBN: 0-596-00590-3 :Notes: Further information in http://www.oreilly.com/catalog/linuxdrive3/ PDF format, URL: https://lwn.net/Kernel/LDD3/ * Title: **Linux Kernel Internals** :Author: Michael Beck :Publisher: Addison-Wesley :Date: 1997 :ISBN: 0-201-33143-8 (second edition) * Title: **Programmation Linux 2.0 API systeme et fonctionnement du noyau** :Author: Remy Card, Eric Dumas, Franck Mevel :Publisher: Eyrolles :Date: 1997 :Pages: 520 :ISBN: 2-212-08932-5 :Notes: French * Title: **The Design and Implementation of the 4.4 BSD UNIX Operating System** :Author: Marshall Kirk McKusick, Keith Bostic, Michael J. Karels, John S. Quarterman :Publisher: Addison-Wesley :Date: 1996 :ISBN: 0-201-54979-4 * Title: **Unix internals -- the new frontiers** :Author: Uresh Vahalia :Publisher: Prentice Hall :Date: 1996 :Pages: 600 :ISBN: 0-13-101908-2 * Title: **Programming for the real world - POSIX.4** :Author: Bill O. Gallmeister :Publisher: O'Reilly \u0026amp; Associates, Inc :Date: 1995 :Pages: 552 :ISBN: I-56592-074-0 :Notes: Though not being directly about Linux, Linux aims to be POSIX. Good reference. * Title: **UNIX Systems for Modern Architectures: Symmetric Multiprocessing and Caching for Kernel Programmers** :Author: Curt Schimmel :Publisher: Addison Wesley :Date: June, 1994 :Pages: 432 :ISBN: 0-201-63338-8 * Title: **The Design and Implementation of the 4.3 BSD UNIX Operating System** :Author: Samuel J. Leffler, Marshall Kirk McKusick, Michael J Karels, John S. Quarterman :Publisher: Addison-Wesley :Date: 1989 (reprinted with corrections on October, 1990) :ISBN: 0-201-06196-1 * Title: **The Design of the UNIX Operating System** :Author: Maurice J. Bach :Publisher: Prentice Hall :Date: 1986 :Pages: 471 :ISBN: 0-13-201757-1  Miscellaneous # * Name: **Cross-Referencing Linux** :URL: https://elixir.bootlin.com/ :Keywords: Browsing source code. :Description: Another web-based Linux kernel source code browser. Lots of cross references to variables and functions. You can see where they are defined and where they are used. * Name: **Linux Weekly News** :URL: https://lwn.net :Keywords: latest kernel news. :Description: The title says it all. There's a fixed kernel section summarizing developers' work, bug fixes, new features and versions produced during the week. Published every Thursday. * Name: **The home page of Linux-MM** :Author: The Linux-MM team. :URL: https://linux-mm.org/ :Keywords: memory management, Linux-MM, mm patches, TODO, docs, mailing list. :Description: Site devoted to Linux Memory Management development. Memory related patches, HOWTOs, links, mm developers... Don't miss it if you are interested in memory management development! * Name: **Kernel Newbies IRC Channel and Website** :URL: https://www.kernelnewbies.org :Keywords: IRC, newbies, channel, asking doubts. :Description: #kernelnewbies on irc.oftc.net. #kernelnewbies is an IRC network dedicated to the 'newbie' kernel hacker. The audience mostly consists of people who are learning about the kernel, working on kernel projects or professional kernel hackers that want to help less seasoned kernel people. #kernelnewbies is on the OFTC IRC Network. Try irc.oftc.net as your server and then /join #kernelnewbies. The kernelnewbies website also hosts articles, documents, FAQs... * Name: **linux-kernel mailing list archives and search engines** :URL: http://vger.kernel.org/vger-lists.html :URL: http://www.uwsg.indiana.edu/hypermail/linux/kernel/index.html :URL: http://groups.google.com/group/mlist.linux.kernel :Keywords: linux-kernel, archives, search. :Description: Some of the linux-kernel mailing list archivers. If you have a better/another one, please let me know.   "}),a.add({id:151,href:"/tags/balancing/",title:"balancing",description:"",content:""}),a.add({id:152,href:"/tags/irq/",title:"irq",description:"",content:""}),a.add({id:153,href:"/tags/nic/",title:"nic",description:"",content:""}),a.add({id:154,href:"/blog/irq-balancing/",title:"中断请求负载均衡",description:"在多CPU系统上，如何对设备的中断请求进行负载均衡，以提升中断处理效率。本文以多队列、单队列网卡为例介绍了中断的负载均衡方法。",content:"如果网卡NIC支持多队列，可以直接设置NIC多个队列的irq affinity到不同的CPU来实现负载均衡； 如果网卡NIC是单队列的，也可以通过RFS或者RPS在soft interrupt层面进行模拟，来实现负载均衡； RPS、RFS这种方式主要是针对单队列NIC的优化。\n我们是以网卡中断作为示例，对其他不同的设备其实也可以做类似处理。 并不是说所有的设备中断都需要绑定到多个cpu来实现负载均衡，因为有的外设的中断请求数可能并不多，就没必要了。\n多队列网卡ethtool -l eth0可以看到combined字段，该字段表明NIC有几个队列，如果有多个队列，比如8个， 那么对应的cpu affinity可以直接设置成ff，表示CPU0-7都可以收NIC中断请求来实现负载均衡。\nlspci -vvv可以看到不同的设备对应的中断号，如网卡设别可能是：pin A routed to IRQ 10，我们就知道10是其中断号。\nTODO:\n irq affinity设定了情况下，OS和硬件是如何交互的？如何负载均衡的，是在硬件层面实现的？ RPS/RFS，这种软中断层面的处理，具体细节是怎样的？  下面以多队列网卡为例来说明怎么回事。\n多队列网卡实现原理 # 1.硬件实现原理 # 下图是Intel 82575硬件逻辑图，有四个硬件队列。当收到报文时，通过hash包头的SIP、Sport、DIP、Dport四元组，将一条流总是收到相同的队列。同时触发与该队列绑定的中断。\n2.单队列驱动原理 # kernel从2.6.21版本之前不支持多队列特性，一个网卡只能申请一个中断号，因此同一个时刻只有一个核在处理网卡收到的包。如图2.1，协议栈通过NAPI轮询收取各个硬件queue中的报文到图2.2的net_device数据结构中，通过QDisc队列将报文发送到网卡。\n2.多队列驱动原理 # 2.6.21开始支持多队列特性，当网卡驱动加载时，通过获取的网卡型号，得到网卡的硬件queue的数量，并结合CPU核的数量，最终通过Sum=Min（网卡queue，CPU core）得出所要激活的网卡queue数量（Sum），并申请Sum个中断号，分配给激活的各个queue。\n如图3.1，当某个queue收到报文时，触发相应的中断，收到中断的核，将该任务加入到协议栈负责收包的该核的NET_RX_SOFTIRQ队列中（NET_RX_SOFTIRQ在每个核上都有一个实例），在NET_RX_SOFTIRQ中，调用NAPI的收包接口，将报文收到CPU中如图3.2的有多个netdev_queue的net_device数据结构中。\n这样，CPU的各个核可以并发的收包，就不会因为一个核不能满足需求，导致网络IO性能下降。\nRSS（Receive Side Scaling，网卡的硬件特性，多队列网卡将不同的流分发到不同的CPU上实现负载均衡）需要硬件支持，在不支持RSS的环境中，RPS/RFS提供了软件的解决方案。\n RPS（Receive Packet Steering）是把一个rx队列的软中断分发到多个CPU核上，从而达到负载均衡的目的。 RFS（Receive Flow Steering）是RPS的扩展，RPS只依靠hash来控制数据包，提供负载平衡，但是没有考虑到应用程序的位置（指应用程序所在CPU）。RFS目标是通过指派应用线程正在运行的CPU处理中断，增加数据缓存的命中率。  参考内容：\n"}),a.add({id:155,href:"/tags/affinity/",title:"affinity",description:"",content:""}),a.add({id:156,href:"/tags/interrupt/",title:"interrupt",description:"",content:""}),a.add({id:157,href:"/blog/irq-affinity/",title:"中断请求亲和性",description:"计算机硬件设备，有些通过中断的方式通知CPU有数据到达进而可以对其进行处理。那么这里设备的中断请求是如何发送到各个处理器的呢，是发送到所有的处理器，还是选择一个发送，有没有可能指定响应中断的CPU列表，即本文提到的中断请求的亲和性问题。Linux内核文档中irq-affinity.rst对此进行了描述，本文参照着文档对irq affinity进行设置、测试，加深理解。",content:"SMP IRQ affinity，指的是对称多处理器中的中断请求绑定。\n/proc/irq/IRQ#/smp_affinity和/proc/irq/IRQ#/smp_affinity_list指明了允许接收某 个中断请求IRQ#的多个或某个cpu。它是一个位掩码smp_affinity或者一个cpu列表 smp_affinity_list，其中记录了允许接受该中断请求的cpu。不允许禁止所有cpu接收该 中断请求，如果一个中断控制器不支持中断请求绑定，那么只能采用默认值，即允许所有 cpu接收该中断请求，并且这个值不会被修改。\n/proc/irq/default_smp_affinity指明了默认的中断绑定掩码，这个默认值将应用于所有 的非活动的、未激活的中断号。一旦一个中断号被分配、激活，那么它的中断绑定掩码将 被设置为这个默认值。这个默认值可以通过前面提到过的方法进行修改。这个默认掩码的 值为0xffffffff，请注意，该掩码是32位的。\n这里举个例子，网卡eth1中断请求IRQ44限定发送到CPU0-3，而后再限定发送到CPU4-7。\n网卡向cpu发中断请求44，下面我们对这个中断请求与cpu的绑定关系进行设置，并通过 ping命令进行测试，网卡会将接收到的icmp请求，以中断44的形式发送到绑定的cpu，通 过查看cpu接收到的中断请求数量，我们可以判断，这个44这个中断请求与cpu的绑定关系 。\n[root@moon 44]# cd /proc/irq/44 [root@moon 44]# cat smp_affinity ffffffff  首先，查看到44这个中断请求的默认绑定掩码为0xffffffff，说明，所有的cpu都可以接 收该中断请求。\n[root@moon 44]# echo 0f \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 0000000f  然后我们设置smp_affinity的值为0x0000000f，即使得编号为0-3的cpu允许接收该44这个 中断请求，其他的cpu都不会接收44这个中断请求。\n[root@moon 44]# ping -f h PING hell (195.4.7.3): 56 data bytes ... --- hell ping statistics --- 6029 packets transmitted, 6027 packets received, 0% packet loss round-trip min/avg/max = 0.1/0.1/0.4 ms  然后，对主机进行ping测试，这里的-f表示洪泛，h表示主机，实际测试的时候，可以修 改为localhost。这个时候，应用程序ping向主机发送了icmp请求包，网卡设备捕获到之 后，会向cpu发送中断号为44的中断请求。现在该主机上有8个cpu，由于我们设置了编号 为0-3的cpu可以接收该中断，其他的则不可以，那么如果我们查看cpu对中断44的接收情 况时，只有编号为0-3的cpu才能接收到中断请求。\n[root@moon 44]# cat /proc/interrupts | grep 'CPU\\|44:' CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 44: 1068 1785 1785 1783 0 0 0 0 IO-APIC-level eth1  通过查看测试结果，我们发现cpu 4-7 确实没有接收到编号为44的中断请求，但是编号 为0-3的cpu接收到了该中断请求。\n现在将其限定到CPU4-7上去：\n[root@moon 44]# echo f0 \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 000000f0  进一步进行测试，我们将允许接收编号44的中断请求的cpu设定为编号4-7，即将 smp_affinity的值设定为0x000000f0，下面再次通过ping进行测试。\n[root@moon 44]# ping -f h PING hell (195.4.7.3): 56 data bytes .. --- hell ping statistics --- 2779 packets transmitted, 2777 packets received, 0% packet loss round-trip min/avg/max = 0.1/0.5/585.4 ms [root@moon 44]# cat /proc/interrupts | 'CPU\\|44:' CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 44: 1068 1785 1785 1783 1784 1069 1070 1069 IO-APIC-level eth1  将当前cpu接收到的中断请求44的数量，与前面一次ping测试时各个cpu接收到的中断请求 44的数量对比发现，只有编号为4-7的cpu接收到的中断请求44的数量发生了改变，说明我 们成功的设置了中断请求44的中断绑定到cpu 4-7。\n如果想将中断请求限定发送到CPU1024-1031上，可以这么操作：\n[root@moon 44]# echo 1024-1031 \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 1024-1031  上面的语法可以将中断绑定到编号范围为1024-1031的cpu上。\nsee: irq affinity\n"}),a.add({id:158,href:"/tags/c/",title:"c",description:"",content:""}),a.add({id:159,href:"/tags/devcontainer/",title:"devcontainer",description:"",content:""}),a.add({id:160,href:"/tags/docker/",title:"docker",description:"",content:""}),a.add({id:161,href:"/tags/ide/",title:"ide",description:"",content:""}),a.add({id:162,href:"/blog/2022-06-28-linux-cc-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E8%AE%BE%E7%BD%AE/",title:"mac/win下linux c/c++开发",description:"Linux C/C++开发是很多后台开发同学必备的一项技能，虽然现在Java、Go等跨平台语言的崛起也吸引了很多开发者，在某些业务中得到了大量的实践，但是C/C++依然是被广泛使用的。据我观察，进行Linux C/C++开发时在工具支持上还是没有Java、Go等开发起来方便，比如这个跨平台开发Linux C/C++程序的问题，头文件、库等等地怎么配置着，编译测试怎么玩着，说真的，我看了有些同事的做法真的头大，特别原始。本文就这个问题进行一点调研、总结，也为日后可能的类似开发工作做一些准备。",content:"问题背景 # 我们很多人主力操作系统是macOS或者Windows，用Linux作为主力操作系统的少吧，不过之前确实有连续7年多是用Fedora作为主力操作系统 :)\n现在很多人开发人员使用MacBook Pro作为自己的开发机，大厂标配，我们很多后台呢，开发的程序一般最后还是要跑在Linux系统上的，尤其是c/c++开发涉及到这里的跨平台开发的问题，很多开发人员用着非常原始的方式在开发，开发体验比较差。\n借这个契机，我调研了下现在比较好的一些开发方式，总结分享下。\n先定一个要实现的小目标：\n 能基于IDE进行开发，比如VSCode; 另外，编译构建必须能够  vscode: add dockerfile to workspace #  在vscode中cmd+p，输入add dockerfile to workspace并执行，此时会选择基础镜像，如面向c++开发的基础镜像，此时会生成默认的dockerfile。 然后在dockerfile选中后点击右键，选择build image，此时就完成镜像构建了，该默认dockerfile默认是一个编译镜像，里面包含了编译构建产物。 直接运行上述镜像默认就是运行程序，运行的方式可以在docker explorer里面找到镜像，右键菜单中选择Run，或者命令行执行。  这个镜像只是用来编译构建、测试运行的，还不能满足我们开发阶段的需求，因为开发阶段需要考虑头文件、库的搜索问题。\n解决思路：\n 至少要构建一个支持开发的镜像，如c/c++镜像； 启动这个镜像，并将当前工程以volume的形式挂在到容器中，或者在容器中clone下来这个项目。提交代码要注意随时提交； 开发通过vscode remote连接到vscode server进行开发，其实是本地vscode通过ssh连接传输vscode server软件包到容器中并安装启动； 如果开发镜像支持类似WebIDE的方式进行开发，也可以代替3这种方式，只是一些本地vscode的快捷配置等可能不是很好同步。  docker desktop: New Dev environment # Docker Desktop的这种实现方式，就是上面提到的2\\3这几步的组合，基本满足我们希望实现的目标了（支持开发容器Mount local directory或者容器中Clone git repository）。\n这种方式也有不足，就是假设后续有人要接手这个项目，或者有人和你协作，你怎么办呢？ 我们可以直接提交一个镜像push到registry，他只要能拉代码，又能拉镜像就基本能还原之前的开发环境。\n但是我为什么非要push一个镜像上去呢（包括自定义的基础镜像、开发阶段的分享镜像）？ 如果不push镜像而docker destop默认的开发镜像调整了或者我希望定制一个统一的怎么办？\nDocker Desktop创建新的开发镜像的时候有一种方式，允许指定一个基础镜像，但是这个基础镜像要push到远程registry。代码会被clone到这个 容器内部，我们就通过vscode remote进行开发即可。\n尽管vscode鼓励非Linux用户尽量通过这种方式，因为fs操作更快，但是还是有点不方便，因为这数据卷相当于额外浪费一份存储，考虑到之前已经克隆过的情况下。 有没有办法既能自定义基础镜像，又能挂载本地磁盘目录为数据卷的方式来解决呢？可以，请看方式3。\nvscode: Remote-Containers # vscode中Command Pallete中Remote-Containers: Add Development Container Configuration Files，执行这个我们可以为工程指定一个配置文件.devcontainer(实际是个目录)，.devcontainer/devcontainer.json中指明了我们要使用哪个镜像作为开发容器的基础镜像。 这里的基础镜像可以用vscode官方提供的，也可以是自己自定义好push到registry的，也可以是Dockerfile需要vscode代为构建本地镜像的，这几种方式均可！\n这样不就方便了吗，既不需要额外存储这个基础镜像，还保留了维护基础镜像的必要配置信息，如Dockerfile等。当然了如果基础镜像维护得当，我们引用registry 中的基础镜像即可，没必要每个工程下都放一份镜像Dockerfile信息。\n我目前比较喜欢这种方式，因为可以使用自定义基础镜像的同时，没有了额外容器中克隆代码导致的占用磁盘空间问题……不过这样性能会差点。\nWebIDE: 基于WebIDE的开发环境 # 在开发容器中支持WebIDE，github的codespace，以及gitpod就是类似的解决方案，我自己也基于开源的theia WebIDE做过类似的demo。\n这种方式也是一个思路，但是这种WebIDE的方式一般和代码托管站点结合起来会比较好些，现在github与gitpod、codespace的结合，腾讯内部工蜂也有与WebIDE的结合。\n这种结合起来是比较方便地，也可以通过与本地vscode的联动，来触发类似方式1中的这种工作方式，ssh到开发容器中，通过vscode client链接到vscode server。\n我们这里主要侧重于本地开发这种更通用点的场景，基于WebIDE的这种方式就不细说了，大家可以了解下gitpod、codespace的工作原理。\nvscode: 更多玩法 # vscode中还有更多玩法，比如docker in docker、docker from docker…和前面集中方式要解决的问题不一样，比如将vscode extension安装也放到容器中管理，而不是和本地vscode混在一起。有需要的时候再细究吧，先这么大只了解下。\n总结 # 本文总结了比较好用的跨平台开发Linux C/C++程序的方法，其实也不仅限于C/C++了，这个方法的适用性很广，只不过对于Linux C/C++跨平台开发这个场景，就比较有价值，因为看到很多同事的做法实在太原始了。\n"}),a.add({id:163,href:"/tags/lock/",title:"lock",description:"",content:""}),a.add({id:164,href:"/tags/mmap/",title:"mmap",description:"",content:""}),a.add({id:165,href:"/tags/multiprocess/",title:"multiprocess",description:"",content:""}),a.add({id:166,href:"/tags/mutex/",title:"mutex",description:"",content:""}),a.add({id:167,href:"/blog/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E4%B8%8E%E9%87%8A%E6%94%BE/",title:"从0细说如何管理内存的？",description:"介绍下从用户态申请内存如malloc开始库函数做了什么、操作系统做了什么、操作系统内存分配器怎么做的、用户态内存分配器怎么做的，为什么用户态又要单独做内存分配器。类似地，释放内存free的时候这一连串的又发生了什么。",content:""}),a.add({id:168,href:"/blog/%E5%B9%B6%E5%8F%91%E5%90%8C%E6%AD%A5/",title:"并发同步",description:"介绍下如何实现多线程、多进程间的并发同步控制，多线程场景并发控制比较常见，多进程的可能不少人都比较陌生一点吧。",content:"并发同步，在并发编程中是非常重要的。当我们讨论并发编程时，我们的程序可能是通过多线程来实现，也可能通过多进程来实现。\n 我们在OS理论中了解到进程是资源分配的最小单位，线程是调度的最小单位。在Linux里面，这么讲也是成立的。更细致地说，在Linux中，线程其实就是轻量级进程LWP来表示的。对Linux调度器而言，可调度实体既可以是进程、线程也可以是一个任务组，这个任务组中又可以有其他的可调度实体。\n 有两个问题：\n  当我们在单进程多线程中该如何通过？\n  当我们在多个进程间进行同步时该如何同步？\n  我们常用的同步的措施包括：\n mutex/rwmutex semaphore condition variable  我们处理最多的可能就是单进程多线程情况下的同步，使用上面这些来处理没啥好说的。现在思考下，如果要实现多个进程之间的同步，有没有办法呢？\n这些玩意的实现，本质上是基于处理器指令lock addr锁总线的这一基础控制，一步步实现了CAS、Spinlock、mutex/semaphore/condvar。所以其核心就是利用了锁一个内存地址总线来实现。\nok，那么假设我们在当前进程全局变量中初始化了一个mutex变量，然后fork下当前进程，然后**父子进程能通过这个mutex变量进行同步控制吗？**不能！因为父子进程中复制后mutex是两个不同的内存变量，这两个变量的内存地址是不同的，其实就是两个不同的锁，所以无法通过这个mutex进行正确的同步控制。\n那怎么办呢？我们只要在共享的内存空间里面来初始化这个mutex变量就可以了（关键的就是lock的底层的内存地址一样就可以了），比如通过：\nbuffer = (*buffer_t)mmap(NULL,4,devzeroFD,MAP_SHARED)，\n然后将buffer-\u0026gt;lock作为mutex变量进行初始化，因为mmap映射的时候指定了共享模式，此时初始化写内存时也是共享的，fork的子进程初始化时其实也是同一个锁（已经初始化过不会重复初始化吧？），然后后续加解锁都是在相同的地址上了，这个很好理解，映射的是同一段内存。就能正常完成多个进程之间的同步控制。\n其他的rwmutex/semaphore/condvar，理论上也可以通过相似的方法来实现。\nreference:\n1: 多进程并发同步控制, Synchronization Across Process Boundaries\n2: 支持优先级继承的锁, Priority Inheritance Mutex\n"}),a.add({id:169,href:"/tags/alignment/",title:"alignment",description:"",content:""}),a.add({id:170,href:"/tags/cache-consistency/",title:"cache consistency",description:"",content:""}),a.add({id:171,href:"/tags/mesi/",title:"mesi",description:"",content:""}),a.add({id:172,href:"/tags/mesif/",title:"MESIF",description:"",content:""}),a.add({id:173,href:"/tags/packed/",title:"packed",description:"",content:""}),a.add({id:174,href:"/tags/padding/",title:"padding",description:"",content:""}),a.add({id:175,href:"/tags/thread-visibility/",title:"thread visibility",description:"",content:""}),a.add({id:176,href:"/tags/volatile/",title:"volatile",description:"",content:""}),a.add({id:177,href:"/blog/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/",title:"为什么需要内存对齐，以及如何控制对齐",description:"介绍下内存对齐访问（aligned access）的重要性，以及不对齐访问的情况下不同处理器的不同的行为，以及如何规避这些问题，比如编译期层面可能有哪些措施。也描述了下如何通过GCC扩展来控制aligned boundary或者packed。",content:"什么是内存对齐？ # 所谓的内存对齐，指的是我们的一些数据在内存中组织的时候，为了后续访问时效率更高，需要将其起始地址进行一定的对齐处理，最常见的就是将结构体各个成员起始地址分别对齐，非结构体比如一个普通的int数也会对齐处理的。\n举个int数的例子：\nint n = 100; printf(\u0026quot;n: %d\\n\u0026quot;, n); printf(\u0026quot;sizeof(int): %lu, address: %p\\n\u0026quot;, sizeof(n), \u0026amp;n);  运行后发现n的大小是4字节，地址是0x16d216c4c，hex \u0026lsquo;c\u0026rsquo;对应二进制数为1100，低位是00，00表示是4字节对齐的，那这个int数在内存中组织就是4字节对齐的。\n再看个struct结构体：\ntypedef struct { char sex; int age; } Person; Person p; printf(\u0026quot;sizeof(person): %lu\\n\u0026quot;, sizeof(p)); printf(\u0026quot;person.sex address: %p\\n\u0026quot;, \u0026amp;p.sex); printf(\u0026quot;person.age address: %p\\n\u0026quot;, \u0026amp;p.age);  运行后发现p的大小是8个字节，我们书本上学习过，sex放在地址0，age放在地址4处，sex后有3个padding char，这样整个是8个字节。然后我们继续看下地址:\nperson address: 0x16fdbac44 person.sex address: 0x16fdbac44 person.age address: 0x16fdbac48  struct的首地址跟第一个成员的首地址是相同的，低位的44表示01000100，说明这个结构体本身以及内部成员sex都是4字节对齐的，然后age地址低位是01001000，在0x16fdbac44+4=0x16fdbac48，其实是4字节对齐的。这么看下来这个结构体中各个字段都是4字节对齐的。在sex和age之间padding了3个char。\n这就是内存对齐了，至少直观地知道是什么了。\n 简单地说，当我们希望读取的数据字节数是N，该数据起始地址是addr，假设 addr % N == 0 就是aligned access，反之就是unaligned access。\n即便是基本类型也会对齐，对于结构体各个field都会对齐，当我们说一个struct是多少字节对齐时，指的是struct中field对齐用的字节数最大的一个。 不妨了解下go语言中的内存对齐规则，see: https://go.dev/ref/spec#:~:text=The%20following%20minimal,array%27s%20element%20type.\n 为什么需要对齐？ # 那么为什么要填充些padding数据呢？这就涉及到处理器访存的工作过程了，我们怎么控制处理器访问内存数据的？一般就是通过mov指令来将内存数据搬迁到内存后者寄存器中。mov指令，指令译码、指令执行，其实就是把一个内存地址放到地址总线上通过内存总线控制对应地址可读，然后通过数据总线从指定起始地址处连续读取数据总线位宽的数据到MDR（存储器数据寄存器）然后进一步加载到指定寄存器或者内存中。\n这里有什么要关注的吗？有，比如8086 20位的地址线可以寻址1MB的内存，内存以字节编址，那么20位地址线可以寻址内存空间为2^20=1MB，一次读取的数据量取决于数据总线位宽，比如8086位 16位数据线，一次也就读取2个字节。\n假设我们一个int数吧存放在地址0处，那么我1条汇编指令mov ax, 0x0就可以完成，为啥呢，数据总线是16位的，一次就能读取出来放到ax里。\n那么如果这个int数不在地址0处，而是在0x1处呢？此时一条mov ax, 0x0就不够了，只读了8个字节，还有8个字节在0x2处，最后就只能movb al, 0x1, movb ah, 0x2。和内存对齐的相比，这种就多了一次访存操作，执行效率自然就慢了啊。\n上面这个例子基本总结了内存对齐的原因，就是为了尽量通过内存对齐充分发挥硬件访问内存的效率，避免因为未合理对齐导致的编译器需要安插一些其他更多的内存访问指令，每条指令执行都需要经过取指、译码、执行等过程，而且还是访存，访存和处理器计算的效率是不在一个数量级的。所以要内存对齐。\n 准确地说，unaligned access的坏处主要包含这些，跟平台有关系：\n 有的平台会透明处理这些问题，只不过是性能上会有些下降； 有的平台可能会抛异常，异常处理函数来解决，性能开销更大； 有的平台可能会抛异常，异常信息不明确，无法修复； 有的平台可能不能正常处理，请求了错误的内存地址的数据，导致bug；  一般编译器会考虑不同平台的差异性，尽量生成aligned access的指令。\nsee：linux unaligned memory access。\n 内存对齐基本规则？ # 内存对齐规则，大面上的大家都清楚，就是算呗，按那几条对齐规则来。\n举个例子：\ntypedef struct { char sex; int age; } Student;  sex占1个字节，放在地址p处1字节对齐；age是4个字节的话应该4字节对齐，这样sex后应该填充3个padding char，age放在地址p+0x4处，本身为4字节。这样整个struct大小为8字节，各字段也合理对齐了。\n读者可以自行找些网上的相关资料了解更多对齐的信息。\n如何人为控制对齐？ # 对于编译期默认是如何控制对齐的，我们可以写程序轻松验证出来。其实gcc编译期扩展可以通过attribute进行修饰，对结构体对齐、结构体字段的对齐规则进行精细控制。\n这部分我们就通过程序来验证学习下，不做过多解释了，注释可以说明一切。\n#include \u0026lt;stdio.h\u0026gt; typedef struct { char sex; int age; } Person; // because it's packed, so sizeof is 5 bytes // 1 + 4 = 5 bytes typedef struct __attribute__ ((packed)) { char sex; int age; } Student; // this way: 1 + 4 + 3padding + 4 = 12 bytes struct StudentX { char sex __attribute__ ((aligned (1))); int age __attribute__ ((packed)); int xxx __attribute__ ((aligned(4))); }; // this way, the sizeof StudentY will be 16 bytes // 8 + 8 = 16 bytes struct StudentY { char sex __attribute__ ((aligned (8))); int age __attribute__ ((aligned (8))); }; // this way, add attributes to the struct means this struct: // - aligned(4) : sizeof is 8 // - aligned(8) : sizeof is 8 // - aligned(16) : sizeof is 16 // - aligned(32) : sizeof is 32 // // i don't know how aligned affects struct members, it looks like // telling the compiler to try to align the struct members in this way: // - if aligned (n) is too small, use default value, like char:1 int:4 // - if aligned (n) is bigger than default values, try to align to bigger boundary. typedef struct __attribute__ ((aligned (4))) { char sex ; int age ; } StudentZ; int main(int argc, char **argv) { int n = 100; printf(\u0026quot;n: %d\\n\u0026quot;, n); printf(\u0026quot;sizeof(int): %lu, address: %p\\n\u0026quot;, sizeof(n), \u0026amp;n); Person p; printf(\u0026quot;sizeof(person): %lu\\n\u0026quot;, sizeof(p)); printf(\u0026quot;person address: %p\\n\u0026quot;, \u0026amp;p); printf(\u0026quot;person.sex address: %p\\n\u0026quot;, \u0026amp;p.sex); printf(\u0026quot;person.age address: %p\\n\u0026quot;, \u0026amp;p.age); Student s; printf(\u0026quot;sizeof(student): %lu\\n\u0026quot;, sizeof(s)); struct StudentX x; printf(\u0026quot;sizeof(studentx): %lu\\n\u0026quot;, sizeof(x)); struct StudentY y; printf(\u0026quot;sizeof(studenty): %lu\\n\u0026quot;, sizeof(y)); StudentZ z; printf(\u0026quot;sizeof(studentz): %lu\\n\u0026quot;, sizeof(z)); printf(\u0026quot;address of z: %p\\n\u0026quot;, \u0026amp;z); return 0; }  运行程序进行测试：\nn: 100 sizeof(int): 4, address: 0x16b356c4c sizeof(person): 8 person address: 0x16b356c44 person.sex address: 0x16b356c44 person.age address: 0x16b356c48 sizeof(student): 5 sizeof(studentx): 12 sizeof(studenty): 16 sizeof(studentz): 8 address of z: 0x16b356c18  通过这里的测试程序，以及输出的结果，我们应该能推断出编译期扩展 __attribute__ ((aligned (n))) 与 __attribute__((packed))的差异。packed表示不再对其进行padding，aligned表示了按照多少字节控制对齐，如果不超过指定的n就不能完成对对齐，就用默认可行的值，如果n超过了最小阈值则安n进行。\n总结 # 本文小结了数据、结构体及其字段在内存中的对齐，并通过实例解释了gcc扩展对对齐的控制。之前天美J3面试时有问及计算sizeof时又没有例外情况，当时也没想起来。除了平台原因（比如int数大小不是4字节），再或者如果是采用的gcc attributes对其进行了扩展，比如padding或者比较大的aligned value也会导致计算结果不一样的问题。\n"}),a.add({id:178,href:"/tags/%E5%86%85%E5%AD%98%E5%AF%B9%E9%BD%90/",title:"内存对齐",description:"",content:""}),a.add({id:179,href:"/blog/volatile/",title:"对volatile的认识",description:"介绍了为什么c/c++需要volatile，关于volatile不能保证线程可见性的说明，以及为什么在x86上似乎可以做到线程可见性的释疑，最后简单提了下mesif来说明线程可见性是要依附于cache一致性协议的。",content:"关于这个我有一篇非常不错的总结，估计是全网最好的总结：你不认识的c/c++ volatile，虽然标题有点“博眼球”，但是内容绝对是很多高T都可能不知道的。\n今天翻之前整理的Linux内核文档笔记时，又看到了当时volatile相关的笔记，也是因为这个事情几年前听中心的高T分享时觉得他搞错了，才写的这篇总结。\n这里也放个简单的文档，系统性的强调下，认识正确了对于并发编程还是很重要的。\nsee also linux volatile considered harmful，linus torvalds大佬亲笔。\n简单总结下的话就是：\n volatile，需要volatile，尤其是对于涉及到外设访问的情况，有些外设的设备端口是通过统一编址来的，使用某些访存指令而非专用的in/out指令的话，有可能读的数据会做优化，比如放到寄存器中，硬件cpu还可能放到cache中。对于这些设备的读操作，需要避免优化才能正常工作，所以需要volatile。这在c/c++设备驱动中应该比较有用。 volatile，在c/c++语言设计层面，没有保证线程可见性的任何保证，切记！它只是告知编译器不要做软件级别的寄存器优化而已，对于硬件级别的cache缓存没有任何控制。 volatile，不能保证线程可见性，但是在不同的处理器平台上却是会有不同的表现，比如在x86平台上，加了volatile修饰的变量就能够保证线程可见性。为什么呢？首先加了volatile修饰后避免了寄存器优化，现在还有cache的顾虑对吧，但是x86平台比较特殊，它使用了一种称作 tso的memory model，x86多核能够看到其他核对某个cacheline的修改，因此能感知到最新写的数据，能做到线程可见性。 volatile在其他平台内存模型不同，不一定能和x86一样实现线程可见性。 要想实现线程可见性，编译器一般是结合语言本身的特性，为止生成一些内存屏障指令，这些屏障指令最终会触发cache的MESIF协议来使得当前核上的修改对其他核可见。  "}),a.add({id:180,href:"/tags/distro/",title:"distro",description:"",content:""}),a.add({id:181,href:"/tags/fedora/",title:"fedora",description:"",content:""}),a.add({id:182,href:"/tags/gnome/",title:"gnome",description:"",content:""}),a.add({id:183,href:"/tags/kde/",title:"kde",description:"",content:""}),a.add({id:184,href:"/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E5%88%86%E4%BA%AB/",title:"Linux桌面发行版分享",description:"这是我很久之前2016.5.7写的一篇关于linux桌面发行版的文章，但是一直停在我的笔记里。ubuntu 16.04 lts是2016年4月21日发布的，到现在也要6年多了，因为最近在整理之前的一些笔记，发现当初的一些想法还挺好的，拿出来继续分享下。",content:"Linux桌面发行版分享 # 这是一篇写在2016年的文章一直在我的个人笔记里，感觉当时很多想法今天依然成立，所以拿出来继续分享下。某些信息可能已经有过时，相关的部分我在备注里进行了标注，\n0.体验Linux发行版 # 今天安装了Ubuntu 16.04 LTS，本来准备一直用Fedora的，但是我的笔记本上安装的还是 Fedora 21版本，但是当前最新的已经更新到了Fedora 24,今天刚刚发布了Beta版本。此 前我对Fedora 23 GA以及Fedora 24 Alpha版本进行了简单的测试，实在是不喜欢KDE 5！\n怎么说呢，其实看上去KDE 5挺漂亮的，应该将来也会有不错的发展，但是考虑到KDE 5刚 出来的时间还不够长，其中很多在KDE 4里面方便实用的功能在KDE 5中还没有被开发出来 ，而我又是一个倾向于“工欲善其事，必先利其器”的同学，让我这样把一个未充分完善好 的桌面环境当做自己的主力系统，我实在难以接受！对于GNOME 3，我就不做任何评论了 ，我宁可用Ubuntu Unity也不用GNOME 3！\n可能有人说，没必要一直跟着更新啊，继续实用Fedora 21也可以啊！？此话当然不假， 可是一个失去后续更新支持的版本，我想还是要继续跟进新版本要更好。其实我现在配置 的已经相当棒了，有的软件源里面的程序存在某些小问题，瑕不掩瑜的，我也对其源代码 进行了部分修改，以为自己所用，因为这部分工作还是相当多、相当细的，如果继续跟进 新的发行版，而软件源里面的软件包可能还没有修改过来，或者不符合我的需要，又要进 行重复性的工作，我觉得这个工作量还是蛮大的，至少现在我没有那么充足的时间。\nFedora发行版每6个月更新一次，CentOS 7可以支持10年，我本来也计划使用CentOS的， 但是CentOS对稳定性的追求，也使得很多软件包不能被加入其软件源，有些我很喜欢的工 具，安装、配置起来就会比较麻烦，dpkg、alien、rpmrebuild甚至修改源代码这些可能 都要用到，以配置出一个趁手的系统环境。半年前，我在另一台三星的笔记本安装了 CentOS 7，配置完成之后，堪称完美，那个时候时间多啊，折腾的时间也挺长的；现在时 间没有那么充裕了，我在这台thinkpad上安装了CentOS 7.2，前后也就折腾了一天，不打 算折腾了。\n最后，我选择了Ubuntu 16.04 LTS版本，可以支持5年，而我本身也想重新比较一下 Ubuntu、Fedora这两大发行版，为什么呢？因为对这两款发行版，我都有向当长的使用时 间，现在也积累了很多的经验，前不久我碰巧又看到了一个各大发行版性能对比的文章， 其中Debian系列的性能要明显优于RHEL系列，原因我暂时也不是特别清楚，这也是激发我 重新选择Ubuntu的原因之一。我希望在使用过程中，重新比较一下Ubuntu和Fedora这两大发行版的差异，例如包管理工具的差异、软件包中的配置文件的差异、系统管理方面的差 异，此外呢，我也希望能够对其性能上的差异进行一下更深的认识。\n1.系统安装过程 # 系统安装过程，应该说是驾轻就熟了，下载一个Ubuntu 16.04 LTS的ISO文件，然后使用 Unetbootin制作一个可以引导系统安装的U盘。U盘要格式化成FAT32格式，且要根据需要 预留一定的存储空间，以供安装过程中释放文件使用，如果预留空间不足，可能导致安装 失败。\n制作完成安装U盘之后，插入电脑，关闭BIOS中的UEFI引导模式，然后从USB HDD启动安装即可。安装的时候手动分区，最好能够把那些第三方软件包给安装上，这样省的后续安装 ，省心。我是深有体会，之前安装音频、视频播放器的时候，安装解码库浪费了很多时间 。安装过程中有个别地方需要设置一下，例如用户名、密码、语言、地区、时间等等的。\n注意，Ubuntu在安装过程中不会对root用户的密码进行设置，并且默认将新建的用户加入 wheel组中！但是在Fedora安装过程中，会对root密码进行设置，然后再创建一个新用户 ，并允许选择是否将该用户加入wheel组中，还可以指定uid、gid等。这是一个区别，需 要注意一下，安装完成之后，需要通过“passwd root”对密码进行重新设定。\n相对来说，安装过程还是比较顺利的，但是需要注意的是，前面提到过Unetbootin需要预 留一定的空间，例如100m，或者200m，甚至500m，如果设置的比较小的话，可能就会遇到“磁盘空间不足，安装失败”，这是由于系统安装过程中，有些压缩文件需要释放，释放的目的地不是在我们要安装到的目标硬盘上，而是在我们的U盘上，剩余空间不足的话，肯 定文件释放就会失败，就不能成功安装到我们的目标硬盘上。例如Ubuntu Kylin设置100m 的话，就会安装失败，设为500m就可以安装成功。用U盘安装与用光盘安装还是有区别的 ，用光盘安装的话，一般释放文件的目的地在目标硬盘上。\n安装完成之后，赶紧试用一下吧。\n2.软件安装配置 # 软件安装完成之后，应该养成一个好习惯，先把软件中的所有配置选项查看一遍，这样的 话就可以对软件整体有个更全面的认识。很多用户在安装了软件之后，就不管不顾了，这 怎么行呢？比如有些人手机上安装了在线视频播放软件，但是从来不关心相关设置，时间 久了，缓存占用空间越来越多，但是却不知道清理这些垃圾；又或者买了IPhone以为手机 有指纹安全了，但是却不知道该在设置里面对Siri进行相关的设置，以阻止未解锁情况下 的绕过安全检查的问题……像这样的类似的问题有很多。\n安装完成一个软件之后尚需如此，安装完成一个操作系统之后，就更需要这样了。对于系 统中的绝大部分配置，例如启动设置、登陆设置、界面设置、环境变量设置、别名设置、 常用软件包设置、安全设置、tricks等等，这些都是一个熟练的计算机用户安装完系统之 后应该考虑的。对于Linux用户，这一点显得尤为重要，一个配置良好的系统，可以让 Linux充分发挥出其优势，成为我们的趁手的兵器！\n3.系统引导设置 # 3.1.设定GRUB引导界面 # 设定GRUB是很重要的，GRUB可以帮助引导多个安装的系统，支持windows、unix、linux等，我之前曾经有专门的笔记对GRUB相关的配置进行了详细地说明，这里就不再阐述了，感兴趣的话，可以参考我之前的说明加以了解。\n这里仅仅对GRUB的工作原理进行一下简单的说明。当我们按下开机按钮的时候，系统BIOS 被启动，并执行加电自检任务，任务完成之后，将引导操作系统启动。BIOS会将系统控制 权交由另一个程序进行处理，这个程序被安装在硬盘的启动扇区中，通常是第一个扇区。 但是一个扇区只有512个字节，不可能装下足够多的代码来完成系统的启动任务。因此在 这个第一扇区中往往存放了一些简单的代码，这段代码接收BIOS转交的系统控制权，去执 行后续的更加复杂的系统启动任务。\n以GRUB2为例，通常将GRUB安装在硬盘的第一扇区中，并且将系统内核映像安装在/boot分区中，并且/boot/grub2中也保留了其他的大量的GRUB2程序、配置文件等。这样硬盘第一扇区中的grub引导代码会加载相应的程序，并最终完成内核的装载任务。当内核装载完成之后，GRUB再将系统控制权交由内核，这时操作系统才算是真正的接管了整个系统。\n3.2.设定Plymouth动画，并开启帧缓冲 # 3.2.1.开启Plymouth # GRUB装载内核、引导内核、内核启动过程中，需要执行很多任务，这个任务耗时可能还比 较长，为了让用户在等待系统启动的过程中，不至于等待地又闷又烦，可以在这段时间里 ，显示一个比较友好的启动界面，例如进度条、启动动画等等。\nplymouth就是这样的一个程序！它通常包括了3个主要部分，一个plymouthd程序，这个相当于一项服务，在系统启动的时候会决定什么时候开启动画、结束动画，开启和结束动画 是通过另一个程序plymouth来完成的。另一个部分也就是这里的动画了，我们称之为 plymouth主题。\n用户可能在同一个系统中安装多个plymouth主题，这就存在一个“系统显示哪个主题”的选择问题！在Fedora里面，是通过plymouth-set-default-theme来选择主题，然后通过 dracut重建initramfs实现的。但是在Ubuntu里面采用了一种更加简便的方式，即通过 update-alternatives来实现。在Fedora里面，其实也存在update-alternatives工具，但 是却采用的重新建立initramfs的方式，相比之下，稍微有点繁琐，但是这种方式可能在 系统启动速度方面更胜一筹。因为plymouth主题所需的资源被直接加入到了了 initramfs中，加载后解压缩的速度可能比通过update-alternatives生成的符号链接再次 访问文件系统更加节省时间。各有优缺点！\n3.2.2.开启帧缓冲 # /etc/initramfs-tools/conf.d/splash中增加一行FRAMEBUFFER=y，没有该文件就创建该 文件。开启帧缓冲之后，可以加速plymouth启动，以使得plymouth动画能够尽量铺满系统启动的整个过程，以使得启动界面更加友好。\n修改完成后，需要重新建立initramfs，执行命令update-initramfs -u命令即可完成。对 于Fedora系统需要通过dracut来完成，其实Ubuntu里面也是通过dracut来完成的， update-initramfs命令只不过是一个shell脚本而已，其只不过是对dracut命令的封装。\n3.3.指定关键内核参数 # 系统中有些参数是在系统启动的过程中指定的，虽然在系统运行期间仍然可以对其进行修 改，但是如果通过配置文件或者其他方式能够指定好相关的参数信息，运行期间就无需再干预、调整了。\n3.3.1.设定虚拟内存换出比率vm.swappiness # 现在的物理内存越来越大了，在一般使用情况下，交换区是很少会被使用到的。虚拟内存 频繁的换入换出会影响系统的响应速度，就算是现在使用SSD，也比内存慢很多，因此合 理地设置内存页面换入换出率是非常重要的，而且我们要使用的是桌面版操作系统，合理 地设置可以减少图形界面的响应延迟时间。\n/etc/sysctl.conf中增加vm.swappiness=16，通过sysctl vm.swappiness命令可以看出默 认设置是60，我们通过修改配置文件将其设置为16。\n3.3.2.设定udev的网卡命名规则 # 对于系统中的网卡，我们更加熟悉eth0、wlan0这样的命名方式，但是如果我们不加配置 ，系统中很可能显示的是enp0s25、wlp3s0这样的名字，为什么呢？这与udev命名规则有 关系。\n如何看到我们熟悉的名字呢？当然业余udev命名规则有关系，这里可以通过grub传递内核 参数“net.ifnames=0 biosdevname=0”来解决，修改/etc/default/grub之后，需要重新更新/boot/grub2/grub.cfg，这个可以通过update-grub2来完成。\n但是，我的情况比较特别，我这个笔记本有两个硬盘，分别记为/dev/sda和/dev/sdb。其中/dev/sdb上安装了Fedora，并且在/dev/sdb上安装了grub；/dev/sda上安装了Ubuntu，并且在/dev/sda上安装了grub。然后将/dev/sdb作为第一启动设备，为啥这么做？因为sdb是一个SSD，速度快，而且Fedora是我的主力系统，就是这么个情况。由于引导Ubuntu启动的grub配置文件是在/dev/sdb上的Fedora中生成的，与Ubuntu上面的grub配置文件没有关系。\n因此如果要正确改过网卡的名字来，还是需要修改/dev/sdb上的 /boot/grub2/grub.cfg中的相关配置。其实也就是将上述提到的内盒参数加入到 menuentry的linux命令后的选项中而已。\n3.3.3.关闭启动时fsck对文件系统的检查 # /etc/fstab中将每个分区的最后的一列数字全部修改为0，这样可以避免系统启动时对文 件系统进行检查，加快系统启动速度。\n3.3.4.激活所有的系统魔法键vm.sysrq # 修改/etc/sysctl.conf，增加一行vm.sysrq=1，这样就可以激活Linux系统内所有的魔法 键，例如比较常用的Ctrl+Alt+Print+K，表示杀死当前会话，包括当前会话中启动的所有 的进程；Ctrl+Alt+Print+B，表示立即重新启动系统。\n这两个魔法键是我经常使用的，非常有用，特别是希望快速检查配置更改是否有效或者图 形界面失去响应的时候。\n4.系统优化及系统工具 # 4.1.系统配置优化 # 4.1.1.Ubuntu greeter配置 # 要创建、修改的文件主要包括：\n /usr/share/glib-2.0/schemas/com.canonical.unity-greeter.gschema.xml  修改该文件，可以禁用greeter界面的系统已就绪的声音提醒、是否绘制网格、是否要加 载一个图像作为背景，加载图像前的界面颜色等。对于要加载的图片最好能够与用户之前 设定的桌面壁纸一致，这样可以加快系统登陆系统的时间（避免了再次加载图片嘛，减少 了访问文件系统的时间）；另外，加载图片之前的颜色，也应尽量与壁纸、plymouth动画 背景色相一致，这样显得系统启动更加流畅，界面更友好。\n修改该xml文件后，需要执行如下命令使其生效：\n sudo glib-compile-schemas /usr/share/glib-2.0/schemas\n 执行改行命令的目的，是将修改后的xml文件与未修改的xml文件重新编译成一个完整的二 进制文件，gsettings读取这个二进制文件并对图形界面进行相关的设置。\n关于如何在用户设定新的壁纸之后，让系统启动到greeter界面的时候可以自动装载的问 题，我们可以在上述xml里面将待加载的图片设为一个符号链接.background-uri。然后当 用户修改背景图片后，可以通过命令update-background来更新该链接，使其指向新的背 景图片；或者在.bashrc里面写入一些脚本来完成链接的更新。总之目的就是保证用户再 次登陆时，能够加载正确的图片，实现平滑地界面过渡。\n /home/username/.bashrc  关于如何在用户设定新的壁纸之后，让系统启动到greeter界面的时候可以自动装载的问 题，我们可以在上述xml里面将待加载的图片设为一个符号链接.background-uri。然后当 用户修改背景图片后，可以通过命令update-background来更新该链接，使其指向新的背 景图片；或者在.bashrc里面写入一些脚本来完成链接的更新。总之目的就是保证用户再 次登陆时，尅加载正确的图片，实现平滑地界面过渡。\n在我以前使用Ubuntu 12.04 LTS的时候，gconf可以在用户选择新的桌面壁纸后执行一些 操作，比如更新%gconf.xml文件，其中保存了用户选择的壁纸的绝对路径，可以利用它来 更新符号链接.background-uri。但是在Ubuntu 16.04 LTS里面，我发现系统中默认没有 使用生成%gconf.xml文件，但是通过gsettings可以获取到壁纸路径信息，并且格式与 %gconf.xml中是一致的。\n在.bashrc中，增加如下三行脚本就够了：\n BACKGROUND_CONFIG=gsettings get org.gnome.desktop.background picture-uri\nBACKGROUND_CONFIG=echo ${BACKGROUND_CONFIG#*//}\nln -sf $BACKGROUND_CONFIG ~/.background-uri\n  /usr/bin/update-background  当然了，也可以把上述三行脚本写入一个bash脚本中，放入搜索路径/usr/bin中：\n #!/bin/bash\nBACKGROUND_CONFIG=gsettings get org.gnome.desktop.background picture-uri\nBACKGROUND_CONFIG=echo ${BACKGROUND_CONFIG#*//}\nln -sf $BACKGROUND_CONFIG ~/.background-uri\necho \u0026ldquo;update background-uri link \u0026hellip; done\u0026rdquo;\n  /home/username/.background-uri  这只是一个符号链接，通过它指向正确的桌面壁纸。由于不希望在后续使用过程中看到这 个文件，或者对其进行直接修改，所以将其设置为隐藏文件。\n4.1.2.bash配置 #   /etc/passwd\n  /etc/bash.bashrc \u0026amp; /etc/profile\n  .bashrc \u0026amp; .profile\n 环境变量   Java相关\nAnt相关\nMaven相关\n\u0026hellip;\n其他\n  别名   alias bb=\u0026ldquo;byobu\u0026rdquo;\nalias clean=\u0026ldquo;dpkg -l | grep ^rc | awk \u0026lsquo;{print $2}\u0026rsquo; | xargs sudo dpkg -P\u0026rdquo; alias cls=\u0026ldquo;reset\u0026rdquo;\nalias duu=\u0026ldquo;du -h -a -d 1\u0026rdquo; alias ee=\u0026ldquo;exit\u0026rdquo;\nalias g++=\u0026ldquo;g++ \u0026ndash;std=c++0x\u0026rdquo;\nalias gentags=\u0026ldquo;sudo /usr/bin/ctags \u0026ndash;c-kinds=+dfglm \u0026ndash;language-force=C -R .\u0026rdquo;\nalias gg=\u0026ldquo;cd /home/user/Github/Study\u0026rdquo;\nalias grep=\u0026ldquo;grep \u0026ndash;color=auto\u0026rdquo;\nalias gvim=\u0026ldquo;gvim -f\u0026rdquo;\nalias indent=\u0026ldquo;indent -kr\u0026rdquo;\nalias l=\u0026ldquo;ls -CF\u0026rdquo;\nalias la=\u0026ldquo;ls -A\u0026rdquo;\nalias ll=\u0026ldquo;ls -al\u0026rdquo;\nalias ls=\u0026ldquo;ls \u0026ndash;color=auto\u0026rdquo;\nalias lg-ce=\u0026ldquo;sdcv -u\u0026rsquo;朗道汉英字典5.0'\u0026rdquo;\nalias lg-ec=\u0026ldquo;sdcv -u\u0026rsquo;朗道英汉字典5.0'\u0026rdquo;\nalias mirror=\u0026ldquo;wget -r -p -np -k\u0026rdquo;\nalias mmatlab=\u0026ldquo;matlab -nojvm\u0026rdquo;\nalias pp=\u0026quot;/usr/bin/proxychains4\u0026quot;\nalias ss=\u0026ldquo;ssh -qtfnN -D 7070 ZhangJie@192.168.56.254\u0026rdquo;\nalias vvim=\u0026ldquo;vim -u ~/.vvimrc\u0026rdquo;\nalias nvim=\u0026ldquo;vim -u NONE\u0026rdquo;\n  函数   hostlist\n\u0026hellip;\n其他\n   4.1.3.gnome-terminal或Konsole配置 # 4.1.4.Vim配置 #  vim.tiny-\u0026gt;vim-\u0026gt;vim.nox-\u0026gt;vim.athena-\u0026gt;vim.gtk/vim.gnome  vim的不同二进制版本，其中内置的功能特性有所差异，在上述箭头所示顺序中，各版本 包含的特征依次增加。系统中可以安装多个vim版本，然后通过update-alternatives来控 制使用那个版本。\n .viminfo  /etc/vim/vimrc中，保存着vim的全局配置。奇葩的是，在Ubuntu里面默认没有开启 viminfo支持，这个只要对/etc/vim/vimrc文件进行修改，取消相应的配置前面的注释就 可以了。\n .vimrc  vimrc这个是vim的主要配置文件，关于vim这一个编辑器，涉及到很多方面的配置，包括 颜色配置、快捷键配置、颜色配置、命令配置、插件配置等等，建议没事多翻翻vim相关 的论坛，总能学到点东西，加快文本编辑效率。vim不愧是编辑器之神！\n如果实在是对vim的相关配置感兴趣，不妨查看一下我的相关配置说明，可以从如下repo 进行获取：https://github.com/hitzhangjie/Conf.git。\n4.1.5.按键延时、按键速率配置，更快速地输入 # 降低按键延时、提高按键速率，这样可以更加快速地进行输入操作，在Vim中进行移动效 率也会更快。可以根据需要、个人习惯进行适当地调整。\n有些情况下，我们进行输入操作时，如果一边思考一边输入的时候，可能输入操作会比较 慢一些，但是如果思考任务不是很重的情况下，输入的速度就会很快，但是呢，系统的默 认按键设置有一个按键延时和输入速率限制，这个限制在某些情况下会严重干扰输入速度 。对于这一点我是深有体会，何况自己还是一个专业级码农，一个不折不扣的输入快手， 一个命令行、vim重度用户，对于按键输入速度有着较高的要求。\n对于OS X用户，其shell中存在较为严重的按键延时问题，我是在体验OS X的虚拟机的时 候发现这个问题的，之后就在Linux上对相应的设置进行了完善，输入体验有了较大提升 。建议朋友们优化一下相应的配置，相信会有更好的输入体验。\n4.2.系统常用工具 # 系统中包括了大量的工具，包括官方的以及第三方提供的，甚至有些个人提供的工具，能 够从众多的工具中遴选出那些高价值的、实用的工具，对于后续的高效工作是非常有利的 。在多年的Linux使用过程中，我将自己觉得非常好的工具介绍给大家，当然了这里的工 具可能不仅仅是一些软件包，也可能是系统中提供的一些不错的功能、组件等等。\n4.2.1.byobu、tmux、screen # 对于Linux而言，命令行是体现其强大之处的一个窗口。有些刚开始学习Linux的用户，很 难以理解为什么命令行这种极其不方便的操作方式会有比GUI更好的体验、效率。其实这 个问题很容易理解，一个命令通常可以灵活指定几个、多个、很多个选项，在GUI中能够 对其进行有效组织不是一项简单的工作，不是说不能，只是说可能会附带很多的工作量。\n举个简单的例子，以windows资源管理器为例吧。windows资源管理器看似已经非常强大了，在里面我们可以将文件以列表、图标等多种视图形式进行展示，并且支持复制、粘贴、 移动、搜索等操作。对于普通桌面用户而言，这个确实已经足够强大了。下面我试着题几 个功能需求，你们看看windows资源管理器是否能够做到。\n 列出最近1分钟内修改过的文件？   Linux下可以通过命令“find -mmin 1”来完成。\n  列出最近10分钟内访问过的文件？   Linux下可以通过命令“find -amin 10\u0026quot;来完成。\n  列出文件内容中包括“xxxx”字样的文件？   Linux下可以通过命令\u0026rsquo;find -iname \u0026ldquo;*\u0026rdquo; | grep \u0026ldquo;xxxx\u0026rdquo; | cut -d':' -f1 | sort | uniq\u0026rsquo;来完成。\n  列出所有的目录文件，或者列出所有的普通文件？   Linux下可以通过shell脚本来完成，如：\n#!/bin/bash\nfor f in find . -iname \u0026quot;*\u0026quot; do\nif [ -d $f ]; then echo $f; fi\ndone\n  显示出指定目录的树形结构，并可以指定深度？   Linux下可以通过命令”tree -L n“来完成。\n   ……\n  其他\n   用户的需求是灵活多样的，是变化的，GUI界面相对比较固定，正所谓众口难调，有的用户希望功能多点，哪怕界面看上去很复杂，但是有的用户却希望界面尽可能简单，仅仅保留刚需的功能就可以。\n 对于windows资源管理器而言，无法完成上述任务，实际上Linux中的某些类似的GUI工具 也难以完整地提供上述功能，而Linux命令行却可以通过某种形式的组合，来快速地满足 各种灵活多变的功能需求，GUI工具相比较之下，显得非常不灵活。这还只是谈到一个简 单的资源管理方面的工作，我们的工作实际上比这个要复杂很多很多，Linux中的命令行 可以通过不同程度地组合来满足解决复杂任务，但是要提供一个GUI来胜任所有的灵 活多变的任务，就太不现实了。\n上面提到了命令行的强大之处，相信大家能够对命令产生一点新的认识，对于重度Linux 用户来说，命令行是不可缺少的，一个不能够熟练使用命令行的用户，很难说他是一个水 平较高的用户，哪怕他有再长的使用经历也是白搭，时间并不能保证用户积累了充足的经 验和知识。重度Linux用户可能会开启很多的命令行窗口，并在不同的窗口中执行不同的 任务，但是如果能够通过一个程序对开启的多个命令行窗口进行更加有组织的管理，操作 起来就会更加方便，tmux、screen就是基于这样的目的诞生的。而byobu是建立在tmux或者screen之上的一个更加界面友好的工具程序，通过它可以更加方便的对打开的多个命令行窗口进行管理。byobu中的常用操作包括F2切换、F8重命名等等。\n4.2.2.lantern、switchomega+chrome、vpn # 在国内，有堵墙阻碍了我们正常上网，就是GFW嘛，不说你们也知道对不对，但是有些人 确实是不知道的，我刚上大学的时候就不知道。09年高中毕业之后，我买了自己的电脑， 才算是真正地用起了互联网。大一的时候，那个时候比较菜，很多计算机技术方面的问题 ，在百度上搜索一下基本就可以得到解决，但是后来慢慢地发现自己提出的问题，百度基 本上搜索不到正确的结果，而且也对百度的搜索质量越来越不满意。后面是一个同学介绍 我使用Google，也确实让自己受益匪浅。\n用Google，需要翻墙，翻墙的手段也是多种多样，翻墙工具更是五花八门。但是说来说去 ，把那些陈年废弃的老古董搬出来没有多大实用价值，当然了它们非常具有历史意义，对 于那些曾经奋斗在翻墙一线的前辈们我们应表示感谢。现在比较好用的翻墙工具，要么就 是直接用vpn，要么就是用开源的lantern。lantern支持Windows、Linux、OS X多种操作 系统，也支持Android手机，目前不支持iOS。感兴趣的话，可以直接从如下链接进行下载 ：https://github.com/getlantern。\n对于lantern的配置，在windows下面，只要运行lantern，IE浏览器、Chrome浏览器等就 会自动进入代理模式，在不同的Linux发行版中可能要进行不同的设置。Ubuntu 16.04 LTS中可以启动lantern后让浏览器自动进入代理模式；Fedora 21中在启动Lantern之后， Firefox浏览器自动进入代理模式，但是对于Chrome浏览器需要通过SwitchyOmega进行相应的代理设置，其实就是创建一个代理代理规则，即使用pac.profile来实现自动代理， pac.profile获取url为: http://localhost:16823/proxy_on.pac。造成这种问题的原因 可能是lantern设置页面没有勾选“管理系统代理”，可能也是lantern在不同系统上的”行为“差异。\nlantern提供了一个http代理端口8787（支持http、https协议），可以通过proxychains 进行设置，对其他http程序进行代理，也可以在其他使用http代理的软件提供代理服务， 例如android studio、eclipse、mendeley desktop等等。\n 写在2022年6月：再见lantern，lantern此时已经退出历史舞台很多年了 :(\n 4.2.3.vim+markdown、cherrytree、wiznote # 不管是在学习Linux的过程中，还是在其他学习过程中，都需要对相关知识进行收藏、整 理、总结，养成一个良好的记笔记的习惯是非常重要的，当然了，拥有一个跟得上思维的 记笔记的工具也是必不可少的，这类工具有很多，也看到很多朋友都选择了了自己的编辑 器。我本人也在长期的学习过程中试用了大量的记笔记工具，但是有的工具提供的功能并 不是我所需要的，或者没有我想要的功能，经过大量尝试之后，我也找到了适合我使用的 记笔记的工具，在这里也简单介绍一下。\n正所谓工具要趁手，趁手的意思也就是说，工具好不好，关键要看是否适合用户自己，因 此不太可能说，我喜欢的工具你也一定喜欢，或者一定能够满足你的需要，请辩证看待。\n vim+markdown  vim作为编辑器之神，已经赢得了很多人的青睐，特别是程序员，我也是程序员，我也喜 欢写东西，比如写总结、写博客、写体会等等吧，但是我讨厌把大量的时间花在排版上。 将vim与markdown结合起来可以说是一个非常好的选择。并且通过配合 vim-instant-markdown插件，可以实现在文字编辑过程中的实时预览。我非常喜欢现在的这种编辑体验。下图是我现在编辑状态下的一个截图。\n对于集成了markdown语法支持的编辑器，也有很多，但是由于我钟情于vim，即便有编辑 器集成了对vim操作方式的模拟，但是毕竟还是模拟，也不是一个完整的vim，编辑效率仍 然大大受限，所以我没有选择像markdown、atom这样的编辑工具。如果朋友们不喜欢vim，可以试用下atom。\n ps：2022年6月更新，我也是instant-markdown-d的贡献者。\n  cherrytree  cherrytree中可以通过树形结构对多个学习不同的学习内容进行阻止，例如为编程、内核 、算法单独创建一棵树进行管理，简单直观；\n树形结构可以任意扩展，支持多级子树的创建，灵活方便；\n编辑器中支持不同编程语言的语法高亮，而且能方便地调节代码窗口的大小，实用；\ncherrytree是我最常用的记笔记工具了，并且其文件支持加密操作，避免信息泄露，也可 以非常方便地将其加入github中，永不丢失，多好啊！\n ps: 2022.6更新，在我后面工作后逐渐将工作迁移到了mac设备下，主要原因是苹果生态下设备之间文件同步非常方便，但是cherrytree的作者表示自己没有mac设备，所以cherrytree短期内兼容mac是不大可能的。有点遗憾，我对mac下的图形化编程一知半解，不然还可以帮助贡献下。\n  wiznote  我们都经常上网，不管是用手机还是用电脑，很多时候，看到非常好的帖子，都是希望将 其收藏一下，收单到浏览器收藏夹或者某些app客户端里面，但是我们也常注意到这种情 况，有的帖子经过很长一段时间之后，不能正常访问了，可能是被删除了，也可能是被和 谐了，或者是被重新编辑过了，与之前相比发生了变化……我们当然是希望收藏的内容日后 查看的时候仍然与收藏时内容保持一致，当然更不希望进行收藏的网页日后居然无法访问 了，这岂不是很糟糕。\n为知笔记很好地解决了这一点，当我们收藏一个网页的时候，并不只是简单地保存一下网 页的链接，而是可以在本地中离线一份完整的网页，将内容保存起来。而且为知笔记还做 到了浏览器页面收藏、微信朋友圈文章收藏、公众号文章收藏，还能够将其他地方看到的 网页分享到为知笔记的公众号，只要分享了就自动保存。非常地方便！现在很多人都在使 用为知笔记了！\n现在为知笔记也可以支持markdown语法了，但是，编辑工作我还是希望使用vim来完成， 为知笔记更多时候被我用来收藏网页、朋友圈、公众号中的文章，过一段时间再对其进行 整理，收入cherrytree中。但是对于一般的笔记，我更强相遇使用vim+markdown来完成。\n ps：2022.6更新，为知笔记也是一个很不错的笔记，但是在我后续使用中遇到了同步错乱的问题，最后放弃使用类似云笔记的东西了，直接用简单靠谱的github来托管数据，用最好用的编辑器typora等来写文档。\n 4.2.4.gthumb、gimp、shotwell # 查看图片工具，gnome、unity里面最好的我认为要数gthumb了，在kde里面gthumb界面比较丑，但是其功能绝对是最强大的。gimp是类似于ps的图像处理工具，小巧也很使用。 shotwell是照片管理软件，平心而论软件做的是不错，但是使用的确实不多。\n4.2.5.virtualbox、vmware workstation # 虚拟机管理软件virtualbox在Linux下是非常赞的，vmware workstation也可以，但是 vmware workstation有些bug，我在Fedora 21上进行安装是遇到了问题，当然通过修改源代码，重新编译也成功进行安装了，但是有的问题还是无法解决。在Linux下面使用 virtualbox要更加省心一些，virtualbox已经做的非常出错了，支持的操作系统类型比 vmware workstation要多，而且性能方面也一点不输vmware workstation，对Linux支持的也比较好。\n在Linux下面，建议使用virtualbox，我现在安装了多个虚拟机，包括windows xp、 openSUSE 13、Mac OS X 10.7是用的非常好，当然其他的系统也都安装后测试过，上面提 到的三个要不同程度地用到。\n以前在windows下面的时候，我确实是用vmware workstation比较多，因为virtualbox在 windows下面跑起来真心慢的要命，vmware workstation要好很多，但是在Linux里面， virtualbox运行速度非常快，而且是自由软件，当然使用virtualbox了。\nvirtualbox提供的几种网络模式，也很简洁明了，nat、host only等模式，可以基本满足 的需要，我倾向于选择virtualbox。\n4.2.6.smplayer、clementine、mixxx、mpg123、openshot # Linux下面的视频播放软件，我认为最方便的应该是smplayer，跟vlc、dragon player、 totem、mpv等等比起来简直是神器，不仅功能多，而且操作也方便，某种程度上归功于其丰富的快捷键配置操作。\n音频播放器，我觉得clementine比较好，听音乐嘛，也不需要非常复杂的操作，界面简单 清爽就好了，clementine满足了我的需要，我不喜欢rhymbox、banshee等其他流行的音频播放器。喜欢dj、电子音等劲爆音乐的，可以使用下mixxx。mpg123是命令行下的一个非常简单的音频播放工具。\nopenshot是一个矢量视频编辑工具，其功能非常多，我经常用它来合成视频、剪辑视频、 视频转码等等，openshot工作过程中，因为计算量较大，cpu使用率较高。\n4.2.7.openssh-server、openssh-client # ssh，secure shell，这个是很有用的代替ftp、telnet的工具，在自己的电脑上搭建一个 sshd服务还是非常有必要的，说不定啥时候就需要从其他电脑链接到自己的电脑，比如 host与guest进行通信的时候，或者在本地搭建git服务器的时候……有很多场景都会用到。 当然了，更多的时候，我们是通过ssh去链接外面的某个主机。\n ps：因为网络的原因访问github不方便，所以我是搞了个二级的git托管，第一级是在本地电脑上开了个专门的账户git，这个账号home目录下用来托管git数据，但是这个账号禁止登录。然后白天我在图书馆或者网络不好的地方干活，就会从本地工作空间提交到这里来，等有网络了我再提交到github，其实有些我也没有提交到github。我主要是担心误删除rm -rf之类的不小心把仓库给删了，所以才搞个独立账号来充当git服务器。\n 总之，sshd、ssh是经常用到的工具，可以通过安装openssh-server将本地主机配置成 sshd服务器，安装openssh-client来获取相应的ssh等众多实用客户端工具。\n4.2.8.git、svn # 版本控制工具的两个代表是git和svn，其中svn是集中式的版本控制工具，而git是分布式 的版本控制工具。相比较而言，git比svn要优秀很多，当然其学习成本要高很多。\n建议学习一下《Pro Git》这本书，深入认识下git的工作原理，并在以后的的学习工作中 养成版本控制的意识，并切实将git应用起来。\n4.2.9.gnome-terminal、Konsole # 一个好用的终端模拟软件，绝对是非常重要的，比较好用的两个，kde下面使用konsole， ubuntu unity、gnome下面使用gnome-terminal。\n在里面可以对字体、颜色、输入指示器等等进行较为丰富的设置，一切为了效率。\n4.2.10.Ubuntu Unity、KDE、GNOME # 当前流行的三大桌面环境，是ubuntu unity、kde、gnome，任何一个Linux发行版都可以 对上述桌面环境进行整合，我对目前主流的桌面环境都使用过，上述三个使用的时间比较 长，根据我多年的使用体会，我自己更加倾向于选择kde和ubuntu unity。如果我使用的 是RHEL系列的，我就使用kde，如果我使用的是Ubuntu，那就使用ubuntu unity。gnome3实在不敢恭维，有很多人比较推崇gnome3，但是我确实不喜欢这种方式，自己感觉操作效率是上述三个中最差劲的。\n ubuntu unity  从使用ubuntu 12.04 lts开始，就开始使用ubuntu unity了，刚开始的时候确实觉得还不 错，但是永久了，就发现有些东西并不实用，我想回归精简了，仍旧是善变，并不就是人 家unity做的不好。后面你们猜我用上了什么，我用上gnome-shell-fallback，没错，我 觉得gnome2时候的界面真是清爽多了，为此，我后面还使用了相当长时间的rhel 6.5，直 到后面我用上了Fedora并开始使用kde作为主要的桌面环境。\n现在发现ubuntu unity确实做的不错，稳定性、速度等各方面都相当不错，所以我要先给 个赞！可以说之前一直都在折腾GUI方面的东西了，越折腾越心累，现在能够平心静气地 来对待这些问题了，自己也有实力对不合心意的地方进行修改了，改配置文件、改源代码 、替换必要的组件等等，随心所欲不逾矩！这种感觉还是非常爽的！当我看到有某个同学 在使用“丑陋”的Ubuntu时，心里面就有种不一样的感觉，很多新手不会配置却总是抱怨，Linux这么灵活，就是让你去探索的，不喜欢探索、折腾，自认为这是浪费时间的可以去买个Mac，不过说真的，Mac OS X的GUI就是一个gnome2的级别，操作效率渣的要命！\n ps：2022.6更新，现在mac使用了马上6年了，和我当年使用Linux发行版的时间差不多久了，说实话mac系统整体而言整合的比较好，但是要想提效，还是有很多东西要配置的，see 你的mac有哪些趁手的工具。\n 现在回头来看，我喜欢Ubuntu Unity哪些地方呢，没有特别推崇的地方，就是一种感觉， 优化的确实不错了，比以前强多了，而且操作起来确实也是很方便。\n kde  自从我使用Fedora 21以来，就一直使用kde作为桌面环境，kde4相当成熟、稳定，我很喜 欢，而且灵活性好，可以进行丰富的配置，这一点我非常喜欢，可以让其变得相当简约不 简单，也可以让其变得相当华丽而优雅。\n但是最新的Fedora里面增加了dnf，怎么说呢，我非常依赖yum，但是目前dnf还没有完全 实现某些功能，而且kde5里面很多地方还不完善。今年6月份才会出Fedora 24的GA版本， 我也等不了那么长时间了，于是提前体验了一下Alpha版本，发现kde5并没有达到我希望 的程度，dnf也没有实现我依赖的功能，所以我暂时先放弃了使用Fedora 24的年头，转而 投奔了Ubuntu，也没有继续采用kde桌面环境，而是使用了自带的unity。\n其实kde4是一个非常高效的桌面环境，简约的界面，丰富的快捷键，简直双到爆。\n gnome  gnome2比较简约，实用性比较好，但是对于追求高效操作的用户来讲，未免又显得过于寒 酸了些，值得一提的是，Mac OS X也就是相当于gnome2的级别，虽然苹果重新设计了很多东西，但是仍然就是这么个水平，操作鸡肋，难以满足我的需要。\ngnome3是比较高级了一点，但是有点哗众取宠，鄙人不喜欢，谁爱谁用，反正我是不用。其实gnome3很早之前就被无数人喷过了，比如Linus Torvalds。\n ps：2022.6更新，anyway，gnome3目前似乎称为了主流桌面环境，特别是服务器为中心的发行版。\n 4.2.11.workspaces、pager、activity #  虚拟桌面  Ubuntu Unity、GNOME里面使用的是workspaces的概念来表达多个虚拟桌面的意思，在KDE里面其实也是用的这个概念，但是它提供的工具却叫pager，表达的意思是一样的，都是表示的虚拟桌面的意思。\n虚拟桌面，其实就是在一个桌面上虚拟出多个桌面，例如一个笔记本就只有一个屏幕，只 能显示一个桌面啊，但是现在我虚拟出4个桌面，可以在其中进行切换。现在主流操作系 统windows、osx、linux中都提供了虚拟桌面支持。而linux中的几乎所有的桌面环境都支 持虚拟桌面。\n ps：2022.6更新，windows是从win10开始支持的吧，叫任务视图。osx下叫桌面1、桌面2……都是类似的东西。\n 虚拟桌面的作用是非常明显的，我们可以在不同的虚拟桌面中做不同的工作，这使得工作 更加井井有条、效率更高。\n 活动  KDE Plasma里面，提供了activity的概念，在同一个用户会话中，可以有多个不同的 activity，比如音乐activity、编程activity等，我们可以在当前会话中的不同activity 中进行切换，使得自己能够在不同的任务之间进行切换。\nactivity看起来也是非常有应用价值的，但是我任务比较明确，并且我认为在不同的任务 之间进行切换，并不需要付出较多的额外的工作，比如在游戏、工作、娱乐之间进行切换 ，我认为是一个很自然的过程，所以我几乎不使用activity。\n ps：2022.6更新，activity其实是在虚拟桌面上的能力升级，它允许你在不同的模式之间进行快速切换，其实这就是一种通过虚拟环境来实现任务隔离并保持专注的能力。\n现在智能手机中一般也会有类似的功能，比如工作、家庭两个不同的虚拟环境，当然了我们确实也可以通过多用户切换的方式来达到类似效果，但是activity可能要更优雅些，你可以复用这个用户下的应用、数据，只是在不同的高强度任务之间做个隔离，比如从工作状态一下子切到休闲模式，一键打开需要休闲的程序之类的。\n现在osx里面提出了一种捷径的软件，你可以自定义一些操作，通过捷径来做一些操作，但是初衷可能不一样，但可以模拟相同的功能。\n 4.2.12.自定义快捷键shortcuts # Ubuntu Unity、KDE Plasma中都提供了非常丰富的快捷键配置，非常棒！快捷键可以极大地提升操作效率。\n4.2.13.tracking mouse # 这个应该算是一个小小的技巧把，一般在animation effect中进行配置。有的时候，鼠标 颜色难免会难以与其所处的区域进行区分，移动一下鼠标还不容易发现鼠标的位置，怎么 办？开启tracking mouse效果之后，按一下快捷键，就可以发现鼠标的位置了。\n ps：2022.6更新，osx下拼命移动鼠标指针，鼠标指针会变大，也比较容易发现。\n 4.2.14.quick tile windows # 快速地将窗口移动到某一区域（上下左右以及屏幕4个角落）并且使其在该范围内最大化 ，是一个很常用的、有效的操作。很多时候，我们都是同时执行多项任务，并且希望能够 看到多个任务的执行情况，因此，该功能就非常有应用价值了。\nwindows环境中一般有quick tile to left\\right操作，Ubuntu Unity和KDE中一般支持上 下左右以及4个角落的quick tile操作，GNOME3中不清楚，GNOME2中倒是有quick tile to left\\right操作。\n ps：2022.6更新，osx下这点没有linux桌面环境支持的好，基本上要借助工具才能解决。我目前是使用hammerspoon+lua脚本的方式来对这些功能进行管理。hs的好处是提供了lua的接口，如果你能看懂文档，懂点变成，就可以写出自己想要的桌面管理软件来。感兴趣的话可以参考我写的：https://github.com/hitzhangjie/conf/tree/master/macOS-hammerspoon。\n 4.2.15.fcitx+sogou输入法 # 配置一个好用的输入法是至关重要的，特别是在需要中英文混输的情况下，能够快速地在 中英文之间进行切换，并能高效地输入中英文，对于提高输入效率、提高输入体验非常重 要。\n目前在Linux中，最主要的输入法框架主要是给予ibus或者fcitx，其他的都不是很流行。 ibus的话，添加中文输入法之后，可以增加搜狗输入法的词库，但是依然比较鸡肋；最好 的办法就是安装fcitx，然后安装搜狗输入法。\n在Ubuntu 12.04 LTS的时候，由于官方软件源中的fcitx版本较低，不能正常启动搜狗输 入法，因此需要手动添加第三方软件源对fcitx进行更新。现在的Ubuntu 16.04 LTS中 fcitx已经足够新了，直接从搜狗官网上下载deb包进行安装就可以了，比较省事。\n关于搜狗输入法的设置问题，搜狗输入法提供了专门的设置面板，可以修改皮肤、模糊音 等等，提高输入体验。对于输入法切换ctrl+space激活输入法，ctrl+shift在输入法之间 进行切换。\n与windows相比，这里的ctrl+shift在输入法之间进行切换有点差别。在windows中是在所 有的输入法之间进行切换，但是在fcitx中是将所有的输入法分成了两组：Active Group 和Inactive Group，当按下ctrl+shift之后，实际上是在当前group中进行切换，而不是 在所有的输入法之间进行切换。如果要想在所有的输入法之间进行切换，需要进行特别的 设置，如下图所示，勾选上“include inactive input methods when scrolling”。\n ps：2022.6更新，抱歉图片失效了，当初没注意是localhost的链接。\n Ubuntu 16.04 LTS里面有点奇葩，不知道为什么，在.xprofile里面增加export GTK_IM_MODULE=fcitx、export QT_IM_MODULE=fcitx、export XMODIFIERS=\u0026quot;@im=fcitx\u0026quot; 会导致fcitx无法启动。以前在Ubuntu 12.04 LTSu以及Fedora里面都是可以的啊，不晓得 这次是因为什么。wpp（wps里面的演示文稿）需要在启动脚本/usr/bin/wpp中增加上述环 境变量，才能正常输入中文。不然可能运行wpp创建新文件的时候可以输入中文，但是打 开一个已有的ppt文档时就不能够正常输入了。而且更加奇葩的是，wpp里面如果对某一页 演示文稿添加了备注，当切换到这一页的时候，会慢成狗。\n ps：2022.6更新，没想到搜狗被腾讯收购了，变成了一家人，不过现在又要裁员。\n 4.2.16.software-center vs gnome-software # 在ubuntu上面，现在有两款软件安装工具，一个是software-center，ubuntu专属的，另 一个是gnome-software，这个在运行gnome环境的系统上都可以安装，比如在fedora上也可以使用。\n但是gnome-software现在非常不稳定，安装、卸载过程中经常出错，而且对于一些软件组 件（不是一个大型的程序），这种软件包很可能在gnome-software安装列表中就不会出现 。但是ubuntu software-center就可以。怎么说呢，感觉gnome-software不如 software-center实用、健壮，把dpkg数据库搞崩溃了可不是什么好玩的事情。\n ps：使用Linux的一个最大感受就是，free software真香，绝大部分都是免费的，最主要的还是开放源代码，你可以修改啊，也可以学习。现在用了mac后只能从应用商店买，有时候还要找破解版的。鼓励支持正版软件，只是说在Linux下的时候真的感觉很自由、很放松。从社区中来，到社区中去，从社区中学习，也回馈到社区。给当年自由软件先驱们个赞！\n 4.2.17.DevHelp # 可以查看glibc的相关手册，极大帮助自己更加深入地学习C语言编程。我下面就要对 glibc中提供的一些特殊的高级数据类型进行学习，例如链表、树、图、map等等。glibc 参考手册如下所示。\n4.2.18.ctags、cscope # 看源代码的，当然了，自己写代码的时候也是用的到的。归根究底，还是要结合vim使用 ，在vim里面可以根据ctags生成的索引进行跳转，例如跳转到函数定义的位置，查看完成 之后再跳转回来。能实现这种功能的原因是ctags生成的索引信息，能够被vim正确解析， vim再执行相应的跳转操作，实现jump to和jump back操作。再将上述跳转操作绑定到其 他快捷键例如[[和]]上将可以极大地提高代码阅读的效率。\n ps：说实话感觉不是很好用。\n 4.2.19.lxr (linux cross reference) # 看源代码，开阔眼界的。lxr也是给予ctags建立索引信息，此外还能够给予swish-e或者 glimpse进行全文检索，因此在阅读代码时检索一个关键词、函数定义、宏定义等方面是 非常方便的。而且lxr支持点击一个函数调用时跳转到相应的函数定义的位置，相当于 jump to的功能，因为lxr是基于浏览器进行访问的，因此可以通过浏览器的历史执行回退 操作，返回到之前的函数调用页面，相当于jump back的操作。\n因为lxr是基于浏览器的、只读的源代码阅读工具，因此在阅读的时候，可以有效避免对 源代码的误修改操作，但是另一方面，我们也不能对源代码添加注释、修改等。\n选择ctags还是lxr关键还是看个人喜好了，我觉得看大型项目的源代码，如果只是本着学 习的目的进行一下阅读的话，那么用lxr好；如果有修改源代码并进行编译、测试等学习 任务的话，最好用ctags。再或者，直接使用某些其他的IDE也是个不错的选择。关键还是 看个人喜好。\n ps：2022.6更新，这个阅读大型项目源码非常赞，不过添加源码比较啰嗦。现在有了比较好的替代品，sourcegraph。之前学习java jdk的时候用的是在线的grepcode，前几年倒闭了。现在比较好的就是sourcegraph了。\n 4.2.20.其他 # 肯定还有一些很好的工具，不能一一列举，上面这些事用的比较多的。先分享这些把。\n5.哪里学习Linux # 首先得搞明白要学习linux哪方面？是linux桌面发行版的使用，还是linux系统管理，还是linux应用开发，还是linux内核开发的知识……幸好，有很多的社区邮件组、讨论组、问答社区可供我们学习。\nStackExchange \u0026amp; CodeProject \u0026amp; Sourceforge，是极好地学习计算机技术的地方，特别是这个StackExchange，它真的是包罗万象，而且里面的管理员很有水平，当你的问题描述不是很准确时，他们还会帮你润色。通常在上面都能得到大佬们的迅速且有效地解答。我自己是从中受益匪浅。\n学习开发的话，c/c++ primer、glibc学习（常用数据结构等支持很好）、gtk/qt/gnome开发（图形界面）、make、cmake的使用（项目构建）等等。\n在Linux下面感觉做什么都简单，你想想啊，全世界那么多服务器都是跑在Linux上的，基于Linux的开发包、经验分享肯定多如牛毛，就是一个字爽。\n"}),a.add({id:185,href:"/tags/ubuntu/",title:"ubuntu",description:"",content:""}),a.add({id:186,href:"/tags/emacs/",title:"emacs",description:"",content:""}),a.add({id:187,href:"/tags/vim/",title:"vim",description:"",content:""}),a.add({id:188,href:"/blog/2016-01-07-vim%E8%BF%9B%E9%98%B6%E7%AE%80%E6%98%93%E6%89%8B%E5%86%8C/",title:"vim使用进阶常用操作",description:"从开始接触Linux开始就开始接触vim，从刚开始地抵触到现在都离不开（这篇文章写在2016年1月，实际上补充到博客是在2022年6月），10年老用户发现日常的浏览器、IDE编辑器等等都改成了vim操作风格，为什么呢？vim的简约不简单的设计让它成为编辑器之神，一点都不为过，这里仅罗列些一些常见的操作吧，其实还有些常用功能，后续陆续补充或者写一个vim系列，以免一篇万字长文把vim新手吓到。不吹不黑，作为编辑器vim确实有它的过人之处。",content:"vim使用进阶常用操作 # 文件打开退出 #   open and edit files has several modes as following:\n vim filename: open this file vim +n filename: open file and position cursor at line n, `n is a number vim + filename: open this file and position your cursor at last line vim +/pattern filename: open file and position at the first match of pattern vim -r filename: open file and recover from swapfile, swapfile on big RAM is unnecessary, so we can disabled it vim -R filename: open file in mode read-only    providing you have edited the file,if you press:\n :q: to exit and you\u0026rsquo;ll be warned because you have edited file :q!: force to quit and won\u0026rsquo;t get warning message :w: to store the current modification into current file :wq: to store current modification into current file and quit :w fname: store current buffer content into another file fname,save as :ZZ: store current modification and quit    :{n}cq[!] : quit and returns an errcode n, default value of n is 1. you\u0026rsquo;ll need this when you want to abort a git rebase operation :)\n  内容插入内容 #  insert modes,if you press:  i:	insert at current position I:	insert at the beginning of current line a:	append after current position A: append at the end of line o:	insert a new line below current line O:	insert a new line above current line    在文件中移动 #   move your cursor in vim:\n j:	to next line k:	to previous line l:	to right h:	to left    go to specified line:\n \u0026lsquo;line number\u0026rsquo;+\u0026lsquo;G\u0026rsquo;    to the beginning of previous line\n shift +: to the beginning of next line 0:	to the beginning of current line $:	to the end of current line w:	to the beginning of next word,use \u0026lsquo;biaodianfuhao\u0026rsquo; as delimiter W:	like \u0026lsquo;w\u0026rsquo;, but use space as delimiter b:	to the beginning of previous word, \u0026lsquo;biaodianfuhao\u0026rsquo; as delimiter B: to the beginning of previous word, use space as delimiter e:	to the end of next word,\u0026lsquo;biaodianfuhao\u0026rsquo; E:	to the end of next word,space (:	to the beginning of current paragraph ):	to the end of current paragraph {:	to the beginning of previous paragraph }: to the end of next paragraph H:	to the beginning of current screen,not the file M:	to the middle of current screen,not the file L:	to the end of current screen,not the file G:	to the end of file gg:	to the beginning of file    move current line to top/center/bottom\n   z+enter: move current line to top of window z-: move current line to bottom of window zz: move current line to center of window  内容删除操作 #  delete content in vim:   x	:	delete character of current position X	:	delete left character of current position d1	:	like \u0026lsquo;x\u0026rsquo; d0	:	delete characters from the beginning of line to current position d$	:	delete characters from current position to end of line D	:	like \u0026rsquo;d$' d^	:	like \u0026lsquo;d0\u0026rsquo; but characters to delete doesn\u0026rsquo;t include space and tab dw	:	delete chars from current pos to end of word d5w	:	delete chars from current pos to end of next 5 words dtc	:	delete chars from current pos to next \u0026lsquo;c\u0026rsquo; (\u0026lsquo;c\u0026rsquo; not included) dfc	: delete chars from current pos to next \u0026lsquo;c\u0026rsquo; (\u0026lsquo;c\u0026rsquo; included) d/word	:	delete chars from current pos to the first match of \u0026lsquo;word\u0026rsquo; d3{	:	delete from previous 3 paragraphs to current pos d{	:	delete from beginning of current paragraph to current pos db	:	delete from beginning of current to current pos dW	:	delete from current pos to end of word,use \u0026lsquo;space\u0026rsquo; as delimiter dB	:	delete from beginning of current word to current pos,\u0026lsquo;space\u0026rsquo; d5B	:	from previous 5 words to current pos d)	:	from current pos to the end of current line d4)	:	from current pos to the end of next 5 lines d}	:	from current pos to the end of current paragraph d4}	:	from current pos to the end of next 4 paragraphs dd	: delete current line 3dd	:	delete 3 lines from current line dL	: delete from current pos to end of current screen dH	:	delete from beginning of current screen to current pos  读写外部文件 #   read file\u0026rsquo;s content into buffer: :[address] r [filename] read content of \u0026lsquo;filename\u0026rsquo;,then insert the content into the \u0026lsquo;address\u0026rsquo; position of buffer. if address is 0,then insert content into the beginning of buffer. if address is 100,then insert content after line number 100. if address is default,then insert content after current cursor position.\n  write buffer content into file on disk :[address] w [!] [filename] because it is rarely used,we neglect it.we usually use command \u0026lsquo;w\u0026rsquo; to store.\n  文件内容搜索 #   search string /pattern : press / then input the pattern to search\n  search string1 and substitute by string2 :[g] [address] s /searchString/substitueString [/option] usually,we use the command as following format: %s /string1/string2/g\nhere is an example:\n%s /string1/string2 /g || | | | ab c d e  a: we can search string1 in all lines in current buffer b: substitue commmand c: the string we want to search d: use string2 to replace string1 e: /g allows us to substitue every match in the same line.if we neglected \u0026lsquo;/g\u0026rsquo; option,and if multiple matches of string1 occurs,we can only substitue the first match.\n  advanced search and substitute by regexp\nProviding there\u0026rsquo;re many strings monitor_\u0026ldquo;desc\u0026rdquo; in code, we want to replace it with cmd_\u0026ldquo;desc\u0026rdquo;_succ，in which the string $desc is composed of characters like abc……xyz. So how to do that? In vim command mode, we can press: :%s/monitor_\\([a-z]\\{1,}\\)/cmd_\\1_succ。Here [a-z]{1,+} is used to match $desc，the outerscope () is used to capture the first matched group, （notice we do some escaping by \\{1,+}），the group \\1 will let us reuse the first captured group (that is $desc) . In vim, the captured group number is numbered by the order ( appears。 If you think the escape logic is complex, then we can use vim magic or very magic search mode, set magic, then we can use :%s/\\v/monitor_([a-z]{1,})/cmd_\\1_succ instead. Please refer to help magic to read more.\n  分屏切换操作 #   split the vim window:\n horizontally split, :split or :split filename vertically split, :vsplit or :vsplit filename    change window focus in vim: ctrl+w+w\n  ​	we can also use shortcuts to change focus but it\u0026rsquo;s inconvenient,so neglect it.\n​	but we can define key maps to use ctrl+hjkl to move between vim buffers.\nclose windows in vim: providing there\u0026rsquo;re several windows splitted existing:  :q :	to close current window :qall	:	to close all windows :only	: to close the other windows    执行shell操作 #   start a shell in vim: :sh this is the first method to execute shell commands in vim. after you start a shell and execute all commands,you can press \u0026lsquo;exit\u0026rsquo; to quit and go back to vim.\n  execute shell cmd this is another method to execute shell commands. by this method,you can execute only one shell command.\n  ​	suggest we use the first method.\n execute shell cmd and insert the result into buffer\n  :.!command if we\u0026rsquo;re in last line mode,we can use \u0026lsquo;.!command\u0026rsquo; instead of \u0026lsquo;!command\u0026rsquo;,like \u0026lsquo;.!ls -al\u0026rsquo;.\n  :!!command if we\u0026rsquo;re in command mode,we can use \u0026lsquo;!!command\u0026rsquo; instead of \u0026lsquo;command\u0026rsquo;. please note,when we type \u0026lsquo;!!command\u0026rsquo;, actually it is \u0026lsquo;.!command\u0026rsquo;.\n    标记跳转操作 #   marks\n ma : create a mark \u0026lsquo;a\u0026rsquo; at current position \u0026lsquo;a : jump to mark \u0026lsquo;a\u0026rsquo; mb : create a mark \u0026lsquo;b\u0026rsquo; at current position \u0026lsquo;b : jump to mark \u0026lsquo;b\u0026rsquo; ma : following mark created with the same name will override the ones create before    视图类操作 #  mkview/loadview we can create a view for current session, like we can fold/unfold some codes, the state will be saved in the view, which is saved under ~/.vim/views/. even we save/quit, later we reopen the same file, the view created before will be loaded automatically. It\u0026rsquo;s convienient if you\u0026rsquo;re writing some code specially the project is big.  tags搜索跳转 #   ctags/etags we can generate tags for your file content, no matter it is normal text file or source code, it just generate tags for your files, then we can search by tags to quickly find the position where it is defined, then we can jump there.\nwhen generating tags, we need install binary tool like ctags/etags, run ctags -R . is OK for most cases, it will generate tags in your current folder for all files recursively.\n  tags search\nby default, it will search tags file under current directory or the same directory which your editing file resides. sometimes we want vim to search other directories, for example, we write linux programs and we need some linux system headers, we want to jump to the system headers by looking up the tags.\nthen we need to generate tags file for system headers, and we should let vim to search through it. we should add the path to that tags file into vim tags search paths.\nset tags=./tags;tags/;~，it first find tags file in the same directory which the editing file resides, if not found, then it keep searching in current working directory; if not found it searched the user homedir. if still not found, it stopped.\nwe can add system headers path into the search paths.\nPlease read more abount vim tags by :help tags.\n其他 #   you can read my .vimrc to learn more about vim settings:\n  plugins\n plugin manager like vundle autocomplete minibuffers guidelines code snippets syntastic file tree comments vim editor statusbar, like vim-airline vim markdown renderer, like vim-instant-markdown vim markdown toc generator file encoding fix    encoding\n encoding/fileencoding/termencoding    backspace/delete\n  line wrapping\n  autoread file when file outer changed\n  key mappings\n  highlight search, cursorline, cursorcolumn, foreground, background\n  autowrap for specified types\n  split window and move btw them\n  syntax highlight\n  colors theme\n  format paragraph\n  tab and spaces\n  fold and unfold, autofold text block\n  insert text effiently, like time, heading, horziontal\n  create helpfile and generate tags for them, jump btw files by tags\n  settings for coding, like vim-go, etc\n  etc.\n  总结 # vim被IT界赞誉为编辑器之神，与emacs这个被称为神之编辑器的都有很多支持者。\n我是vim的支持者，我喜欢能用一个按键搞定的就不用同时按组合键。有人会质疑，这么多的按键你记得住吗？不是在装x吧？\n真不是，vim优秀的地方，一个是奉行极简主义，这个很符合我的习惯或者说性格；再就是它有非常强大的定制功能，你可以把自己想要的配置以dotfiles的形式维护起来，就像我一样，换个地方换个机器把配置拖下来，就可以用起来。\n前期虽然学习成本高，一旦上手很容易爱不释手，萝卜青菜各有所爱 :) 当时是怎么决定要修炼vim的呢？是为了装x看能不能在完全脱离鼠标的情况下对计算机进行各种操作，比如通过命令、配置等等，虽然初衷不纯，但是最后还是上车了 :)\n"}),a.add({id:189,href:"/blog/2022-05-08-%E5%86%99%E5%9C%A8%E6%AF%8D%E4%BA%B2%E8%8A%82/",title:"写在2022.5.8母亲节：无题",description:"今天是母亲节，在这个特殊的日子，默默地写点东西表达下对妈妈、老婆的感谢，写着写着就跑偏了，都感谢下吧，希望今年一切顺利。",content:" img { width: 680px; padding-bottom: 1rem; }  写在前面\n过去很多个时间节点，本来应该写下点什么，好让它显得更丰满些、有仪式感些，显得自己没有虚度这段时光。这样那样的原因，一次次作罢。今天有点手指酸疼，也不是很想去写的，但我担心错过这个特殊的日子，以后找不到这样的好时机来倾诉这些沉积很久的想法，所以还是矫情一回吧。\n竟也用上了“无题”做题目，可能是因为多重角色的变化，萦绕在心头的思绪更多了些、复杂了些吧，不过本文也确实没预设主题。\n感恩老婆：你的第一个母亲节\n对农历我总是搞不清楚，即便偶尔发现个特殊的节气、节日也是无意中听说，由于从小过生日都是按照农历，所以我的生日也基本是父母、姨妈、姥姥他们提及的时候我才会知道，哦，生日那天可以加餐意思下。\n也经常有这样的文章，孩子生日那天，却也是母亲最痛的那天，孩子也应该在生日那天表达下对母亲的感恩。也明白这个道理，但是却没法感同身受。\n宝贝闺女出生，我从深圳赶到武汉后，只能在产房外等待，没能陪伴在老婆旁边，也没感受到她有多撕心裂肺的疼痛，当我怀揣着惊喜去看她娘俩时，看到老婆脸色那么憔悴，加上晚上陪床时临近产房的年轻妈妈疼的直喊，我也看到了医护清理出来的胎盘……一下子内心揪了一下，生个娃做母亲的真的太不容易了。\n联想到老婆产前从体型微胖到长个大肚子行动不便，产后的各种恢复，带娃的辛苦，在我这个“奋斗B”在深圳几乎缺席了一切相关事项的情况下，老婆几乎自己一个人扛下了所有劳累和委屈。\n感谢老婆，送给我一个小天使，感谢老婆的辛苦付出，今天也是你的第一个节日。虽然小宝贝还不会叫妈妈，但现在已经知道了去找妈妈，以后她也会慢慢变成你的跟屁虫，母亲节也会给你送来束康乃馨，就先憧憬下吧。\n感恩母亲：今天才体会到那份不易\n如果没有亲自看到老婆经历的那些不易，我可能永远也不会感受到做母亲的那份不易，而且是在30年前那样的生活、医疗条件下。\n从我记事起，妈妈就是我心灵的港湾，省吃俭用，给我做好吃的，给我做衣服，做鞋子，教我识拼音、写字、算术，刚去上学时该会的也都会差不多了。那时候，家里条件也不好，爸爸妈妈辛辛苦苦地劳动，家里再难的时候，也不让我因此而受伤分毫。\n念了那么多年书，终于毕业了，我急不可耐地要去试试，可是爸爸却先走了，那段时间虽然妈妈和我来了深圳，但是我能感受到，她很压抑，早出晚归的儿子、不熟悉的环境、不熟悉的网络购物、不熟悉的医院就诊流程，等等。我开始想，有可能妈妈是为了维护儿子在他人眼中的孝心选择性地放弃了熟悉的家、人、环境，难为妈妈了。\n老婆怀孕后，妈妈也尽己所能赶来照顾，人生地不熟的武汉，我也担心这婆媳矛盾会不会也让我束手无策，不过妈妈和老婆都是通情达理之人，也没出现过矛盾，真的很让人欣慰，但这背后她们也各自牺牲了很多。\n母亲节快乐，再过些天，你也会多个跟屁虫，被喊“奶奶”也很开心吧。\n感谢警察：对我的批评教育\n爸爸刚走那一两年，我常觉得这个没有他的世界几乎不可接受。爸爸身上那种正直、坚毅、豁达的品质，在家族中也比较受长辈同辈小辈的信任。我虽本性不坏，但是做的就没爸爸好，原本打算多跟爸爸聊聊，让自己做的更好。可谁能想到，我的良师益友就这么走了。\n那段时间眼里容不得沙子了，几乎自我封闭了和其他人的接触和交流。工作上也因此或多或少遇到些不快，这段时间也没少和老婆、妈妈抱怨。\n有段时间我也经常看些“针砭时弊”的内容，好的坏的、对的错的，我只相信自己的眼睛、思考，唠叨个不停，老婆也听的烦，妈妈再听估计也听出了老茧。后面我发现也改变不了她们，她们也不关心这些，我就更郁闷了。当我看Youtube一些相关内容时，老婆就会主动播放金灿荣等人的视频。\n深圳的快节奏也是出了名的，当你双脚落地深圳开始，你就开始走路带风了。大多数年轻人都脚步如飞，他们也很拼，惜时如金。有时是城市规划的问题，有时是平台调度策略的问题，有时是人自己的问题，谁都想快一点，你快就需要有人配合你慢一点，不然就容易出冲突。\n总有些漠视规则的人会来挑动你的神经，差点割喉的电动车遮阳棚、看手机频繁踩你脚后跟的行人、斑马线和行人抢路的司机、和行人抢路闯红灯的外卖小哥、不避让自行车的司机，等等。\n这些因素叠加到一起，最终让我变成一个火药桶。终于后面发生了一次冲突，调节中，一个差不多爸爸这个年纪的警察，和我聊了聊，“你就说大哥你厉害”，“你可以骂他吐口水”，“他不对在先，但你犯不着把他……”，“年轻人年轻气盛可以理解”，“不值得”，道理是很简单的道理……但是我有多久没有听到来自长辈的“疏导”了。我忽然感觉到豁然开朗，前所未有的轻松，感谢深圳警察的批评教育，让我以一个小错误及时“迷途知返”。\n去年年底，对一家假冒的苹果售后服务中心的维权过程，算是我把警察的话听进去了，这个社会上有很多资源能协助你惩罚犯错误的人，只要你利用好它们，没必要剑走偏锋。\n感谢亲朋：谢谢你们一直在\n工作后也没什么机会和亲朋常聚聚，再加上这几年疫情防控，机会就更少了，21年底因为小宝宝太小也没有回老家。20年底办婚礼的时候，那个时候在婚礼现场心血来潮拍照怎么能少的了和发小、朋友们呢？拍了几张合照。\n不过没几天老婆就有喜了，后面就忙着各种相关的事情，竟然忘记了把这些照片给导出来。过些天抽个周末，把这些照片整理一下，给家人朋友们发一下。\n感谢你们一直在，虽然也常常很久不联系。虽然我们身处不同的城市，做着不同的工作，每天操心着不同的话题，但是总有些东西是我们共同关注的，比如生活、带娃。\n时间、空间，会让人与人产生距离感，像山东、深圳距离1700公里，也不过是2小时的距离，友谊之上的时空距离，我认为只是一句微信“嘿，在吗”的距离。\n感谢伤疤：认识并爱惜身体\n这个世界离了谁都会转，哪怕人类灭绝，几百亿年后也可能诞生其他物种，所以，这个世界不是为谁而存在，我们才是这个世界的游客。当我们在旅途中遇到些不快，也尽量怀揣着乐观的心态去观察它吧。\n“伤疤，是美好生活的刺青”，20年吧，骑着自行车重重从车把前摔了出去（车轮卡在砖缝里），晚上太黑来不及反应，手掌被擦掉3~4平方厘米左右的皮，火辣辣地疼，一只手骑到小区门口发了这条朋友圈， “Scars are just tattoos of better stories”。\n因为我坚持骑行十几年，这是我喜欢的事情，所以在因它而受伤后才会这么乐观，如果是工作生活上的糟糕的其他事，我可能就没这么好心情了。\n21年，因为意外伤到了一只手指，住院。病房里有位大哥类似的伤，因为想省钱选择截去了手指。我的费用，报销前总计1w多，报销完后2600。这个社会并不是那么其乐融融的，有很多群体收入并不高，在出现身体上的问题时，还是会有些人迫于经济压力被动地、无奈地放弃。这件事对我触动还是很大，我也开始关注治疗的局限性，有些东西能修但修不彻底。\n以前我听过两种不同的声音，“留得青山在，不怕没柴烧”，“为了革命，你还怕流血牺牲吗”。很明显，断章取义只会曲解我们的认识。\n我想说的是，任何时候我们选择爱惜自己的身体，都不能算作是错误。从自己这个个体而言，这个世界上除了你甘愿为之献身的目标以外，几乎不存在任何比你的身体更有价值、高级的东西。\n21年读了一本书《人体的秘密》，我很喜欢里面一段话，和大家分享下，大意是说：“就在我们迷茫、不知所措的当下，你的身体里无数的细胞、各种组织、器官正在为你的正常运行以最大地效率工作……”。闭上眼睛体会下，就在我们不知所措的当下，有无数的细胞正在为我们拼命地运转。人体、生命，是多么奇妙啊！事实上，除去健康人体中的“精神”，单看组建人体的化学元素，造价就要上百万元（或者百万美元），更不用说这些物质组件起来的复杂的组织、器官了，而且还没有考虑人类最伟大的“大脑的思维”。\n身体有些东西，坏了就是修不好的，比如伤疤、牙齿、脱发、肌腱，等等这些显而易见的。更值得深思的是，我们挣得的收入，并不一定够用来垫付身体损害的修复费用。\n希望大家能坚持查体，多关注身体异常，用正确的方法爱惜自己的身体总没有错的，除非你愿意为之做出牺牲。\n拥抱多元：不同正是存在的价值\n慢慢地发现很多人对很多事务的看法都是不同的，我们常以这句话自驱，“君子和而不同，小人同而不合”，说直白点，不同才是我们存在的价值，我思故我在，尽管我的认知不一定全面、正确，但是我相信一定有比我更聪明、有见识的人，只要他能把我反映的因素考虑进去，在更高层次的抽象、设计层面予以解决掉，那这就是有价值的。\n因为做计算机相关工作的原因，我加入了一些Slack群组、Twitter关注了一些比较牛的技术人员，几年之后，我可以很舒心的说，showoff一下没事，这很正常。\n以前我的QQ空间、朋友圈、微博夹杂着各种技术文章，后来我看大家都不怎么发，那算了吧，我感觉我也打扰到大家了，就不发了吧。遗憾的是，我认为这是一种圈子里的交流。我们真的要对好友列表打上各种标签，发条朋友圈之前斟酌一番吗？\n我关注的这些大佬还都挺平易近人的，他们也会晒娃，晒codesnippet，晒自己新买的宝马，晒自己刚还完房贷，晒自己书写到哪里了，晒自己敲键盘手速有多快（有次跟大佬pk过，略逊一筹），晒自己接下来要去哪里分享，晒今天和女友的约会很开心…这样的生活多简单！\n另外，近几年出现了不少App想打破熟人社交的模式，soul等等的，主要原因还是一些现实原因导致上述问题似乎无法不好解决，年轻人甚至也包括一些像我这样的“老人”也开始去尝试一些打破熟人社交的方式，showoff是多么重要，目的还是为了给社交注入一些有活力的元素，才更有可玩性。\n人，真的没必要把自己隐藏起来，我还是希望我的朋友圈里面能有些晒这个晒那个的，虽然我不一定看的懂，但如果你能炫一下，那对我而言应该也确实开拓了下眼界。也不用担心自己的意见是否不同，是否会被赞同，如果你抱着更加积极开放的心态去互动，也会不断修正自己的观点。\n现实中，有很多人不分享，有的是担心被认为是炫耀，但是他明明只是为了分享体验，如果后续XR技术的加成，一位身处德国骑着s1000rr的骑友可以让处于禁摩地带的我感受一波300km/h的癫狂速度，那你说我会以为他在炫耀他有跑车吗？不会。\n技术，归根结底还是服务于人类的现实生活，只不过它可能通过了虚拟的途径，这里的“虚拟”也只是一种媒介而已，又有什么区别呢？我和异国他乡的朋友通电话，他听到的声音也是虚拟的，并不是我的声音340m/s传播过去的，可这又有什么关系呢？\n虚拟，并不是为了把大家架设在虚拟中，恰恰它是建立在现实基础上的进一步抽象，通过它可以丰富我们连接的媒介。比如深圳夜晚加班的我可以触摸到武汉婴儿床上的宝贝，感受到她q弹的皮肤、宁静的喘息声。\n现在元宇宙概念火热，如果你联想不到更多的场景，不要急，不妨让子弹再飞一会儿，也许那时候会有还不错的场景落地实现。\n收尾吧\n好像说了很多，这大致就是我近段时间的想法，感谢老婆、感谢母亲、感谢亲朋、感谢警察同志、拥抱不同的声音。2022变化颇多，做当下最正确的决定吧，剩下的交给运气，相信大家运气都不会太差。\n"}),a.add({id:190,href:"/tags/%E6%AF%8D%E4%BA%B2%E8%8A%82/",title:"母亲节",description:"",content:""}),a.add({id:191,href:"/tags/%E7%88%B6%E4%BA%B2%E8%8A%82/",title:"父亲节",description:"",content:""}),a.add({id:192,href:"/tags/ha/",title:"HA",description:"",content:""}),a.add({id:193,href:"/tags/sla/",title:"SLA",description:"",content:""}),a.add({id:194,href:"/blog/2022-06-21-%E5%AE%9E%E8%B7%B5%E4%B8%AD%E9%AB%98%E5%8F%AF%E7%94%A8%E5%A6%82%E4%BD%95%E5%81%9A/",title:"实践中高可用如何做",description:"大家经常提及高可用，但是什么情况下要去考虑高可用，哪些服务应该做高可用，有状态、无状态服务实现高可用的方法又有什么不同？本文对此做了一些思考，也提供了一些比较常用的低成本的解决思路。",content:"高可用 # 提升服务可用性当然是一件好事，但是实现高可用也是有成本的。提升可用性的常用做法是通过靠设备冗余来实现，当然还有其他的办法，但是不管是哪种办法，做这些工作是有成本的。实践中，一般要权衡投入产出比，来决定需不需要做HA，做的话对哪些服务做HA。\n提升可用性的手段 # 所谓高可用，可以从以下几个方面来考虑：\n 进程内模块的开闭（特性开关）：对异常代码分支进行打开、关闭控制，有问题时可以关闭 特定用户的影响：特定用户本地数据问题可能触发某种异常，可以暂时对用户屏蔽特定逻辑 子系统级的影响：大系统小做，轻重分离，将关键服务和一般服务拆分开，避免互相影响 进程级的影响：多进程模型，避免单个进程挂掉产生影响，常用的共享内存队列+多进程 节点级的影响：单个节点挂掉，可以通过冗余、屏蔽故障节点的方式来解决，主备、集群等 组件级的影响：对组件的性能边界要有清晰的认识 大流量冲击：消息队列削峰 地震火灾导致的区域性故障：部署时考虑跨机房、跨区域部署，异地多活 等等  有状态、无状态服务 # 服务也分为有状态服务、无状态服务，对这两种情景的处理方式一般也不同的。\n 无状态服务，一般通过屏蔽故障节点、负载均衡的方式来解决即可； 有状态服务，则相对更复杂一些。总而言之节点级的可用性的提升，一般要借助设备冗余来实现，但是对游戏业务而言，这个成本会比较高。而且有些游戏后台服务是有状态服务，对这类服务做HA会明显增加整体方案的复杂度（比如主备方案，或者分片+副本的集群方案），而且设备成本也会增加很多。设备成本过高，还不如让玩家重开一局。  游戏业务的特点和普通的业务可能不太一样，其战斗服务器一般都是有状态服务，所以主流无状态服务采用的HA方案、主备或者集群方案，不一定总适用于游戏场景的，因为考虑到机器挂掉后恢复的收益，这个实现成本、方案复杂度就太高了。\n游戏业务中对有状态服务的HA一般这样做，可能会通过：\n 分区分服 分set 多进程 大系统小做+轻重分离 特性开关 用户数据异常屏蔽 等等  通过这些方式的来降低问题影响面，也算是提升可用性的办法吧。\n"}),a.add({id:195,href:"/tags/%E6%97%A0%E7%8A%B6%E6%80%81/",title:"无状态",description:"",content:""}),a.add({id:196,href:"/tags/%E6%9C%89%E7%8A%B6%E6%80%81/",title:"有状态",description:"",content:""}),a.add({id:197,href:"/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/",title:"高可用",description:"",content:""}),a.add({id:198,href:"/tags/algorithm/",title:"algorithm",description:"",content:""}),a.add({id:199,href:"/tags/data-structure/",title:"data structure",description:"",content:""}),a.add({id:200,href:"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/",title:"数据结构与算法",description:"",content:""}),a.add({id:201,href:"/blog/2022-05-24-%E6%B5%85%E8%B0%88%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/",title:"浅谈数据结构与算法",description:"本科学数据结构与算法时，自己也比较注意理论实践想结合，对课本上讲授的内容也算是掌握的比较好，到考研复习时甚至能直接拿出草稿纸把课本中所有线性表、树、图等相关的算法直接给手写出来，至今我还保留着当时的一份草稿 :)\n数据结构与算法是比较重要的，当对计算性能、存储空间提出明确要求时，就需要考虑计算复杂度、空间复杂度的问题，只不过实际工作中要求没有那么高，大家也没有那么重视而已。但是当涉及到一些复用范围比较广的代码，一般都会做benchmark来验证其是否ok。\n如果一个同学脑海里有成体系的数据结构与算法的训练，在设计方案时也会同时考虑几种方案并平衡各自优缺点，这其实就是一个非常好的工程素养。当然了数据结构与算法的训练，也会逐渐培养大家一种能力，就是化繁为简、把特殊问题一般化，这种能力在编码、设计解决方案时也会具备更好的维护性。\n我自认为自己具备这种能力了，但是实际情况是，在我接触了分布式领域的相关知识后，我发现数据结构与算法真的是博大精深，数据结构可以小到一个数组，也可以大到一个B+树，而对他们的运用更能彰显掌握的精炼程度，数组记录的可能是一系列普通数值，也可能是一个分布式领域冲突检测的时钟向量。\n在数据结构与算法的课本上，可能接触不到这么广泛的领域，某种程度上会让人觉得课本知识有点死板、枯燥，不知道前Google工程师王争的极客时间课程《数据结构与算法》之美，是否会有另一番味道？另外，自己从未参加过ACM竞赛之类的，也看过一些参与竞赛的同学的分享、编程模板，内容覆盖面之广也让我汗颜，自觉能力不能及。\n所以我准备试读下王争的课程《数据结构与算法》，go go go。",content:"本科学数据结构与算法时，自己也比较注意理论实践想结合，对课本上讲授的内容也算是掌握的比较好，到考研复习时甚至能直接拿出草稿纸把课本中所有线性表、树、图等相关的算法直接给手写出来，至今我还保留着当时的一份草稿 :)\n数据结构与算法是比较重要的，当对计算性能、存储空间提出明确要求时，就需要考虑计算复杂度、空间复杂度的问题，只不过实际工作中要求没有那么高，大家也没有那么重视而已。但是当涉及到一些复用范围比较广的代码，一般都会做benchmark来验证其是否ok。\n如果一个同学脑海里有成体系的数据结构与算法的训练，在设计方案时也会同时考虑几种方案并平衡各自优缺点，这其实就是一个非常好的工程素养。当然了数据结构与算法的训练，也会逐渐培养大家一种能力，就是化繁为简、把特殊问题一般化，这种能力在编码、设计解决方案时也会具备更好的维护性。\n我自认为自己具备这种能力了，但是实际情况是，在我接触了分布式领域的相关知识后，我发现数据结构与算法真的是博大精深，数据结构可以小到一个数组，也可以大到一个B+树，而对他们的运用更能彰显掌握的精炼程度，数组记录的可能是一系列普通数值，也可能是一个分布式领域冲突检测的时钟向量。\n在数据结构与算法的课本上，可能接触不到这么广泛的领域，某种程度上会让人觉得课本知识有点死板、枯燥，不知道前Google工程师王争的极客时间课程《数据结构与算法》之美，是否会有另一番味道？另外，自己从未参加过ACM竞赛之类的，也看过一些参与竞赛的同学的分享、编程模板，内容覆盖面之广也让我汗颜，自觉能力不能及。\n所以我准备试读下王争的课程《数据结构与算法》，go go go。\n"}),a.add({id:202,href:"/tags/pattern/",title:"pattern",description:"",content:""}),a.add({id:203,href:"/blog/2022-04-24-understanding-design-patterns/",title:"Understanding the Design Patterns",description:"The design patterns is a blueprint about how to solve a commonly-reoccuring prolem in specific occasions.According to scale and complexity, the patterns could be categorized as Architecture Patterns, Design Patterns and Idioms.",content:"The design patterns is a blueprint about how to solve a commonly-reoccuring prolem in specific occasions.According to scale and complexity, the patterns could be categorized as Architecture Patterns, Design Patterns and Idioms.\nIntroduction # go-patterns actually is short for design patterns in go, which shows list of demos behind the concepts.\nWe must think about the following questions before we dive into the demos, it is really important.\n What\u0026rsquo;s a pattern? What\u0026rsquo;s a design pattern? History of patterns? Why should I learn patterns? Criticism of patterns? Classification of patterns? etc.  What\u0026rsquo;s a pattern? # Pattern is a solution, which works well in practices, to a commonly reoccurring problems. Patterns could be created and shared in every area, like building body, improving representation skills, architecture skills, or software design.\nI\u0026rsquo;m a developer, when I talk about patterns, I mean the software design pattern. Learning patterns can help us build software on the collective experience of skilled software engineers. Then when we work on a particular problem, we could recall a similar problem which had already been solved and reuse the essense of its solution to solve this new problem. That\u0026rsquo;s 举一反三 in Chinese.\nWith the help of patterns, novices will work better as if they were (or almost as if they were) experts on modest-sized projects, without having to gain many years of experience.\nWhat makes a pattern? # A pattern for software architecture describes a particular recurring design problem that arises in specific design contexts, and presents a well-proven generic scheme for its solution. The solution scheme is specified by describing its consitituent components, their responsibilities and relationships, and the ways in which they collaborate.\nSee: Pattern-Oriented Software Architecture, Volume 1, Page 8~11.\n Context: a situation giving rise to a problem. Problem: the recurring problem arising in that context. Solution: a proven resolution of the problem.  Pattern Categories # In software design area, patterns could be split into different layers.\nA closer look at existing patterns reveals that they cover various ranges of scale and abstraction.\n Some patterns help in structuring a software system into subsystems. Other patterns support the refinement of subsystems and components, or of the relationships between them. Further patterns help in implementing particular design aspects in a specific programming language.  Patterns also range from domain-independent ones, such as those for decoupling interacting components, to patterns addressing domain-specific aspects such as transaction policies in business applications, or call routing in telecommunication.\nTo refine our classification, we group patterns into three categories:\n  Architecture Patterns\nViable software architectures are built according to some overall structuring principle. We describe these principles with architectural patterns.\n A architectural pattern expresses a fundamental structural organization schema for software systems. It provides a set of predefined subsystems, specifies their responsibilities, and includes rules and guidelines for organizing the relationships between them.\n Architectural patterns are templates for concrete software architectures. They specify the system-wide structual properties of an application, and have an impact on the architecture of its subsystems. The selection of an architecture pattern is therefore a fundamental design decision when developing a software system.\n  Design Patterns The subsystems of a software architecture, as well as the relationships between them, usually consist of several smaller architectural units. We describe these using design patterns.\n A design pattern provides a scheme for refining the subsystems or components of a software system, or the relationships between them. It describes a commonly-recurring structure of communicating components that solves a general design problem within a particular context.\n Design patterns are medium-scale patterns. They are smaller in scale than architectural patterns, but tend to be independent of a particular programming language or programming paradigm. The application of a design pattern has no effect on the fundamental structure of a software system, but may have a strong influence on the architecture of a subsystem.\nMany design patterns provides structures for decomposing more complex services or components. Others address the effective cooperation between them, such as the following pattern: Observer or Publisher-Subscriber.\n  Idioms Idioms deal with the implemention of particular design issues.\n An idiom is a low-level pattern specific to a programming language. An idiom describes how to implement particular aspects of components or the relationships between them using the features of the given language.\n Idiom represent the lowest-level patterns. They address aspects of both design and implemention.\nMost idioms are language-specific, they capture existing programming experience. Often the same idiom looks different for different languages, and sometimes an idiom that is useful for one programming language doesn\u0026rsquo;t make sense in another.\n  Relationships between Patterns # A pattern solves a particular problem, but its application may raise new problems. Some of these can be solved by other patterns.\nMost patterns for software architecture raise problems that can be solved by smaller patterns. Patterns do not usually exist in isolation. Each pattern depends on the smaller patterns it contains and on the larger patterns in which it is contained.\nAnd a pattern may also be a variant of another.\nPatterns can also combine in more complex structures at the same level of abstraction. Each pattern resolves a particular subset of the forces to balance the forces when solving the problem.\nPattern Description # Patterns must be presented in an appropriate form if we are to understand and discuss them. A good description helps us grasp the essense of a pattern immediately:\n what\u0026rsquo;s the problem the pattern addresses? what\u0026rsquo;s the proposed solution?\nA good description also provides us with all the details necessary to implement a pattern, and to consider the consequences of its application. describe the solution uniformly!\nThis helps us to compare one pattern with another, especially when we are looking for alternative solutions to a problem.  The basic Context-Prolem-Solution structure provides a good starting point for a description format, but it is not enough.\nA pattern must be named - preferably with an intuitive name - if we are to share it and discuss it.\nOK, a good pattern template is showed below, please use it as a starting point:\n Name The name and a short Summary of the pattern. Also Known As Other names for the pattern, if any are known. Example A real-world example demonstrating the existence of the problem and the need for the pattern. Throughout the description we refer to the example to illustrate solution and implementation aspects, where this is necessary for useful. Context The situations in which the pattern may apply. Problem the problem the pattern addresses, including a discussion of its associated forces. Solution The fundamental solution principle underlying the pattern. Structure A detailed specification of the structural aspects of the pattern, including CRC-cards and OMT class diagram. Dynamics Typical scenarios describing the runtime behavior of the pattern. We further illustrate the scenarios with Object Message Sequences Charts. Implementation Guidelines for implementing the pattern. ...... ....... Variants A brief description of variants or specializations of a pattern. Known Uses Examples of the use of this pattern, taken from existing systems. Consequences The benefits the pattern provides, and any potiential liabilities. See Also References to patterns that solve similar problems, and to patterns that help us refine the pattern we are describing.  Will you learn patterns? # Now I think your answer will be definitely 100% Yes.\nRepository hitzhangjie/go-patterns will aim to provide demos for design patterns and idioms in golang. Hope we could follow the design details of design patterns to quickly solve the recurring problems.\n"}),a.add({id:204,href:"/tags/gdb/",title:"gdb",description:"",content:""}),a.add({id:205,href:"/blog/2022-04-10-macos-10.15.7%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AEgdb/",title:"macOS 10.15.7安装配置gdb",description:"macOS darwin内核的调整导致gdb无法正常工作，本文总结了权限问题、调试卡死问题的一种解决办法，亲测可用。但是该办法只是绕过了某些异常，并没有彻底修复gdb的bug",content:"问题简介 # gdb作为一款符号级调试器，是广大开发人员排查问题的神兵利器，但是因为macOS darwin内核的一些调整，gdb出现了各种神奇的bug行为，如权限问题导致的无法启动调试、启动调试后调试会话卡死等等。\n作者此前也曾经因为此类问题而苦恼，甚至不得不放弃了使用gdb调试器而使用其他办法来排查。最近在通过homebrew安装jupyterlab的时候发现gdb被升级了，就突然想起了之前被搁置的这个问题，测试后发现gdb还是不可正常使用。因此google一圈加不断测试，最终终于成功了。\n这里总结下方便日后查阅，也供遇到类似问题的朋友参考，这确实是一个老大难的问题了。google能发现很多针对该问题的讨论，难兄难弟们，let\u0026rsquo;s go。\n如何解决 #   download the source code zip file from https://github.com/bminor/binutils-gdb.git, unzip the zipfile to ./binutils-gdb-master\n  then try to build from master HEAD\nmkdir build cd build ../binutils-gdb-master/configure \\ --disable-unit-tests \\ --disable-binutils \\ --without-guile make -j8  the built gdb binary is put here: ./gdb/gdb. Because I want to make package management simpler, so I don\u0026rsquo;t want to run make install to install the gdb and other files.\n ps: there\u0026rsquo;s no make uninstall target in the Makefile, if you want to remove all installed files, try this:\n make install DESTDIR=/tmp/gccinst find /tmp/gccinst | sed -e s,/tmp/gccinst,, | \\ (while read F; do rm \u0026quot;$F\u0026quot;; done)    I then run brew install gdb to install the homebrew latest version, then I replace the gdb binary by:\ncp ./gdb/gdb /usr/local/Cellar/gdb/11.2/bin/gdb -f    Then codesign mentioned above, OK, I put it here for convenience: write a gdb-entitlement.xml:\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot; encoding=\u0026quot;UTF-8\u0026quot;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026quot;-//Apple//DTD PLIST 1.0//EN\u0026quot; \u0026quot;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026quot;\u0026gt; \u0026lt;plist version=\u0026quot;1.0\u0026quot;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.allow-jit\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.allow-unsigned-executable-memory\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.allow-dyld-environment-variables\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.disable-library-validation\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.disable-executable-page-protection\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.cs.debugger\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;com.apple.security.get-task-allow\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt;  then run following command to codesign:\nsudo codesign --entitlements gdb-entitlement.xml -fs gdb-cert $(which gdb)  If you haven\u0026rsquo;t created gdb-cert before, run following command to create:\n# download the script, or create one with the content in Appendix https://github.com/conda-forge/gdb-feedstock/blob/main/recipe/macos-codesign/macos-setup-codesign.sh # replace the certificate name sed -i 's/gdb-codesign/gdb-cert/g' macos-setup-codesign.sh # run the script to create the certificate and trust it ./macos-setup-codesign.sh # check the certificate is create or not security find-certificate -p -c gdb-cert | openssl x509 -checkend 0 or security find-certificate -p -c gdb-cert |openssl x509 -noout -text\\    then you can start your debugging, it works.\n  小节 # 本文总结了解决macOS平台上gdb无法正常调试的问题，这个办法只是解决了我和部分开发人员遇到的问题，但是并没有从根本上修复问题，不排除在您的环境下依然存在问题，请自己尝试是否有效，不行就继续寻找其他解决方案。\n附录 #   macos-setup-codesign.sh\n#!/bin/bash # This script is copied from https://github.com/llvm/llvm-project/blob/master/lldb/scripts/macos-setup-codesign.sh CERT=\u0026quot;gdb_codesign\u0026quot; function error() { echo error: \u0026quot;$@\u0026quot; 1\u0026gt;\u0026amp;2 exit 1 } function cleanup { # Remove generated files rm -f \u0026quot;$TMPDIR/$CERT.tmpl\u0026quot; \u0026quot;$TMPDIR/$CERT.cer\u0026quot; \u0026quot;$TMPDIR/$CERT.key\u0026quot; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 } trap cleanup EXIT # Check if the certificate is already present in the system keychain security find-certificate -Z -p -c \u0026quot;$CERT\u0026quot; /Library/Keychains/System.keychain \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 if [ $? -eq 0 ]; then echo Certificate has already been generated and installed exit 0 fi # Create the certificate template cat \u0026lt;\u0026lt;EOF \u0026gt;$TMPDIR/$CERT.tmpl [ req ] default_bits = 2048 # RSA key size encrypt_key = no # Protect private key default_md = sha512 # MD to use prompt = no # Prompt for DN distinguished_name = codesign_dn # DN template [ codesign_dn ] commonName = \u0026quot;$CERT\u0026quot; [ codesign_reqext ] keyUsage = critical,digitalSignature extendedKeyUsage = critical,codeSigning EOF echo Generating and installing gdb_codesign certificate # Generate a new certificate openssl req -new -newkey rsa:2048 -x509 -days 3650 -nodes -config \u0026quot;$TMPDIR/$CERT.tmpl\u0026quot; -extensions codesign_reqext -batch -out \u0026quot;$TMPDIR/$CERT.cer\u0026quot; -keyout \u0026quot;$TMPDIR/$CERT.key\u0026quot; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 [ $? -eq 0 ] || error Something went wrong when generating the certificate # Install the certificate in the system keychain sudo security add-trusted-cert -d -r trustRoot -p codeSign -k /Library/Keychains/System.keychain \u0026quot;$TMPDIR/$CERT.cer\u0026quot; \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 [ $? -eq 0 ] || error Something went wrong when installing the certificate # Install the key for the certificate in the system keychain sudo security import \u0026quot;$TMPDIR/$CERT.key\u0026quot; -A -k /Library/Keychains/System.keychain \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 [ $? -eq 0 ] || error Something went wrong when installing the key # Kill task_for_pid access control daemon sudo pkill -f /usr/libexec/taskgated \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 # Exit indicating the certificate is now generated and installed exit 0    "}),a.add({id:206,href:"/tags/debugging/",title:"debugging",description:"",content:""}),a.add({id:207,href:"/tags/delve/",title:"delve",description:"",content:""}),a.add({id:208,href:"/tags/dlv/",title:"dlv",description:"",content:""}),a.add({id:209,href:"/tags/k8s/",title:"k8s",description:"",content:""}),a.add({id:210,href:"/tags/kubernetes/",title:"kubernetes",description:"",content:""}),a.add({id:211,href:"/blog/2022-04-08-%E5%AE%9E%E7%8E%B0k8s%E5%BA%94%E7%94%A8%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/",title:"实现k8s应用远程调试",description:"最近在支持团队测试左移、测试规范、CI/CD流水线方面的一些工作，针对开发人员发现问题、定位问题、修复问题这个过程产生了一点新的想法，尤其是在整体上云后的大背景下，我认为值得和大家一起探讨下，如何借助远程调试更快速地定位k8s应用问题。",content:"最近在支持团队测试左移、测试规范、CI/CD流水线方面的一些工作，针对开发人员发现问题、定位问题、修复问题这个过程产生了一点新的想法，尤其是在整体上云后的大背景下，我认为值得和大家一起探讨下，如何借助远程调试更快速地定位k8s应用问题。\n1 问题背景 # 现在公司大部分业务都上云了，服务部署基本上也k8s容器化了，解决了一些老大难的问题，本文不讨论k8s的好处，我们讨论下开发k8s应用（比如微服务）时开发侧可能碰到的一些问题。前段时间我开发了一个统计模调接口成功率的服务，部署在123平台，因为服务代码有些隐晦的bug排查修复花了些时间，这个过程中就开始思考为什么我对go、trpc很熟的情况下定位问题还这么麻烦呢？于是就有了接下来的探索以及这篇总结。\n2 经常遇到的问题 # 如果一件事情，短时间内需要人肉重复很多遍，就很容易让人抓狂，比如这次开发体验很快就让我抓狂了：\n 测试服务发现服务表现不正常，准备定位bug 查看错误日志初步锁定问题范围，重新走读代码进一步缩小问题范围 修改代码、提交代码，构建镜像、发布，然后重新测试  排查问题不只是这么轻描淡写，简单3步就搞定了：\n 可能是bug不容易定位，在外部数据满足某种条件下或者遇到某种事件时才会触发bug； 可能是测试用例覆盖不够，通过上述方法定位并解决了问题1，但是后面发现了问题2； 可能是日志信息不够，错误异常分支没有日志，或者日志信息不全； 微服务架构事务处理会跨越多个服务，可能要结合tracing、logging、metrics多个系统联合排查； 修改代码后提交并构建发布，可能涉及到CI/CD环节，流水线耗时较长； 123平台提供了dtools来快速构建、patch，但是破坏了测试环境稳定性（缺少镜像） TKE有同学基于七彩石配置下发实现的替换工具，存在dtools类似的问题； ……  总之，这个排查过程可能要涉及到多轮人肉操作，作为一个VIM党连上下移动都觉得用滑动鼠标、按上下左右是种低效的操作，更不用说让我在各个系统中间（而且系统衔接当前也还有较大空间）切来切去了。做了这么多“额外”的操作，才能渐渐去逼近真相、解决真正的问题。\n3 降低问题复杂度 # 这里先声明下，并不是说通过日志这种方式排查问题不好，主要还是要看待解决问题的复杂度，如果加几行日志就可以轻松缩小问题域并解决，那自然是好的。但是实际情况是，并不是所有问题都这么容易解决，而且也确实需要多考虑一些其他影响，比如dtools对测试环境的破坏（覆盖了镜像、忘了打镜像怎么办），频繁测试严格走CI/CD的耗时，等等。\n包括现在提倡的测试左移，单测覆盖、接口测试、集成测试等等，测试是门艺术，远比我之前肤浅的认识要重要，除了质量也要关注效率，做这么多其实也是像在投入时间、迭代效率、软件质量、团队构成等因素之间寻求一种平衡，降低整体复杂度。现在有些团队已经不再将单测覆盖率当做硬指标了，而是通过结合多种测试手段来寻求这种平衡。\n很多人对TDD有认识，但是在实际开发过程中并不会真的去做，代码语句覆盖、分支覆盖情况可能并不高，而且对某些corner cases可能靠正常思路也很难构造出来，可能要结合fuzz testing来协助。\n说这么多，只是为了说明一点，发现问题、走查日志、走查代码、修复提交、构建发布、重新测试，可能是我们每个开发同学解决定位解决bug时高频出现的操作流程，没有好的问题定位工具支持，对宝贵的开发资源就是种浪费。\n我看了下外部的很多团队在k8s开发方面的一些实践，这个过程感觉是可以优化的，那就是让开发k8s应用的我们获得本地调试能力，让远程的一些“不确定性的因素”变成本地“肉眼可见”的观测，问题解决起来就方便多了。尤其是对某些testcase，可能需要反复往前、往后翻代码才能定位到问题，这种在将mozilla rr（record and replay）作为调试器backend的加成下优势会非常明显。\n4 远程调试k8s应用 # 前面我们说了开发定位bug时大致的手段，并且强调了在问题比较复杂时，我们可能会通过多次“修改代码、构建发布、测试”这样的流程来逼近bug，这种场景下，如果能用调试器来跟踪下应用的执行过程，观测下执行流程、变量信息等是否符合预期，缩小问题域的过程会快很多，扩展阅读部分给出了一些业界团队的实践，供参考。\n调试器基础 # 对于一般的应用程序调试器大致可以分为两种类型：指令级调试器、符号级调试器，大家平时调试用的gdb、delve等就是符号级调试器，当然他们也具备一定的指令级调试能力。现代符号级调试器架构一般分为frontend、backend，二者通过service层进行通信（如借助rpc或者pipe），frontend主要是完成与用户的交互、展示，backend完成对tracee（被调试线程）的实际控制。\n以go语言的符号级调试器go-delve/delve为例，其分为frontend、backend，frontend可以是命令行、gdlv图形界面、vscode、goland等，backend针对不同的平台有多种实现，如借助平台的delve native实现、借助其他调试器能力gdbserver、mozilla rr等。本地调试frontend和backend之间通信通过net.pipe，远程通信通过json-rpc，如果是考虑到与vscode、goland集成的话则需要考虑类似DAP（debugger adapter protocol）的方式。\nps: 这里不过多展开了，对调试器设计实现感兴趣的朋友，可以参考我的电子书（最后一章待完成）：https://www.hitzhangjie.pro/debugger101.io/\n大家用的vscode插件、go-delve/delve调试器，其实就是先起个dlv backend以server的形式监听，协议就是DAP，通过vscode调试的时候，会通过DAP协议与dlv backend交互，dlv backend对被调试进程进行控制（如控制单步执行、读写内存等），大致就是这样的，对于远程调试k8s应用，也是这样的过程。\n远程调试演示 # 首先给大家简单实操演示下远程调试k8s应用，最后大家会意识到这个是完全可以实现的，而且可以做的更方便易用。\n示例工程说明 # 下面以一个简单的工程作为示例，实操下如何远程调试k8s应用，这个工程只有这么几个文件：\n/Volumes/kubernetes/debugging-go-app-in-k8s $ tree . . ├── Dockerfile ├── Makefile ├── app └── main.go 0 directories, 4 files  这里的main.go，是一个http服务，模拟我们的微服务，可以长期运行并接受用户请求。\npackage main import ( \u0026quot;log\u0026quot; \u0026quot;net/http\u0026quot; \u0026quot;os\u0026quot; ) // DefaultPort is the default port to use if once is not specified by the SERVER_PORT environment variable const DefaultPort = \u0026quot;8080\u0026quot; func getServerPort() string { port := os.Getenv(\u0026quot;SERVER_PORT\u0026quot;) if port != \u0026quot;\u0026quot; { return port } return DefaultPort } // EchoHandler echos back the request as a response func EchoHandler(writer http.ResponseWriter, request *http.Request) { log.Println(\u0026quot;Echoing back request made to \u0026quot; + request.URL.Path + \u0026quot; to client (\u0026quot; + request.RemoteAddr + \u0026quot;)\u0026quot;) writer.Header().Set(\u0026quot;Access-Control-Allow-Origin\u0026quot;, \u0026quot;*\u0026quot;) // allow pre-flight headers writer.Header().Set(\u0026quot;Access-Control-Allow-Headers\u0026quot;, \u0026quot;Content-Range, Content-Disposition, Content-Type, ETag\u0026quot;) request.Write(writer) } func main() { log.Println(\u0026quot;starting server, listening on port \u0026quot; + getServerPort()) http.HandleFunc(\u0026quot;/\u0026quot;, EchoHandler) http.ListenAndServe(\u0026quot;:\u0026quot;+getServerPort(), nil) }  Makefile完成应用程序的构建：\nall: GOOS=linux GOARCH=amd64 go build -gcflags 'all=-N -l' -o ./app ./main.go  Dockerfile完成镜像构建：\nFROM golang:1.16.3 ENV GO111MODULE=on RUN go get github.com/go-delve/delve/cmd/dlv@v1.8.2 RUN mkdir app WORKDIR /app COPY app . EXPOSE 10000 EXPOSE 8080 ENTRYPOINT [\u0026quot;/go/bin/dlv\u0026quot;, \u0026quot;--listen=:10000\u0026quot;, \u0026quot;--headless=true\u0026quot;, \u0026quot;--api-version=2\u0026quot;, \u0026quot;exec\u0026quot;, \u0026quot;./app\u0026quot;]  注意这里我们直接dlv、app加到了镜像里，并且应用程序直接是以被调试模式运行的。实际真的考虑到便利性的话，dlv以sidecar的形式提供，并且接收dlv connect请求后attach到running process的方式更合适，现在是完全可以做到这点的，dlv作者Derek Parker曾经做过一期分享，专门介绍k8s cluster应用调试，感兴趣的可以从文末参考链接中找到。\n示例工程部署 # 后续内容假定大家已经安装了docker、minikube，如果没有请自行了解下如何安装，然后启动docker、minikube start启动本地k8s cluster。\n构建镜像前先将docker registry指向minikube默认的registry：\neval $(minikube -p minikube docker-env)  然后再构建这个镜像，这样kubectl就能引用到本地镜像：\ndocker build -t debugging-go-app-in-k8s:latest .  k8s部署并运行这个镜像：\nkubectl run --rm -i debugging-go-app-in-k8s:latest --image-pull-policy=Never  运行并查看容器是否起来：\nkubectl get pods  应该能看到debugging-go-app-in-k8s，起来就ok了。\nminikube有点特殊，正常来说可以通过minikube service来创建个tunnel以与容器中的程序通信，比如测试http接口。\n也可以通过kubectl port-forward来实现：\nkubectl port-forward debugging-go-app-in-k8s 10000:10000 // 这个是dlv backend端口 kubectl port-forward debugging-go-app-in-k8s 8080:8080 // 这个是http服务端口  一个支持调试的k8s应用已经准备好了，然后可以通过dlv或者IDE进行调试了。\n远程调试测试 # 以dlv命令行调试为例：\n// 先连接到远程k8s pod中的debugger backend dlv connect localhost:10000 dlv\u0026gt; _ // 准备个断点，比如接口处理函数 dlv\u0026gt; break EchoHandler dlv\u0026gt; _  然后给http服务发个请求 curl http://localhost:8080，此时就会发现dlv frontend已经停在EchoHandler这个位置了，此时我们可以正常进行调试了。当然也可以通过vscode里面的Run\u0026gt;Connect and Debug来设置remote address为localhost:8080后在vscode中进行调试。\n与容器平台结合 # 开发同学如果觉得有用的话，不妨主动贡献一下，腾讯内部的主流容器平台是TKE（Tencent Kubernetes Engine），PCG 123平台也是在TKE基础上构建。理论上我们围绕容器平台提供些调试器插件即可实现远程调试能力。最终远程调试能力支持的话，可能最终形态应该是这样的。\n在同一个pod中部署一个delve，delve对同一个pod中的go-app进行调试，然后开发人员通过debugger frontend通过json-rpc或者DAP与pod中的delve（debugger backend）进行交互，完成对服务go-app的调试。\n由于源代码存放路径差异的问题，dlv提供了一种解决思路substitute-path，这样在涉及到源码相关的转换时（比如基于file lineno添加断点等）依然可以顺利调试。\n5 本文小结 # 开发过程中对问题定位的一点思考，了解了下业界一些实践，对于k8s、微服务这种情况，还是很值得建设远程调试能力的。业界很多头部企业都有这方面的实践，比如Google、RHEL等，以Google Cloud的Cloud Code为例，支持watch本地代码更新并自动发布、重新启动调试，其他的可以通过下面的扩展阅读了解。\n研发效率、工具建设是一项长跑，我们要倾听一线用户的真实诉求，也要多去探索优秀团队的实践来反哺自身。\n6 扩展阅读 #  Google Cloud: Cloud Code调试k8s应用，https://cloud.google.com/code/docs/vscode/debug solo-io/Squash: The debuggers for microservices，https://github.com/solo-io/squash vscode-kubernetes-tools/debug，https://github.com/vscode-kubernetes-tools/vscode-kubernetes-tools/blob/master/debug-on-kubernetes.md setlog/debug-k8s: how to debug a go-service in k8s, https://github.com/setlog/debug-k8s remote debugging on k8s using vscode, https://www.youtube.com/watch?v=nMm-vaFcG9c\u0026amp;list=LL\u0026amp;index=2 bug on a cluster by derek parker - 20220317, https://www.youtube.com/watch?v=TKPmvy6xGlQ\u0026amp;t=340s bug on a cluster by derek parker - 20220406，https://www.meetup.com/ChicagoGo/events/284436038 debugging go applications inside k8s，https://hackernoon.com/debugging-go-application-inside-kubernetes-from-ide-h5683xeb telepresence: making the remote local: faster feedback, collaboration and debugging，https://www.telepresence.io/docs/latest/concepts/faster/ Debugging Go Microservices in Kubernetes with VScode，https://blog.getambassador.io/debugging-go-microservices-in-kubernetes-with-vscode-a36beb48ef1  "}),a.add({id:212,href:"/tags/ast/",title:"AST",description:"",content:""}),a.add({id:213,href:"/tags/highlight/",title:"highlight",description:"",content:""}),a.add({id:214,href:"/tags/ident/",title:"ident",description:"",content:""}),a.add({id:215,href:"/tags/keyword/",title:"keyword",description:"",content:""}),a.add({id:216,href:"/blog/2022-02-09-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E6%BA%90%E4%BB%A3%E7%A0%81%E8%AF%AD%E6%B3%95%E9%AB%98%E4%BA%AE/",title:"如何实现源代码语法高亮",description:"大家对源代码语法高亮并不陌生，不管是功能强大的IDE，还是常规的一些编辑器vim、sublime、markdown codefences等都支持不同编程语言的语法高亮，大家知道具体是如何实现的吗？本文就以go语言语法高亮为例简单做个介绍。",content:"语法高亮 # 软件开发过程中对源代码进行语法高亮是非常有必要的，通过这种方式可以将程序中不同的要素进行有效地区分，如关键字、保留字、标识符、括号匹配、注释、字符串等等。开发人员使用的IDE一般都支持语法高亮，像vim、sublime等的编辑器也可以通过插件对不同编程语言的源代码进行语法高亮支持。\n如何实现 # 要实现语法高亮，需要做哪些工作呢？如果学习过编译原理，其实应该很容易想到，我们只需要实现一个词法分析器能够提取程序中的token序列，并通过语法分析器进行分析识别这些token具体为何物、它们之间具体是什么联系，是构成一个函数，还是构成一个表达式，还是简单到定义了一个变量、一个分支控制语句，等等。只要识别出来了，将这些不同的程序构造进行高亮显示自然不再困难。\n动手实践 # 我们就以go语言为例，来具体讨论下如何对源码进行高亮显示。自然我们不希望重新实现一遍词法分析器、语法分析器之类的琐碎工作，我们也没有精力去重新实现一遍这类工作。尽管flex、yacc可以帮助我们简化这类工作，但是go标准库其实已经提供了package ast来帮助我们做一些语法分析相关的工作。本文我们就基于package ast来演示下如何对go源码进行语法高亮。\n设计一个package colorize来提供一个colorize.Print(\u0026hellip;)方法，来将指定的源码文件进行高亮展示，并且允许指定源文件的行号范围、io.Writer、高亮颜色风格。只用编写如下几个源文件即可：\n line_writer.go，负责按行输出，输出的时候允许指定token、高亮颜色风格，token包含了起始位置信息，所以配合颜色，即可完成对特定关键字、标识符、注释等不同程序构造的高亮显示； colorize.go，负责读取源文件并对其进行AST分析，将其中我们要高亮的一些程序构造提取出来，如关键字package、var、func等作为token提取出来，并构造一个colorTok（包含了token本身位置信息、属于哪一类别，这里的类别决定了最终的颜色风格）； style.go，即高亮显示风格，不同类别对应着不同的终端颜色；  下面就是具体的源码实现了，其实这里的源码源自go-delve/delve，我在编写debugger101相关的demo时发现了go-delve/delve中存在的bug，并对其进行了修复，这里也算是简单记录分享一下吧。同学们真正有机会去尝试这个的也不多。\nfile: colorize.go # // Package colorize use AST analysis to analyze the source and colorize the different kinds // of literals, like keywords, imported packages, etc. // // If you want to highlight source parts, for example, the identifiers. // - firstly, colorTok must be generated by `emit(token.IDENT, n.Pos(), n.End())` in colorize.go // - secondly, we should map the token.IDENT to some style in style.go // - thirdly, we should define the color escape in terminal.go package colorize import ( \u0026quot;go/ast\u0026quot; \u0026quot;go/parser\u0026quot; \u0026quot;go/token\u0026quot; \u0026quot;io\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;path/filepath\u0026quot; \u0026quot;reflect\u0026quot; \u0026quot;sort\u0026quot; ) // Print prints to out a syntax highlighted version of the text read from // path, between lines startLine and endLine. func Print(out io.Writer, path string, startLine, endLine, arrowLine int, colorEscapes map[Style]string) error { buf, err := ioutil.ReadFile(path) if err != nil { return err } w := \u0026amp;lineWriter{w: out, lineRange: [2]int{startLine, endLine}, arrowLine: arrowLine, colorEscapes: colorEscapes} var fset token.FileSet f, err := parser.ParseFile(\u0026amp;fset, path, buf, parser.ParseComments) if err != nil { w.Write(NormalStyle, buf, true) return nil } var base int fset.Iterate(func(file *token.File) bool { base = file.Base() return false }) type colorTok struct { tok token.Token // the token type or ILLEGAL for keywords start, end int // start and end positions of the token } toks := []colorTok{} emit := func(tok token.Token, start, end token.Pos) { if _, ok := tokenToStyle[tok]; !ok { return } start -= token.Pos(base) if end == token.NoPos { // end == token.NoPos it's a keyword and we have to find where it ends by looking at the file for end = start; end \u0026lt; token.Pos(len(buf)); end++ { if buf[end] \u0026lt; 'a' || buf[end] \u0026gt; 'z' { break } } } else { end -= token.Pos(base) } if start \u0026lt; 0 || start \u0026gt;= end || end \u0026gt; token.Pos(len(buf)) { // invalid token? return } toks = append(toks, colorTok{tok, int(start), int(end)}) } for _, cgrp := range f.Comments { for _, cmnt := range cgrp.List { emit(token.COMMENT, cmnt.Pos(), cmnt.End()) } } ast.Inspect(f, func(n ast.Node) bool { if n == nil { return true } switch n := n.(type) { case *ast.File: emit(token.PACKAGE, f.Package, token.NoPos) return true case *ast.BasicLit: emit(n.Kind, n.Pos(), n.End()) return true case *ast.Ident: // TODO(aarzilli): builtin functions? basic types? return true case *ast.IfStmt: emit(token.IF, n.If, token.NoPos) if n.Else != nil { for elsepos := int(n.Body.End()) - base; elsepos \u0026lt; len(buf)-4; elsepos++ { if string(buf[elsepos:][:4]) == \u0026quot;else\u0026quot; { emit(token.ELSE, token.Pos(elsepos+base), token.Pos(elsepos+base+4)) break } } } return true } nval := reflect.ValueOf(n) if nval.Kind() != reflect.Ptr { return true } nval = nval.Elem() if nval.Kind() != reflect.Struct { return true } tokposval := nval.FieldByName(\u0026quot;TokPos\u0026quot;) tokval := nval.FieldByName(\u0026quot;Tok\u0026quot;) if tokposval != (reflect.Value{}) \u0026amp;\u0026amp; tokval != (reflect.Value{}) { emit(tokval.Interface().(token.Token), tokposval.Interface().(token.Pos), token.NoPos) } for _, kwname := range []string{\u0026quot;Case\u0026quot;, \u0026quot;Begin\u0026quot;, \u0026quot;Defer\u0026quot;, \u0026quot;Package\u0026quot;, \u0026quot;For\u0026quot;, \u0026quot;Func\u0026quot;, \u0026quot;Go\u0026quot;, \u0026quot;Interface\u0026quot;, \u0026quot;Map\u0026quot;, \u0026quot;Return\u0026quot;, \u0026quot;Select\u0026quot;, \u0026quot;Struct\u0026quot;, \u0026quot;Switch\u0026quot;} { kwposval := nval.FieldByName(kwname) if kwposval != (reflect.Value{}) { kwpos, ok := kwposval.Interface().(token.Pos) if ok \u0026amp;\u0026amp; kwpos != token.NoPos { emit(token.ILLEGAL, kwpos, token.NoPos) } } } return true }) sort.Slice(toks, func(i, j int) bool { return toks[i].start \u0026lt; toks[j].start }) flush := func(start, end int, style Style) { if start \u0026lt; end { w.Write(style, buf[start:end], end == len(buf)) } } cur := 0 for _, tok := range toks { flush(cur, tok.start, NormalStyle) flush(tok.start, tok.end, tokenToStyle[tok.tok]) cur = tok.end } if cur != len(buf) { flush(cur, len(buf), NormalStyle) } return nil }  file: style.go # package colorize import \u0026quot;go/token\u0026quot; // Style describes the style of a chunk of text. type Style uint8 const ( NormalStyle Style = iota KeywordStyle StringStyle NumberStyle CommentStyle LineNoStyle ArrowStyle ) var tokenToStyle = map[token.Token]Style{ token.ILLEGAL: KeywordStyle, token.COMMENT: CommentStyle, token.INT: NumberStyle, token.FLOAT: NumberStyle, token.IMAG: NumberStyle, token.CHAR: StringStyle, token.STRING: StringStyle, token.BREAK: KeywordStyle, token.CASE: KeywordStyle, token.CHAN: KeywordStyle, token.CONST: KeywordStyle, token.CONTINUE: KeywordStyle, token.DEFAULT: KeywordStyle, token.DEFER: KeywordStyle, token.ELSE: KeywordStyle, token.FALLTHROUGH: KeywordStyle, token.FOR: KeywordStyle, token.FUNC: KeywordStyle, token.GO: KeywordStyle, token.GOTO: KeywordStyle, token.IF: KeywordStyle, token.IMPORT: KeywordStyle, token.INTERFACE: KeywordStyle, token.MAP: KeywordStyle, token.PACKAGE: KeywordStyle, token.RANGE: KeywordStyle, token.RETURN: KeywordStyle, token.SELECT: KeywordStyle, token.STRUCT: KeywordStyle, token.SWITCH: KeywordStyle, token.TYPE: KeywordStyle, token.VAR: KeywordStyle, }  file: line_writer.go # package colorize import ( \u0026quot;fmt\u0026quot; \u0026quot;io\u0026quot; ) type lineWriter struct { w io.Writer lineRange [2]int arrowLine int curStyle Style started bool lineno int colorEscapes map[Style]string } func (w *lineWriter) style(style Style) { if w.colorEscapes == nil { return } esc := w.colorEscapes[style] if esc == \u0026quot;\u0026quot; { esc = w.colorEscapes[NormalStyle] } fmt.Fprintf(w.w, \u0026quot;%s\u0026quot;, esc) } func (w *lineWriter) inrange() bool { lno := w.lineno if !w.started { lno = w.lineno + 1 } return lno \u0026gt;= w.lineRange[0] \u0026amp;\u0026amp; lno \u0026lt; w.lineRange[1] } func (w *lineWriter) nl() { w.lineno++ if !w.inrange() || !w.started { return } w.style(ArrowStyle) if w.lineno == w.arrowLine { fmt.Fprintf(w.w, \u0026quot;=\u0026gt;\u0026quot;) } else { fmt.Fprintf(w.w, \u0026quot; \u0026quot;) } w.style(LineNoStyle) fmt.Fprintf(w.w, \u0026quot;%4d:\\t\u0026quot;, w.lineno) w.style(w.curStyle) } func (w *lineWriter) writeInternal(style Style, data []byte) { if !w.inrange() { return } if !w.started { w.started = true w.curStyle = style w.nl() } else if w.curStyle != style { w.curStyle = style w.style(w.curStyle) } w.w.Write(data) } func (w *lineWriter) Write(style Style, data []byte, last bool) { cur := 0 for i := range data { if data[i] == '\\n' { if last \u0026amp;\u0026amp; i == len(data)-1 { w.writeInternal(style, data[cur:i]) if w.curStyle != NormalStyle { w.style(NormalStyle) } if w.inrange() { w.w.Write([]byte{'\\n'}) } last = false } else { w.writeInternal(style, data[cur:i+1]) w.nl() } cur = i + 1 } } if cur \u0026lt; len(data) { w.writeInternal(style, data[cur:]) } if last { if w.curStyle != NormalStyle { w.style(NormalStyle) } if w.inrange() { w.w.Write([]byte{'\\n'}) } } }  运行测试 # 下面是测试文件，我们定义了一个表示源码内容的字符串，并通过gomonkey mock掉了ioutil.ReadFile(\u0026hellip;)的操作让其返回定义的源码字符串，然后执行colorize.Print(\u0026hellip;)对其进行高亮显示。\nfile: colorize_test.go\npackage colorize_test import ( \u0026quot;bytes\u0026quot; \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;reflect\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;github.com/agiledragon/gomonkey/v2\u0026quot; \u0026quot;github.com/hitzhangjie/dlv/pkg/terminal/colorize\u0026quot; ) var src = `package main // Vehicle defines the vehicle behavior type Vehicle interface{ // Run vehicle can run in a speed Run() } // BMWS1000RR defines the motocycle bmw s1000rr type BMWS1000RR struct { } // Run bwm s1000rr run func (a *BMWS1000RR) Run() { println(\u0026quot;I can run at 300km/h\u0026quot;) } func main() { var vehicle = \u0026amp;BMWS1000RR{} vehicle.Run() } ` const terminalHighlightEscapeCode string = \u0026quot;\\033[%2dm\u0026quot; const ( ansiBlack = 30 ansiRed = 31 ansiGreen = 32 ansiYellow = 33 ansiBlue = 34 ansiMagenta = 35 ansiCyan = 36 ansiWhite = 37 ansiBrBlack = 90 ansiBrRed = 91 ansiBrGreen = 92 ansiBrYellow = 93 ansiBrBlue = 94 ansiBrMagenta = 95 ansiBrCyan = 96 ansiBrWhite = 97 ) func colorizeCode(code int) string { return fmt.Sprintf(terminalHighlightEscapeCode, code) } var colors = map[colorize.Style]string{ colorize.KeywordStyle: colorizeCode(ansiYellow), colorize.ArrowStyle: colorizeCode(ansiBlue), colorize.CommentStyle: colorizeCode(ansiGreen), colorize.LineNoStyle: colorizeCode(ansiBrWhite), colorize.NormalStyle: colorizeCode(ansiBrWhite), colorize.NumberStyle: colorizeCode(ansiBrCyan), colorize.StringStyle: colorizeCode(ansiBrBlue), } func TestPrint(t *testing.T) { p := gomonkey.ApplyFunc(ioutil.ReadFile, func(name string) ([]byte, error) { return []byte(src), nil }) defer p.Reset() buf := \u0026amp;bytes.Buffer{} colorize.Print(buf, \u0026quot;main.go\u0026quot;, bytes.NewBufferString(src), 1, 30, 10, colors) colorize.Print(os.Stdout, \u0026quot;main.go\u0026quot;, bytes.NewBufferString(src), 1, 30, 10, colors) }  现在运行这个测试用例go test -run TestPrint，程序运行结果如下：\n我们看到程序中的部分程序元素被高亮显示了，当然我们只识别了简单的一小部分，关键字、字符串、注释，实际IDE中会分析的更加的细致，大家在使用IDE的时候应该也都有这方面的体会。\n本文小结 # 本文简单总结了如何基于go ast对源代码进行语法分析并进行高亮显示，希望读者能了解到这里的知识点，并能认识到编译原理的相关知识真的是可以用来做些有价值、有意思的东西的。再比如，我们实现一些linters对源码进行检查（如golangci-linter），作者之前还写过一篇文章是讲述如何对go程序进行可视化，有些IDE还支持自动生成classgram、callgraph等等，这些也是对go ast的另一种应用。\n新的一年与大家共勉，做有追求的工程师，知其然知其所以然 :)\n"}),a.add({id:217,href:"/tags/b+tree/",title:"B+Tree",description:"",content:""}),a.add({id:218,href:"/tags/btree/",title:"BTree",description:"",content:""}),a.add({id:219,href:"/tags/explain/",title:"explain",description:"",content:""}),a.add({id:220,href:"/tags/index/",title:"index",description:"",content:""}),a.add({id:221,href:"/tags/mysql/",title:"mysql",description:"",content:""}),a.add({id:222,href:"/blog/2022-01-06-mysql%E6%9F%A5%E8%AF%A2%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/",title:"MySQL查询性能优化",description:"【转】MySQL优化原理，https://www.cnblogs.com/zhangyinhua/p/7620964.html\n说起MySQL的查询优化，相信大家积累一堆技巧：不能使用SELECT *、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？\n我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。\n  img { width: 680px; padding-bottom: 1rem; }  MySQL逻辑架构 # 如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。\nMySQL逻辑架构，来自：高性能MySQL\nMySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。\nMySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。\n最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。\n MySQL查询过程 # 我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。\n当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？\nMySQL查询过程\n客户端/服务端通信协议 # MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。\n客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。\n与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。\n查询缓存 # 在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。\nMySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。\n如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。\n既然是缓存，就会失效，那查询缓存何时失效呢？　MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：\n 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗  基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：\n 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存  最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。\n当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等，读者可以自行阅读相关资料，这里权当抛砖引玉吧。\n语法解析和预处理 # MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。\n查询优化 # 经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。\nMySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。\nMysql代码\nmysql\u0026gt; select * from t_message limit 10; ...省略结果集 mysql\u0026gt; show status like 'last_query_cost'; +-----------------+-------------+ | Variable_name | Value | +-----------------+-------------+ | Last_query_cost | 6391.",content:"【转】MySQL优化原理，https://www.cnblogs.com/zhangyinhua/p/7620964.html\n说起MySQL的查询优化，相信大家积累一堆技巧：不能使用SELECT *、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？\n我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。\n  img { width: 680px; padding-bottom: 1rem; }  MySQL逻辑架构 # 如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。\nMySQL逻辑架构，来自：高性能MySQL\nMySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。\nMySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。\n最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。\n MySQL查询过程 # 我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：很多的查询优化工作实际上就是遵循一些原则让MySQL的优化器能够按照预想的合理方式运行而已。\n当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？\nMySQL查询过程\n客户端/服务端通信协议 # MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。\n客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置max_allowed_packet参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。\n与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用SELECT *以及加上LIMIT限制的原因之一。\n查询缓存 # 在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。\nMySQL将缓存存放在一个引用表（不要理解成table，可以认为是类似于HashMap的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。\n如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果都不会被缓存。比如函数NOW()或者CURRENT_DATE()会因为不同的查询时间，返回不同的查询结果，再比如包含CURRENT_USER或者CONNECION_ID()的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。\n既然是缓存，就会失效，那查询缓存何时失效呢？　MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：\n 任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存 如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗  基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：\n 用多个小表代替一个大表，注意不要过度设计 批量插入代替循环单条插入 合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适 可以通过SQL_CACHE和SQL_NO_CACHE来控制某个查询语句是否需要进行缓存  最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将query_cache_type设置为DEMAND，这时只有加入SQL_CACHE的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。\n当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等，读者可以自行阅读相关资料，这里权当抛砖引玉吧。\n语法解析和预处理 # MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。\n查询优化 # 经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。\nMySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的last_query_cost的值来得到其计算当前查询的成本。\nMysql代码\nmysql\u0026gt; select * from t_message limit 10; ...省略结果集 mysql\u0026gt; show status like 'last_query_cost'; +-----------------+-------------+ | Variable_name | Value | +-----------------+-------------+ | Last_query_cost | 6391.799000 | +-----------------+-------------+  示例中的结果表示优化器认为大概需要做6391个数据页的随机查找才能完成上面的查询。这个结果是根据一些列的统计信息计算得来的，这些统计信息包括：每张表或者索引的页面个数、索引的基数、索引和数据行的长度、索引的分布情况等等。\n有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL只选择它认为成本小的，但成本小并不意味着执行时间短）等等。\nMySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：\n 重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序） 优化MIN()和MAX()函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值，具体原理见下文） 提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询） 优化排序（在老版本MySQL会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多）  随着MySQL的不断发展，优化器使用的优化策略也在不断的进化，这里仅仅介绍几个非常常用且容易理解的优化策略，其他的优化策略，大家自行查阅吧。\n查询执行引擎 # 在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为handlerAPI。查询过程中的每一张表由一个handler实例表示。\n实际上，MySQL在查询优化阶段就为每一张表创建了一个handler实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。\n返回结果给客户端 # 查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如改查询影响到的行数以及执行时间等等。\n如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。\n结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。\n回头总结一下MySQL整个查询执行过程，总的来说分为5个步骤：\n 客户端向MySQL服务器发送一条查询请求 服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段 服务器进行SQL解析、预处理、再由优化器生成对应的执行计划 MySQL根据执行计划，调用存储引擎的API来执行查询 将结果返回给客户端，同时缓存查询结果   性能优化建议 # 看了这么多，你可能会期待给出一些优化手段，是的，下面会从3个不同方面给出一些优化建议。但请等等，还有一句忠告要先送给你：不要听信你看到的关于优化的“绝对真理”，包括本文所讨论的内容，而应该是在实际的业务场景下通过测试来验证你关于执行计划以及响应时间的假设。\nScheme设计与数据类型优化 # 选择数据类型只要遵循小而简单的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。越简单的数据类型在计算时需要更少的CPU周期，比如，整型就比字符操作代价低，因而会使用整型来存储ip地址，使用DATETIME来存储时间，而不是使用字符串。\n这里总结几个可能容易理解错误的技巧：\n 通常来说把可为NULL的列改为NOT NULL不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为NOT NULL。 对整数类型指定宽度，比如INT(11)，没有任何卵用。INT使用16为存储空间，那么它的表示范围已经确定，所以INT(1)和INT(20)对于存储和计算是相同的。 UNSIGNED表示不允许负值，大致可以使正数的上限提高一倍。比如TINYINT存储范围是通常来讲，没有太大的必要使用DECIMAL数据类型。即使是在需要存储财务数据时，仍然可以使用BIGINT。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用TIMESTAMP使用4个字节存储空间，DATETIME使用8个字节存储空间。因而，TIMESTAMP只能表示1970 - 2038年，比DATETIME表示的范围小得多，而且TIMESTAMP的值因时区不同而不同。 大多数情况下没有使用枚举类型的必要，其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用ALTER TABLE（如果只只是在列表末尾追加元素，不需要重建表）。 schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。 大表ALTER TABLE非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇淫技巧可以解决这个问题，有兴趣可自行查阅。  创建高性能索引 # 索引是提高MySQL查询性能的一个重要途径，但过多的索引可能会导致过高的磁盘使用率以及过高的内存占用，从而影响应用程序的整体性能。应当尽量避免事后才想起添加索引，因为事后可能需要监控大量的SQL才能定位到问题所在，而且添加索引的时间肯定是远大于初始添加索引所需要的时间，可见索引的添加也是非常有技术含量的。\n接下来将向你展示一系列创建高性能索引的策略，以及每条策略其背后的工作原理。但在此之前，先了解与索引相关的一些算法和数据结构，将有助于更好的理解后文的内容。推荐：带你从头到尾捋一遍MySQL索引结构！\n索引相关的数据结构和算法 # 通常我们所说的索引是指B-Tree索引，它是目前关系型数据库中查找数据最为常用和有效的索引，大多数存储引擎都支持这种索引。使用B-Tree这个术语，是因为MySQL在CREATE TABLE或其它语句中使用了这个关键字，但实际上不同的存储引擎可能使用不同的数据结构，比如InnoDB就是使用的B+Tree。\nB+Tree中的B是指balance，意为平衡。需要注意的是，B+树索引并不能找到一个给定键值的具体行，它找到的只是被查找数据行所在的页，接着数据库会把页读入到内存，再在内存中进行查找，最后得到要查找的数据。\n在介绍B+Tree前，先了解一下二叉查找树，它是一种经典的数据结构，其左子树的值总是小于根的值，右子树的值总是大于根的值，如下图①。如果要在这课树中查找值为5的记录，其大致流程：先找到根，其值为6，大于5，所以查找左子树，找到3，而5大于3，接着找3的右子树，总共找了3次。同样的方法，如果查找值为8的记录，也需要查找3次。所以二叉查找树的平均查找次数为(3 + 3 + 3 + 2 + 2 + 1) / 6 = 2.3次，而顺序查找的话，查找值为2的记录，仅需要1次，但查找值为8的记录则需要6次，所以顺序查找的平均查找次数为：(1 + 2 + 3 + 4 + 5 + 6) / 6 = 3.3次，因为大多数情况下二叉查找树的平均查找速度比顺序查找要快。\n二叉查找树和平衡二叉树\n由于二叉查找树可以任意构造，同样的值，可以构造出如图②的二叉查找树，显然这棵二叉树的查询效率和顺序查找差不多。若想二叉查找数的查询性能最高，需要这棵二叉查找树是平衡的，也即平衡二叉树（AVL树）。\n平衡二叉树首先需要符合二叉查找树的定义，其次必须满足任何节点的两个子树的高度差不能大于1。显然图②不满足平衡二叉树的定义，而图①是一课平衡二叉树。平衡二叉树的查找性能是比较高的（性能最好的是最优二叉树），查询性能越好，维护的成本就越大。比如图①的平衡二叉树，当用户需要插入一个新的值9的节点时，就需要做出如下变动。\n平衡二叉树旋转\n通过一次左旋操作就将插入后的树重新变为平衡二叉树是最简单的情况了，实际应用场景中可能需要旋转多次。至此我们可以考虑一个问题，平衡二叉树的查找效率还不错，实现也非常简单，相应的维护成本还能接受，为什么MySQL索引不直接使用平衡二叉树？\n随着数据库中数据的增加，索引本身大小随之增加，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级。可以想象一下一棵几百万节点的二叉树的深度是多少？如果将这么大深度的一颗二叉树放磁盘上，每读取一个节点，需要一次磁盘的I/O读取，整个查找的耗时显然是不能够接受的。那么如何减少查找过程中的I/O存取次数？\n一种行之有效的解决方法是减少树的深度，将二叉树变为m叉树（多路搜索树），而B+Tree就是一种多路搜索树。理解B+Tree时，只需要理解其最重要的两个特征即可：第一，所有的关键字（可以理解为数据）都存储在叶子节点（Leaf Page），非叶子节点（Index Page）并不存储真正的数据，所有记录节点都是按键值大小顺序存放在同一层叶子节点上。其次，所有的叶子节点由指针连接。如下图为高度为2的简化了的B+Tree。\n简化B+Tree\n怎么理解这两个特征？MySQL将每个节点的大小设置为一个页的整数倍（原因下文会介绍），也就是在节点空间大小一定的情况下，每个节点可以存储更多的内结点，这样每个结点能索引的范围更大更精确。所有的叶子节点使用指针链接的好处是可以进行区间访问，比如上图中，如果查找大于20而小于30的记录，只需要找到节点20，就可以遍历指针依次找到25、30。如果没有链接指针的话，就无法进行区间查找。这也是MySQL使用B+Tree作为索引存储结构的重要原因。\nMySQL为何将节点大小设置为页的整数倍，这就需要理解磁盘的存储原理。磁盘本身存取就比主存慢很多，在加上机械运动损耗（特别是普通的机械硬盘），磁盘的存取速度往往是主存的几百万分之一，为了尽量减少磁盘I/O，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，预读的长度一般为页的整数倍。\n 页是计算机管理存储器的逻辑块，硬件及OS往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（许多OS中，页的大小通常为4K）。主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行。\n MySQL巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了读取一个节点只需一次I/O。假设B+Tree的高度为h，一次检索最多需要h-1I/O（根节点常驻内存），复杂度O(h)=O(logMN)。实际应用场景中，M通常较大，常常超过100，因此树的高度一般都比较小，通常不超过3。\n最后简单了解下B+Tree节点的操作，在整体上对索引的维护有一个大概的了解，虽然索引可以大大提高查询效率，但维护索引仍要花费很大的代价，因此合理的创建索引也就尤为重要。\n仍以上面的树为例，我们假设每个节点只能存储4个内节点。首先要插入第一个节点28，如下图所示。\nleaf page和index page都没有满\n接着插入下一个节点70，在Index Page中查询后得知应该插入到50 - 70之间的叶子节点，但叶子节点已满，这时候就需要进行也分裂的操作，当前的叶子节点起点为50，所以根据中间值来拆分叶子节点，如下图所示。\nLeaf Page拆分\n最后插入一个节点95，这时候Index Page和Leaf Page都满了，就需要做两次拆分，如下图所示。\nLeaf Page与Index Page拆分\n拆分后最终形成了这样一颗树。\n最终树\nB+Tree为了保持平衡，对于新插入的值需要做大量的拆分页操作，而页的拆分需要I/O操作，为了尽可能的减少页的拆分操作，B+Tree也提供了类似于平衡二叉树的旋转功能。当LeafPage已满但其左右兄弟节点没有满的情况下，B+Tree并不急于去做拆分操作，而是将记录移到当前所在页的兄弟节点上。通常情况下，左兄弟会被先检查用来做旋转操作。就比如上面第二个示例，当插入70的时候，并不会去做页拆分，而是左旋操作。\n左旋操作\n通过旋转操作可以最大限度的减少页分裂，从而减少索引维护过程中的磁盘的I/O操作，也提高索引维护效率。需要注意的是，删除节点跟插入节点类型，仍然需要旋转和拆分操作，这里就不再说明。\n高性能策略 # 通过上文，相信你对B+Tree的数据结构已经有了大致的了解，但MySQL中索引是如何组织数据的存储呢？以一个简单的示例来说明，假如有如下数据表：\nMysql代码\nCREATE TABLE People( last_name varchar(50) not null, first_name varchar(50) not null, dob date not null, gender enum(`m`,`f`) not null, key(last_name,first_name,dob) );  对于表中每一行数据，索引中包含了last_name、first_name、dob列的值，下图展示了索引是如何组织数据存储的。\n索引如何组织数据存储，来自：高性能MySQL\n可以看到，索引首先根据第一个字段来排列顺序，当名字相同时，则根据第三个字段，即出生日期来排序，正是因为这个原因，才有了索引的“最左原则”。\n1、MySQL不会使用索引的情况：非独立的列 # “独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数。比如：\nselect * from where id + 1 = 5  我们很容易看出其等价于 id = 4，但是MySQL无法自动解析这个表达式，使用函数是同样的道理。\n2、前缀索引 # 如果列很长，通常可以索引开始的部分字符，这样可以有效节约索引空间，从而提高索引效率。\n3、多列索引和索引顺序 # 在多数情况下，在多个列上建立独立的索引并不能提高查询性能。理由非常简单，MySQL不知道选择哪个索引的查询效率更好，所以在老版本，比如MySQL5.0之前就会随便选择一个列的索引，而新的版本会采用合并索引的策略。举个简单的例子，在一张电影演员表中，在actor_id和film_id两个列上都建立了独立的索引，然后有如下查询：\nselect film_id,actor_id from film_actor where actor_id = 1 or film_id = 1  老版本的MySQL会随机选择一个索引，但新版本做如下的优化：\nselect film_id,actor_id from film_actor where actor_id = 1 union all select film_id,actor_id from film_actor where film_id = 1 and actor_id \u0026lt;\u0026gt; 1   当出现多个索引做相交操作时（多个AND条件），通常来说一个包含所有相关列的索引要优于多个独立索引。 当出现多个索引做联合操作时（多个OR条件），对结果集的合并、排序等操作需要耗费大量的CPU和内存资源，特别是当其中的某些索引的选择性不高，需要返回合并大量数据时，查询成本更高。所以这种情况下还不如走全表扫描。  因此explain时如果发现有索引合并（Extra字段出现Using union），应该好好检查一下查询和表结构是不是已经是最优的，如果查询和表都没有问题，那只能说明索引建的非常糟糕，应当慎重考虑索引是否合适，有可能一个包含所有相关列的多列索引更适合。\n前面我们提到过索引如何组织数据存储的，从图中可以看到多列索引时，索引的顺序对于查询是至关重要的，很明显应该把选择性更高的字段放到索引的前面，这样通过第一个字段就可以过滤掉大多数不符合条件的数据。\n索引选择性是指不重复的索引值和数据表的总记录数的比值，选择性越高查询效率越高，因为选择性越高的索引可以让MySQL在查询时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。\n理解索引选择性的概念后，就不难确定哪个字段的选择性较高了，查一下就知道了，比如：\nSELECT * FROM payment where staff_id = 2 and customer_id = 584  是应该创建(staff_id,customer_id)的索引还是应该颠倒一下顺序？执行下面的查询，哪个字段的选择性更接近1就把哪个字段索引前面就好。\nselect count(distinct staff_id)/count(*) as staff_id_selectivity, count(distinct customer_id)/count(*) as customer_id_selectivity, count(*) from payment  多数情况下使用这个原则没有任何问题，但仍然注意你的数据中是否存在一些特殊情况。举个简单的例子，比如要查询某个用户组下有过交易的用户信息：\nselect user_id from trade where user_group_id = 1 and trade_amount \u0026gt; 0  MySQL为这个查询选择了索引(user_group_id,trade_amount)，如果不考虑特殊情况，这看起来没有任何问题，但实际情况是这张表的大多数数据都是从老系统中迁移过来的，由于新老系统的数据不兼容，所以就给老系统迁移过来的数据赋予了一个默认的用户组。这种情况下，通过索引扫描的行数跟全表扫描基本没什么区别，索引也就起不到任何作用。\n推广开来说，经验法则和推论在多数情况下是有用的，可以指导我们开发和设计，但实际情况往往会更复杂，实际业务场景下的某些特殊情况可能会摧毁你的整个设计。\n4、避免多个范围条件 # 实际开发中，我们会经常使用多个范围条件，比如想查询某个时间段内登录过的用户：\nselect user.* from user where login_time \u0026gt; '2017-04-01' and age between 18 and 30;  这个查询有一个问题：它有两个范围条件，login_time列和age列，MySQL可以使用login_time列的索引或者age列的索引，但无法同时使用它们。\n5、覆盖索引 # 如果一个索引包含或者说覆盖所有需要查询的字段的值，那么就没有必要再回表查询，这就称为覆盖索引。覆盖索引是非常有用的工具，可以极大的提高性能，因为查询只需要扫描索引会带来许多好处：\n 索引条目远小于数据行大小，如果只读取索引，极大减少数据访问量 索引是有按照列值顺序存储的，对于I/O密集型的范围查询要比随机从磁盘读取每一行数据的IO要少的多  6、使用索引扫描来排序 # MySQL有两种方式可以生产有序的结果集，其一是对结果集进行排序的操作，其二是按照索引顺序扫描得出的结果自然是有序的。如果explain的结果中type列的值为index表示使用了索引扫描来做排序。\n扫描索引本身很快，因为只需要从一条索引记录移动到相邻的下一条记录。但如果索引本身不能覆盖所有需要查询的列，那么就不得不每扫描一条索引记录就回表查询一次对应的行。这个读取操作基本上是随机I/O，因此按照索引顺序读取数据的速度通常要比顺序地全表扫描要慢。\n在设计索引时，如果一个索引既能够满足排序，又满足查询，是最好的。\n只有当索引的列顺序和ORDER BY子句的顺序完全一致，并且所有列的排序方向也一样时，才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有ORDER BY子句引用的字段全部为第一张表时，才能使用索引做排序。ORDER BY子句和查询的限制是一样的，都要满足最左前缀的要求（有一种情况例外，就是最左的列被指定为常数，下面是一个简单的示例），其他情况下都需要执行排序操作，而无法利用索引排序。\n-- 最左列为常数，索引：(date,staff_id,customer_id) select staff_id,customer_id from demo where date = '2015-06-01' ``order by staff_id,customer_id  7、冗余和重复索引 # 冗余索引是指在相同的列上按照相同的顺序创建的相同类型的索引，应当尽量避免这种索引，发现后立即删除。比如有一个索引(A,B)，再创建索引(A)就是冗余索引。冗余索引经常发生在为表添加新索引时，比如有人新建了索引(A,B)，但这个索引不是扩展已有的索引(A)。\n大多数情况下都应该尽量扩展已有的索引而不是创建新索引。但有极少情况下出现性能方面的考虑需要冗余索引，比如扩展已有索引而导致其变得过大，从而影响到其他使用该索引的查询。\n8、删除长期未使用的索引 # 定期删除一些长时间未使用过的索引是一个非常好的习惯。\n关于索引这个话题打算就此打住，最后要说一句，索引并不总是最好的工具，只有当索引帮助提高查询速度带来的好处大于其带来的额外工作时，索引才是有效的。对于非常小的表，简单的全表扫描更高效。对于中到大型的表，索引就非常有效。对于超大型的表，建立和维护索引的代价随之增长，这时候其他技术也许更有效，比如分区表。最后的最后，explain后再提测是一种美德。\n特定类型查询优化 # 优化COUNT()查询 # COUNT()可能是被大家误解最多的函数了，它有两种不同的作用，其一是统计某个列值的数量，其二是统计行数。统计列值时，要求列值是非空的，它不会统计NULL。如果确认括号中的表达式不可能为空时，实际上就是在统计行数。最简单的就是当使用COUNT(*)时，并不是我们所想象的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计行数。\n我们最常见的误解也就在这儿，在括号内指定了一列却希望统计结果是行数，而且还常常误以为前者的性能会更好。但实际并非这样，如果要统计行数，直接使用COUNT(*)，意义清晰，且性能更好。\n有时候某些业务场景并不需要完全精确的COUNT值，可以用近似值来代替，EXPLAIN出来的行数就是一个不错的近似值，而且执行EXPLAIN并不需要真正地去执行查询，所以成本非常低。通常来说，执行COUNT()都需要扫描大量的行才能获取到精确的数据，因此很难优化，MySQL层面还能做得也就只有覆盖索引了。如果不还能解决问题，只有从架构层面解决了，比如添加汇总表，或者使用redis这样的外部缓存系统。\n优化关联查询 # 在大数据场景下，表与表之间通过一个冗余字段来关联，要比直接使用JOIN有更好的性能。如果确实需要使用关联查询的情况下，需要特别注意的是：\n 确保ON和USING字句中的列上有索引。在创建索引的时候就要考虑到关联的顺序。当表A和表B用列c关联的时候，如果优化器关联的顺序是A、B，那么就不需要在A表的对应列上创建索引。没有用到的索引会带来额外的负担，一般来说，除非有其他理由，只需要在关联顺序中的第二张表的相应列上创建索引（具体原因下文分析）。 确保任何的GROUP BY和ORDER BY中的表达式只涉及到一个表中的列，这样MySQL才有可能使用索引来优化。  要理解优化关联查询的第一个技巧，就需要理解MySQL是如何执行关联查询的。当前MySQL关联执行的策略非常简单，它对任何的关联都执行嵌套循环关联操作，即先在一个表中循环取出单条数据，然后在嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为为止。然后根据各个表匹配的行，返回查询中需要的各个列。\n太抽象了？以上面的示例来说明，比如有这样的一个查询：\nSELECT A.xx,B.yy FROM A INNER JOIN B USING(c) WHERE A.xx IN (5,6)  假设MySQL按照查询中的关联顺序A、B来进行关联操作，那么可以用下面的伪代码表示MySQL如何完成这个查询：\nouter_iterator = SELECT A.xx,A.c FROM A WHERE A.xx IN (5,6); outer_row = outer_iterator.next; while(outer_row) { inner_iterator = SELECT B.yy FROM B WHERE B.c = outer_row.c; inner_row = inner_iterator.next; while(inner_row) { output[inner_row.yy,outer_row.xx]; inner_row = inner_iterator.next; } outer_row = outer_iterator.next; }  可以看到，最外层的查询是根据A.xx列来查询的，A.c上如果有索引的话，整个关联查询也不会使用。再看内层的查询，很明显B.c上如果有索引的话，能够加速查询，因此只需要在关联顺序中的第二张表的相应列上创建索引即可。\n优化LIMIT分页 # 当需要分页操作时，通常会使用LIMIT加上偏移量的办法实现，同时加上合适的ORDER BY字句。如果有对应的索引，通常效率会不错，否则，MySQL需要做大量的文件排序操作。\n一个常见的问题是当偏移量非常大的时候，比如：LIMIT 10000 20这样的查询，MySQL需要查询10020条记录然后只返回20条记录，前面的10000条都将被抛弃，这样的代价非常高。\n优化这种查询一个最简单的办法就是尽可能的使用覆盖索引扫描，而不是查询所有的列。然后根据需要做一次关联查询再返回所有的列。对于偏移量很大时，这样做的效率会提升非常大。考虑下面的查询：\nSELECT film_id,description FROM film ORDER BY title LIMIT 50,5;  如果这张表非常大，那么这个查询最好改成下面的样子：\nSELECT film.film_id,film.description FROM film INNER JOIN ( SELECT film_id FROM film ORDER BY title LIMIT 50,5 ) AS tmp USING(film_id);  这里的延迟关联将大大提升查询效率，让MySQL扫描尽可能少的页面，获取需要访问的记录后在根据关联列回原表查询所需要的列。\n有时候如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用OFFSET，比如下面的查询：\nSELECT id FROM t LIMIT 10000, 10;  改为：\nSELECT id FROM t WHERE id \u0026gt; 10000 LIMIT 10;  其他优化的办法还包括使用预先计算的汇总表，或者关联到一个冗余表，冗余表中只包含主键列和需要做排序的列。\n优化UNION # MySQL处理UNION的策略是先创建临时表，然后再把各个查询结果插入到临时表中，最后再来做查询。因此很多优化策略在UNION查询中都没有办法很好的时候。经常需要手动将WHERE、LIMIT、ORDER BY等字句“下推”到各个子查询中，以便优化器可以充分利用这些条件先优化。\n除非确实需要服务器去重，否则就一定要使用UNION ALL，如果没有ALL关键字，MySQL会给临时表加上DISTINCT选项，这会导致整个临时表的数据做唯一性检查，这样做的代价非常高。当然即使使用ALL关键字，MySQL总是将结果放入临时表，然后再读出，再返回给客户端。虽然很多时候没有这个必要，比如有时候可以直接把每个子查询的结果返回给客户端。\n结语 # 理解查询是如何执行以及时间都消耗在哪些地方，再加上一些优化过程的知识，可以帮助大家更好的理解MySQL，理解常见优化技巧背后的原理。希望本文中的原理、示例能够帮助大家更好的将理论和实践联系起来，更多的将理论知识运用到实践中。\n其他也没啥说的了，给大家留两个思考题吧，可以在脑袋里想想答案，这也是大家经常挂在嘴边的，但很少有人会思考为什么？\n 有非常多的程序员在分享时都会抛出这样一个观点：尽可能不要使用存储过程，存储过程非常不容易维护，也会增加使用成本，应该把业务逻辑放到客户端。既然客户端都能干这些事，那为什么还要存储过程？ JOIN本身也挺方便的，直接查询就好了，为什么还需要视图呢？  参考资料 #  [1] 姜承尧 著；MySQL技术内幕-InnoDB存储引擎；机械工业出版社，2013 [2] Baron Scbwartz 等著；宁海元 周振兴等译；高性能MySQL（第三版）; 电子工业出版社， 2013 [3] 由 B-/B+树看 MySQL索引结构\n "}),a.add({id:223,href:"/tags/bazelbuild/",title:"bazelbuild",description:"",content:""}),a.add({id:224,href:"/blog/2021-10-21-bazelbuild%E6%9E%84%E5%BB%BAgo%E5%BE%AE%E6%9C%8D%E5%8A%A1/",title:"bazelbuild：构建go微服务",description:"关于monorepo、multirepo的争论不绝于耳，至于采用哪种方式进行管理，要因地制宜地选择最合适的方案，要看到其优势，也要看到工具建设和迁移的成本。这里重点谈下各自的优势及什么时候适用Bazel构建。",content:" img { width: 680px; padding-bottom: 1rem; }  1 前言 # 关于monorepo、multirepo的争论不绝于耳，至于采用哪种方式进行管理，要因地制宜地选择最合适的方案，要看到其优势，也要看到工具建设和迁移的成本。这里重点谈下各自的优势及什么时候适用Bazel构建。\n1.1 monorepo # 如果团队采用的是希望改善代码复用、希望让烂代码无处遁形、希望构建一致的CI/CD标准并落地、希望更好地沉淀经验、希望更好地促进团队成员成长等等，考虑到这些，似乎monorepo是更好的代码管理方式。\n但是也要考虑代码管理的规模、是否多语言技术栈、如何保证高效、封闭、可重复的构建。\n虽然google、uber、twitter等很多国内外大厂都采用了monorepo方式进行管理，但是也要看到这背后投入的大量的基础工具、平台的建设，这些并不是每个公司、团队所能予以支持的。目前开源的技术方案也并非完整的解决方案。\n谷歌为什么采用单仓：Why Google Stores Billions of Lines of Code in a Single Repository\n1.2 multirepo # multirepo每个仓库代码规模小，灵活易管理，做什么调整也很方便，也不需要特别重的基础工具、平台的支持，当然如果有大规模代码检索等之类的工具加成，也算锦上添花。\n对于小仓模式、大仓模式之争，微信同事曾经有专门做过一个具体的小仓模式实践分享。\n1.3 构建系统 # 这个世界就没有所谓的银弹，当我们企图用一种看似不错的方案解决问题时，这种方案本身也会重新引入一些新的问题。所以量体裁衣、因地制宜很重要，希望我们能结合自身情况（基础平台、工程素养现状、业务场景、业务迭代效率、产品定位等等）选择合适的方案。\nps：我认为，monorepo的规模至少要做到部门及以上级别，否则真的就是费力不讨好。\n关于monorepo、multirepo的异同、优缺点这里就暂不讨论了，这里准备讨论下monorepo下的构建系统支持。\ngo一般用go module构建，java一般用gradle或者maven构建，c++一般用cmake或makefile构建…总之有很多类似的构建方式，现在是多语言同一个repo管理，如果依然各个语言各自一套构建系统的话，随着代码规模上升，会变得很难管理。\n一个好的构建系统必须需要解决如下几个问题：\n- 如何建模待构建目标的依赖清单；\n- 如何实现高效地构建；\n- 如何保证可重复地构建；\n- 如何解决多语言构建问题；\n目前来看，从互联网大厂及开源社区的反馈来看，谷歌开源的bazel应该是当前的主流方案。\n2 Bazel基础 # 本文后续讨论建立在开发团队基于“monorepo+multi-language”的背景下，应该如何使用bazel对trpc-go项目进行构建。与此无关的内容不予以讨论。\n2.1 为什么用Bazel # - 代码管理方式：monorepo\n- repo中包含多种编程语言开发的projects；\n- 自定义rules、target来生成文件，如通过pb生成pb.go（不提交代码版本控制）；\n- 通过封闭构建，来保证可重复构建；\n- 希望能实现更细粒度的增量构建；\n- 希望能实现分布式构建；\n- 希望能利用构建缓存避免不必要地重复构建；\n- etc；\nps：if using multirepo \u0026amp;\u0026amp; go build, forget bazel. it overkills your project.\n2.2 Bazel核心概念 # bazel的上手成本相对熟悉go module的同学来说，还是有一定的学习成本的，学习bazel并不轻松，但是随着实践并陆续体会到monorepo+bazel带来的好处之后，会发现bazel是非常好的一个构建系统。当然，也可能体会不到 :(。\n要想熟练使用bazel，理解其工作原理不可缺少的，我们先来了解下bazel构建的核心概念。\n2.2.1 WORKSPACE # WORKSPACE，是一个文本文件，位于repo根目录下，这样的repo也称bazel工作区。\nWORKSPACE文件，定义了工作区下项目依赖的构建规则、外部依赖等，bazel构建targets时需要的输入、BUILD文件都在工作区下搜索，构建targets的输出也是存储在工作区中。\nbazel运行过程中会在工作区根目录下生成名如“bazel-*”的多个目录，构建依赖、输出等就是存储在这些目录下。\n2.2.2 BUILD # BUILD，是一个文本文件，位于工作区根目录以及子目录下，用于定义package。BUILD文件用于描述待构建的targets，以及构建每个target的输入、输出。\n2.2.3 TARGET # TARGET，是构建目标的意思，它位于BUILD文件中，每个BUILD文件中可以有多个targets。\ntargets的类型是多种多样的，如cc_binary、cc_library、cc_test分别表示构建c++可执行程序、库、单元测试，java_binary、java_library、java_test分别表示构建java可执行程序、库、单元测试。\nbazel内置支持的语言数量是有限的，只支持c++、java、python，其他语言要通过扩展rules来支持，比如rules_go提供了对go语言的构建支持，rules_go中定义了go_binary、go_library、go_test分别构建go可执行程序、库、单元测试。\n同样地，我们也可以扩展rules来调用一些代码生成工具自动生成一些桩代码文件，比如根据pb文件自动生成pb.go、grpc.go，或针对trpc框架的pb.go、trpc.go、validate.pb.go、_mock.go文件等等。\n2.2.4 RULES # RULES，简言之就是一系列扩展规则，它允许我们扩展新的target类型。RULES的编写，是通过Starlark语言来完成的，Starlark是一门配置语言，特别适用于bazel rules的编写。后面我们会通过扩展rules来扩展trpc相关的target，以通过pb生成trpc框架需要的桩代码。\n2.2.5 可见性 # 编程语言提供了某些语言级别的可见性保证，如C语言可以利用static/extern来声明变量的链接属性（对编译单元内可见还是全局可见），C++、Java类提供了一些修饰符，Go提供了导出、非导出的支持。\nBazel内部定义了一些可见性的声明方式，允许在语言之上提供更进一步的控制。可能有些语言没有提供可见性保证，即便是语言提供了类似的保证，Bazel的这个能力也能使得我们对代码施加更进一步的控制。如Go package A导出了一个类型给package B使用（跨包，不得不导出，这是语言级别的限制），但是出于某种原因（如不打算长期维护）并不希望这个类型给更大范围的团队使用，就可以通过Bazel可见性来进行精细化约束。\n2.2.6 封闭构建 # 当开发人员写完代码本地编译成功了，代码提交后，其他人在自己的构建环境下却构建失败，可能原因有多种：\n- go版本不一致，如go1.13才引入了errors.Is/As/Unwrap等，他人构建环境可能是go1.12；\n- protoc及插件版本不一致，如protoc-gen-go旧版本不支持paths=source_relative选项可能导致生成的桩代码路径位置错误，编译时引用失败；\n- mockgen版本不一致，如新版本要求go.mod已初始化，反之则会mock桩代码生成失败，go test因为缺少必要mock代码而构建失败；\n- etc；\n类似的原因还有很多，无法一一列举，我们应花功夫消除这些破坏可重复构建的因素。封闭构建，简言之就是保证构建环境的一致，并保证制品的可重复构建。\n要实现封闭构建，就要识别当前构建中的这些破坏性行为，并予以消除，如将分散在各开发同学机器上的构建工具锁定一个稳定的版本并打包成构建依赖，在WORKSPACE中定义该依赖及版本，构建时自动拉取该依赖并用其进行构建。\n2.3 Bazel构建实践 # 理解了上述的一些Bazel核心概念之后，看几个使用Bazel来进行构建的工程实例，加深理解。\n2.3.1 Bazel构建demo # - Building a C++ Project: https://docs.bazel.build/versions/4.2.1/tutorial/cpp.html\n- Building a Java Project: https://docs.bazel.build/versions/4.2.1/tutorial/java.html\n- Building a Android Project: https://docs.bazel.build/versions/4.2.1/tutorial/android-app.html\n- Building a iOS Project: https://docs.bazel.build/versions/4.2.1/tutorial/ios-app.html\n把上述4个构建实例全部看完，应该已经大致掌握了Bazel的使用了。\n有可能读者并不熟悉C++、Java、Android、iOS，有可能只熟悉Go呢？即便熟悉，要想直接从go module迁移到bazel构建也还是有相当大的成本的。所以我们还是要单独介绍下如何一步步从go module迁移到bazel构建，然后我们再介绍最终沉淀下来的trpc-go项目构建方案。\n2.3.2 Bazel构建Go # Go语言支持 # 不同于使用Bazel构建C++、Java，Bazel支持的内置语言不支持Go，需要引入扩展的rules来支持Go构建，即：https://github.com/bazelbuild/rules_go，参考bazelbuild/rules_go readme在WORKSPACE中增加相应的starlark脚本即可支持到。\nBUILD文件中，也要从bazelbuild/rules_go中加载target定义，如go_binary、go_library、go_test，此时我们便可以在BUILD文件定义go相关的targets了。\nGo依赖管理 # go工具链有支持go的依赖管理，开发人员在写代码的时候，go工具链能够自动地协助开发人员更新go.mod、go.sum，是非常易用的。ps 当然关于go module的不足我们就不讨论了。\n以go1.16为例，当我们代码中import了某个外部依赖，当我们编译的时候，为了保证可重复构建，go1.16要求我们显示地通过“go get $dependency”的方式将依赖添加到go.mod、go.sum中。这个过程比较严谨，开发人员在确认没有什么风险的时候，也会通过“go mod tidy”来批量将依赖更新到go.mod、go.sum中（只是为了方便）。\n要知道，go mod对依赖的管理是基于源代码中的importpath分析来实现的，bazel中如果要描述go packages之间的依赖关系，也是要采取类似的方式的，但是谁来做这个工作呢？rules_go这个扩展的规则集。\n一般来说，我们是要通过go_repository来定义外部依赖的（包括别名、importpath、版本、hash），然后在go_binary、go_library的deps属性中引用这些外部依赖，但是联想go get逐个添加的情况，逐个手写也bazel go依赖是会很啰嗦的。\n能否像执行“go mod tidy”一样自动更新所有的依赖呢？gazelle！\ngazelle，即：https://github.com/bazelbuild/bazel-gazelle。它能分析go源码中的importpath来自动更新deps.bzl（外部依赖）并自动生成go_binary、go_library、go_test，同时还能自动填充这些targets的deps属性。如果项目中同时支持go module、bazel构建，gazelle也可以通过go.mod、go.sum来更新deps.bzl以及targets的依赖。\nGo桩代码 # 在微服务开发中，RPC通信模式是当下主流方式，通信双方基于同一份IDL生成rpcstub文件，如grpc框架需要基于pb文件生成pb.go、grpc.go。pb也不属于bazel官方支持的语言，也是需要通过引入额外的rules扩展来支持对pb相关的桩代码的生成。\nrules_proto，即：https://github.com/bazelbuild/rules_proto，是对pb的扩展支持。\nps：大家可能会困惑，需要引入这么多扩展的rules？其实，这个只需要在WORKSPACE的根目录中配置一次就可以了，后续在工作区中开发，大家只关心BUILD文件编写就可以了。而且我们也会在工作区下放置一些shell脚本，运行脚本就能快速生成一个模板BUILD文件。这样使用起来就会方便多了。\nGRPC构建 # bazelbuild/codelabs，即：https://github.com/bazelbuild/codelabs，提供了一个比较完整的bazel构建demo，同一个WORKSPACE下包括了go、java、typescript、android、proto多个targets的构建，这也算个极简的monorepo了。\n2.3.3 构建trpc服务 # 我们将在第3节构建trpc服务中详细展开，我们推荐的目录组织方式、当前要做的工作，将来要进一步完善的工作。\n这里我们先简单梳理下，使用bazel构建trpc服务（先考虑trpc-go），我们需要考虑哪些：\ngo语言构建支持 # 前面我们介绍了基于rules_go扩展了对go的支持，以及基于go_binary、go_library、go_test来定义不同类型targets的方式。这部分内容对我们不再是挑战。\ngo module依赖管理 # 前面我们介绍了基于rules_go扩展了对go的支持，以及基于go_repository定义外部依赖并通过targets的deps对依赖进行显示声明，也介绍了基于gazelle进行辅助依赖管理。这部分内容对我们不再是挑战。\npb桩代码支持 # 前面我们提到了rules_proto对pb桩代码进行支持，通过rules_proto扩展的target类型，我们能生成pb.go文件，通过proto grpc扩展规则，我们也能生成grpc.go文件。但是trpc有点不同的是，trpc相关的桩代码生成逻辑，是通过统一的一个trpc命令行工具来生成的，包括：\n- $pb.pb.go：trpc调用protoc-gen-go生成；\n- $pb.pb.validate.go：trpc调用protoc-gen-secv生成；\n- $pb.trpc.go：trpc生成的适配trpc框架的rpcstub，作用等同于grpc.go；\n- $pb_mock.go：trpc调用mockgen生成；\n我们需要自定义新的规则集来支持trpc相关的代码生成逻辑，包括要定义对应的target类型，比如trpc_proto，其输入为pb文件，输出为对应的上述桩代码。trpc_proto该target应该作为trpc服务中go_binary、go_library、go_test的输入，准确地说是其trpc_proto的输出作为这几个target的输入。\nps：当然我们可以在将trpc_proto作为go_library的输入，让go_binary、go_test依赖go_library来完成与pb桩代码的链接，最终成功构建。\n现实比想象复杂 # bazel构建的掌握还是有一定学习成本的，当前公司里面，大范围采用monorepo+多语言开发的团队，采用bazel进行构建的实践并不多，借鉴加改进是必须的。\n依赖管理，并不如前文介绍那么简单，实际工程中依赖管理要复杂一些，要求对bazel的工作原理、扩展的rules的实现有更加清晰、完整的认识，否则构建失败将是家常便饭。\ntrpc工具的工作方式，安装加载配置文件、模板依赖$USER、$HOME，违背了bazel的封闭构建原则，需要进行定制化改造，以在bazel中正常使用。\nbazel构建，如果一不小心执行了bazel clean，那么后续再次构建将非常耗时，要拉取并构建大量的依赖工具，如protoc等等。大仓模式下，分布式增量构建、缓存是必须要开启的，否则与multirepo+go build相比构建效率严重下降。\n接触bazel时间不长、实践经验偏少，折腾两周，现仍存在一些未知事项。bazel的掌握，可能需要在推行monorepo+bazelbuild的团队进行适当的培训，加以指导。\n3 Bazel构建trpc # 这里介绍bazel构建trpc服务（如无特殊提及，这里的trpc服务均代指trpc-go服务），包括独立的trpc服务的构建、后续工程目录的组织方式、后续协议的托管方式，以及其他保证封闭构建、提高构建效率所需要做的工作。\n3.1 构建trpc服务 # 3.1.1 快速体验 # 为演示如何使用bazel构建一个trpc服务，准备了一个demo，以截图的形式提供。\n项目目录结构如下图所示：\n和trpc命令生成的模板工程有何不同？\n- 根目录下多了两个文件：WORKSPACE、BUILD文件；\n- stub目录下多了BUILD文件；\n- stub目录下少了hello.proto相关的go文件、go.mod文件、go.sum文件；\n确保已经安装bazel（macOS可以brew install bazel），cd到项目根目录：\n- 执行“bazel build //:helloworld”，即完成服务二进制程序的构建；\n- 执行“bazel run //:helloworld \u0026ndash; -conf=trpc_go.yaml”来启动程序；\n- 执行“bazel test //:helloworld_test”，将构建失败，现在还没有支持mock代码的生成；\nFIXME mockgen执行失败\n3.1.2 配置WORKSPACE # 如下图所示，通过注释部分可以看到做了哪些工作：支持go语言、通过gazelle辅助go依赖管理、支持protobuf、支持我们自定义的trpc。需要注意的是自定义的trpc是放置到该示例工程的trpc目录下的，将来推行大仓时，我们可以将其放在monorepo的根目录下。\n3.1.3 配置BUILD # 项目根目录下的BUILD中定义了该trpc服务的几个构建目标：\n- gazelle是为了辅助从go.mod文件自动更新依赖、targets中的deps属性的；\n- go_binary定义了要构建的可执行程序，它依赖helloworld_lib这个target，这个target由go_library定义，这里的这个定义实际上是所有源代码构建而成的一个库；\n- go_library定义了一个库，它被go_binary引用，它里面包含了一系列要构建的源文件，有工程内部的main.go、hello_service.go，也有外部依赖@repo//path-to:target，也有版本控制系统中未纳入的一些文件编译出的库，便是//stub/\u0026hellip;./helloworld:helloworld-stub-lib，这个依赖在stub/\u0026hellip;./helloworld/BUILD中定义，其实它把pb文件对应的pb.go、trpc.go编译成了可链接的库；\n- go_test定义了单测测试相关的构建，这里先不细看；\nok，现在我们先大致了解这几个target是怎么回事即可。\n继续看下stub/\u0026hellip;./helloworld/BUILD文件中的配置信息：\n- 加载了工作区根目录下的trpc/defs.bzl，其中定义了一个函数trpc_proto，这其实描述了一个新target类型的定义；\n- 使用trpc_proto定义了一个新的target，其输入为stub目录下的hello.proto文件，其输出当前由trpc_proto的生成文件列表决定，当前只生成pb.go、trpc.go；\n- 加载rules_go并通过go_library定义了一个新的target，这个target将trpc_proto的输出作为作为，同时该target也声明了一些外部依赖，该target编译出的库最终其导入路径为：脱敏处理，${importPath}/trpcprotocol/helloworld，通过这个importpath来帮助go编译器进行链接；\n到这里，我们了解了WORKSPACE、BUILD文件的大致配置，应该能理解bazel编译过程中的大致工作方式了。\n接下来我们再来看下我们自定义的trpc_proto target类型是如何定义的。\n3.1.4 扩展RULES # load(\u0026quot;//trpc:defs.bzl\u0026quot;, \u0026ldquo;trpc_proto\u0026rdquo;), trpc_proto实际上只是一个starlark编写的函数，就放在工作区根路径下的trpc/defs.bzl文件中。\n可能读者对starlark不熟悉，但是阅读应该能知晓其含义的。trpc_proto这个函数就是将定义的target中的属性作为参数传入，然后执行。该函数确定了要输出的文件列表，然后调用trpc_create函数对pb文件进行处理。trpc_create函数内部调用了trpc命令完成对pb文件桩代码的生成逻辑。\n但是这些工具从哪里来呢？通过trpc_create函数中引用的$$TRPC的值，可以确定trpc命令行即为//trpc:trpc，通过trpc/BUILD文件可以确定，//trpc:trpc指的就是//@trpc//:trpc。\n那@trpc这个外部依赖是从哪里来的呢？@trpc这个外部依赖又包含了哪些内容呢？\n外部依赖都是在WORKSPACE中定义的（或者由starlark函数从其他文件中加载而来），我们看下WORKSPACE文件中对该外部依赖trpc的定义，其实@trpc是引用的腾讯软件源上的一个压缩包，http_archive会下载该压缩包放到bazel-*临时目录中，并解压。\n这个压缩包中包含的内容都有哪些呢？可以下载下来看看，包含了trpc、protoc等常用命令以及pb文件。这个压缩包的内容，实际上是由 https://{脱敏处理}/go-kits/bazelbuild下的publish.sh脚本构建并推送到腾讯软件源的。\n上述http_archive中还有个配置项build_file，它表示将//trpc:BUILD.trpc.bazel作为该外部依赖@trpc的BUILD文件，这个文件干了什么呢？它定义了该package（BUILD对应package）的可见性，这样我们才能引用其下的一些trpc、protoc等二进制工具以及include/**下的pb文件。\n3.2 沉淀构建脚本 # 为方便编写WORKSPACE、BUILD文件，需定义几个shell脚本，帮助快速生成该类文件：\n- 沉淀常用的WORKSPACE配置到生成脚本generate_workspace.sh，放到公共库目录下；\n- 沉淀常用的BUILD配置到生成脚本generate_build.sh，放到公共库目录下；\n开发人员不管是定义新的WORKSPACE，还是在现有WORKSPACE中编写BUILD，借助上述脚本可以快速生成对应的文件模板，稍加修改便是。\n3.2 目录组织方式 # 如果后续推行大仓，大致的目录组织方式是这样的（红色部分与trpc构建相关）：\n- monorepo根目录下放置上述WORKSPACE；\n- monorepo根目录下放置上述自定义的trpc相关的bazel定义；\n- monorepo根目录下组织子文件夹，如大仓是BG级规模，子文件夹可用来区分部门、业务；\n- 部门、子业务下的项目按projects维度进一步组织子文件夹；\n- project维度就可以对应到我们的trpc微服务了；\n- project下的文件夹（go package)对应bazel package，需编写BUILD文件；\n- project下的go.mod、go.sum其实都可以删除了，保留应该也可以；\n- project下的stub下仅保留pb文件；\n- project下不保留stub目录，协议托管在rick，通过go_repository下载，project下BUILD中增加原stub/\u0026hellip;./helloworld/BUILD中target定义即可；\n- project下的go.mod、go.sum其实都可以删除了，保留应该也可以，辅助gazelle生成依赖；\n- @trpc常用工具，不再依赖开发个人、公共构建机上安装的资源，统一在软件源维护；\n- 其他；\n3.3 协议托管方式 # 3.3.1 随项目stub子目录 # 这种方式前文已经演示过了，可以支持到。\n3.3.2 协议管理平台托管 # 协议管理平台也是托管到工蜂，可以通过go_repository下载，也可以支持到。\n这两种协议托管方式都是可以支持到的。\n3.4 保证封闭构建 # 通过封闭构建来保证可重复构建，我们需要识别可能破坏封闭构建的一些行为，将其移除。\n目前观察，trpc命令及其依赖的工具的一些工作方式，可能有违背封闭构建的行为，如强依赖$USER、$HOME来安装加载配置、模板信息。工具侧可能需要进行对应的改造。\n3.5 改善构建效率 # 如果推行大仓+bazelbuild，需要把bazel的分布式构建、增量构建、缓存优势发挥出来，bazel cluster需要提前做相应的规划。\n掌握bazel构建和简单的go build管理起来，还是有一定的上手成本的 :)，想让大家使用monorepo+bazel build而非monorepo+go build，还是需要尽快做准备、优化bazel构建体验。说一千道一万，不如美好的初体验。\n4 总结 # 本文总结了Bazel构建的优势、核心概念、示例demo，以及使用Bazel构建trpc服务的一点实践总结，以及后续可行的目录组织、协议托管方式、其他相关工作。\n对Bazel相关的最佳实践还需要进一步去学习、探索，以充分发挥Bazel构建的优势。\n最后也感谢小伙伴等给予的反馈、提供的可供参考的bazelbuild工程。\n5 参考内容 # 1、官方bazelbuild文档\n2、bazelbuild/codelabs\n3、book: beginning bazel\n4、PCG个别团队的go bazelbuild实践，go项目bazel迁移\n​ TEG个别团队的bazelbuild实践：https://脱敏处理/yak/yak2\n5、其他km文章及外部分享\n6、Bazel学习笔记\n"}),a.add({id:225,href:"/tags/hermetic/",title:"hermetic",description:"",content:""}),a.add({id:226,href:"/tags/monorepo/",title:"monorepo",description:"",content:""}),a.add({id:227,href:"/tags/multirepo/",title:"multirepo",description:"",content:""}),a.add({id:228,href:"/tags/dma/",title:"dma",description:"",content:""}),a.add({id:229,href:"/tags/io/",title:"io",description:"",content:""}),a.add({id:230,href:"/tags/sendfile/",title:"sendfile",description:"",content:""}),a.add({id:231,href:"/tags/splice/",title:"splice",description:"",content:""}),a.add({id:232,href:"/tags/zero-copy/",title:"zero copy",description:"",content:""}),a.add({id:233,href:"/blog/2021-09-09-%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9B%B6%E6%8B%B7%E8%B4%9D%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF/",title:"常见的零拷贝优化技术",description:"本文介绍了零拷贝是什么、零拷贝优化的目的以及常见的零拷贝手段。",content:"在关注IO性能时我们经常听到零拷贝，那么零拷贝到底是什么呢？为什么要做零拷贝？又有哪些方案？本文就一起来看下。\n零拷贝技术一般可以分为两类 #  devices（disk、nic）和kernel buffer之间的数据拷贝，一般可以通过DMA（直接存储器访问）来优化掉，既能够避免中断CPU减轻CPU负载，也能够直接读写内存减少数据从nic到cpu再到kernel buffer的拷贝动作； kernel buffer和application buffer之间的数据拷贝；  说优化拷贝一般是去优化cpu拷贝，DMA拷贝是无法避免的。零拷贝则强调的是kernel buffer和application buffer之间的拷贝，零拷贝并不是说整个过程中完全有没有数据拷贝，在kernel space还是发生拷贝，当然下面提到的sendfile+DMA硬件支持分散读/聚集写情况下能优化掉kernel buffer之间的拷贝。\n然后明确下优化拷贝的原因 #  使用系统调用的次数影响到上下文切换次数，上下文切换会带来一定的开销，如read、write组合起来完成磁盘数据读取、网络发送，就要切换4次，而且read、write要重复很多次，上下文切换开销就不能完全忽视； 数据拷贝，主要是说利用cpu来拷贝，cpu势必要中断原来的任务去做拷贝的事情，move来move去，干了些杂活，理想情况下是希望尽可能做更多的事，当然不一定能完全避免cpu拷贝，但是能让拷贝的数据量减少点还是值得的；  零拷贝优化一方面是要优化掉kernel buffer和application buffer的数据拷贝问题，一方面也要考虑下如何尽可能减少cpu拷贝对程序停顿的影响。\n常见的拷贝优化方案 # 这里解决kernel buffer和application buffer之间数据拷贝的常用办法有以下几种，以读取磁盘数据发送到socket为例说明：\nmemory mapping # mmap系统调用，read的时候，dma从磁盘发送数据到kernel buffer，mmap根据fd映射对应的kernel buffer和application buffer，省掉一次考拷贝。write的时候，数据从kernel buffer直接拷贝到socket buffer再到nic buffer;\nshared buffers in kernel memory space # 这里希望能再次优化掉mmap方案中write时从kernel buffer到nic buffer的拷贝，在kernel space中建立一个共享内存区域buf，dma传送数据到这个buf的b_data指针指向的位置，write的时候使用dma从这个buf的m_data位置开始写，其实b_data、m_data共享了底层内存区域。相当于一个写指针、一个读指针。通过这种方式优化掉了kernel space到nic space的拷贝；\nshared buffers between user and kernel space # linux sk_buffers结构，其中有个指针记录着要发送的数据（application buffer中）的地址，避免了从application buffer到kernel buffer的拷贝；\ndifferent system calls, sendfile, splice, etc # 先说sendfile，sendfile允许在fd之间直接传送数据，进出sendfile上下文切换只需两次，数据直接从源fd对应的kernel buffer（dma从设备上拷贝过去）到目的socketfd的socket buffer拷贝，完全绕过了应用程序buffer及其拷贝；\nsendfile with DMA Scatter/Gather copy # 上面sendfile存在一个从kernel buffer到socket buffer的cpu拷贝，如何优化掉？在硬件支持下，kernel buffer可以只把这个buffer的fd信息发送给socket，这里就避免了数据拷贝，这里的kernel buffer可以是多个，那就发送多个buffer的fd信息给socket，然后DMA借助分散读聚集写直接从上述kernel buffers拷贝到nic buffer。这样完全消除了cpu拷贝动作，避免了对cpu的中断；\nsplice # 从一个fd到另一个fd拷贝数据，先要在两个fd之间通过pipe系统调用构建一个管道，管道在内核中就是一个buffer只不过返回读端、写端在userspace中供读写。splice就是从源fd的kernel buffer写到pipe buffer的写端，然后再从这个pipe buffer的读端拷贝数据到目的fd的kernel buffer。和前面最牛对技术方案相比，这种方案和前面这种sendfile+DMA分散读聚集写相比，kernel space中多了两次cpu copy，好处是可以不需要硬件的支持；\nhardware support # 前面已经提到过了DMA相关的加成，可能还有其他方案；\n总结 # 本文总结了零拷贝是什么、目的是什么以及有哪些常见的优化手段，除了软件层面的方案，在硬件加成下还可以做更好的方案。其实不同零拷贝技术对安全加密、过滤也有不同的影响，这部分内容如果有机会再总结分享。\n参考内容 #  https://www.uidaho.edu/-/media/UIdaho-Responsive/Files/engr/research/csds/publications/2012/Performance-Review-of-Zero-Copy-Techniques-2012.pdf mmap：https://man7.org/linux/man-pages/man2/mmap.2.html splice/tee：https://www.kernelhcy.info/?p=202 splice: https://man7.org/linux/man-pages/man2/splice.2.html  "}),a.add({id:234,href:"/tags/etcd/",title:"etcd",description:"",content:""}),a.add({id:235,href:"/tags/kvstore/",title:"kvstore",description:"",content:""}),a.add({id:236,href:"/tags/raft/",title:"Raft",description:"",content:""}),a.add({id:237,href:"/tags/wal/",title:"wal",description:"",content:""}),a.add({id:238,href:"/blog/2021-09-04-%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8raft%E5%BC%80%E5%8F%91%E5%BC%BA%E4%B8%80%E8%87%B4kv%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/",title:"如何使用raft算法开发强一致kv存储系统",description:"...",content:"本文内容 # 本文结合etcd源码来进行介绍，etcd/contrib/raftexample提供了一个基于etcd/raft实现的kv存储系统。从该示例出发，我们来看一看如何基于raft算法开发一个强一致的kv存储系统。\n看完本文的源码分析后，上手一个raft强一致系统开发就不是什么难事了。\nps：假定读者已经阅读并理解了raft论文，这里有我的批注版的In Search of an Understandable Consensus Algorithm.pdf，读起来可能会好理解点。\netcd/raft # etcd服务端程序入口：see 源码\n 启动过程中区分当前节点类型：根据data-dir目录下的目录名member/proxy/empty来区分，然后启动etcd实例或者proxy； 启动etcd服务节点：startEtcd这个函数，逻辑主要包括启动供集群节点间通信的rafthttp服务，以及供客户端请求的服务； 启动etcd proxy：startProxy这个函数，逻辑主要是启动etcd代理；  etcd哪些部分值得学习：\n etcd proxy从项目功能上来说虽然很重要，但是从学习角度来说没那么有价值，不看这个； etcd server从项目功能上来说是核心，但是我们也没有必要学习所有的请求处理逻辑，重点是关注读写操作时如何基于raft实现强一致； raft：这部分是raft算法的核心实现，从理解raft论文到算法工程化需要额外做出巨大的优化，这些知识点往往是通用的，重点掌握；  raft部分：\n pb协议：  raft peers的通信协议，see 源码； raft算法中提到核心的几个rpc就是Vote、AppendEntries，但是工程中需要考虑更多，详见上述pb中的enum MessageType； 上述pb中的message Message类型定义了rpc通信过程中的请求/响应，不同rpc通过MessageType type字段区分；   状态机：  raft实现数据一致性是通过replicated log（复制日志）实现的，这里的replicated log有时也称为WAL（write ahead log）； raft算法中，每个节点raftnode可能处于以下状态中的一种：follower、candidate、precandidate、leader； raft算法中，每个节点的状态可以通过一个状态机来建模；    了解了这些基础知识之后，我们结合etcd/contrib/raftexample来解释下raft如何选举，以及leader遇到写操作如何保证数据强一致。\netcd/raft如何进行leader选举 # newRaftNode newRaftNode，see 源码，这个函数包括创建一个var rc raftNode，然后rc.startRaft()，这个函数包含非常重要的几个部分：\n startNode，see 源码，这个主要是建立好raftnode启动时的一些初始状态转换，有一个for事件循环处理，如改变raftnode的状态：tick函数、step函数，以及一些message的处理等等； serveRaft： serveChannels：see 源码  startNode:\n 如何查看这部分源码呢，首先从启动一个raftnode开始吧：see 源码； StartNode函数启动一个raftnode，节点刚启动的时候state都是follower：see 源码； StartNode→Bootstrap(peers)通过配置告诉当前raftnode有多少个raftpeers，然后这些raftpeers加入与当前节点所在的集群属于变更配置，也要记录到raftlog中； raftnode真正跑起来是在这里：see 源码，这里有个大的for循环，node的主要逻辑都在这里了；  tickElection：for/switch-case n.tickC，选举逻辑，此时如果当前raftnode为follower或者candidate吧，此时的tick函数为tickElection，如果选举超时时间过了并且没收到leader的heartbeat来重置选举超时时间，此时会将MsgHup消息类型传入step函数中，将当前follower变为candidate发起选举：see 源码。这里的选举在raft论文中是直接就是选举动作，但是工程上做了优化，引入了一个可选的两阶段选举prevote。虽然可以tick是触发了tickElection，但是这个后续执行中会检查当前节点是否有资格成为leader，不一定有资格（比如自身的WAL不满足条件）。 假如有资格发起选举，则会调用becomeCandidate，会将当前raftnode的term+1，并且step函数变为stepCandidate。然后会调用r.poll来判断是否胜选：see 源码，其实这里是判断的自己给自己投票的话能否胜选，对于single raftnode的集群有用，假如是多节点集群那么这里无法胜选，继续看。ps：如果胜选就becomeLeader成为leader了。如果不是单节点，就要通过r.send发送投票给各个peers：see 源码。这里的r.send并不是真的网络发送，而是记录到r.msgs里面等下处理这里的r.msgs。注意这里r.send的时候已经编程了MsgVote类型了，表示投票请求，后续也应该收到MsgVoteResp。 r.msgs什么时候处理呢？还是前面我们提到的这个大循环体，每轮循环都会检查r.msgs中有没有message要处理：see 源码，这里的函数n.rn.HasReady()方法检查到len(r.msgs)\u0026gt;0，则认为有消息要处理，这个消息最终会被包装到一个Ready{}事件中，这个事件会被丢到n.readyc这个chan中，什么时候处理在下面serveChannels中介绍。 becomeLeader：see 源码，step函数变为stepLeader，tick函数则变成tickHeartbeat，意味着当前为leader需要给followers定时发送heartbeat来重置它们的选举超时时间，那么heartbeat是什么形式的呢？其实就是通过appendEntry，只不过entry为空，用这种空的entry来表示心跳。leader就要担负起write请求的重任了。 但是如果没胜选的话，raftnode的状态就是candidate，step函数未stepCandidate，下面会继续用到。    serveChannels： 前面关于r.msgs的消息没跟踪到在哪里处理的，我们看下是不是在serveChannels里面？ serveChannels: see 源码\n 这个函数里面也有一个for事件循环，当它发现rc.node.Ready()有var rd Ready{}事件可处理时，如果rd上有非空的snapshot，就写入storage，然后将rd.Entries也记录到rd.HardState，然后将rd.Entries也写入storage，最后将rd.Messages发送到peers。我们感觉voteMsg是在这个时候发送给peers的，到底是不是呢：see 源码。是的，这里的rd事件就是从raftnode.Ready()从发从其raftnode.readyc这个channel中取出来的。取出来后通过transport发送出去，这样voteMsg就发送出去了，那么投票的响应又是什么时候收到、什么时候处理的呢？ startRaft/AddPeer的时候会调用startPeer，内部会开始循环收包，收peer发来的raftmessage放入一个recvc chan中，startPeer中专门开启了一个goroutine来检查recvc中有没有peer发送来的消息，比如peer发送给我们的voteMsg的响应包：see 源码。这里通过raft.Process(ctx,m)对raftmessage进行处理。如何处理是在这个示例代码中定义的：see 源码，即调用step函数进行处理。我们再往回看下，发送这个消息前已经把节点的step函数修改为了stepCandidate，那我们再看下这个函数里面干了啥，猜测应该有判断是否收到多数投票确认的逻辑； stepCandidate：see 源码，我们不考虑可选的prevote阶段，很显然这个消息MsgVote的响应类型应该是MsgVoteResp，如果是的话，就继续r.poll检查下是否胜选吧，如果胜选了，则自己becomeLeader，然后广播appendEntries，这里append是干啥，是为了通治其他peers更新commit index吧。  这样leader选举就完成了！！！\netcd/raft leader执行put操作如何保证强一致 # 用etcd/raft实现强一致的系统示例：https://github.com/etcd-io/etcd/tree/main/contrib/raftexample。我们不妨从这个项目入手来看下到底是怎么工作的。上述项目是一个暴露http接口的kv强一致存储系统。\n接下来重点看一个leader负责执行命令put \u0026lt;key\u0026gt; \u0026lt;value\u0026gt;时的执行逻辑，是怎样的，领略下这个过程中raft扮演的角色。 put命令是通过http put method实现的，see 源码。\n这里的处理逻辑也很简单，它直接调用了h.store.Propose(key, string(v))，h.store是一个kvstore，这里的Propose是干嘛呢？这里就可以跟raft算法中的MsgProp关联起来了，还记得吗？MsgProp这种消息类型是用来appendEntries的。这里的思想就是WAL（write ahead log）的思想，先把动作记录到日志中，后面在通过日志来更新状态机。状态机的状态都包含什么呢，我们前面已经知道有各种状态的流转，那么这个日志中记录的数据存储在哪呢？\n就是这里的kvstore啊！一个raftnode启动后要把快照、日志中记录的事件还原到一个特定的存储中，这个示例中就是一个内存中的kv数据结构。h.store.Propose(key,string(v))首先异步地调用kvstore.Propose(key,val)将数据写入到proposeC这个chan中：see 源码，然后再异步地从中取出来：see 源码，通过rc.node.Propose(ctx, prop)，转入raft.node.Propose实现：see 源码，这里的n.stepWait方法将MsgProp消息类型以及要写入的日志数据传给stepWait，这里面将消息写入到raftnode.propc就完事返回了。\nstartPeer从这个propc chan中取出消息m，然后r.Process(ctx, m)去处理，r.Process方法是在示例代码中自定义的，see 源码，通过r.Process进入step函数又来到r.Step(m)，此时raftnode.Step函数是什么呢？赶紧看看发送MsgProp消息时又没有更改raftnode.Step，没有，那这个Step应该是stepLeader\u0026hellip;没错，沿着stepLeader一路看下来：see 源码，这里果然是leader让peers appendEntries的动作，干了什么呢？\n首先当前raftnode.appendEntries，把MsgProp消息里的日志项（可能有多条）先追加到自己的log entries里面，然后bcastAppend发送给所有的peers让它们去append entries，它们追加成功后肯定回回包MsgPropResp消息类型的消息。我们看看这个消息是在哪里处理的？感觉应该也是在startPeer函数中的收包逻辑里面。那应该也是从recvc chan中取出回包处理。\n哈哈，看半天竟然没搜索到MsgPropResp消息类型，前面读源码时有个细节漏掉了。sendAppend的时候实际上会把消息类型改成MsgApp（MessageAppend）去追加日志，followers处理完成后响应一个MsgAppResp消息类型。对于leader raftnode，收到消息后触发状态转换，又要执行其step函数，此时step函数还是stepLeader，发现消息是MsgAppResp，准备处理：see 源码。\n我们先考虑正常情况，leader收到响应发现follower在WAL中记录了发送的log entries，leader收到此响应后就会决定是否要更新该follower的next index（下次要发送的log entries开始索引）。然后判断是否可以更新leader的commit index了，更新了之后对client的读请求就可见了。leader更新了commit index之后也要通过bcastAppend通知followers更新commit index。\n这些已提交索引之前的log entries会被发布到示例代码中的commitsC chan中，然后有一个goroutine专门读取这上面的commitC并把其中的entries读取出来，应用到我们的kvstore中，这样存储的一些数据就从WAL日志转化为了内存数据结构中的真实数据，可以对外提供查询服务了。\n小结 # 大致就是这些内容吧！感兴趣的继续深挖下raftexample+raft实现吧。感觉自己已经理解了raft的核心思想以及如何使用raft来开发强一致存储系统了，读者是不是也有同感呢:)\n"}),a.add({id:239,href:"/tags/techlead/",title:"techlead",description:"",content:""}),a.add({id:240,href:"/tags/technical-leadership/",title:"technical leadership",description:"",content:""}),a.add({id:241,href:"/blog/2021-08-17-%E5%9F%B9%E5%85%BB%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/",title:"培养技术领导力",description:"技术领导力的3个层次：leading self, leading others, leading organizations，你准备好了吗？",content:"关于如何培养自己的技术领导力，文章technical leadership: getting started 中作者分享了自己的心得。\n读后深有感触，现在做一个简单的总结。总结不拘泥于原文结构，根据个人感悟重新整理下。\n塑造领导力的3个层次：leading self，leading others，leading organizations。没有人天生就是专家，在成为专家的路线上，我们就要沿着这3个层次慢慢锻炼提升自己。\n成为专家 # 想起10000小时定律，要成为领域专家是需要付出大量的实践的，过程中要不断提升自己的实践能力、技术视野、对公司业务价值及目标的理解。能否成为真正的专家，靠的不是运气，而是稳定持续地有力输出，again and again and again…consistently！这里就要求自己先做到leading self，把自己做到最好，起到表率的作用。然后再尝试靠技术领导力去leading others，leading organizations。\n善于分享 # 提高这里的输出，也不能总是依靠个人能力。如果你想走得够快，你可能选择自己走；如果你想走得更远，那必须依靠团队的力量。对于掌握的知识、技能，藏着掖着并不是在帮你，因为你没有正向激励到身边的人，没有在恰当的时候塑造有力的技术影响力，更没有帮助大家提升到更接近的段位来一场更漂亮的团战。是时候地分享自己掌握的知识、技能，也减少他人对自己的依赖，侧面上可以赢取更多的时间放在更有价值的事情上。知识是没有穷尽的，总会有更值得钻研的领域等着去探索。\n有效沟通 # 有效沟通，并不是说要如何快速地结束沟通，而是如何高效率地达成共识。当然有些沟通不能达成共识，但是也要有效地同步双方掌握的问题背景、信息，完成意见的交换，仍应当放在沟通目的的第一位。看待问题要避免掺杂过多主观成分，客观看待问题，以目标为导向，更有助于促成有效沟通。有效沟通是表达自己、了解他人的前提，也是能团战的必要条件。\n加油！加油！加油！\n"}),a.add({id:242,href:"/tags/%E6%8A%80%E6%9C%AF%E9%A2%86%E5%AF%BC%E5%8A%9B/",title:"技术领导力",description:"",content:""}),a.add({id:243,href:"/books/golang/",title:"Go语言设计实现内幕",description:"作为一名Go语言开发展，很庆幸见证了Go语言的逐渐发展壮大，现在也赢得了很多开发者的青睐。作为一名Gopher，很难不被Go语言的设计实现所着迷，或者说，了解这里的设计实现细节，可以让我们学到更多，也可以写出更好的代码。",content:"作为一名Go语言开发展，很庆幸见证了Go语言的逐渐发展壮大，现在也赢得了很多开发者的青睐。作为一名Gopher，很难不被Go语言的设计实现所着迷，或者说，了解这里的设计实现细节，可以让我们学到更多，也可以写出更好的代码。\n 在我学习Go语言的过程中，也阅读了不少其他开发者写的文章，也做了很多源码分析、跟踪调试，怎么说呢？了解这些细节其实并不是最重要的，了解背后的设计方案、设计思想才是最有价值的。细节总是在变化中的，但是设计方案、思想的大方向是更加明确些的。我逐渐将之前收集、书写的内容进行分类整理，就变成了当前的电子书。\n本内容涉及大量的Go语言设计实现方面的内容，包括编译器、链接器、运行时调度、内存分配器、垃圾回收器、标准库等等，尽量保证知识点的系统性，《Go语言设计实现内幕》。\n欢迎阅读，如果您在阅读过程中发现有错误、疏漏、建议，不要犹豫，请给我提issue。\n"}),a.add({id:244,href:"/tags/8%E6%9D%A1%E8%B0%AC%E8%AE%BA/",title:"8条谬论",description:"",content:""}),a.add({id:245,href:"/tags/%E5%88%86%E5%B8%83%E5%BC%8F/",title:"分布式",description:"",content:""}),a.add({id:246,href:"/blog/2021-07-05-%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%978%E6%9D%A1%E8%B0%AC%E8%AE%BA/",title:"分布式计算的8条谬论",description:"分布式计算的谬论，是由L Peter Deutsch以及其他Sun Microsystems的同行总结的几条分布式计算初学者经常误以为成立的判断。",content:"分布式计算的谬论，是由L Peter Deutsch以及其他Sun Microsystems的同行总结的几条分布式计算初学者经常误以为成立的判断。\n这8条谬论分别是：\n 网络是可靠的； 通信时延为0； 带宽是无限的； 网络是安全的； 拓扑不会改变； 只有一个管理者； 传输成本为0； 网络是同构的；  陷入这8条谬论会导致如下后果：\n 开发的软件程序中针对网络的错误处理不够健壮，遇到网络错误时程序会stall或者无限等待响应，即便是网络恢复了，程序也不能自行恢复或需要手动重启； 忽视通信时延以及可能导致的丢包问题，应用层、传输层开发人员开发的程序对于传输流量大小没有任何限制，会导致严重的的丢包或者带宽浪费； 流量的发送方，忽视带宽本身的限制，会导致一些瓶颈； 忽视网络安全容易被恶意用户和不断演进的能绕过安全软件的恶意程序蒙蔽双眼； 网络拓扑的改变也会对网络带宽和通信时延产生影响，因此会产生相似的问题； 可能会出现多个管理员，它们可能会制定出相互冲突的策略，流量的发送方需要知道这里的“策略”才能按预期路径传输，但是策略出现冲突，会对传输造成影响。 构建、维护一个网络或者子网的隐藏成本不能被忽略，在预算中必须清晰地列出来，而不能出现突然地削减； 如果假定一个系统是同构网络，那么可能会导致这里列出的前3个谬论；  这8条谬论的诞生：\n这8个谬论大部分由来自Sun Microsystems公司的L. Peter Deutsch提出，1994年它提出了前7个。不过Bill Joy和Tom Lyon在那时就早已经将前4条作为网络计算的谬论了。在1997年，James Gosling（Sun员工，也是Java之父）添加了第8条谬论。\n"}),a.add({id:247,href:"/tags/2pc/",title:"2PC",description:"",content:""}),a.add({id:248,href:"/tags/3pc/",title:"3PC",description:"",content:""}),a.add({id:249,href:"/tags/base/",title:"BASE",description:"",content:""}),a.add({id:250,href:"/tags/cap/",title:"CAP",description:"",content:""}),a.add({id:251,href:"/tags/concenus/",title:"Concenus",description:"",content:""}),a.add({id:252,href:"/tags/flp/",title:"FLP",description:"",content:""}),a.add({id:253,href:"/tags/paxos/",title:"Paxos",description:"",content:""}),a.add({id:254,href:"/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F/",title:"分布式系统",description:"",content:""}),a.add({id:255,href:"/blog/2021-07-01-%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E5%B7%A5%E7%A8%8B%E5%B8%88roadmap/",title:"分布式系统工程师roadmap",description:"广大后台开发同僚们，想必都经历了这样那样的分布式系统实战，可能遇到过数据一致性问题，可能遇到过事务一致性问题，可能遇到过集群变更问题……似乎大家没有深厚的分布式系统理论，也在实践中渐渐成长为了有经验的分布式系统工程师。但是，“有经验”也可能是只是经验主义，并不是真的知道了“真理”。这里并不是要做个老学究，而是说深入理解了分布式系统理论后，实践中会更加得心应手。本文整理汇总了一些比较重要的分布式系统教程，以及工程参考范例，理论与实践相结合想必会有更大收获。",content:"如何成为一名资深的分布式系统工程师，需要补齐哪些理论基础，又需要哪些工程方面的锻炼？本文原文见 Henry Robinson 的文章 distributed systems theory for the distributed systems engineer，我觉得是一个很不错的roadmap，沿着这个脉络半年下来，还是很有收获的……继续:)\n1 掌握分布式背后的相关理论 # 可能会有人甩出很多论文，FLP论文、Paxos论文、Raft论文、拜占庭将军相关的论文\u0026hellip;相关的论文可以摆出很多，但是论文是有一定深度的，是非常严谨的论述，对于攻读PhD的同学有帮助，但是对于一名从事分布式系统工程的同学真的有必要全部掌握吗？应该看多少论文，毕竟经过了那么多年的发展、沉淀呢？ 作为一名分布式系统工程师，搞明白需要掌握哪些理论，比单纯了解有哪些论文更重要。\n2 First Steps # 下面的4个文集很好地介绍了构建一个分布式系统要面临的挑战，它们共同概述了分布式系统工程师必须克服的一些技术上的困难，并为后面章节中更详细的说明奠定了基础。\n Distributed Systems for Fun and Profit，介绍了分布式系统的基础知识，包括时间在分布式系统中扮演的角色、不同的复制策略等； Notes on distributed systems for young bloods，不是纯理论介绍，在理论和实践中做到了一个不错的平衡，为后续更深入学习打好基础； A Note on Distributed Systems，一篇很经典的论文，解释了分布式系统中为什么不能总把远程交互对象当做本地的对象，让读者理解分布式场景中的问题和挑战； The fallacies of distributed computing，分布式计算的8个谬论，为分布式系统设计人员设计系统打下基础；  我们需要了解两个重要属性的含义，“safety”和“liveness”：\n safety，该属性表示不会有坏的事情发生，如API不会返回不一致的value、集群中不会同时选出两个leader等； liveness，该属性表示好的事情最终会发生，如API最终会返回一个结果、磁盘写操作最终会完成等；  3 Failure and Time # 分布式系统工程师面对的一些困难，其实可以归结为下面2个原因：\n Processes may fail There\u0026rsquo;s no good way to tell that they have done so  即，分布式系统中的任意进程可能会出现故障，但是其他进程又没有可靠的方式来感知这个进程出现了故障。\n进程掌握并共享给其他进程的时间方面的信息、可能检测到的故障场景以及可以正确实现的算法和原语之间存在非常紧密的关系。大多数情况下，我们假设两个不同的节点对于现在是什么时间或时间流逝的速度完全没有共享的信息。\n我们需要认识到：\n 故障模式（failure modes）也是分层次的，大致分成：crash stop（崩溃停止） → omission（遗漏） → Byzantine（拜占庭）。我们要知道在层次结构顶部可能发生的在较低级别必须是可能的，在较低层不可能发生的在更高级别也必须是不可能的； 在缺少任何共享时钟的情况下，如何判断一个事件和另外一个事件发生的先后顺序。我们需要掌握Lamport clocks，以及它的泛化Vector clocks，也参考下Dynamo的这篇论文吧； 发生单个故障的可能性，对我们实现一个正确的分布式系统的影响有多大（可以参考下面给出的FLP result的笔记）； 不同的时间模型（models of time），同步（synchronous）、部分同步（partially synchronous）、异步（asynchronous）； 检测故障是一个基本问题，它在准确性和完整性之间进行权衡——这是另一个safety与liveness（安全与活跃）的冲突。 真正将故障检测作为理论问题提出的论文是 Chandra 和 Toueg 的“Unreliable Failure Detectors for Reliable Distributed Systems（可靠分布式系统的不可靠故障检测器）”。但是也有几个较短的摘要总结 - 我非常喜欢斯坦福大学的这个随机摘要总结Survey on Scalable Failure Detectors。  4 The basic tension of fault tolerance # 一个可以容忍某些故障（fault tolerance）而不降级（downgrade）的系统必须能够像这些故障没有发生一样运行。 这通常意味着系统的某些部分必须冗余地工作（work redundantly），但做比绝对必要的工作更多的工作（do more work than is absolutely necessary）通常会带来性能和资源消耗的成本。 这是为系统添加容错（fault tolerance）的基本冲突。\n我们需要了解：\n 确保单副本可串行化（single-copy serialisability）的仲裁技术（quorum technique）。 请参阅 Skeen 的原始论文 a quorum-based commit protocol，但也许更好的是 Wikipedia 的条目。 关于2阶段提交（2-phase-commit，简称2PC）、3阶段提交（3PC）、Paxos，等等，它们为什么会拥有不同的容错属性； 最终一致性（eventual consistency）及其他技术，如何以对系统行为的较弱保证为代价，来避免一致性、性能之间的冲突。Dynamo论文（Dynamo: Amazon\u0026rsquo;s Highly Available Key-Value Store）是一个了解这些内容不错的起点吧，Pat Helland的经典论文 Life Beyond Transactions（Life beyond Distributed Transactions: an Apostate\u0026rsquo;s Opinion） 也值得一读。  5 Basic Primitives # 分布式系统中几乎没有达成一致的基本构建块（building blocks），但更多的开始出现。 我们需要知道以下问题是什么，以及在哪里可以找到对应的解决方案：\n 领导者选举（leader election），Bully算法等； 一致性快照（consistent snapshotting），Chandy和Lamport的经典论文 Distributed Snapshots: Determining Global States of a Distributed System 等； 共识问题（consensus），参考上面提及的2PC、Paxos论文； 分布式状态机复制（distributed state machine replication），wikipedia的介绍就不错，Lampson的论文 How to build a highly available system using consensus 比较正式但是有点枯燥； 广播（broadcast），同时传递消息给不止一个节点，这里又有几种不同的技术：1）原子广播（atomic broadcast），要么广播一个消息给分组（group）内的所有节点，要么不广播给任何一个节点；2）gossip，参考经典论文；3）因果多播（causal multicast），也考虑下Birman和Cheriton之间令人愉快的来回。 链式复制（chain replication），通过将节点组织成虚拟链表来确保写入的一致性和顺序性的一种巧妙方法。1）最早的论文 Chain Replication for Supporting High Throughput and Availability；2）对读多写少场景的一系列改进 Object Storage on CRAQ: High-throughput chain replication for read-mostly workloads；3）@slfritchie做的一个实验报告 Chain Replication In Theory and in Practice Working Title, rough draft。  6 Fundamental Results # 关于分布式理论的几个事实要牢记在心，先列几个帮助比较大的。\n 如果在不同进程之间有消息丢失（网络分区），我们将不能实现强一致性存储（C）的同时还能对所有请求进行正确响应（A）。这就是大家熟知的CAP理论； 共识（concensus）是不可能通过如下方式实现的：1）总是正确的；2）总能终止，即使当（异步）系统中某台机器出现“崩溃-停止（crash-stop）”时（FLP result）。在论文“We Love SF Talk”第一页解释了FLP result，后面是证明，没有必要去搞明白证明过程（反证，琢磨下也好理解）。 一般而言，在少于2轮消息交互的情况下不可能解决共识问题； 原子广播（atomic broadcast）和共识问题一样困难——准确地说，如果我们解决了原子广播，也就解决了共识问题；反之亦然。Chandra和Toueg证明了这一点（Unreliable Failure Detectors for Reliable Distributed Systems），我们了解这是对的就好了。  7 Real Systems # 掌握、精通分布式的最重要的方式就是不断实践，不断阅读、了解、跟进、评价业界的真实系统、新出现系统的设计决策。 一遍又一遍地这样做。\n下面是一些推荐阅读信息：\nGoogle：\n GFS Spanner F1 Chubby BigTable MillWheel Omega Dapper Paxos Made Live The Tail At Scale  Not Google：\n Dryad Cassandra Ceph RAMCloud HyperDex PNUTS Azure Data Lake Store  8 Postscript # 本文作者是 Henry Robinson ，原文见 distributed systems theory for the distributed systems engineer。作者在文末留了个招聘广告，这里就保留了（既然干货满满如此有诚意）。\n 如果你掌握了这个列表中的所有概念和技术，可以联系我，我想和你谈谈我们在Cloudera Slack的分布式系统工程师开发职位。—— Henry Robinson\n ps：作者功力有限，翻译中如有疏漏错误之处，请指出来避免我误导他人。\n"}),a.add({id:256,href:"/tags/design/",title:"design",description:"",content:""}),a.add({id:257,href:"/blog/2021-06-23-go%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0%E7%B3%BB%E5%88%97%E6%96%87%E9%9B%86/",title:"go设计实现系列文集",description:"陆续看过一些go语言设计实现的文章，编译器、运行时调度、内存管理、垃圾回收、race检测、AST、locks等等吧，相对来说比较系统。收藏的这些文章，描述都比较形象、简单易懂，和动辄分析大篇幅的源码来说，对初学者或者希望利用碎片化时间学习的同学来说，会比较友好一点……就分享一下吧。",content:"陆续看过一些go语言设计实现的文章，编译器、运行时调度、内存管理、垃圾回收、race检测、AST、locks等等吧，相对来说比较系统。收藏的这些文章，描述都比较形象、简单易懂，和动辄分析大篇幅的源码来说，对初学者或者希望利用碎片化时间学习的同学来说，会比较友好一点……就分享一下吧。\n"}),a.add({id:258,href:"/tags/internals/",title:"internals",description:"",content:""}),a.add({id:259,href:"/tags/%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"设计实现",description:"",content:""}),a.add({id:260,href:"/tags/l4/",title:"L4",description:"",content:""}),a.add({id:261,href:"/tags/l4ka/",title:"L4Ka",description:"",content:""}),a.add({id:262,href:"/tags/microkernel/",title:"microkernel",description:"",content:""}),a.add({id:263,href:"/blog/2021-06-19-the-l4-microkernel/",title:"The L4 MicroKernel",description:"L4简介 # L4是在L3基础上开发的，改进了IO和IPC等，L4致力于打造一个通用的微内核，以便允许在其基础上进一步定制化来满足场景需求，L4衍生了不少微内核实现。\n现在也有些工作组致力于将Linux在L4上运行起来（L4Linux），将Windows在L4上运行起来（L4Windows），著名的GNU Hurd已经从老的Mach微内核迁移到了L4微内核。\n内核划分依据 # 微内核相比于宏内核，主要是微内核提供的核心更小，区别二者的依据并非源码多少，而是内核中提供功能的多寡。GNU Hurd中有提供宏内核、微内核、混合内核的对比示意图，点击查看。注意，宏内核有时记作monolithic kernel，也记作macro kernel。\nps：通常微内核源码会比宏内核少很多，如L4::Pistachio/ia32只有1w+左右的代码，但是Linux有几百万行。\n微内核通常将内核功能限定在下面几个方面：\n 进程管理； 虚拟内存管理； 进程通信、同步机制；  其他宏内核中常见的文件系统、设备驱动、网络功能在微内核中都是在用户态实现，这些功能可能在single-server中全部实现，也可能在multi-server中实现，进程通过内核IPC机制与server之间进行通信来。\n因为微内核中用户程序请求一些用户态的server（如文件系统、网络等服务）都需要借助IPC来完成，IPC用的非常多，改进其性能就显得尤为重要。早期的微内核实现IPC性能比较差，L4及以后的微内核设计都将提升IPC性能作为一个重要方向，L4中已经做的不错了，一起来了解下是如何实现的。\n微内核优缺点 # 优点 #   robustness：微内核中将很多功能在用户态实现，比如以multi-server的方式实现，假如文件系统服务出故障了，直接重启该服务即可，无需重启整个内核。而且这些服务是在用户态运行的，无权访问核心态数据，对整个内核无破坏性。微内核体积小也更方便维护、调试、定位、修复。\n  security：安全是系统很重要的方面，root用户可以访问一切资源，宏内核中root的权限、可支配范围相当大，root权限被滥用会导致严重问题，如Linux 2.4以前版本ptrace可以加载任意模块包括恶意模块。微内核中这样对权限收的更紧，没那么多系统调用，自然获得root权限的入口更少，更容易约束。\n  memory usage：内核的代码、数据需要常驻内存，宏内核中即便某些部分不常用到也不能够换出到交换区，会浪费内存空间，也影响用户程序执行效率。在微内核中，微内核本身体积小，宏内核中的一些核心服务被放到用户态中实现了，使用不频繁的内存区可以换出到交换区。\n  performance：当想在微内核核心态执行操作时，通常要关闭中断，以避免一些重要的处理过程被中断，这么做顶多会导致当前的一些程序、服务没有处理中断请求。如果考虑实时处理的话，则需要考虑这点。\n  缺点 # 微内核的缺点就是程序之间、程序和某些系统服务之间的通信都需要通过IPC来完成，如果IPC性能差则会导致整体性能差，所以有很多研究如何提高IPC性能的研究。L4Ka的研究人员可以证明，能够将IPC的开销从100ms降低到5ms及以下。\nsee: https://www.youtube.com/watch?v=wCoLTnHUwEY.\nL4Ka的设计 # L4表示第二代微内核，它吸收了第一代微内核设计上的一些经验教训，第一代微内核中Mach是最有名的实现之一。Mach和当时的其他微内核实现类似，没有自底向上地思考到底哪些功能应该在内核中实现，哪些不应该在内核中实现。其实它们看上去更像是拿到一个宏内核，然后再尝试将一些内核中的系统服务搞到用户层去。\nL4考虑了这些问题，比如哪些服务在用户态运行并且不损失安全性和功能。比如L4内核甚至都没必要引入threads或scheduler的概念，只提供实现进程抢占的系统调用就可以（尽管实际情况是L4支持用户级线程）。微内核就是这样，提供最基础的功能，在不同场景中用户可以执行特定的策略来实现更加复杂的功能。\n看L4Ka的详细设计之前，先来了解几个概念。\nL4Ka基本概念 #   threads：线程是最基本的调度实体，只有线程可以被调度。线程之间的同学是通过IPC来完成的，每个线程都有一个寄存器集合（IP、SP、user-visible registers、processor table）、一个关联的task、进程地址空间、pagefault handler（页式管理器，通过IPC接收pagefault请求）、exception handler、preempters和一些其他的调度参数（优先级、时间片等）。\n  tasks：task提供了进程执行需要的环境，它包括了一个虚地址空间、通信端口，一个task至少包括了一个thread，最新的L4实现不限制线程数量。task中创建的所有线程（除了主线程）创建后都需要显示启动，通过系统调用lthread_ex_regs()来启动。一个clan可以包括一个或多个tasks，其中只有一个是chief task，一个task创建另一个task，前者成为后者的chief task。task只可以被chief task kill掉，或者因为chief task被kill掉而间接被kill掉。\n  ps：这里clan、task、chief task的关系，可以联系下Linux下的会话session、会话首进程、进程组、组长进程、父进程之类的来理解。",content:"L4简介 # L4是在L3基础上开发的，改进了IO和IPC等，L4致力于打造一个通用的微内核，以便允许在其基础上进一步定制化来满足场景需求，L4衍生了不少微内核实现。\n现在也有些工作组致力于将Linux在L4上运行起来（L4Linux），将Windows在L4上运行起来（L4Windows），著名的GNU Hurd已经从老的Mach微内核迁移到了L4微内核。\n内核划分依据 # 微内核相比于宏内核，主要是微内核提供的核心更小，区别二者的依据并非源码多少，而是内核中提供功能的多寡。GNU Hurd中有提供宏内核、微内核、混合内核的对比示意图，点击查看。注意，宏内核有时记作monolithic kernel，也记作macro kernel。\nps：通常微内核源码会比宏内核少很多，如L4::Pistachio/ia32只有1w+左右的代码，但是Linux有几百万行。\n微内核通常将内核功能限定在下面几个方面：\n 进程管理； 虚拟内存管理； 进程通信、同步机制；  其他宏内核中常见的文件系统、设备驱动、网络功能在微内核中都是在用户态实现，这些功能可能在single-server中全部实现，也可能在multi-server中实现，进程通过内核IPC机制与server之间进行通信来。\n因为微内核中用户程序请求一些用户态的server（如文件系统、网络等服务）都需要借助IPC来完成，IPC用的非常多，改进其性能就显得尤为重要。早期的微内核实现IPC性能比较差，L4及以后的微内核设计都将提升IPC性能作为一个重要方向，L4中已经做的不错了，一起来了解下是如何实现的。\n微内核优缺点 # 优点 #   robustness：微内核中将很多功能在用户态实现，比如以multi-server的方式实现，假如文件系统服务出故障了，直接重启该服务即可，无需重启整个内核。而且这些服务是在用户态运行的，无权访问核心态数据，对整个内核无破坏性。微内核体积小也更方便维护、调试、定位、修复。\n  security：安全是系统很重要的方面，root用户可以访问一切资源，宏内核中root的权限、可支配范围相当大，root权限被滥用会导致严重问题，如Linux 2.4以前版本ptrace可以加载任意模块包括恶意模块。微内核中这样对权限收的更紧，没那么多系统调用，自然获得root权限的入口更少，更容易约束。\n  memory usage：内核的代码、数据需要常驻内存，宏内核中即便某些部分不常用到也不能够换出到交换区，会浪费内存空间，也影响用户程序执行效率。在微内核中，微内核本身体积小，宏内核中的一些核心服务被放到用户态中实现了，使用不频繁的内存区可以换出到交换区。\n  performance：当想在微内核核心态执行操作时，通常要关闭中断，以避免一些重要的处理过程被中断，这么做顶多会导致当前的一些程序、服务没有处理中断请求。如果考虑实时处理的话，则需要考虑这点。\n  缺点 # 微内核的缺点就是程序之间、程序和某些系统服务之间的通信都需要通过IPC来完成，如果IPC性能差则会导致整体性能差，所以有很多研究如何提高IPC性能的研究。L4Ka的研究人员可以证明，能够将IPC的开销从100ms降低到5ms及以下。\nsee: https://www.youtube.com/watch?v=wCoLTnHUwEY.\nL4Ka的设计 # L4表示第二代微内核，它吸收了第一代微内核设计上的一些经验教训，第一代微内核中Mach是最有名的实现之一。Mach和当时的其他微内核实现类似，没有自底向上地思考到底哪些功能应该在内核中实现，哪些不应该在内核中实现。其实它们看上去更像是拿到一个宏内核，然后再尝试将一些内核中的系统服务搞到用户层去。\nL4考虑了这些问题，比如哪些服务在用户态运行并且不损失安全性和功能。比如L4内核甚至都没必要引入threads或scheduler的概念，只提供实现进程抢占的系统调用就可以（尽管实际情况是L4支持用户级线程）。微内核就是这样，提供最基础的功能，在不同场景中用户可以执行特定的策略来实现更加复杂的功能。\n看L4Ka的详细设计之前，先来了解几个概念。\nL4Ka基本概念 #   threads：线程是最基本的调度实体，只有线程可以被调度。线程之间的同学是通过IPC来完成的，每个线程都有一个寄存器集合（IP、SP、user-visible registers、processor table）、一个关联的task、进程地址空间、pagefault handler（页式管理器，通过IPC接收pagefault请求）、exception handler、preempters和一些其他的调度参数（优先级、时间片等）。\n  tasks：task提供了进程执行需要的环境，它包括了一个虚地址空间、通信端口，一个task至少包括了一个thread，最新的L4实现不限制线程数量。task中创建的所有线程（除了主线程）创建后都需要显示启动，通过系统调用lthread_ex_regs()来启动。一个clan可以包括一个或多个tasks，其中只有一个是chief task，一个task创建另一个task，前者成为后者的chief task。task只可以被chief task kill掉，或者因为chief task被kill掉而间接被kill掉。\n  ps：这里clan、task、chief task的关系，可以联系下Linux下的会话session、会话首进程、进程组、组长进程、父进程之类的来理解。\n flexpages and Virtual Address Space：flexpages指的是flexible large memory pages，L4通过这些内存来访问主存和设备IO内存。进程虚地址空间也是由flexpages构成的，提供了两个系统调用来管理flexpages：grant、map、flush。grant将内存页从一个user交给另一个user，前者失去访问权限；map将内存页共享给另一个task，二者均可以访问；如果一个内存页已经映射给其他用户使用了，flush将清空对应地址空间。  IO实现 # L4并没有在内核中实现IO，而是将其放到了内核外的用户层去实现。内核只是接受IO相关的中断请求（IPC请求的形式），然后将其转发给对应的设备驱动来完成处理。访问外设IO都是以这种方式进行的。\nIPC实现 # 假如task A的线程发送给task B中的线程一个消息M，需要经历这么几步：\n A: load B的id A: load data of M A: call kernel kernel: read IPC request，load B的id kernel：switch rsp to B\u0026rsquo;s rsp kernel：switch VMA to B\u0026rsquo;s VMA kernel: load A的id并设置 kernel：return to userspace（B\u0026rsquo;s VMA) B: receive A发送的M（来自kernel load A的id并设置这步）  ps：这里的设计实现see：https://www.youtube.com/watch?v=mRr1lCJse_I。据说现在宏内核之所以还能活的好好的，主要是之前的微内核IPC性能实在太差。\n如果是发送小消息，拷贝数据到用户态深圳可以用寄存器来搞定，速度快；如果是发送大消息，则需要减少这里的两次拷贝到一次拷贝，怎么搞呢？让B先设置一个共享内存区，然后A将M写入后call kernel，内核直接切换到B，从共享内存区中recieve数据。\nLinux中的IPC涉及很多操作：数据copy、syscall、ctxt switch、blocking、waking，但是微内核L4设计中可以去掉scheduler导致的blocking、waking开销，数据拷贝也可以分为寄存区、共享内存区方式来减少往内核缓冲区的一次拷贝，系统调用中做的工作也简单，整体可以去掉不少开销。\n本分析中测试给出的数据（不确定一次通信传输了多少数据）：\n Linux IPC开销~4500 cycles，约2微秒 L4 IPC开销~900 cycles，约0.33微秒  L4 IPC性能大致是Linux的5倍，之前有个L4 fast inter-process communication的分享提到L4是L3 IPC性能的20倍。\n微内核IPC设计及优化，不止上面这点，详细地可以参考：GW AdvOS: Microkernel IPC Design and Optimizationm。\n安全性实现 # L4安全性机制是基于secure domains来实现的，即tasks、clans、chiefs。之前有提到过L4中进程通信不是基于channel的而是基于IPC请求的。如果是同一个clans中的task通信，那么直接用普通的IPC通信即可，但是如果是不同clans中的task通信，IPC消息必须转到发送方的clans的chief task处理后（chief可以对消息做些操作），才能发送给请求方所在clans的chief task，然后chief task转发给目标task。\n如果是跨越机器的通信，可以把IPC换成协议TCP/IP。\nps: 至于为什么不用channels来通信的方式，简单提一下，channels通信势必要引入chan sender、receiver，sender、receiver要根据chan状态进行同步，还要考虑阻塞、唤醒问题，也不得不考虑scheduler的问题，这里的开销就上来了，会导致IPC性能很差。前面也提过了，微内核IPC设计中优化掉了部分操作来减少开销。\n总结 # 本文介绍了微内核、宏内核的划分方法，介绍了L4的一些背景，以及L4中IO、IPC、安全性的实现方法。\n微内核相对于宏内核来说也具有一定的优势，并且第一代微内核IPC性能差的问题已经得到了明显改善。在如今万物互联的趋势下，微内核对资源占用小的优势应该也更适合资源有限的IoT设备。现在华为也在大力推动自己鸿蒙微内核liteos_a的开源协同，微内核将来还是有很大的市场空间的。\n本文就算是，我迈出了认真学习微内核设计、开发的第一步吧。\n参考内容 #  L4 and Fast Interprocess Communication, https://www.youtube.com/watch?v=mRr1lCJse_I GW AdvOS: Microkernel IPC Design and Optimizationm, https://www.youtube.com/watch?v=wCoLTnHUwEY  "}),a.add({id:264,href:"/blog/2021-06-15-go-map%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0%E5%8F%8A%E5%BA%94%E7%94%A8%E9%80%89%E5%9E%8B/",title:"go map设计实现及应用选型",description:"map大致实现 # buckets \u0026amp; overflow # 本文介绍了map的内部数据结构，每个桶8个kvpairs，超过了可以用溢出桶，但是溢出桶会降低map性能，所以会创建新的bucket将数据迁到新bucket里面。\nhash \u0026amp; top hash table # 一个kvpairs存储在哪个bucket里面呢，首先根据key计算hash，然后对buckets数量取余，再放到对应桶里面，如果有空位置就放入，没有就需要走前面提到的溢出桶的逻辑。\n根据key计算出的hash除了计算key分布在哪个桶，还有其他用途，每个桶里都有一个top hash构成的数组，是为了map访问时加快查询key所在的数组索引的，通过减少比较key的耗时来加速访问。\nmapaccess_faststr, mapaccess_fast64\u0026hellip;访问map中元素时，根据key类型不同编译器插入不同的函数调用，函数名后缀表示key的类型，为什么有不同的函数呢？这是为了提高key的hash计算效率和比较效率。\nload factor # 装填因子，是用来控制map装填的元素数量，即元素数量除以桶数量。装填因子过小容易浪费内存空间，过大容易引发更多的碰撞冲突导致性能下降。\ninitialization \u0026amp;\u0026amp; lazy initialization # map提前初始化再赋值，比lazy初始化后再赋值效率高，为什么呢？lazy初始化桶是后面创建的更花时间。但是lazy初始化相比较而言容易节省内存。\nkvpairs padding # map中kvpairs的存储有考虑内存占用方面的优化，key的类型和value的类型可能不同，所以在数据对齐过程中padding会浪费不少内存，所以go map中的keys和values是分开存储的，先存储keys再存储values。\n并发安全检测 # map中的并发读写问题，go提供了如下方式进行检查：\n  data race detection：通过选项-race来检测是否存在data race，关于data race检测的问题，kavya joshi的分享里有介绍；\n  concurrent map writes：map对应的数据结构hmap中有个字段flags来记录当前的map操作，比如当前执行m[1]=1，是一个kv的赋值，对应的函数是mapassign_fast64，如果执行的是delete(m, 1)，对应的函数是mapdelete_fast64，这里的map修改操作对应的函数内部会将hmap.flags^=hashWriting，如果已经有一个写操作在执行，后面又有一个写操作执行，后面的写操作就有很大概率检测到flags的hashWriting位被设置了，此时就会抛出错误“concurrent map writes”错误；\n  关于map为什么不直接提供并发安全的版本，原因也简单。并发安全的版本是有同步开销的，但是很多时候并不需要并发安全的版本，如果默认实现是并发安全的，性能上就要大打折扣了。不考虑并发安全问题的话，map比sync.Map要快7~10倍。\n并发安全实现 # sync.Map是并发安全的实现，它对某些场景下的并发读写做了性能方面的优化：\n \u0026ldquo;The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, (2) when multiple goroutines read, write and overwrite entries for disjoint sets of keys.",content:"map大致实现 # buckets \u0026amp; overflow # 本文介绍了map的内部数据结构，每个桶8个kvpairs，超过了可以用溢出桶，但是溢出桶会降低map性能，所以会创建新的bucket将数据迁到新bucket里面。\nhash \u0026amp; top hash table # 一个kvpairs存储在哪个bucket里面呢，首先根据key计算hash，然后对buckets数量取余，再放到对应桶里面，如果有空位置就放入，没有就需要走前面提到的溢出桶的逻辑。\n根据key计算出的hash除了计算key分布在哪个桶，还有其他用途，每个桶里都有一个top hash构成的数组，是为了map访问时加快查询key所在的数组索引的，通过减少比较key的耗时来加速访问。\nmapaccess_faststr, mapaccess_fast64\u0026hellip;访问map中元素时，根据key类型不同编译器插入不同的函数调用，函数名后缀表示key的类型，为什么有不同的函数呢？这是为了提高key的hash计算效率和比较效率。\nload factor # 装填因子，是用来控制map装填的元素数量，即元素数量除以桶数量。装填因子过小容易浪费内存空间，过大容易引发更多的碰撞冲突导致性能下降。\ninitialization \u0026amp;\u0026amp; lazy initialization # map提前初始化再赋值，比lazy初始化后再赋值效率高，为什么呢？lazy初始化桶是后面创建的更花时间。但是lazy初始化相比较而言容易节省内存。\nkvpairs padding # map中kvpairs的存储有考虑内存占用方面的优化，key的类型和value的类型可能不同，所以在数据对齐过程中padding会浪费不少内存，所以go map中的keys和values是分开存储的，先存储keys再存储values。\n并发安全检测 # map中的并发读写问题，go提供了如下方式进行检查：\n  data race detection：通过选项-race来检测是否存在data race，关于data race检测的问题，kavya joshi的分享里有介绍；\n  concurrent map writes：map对应的数据结构hmap中有个字段flags来记录当前的map操作，比如当前执行m[1]=1，是一个kv的赋值，对应的函数是mapassign_fast64，如果执行的是delete(m, 1)，对应的函数是mapdelete_fast64，这里的map修改操作对应的函数内部会将hmap.flags^=hashWriting，如果已经有一个写操作在执行，后面又有一个写操作执行，后面的写操作就有很大概率检测到flags的hashWriting位被设置了，此时就会抛出错误“concurrent map writes”错误；\n  关于map为什么不直接提供并发安全的版本，原因也简单。并发安全的版本是有同步开销的，但是很多时候并不需要并发安全的版本，如果默认实现是并发安全的，性能上就要大打折扣了。不考虑并发安全问题的话，map比sync.Map要快7~10倍。\n并发安全实现 # sync.Map是并发安全的实现，它对某些场景下的并发读写做了性能方面的优化：\n \u0026ldquo;The Map type is optimized for two common use cases: (1) when the entry for a given key is only ever written once but read many times, as in caches that only grow, (2) when multiple goroutines read, write and overwrite entries for disjoint sets of keys. In these two cases, use of a Map may significantly reduce lock contention compared to a Go map paired with a separate Mutex or RWMutex.\u0026rdquo;\n 意思就是说，sync.Map对于像缓存（caches）这种写一次（或次数很少）但是读取次数多的场景就很适用，或者存在多个goroutines并发读写，但是读写的keys集合是不相交的。\n第三方实现：ShardedMap # sync.Map对于需要频繁执行删除的场景、更广泛的写场景，没有对其进行足够的优化，这两个场景可以参考shardedmap实现。\nBenchmark及选型 # 对map、sync.Map、concurrent_map（shardedmap）进行了benchmark，结果如下：\nBenchmarkDeleteEmptyMap-8 20000000 86.9 ns/op BenchmarkDeleteEmptySyncMap-8 300000000 5.16 ns/op BenchmarkDeleteEmptyCMap-8 50000000 34.8 ns/op BenchmarkDeleteMap-8 10000000 131 ns/op BenchmarkDeleteSyncMap-8 10000000 135 ns/op BenchmarkDeleteCMap-8 30000000 37.0 ns/op BenchmarkLoadEmptyMap-8 20000000 87.9 ns/op BenchmarkLoadEmptySyncMap-8 300000000 5.03 ns/op BenchmarkLoadEmptyCMap-8 100000000 17.1 ns/op BenchmarkLoadMap-8 20000000 111 ns/op BenchmarkLoadSyncMap-8 100000000 12.8 ns/op BenchmarkLoadCMap-8 100000000 22.5 ns/op BenchmarkSetMap-8 10000000 187 ns/op BenchmarkSetSyncMap-8 5000000 396 ns/op BenchmarkSetCMap-8 20000000 84.9 ns/op  benchmark结果表明：\n map+rwmutex这种方式，锁粒度比加大，增删该查操作耗时相对来说都是比较明显的； sync.Map这种方式，写少读多的情况是非常合适的，效率比较明显，优于map、concurrent_map； concurrent_map，考虑了并发写比较频繁的情况，特别是删除，多shard执行删除操作时效率非常明显；  举个应用选型的例子：连接池明明显属于读多写少的场景，建议用sync.Map代替（key为ip:port，value为connection），后面transport如果要实现双工模式的时候，需要维护req.seqno\\req的映射关系，增删频繁，可以考虑用concurrent_map（key为req.seqno，value为req）。\n参考内容 #  https://medium.com/a-journey-with-go/go-map-design-by-example-part-i-3f78a064a352?source=\u0026mdash;\u0026mdash;\u0026mdash;45\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; https://medium.com/a-journey-with-go/go-map-design-by-code-part-ii-50d111557c08 https://medium.com/a-journey-with-go/go-concurrency-access-with-maps-part-iii-8c0a0e4eb27e https://github.com/orcaman/concurrent-map/blob/master/concurrent_map.go https://golangexample.com/a-simple-and-efficient-thread-safe-sharded-hashmap-for-go/  "}),a.add({id:265,href:"/tags/map/",title:"map",description:"",content:""}),a.add({id:266,href:"/tags/shardedmap/",title:"ShardedMap",description:"",content:""}),a.add({id:267,href:"/tags/sync.map/",title:"sync.Map",description:"",content:""}),a.add({id:268,href:"/tags/runtime/",title:"runtime",description:"",content:""}),a.add({id:269,href:"/tags/syscall/",title:"syscall",description:"",content:""}),a.add({id:270,href:"/blog/2021-06-06-how-go-handles-syscall/",title:"syscall：how does go runtime handles syscall",description:"1 How go runtime handle syscall ? # 最近遇到个线上服务频繁陷入系统调用导致go运行时创建了大量线程，影响到了服务质量，定位、解决问题之后，希望能进一步探究go运行时处理系统调用的过程，以便加深理解。参考了不少网友的分享，特别是知乎Golang Inernal专栏，结合个人的学习理解在此整理记录一下，与大家分享。\n1.1 前言 # 在开始结合源码进行分析之前，先做下简单的介绍，方便先从整体上把握go对系统调用的处理过程，然后从第二部分开始，再结合源码介绍具体的细节。\n系统调用分为阻塞系统调用、非阻塞系统调用，go里面对这些系统调用有归类整理，详见源文件：/src/syscall/syscall_linux_amd64.go。\n如下图所示，sys开头的表示的是阻塞系统调用，会调用Syscall，以sysnb开头的是非阻塞系统调用，会调用RawSyscall，关于Syscall和RawSyscall的区别下面整理。阻塞型的系统调用本身会阻塞线程，为了避免线程阻塞导致协程不可调度，golang运行时要感知这样的系统调用并做特殊处理，非阻塞的系统调用直接调即可，不需要golang运行时参与。 Syscall定义在asm_linux_amd64.s里面，代码中有runtime.entersyscall(SB)和runtime.exitsyscall(SB)函数调用，这个是与golang运行时进行交互的，用于通知golang运行时我即将发起或者退出一个系统调用。\n对于会导致阻塞的系统调用，都要通过Syscall来调用来通知golang运行时，以便golang运行时做处理，如创建新的物理线程调度器其它的goroutine，避免整个进程无线程可调度而最终被sysmon杀死进程。 对于某些非阻塞的系统调用，就不必再与golang运行时交互了，直接调用就可以，这样可以减少两次与golang运行时交互的函数调用开销，这里就掉的是RawSyscall： 网络io操作本来也是阻塞的，但是因为socket fd会被设置为non-blocking，系统调用虽然还是阻塞的系统调用，但是已经不会阻塞调用线程了，所以也无所谓了。\n有个脚本mksyscall.pl根据syscall_linux_amd64.go里面定义的系通调用列表，就是第一张图那些带注释的部分，这个pl脚本会负责生成与之相关的系统调用函数，生成在syscall/zsyscall_linux_amd64.go里面。可以找几个有代表性的来看下生成的系统调用函数：\n比如sendfile是阻塞的系统调用： 比如settimeofday是非阻塞的系统调用： epoll相关的epollwait也是阻塞的，但是网络socket fd在go里面都统一设置为了nonblocking fd处理了，因此并不会阻塞。 1.2 开始分析源码 # 在讲述系统调用发生的协程调度之前，让我们看看go是如何进入系统调用的，理解了这个让我们不会对后面所说的一些东西感到很陌生。\ngolang对操作系统的系统调用作了封装，提供了syscall这样的库让我们执行系统调用。例如，Read系统调用实现如下：\nfunc Read(fd int, p []byte) (n int, err error) { n, err = read(fd, p) if raceenabled { if n \u0026gt; 0 { ...... } ...... } return } // 最终封装了Syscall func read(fd int, p []byte) (n int, err error) { var _p0 unsafe.",content:"1 How go runtime handle syscall ? # 最近遇到个线上服务频繁陷入系统调用导致go运行时创建了大量线程，影响到了服务质量，定位、解决问题之后，希望能进一步探究go运行时处理系统调用的过程，以便加深理解。参考了不少网友的分享，特别是知乎Golang Inernal专栏，结合个人的学习理解在此整理记录一下，与大家分享。\n1.1 前言 # 在开始结合源码进行分析之前，先做下简单的介绍，方便先从整体上把握go对系统调用的处理过程，然后从第二部分开始，再结合源码介绍具体的细节。\n系统调用分为阻塞系统调用、非阻塞系统调用，go里面对这些系统调用有归类整理，详见源文件：/src/syscall/syscall_linux_amd64.go。\n如下图所示，sys开头的表示的是阻塞系统调用，会调用Syscall，以sysnb开头的是非阻塞系统调用，会调用RawSyscall，关于Syscall和RawSyscall的区别下面整理。阻塞型的系统调用本身会阻塞线程，为了避免线程阻塞导致协程不可调度，golang运行时要感知这样的系统调用并做特殊处理，非阻塞的系统调用直接调即可，不需要golang运行时参与。 Syscall定义在asm_linux_amd64.s里面，代码中有runtime.entersyscall(SB)和runtime.exitsyscall(SB)函数调用，这个是与golang运行时进行交互的，用于通知golang运行时我即将发起或者退出一个系统调用。\n对于会导致阻塞的系统调用，都要通过Syscall来调用来通知golang运行时，以便golang运行时做处理，如创建新的物理线程调度器其它的goroutine，避免整个进程无线程可调度而最终被sysmon杀死进程。 对于某些非阻塞的系统调用，就不必再与golang运行时交互了，直接调用就可以，这样可以减少两次与golang运行时交互的函数调用开销，这里就掉的是RawSyscall： 网络io操作本来也是阻塞的，但是因为socket fd会被设置为non-blocking，系统调用虽然还是阻塞的系统调用，但是已经不会阻塞调用线程了，所以也无所谓了。\n有个脚本mksyscall.pl根据syscall_linux_amd64.go里面定义的系通调用列表，就是第一张图那些带注释的部分，这个pl脚本会负责生成与之相关的系统调用函数，生成在syscall/zsyscall_linux_amd64.go里面。可以找几个有代表性的来看下生成的系统调用函数：\n比如sendfile是阻塞的系统调用： 比如settimeofday是非阻塞的系统调用： epoll相关的epollwait也是阻塞的，但是网络socket fd在go里面都统一设置为了nonblocking fd处理了，因此并不会阻塞。 1.2 开始分析源码 # 在讲述系统调用发生的协程调度之前，让我们看看go是如何进入系统调用的，理解了这个让我们不会对后面所说的一些东西感到很陌生。\ngolang对操作系统的系统调用作了封装，提供了syscall这样的库让我们执行系统调用。例如，Read系统调用实现如下：\nfunc Read(fd int, p []byte) (n int, err error) { n, err = read(fd, p) if raceenabled { if n \u0026gt; 0 { ...... } ...... } return } // 最终封装了Syscall func read(fd int, p []byte) (n int, err error) { var _p0 unsafe.Pointer if len(p) \u0026gt; 0 { _p0 = unsafe.Pointer(\u0026amp;p[0]) } else { _p0 = unsafe.Pointer(\u0026amp;_zero) } r0, _, e1 := Syscall(SYS_READ, uintptr(fd), uintptr(_p0), uintptr(len(p))) n = int(r0) if e1 != 0 { err = e1 } return } // 我们只关心进入系统调用时调用的runtime·entersyscall // 和退出时调用的runtime·exitsyscall TEXT ·Syscall(SB),NOSPLIT,$0-56 CALL runtime·entersyscall(SB) MOVQ 16(SP), DI MOVQ 24(SP), SI MOVQ 32(SP), DX MOVQ $0, R10 s MOVQ $0, R8 MOVQ $0, R9 MOVQ 8(SP), AX // syscall entry SYSCALL CMPQ AX, $0xfffffffffffff001 JLS ok MOVQ $-1, 40(SP) // r1 MOVQ $0, 48(SP) // r2 NEGQ AX MOVQ AX, 56(SP) // errno CALL runtime·exitsyscall(SB) RET  我们并不关心系统调用到底怎么实现。我们只关心系统调用过程与调度器相关内容，因为Golang自己接管系统调用，调度器便可以在进出系统调用时做一些你所不明白的优化，这里我要带你弄清楚调度器怎么做优化的。\n1.3 进入系统调用前 # 我们前面说过，系统调用是一个相对耗时的过程。一旦P中的某个G进入系统调用状态而阻塞了该P内的其他协程。此时调度器必须得做点什么吧，这就是调度器在进入系统调用前call runtime·entersyscall目的所在。\n 关于调度粘性（亲和性）问题，这里提一嘴：\n下文描述的时候有点偏故事性，关于GMP三者之间的关系，请务必注意goroutine、thread调度亲和性问题，这样就比较容易理解为什么G想再原来的M上执行，而M又想在原来的P上执行。\np上有mcache、gFree，m上有tls，m运行g申请小于32K的内存是从p.mcache中分配，维持g、m、p之间的关系有助于复用之前p上建立的mcache，也有助于m创建新的g时复用p上之前维护的空闲g列表。\n当然可能还有一些其他的原因，这里暂时先不展开了 see：https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/runtime2.go#L613。\n OK，我们继续讲运行时对系统调用的处理。\nvoid ·entersyscall(int32 dummy) { runtime·reentersyscall((uintptr)runtime·getcallerpc(\u0026amp;dummy), runtime·getcallersp(\u0026amp;dummy)); } void runtime·reentersyscall(uintptr pc, uintptr sp) { void (*fn)(void); // 为什么g-\u0026gt;m-\u0026gt;locks++? g-\u0026gt;m-\u0026gt;locks++; g-\u0026gt;stackguard0 = StackPreempt; g-\u0026gt;throwsplit = 1; // Leave SP around for GC and traceback. // save()到底在save什么？ save(pc, sp); g-\u0026gt;syscallsp = sp; g-\u0026gt;syscallpc = pc; runtime·casgstatus(g, Grunning, Gsyscall); // 这些堆栈之间到底是什么关系？ if(g-\u0026gt;syscallsp \u0026lt; g-\u0026gt;stack.lo || g-\u0026gt;stack.hi \u0026lt; g-\u0026gt;syscallsp) { fn = entersyscall_bad; runtime·onM(\u0026amp;fn); } // 这个还不知道是啥意思 if(runtime·atomicload(\u0026amp;runtime·sched.sysmonwait)) { fn = entersyscall_sysmon; runtime·onM(\u0026amp;fn); save(pc, sp); } // 这里很关键：P的M已经陷入系统调用，于是P忍痛放弃该M // 但是请注意：此时M还指向P，在M从系统调用返回后还能找到P g-\u0026gt;m-\u0026gt;mcache = nil; g-\u0026gt;m-\u0026gt;p-\u0026gt;m = nil; // P的状态变为Psyscall runtime·atomicstore(\u0026amp;g-\u0026gt;m-\u0026gt;p-\u0026gt;status, Psyscall); if(runtime·sched.gcwaiting) { fn = entersyscall_gcwait; runtime·onM(\u0026amp;fn); save(pc, sp); } g-\u0026gt;stackguard0 = StackPreempt; g-\u0026gt;m-\u0026gt;locks--; }  上面与调度器相关的内容其实就是将M从P剥离出去，告诉调度器，我已经放弃M了，我不能饿着我的孩子们（G）。但是M内心还是记着P的，在系统调用返回后，M还尽量找回原来的P，至于P是不是另结新欢就得看情况了。\n注意这时候P放弃了前妻M，但是还没有给孩子们找后妈（M），只是将P的状态标记为PSyscall，那么什么时候以及怎么样给孩子们找后妈呢？我们在后面详细阐述。\n1.4 从系统调用返回后 # 从系统调用返回后，也要告诉调度器，因为需要调度器做一些事情，根据前面系统调用的实现，具体实现是：\nvoid ·exitsyscall(int32 dummy) { void (*fn)(G*); // 这个g到底是什么？ g-\u0026gt;m-\u0026gt;locks++; // see comment in entersyscall if(runtime·getcallersp(\u0026amp;dummy) \u0026gt; g-\u0026gt;syscallsp) runtime·throw(\u0026quot;exitsyscall: syscall frame is no longer valid\u0026quot;); g-\u0026gt;waitsince = 0; // 判断能否快速找到归属 if(exitsyscallfast()) { g-\u0026gt;m-\u0026gt;p-\u0026gt;syscalltick++; // g的状态从syscall变成running，继续欢快地跑着 runtime·casgstatus(g, Gsyscall, Grunning); g-\u0026gt;syscallsp = (uintptr)nil; g-\u0026gt;m-\u0026gt;locks--; if(g-\u0026gt;preempt) { g-\u0026gt;stackguard0 = StackPreempt; } else { g-\u0026gt;stackguard0 = g-\u0026gt;stack.lo + StackGuard; } g-\u0026gt;throwsplit = 0; return; } g-\u0026gt;m-\u0026gt;locks--; // Call the scheduler. // 如果M回来发现P已经有别人服务了，那只能将自己挂起 // 等着服务别人。 fn = exitsyscall0; runtime·mcall(\u0026amp;fn); ...... } static bool exitsyscallfast(void) { void (*fn)(void); if(runtime·sched.stopwait) { g-\u0026gt;m-\u0026gt;p = nil; return false; } // 如果之前附属的P尚未被其他M,尝试绑定该P if(g-\u0026gt;m-\u0026gt;p \u0026amp;\u0026amp; g-\u0026gt;m-\u0026gt;p-\u0026gt;status == Psyscall \u0026amp;\u0026amp; runtime·cas(\u0026amp;g-\u0026gt;m-\u0026gt;p-\u0026gt;status, Psyscall, Prunning)) { g-\u0026gt;m-\u0026gt;mcache = g-\u0026gt;m-\u0026gt;p-\u0026gt;mcache; g-\u0026gt;m-\u0026gt;p-\u0026gt;m = g-\u0026gt;m; return true; } // Try to get any other idle P. // 否则从空闲P列表中随便捞一个出来 g-\u0026gt;m-\u0026gt;p = nil; if(runtime·sched.pidle) { fn = exitsyscallfast_pidle; runtime·onM(\u0026amp;fn); if(g-\u0026gt;m-\u0026gt;scalararg[0]) { g-\u0026gt;m-\u0026gt;scalararg[0] = 0; return true; } } return false; }  G从系统调用返回的过程，其实就是失足妇女找男人的逻辑：\n 首先看看能否回到当初爱人(P)的怀抱：找到当初被我抛弃的男人，我这里还存着它的名片(m-\u0026gt;p)，家庭住址什么的我都还知道； 如果爱人受不了寂寞和抚养孩子的压力已经变节（P的状态不再是Psyscall），那我就随便找个单身待解救男人从了也行； 如果上面的1、2都找不到，那也没办法，男人都死绝了，老娘只好另想他法。  以上过程1和2其实就是exitsyscallfast()的主要流程，用怀孕了的失足妇女找男人再合适不过。 一个女人由于年轻不懂事失足，抛家弃子（家是P，子是P的G）。当浪子回头后，意欲寻回从前的夫君，只能有两种可能：\n 等了很久已然心灰意冷的夫君在家人的安排下另娶他人； 痴情的夫君已然和嗷嗷待哺的孩子们依然在等待她的归回。  当然第二种的结局比较圆满，这个女人从此死心塌地守着这个家，于是p-\u0026gt;m又回来了，孩子们(g)又可以继续活下去了。 第一种就比较难办了，女人（m）心灰意冷，将产下的儿子（陷入系统调用的g）交于他人（全局g的运行队列）抚养，远走他乡，从此接收命运的安排（参与调度，以后可能服务于别的p）。 对于第二种可能性，只能说女人的命运比较悲惨了：\nstatic void exitsyscall0(G *gp) { P *p; runtime·casgstatus(gp, Gsyscall, Grunnable); dropg(); runtime·lock(\u0026amp;runtime·sched.lock); // 这里M再次尝试为自己找个归宿P p = pidleget(); // 如果没找到P，M讲自己放入全局的运行队列中 // 同时将它的g放置到全局的P queue中进去，自己不管了 if(p == nil) globrunqput(gp); else if(runtime·atomicload(\u0026amp;runtime·sched.sysmonwait)) { runtime·atomicstore(\u0026amp;runtime·sched.sysmonwait, 0); runtime·notewakeup(\u0026amp;runtime·sched.sysmonnote); } runtime·unlock(\u0026amp;runtime·sched.lock); // 如果找到了P，占有P并且开始执行P内的g，永不回头 if(p) { acquirep(p); execute(gp); // Never returns. } if(g-\u0026gt;m-\u0026gt;lockedg) { // Wait until another thread schedules gp and so m again. stoplockedm(); execute(gp); // Never returns. } // 找了一圈还是没找到，释放掉M当前执行环境，M不再做事 // stopm会暂停当前M直到其找到了可运行的P为止 // 找到以后进入schedule，执行P内的g stopm(); // m从stopm()中返回以后，说明该m被绑定至某个P,可以开始 // 继续欢快地跑了,此时就需要调度找到一个g去执行 // 这就是调用schedule的目的所在 schedule(); // Never returns. }  话说到这里，其实这个M当前没有运行的价值了（无法找到p运行它），那么我们就将她挂起，直到被其他人唤醒。 m被挂起调用的函数是stopm()\n// Stops execution of the current m until new work is available. // Returns with acquired P. static void stopm(void) { if(g-\u0026gt;m-\u0026gt;locks) runtime·throw(\u0026quot;stopm holding locks\u0026quot;); if(g-\u0026gt;m-\u0026gt;p) runtime·throw(\u0026quot;stopm holding p\u0026quot;); if(g-\u0026gt;m-\u0026gt;spinning) { g-\u0026gt;m-\u0026gt;spinning = false; runtime·xadd(\u0026amp;runtime·sched.nmspinning, -1); } retry: runtime·lock(\u0026amp;runtime·sched.lock); // 将m插入到空闲m队列中，统一管理 mput(g-\u0026gt;m); runtime·unlock(\u0026amp;runtime·sched.lock); // 在这里被挂起，阻塞在m-\u0026gt;park上，位于lock_futex.go runtime·notesleep(\u0026amp;g-\u0026gt;m-\u0026gt;park); // 从挂起被唤醒后开始执行 runtime·noteclear(\u0026amp;g-\u0026gt;m-\u0026gt;park); if(g-\u0026gt;m-\u0026gt;helpgc) { runtime·gchelper(); g-\u0026gt;m-\u0026gt;helpgc = 0; g-\u0026gt;m-\u0026gt;mcache = nil; goto retry; } // m-\u0026gt;nextp是什么？ acquirep(g-\u0026gt;m-\u0026gt;nextp); g-\u0026gt;m-\u0026gt;nextp = nil; }  那么说到这里，其实很多事情都一目了然，当一个M从系统调用返回后，通过各种方式想找到可以托付的P(找前夫—\u0026gt;找闲汉)，求之不得最终只能将自己挂起，等待下次系统中有空闲的P的时候被唤醒。\n1.5 sysmon # 前面我们重点讲了一个m是如何陷入系统调用和如何返回的心酸之路。我们忽略了p的感情，因为他才是真正的受害者，它被剥夺了m，从此无人理会它嗷嗷待哺的孩子们(g)，并且状态还被变成了Psyscall，相当于贴上了屌丝标签，别无他法，只能等待陷入系统调用的m返回，再续前缘。 当然，这样做是不合理的，因为如果m进入系统调用后乐不思蜀，那P的孩子们都得饿死，这在现实社会中可以发生，但在数字世界里是决不允许的。 OK，组织绝对不会忽略这种情况的，于是，保姆（管家）出现了，它就是sysmon线程，这是一个特殊的m，专门监控系统状态。 sysmon周期性醒来，并且遍历所有的p，如果发现有Psyscall状态的p并且已经处于该状态超过一定时间了，那就不管那个负心的前妻，再次p安排一个m，这样p内的任务又可以得到处理了。\nfunc sysmon() { ...... retake(now); ...... } // 我们只摘取了sysmon中与P处理相关的代码分析： static uint32 retake(int64 now) { uint32 i, s, n; int64 t; P *p; Pdesc *pd; n = 0; // 遍历所有的P，根据其状态作相应处理，我们只关注Psyscall for(i = 0; i \u0026lt; runtime·gomaxprocs; i++) { p = runtime·allp[i]; if(p==nil) continue; pd = \u0026amp;pdesc[i]; s = p-\u0026gt;status; if(s == Psyscall) { t = p-\u0026gt;syscalltick; if(pd-\u0026gt;syscalltick != t) { pd-\u0026gt;syscalltick = t; pd-\u0026gt;syscallwhen = now; continue; } if(p-\u0026gt;runqhead == p-\u0026gt;runqtail \u0026amp;\u0026amp; runtime·atomicload(\u0026amp;runtime·sched.nmspinning) + runtime·atomicload(\u0026amp;runtime·sched.npidle) \u0026gt; 0 \u0026amp;\u0026amp; pd-\u0026gt;syscallwhen + 10*1000*1000 \u0026gt; now) continue; incidlelocked(-1); // 因为需要将P重新安排m，所以状态转化为Pidle if(runtime·cas(\u0026amp;p-\u0026gt;status, s, Pidle)) { n++; handoffp(p); } incidlelocked(1); ...... }  找到了处于Psyscall状态的P后，继续判断它等待的时间是否已经太长，如果是这样，就准备抛弃原来的还陷入syscall的m，调用handoff(p)，开始为p准备新生活。\n我们接下来仔细分析下p是怎么过上新生活的，handoffp无非就是找一个新的m，将m与该p绑定，接下来将由m继续执行该p内的g。\nhandoffp()找到的新的m可能是别人以前的m(私生活好混乱)。由于这里获得的m是处于idle状态，处于wait状态（在stopm()中被sleep的），在这里，handoffp中会通过startm()来唤醒它，一个常见逻辑就是这个p里面还有g要执行那么就直接startm，这里的startm会通过mget获取一个空闲的m（如stopm暂停的m），获取不到就通过newm()创建一个m。\n这里的startm以被唤醒的m为例继续说明，关于新创建的m被唤醒的m继续执行它被阻塞的下一条语句：\nstopm() { ...... // 从挂起被唤醒后开始执行 runtime·noteclear(\u0026amp;g-\u0026gt;m-\u0026gt;park); if(g-\u0026gt;m-\u0026gt;helpgc) { runtime·gchelper(); g-\u0026gt;m-\u0026gt;helpgc = 0; g-\u0026gt;m-\u0026gt;mcache = nil; goto retry; } // 将M和P绑定 acquirep(g-\u0026gt;m-\u0026gt;nextp); g-\u0026gt;m-\u0026gt;nextp = nil; } // 由于m在sleep前的调用路径是exitsyscall0() –\u0026gt; stopm()，从stopm()中返回至exitsyscall0后，执行接下来的语句 func exitsyscall0(gp *g) { _g_ := getg() ...... stopm() // m继续run起来后，执行一次schedule // 找到m-\u0026gt;p里面可运行的g并执行 schedule() // Never returns. } // One round of scheduler: find a runnable goroutine and execute it. // Never returns. func schedule() { _g_ := getg() ...... if gp == nil { gp, inheritTime = runqget(_g_.m.p.ptr()) if gp != nil \u0026amp;\u0026amp; _g_.m.spinning { throw(\u0026quot;schedule: spinning with local work\u0026quot;) } } if gp == nil { gp, inheritTime = findrunnable() resetspinning() } if gp.lockedm != nil { // Hands off own p to the locked m, // then blocks waiting for a new p. startlockedm(gp) goto top } // 执行该gp execute(gp, inheritTime) }  1.6 总结 # 本文介绍了go对系统调用的大致处理过程，感谢知乎网友丁凯在知乎的分享，结合个人理解，略作整理也分享给大家。\n"}),a.add({id:271,href:"/blog/2021-05-25-go%E6%8A%A2%E5%8D%A0%E5%BC%8F%E8%B0%83%E5%BA%A6/",title:"go抢占式调度",description:"SIGURG，在信号处理函数runtime/signal_unix.go:sighandler(\u0026hellip;)函数中又看到对sigPreempt的处理。\nSIGURG实现抢占式调度： 对应这个函数doSigPreempt，检查当前g是不是wantAsyncPreempt，ok的话检查是不是isAsyncSafePoint，ok的话，sigctxt.pushCall(funcPC(asyncPreempt), newpc)，这个函数调整PC并注入一个对asyncPreempt的调用。\nTODO wantAsyncPreempt对应的判断参数是谁去设置的，什么时候设置的？\nTODO isAsyncSafePoint，safepoint的含义？这个函数的注释以及代码中的if-else已经足够结实清楚什么是safepoint了，以及safepoint的意义了。\n看下asyncPreempt的逻辑，该函数是在汇编中实现的，首先保存寄存器的值，然后调用asyncPreempt2执行其他处理。\ng.preemptStop决定是挂起g还是重新调度g：\n 如果被抢占的g的g.preemptStop为true，则执行mcall(preemptPark)挂起该g，g的状态被改为preempted，后面什么时机会重新调度它吧。然后执行schedule调度其他goroutine执行； 如果g.preemptStop为false，则mcall(gopreempt_m)将g从running改为runnable重新调度一次。  大致的抢占式调度逻辑就是这样的。\nps: func mcall(fn func(*g))，mcall switches from the g to the g0 stack and invokes fn(g), where g is the goroutine that made the call.",content:"SIGURG，在信号处理函数runtime/signal_unix.go:sighandler(\u0026hellip;)函数中又看到对sigPreempt的处理。\nSIGURG实现抢占式调度： 对应这个函数doSigPreempt，检查当前g是不是wantAsyncPreempt，ok的话检查是不是isAsyncSafePoint，ok的话，sigctxt.pushCall(funcPC(asyncPreempt), newpc)，这个函数调整PC并注入一个对asyncPreempt的调用。\nTODO wantAsyncPreempt对应的判断参数是谁去设置的，什么时候设置的？\nTODO isAsyncSafePoint，safepoint的含义？这个函数的注释以及代码中的if-else已经足够结实清楚什么是safepoint了，以及safepoint的意义了。\n看下asyncPreempt的逻辑，该函数是在汇编中实现的，首先保存寄存器的值，然后调用asyncPreempt2执行其他处理。\ng.preemptStop决定是挂起g还是重新调度g：\n 如果被抢占的g的g.preemptStop为true，则执行mcall(preemptPark)挂起该g，g的状态被改为preempted，后面什么时机会重新调度它吧。然后执行schedule调度其他goroutine执行； 如果g.preemptStop为false，则mcall(gopreempt_m)将g从running改为runnable重新调度一次。  大致的抢占式调度逻辑就是这样的。\nps: func mcall(fn func(*g))，mcall switches from the g to the g0 stack and invokes fn(g), where g is the goroutine that made the call.\n"}),a.add({id:272,href:"/tags/preemption/",title:"preemption",description:"",content:""}),a.add({id:273,href:"/tags/schedule/",title:"schedule",description:"",content:""}),a.add({id:274,href:"/blog/2021-05-25-go%E7%A8%8B%E5%BA%8F%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86%E8%BF%87%E7%A8%8B/",title:"go程序信号处理过程",description:"go信号处理基础 # go os.signal package对信号处理做了封装，其中信号SIGKILL、SIGSTOP是操作系统规定的不允许捕获的信号，是不受os.signal这个package影响的\ngo中将信号分为两类：同步信号和异步信号。\n  同步信号：指的是go程序运行时程序内部错误触发的一些问题，如SIGBUS、SIGFPE、SIGSEGV，这些信号会被转换成运行时panic信息；\n  异步信号：除了上述提及的信号之外的信号，就是异步信号了。异步信号不是程序内部错误导致的，而是由操作系统或者外部其他程序发送给它的。\n  有哪些异步信号？ #  当程序失去对控制终端的控制时，会收到SIGHUP信号； 在控制终端中输入Ctrl+C时会收到SIGINT信号； 在控制终端中输入Ctrl+\\时会受到SIGQUIT信号；  ps：通常想让程序退出的话，Ctrl+C就可以了，如果想让程序退出同时打印栈转储信息，那就用Ctrl+\\。\n默认的信号处理方式？ # 接收到信号之后，肯定有默认的处理方式，这个在学习linux信号处理时肯定有了解过的，在go程序中可能只是默认处理方式有点不同，这个有需要的时候去了解就可以了。这里不展开了。\n值得一提的是信号SIGPROF，这个信号用于实现runtime.CPUProfile。\n自定义信号处理方式？ # 自定义信号处理方式，在linux signal函数中可以指定信号及对应对应的处理函数，go中类似，它允许通过os.Notify指定一个或多个信号chan，里面可以注册感兴趣的信号，当收到这些信号时，就可以执行用户自定义的信号处理逻辑。\nSIGPIPE信号处理 # 当程序write broken pipe时，会收到SIGPIPE信号，比如写网络连接失败，如果不做处理默认崩溃掉那就完蛋了。go程序中对这个做了优化处理。\nwrite broken pipe的行为与write的file descriptor的fd有关系：\n 如果fd是stdout、stderr，那么程序收到SIGPIPE信号，默认行为是程序会退出； 如果是其他fd，程序收到SIGPIPE信号，默认行为是不采取任何动作，对应的write操作返回一个EPIPE错误；  ps：后者很重要，写网络连接失败是常有的事情，linux c程序如果不显示处理SIGPIPE信号，默认行为将是程序直接crash，go程序对此作了优化，让write返回error而非crash，对于go将构建高性能、稳定健壮的网络程序的初衷来说是有必要的。\ncgo程序信号处理？ # 涉及到cgo就要分几种情况来讨论，这里会有点麻烦了，涉及到信号处理函数的重复注册、信号掩码设置、信号处理函数的栈等问题，在os/signal/doc.go里面有这方面的描述，这里不赘述。\ngo信号处理过程 # 介绍了go程序内部的信号处理过程。GMP调度模型里面，每个M都有一个独立的gsignal goroutine，系统投递信号给进程时实际上是有gsignal goroutine来接受这个信号，然后检查下是否可处理。如果可处理就将其push到一个信号队列中，然后有一个专门的goroutine执行signal.loop，这个函数从上述信号队列中取信号，并转移到用户自定义的chan os.Signal中，再由我们自己写的chan read代码消费，并执行处理。\n对应到源码中主要有几个函数：\n对应到源码中主要有几个函数：\n  os/signal/signal.go：这个函数里面在func init()的时候有启动一个loop函数，这个函数内调用runtime.signal_recv来不停地接收信号，然后检查程序通过os.Notify为哪些chan os.Signal订阅了该信号，就将该信号push到对应的chan中，后面应用程序就可以自行处理了；\n  runtime/sigqueue.go：runtime.sigsend、runtime.signal_recv这两个函数很重要，前者是程序收到系统发送来的信号时将信号写入outgoing sigqueue中，其实就是sig结构体的mask字段，后面signal_recv的时候也是从该mask字段读取，并写入recv字段中，recv中非0的应该就是表示收到了信号（信号编号为索引值）；\n  runtime/signal_unix.go：有个函数sighandler，这个函数负责对不同的信号执行不同的处理，比如抢占式调度SIGURG的处理，比如SIGPROF的处理，比如我们这里讨论的一些异步信号的处理sigsend。在go程序中不管是什么信号，这些信号是在sighandler做不同处理。sighandler虽然名字是信号处理函数，我们也看到了通过setsig将所有信号全部设置sighandler为信号处理函数，但是其实这只是表现。setsig函数内部又做了一个转换，将信号的信号处理函数设置为了sigtramp活着cgosigtramp，这些函数内部又调用sighandler。下面会提到sigtramp的逻辑；\n  runtime/runtime2.",content:"go信号处理基础 # go os.signal package对信号处理做了封装，其中信号SIGKILL、SIGSTOP是操作系统规定的不允许捕获的信号，是不受os.signal这个package影响的\ngo中将信号分为两类：同步信号和异步信号。\n  同步信号：指的是go程序运行时程序内部错误触发的一些问题，如SIGBUS、SIGFPE、SIGSEGV，这些信号会被转换成运行时panic信息；\n  异步信号：除了上述提及的信号之外的信号，就是异步信号了。异步信号不是程序内部错误导致的，而是由操作系统或者外部其他程序发送给它的。\n  有哪些异步信号？ #  当程序失去对控制终端的控制时，会收到SIGHUP信号； 在控制终端中输入Ctrl+C时会收到SIGINT信号； 在控制终端中输入Ctrl+\\时会受到SIGQUIT信号；  ps：通常想让程序退出的话，Ctrl+C就可以了，如果想让程序退出同时打印栈转储信息，那就用Ctrl+\\。\n默认的信号处理方式？ # 接收到信号之后，肯定有默认的处理方式，这个在学习linux信号处理时肯定有了解过的，在go程序中可能只是默认处理方式有点不同，这个有需要的时候去了解就可以了。这里不展开了。\n值得一提的是信号SIGPROF，这个信号用于实现runtime.CPUProfile。\n自定义信号处理方式？ # 自定义信号处理方式，在linux signal函数中可以指定信号及对应对应的处理函数，go中类似，它允许通过os.Notify指定一个或多个信号chan，里面可以注册感兴趣的信号，当收到这些信号时，就可以执行用户自定义的信号处理逻辑。\nSIGPIPE信号处理 # 当程序write broken pipe时，会收到SIGPIPE信号，比如写网络连接失败，如果不做处理默认崩溃掉那就完蛋了。go程序中对这个做了优化处理。\nwrite broken pipe的行为与write的file descriptor的fd有关系：\n 如果fd是stdout、stderr，那么程序收到SIGPIPE信号，默认行为是程序会退出； 如果是其他fd，程序收到SIGPIPE信号，默认行为是不采取任何动作，对应的write操作返回一个EPIPE错误；  ps：后者很重要，写网络连接失败是常有的事情，linux c程序如果不显示处理SIGPIPE信号，默认行为将是程序直接crash，go程序对此作了优化，让write返回error而非crash，对于go将构建高性能、稳定健壮的网络程序的初衷来说是有必要的。\ncgo程序信号处理？ # 涉及到cgo就要分几种情况来讨论，这里会有点麻烦了，涉及到信号处理函数的重复注册、信号掩码设置、信号处理函数的栈等问题，在os/signal/doc.go里面有这方面的描述，这里不赘述。\ngo信号处理过程 # 介绍了go程序内部的信号处理过程。GMP调度模型里面，每个M都有一个独立的gsignal goroutine，系统投递信号给进程时实际上是有gsignal goroutine来接受这个信号，然后检查下是否可处理。如果可处理就将其push到一个信号队列中，然后有一个专门的goroutine执行signal.loop，这个函数从上述信号队列中取信号，并转移到用户自定义的chan os.Signal中，再由我们自己写的chan read代码消费，并执行处理。\n对应到源码中主要有几个函数：\n对应到源码中主要有几个函数：\n  os/signal/signal.go：这个函数里面在func init()的时候有启动一个loop函数，这个函数内调用runtime.signal_recv来不停地接收信号，然后检查程序通过os.Notify为哪些chan os.Signal订阅了该信号，就将该信号push到对应的chan中，后面应用程序就可以自行处理了；\n  runtime/sigqueue.go：runtime.sigsend、runtime.signal_recv这两个函数很重要，前者是程序收到系统发送来的信号时将信号写入outgoing sigqueue中，其实就是sig结构体的mask字段，后面signal_recv的时候也是从该mask字段读取，并写入recv字段中，recv中非0的应该就是表示收到了信号（信号编号为索引值）；\n  runtime/signal_unix.go：有个函数sighandler，这个函数负责对不同的信号执行不同的处理，比如抢占式调度SIGURG的处理，比如SIGPROF的处理，比如我们这里讨论的一些异步信号的处理sigsend。在go程序中不管是什么信号，这些信号是在sighandler做不同处理。sighandler虽然名字是信号处理函数，我们也看到了通过setsig将所有信号全部设置sighandler为信号处理函数，但是其实这只是表现。setsig函数内部又做了一个转换，将信号的信号处理函数设置为了sigtramp活着cgosigtramp，这些函数内部又调用sighandler。下面会提到sigtramp的逻辑；\n  runtime/runtime2.go：这里定义了GMP调度模型中的m，m包含一个成员gsignal，它表示信号处理用的goroutine。os_linux.go中mpreinit会为创建一个goroutine，协程栈被初始化一个32KB大小的信号处理栈，很大这是为了兼容不同操作系统的一些问题，linux要≥2KB，OSX要≥8KB\u0026hellip;\n  sigtramp是注册到操作系统的信号处理函数，当操作系统执行系统调用返回时检查进程有没有信号到达，有并且没有屏蔽信号则执行对应的信号处理函数，这个时候是切到了用户态去执行信号处理函数。在执行信号处理函数的时候比较特殊，go需要为信号处理函数准备一个不同的栈帧，即信号处理栈，这个前面提过了是一个32KB大小的栈，然后将当前m.g设置为gsignal（栈大小为32KB），栈准备好之后，执行前面提过的sighandler执行信号处理，处理完成返回后，再将m.g设置为原来的g恢复正常执行。其实signhandler执行过程中，sigsend发送到outgoing sigqueue，然后signal_recv收信号发送到os.Notify订阅的chan，就完事了，后面就是我们熟悉的chan read并处理逻辑了。\n  算是介绍的比较详细了吧，篇幅、时间原因就不贴源码了，感兴趣的可以对着提及的源码仔细看看、求证一下。\n"}),a.add({id:275,href:"/tags/signal/",title:"signal",description:"",content:""}),a.add({id:276,href:"/tags/goroutine/",title:"goroutine",description:"",content:""}),a.add({id:277,href:"/blog/2021-05-24-how-goroutine-created-and-started/",title:"how goroutine created and started",description:"goroutine创建：runtime.newproc(siz int32, fn *funcval)\n go fn()，传递给fn的参数实际上是紧跟着存在fn压栈后的地址后面，在newproc1的栈帧里面，但是不出现在签名参数列表中，因为这些参数类型、数量不一样，也无法出现在签名参数列表中； newproc1创建g； getg().m.p.ptr()拿到当前p； runqput将当前g放入p的local queue中，如果满则放到global queue中； g等待被调度器调度执行；  大致创建执行goroutine的逻辑是这样的，下面的逻辑都是切到系统栈上去执行的。\n1 newproc1逻辑\n查看源码发现，goroutine初始创建时对函数参数大小是有限制的，如果参数占内存空间很大，比如超过初始栈帧大小2KB，那么goroutine创建会失败：\u0026ldquo;fatal error: newproc: function arguments too large for new goroutine\u0026rdquo;，比如，go func(a [1024]int) {}([1024]int{})。\n每个p内部都有一个空闲goroutine队列gFree，这个就是用来执行fn的goroutine，是可以复用的，不用的时候可以丢给调度器schedt.gFree供其他p复用。这里空闲的goroutines，一部分存在于p.gFree，如果gfput(p, gp)时发现p.gFree队列太长说明过剩了，就转移一部分到调度器schedt.gFree中供其他p复用。\ngoroutine执行完毕后运行时并不急于将其销毁，而是会考虑goroutine的复用，gfput，前面提过了。希望go func()通过协程执行时，也不必每次创建新的goroutine，gfget，可以复用p.gFree中的goroutine，如果p.gFree空或者过少（32）且调度器schedt.gFree中有空闲，则转移一部分过来给p复用。但是goroutine的栈有可能会被销毁，如果复用到栈被销毁的goroutine就需要stackalloc重新为其分配新栈帧。\n如果没有空闲的g可供复用，那就只能malg从头新建一个goroutine了。\ngoroutine创建成功、栈空间也ok了之后，就要把goroutine要执行的函数对应的函数参数给拷贝到这个栈空间里面来，通过memmove(spArg, argp, uintptr(narg))来完成。完成后调整newg的调度上下文相关的寄存器值，等调度器调度它时，还原其中的上下文信息，pc就指向其对应的函数地址了，对应的数据也会指向其对应的栈空间。\n然后，通过gostartcallfn→gostartcall(buf, fn, ctxt)，之前已经拷贝了函数fn的参数到goroutine栈空间了，这里面再继续在栈内设置fn返回地址、gobuf.sp+gobuf.pc信息。\n上述调整完成之后，将goroutine的状态从_Gdead调整为_Grunnable，等待调度器调度。新创建的时候其状态是_Gidle，一定会将其调整为_Gdead然后再进行上述准备工作，一切就绪后才调整为_Grunnable让其参与调度。\n2 runqput(p, gp, next) 这里的逻辑是，希望将gp放到p的local queue中，但是也有头插、尾插两种方式。\n 如果next为true，可以认为是头插，其实是放到p.runnext中，比p.queue中的得到优先调度。如果之前p.runnext有值，还要该值对应的g放入p.queue中； 如果next为false，则尝试将其放置到p.queue中，这里也有快慢两种情况，快的情况就是，因为p.queue这个本地队列长度最大为256，如果有空余位置放入就返回，这是快的情况。慢的情况就是如果p.queue满了就要先转移1/2到调度器全局队列schedt.queue中，然后再放入，这个过程就慢一些。  放置过程中，如果p.runqueue满了怎么办，将其放置到调度器schedt.queue这个全局队列中。\n3 wakeup()逻辑\n这个函数内部执行startm(p, spinning)，来找一个m来执行goroutine，具体是怎么做的呢？\n  如果没有指定p，比如新建goroutine时，此时会尝试检查有没有空闲的p，没有的话就直接返回了，相当于当前一次没有执行成功，那么只能下次调度的时候再执行这个新建的goroutine了；\n  现在有空闲的p，我们还缺什么，m！然后mget找一个空闲的m，如果没有空闲的，就newm创建一个新的，本质上是通过clone系统调用创建的新的线程。然后将这个m和这个p关联起来，m.nextp = p。值得一提的是clone出来的线程对应的线程处理函数是mstart，mstart使用汇编写的，内部实际调用的是mstart0，它内部又请求mstart1，获取当前g：\n  如果g.m==\u0026amp;m0，则执行mstartm0完成信号处理注册，继续执行其他；\n  获取当前m.",content:"goroutine创建：runtime.newproc(siz int32, fn *funcval)\n go fn()，传递给fn的参数实际上是紧跟着存在fn压栈后的地址后面，在newproc1的栈帧里面，但是不出现在签名参数列表中，因为这些参数类型、数量不一样，也无法出现在签名参数列表中； newproc1创建g； getg().m.p.ptr()拿到当前p； runqput将当前g放入p的local queue中，如果满则放到global queue中； g等待被调度器调度执行；  大致创建执行goroutine的逻辑是这样的，下面的逻辑都是切到系统栈上去执行的。\n1 newproc1逻辑\n查看源码发现，goroutine初始创建时对函数参数大小是有限制的，如果参数占内存空间很大，比如超过初始栈帧大小2KB，那么goroutine创建会失败：\u0026ldquo;fatal error: newproc: function arguments too large for new goroutine\u0026rdquo;，比如，go func(a [1024]int) {}([1024]int{})。\n每个p内部都有一个空闲goroutine队列gFree，这个就是用来执行fn的goroutine，是可以复用的，不用的时候可以丢给调度器schedt.gFree供其他p复用。这里空闲的goroutines，一部分存在于p.gFree，如果gfput(p, gp)时发现p.gFree队列太长说明过剩了，就转移一部分到调度器schedt.gFree中供其他p复用。\ngoroutine执行完毕后运行时并不急于将其销毁，而是会考虑goroutine的复用，gfput，前面提过了。希望go func()通过协程执行时，也不必每次创建新的goroutine，gfget，可以复用p.gFree中的goroutine，如果p.gFree空或者过少（32）且调度器schedt.gFree中有空闲，则转移一部分过来给p复用。但是goroutine的栈有可能会被销毁，如果复用到栈被销毁的goroutine就需要stackalloc重新为其分配新栈帧。\n如果没有空闲的g可供复用，那就只能malg从头新建一个goroutine了。\ngoroutine创建成功、栈空间也ok了之后，就要把goroutine要执行的函数对应的函数参数给拷贝到这个栈空间里面来，通过memmove(spArg, argp, uintptr(narg))来完成。完成后调整newg的调度上下文相关的寄存器值，等调度器调度它时，还原其中的上下文信息，pc就指向其对应的函数地址了，对应的数据也会指向其对应的栈空间。\n然后，通过gostartcallfn→gostartcall(buf, fn, ctxt)，之前已经拷贝了函数fn的参数到goroutine栈空间了，这里面再继续在栈内设置fn返回地址、gobuf.sp+gobuf.pc信息。\n上述调整完成之后，将goroutine的状态从_Gdead调整为_Grunnable，等待调度器调度。新创建的时候其状态是_Gidle，一定会将其调整为_Gdead然后再进行上述准备工作，一切就绪后才调整为_Grunnable让其参与调度。\n2 runqput(p, gp, next) 这里的逻辑是，希望将gp放到p的local queue中，但是也有头插、尾插两种方式。\n 如果next为true，可以认为是头插，其实是放到p.runnext中，比p.queue中的得到优先调度。如果之前p.runnext有值，还要该值对应的g放入p.queue中； 如果next为false，则尝试将其放置到p.queue中，这里也有快慢两种情况，快的情况就是，因为p.queue这个本地队列长度最大为256，如果有空余位置放入就返回，这是快的情况。慢的情况就是如果p.queue满了就要先转移1/2到调度器全局队列schedt.queue中，然后再放入，这个过程就慢一些。  放置过程中，如果p.runqueue满了怎么办，将其放置到调度器schedt.queue这个全局队列中。\n3 wakeup()逻辑\n这个函数内部执行startm(p, spinning)，来找一个m来执行goroutine，具体是怎么做的呢？\n  如果没有指定p，比如新建goroutine时，此时会尝试检查有没有空闲的p，没有的话就直接返回了，相当于当前一次没有执行成功，那么只能下次调度的时候再执行这个新建的goroutine了；\n  现在有空闲的p，我们还缺什么，m！然后mget找一个空闲的m，如果没有空闲的，就newm创建一个新的，本质上是通过clone系统调用创建的新的线程。然后将这个m和这个p关联起来，m.nextp = p。值得一提的是clone出来的线程对应的线程处理函数是mstart，mstart使用汇编写的，内部实际调用的是mstart0，它内部又请求mstart1，获取当前g：\n  如果g.m==\u0026amp;m0，则执行mstartm0完成信号处理注册，继续执行其他；\n  获取当前m.mstartfn，即线程处理函数，执行该函数，如果该函数会执行结束那还要继续执行；\n  如果当前g.m不是m0，那么要将g.m.nextp与当前m关联起来，为什么呢？m执行调度时用这个p呗，执行它的queue中的goroutine呗；\n  执行调度schedule()逻辑，这个函数调用一次就是执行一轮调度，逻辑就是寻找一个可运行的goroutine然后执行。这个函数比较有意思了，有些goroutine是通过lockOSThread绑定了执行它的线程的，这样的goroutine只能用那个绑定的m来执行，未绑定的则无此限制。 lockedg：这个schedule函数先获取当前g，如果发现当前g.m.lockedg不为0，表示有一个g通过lockOSThread绑定到了g.m，这个时候先停掉当前m，让其把p交出来，等下次有线程schedule里面调度执行lockedg时再唤醒该m，此时m被parked，p被空出来了。再调用execute(lockedg, inheritTime)，将该lockedg设置为当前g.m.curg，并修改装改为_Grunning，然后下面gogo(\u0026amp;gp.sched)恢复该待执行goroutine的上下文，执行之，execute函数never returns。可以想象下，如果一个m有g locked，那么每次调度都会先优先执行该goroutine？ 剩下的逻辑：获取当前g.m.p，\u0026hellip;..一堆有的没的逻辑，会通过findRunnable找一个可以运行的g来执行，最后也是调用execute来执行gp。 netpoller：值得一提的是这个函数里面会通过findRunnable来查找一个可执行的g，除了从p.queue、schedt.queue、其他p.queue中找可运行的goroutine外，也包括从netpoller中获取等待网络IO事件就绪的g。\n  到这里就可以算是结束了，到这里基本就了解了整个goroutine从创建到执行的完整逻辑了。当然这个后面还有点逻辑，目前也没搞懂写来干嘛的，先不管后面这个逻辑吧。\n 然后notewakeup唤醒阻塞在\u0026amp;m.park上的一个proc，这个是做什么呢？意思是说，如果之前m执行（执行某个goroutine的代码）时，因为某个原因阻塞了（这个原因通常用目标对象的事件地址来表示，如\u0026amp;m.park），现在这个条件满足了，现在将其唤醒继续执行。我们不禁想问，这里的\u0026amp;m.park表示的是什么呢？  ps：这里用到了futex来实现轻量级地锁获取+获取失败阻塞、锁释放+唤醒阻塞线程操作，see https://lwn.net/Articles/360699/。\n"}),a.add({id:278,href:"/tags/garbage-collector/",title:"garbage collector",description:"",content:""}),a.add({id:279,href:"/blog/2021-05-01-gogc-prioritizing-low-latency-and-simplicity/",title:"GC: prioritizing low latency and simplicity",description:"go GC 如何实现一个面向未来10年的低延迟、简洁的垃圾回收器，本文摘自golang官方blog，介绍了go团队针对GC所做的系列优化",content:"原文地址：https://blog.golang.org/go15gc\n介绍了当前软硬件大规模发展的趋势以及go GC需要优先解决的问题：低延迟和简单性（通过一个参数就可以控制，而非像JVM调参那样）。\ngo团队的目标是设计一个面向未来十年的垃圾回收器，借鉴了十几年前发明的算法。go GC使用的是并发三色标记清除算法（concurrent, tri-color, mark-sweep collector），由Dijkstra在1978年提出。该算法与现在大多数企业级的GC实现不同，但是go团队认为该算法更适合于现代硬件的发展，也更有助于实现现代软件的GC低延迟目标。\n该GC算法中，每个对象只能是white、grey、black中的其中一种，heap可以看做是互相连接的对象构成的一个graph。GC算法流程是：\n GC开始时，所有对象都是white； GC遍历所有的roots对象（比如全局变量、栈变量）将其标记为灰色； 然后GC选择一个grey对象，将其标记为black，并扫描（scan）该对象检查它内部的指向其他对象的指针。如果发现有指针指向其他white对象，将white对象标记为grey； 该过程重复执行，直到没有任何的灰色对象； 最后，剩下的白色对象即认为是不可达对象，可以被回收再利用；  GC过程和应用程序执行是并发进行的，应用程序也称为mutator，它会在GC运行期间修改一些指针的值。mutator必须遵循这样一条规则，就是不允许出现一个黑色对象指向一个白色对象，这样会导致对象被错误地回收。为了保证该规则成立，就需要引入写屏障（write barrier），它是编译阶段由编译器对mutator指针操作安插的一些特殊指令，用来跟踪对指针的修改，write barrier如果发现当前黑色对象的内部指针字段指向了外部的一个白色对象，则会将白色对象染色为grey，避免其被错误地GC掉，也保证其可以被继续扫描。\n有些GC相关的问题：\n 什么时候启动GC？ 通过哪些指标来判断要启动GC？ GC应该如何与scheduler进行交互？ 如何暂停一个mutator线程足够长时间，以扫描器stack？ 如何表示white、grey和black三种颜色来实现高效地查找、扫描grey对象？ 如何知道roots对象在哪里？ 如何知道一个指向对象的指针的位置？ 如何最小化内存碎片？ 如何解决cache性能问题？ heap应该设置为多大？ 等等。  上述问题有些与内存分配有关，有些与可达对象分析有关，有些与goroutine调度有关，有些与性能有关，关于这些内容的讨论远远超出本文篇幅，可以自己参考相关的材料。\n为了解决GC性能问题，可以考虑为每一种优化加个参数来控制，开发人员可以自己调整这里的参数来达到想要的优化效果。但是这种做法时间久了之后会发现有非常多的参数，调优就会变得非常困难，比如JVM调优。go团队不想走这样的老路，力求简单高效。\ngo通过GOGC这个环境变量来控制整个堆大小相对于现阶段可达对象大小的比例。GOGC默认值是100%，意味着当堆大小增长了当前可达对象大小的1倍时（2倍大小），就会触发GC；200%则意味着继续增长了当前可达对象的2倍时触发GC（3倍大小）。\n 如果想降低GC花费的时间，就把这个值设置的大一点，因为这样不容易频繁触发GC； 如果愿意花费更多的GC时间来换取更少的内存占用，就把这个值设置的小一点，因为这样能够更加频繁地GC；  前面提到go团队要设计一个面向未来十年的垃圾回收器，未来十年机器内存容量可能会翻倍或者成倍增长，简单地将GOGC设置为一定倍率也可以很好地工作，也不用像JVM调优那样重新设置一堆地参数，调参大军好惨。go团队也可以倾听用户真正地诉求在运行时方面做更多的优化。\n"}),a.add({id:280,href:"/blog/09%E6%99%AE%E9%80%9A%E7%B4%A2%E5%BC%95%E5%92%8C%E5%94%AF%E4%B8%80%E7%B4%A2%E5%BC%95%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9/",title:"09普通索引和唯一索引：如何选择",description:"对比两种类型的索引 #  普通索引，允许多条记录中组成索引的字段值出现重复的情况； 唯一索引，不允许……  两种类型索引实现 # 肯定都是一样的啊\n两种类型索引效率 # 我们以表user为例：\ncreate table `user` ( id int auto_increment, id_card varchar(64), name varchar(32), primary key(id), [uique|index] (id_card) -- 创建索引：唯一索引或者普通索引 )  其中id_card可能是唯一索引，也可能是普通索引。\n查询效率 # 以这条查询语句为例：select name from user where id_card=?\n  普通索引的查询\n顺着B+树根据id_card查询，查询到第一条记录之后，回表查询对应的name，加入结果集。继续遍历向右的指针对应的记录，直到找到第一条id_card不匹配的记录为止。因为id_card肯定是不重复的，所以这里向右的匹配开销顶多也就是多比较一次。\n当然如果匹配到的这条记录如果是page的最后一条记录的话，那么可能向右的查找需要加载另一个page，这是最坏的情况了。\n实际情况是B+树种一个节点可以存储非常多的key和指针，真的出现匹配记录出现在最后一个的情况非常少。\n  唯一索引的查询\n查找过程也是顺着B+树根据id_card查询，然后再回表。区别是它找到第一个匹配的节点之后就停止向右的查找了，因为它知道是唯一索引，不可能有重复的记录存在。\n  性能对比\n看上去唯一索引查询性能会高一点，但是前面也分析了id_card本身具备唯一性，普通查询中这种继续向右查找的操作对性能影响开销并不大，微乎其微。所以对于这两种索引，建议使用普通索引来代替唯一索引。\n  更新效率 # 更新语句以这个为例：update user set name=\u0026quot;xxxx\u0026quot; where id_card=?\n  change buffer\n在mysql执行数据更新时，会先写redo log，然后收到ok后准备更新数据。这个要更新的行对应的页数据如果在内存中，则直接更新内内存中的相应字段就可以了。",content:"对比两种类型的索引 #  普通索引，允许多条记录中组成索引的字段值出现重复的情况； 唯一索引，不允许……  两种类型索引实现 # 肯定都是一样的啊\n两种类型索引效率 # 我们以表user为例：\ncreate table `user` ( id int auto_increment, id_card varchar(64), name varchar(32), primary key(id), [uique|index] (id_card) -- 创建索引：唯一索引或者普通索引 )  其中id_card可能是唯一索引，也可能是普通索引。\n查询效率 # 以这条查询语句为例：select name from user where id_card=?\n  普通索引的查询\n顺着B+树根据id_card查询，查询到第一条记录之后，回表查询对应的name，加入结果集。继续遍历向右的指针对应的记录，直到找到第一条id_card不匹配的记录为止。因为id_card肯定是不重复的，所以这里向右的匹配开销顶多也就是多比较一次。\n当然如果匹配到的这条记录如果是page的最后一条记录的话，那么可能向右的查找需要加载另一个page，这是最坏的情况了。\n实际情况是B+树种一个节点可以存储非常多的key和指针，真的出现匹配记录出现在最后一个的情况非常少。\n  唯一索引的查询\n查找过程也是顺着B+树根据id_card查询，然后再回表。区别是它找到第一个匹配的节点之后就停止向右的查找了，因为它知道是唯一索引，不可能有重复的记录存在。\n  性能对比\n看上去唯一索引查询性能会高一点，但是前面也分析了id_card本身具备唯一性，普通查询中这种继续向右查找的操作对性能影响开销并不大，微乎其微。所以对于这两种索引，建议使用普通索引来代替唯一索引。\n  更新效率 # 更新语句以这个为例：update user set name=\u0026quot;xxxx\u0026quot; where id_card=?\n  change buffer\n在mysql执行数据更新时，会先写redo log，然后收到ok后准备更新数据。这个要更新的行对应的页数据如果在内存中，则直接更新内内存中的相应字段就可以了。\n如果这个数据没有在binlog中，也不会立即写入磁盘，而是从从磁盘加载速度比较慢，所以可以将一些更新操作，记录到change buffer中。后面有读数据请求等等时，会触发从磁盘加载文件，加载成功后再应用change buffer中的数据。\n  普通索引更新\n普通索引更新的时候，基本上就是上述说的过程，它是可以使用change buffer的。\n  唯一索引更新\n唯一索引，这里的唯一意味着每次操作都要判断是否会违反唯一性这个约束。比如要插入一行数据(1,\u0026lsquo;id_card\u0026rsquo;,100)，就要判断是否已经有将“id_card”写入的记录。\n类似地，要对id_card=\u0026lsquo;xxx\u0026rsquo;的记录做更新，就要能够找到id_card对应的行数据，这个时候目标行数肯定是要加载到内存中的，所以对应的页一定在内存中。\n这种情况下直接更新内存肯定比更新change buffer要快了，change buffer还受限于buffer pool大小机器设定的可占buffer pool的比例呢，所以这种情况下就没必要使用change buffer了。\n所以唯一索引不使用change buffer。\n  对比\n实际情况是，唯一索引的更新效率会比普通索引低。因为它必须要将行数据加载到内存中判断并更新，不能向普通索引那样直接写完change buffer就完事了。change buffer中的一些操作，会在后续读取的时候加载完原始数据之后，然后应用change buffer中的操作到原始数据，这个过程称为merge。\n  changebuffer应用场景 # 也不是说所有的场景都适合使用changebuffer，如果写多读少的话，就很适用了。反过来的话，读多写少，这种就不适合使用change buffer了，可以考虑禁用。\nchangebuffer是通过buffer pool分配的，可以设定一个变量来控制change buffer的大小。\n"}),a.add({id:281,href:"/tags/isolation/",title:"isolation",description:"",content:""}),a.add({id:282,href:"/tags/mvcc/",title:"mvcc",description:"",content:""}),a.add({id:283,href:"/categories/mysql%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"MySQL设计实现",description:"",content:""}),a.add({id:284,href:"/tags/transaction/",title:"transaction",description:"",content:""}),a.add({id:285,href:"/blog/07%E9%87%8D%E8%A6%81%E7%9A%84%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E4%B8%8A/",title:"07重要的集群参数配置",description:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101171",content:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101171\n"}),a.add({id:286,href:"/tags/kafka/",title:"kafka",description:"",content:""}),a.add({id:287,href:"/categories/kafka%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E6%88%98/",title:"kafka核心技术与实战",description:"",content:""}),a.add({id:288,href:"/blog/06kafka%E7%BA%BF%E4%B8%8A%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2%E6%96%B9%E6%A1%88%E6%80%8E%E4%B9%88%E5%81%9A/",title:"06kafka线上集群部署方案怎么做",description:"kafka线上集群部署，该怎么做呢？可以从下面几个大的方向入手。\n操作系统选型 # kafka是基于Java、Scala实现的跨平台的消息引擎系统，虽然是跨平台的，但是线上部署kafka用的最多的操作系统还是Linux，Window、macOS应该都非常少，可能只适合用来学习测试用，线上还是要尽量用Linux。\nLinux操作系统的一些亮点：\n IO多路复用技术，实现更加高效的网络IO操作； 零拷贝技术，数据网络传输效率； 应用部署广泛，社区支持度比较好；  关于零拷贝技术，公司同事allanpan写过一篇非常好的文章，可供参考：\n Linux I/O 原理和 Zero-copy 技术全面揭秘  磁盘选型 # 选机械硬盘呢，还是选固态硬盘呢？Kafka工作过程中比较多的方式是“顺序读写”操作，普通机械硬盘顺序读写效率已经比较高了，因此使用机械硬盘就可以了。\nkafka使用机械硬盘，一个是性能上有也不会比使用固态硬盘差多少（应该是说固态硬盘也没什么优势），再一个是便宜，能降低成本。\n另外要注意冗余，倒不是说就要用RAID，可以多加几个硬盘做冗余就行了。\n磁盘容量 # 磁盘容量要根据业务当前现状，及未来发展情况，合理地规划存储容量。\n可以从以下几个方面入手：\n 写入的消息格式是怎样的，存储一条消息需要多少字节？ 当前业务一天需要写入多少消息，10w条，100w条，未来呢？ 消息希望保留多长时间，2周，1个月？ 磁盘冗余备份数是多少，2？3？ 使用启用压缩？用哪种压缩算法？压缩率多少？  小心评估上述每一个问题，最后就能给出一个相对比较合理地预估了，当然要留些buffer，以应对预料之外的情况。\n网络带宽 # 当我们说带宽的时候，我们真正关心的是什么？我们要处理一批数据，比如kafka中的数据，每台机器都是千兆网卡，我们需要多少台机器的合力，才能保证对消息的高效处理。\nSo，每台机器的网卡带宽是固定的，我们关心的其实是处理一批数据我们需要多少台机器的问题。\n根据消息生产速率，以及单条消息大小，可以很容易计算出每秒大约能生成多少数据，现在我们要处理这些数据，消息队列中的消息不能一直处于积压状态，那意味着处理速度跟不上生产，后面会处理地越来越不及时。\n怎么办？就需要根据接受消息处理的速率，来评估大约需要机器来处理。而接收消息的速率，单机受限于网卡，用总的生产数据量（通常等于消费数据量）除以网卡带宽，就可以拿到一个比较粗糙的机器数量。\n真实情况是，要为每台机器预留一定的贷款，比如每台机器70%的带宽用于处理数据，其他 的留给一些系统、网络服务等。",content:"kafka线上集群部署，该怎么做呢？可以从下面几个大的方向入手。\n操作系统选型 # kafka是基于Java、Scala实现的跨平台的消息引擎系统，虽然是跨平台的，但是线上部署kafka用的最多的操作系统还是Linux，Window、macOS应该都非常少，可能只适合用来学习测试用，线上还是要尽量用Linux。\nLinux操作系统的一些亮点：\n IO多路复用技术，实现更加高效的网络IO操作； 零拷贝技术，数据网络传输效率； 应用部署广泛，社区支持度比较好；  关于零拷贝技术，公司同事allanpan写过一篇非常好的文章，可供参考：\n Linux I/O 原理和 Zero-copy 技术全面揭秘  磁盘选型 # 选机械硬盘呢，还是选固态硬盘呢？Kafka工作过程中比较多的方式是“顺序读写”操作，普通机械硬盘顺序读写效率已经比较高了，因此使用机械硬盘就可以了。\nkafka使用机械硬盘，一个是性能上有也不会比使用固态硬盘差多少（应该是说固态硬盘也没什么优势），再一个是便宜，能降低成本。\n另外要注意冗余，倒不是说就要用RAID，可以多加几个硬盘做冗余就行了。\n磁盘容量 # 磁盘容量要根据业务当前现状，及未来发展情况，合理地规划存储容量。\n可以从以下几个方面入手：\n 写入的消息格式是怎样的，存储一条消息需要多少字节？ 当前业务一天需要写入多少消息，10w条，100w条，未来呢？ 消息希望保留多长时间，2周，1个月？ 磁盘冗余备份数是多少，2？3？ 使用启用压缩？用哪种压缩算法？压缩率多少？  小心评估上述每一个问题，最后就能给出一个相对比较合理地预估了，当然要留些buffer，以应对预料之外的情况。\n网络带宽 # 当我们说带宽的时候，我们真正关心的是什么？我们要处理一批数据，比如kafka中的数据，每台机器都是千兆网卡，我们需要多少台机器的合力，才能保证对消息的高效处理。\nSo，每台机器的网卡带宽是固定的，我们关心的其实是处理一批数据我们需要多少台机器的问题。\n根据消息生产速率，以及单条消息大小，可以很容易计算出每秒大约能生成多少数据，现在我们要处理这些数据，消息队列中的消息不能一直处于积压状态，那意味着处理速度跟不上生产，后面会处理地越来越不及时。\n怎么办？就需要根据接受消息处理的速率，来评估大约需要机器来处理。而接收消息的速率，单机受限于网卡，用总的生产数据量（通常等于消费数据量）除以网卡带宽，就可以拿到一个比较粗糙的机器数量。\n真实情况是，要为每台机器预留一定的贷款，比如每台机器70%的带宽用于处理数据，其他 的留给一些系统、网络服务等。\n"}),a.add({id:289,href:"/blog/05%E8%81%8A%E8%81%8Akafka%E7%9A%84%E7%89%88%E6%9C%AC%E5%8F%B7/",title:"05聊聊kafka的版本号",description:"了解kafka的版本演进，及各个版本的特性，更方便确定自己的业务选择合适的版本。\nkafka版本号说明：kafka-2.11-2.2.1.tgz\nkafka的服务端是用scala编写的，其中2.11表示的是scala编译器实现的，其中2.2.1才是kafka的版本号，主版本2、副版本2、修订版本1。\n了解各个版本的演进\nKafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0，其中的小版本和 Patch 版本很多。哪些版本引入了哪些重大的功能改进？关于这个问题，我建议你最好能做到如数家珍。\n额，历史版本暂时先不深究了。\n最后还有个建议，不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多 Kafka 为你提供的性能优化收益。",content:"了解kafka的版本演进，及各个版本的特性，更方便确定自己的业务选择合适的版本。\nkafka版本号说明：kafka-2.11-2.2.1.tgz\nkafka的服务端是用scala编写的，其中2.11表示的是scala编译器实现的，其中2.2.1才是kafka的版本号，主版本2、副版本2、修订版本1。\n了解各个版本的演进\nKafka 目前总共演进了 7 个大版本，分别是 0.7、0.8、0.9、0.10、0.11、1.0 和 2.0，其中的小版本和 Patch 版本很多。哪些版本引入了哪些重大的功能改进？关于这个问题，我建议你最好能做到如数家珍。\n额，历史版本暂时先不深究了。\n最后还有个建议，不论你用的是哪个版本，都请尽量保持服务器端版本和客户端版本一致，否则你将损失很多 Kafka 为你提供的性能优化收益。\n"}),a.add({id:290,href:"/blog/04%E6%88%91%E4%BB%AC%E5%BA%94%E8%AF%A5%E9%80%89%E6%8B%A9%E5%93%AA%E7%A7%8Dkafka/",title:"04我们应该选择哪种kafka",description:"pk其他流处理平台 # Apache Storm、Apache Spark Streaming 亦或是 Apache Flink，它们在大规模流处理领域可都是响当当的名字。\n令人高兴的是，Kafka 经过这么长时间不断的迭代，现在已经能够稍稍比肩这些框架了。我在这里使用了“稍稍”这个字眼，一方面想表达 Kafka 社区对于这些框架心存敬意；另一方面也想表达目前国内鲜有大厂将 Kafka 用于流处理的尴尬境地，毕竟 Kafka 是从消息引擎“半路出家”转型成流处理平台的，它在流处理方面的表现还需要经过时间的检验。\n kafka connect，扩展了kafka的流式处理生态\n 你知道几种kafka？ #  apache kafka，社区版，是后续所有版本的基础 confluent kafka，提供了一些其他功能，如跨数据中心备份、集群监控工具等 cloudera/hortonworks kafka，提供的CDH和HDP是非常有名的大数据平台，里面集成了目前主流的大数据框架，现在两个公司已经合并，都集成了apache kafka。  apache kafka的优缺点 # 优点：\n 开发人数多、活跃，版本迭代快  缺点：\n 仅仅提供最基础的组件 kafka connect，仅提供一种读写文件的连接器，其他的要自己实现 没有任何监控框架或者工具，要借助第三方监控框架来监控（如kafka manager）  confluent kafka、cdh/hdp kafka的优缺点就不多说了，国内大公司很少有使用的。",content:"pk其他流处理平台 # Apache Storm、Apache Spark Streaming 亦或是 Apache Flink，它们在大规模流处理领域可都是响当当的名字。\n令人高兴的是，Kafka 经过这么长时间不断的迭代，现在已经能够稍稍比肩这些框架了。我在这里使用了“稍稍”这个字眼，一方面想表达 Kafka 社区对于这些框架心存敬意；另一方面也想表达目前国内鲜有大厂将 Kafka 用于流处理的尴尬境地，毕竟 Kafka 是从消息引擎“半路出家”转型成流处理平台的，它在流处理方面的表现还需要经过时间的检验。\n kafka connect，扩展了kafka的流式处理生态\n 你知道几种kafka？ #  apache kafka，社区版，是后续所有版本的基础 confluent kafka，提供了一些其他功能，如跨数据中心备份、集群监控工具等 cloudera/hortonworks kafka，提供的CDH和HDP是非常有名的大数据平台，里面集成了目前主流的大数据框架，现在两个公司已经合并，都集成了apache kafka。  apache kafka的优缺点 # 优点：\n 开发人数多、活跃，版本迭代快  缺点：\n 仅仅提供最基础的组件 kafka connect，仅提供一种读写文件的连接器，其他的要自己实现 没有任何监控框架或者工具，要借助第三方监控框架来监控（如kafka manager）  confluent kafka、cdh/hdp kafka的优缺点就不多说了，国内大公司很少有使用的。\n"}),a.add({id:291,href:"/blog/03kafka%E5%8F%AA%E6%98%AF%E6%B6%88%E6%81%AF%E5%BC%95%E6%93%8E%E7%B3%BB%E7%BB%9F%E5%90%97/",title:"03kafka只是消息引擎系统吗",description:"如果一个点一个点的学习，虽然了解了一个个点的作用，但是不能快速建立起全局的认识，也比较容易丧失学习兴趣，还是先了解全貌再深入细节，学习效果会更好一点。\napache kafka只是一个消息引擎系统吗 #  apache kafka是消息引擎系统； apache kafka也是一个分布式流式处理平台（distributed streaming platform）；  kafka出自linkedin，kafka 社区将其清晰地定位为一个分布式、分区化且带备份功能的提交日志（Commit Log）服务。\nKafka 在设计之初就旨在提供三个方面的特性 #  提供一套 API 实现生产者和消费者； 降低网络传输和磁盘存储开销； 实现高伸缩性架构。  kafka的华丽变身 # 所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？Kafka Streams诞生了！\nkafka与其他主流大数据流式计算框架相比，优势在哪里呢？\n  更容易实现端到端的正确性，能够实现端到端的精确一次性处理语义。\n  自己对于流式计算的定位，和其他的一些流失计算框架不同，它更轻量，不涉及集群调度等等比较重的东西，比较适合中小企业；\n   ps：kafka不适合当做最终存储。\n ",content:"如果一个点一个点的学习，虽然了解了一个个点的作用，但是不能快速建立起全局的认识，也比较容易丧失学习兴趣，还是先了解全貌再深入细节，学习效果会更好一点。\napache kafka只是一个消息引擎系统吗 #  apache kafka是消息引擎系统； apache kafka也是一个分布式流式处理平台（distributed streaming platform）；  kafka出自linkedin，kafka 社区将其清晰地定位为一个分布式、分区化且带备份功能的提交日志（Commit Log）服务。\nKafka 在设计之初就旨在提供三个方面的特性 #  提供一套 API 实现生产者和消费者； 降低网络传输和磁盘存储开销； 实现高伸缩性架构。  kafka的华丽变身 # 所有的数据几乎都要从一个系统流入 Kafka 然后再流向下游的另一个系统中。这样的使用方式屡见不鲜以至于引发了 Kafka 社区的思考：与其我把数据从一个系统传递到下一个系统中做处理，我为何不自己实现一套流处理框架呢？Kafka Streams诞生了！\nkafka与其他主流大数据流式计算框架相比，优势在哪里呢？\n  更容易实现端到端的正确性，能够实现端到端的精确一次性处理语义。\n  自己对于流式计算的定位，和其他的一些流失计算框架不同，它更轻量，不涉及集群调度等等比较重的东西，比较适合中小企业；\n   ps：kafka不适合当做最终存储。\n "}),a.add({id:292,href:"/blog/02%E5%BF%AB%E9%80%9F%E6%90%9E%E5%AE%9Akafka%E6%9C%AF%E8%AF%AD/",title:"02快速搞定kafka术语",description:"kafka属于分布式的消息引擎系统，主要功能是提供一套完备的消息发布与订阅解决方案：\n  发布的订阅的对象是主题，topic；\n  client端\n 消息的生产者，producer； 消息的消费者，consumer；    server端\n broker 一个broker集群有多个broker，将多个broker部署在多台机器上，当其中一个挂了，另一个broker也依然能对外提供服务，这就是kafka实现高可用的手段之一。    备份机制，replication\n  副本，replica，相同的数据在被存储到多台机器上\n  领导者副本（leader replica），对外提供服务（与客户端交互）\n  追随者副本（follower replica），只能被动地跟随领导者副本，不与外界交互\n追随者副本请求领导者副本，把最新的更新操作发送给它，以完成同步\n    可伸缩性\n 将每个topic，划分成多个分区（partition），分区编号从0开始； 副本是在分区这个层级定义的，即每个分区可以定义副本的数量；    topic ：每个主题可以包含多个分区\n​	\\\npartition：每个分区可以配置多个副本\n​	\\\n​	replica (leader/follower)：每个分区的多个副本中只能有一个为leader，对外服务\n​	\\\n​	offset：消息曾，分区中包含若干条消息，每条消息的位移从0开始，依次递增\nclient只能与分区的leader replica进行通信。\n消费组里面可以订阅\nkafka broker通过追加写，来实现持久化，来避免缓慢的随机IO操，利用了比较好的顺序写操作。\n再来回顾下这里的常见术语：\n消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。\n主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\n分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。",content:"kafka属于分布式的消息引擎系统，主要功能是提供一套完备的消息发布与订阅解决方案：\n  发布的订阅的对象是主题，topic；\n  client端\n 消息的生产者，producer； 消息的消费者，consumer；    server端\n broker 一个broker集群有多个broker，将多个broker部署在多台机器上，当其中一个挂了，另一个broker也依然能对外提供服务，这就是kafka实现高可用的手段之一。    备份机制，replication\n  副本，replica，相同的数据在被存储到多台机器上\n  领导者副本（leader replica），对外提供服务（与客户端交互）\n  追随者副本（follower replica），只能被动地跟随领导者副本，不与外界交互\n追随者副本请求领导者副本，把最新的更新操作发送给它，以完成同步\n    可伸缩性\n 将每个topic，划分成多个分区（partition），分区编号从0开始； 副本是在分区这个层级定义的，即每个分区可以定义副本的数量；    topic ：每个主题可以包含多个分区\n​	\\\npartition：每个分区可以配置多个副本\n​	\\\n​	replica (leader/follower)：每个分区的多个副本中只能有一个为leader，对外服务\n​	\\\n​	offset：消息曾，分区中包含若干条消息，每条消息的位移从0开始，依次递增\nclient只能与分区的leader replica进行通信。\n消费组里面可以订阅\nkafka broker通过追加写，来实现持久化，来避免缓慢的随机IO操，利用了比较好的顺序写操作。\n再来回顾下这里的常见术语：\n消息：Record。Kafka 是消息引擎嘛，这里的消息就是指 Kafka 处理的主要对象。\n主题：Topic。主题是承载消息的逻辑容器，在实际使用中多用来区分具体的业务。\n分区：Partition。一个有序不变的消息序列。每个主题下可以有多个分区。\n消息位移：Offset。表示分区中每条消息的位置信息，是一个单调递增且不变的值。\n副本：Replica。Kafka 中同一条消息能够被拷贝到多个地方以提供数据冗余，这些地方就是所谓的副本。副本还分为领导者副本和追随者副本，各自有不同的角色划分。副本是在分区层级下的，即每个分区可配置多个副本实现高可用。\n生产者：Producer。向主题发布新消息的应用程序。\n消费者：Consumer。从主题订阅新消息的应用程序。\n消费者位移：Consumer Offset。表征消费者消费进度，每个消费者都有自己的消费者位移。\n消费者组：Consumer Group。多个消费者实例共同组成的一个组，同时消费多个分区以实现高吞吐。\n重平衡：Rebalance。消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。\n"}),a.add({id:293,href:"/blog/01%E6%B6%88%E6%81%AF%E5%BC%95%E6%93%8E%E7%B3%BB%E7%BB%9Fabc/",title:"01消息引擎系统",description:"apache kafka是什么呢？\n 消息引擎系统（messaging systems）🆗 这种描述更加准确！ 消息队列（是用队列实现的？not accurately) 消息中间件（messaging middleware）   类似地，比如consensus algorithm，翻译成共识算法，比一致性算法更合适，一致性已经被用的泛滥了。\n 消息编码方式： #  消息编码格式，csv、xml、json、pb、thrift； kafka使用的是纯二进制的字节序列；  消息传输方式： #  点对点，系统a发送的消息只能被b接受，其他人都不能接收； 发布订阅，可以有多个发送方（发布者，可能有多个），接收方（订阅方，可能有多个），这种能够实现非常灵活的系统扩展；  JMS：严格来说，是一种规范，而不是一种实现。\n消息引擎的作用： #   削峰填谷，避免生产者发送过量消息冲垮下游，使得下游能够平滑处理大量请求；\n为什么不对上游进行限速？限制后影响到用户体验怎么办？不现实！\n  解耦，解耦生产者和消费者，容易实现灵活的扩展；\n比如量大了之后，加更多的消费者来提高处理效率就行了嘛，加的慢也没影响，不会直接对用户体验造成影响。\n  ",content:"apache kafka是什么呢？\n 消息引擎系统（messaging systems）🆗 这种描述更加准确！ 消息队列（是用队列实现的？not accurately) 消息中间件（messaging middleware）   类似地，比如consensus algorithm，翻译成共识算法，比一致性算法更合适，一致性已经被用的泛滥了。\n 消息编码方式： #  消息编码格式，csv、xml、json、pb、thrift； kafka使用的是纯二进制的字节序列；  消息传输方式： #  点对点，系统a发送的消息只能被b接受，其他人都不能接收； 发布订阅，可以有多个发送方（发布者，可能有多个），接收方（订阅方，可能有多个），这种能够实现非常灵活的系统扩展；  JMS：严格来说，是一种规范，而不是一种实现。\n消息引擎的作用： #   削峰填谷，避免生产者发送过量消息冲垮下游，使得下游能够平滑处理大量请求；\n为什么不对上游进行限速？限制后影响到用户体验怎么办？不现实！\n  解耦，解耦生产者和消费者，容易实现灵活的扩展；\n比如量大了之后，加更多的消费者来提高处理效率就行了嘛，加的慢也没影响，不会直接对用户体验造成影响。\n  "}),a.add({id:294,href:"/blog/08%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%BA%8B%E5%8A%A1%E5%88%B0%E5%BA%95%E6%98%AF%E9%9A%94%E7%A6%BB%E7%9A%84%E8%BF%98%E6%98%AF%E4%B8%8D%E9%9A%94%E7%A6%BB%E7%9A%84/",title:"08事务隔离：事务到底是隔离的还是不隔离的",description:"启动事务 # 启动事务的方式有哪些：\n autocommit=1，每条语句是一个独立的事务，比如select、update、delete； 通过begin/start transaction来启动一个事务，但是该语句并不是事务的起点，起点是在后面的第一条sql语句执行的时候； start transaction with consistent snapshot，立即启动一个新的事务，和begin/start transaction不同，该语句是一个事务的起点；  视图的概念 # 在mysql里，视图，有两种意思：\n  一个是“view”，它是一个用查询语句定义的虚拟表，如执行create view select * from table，该语句执行的时候执行查询语句获得结果并创建视图，可以在视图上执行查询操作，查询语法与在表上的查询方式类似；\n  另一个是InnoDB在实现MVCC时用到的“一致性读视图”，即consistent read view，用于支持RC（read commited，读提交）和RR（repeatable read，可重复读）隔离级别的实现；\n它没有物理结构，作用是事务执行期间用来定义“当前事务能看到什么数据”。\n  “快照”在MVCC里是怎么工作的 # 在可重复读隔离级别下，事务在启动的时候就“创建了个快照”，这个快照是基于整库的。\n但是这里的创建快照，并不是复制一份完整的数据作为只读，肯定不能这样实现，想想一下一个数据库如果数量很大，复制的存储开销也太大了。\nmysql MVCC里实现的这个快照非常聪明：\n  InnoDB里每个事务都有一个唯一的事务ID，叫transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。\n  每行数据也是有多个版本的，这里的版本就用transaction id来表示。哪个数据版本更加新一点旧一点，还是根据生成该版本时的顺序来决定的，每行数据的transaction id则用来维护一个一致性读视图；\n  当对某行数据进行更新操作时，会申请一个新的事务id，并插入新行数据，并更新字段trx_id为事务id，此时，插入了新的数据并不会删除旧的，旧的还是保存着的。但是新版的行数据有办法能找到旧版本的数据；\n注意新生成一个版本数据时，也会插入一行undo log，一个事务可以借助其事务id，从当前数据版本开始读，然后结合每行数据的trx_id和undo log，来读取到当前事务可见的数据版本，来实现一致性读视图，也就实现了可重复读；\n就是当前事务id可能是100，现在对应行的数据当前版本是102，100这个事务就顺着数据行的当前版本开始找，直到发现一个版本\u0026lt;=100时才行，也就保证了一致性读，这里就是根据数据行102版本的undo log找到前一条数据行，重复这个过程，直到发现一个版本\u0026lt;=100。\n  通过这种方式，实现了秒级快照的能力！\n当前读（current read） # 如果事务中涉及到一些更新类的操作的话，这里的更新是在数据“最新版本”上进行的更新，也就是说在“当前读”的版本上进行更新。后续的读，看上去读取到的就是最新值。\n这可能会让我们觉得，与我们之前MVCC里面一致性读时说的一些有矛盾。其实没有矛盾的，只是更新操作的时候是在当前读的最新数据上进行更新。而后续读取的时候依然是按照MVCC里一致性读的方式来的。\n如果更新时不是按照当前读来更新，那么就会造成以前已经提交的事务更新操作丢失了。\n有几种办法可以实现当前读：\n 更新操作肯定是当前读了； select + lock in share mod，也是当前读； select + for update，也是当前读；  ",content:"启动事务 # 启动事务的方式有哪些：\n autocommit=1，每条语句是一个独立的事务，比如select、update、delete； 通过begin/start transaction来启动一个事务，但是该语句并不是事务的起点，起点是在后面的第一条sql语句执行的时候； start transaction with consistent snapshot，立即启动一个新的事务，和begin/start transaction不同，该语句是一个事务的起点；  视图的概念 # 在mysql里，视图，有两种意思：\n  一个是“view”，它是一个用查询语句定义的虚拟表，如执行create view select * from table，该语句执行的时候执行查询语句获得结果并创建视图，可以在视图上执行查询操作，查询语法与在表上的查询方式类似；\n  另一个是InnoDB在实现MVCC时用到的“一致性读视图”，即consistent read view，用于支持RC（read commited，读提交）和RR（repeatable read，可重复读）隔离级别的实现；\n它没有物理结构，作用是事务执行期间用来定义“当前事务能看到什么数据”。\n  “快照”在MVCC里是怎么工作的 # 在可重复读隔离级别下，事务在启动的时候就“创建了个快照”，这个快照是基于整库的。\n但是这里的创建快照，并不是复制一份完整的数据作为只读，肯定不能这样实现，想想一下一个数据库如果数量很大，复制的存储开销也太大了。\nmysql MVCC里实现的这个快照非常聪明：\n  InnoDB里每个事务都有一个唯一的事务ID，叫transaction id。它是在事务开始的时候向InnoDB的事务系统申请的，是按申请顺序严格递增的。\n  每行数据也是有多个版本的，这里的版本就用transaction id来表示。哪个数据版本更加新一点旧一点，还是根据生成该版本时的顺序来决定的，每行数据的transaction id则用来维护一个一致性读视图；\n  当对某行数据进行更新操作时，会申请一个新的事务id，并插入新行数据，并更新字段trx_id为事务id，此时，插入了新的数据并不会删除旧的，旧的还是保存着的。但是新版的行数据有办法能找到旧版本的数据；\n注意新生成一个版本数据时，也会插入一行undo log，一个事务可以借助其事务id，从当前数据版本开始读，然后结合每行数据的trx_id和undo log，来读取到当前事务可见的数据版本，来实现一致性读视图，也就实现了可重复读；\n就是当前事务id可能是100，现在对应行的数据当前版本是102，100这个事务就顺着数据行的当前版本开始找，直到发现一个版本\u0026lt;=100时才行，也就保证了一致性读，这里就是根据数据行102版本的undo log找到前一条数据行，重复这个过程，直到发现一个版本\u0026lt;=100。\n  通过这种方式，实现了秒级快照的能力！\n当前读（current read） # 如果事务中涉及到一些更新类的操作的话，这里的更新是在数据“最新版本”上进行的更新，也就是说在“当前读”的版本上进行更新。后续的读，看上去读取到的就是最新值。\n这可能会让我们觉得，与我们之前MVCC里面一致性读时说的一些有矛盾。其实没有矛盾的，只是更新操作的时候是在当前读的最新数据上进行更新。而后续读取的时候依然是按照MVCC里一致性读的方式来的。\n如果更新时不是按照当前读来更新，那么就会造成以前已经提交的事务更新操作丢失了。\n有几种办法可以实现当前读：\n 更新操作肯定是当前读了； select + lock in share mod，也是当前读； select + for update，也是当前读；  "}),a.add({id:295,href:"/blog/07%E8%A1%8C%E9%94%81%E5%8A%9F%E8%BF%87%E6%80%8E%E4%B9%88%E5%87%8F%E5%B0%91%E8%A1%8C%E9%94%81%E5%AF%B9%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D/",title:"07行锁功过：怎么减少行锁对性能的影响",description:"行锁 # 行锁，顾名思义就是对表的行进行加锁，是存储引擎层来设计实现的：\n MyISAM没有行锁，对表执行更新时只能加表锁，并发度就比较低 InnoDB支持行锁，并发度就比MyISAM高，所以一般用InnoDB代替MyISAM   ps: 减少行锁的冲突，有助于进一步提高并发处理能力。\n 两阶段封锁协议 # 在一个事务中：\n 加锁，是在需要的时候按需加锁； 释放锁，是在事务提交的时候释放锁；  知道这个后，我们可以在编码时进行一点优化。\n如果事务涉及到锁定多个行的情况，尽量将可能导致锁冲突的行操作往后放，这样减少了锁持有时间，从而降低锁冲突。\n举个例子，现在有个顾客A从电影院B买电影票，需要执行：\n  1：扣账户A余额的操作；\n  2：需要给电影院B增加余额的操作；\n  3：记录一条交易日志；\n  那这几个操作该如何排序呢？因为会有很多人买电影票，所以操作2的冲突概率是比较大的，所以将2排在最后，而操作3是在额外的表中追加记录，基本不存在行冲突，所以不如放在最前面，A可能除了买电影票还可能买其他，冲突概率次之。\n所以排序为3、1、2比较合理。\n死锁和死锁检测 # 调整上面的操作顺序，只能尽量减少锁冲突，提高并发度，但是不能完全保证避免死锁。\n死锁原因 # 造成死锁的原因，就是多个事务中加锁顺序不一致，造成了循环依赖：比如事务t1已经持有了锁a，现在申请锁b，但是锁b呢已经被事务t2持有，事务t2还在申请锁a，但是a已经被t持有。这样事务t1、t2相互等待对方，都拿不到锁，就造成了死锁。\n死锁检测 # 解决死锁问题，有这么几种方法，一种是死锁避免，一种是死锁检测。\n  死锁避免，可以让获取锁的操作有一个最大超时时间，超过这个时间就返回获取锁失败，让事务退出，事务退出的时候释放掉已经持有的锁，这样就避免了死锁。\nmysql中可以通过设置变量innodb_lock_wait_timeout的值来设定这个超时时间，默认值是50s，这个时间还是很长的，一旦真的发生了死锁，对业务不可用时间也比较长，50s啊！\n如果把这个变量设为1s呢，也不行，可能会有很多的锁获取失败的情况，但是可能是正常获取锁操作，非死锁，会造成很多误伤，也不好！\n  死锁检测，通过死锁检测算法来检测是否会出现死锁操作，比如获取一个锁之前，先检查这个锁被哪个线程持有，没有也就正常拿到锁了，如果被线程t2持有，继续检查这个线程t2有没有要申请的锁被当前线程持有，如果有，那么当前线程发起的加锁请求将会导致一个循环依赖，会发生死锁。\n这个时候，可以直接让当前事务失败，释放锁，或者干掉另一个事务t2让它释放锁，也就避免了死锁。\n死锁检测默认是开启的，innodb_deadlock_detect，通过这个变量来设置。\n  相关开销 # 死锁避免虽然效果不怎么令人满意，一般还是会开启死锁检测的，但是死锁检测的过程前面也简单描述了，实际上这个死锁检测的过程会更复杂，假如有1000个线程，当前线程t1可能希望获得线程t2上的锁，t2可能希望获得t3上的锁，\u0026hellip;.，t1000可能希望获得当前线程t1的锁……就是要分析做很多分析才能判断出会不会导致死锁。\n有的时候线程数多了之后，死锁检测开销也会比较高，表现就是CPU占用率很高，比如100%，但是每秒并没有执行几个事务。\n热点记录 # 对于某些热点记录，更新频繁的记录，这样的锁冲突的情况会比较多，而且线程数也比较多的情况下，问题更明显，CPU占用很高，但是执行不了几个事务，尽管没有真的发生死锁。\n对于热点记录如何解决呢？\n 方法一：将对一条记录的操作拆分成对多个记录，每次更新时随机选一条，降低锁冲突的概率，比如改为随机更新10条记录中的一条，冲突概率就下降为原来的1/10； 方法二：改成用写增量流水日志的方式，定期地取合并日志中的操作更新到原来的那一条记录；  这里的思想，很分布式缓存热key的处理方式也是类似的，要么就是通过写多个key来解决，要么就是记录流水异步更新来解决。",content:"行锁 # 行锁，顾名思义就是对表的行进行加锁，是存储引擎层来设计实现的：\n MyISAM没有行锁，对表执行更新时只能加表锁，并发度就比较低 InnoDB支持行锁，并发度就比MyISAM高，所以一般用InnoDB代替MyISAM   ps: 减少行锁的冲突，有助于进一步提高并发处理能力。\n 两阶段封锁协议 # 在一个事务中：\n 加锁，是在需要的时候按需加锁； 释放锁，是在事务提交的时候释放锁；  知道这个后，我们可以在编码时进行一点优化。\n如果事务涉及到锁定多个行的情况，尽量将可能导致锁冲突的行操作往后放，这样减少了锁持有时间，从而降低锁冲突。\n举个例子，现在有个顾客A从电影院B买电影票，需要执行：\n  1：扣账户A余额的操作；\n  2：需要给电影院B增加余额的操作；\n  3：记录一条交易日志；\n  那这几个操作该如何排序呢？因为会有很多人买电影票，所以操作2的冲突概率是比较大的，所以将2排在最后，而操作3是在额外的表中追加记录，基本不存在行冲突，所以不如放在最前面，A可能除了买电影票还可能买其他，冲突概率次之。\n所以排序为3、1、2比较合理。\n死锁和死锁检测 # 调整上面的操作顺序，只能尽量减少锁冲突，提高并发度，但是不能完全保证避免死锁。\n死锁原因 # 造成死锁的原因，就是多个事务中加锁顺序不一致，造成了循环依赖：比如事务t1已经持有了锁a，现在申请锁b，但是锁b呢已经被事务t2持有，事务t2还在申请锁a，但是a已经被t持有。这样事务t1、t2相互等待对方，都拿不到锁，就造成了死锁。\n死锁检测 # 解决死锁问题，有这么几种方法，一种是死锁避免，一种是死锁检测。\n  死锁避免，可以让获取锁的操作有一个最大超时时间，超过这个时间就返回获取锁失败，让事务退出，事务退出的时候释放掉已经持有的锁，这样就避免了死锁。\nmysql中可以通过设置变量innodb_lock_wait_timeout的值来设定这个超时时间，默认值是50s，这个时间还是很长的，一旦真的发生了死锁，对业务不可用时间也比较长，50s啊！\n如果把这个变量设为1s呢，也不行，可能会有很多的锁获取失败的情况，但是可能是正常获取锁操作，非死锁，会造成很多误伤，也不好！\n  死锁检测，通过死锁检测算法来检测是否会出现死锁操作，比如获取一个锁之前，先检查这个锁被哪个线程持有，没有也就正常拿到锁了，如果被线程t2持有，继续检查这个线程t2有没有要申请的锁被当前线程持有，如果有，那么当前线程发起的加锁请求将会导致一个循环依赖，会发生死锁。\n这个时候，可以直接让当前事务失败，释放锁，或者干掉另一个事务t2让它释放锁，也就避免了死锁。\n死锁检测默认是开启的，innodb_deadlock_detect，通过这个变量来设置。\n  相关开销 # 死锁避免虽然效果不怎么令人满意，一般还是会开启死锁检测的，但是死锁检测的过程前面也简单描述了，实际上这个死锁检测的过程会更复杂，假如有1000个线程，当前线程t1可能希望获得线程t2上的锁，t2可能希望获得t3上的锁，\u0026hellip;.，t1000可能希望获得当前线程t1的锁……就是要分析做很多分析才能判断出会不会导致死锁。\n有的时候线程数多了之后，死锁检测开销也会比较高，表现就是CPU占用率很高，比如100%，但是每秒并没有执行几个事务。\n热点记录 # 对于某些热点记录，更新频繁的记录，这样的锁冲突的情况会比较多，而且线程数也比较多的情况下，问题更明显，CPU占用很高，但是执行不了几个事务，尽管没有真的发生死锁。\n对于热点记录如何解决呢？\n 方法一：将对一条记录的操作拆分成对多个记录，每次更新时随机选一条，降低锁冲突的概率，比如改为随机更新10条记录中的一条，冲突概率就下降为原来的1/10； 方法二：改成用写增量流水日志的方式，定期地取合并日志中的操作更新到原来的那一条记录；  这里的思想，很分布式缓存热key的处理方式也是类似的，要么就是通过写多个key来解决，要么就是记录流水异步更新来解决。\n"}),a.add({id:296,href:"/tags/locks/",title:"locks",description:"",content:""}),a.add({id:297,href:"/tags/row-lock/",title:"row lock",description:"",content:""}),a.add({id:298,href:"/blog/06%E5%85%A8%E5%B1%80%E9%94%81%E5%92%8C%E8%A1%A8%E9%94%81%E7%BB%99%E8%A1%A8%E5%8A%A0%E4%B8%AA%E5%AD%97%E6%AE%B5%E6%80%8E%E4%B9%88%E8%BF%99%E4%B9%88%E9%9A%BE/",title:"06全局锁和表锁：给表加个字段怎么这么难",description:"根据加锁的范围，mysql中的锁可以分为：全局锁、表锁、行锁 3类。\n全局锁 # 全局锁，是对整个数据库实例进行加锁，如通过命令Flush tables with read lock (FTWRL)加全局读锁，锁定后，数据更新（增删改）、数据定义（建表、修改表等）都会被阻塞。\n其作用，主要是做全库逻辑备份，也就是把全表select出来存成文本。\n加全局读锁之后，再开始备份，但是有风险：\n 如果是对主库备份，开了全局读锁之后，库不能写入，意味着业务基本不可用； 如果是对从库备份，开了全局读锁之后，从库新同步过来的binlog假如有表结构修改的操作，会导致因为拿不到MDL（metadata lock）而阻塞，无法修改表结构这一个阻塞还好，更严重的是会导致后续所有的拿MDL读锁的操作失败，包括正常的更新数据。因此这种方法容易造成主从同步延迟；  **备份数据，为什么要加锁，能不能不加锁？**不能！数据一致性，这个很好理解，不解释！\n有没有不加全局锁的方法，有，但是要看引擎是否支持事务：\n  MyISAM引擎，不支持事务，只能用加全局读锁的方式锁定之后再开始备份\n  InnoDB引擎，支持事务，主库备份的时候通过\u0026ndash;single-transaction，开启独立的事务进行备份：\n 因为备份时候设定的事务隔离级别是RR（可重复读），一致性问题不用担心了； 备份过程中也会拿MDL lock读锁，如果备份过程中有表结构更新操作，也可能会因为拿不到MDL写锁而阻塞，也会阻塞后续的所有数据更新动作； 针对上面问题，AliSQL提了个PR已经合入MariaDB，即尝试修改表的时候加个超时时间，如果过了超时时间还没有拿到MDL锁，则失败，等后续重试，这样至少不会阻塞正常的数据更新操作；   这里涉及了表锁中的一种：MDL锁\n   加全局读锁，可以将数据库设置为只读，还有一种办法，设置全局变量set global readonly=true，但是这种方式，风险更高：\n 通常这个属性还用来区分一个数据库是主库还是从从库，如果贸然修改这个变量，可能会造成一些其他应用的误判； 假如客户端申请了加全局锁且成功之后，如果客户端崩溃了，这个全局锁还是可以自动被释放掉的，库还是可以写入的。但是，如果客户端通过全局变量将库设置为了只读，那么客户端崩溃后，库也是只读的，不可写入的；  表锁 # 加表锁，主要有两种形式，lock tables\u0026hellip; 和 MDL lock。\nlock tables \u0026hellip; with read/write #   这种加锁方式，对应的解锁方式是 unlock tables\n  这种加锁方式，对其他线程能否读写、当前线程能否读写都做了明确的限制。假定当前线程p读表t1加读锁、对表t2加写锁，那么：\n 其他线程q是不能对t1执行写操作的，对t2也不能执行读操作，这个好理解； 当前线程p也是不能对t1执行写操作的，也不能对t2执行读操作；   可以理解成没有考虑锁的重入、读写排他性；",content:"根据加锁的范围，mysql中的锁可以分为：全局锁、表锁、行锁 3类。\n全局锁 # 全局锁，是对整个数据库实例进行加锁，如通过命令Flush tables with read lock (FTWRL)加全局读锁，锁定后，数据更新（增删改）、数据定义（建表、修改表等）都会被阻塞。\n其作用，主要是做全库逻辑备份，也就是把全表select出来存成文本。\n加全局读锁之后，再开始备份，但是有风险：\n 如果是对主库备份，开了全局读锁之后，库不能写入，意味着业务基本不可用； 如果是对从库备份，开了全局读锁之后，从库新同步过来的binlog假如有表结构修改的操作，会导致因为拿不到MDL（metadata lock）而阻塞，无法修改表结构这一个阻塞还好，更严重的是会导致后续所有的拿MDL读锁的操作失败，包括正常的更新数据。因此这种方法容易造成主从同步延迟；  **备份数据，为什么要加锁，能不能不加锁？**不能！数据一致性，这个很好理解，不解释！\n有没有不加全局锁的方法，有，但是要看引擎是否支持事务：\n  MyISAM引擎，不支持事务，只能用加全局读锁的方式锁定之后再开始备份\n  InnoDB引擎，支持事务，主库备份的时候通过\u0026ndash;single-transaction，开启独立的事务进行备份：\n 因为备份时候设定的事务隔离级别是RR（可重复读），一致性问题不用担心了； 备份过程中也会拿MDL lock读锁，如果备份过程中有表结构更新操作，也可能会因为拿不到MDL写锁而阻塞，也会阻塞后续的所有数据更新动作； 针对上面问题，AliSQL提了个PR已经合入MariaDB，即尝试修改表的时候加个超时时间，如果过了超时时间还没有拿到MDL锁，则失败，等后续重试，这样至少不会阻塞正常的数据更新操作；   这里涉及了表锁中的一种：MDL锁\n   加全局读锁，可以将数据库设置为只读，还有一种办法，设置全局变量set global readonly=true，但是这种方式，风险更高：\n 通常这个属性还用来区分一个数据库是主库还是从从库，如果贸然修改这个变量，可能会造成一些其他应用的误判； 假如客户端申请了加全局锁且成功之后，如果客户端崩溃了，这个全局锁还是可以自动被释放掉的，库还是可以写入的。但是，如果客户端通过全局变量将库设置为了只读，那么客户端崩溃后，库也是只读的，不可写入的；  表锁 # 加表锁，主要有两种形式，lock tables\u0026hellip; 和 MDL lock。\nlock tables \u0026hellip; with read/write #   这种加锁方式，对应的解锁方式是 unlock tables\n  这种加锁方式，对其他线程能否读写、当前线程能否读写都做了明确的限制。假定当前线程p读表t1加读锁、对表t2加写锁，那么：\n 其他线程q是不能对t1执行写操作的，对t2也不能执行读操作，这个好理解； 当前线程p也是不能对t1执行写操作的，也不能对t2执行读操作；   可以理解成没有考虑锁的重入、读写排他性；\n   MDL lock # 表的定义都记录在表的元信息里，要对表执行增删改查等DML操作，或者对表执行表结构修改等DDL操作时，都需要现获取表的MDL锁。增删改查就是MDL读锁，修改表结构就是拿MDL写锁。\nMDL锁也是是有可能导致数据库操作阻塞的。在前面描述数据库备份操作时，我们介绍了InnoDB通过\u0026ndash;single-transaction来进行备份的方法，其中描述了MDL读写锁排他性对备份过程、binlog主备同步延迟的影响。\n也介绍了如何尽量规避这个问题：尝试修改表结构（MDL写锁）时加个超时时间，避免长时间阻塞进而导致后续的数据更新操作失败（或者，导致主备同步延迟过大）。\n行锁 # 行锁，InnoDB执行引擎支持对加行锁，以前不支持行锁的时候，就要通过表锁来解决，先锁表，再修改、再解锁表，这种效率比较低。\n 执行引擎：推荐现在没有使用InnoDB执行引擎的更换数据库引擎为InnoDB； 代码写法：有些虽然更换了引擎，但是代码中还是用的lock tables、unlock tables，这种一般替换成begin、commit就可以了；  "}),a.add({id:299,href:"/tags/global-lock/",title:"global lock",description:"",content:""}),a.add({id:300,href:"/tags/lock-tables/",title:"lock tables",description:"",content:""}),a.add({id:301,href:"/tags/mdl-lock/",title:"mdl lock",description:"",content:""}),a.add({id:302,href:"/tags/table-lock/",title:"table lock",description:"",content:""}),a.add({id:303,href:"/blog/05%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8B/",title:"05索引原理：深入浅出索引（下）",description:"前面介绍了常见的查询类型，支持查询的常用数据结构和算法，然后介绍了InnoDB执行引擎B+树的优势，主要是和机械硬盘的特性结合起来实现高性能的读写，也描述了B+树层高与可存储的数据量的计算方式，等等吧。\n这里重点介绍下索引的设计、使用方面的一些知识点，下面讨论的都是InnoDB B+树。\nuser(id,name,age), pk(id),index(name)\n  主键索引\nb+树中索引节点存储的是关键字以及指针，指向指向索引节点或者数据节点的page。索引中的关键字，可以是一个列字段，也可以是多个列字段，如果是多个列字段的话，它们出现的顺序就是定义索引时写的顺序。\ninnodb主键索引是聚集索引，叶子节点中的数据直接包含了记录行的数据。\n  普通索引\n其他普通索引，比如id为主键，在name上创建索引，这种索引的叶子节点中记录的主键的id，如果要通过name去查age之类的其他字段信息，要先通过这里的name索引查到id，然后回表，也就是通过主键索引查找到对应的记录后（实际上是主键索引查找到指针对应的page，然后遍历page里面的各个记录找到的），再去拿到age等其他信息。\n所以普通索引这样查起来会多一次回表的操作。\n  覆盖索引\n假如说现在我想通过name，直接查找到对应的age行不行啊，不想先查到id，再回表查。不回表的话，就可以考虑索引覆盖，比如创建个索引index(name,age)，这样就会先通过这个组合索引中的name找到对应的叶子节点，叶子节点中也包含了age这个关键字，就可以直接返回age。\n当然name有可能重复，所以可能查询结果不是单条记录，那还得沿着这个第一次找到的节点，向右遍历叶子节点列表，知道name不满足为止。\n由于索引中包含了age，也就不需要回表了。\n  最左前缀原则\n创建组合（联合）索引之后，查询的时候一定要注意，要用最左匹配原则才能应用索引，否则用不上索引，为什么呢？比如我们定义索引的时候是index(name,age)，那么你查询到时候where age=xxx and name=yyy，这种就没有优先用name，查询比较的时候就用不上索引，但是where name=yyy and age=xxx就能用上索引。\n为什么会这样呢？b+数索引节点中关键字，是按照定义索引时字段的顺序设置的，比较的时候也是按照这个顺序来比较。\n 如何安排组合索引内的字段顺序？将更容易用到的放前面，这样可以提高复用的程度。 由于建立了索引index(a,b)，最左前缀可以在a上引用索引，也就不需要再单独为a建立索引index(a)了。 另外就是要考虑空间原则，是不是一定要(name，age)建联合索引，那就得考虑用的频率了，如果这种查询场景不多，查询效率要求也不高，那么确实不适合建立联合索引，浪费存储空间啊。但是也不能全表扫描那么慢吧，这个时候为name建个索引，回表查age，还是可以接受的。    索引下推\n对于组合索引index(a,b,c)，我们建议使用最左前缀匹配的方式来应用索引，那么如果查询的时候第一列是匹配的，第二列不配的，这种情况下会怎么处理呢？\n5.6以前的话，会直接根据匹配到的a回表，查出记录后再对比b是否匹配，不匹配再过滤掉，很明显这种效率是比较低的。\n5.6以后的话，引入了索引下推，什么意思呢，就是在组合索引上遍历的时候就直接比较其他几个索引列字段是否匹配，不匹配直接过滤掉，也不用回表了，减少了回表次数，效率自然也就高了。\n范围查询：说下范围查询大致是怎么工作的？\n最后说下范围查询，比如 user表上的索引有pk(id), age(name)，现在查询select name,age from user where age\u0026gt;25 and age\u0026lt;30 ，这个时候会现在index(age)这个索引上找到age\u0026gt;25的一个叶子节点，然后从这个节点开始，沿着叶子节点链表，直接向右遍历，因为都是按照age有序的嘛，每遍历一个叶子节点，回表查询name假如结果集，直到发现age\u0026lt;30不成立结束。\n  g",content:"前面介绍了常见的查询类型，支持查询的常用数据结构和算法，然后介绍了InnoDB执行引擎B+树的优势，主要是和机械硬盘的特性结合起来实现高性能的读写，也描述了B+树层高与可存储的数据量的计算方式，等等吧。\n这里重点介绍下索引的设计、使用方面的一些知识点，下面讨论的都是InnoDB B+树。\nuser(id,name,age), pk(id),index(name)\n  主键索引\nb+树中索引节点存储的是关键字以及指针，指向指向索引节点或者数据节点的page。索引中的关键字，可以是一个列字段，也可以是多个列字段，如果是多个列字段的话，它们出现的顺序就是定义索引时写的顺序。\ninnodb主键索引是聚集索引，叶子节点中的数据直接包含了记录行的数据。\n  普通索引\n其他普通索引，比如id为主键，在name上创建索引，这种索引的叶子节点中记录的主键的id，如果要通过name去查age之类的其他字段信息，要先通过这里的name索引查到id，然后回表，也就是通过主键索引查找到对应的记录后（实际上是主键索引查找到指针对应的page，然后遍历page里面的各个记录找到的），再去拿到age等其他信息。\n所以普通索引这样查起来会多一次回表的操作。\n  覆盖索引\n假如说现在我想通过name，直接查找到对应的age行不行啊，不想先查到id，再回表查。不回表的话，就可以考虑索引覆盖，比如创建个索引index(name,age)，这样就会先通过这个组合索引中的name找到对应的叶子节点，叶子节点中也包含了age这个关键字，就可以直接返回age。\n当然name有可能重复，所以可能查询结果不是单条记录，那还得沿着这个第一次找到的节点，向右遍历叶子节点列表，知道name不满足为止。\n由于索引中包含了age，也就不需要回表了。\n  最左前缀原则\n创建组合（联合）索引之后，查询的时候一定要注意，要用最左匹配原则才能应用索引，否则用不上索引，为什么呢？比如我们定义索引的时候是index(name,age)，那么你查询到时候where age=xxx and name=yyy，这种就没有优先用name，查询比较的时候就用不上索引，但是where name=yyy and age=xxx就能用上索引。\n为什么会这样呢？b+数索引节点中关键字，是按照定义索引时字段的顺序设置的，比较的时候也是按照这个顺序来比较。\n 如何安排组合索引内的字段顺序？将更容易用到的放前面，这样可以提高复用的程度。 由于建立了索引index(a,b)，最左前缀可以在a上引用索引，也就不需要再单独为a建立索引index(a)了。 另外就是要考虑空间原则，是不是一定要(name，age)建联合索引，那就得考虑用的频率了，如果这种查询场景不多，查询效率要求也不高，那么确实不适合建立联合索引，浪费存储空间啊。但是也不能全表扫描那么慢吧，这个时候为name建个索引，回表查age，还是可以接受的。    索引下推\n对于组合索引index(a,b,c)，我们建议使用最左前缀匹配的方式来应用索引，那么如果查询的时候第一列是匹配的，第二列不配的，这种情况下会怎么处理呢？\n5.6以前的话，会直接根据匹配到的a回表，查出记录后再对比b是否匹配，不匹配再过滤掉，很明显这种效率是比较低的。\n5.6以后的话，引入了索引下推，什么意思呢，就是在组合索引上遍历的时候就直接比较其他几个索引列字段是否匹配，不匹配直接过滤掉，也不用回表了，减少了回表次数，效率自然也就高了。\n范围查询：说下范围查询大致是怎么工作的？\n最后说下范围查询，比如 user表上的索引有pk(id), age(name)，现在查询select name,age from user where age\u0026gt;25 and age\u0026lt;30 ，这个时候会现在index(age)这个索引上找到age\u0026gt;25的一个叶子节点，然后从这个节点开始，沿着叶子节点链表，直接向右遍历，因为都是按照age有序的嘛，每遍历一个叶子节点，回表查询name假如结果集，直到发现age\u0026lt;30不成立结束。\n  g\n"}),a.add({id:304,href:"/blog/04%E7%B4%A2%E5%BC%95%E5%8E%9F%E7%90%86%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BA%E7%B4%A2%E5%BC%95%E4%B8%8A/",title:"04索引原理：深入浅出索引（上）",description:"索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。直接在几百页的书找一个关键词可能要找很久，但是通过附录中先通过首字母找到对应的关键词，再通过关键词对应页码找到书中对应页、对应内容，就会比较快。查词典、查电话本，都是类似的思想。\n查询类型：\n 等值查询； 区间查询；  几种索引模型：\n  hash\n这种只适合等值查询，接近O(1)的时间复杂度，不适合范围查询（比如key介于[k1,k2]之间的就得全量扫描了）。这类存储，主要有memcached及其他一些nosql存储；\n  有序数组\n在等值查询、范围查询场景中，性能都比较好，基本可以在O(log(n))时间复杂度内搞定。当然数据有序、没有重复等情况下，平均复杂度要坏一点。但是考虑到插入的场景，插入点位置及以后的数据要移动的，代价比较高。\n有序数组，只适用于静态存储引擎，不怎么变化的那种存储。\n  搜索树\n根据对树中索引节点key的数量以及对树的高度的不同，可以分为好几种，比较常见的有二叉搜索树、二叉平衡树、红黑树，这些都是二叉的，时间复杂度基本都是O(log(n))，但是考虑到平均时间复杂度二叉平衡树是最好的，但是它的插入操作涉及到大量的树调整步骤，开销较大，普通二叉搜索树的话又有可能退化为一个单支的链表，查询性能退化为O(n)。红黑树是一个比较好的选择，使用也比较广，它通过施加一些约束限制了左、右子树高度不会成为另一个的两倍，这比二叉平衡树左右子树高度差最多为1可松多了，减轻了树调整的开销。红黑树是用的比较多的。\n树的搜索效率取决于树的高度，如果树高度很高，那么查询效率自然就会比较低。考虑到机械硬盘随机访问慢的特性，每个索引节点都要取机械硬盘里面去加载的，这个很慢的。数据库设计出来是要存储大量数据的，索引关键字区分度再高，二叉树出度太低，树还是会很高的，这对存储大量数据（几千万上亿）的数据库系统来说，二叉树有点吃不消，所以B树、B+树出现了。\n试想下，二叉树的情况下，节点多了之后，树高度会很高的，每个索引节点都可能存储在机械硬盘上离散的位置，读取每个索引节点会很耗时的。\nB树是m叉树，但是B树中的非叶子节点既可能是索引节点，也可能是数据节点，数据节点之间没有形成一个有序链表，没有充分考虑到机械硬盘顺序读取效率高的特点，B+树考虑到了，所有非叶子节点都是索引节点，所有，叶子节点均为数据节点，且构成了一个有序的链表，正好能解决机械硬盘随机访问慢的问题，也能利用硬盘顺序读取快的优势。\n  m叉树中的这个m应该多大呢？这个取决于数据块的大小，以InnoDB的一个整数字段索引为例，这个N差不多是1200。树高4层的时候，就差不多可以存储17亿条数据了。\nps：类似的怎么计算呢？\n学习下怎么计算的：https://www.programmersought.com/article/65874297377/\n现代机械硬盘最大不知道多少，innodb里面定义的是索引中指针大小是6个字节，意味着2^(6*8)/2^40=256TB，这里的指针大小表示的是数据在表空间中的偏移量，可以理解成可以寻址256TB的硬盘空间？\ninnodb默认的pagesize是16KB，ok！\n 先算一个索引可以存多少指针：假定我们用bigint作为主键，8个字节，指针6字节，那一个索引节点可以存储16KB/14B=1170个关键字和指针。 再算一个叶子节点可以存多少记录：聚集索引里面叶子节点中，索引关键字是数据记录的一部分，至少大于8个字节了，我们就假定一行记录大约么为1KB吧。那么一个叶子节点可以存储记录数量为16KB/1KB=16。  现在我们笼统算法下：\n  假如树最大高度为2，那么就是根节点指针数量*每个叶子节点记录数量，可以存储1170x16=18720\n  假如数最大高度为3，那么就是1170^2*16=21902400=2190w\n  假如数最大高度为4，那么就是1170^3*16=25625808000=256亿\n  实际情况一般3层就可以满足绝大部分场景使用了，数据量大的话，也极少有业务会超过4层。所以存储很多的数据，查询效率也基本上是有保证的。\n每次查询索引节点，都代表了一次磁盘IO，所以通过主键索引查询，会比借助其他辅助索引查询、再回表的方式要快一些。\n指针6个字节，意味着可以寻址的索引地址空间很大的，256TB，哪有这么大的内存，这个东西也可以理解成磁盘上索引的偏移量，256TB的硬盘。\n但是看得出来，索引可能也很大，不一定能完全在硬盘中存储的下，也是按需加载的！\nps：为什么要用自增id作为主键，有什么好处，主要是为了避免插入时页分裂，b+树调整导致的效率低下：https://zhuanlan.zhihu.com/p/71022670\nps：innodb b+tree索引结构：https://www.programmersought.com/article/1411118316/",content:"索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。直接在几百页的书找一个关键词可能要找很久，但是通过附录中先通过首字母找到对应的关键词，再通过关键词对应页码找到书中对应页、对应内容，就会比较快。查词典、查电话本，都是类似的思想。\n查询类型：\n 等值查询； 区间查询；  几种索引模型：\n  hash\n这种只适合等值查询，接近O(1)的时间复杂度，不适合范围查询（比如key介于[k1,k2]之间的就得全量扫描了）。这类存储，主要有memcached及其他一些nosql存储；\n  有序数组\n在等值查询、范围查询场景中，性能都比较好，基本可以在O(log(n))时间复杂度内搞定。当然数据有序、没有重复等情况下，平均复杂度要坏一点。但是考虑到插入的场景，插入点位置及以后的数据要移动的，代价比较高。\n有序数组，只适用于静态存储引擎，不怎么变化的那种存储。\n  搜索树\n根据对树中索引节点key的数量以及对树的高度的不同，可以分为好几种，比较常见的有二叉搜索树、二叉平衡树、红黑树，这些都是二叉的，时间复杂度基本都是O(log(n))，但是考虑到平均时间复杂度二叉平衡树是最好的，但是它的插入操作涉及到大量的树调整步骤，开销较大，普通二叉搜索树的话又有可能退化为一个单支的链表，查询性能退化为O(n)。红黑树是一个比较好的选择，使用也比较广，它通过施加一些约束限制了左、右子树高度不会成为另一个的两倍，这比二叉平衡树左右子树高度差最多为1可松多了，减轻了树调整的开销。红黑树是用的比较多的。\n树的搜索效率取决于树的高度，如果树高度很高，那么查询效率自然就会比较低。考虑到机械硬盘随机访问慢的特性，每个索引节点都要取机械硬盘里面去加载的，这个很慢的。数据库设计出来是要存储大量数据的，索引关键字区分度再高，二叉树出度太低，树还是会很高的，这对存储大量数据（几千万上亿）的数据库系统来说，二叉树有点吃不消，所以B树、B+树出现了。\n试想下，二叉树的情况下，节点多了之后，树高度会很高的，每个索引节点都可能存储在机械硬盘上离散的位置，读取每个索引节点会很耗时的。\nB树是m叉树，但是B树中的非叶子节点既可能是索引节点，也可能是数据节点，数据节点之间没有形成一个有序链表，没有充分考虑到机械硬盘顺序读取效率高的特点，B+树考虑到了，所有非叶子节点都是索引节点，所有，叶子节点均为数据节点，且构成了一个有序的链表，正好能解决机械硬盘随机访问慢的问题，也能利用硬盘顺序读取快的优势。\n  m叉树中的这个m应该多大呢？这个取决于数据块的大小，以InnoDB的一个整数字段索引为例，这个N差不多是1200。树高4层的时候，就差不多可以存储17亿条数据了。\nps：类似的怎么计算呢？\n学习下怎么计算的：https://www.programmersought.com/article/65874297377/\n现代机械硬盘最大不知道多少，innodb里面定义的是索引中指针大小是6个字节，意味着2^(6*8)/2^40=256TB，这里的指针大小表示的是数据在表空间中的偏移量，可以理解成可以寻址256TB的硬盘空间？\ninnodb默认的pagesize是16KB，ok！\n 先算一个索引可以存多少指针：假定我们用bigint作为主键，8个字节，指针6字节，那一个索引节点可以存储16KB/14B=1170个关键字和指针。 再算一个叶子节点可以存多少记录：聚集索引里面叶子节点中，索引关键字是数据记录的一部分，至少大于8个字节了，我们就假定一行记录大约么为1KB吧。那么一个叶子节点可以存储记录数量为16KB/1KB=16。  现在我们笼统算法下：\n  假如树最大高度为2，那么就是根节点指针数量*每个叶子节点记录数量，可以存储1170x16=18720\n  假如数最大高度为3，那么就是1170^2*16=21902400=2190w\n  假如数最大高度为4，那么就是1170^3*16=25625808000=256亿\n  实际情况一般3层就可以满足绝大部分场景使用了，数据量大的话，也极少有业务会超过4层。所以存储很多的数据，查询效率也基本上是有保证的。\n每次查询索引节点，都代表了一次磁盘IO，所以通过主键索引查询，会比借助其他辅助索引查询、再回表的方式要快一些。\n指针6个字节，意味着可以寻址的索引地址空间很大的，256TB，哪有这么大的内存，这个东西也可以理解成磁盘上索引的偏移量，256TB的硬盘。\n但是看得出来，索引可能也很大，不一定能完全在硬盘中存储的下，也是按需加载的！\nps：为什么要用自增id作为主键，有什么好处，主要是为了避免插入时页分裂，b+树调整导致的效率低下：https://zhuanlan.zhihu.com/p/71022670\nps：innodb b+tree索引结构：https://www.programmersought.com/article/1411118316/\n"}),a.add({id:305,href:"/blog/03%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%A0%E6%94%B9%E4%BA%86%E6%88%91%E8%BF%98%E7%9C%8B%E4%B8%8D%E8%A7%81/",title:"03事务隔离：为什么你改了我还看不见",description:"数据库事务（刚性事务）\n事务特性：ACID\n Atomic Consistency Isolation Durability  事务隔离性及事务隔离级别：\n read uncommited read committed repeatable read serializable  在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念； 而“串行化”隔离级别下直接用加锁（读写冲突、写写冲突）的方式来避免并行访问。  事务隔离性级别通过变量 transaction_isolation 来设置。\nMVCC：\n在执行更新操作的时候，也会对应的插入一行“回滚记录”，用于MVCC（多版本并发控制）中构建不同时间启动的事务的视图，这主要是为了维持一个可重复读的视图。\n比如现在执行操作假如现在c=1，执行update c=2, c=3, c=4的操作，那么对应的就会插入四行回滚记录，将2回滚为1，将3回滚为2，将4回滚为3。\n三个更新操作的时刻t1、t2、t3，相当于确立了三个边界，边界时间点前后可能会有不同的事务启动、结束。那些依然还未结束的事务，通过他们的启动时间与回滚记录插入时的时间做对比，就可以找到应该依次执行哪些回滚记录来恢复到启动事务时的数据库状态，通过这种方式来重建一个可重复读的视图。\n这就是MVCC的要义。\n这些回滚日志，多了之后也会占用存储空间，浪费资源，需要清除？但是假如有个事务是时刻t启动的，那么时刻t之后的回滚日志都是要保留的，如果这个事务执行时间很长，就会导致回滚日志积累很多，浪费资源。因此不建议使用长事务。\n查找执行时间超过60s的长事务：\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60  了解下这个事务统计表几个比较有用的字段：\nmysql\u0026gt; desc innodb_trx; +----------------------------+-----------------+------+-----+---------+-------+ | Field | Type | Null | | +----------------------------+-----------------+------+-----+---------+-------+ | trx_id | bigint unsigned | NO | 事务id | | trx_state | varchar(13) | NO | 事务状态，如RUNNING | | trx_started | datetime | NO | 事务启动时间 | .",content:"数据库事务（刚性事务）\n事务特性：ACID\n Atomic Consistency Isolation Durability  事务隔离性及事务隔离级别：\n read uncommited read committed repeatable read serializable  在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n 在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。 在“读提交”隔离级别下，这个视图是在每个SQL语句开始执行的时候创建的。 这里需要注意的是，“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念； 而“串行化”隔离级别下直接用加锁（读写冲突、写写冲突）的方式来避免并行访问。  事务隔离性级别通过变量 transaction_isolation 来设置。\nMVCC：\n在执行更新操作的时候，也会对应的插入一行“回滚记录”，用于MVCC（多版本并发控制）中构建不同时间启动的事务的视图，这主要是为了维持一个可重复读的视图。\n比如现在执行操作假如现在c=1，执行update c=2, c=3, c=4的操作，那么对应的就会插入四行回滚记录，将2回滚为1，将3回滚为2，将4回滚为3。\n三个更新操作的时刻t1、t2、t3，相当于确立了三个边界，边界时间点前后可能会有不同的事务启动、结束。那些依然还未结束的事务，通过他们的启动时间与回滚记录插入时的时间做对比，就可以找到应该依次执行哪些回滚记录来恢复到启动事务时的数据库状态，通过这种方式来重建一个可重复读的视图。\n这就是MVCC的要义。\n这些回滚日志，多了之后也会占用存储空间，浪费资源，需要清除？但是假如有个事务是时刻t启动的，那么时刻t之后的回滚日志都是要保留的，如果这个事务执行时间很长，就会导致回滚日志积累很多，浪费资源。因此不建议使用长事务。\n查找执行时间超过60s的长事务：\nselect * from information_schema.innodb_trx where TIME_TO_SEC(timediff(now(),trx_started))\u0026gt;60  了解下这个事务统计表几个比较有用的字段：\nmysql\u0026gt; desc innodb_trx; +----------------------------+-----------------+------+-----+---------+-------+ | Field | Type | Null | | +----------------------------+-----------------+------+-----+---------+-------+ | trx_id | bigint unsigned | NO | 事务id | | trx_state | varchar(13) | NO | 事务状态，如RUNNING | | trx_started | datetime | NO | 事务启动时间 | ... | trx_tables_locked | bigint unsigned | NO | 增删记录会锁表的 | ... | trx_rows_locked | bigint unsigned | NO | 更新记录会锁行的 | | trx_rows_modified | bigint unsigned | NO | 修改的行数量 | ... | trx_isolation_level | varchar(16) | NO | 当前事务隔离级别 | ... +----------------------------+-----------------+------+-----+---------+-------+  "}),a.add({id:306,href:"/blog/02%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E4%B8%80%E6%9D%A1sql%E6%9B%B4%E6%96%B0%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/",title:"02一条SQL更新语句是如何执行的",description:"这里涉及的日志类型：\n  执行引擎层：innodb redolog\n  mysql服务层：mysql binlog\n  买东西赊账为例，老板通常有个账本，上面记录了所有人总的赊账情况，但是忙的时候是来不及查、计算的，可能就会在一个粉板上记录当前次的赊账情况，等打烊之后再去算，算完更新到账本上。\nmysql的设计者，采用了类似老板记账的方式，来提高更新效率。\nWAL：write ahead log，关键点就是：\n 先写日志，再写磁盘 也就是先写粉板，不忙的时候再写账本；   WAL log写操作基本只是追加，磁盘顺序写，效率高；写记录到磁盘还要考虑B+树特性、磁盘特性，要找到在哪里插入，涉及到多次随机读，效率是比较差的。\n所以说先写WAL这里是提高更新效率是没有问题的，当然了，也提供了崩溃后恢复的一种保证。\n 具体说，就是innodb引擎会：\n 先把记录写到redo log里面； 再更新内存，（这个时候就算更新完成了）； 然后比较空闲的时候再写回磁盘。  但是如果粉板写满了怎么办呢？老板只能停下手中的活，先把粉板上的赊账记录算完腾到账本上，然后擦掉粉板腾出新的空间，然后再继续赊账。\n类似地，innodb的redo log也是固定大小的（和粉板类似），从头到尾写满了，就得再从头写。redolog维护了两个指针：\n write pos，写最新赊账记录的位置，++，到头后再开始； checkpoint，表示已经将对应操作同步到磁盘数据文件的位置，相当于腾空的粉板位置，可以继续记录赊账位置。  当writepos追上checkpoint的时候，表示写满了，这时候mysql就得和老板一样停下来算账，不能接受新的更新请求，这样把checkpoint推进以下之后，再继续接受更新请求。\n这样即使数据库运行期间崩溃了，但是有了这个redolog，就可以将之前的操作全部恢复，不会丢失，这个能力称之为crash-safe。\n这里的write pos、checkpoint的作用，是为了提高更新效率，延时写入磁盘用的。\n一个更新操作是如何执行的？\n  当执行一个更新操作时，执行器找到记录对应的行，请求执行引擎返回行数据，如果行数据在内存中，执行引擎就从内存直接返回，反之还需要从磁盘上读回来返回。执行器拿到行数据之后完成更新，比如某列N=N+1，并请求执行引擎更新行数据。\n  执行引擎将数据更新到内存中，然后写redo log，然后返回给执行引擎成功，表示进入prepare状态，随时可提交。\n 为什么不先写redolog，再写内存？\n没有实质区别吧，不都写了内存嘛。是担心数据不一致问题吗？别担心，mysql用了MVCC的，（可重复读级别）不会出现不可重复读的。\n   执行器收到正常响应后，生成binlog并写入磁盘binlog文件，然后对刚才的操作继续请求置引擎发起commit操作。\n 如果写binlog失败会怎样？mysql中有个选项binlog_error_action，用来控制如果binlog写失败：\n  上述变量，其默认值是ABORT_SERVER，即mysqld退出。需要排除binlog写失败原因（如磁盘满、inode耗光等）后再启动起来。\n  还可以将上述变量设置为IGNORE_ERROR，就是写binlog失败就失败，继续执行，此时就会导致没有生成binlog，无法同步给slave，master-slave数据就会变得不一致。而且也会影响到数据备份。一般是不太能接受的。\n  重启后，innodb中有prepare阶段的redo log（未commited），这个时候binlog中又没有对应的binlog，此时就会rollback掉。",content:"这里涉及的日志类型：\n  执行引擎层：innodb redolog\n  mysql服务层：mysql binlog\n  买东西赊账为例，老板通常有个账本，上面记录了所有人总的赊账情况，但是忙的时候是来不及查、计算的，可能就会在一个粉板上记录当前次的赊账情况，等打烊之后再去算，算完更新到账本上。\nmysql的设计者，采用了类似老板记账的方式，来提高更新效率。\nWAL：write ahead log，关键点就是：\n 先写日志，再写磁盘 也就是先写粉板，不忙的时候再写账本；   WAL log写操作基本只是追加，磁盘顺序写，效率高；写记录到磁盘还要考虑B+树特性、磁盘特性，要找到在哪里插入，涉及到多次随机读，效率是比较差的。\n所以说先写WAL这里是提高更新效率是没有问题的，当然了，也提供了崩溃后恢复的一种保证。\n 具体说，就是innodb引擎会：\n 先把记录写到redo log里面； 再更新内存，（这个时候就算更新完成了）； 然后比较空闲的时候再写回磁盘。  但是如果粉板写满了怎么办呢？老板只能停下手中的活，先把粉板上的赊账记录算完腾到账本上，然后擦掉粉板腾出新的空间，然后再继续赊账。\n类似地，innodb的redo log也是固定大小的（和粉板类似），从头到尾写满了，就得再从头写。redolog维护了两个指针：\n write pos，写最新赊账记录的位置，++，到头后再开始； checkpoint，表示已经将对应操作同步到磁盘数据文件的位置，相当于腾空的粉板位置，可以继续记录赊账位置。  当writepos追上checkpoint的时候，表示写满了，这时候mysql就得和老板一样停下来算账，不能接受新的更新请求，这样把checkpoint推进以下之后，再继续接受更新请求。\n这样即使数据库运行期间崩溃了，但是有了这个redolog，就可以将之前的操作全部恢复，不会丢失，这个能力称之为crash-safe。\n这里的write pos、checkpoint的作用，是为了提高更新效率，延时写入磁盘用的。\n一个更新操作是如何执行的？\n  当执行一个更新操作时，执行器找到记录对应的行，请求执行引擎返回行数据，如果行数据在内存中，执行引擎就从内存直接返回，反之还需要从磁盘上读回来返回。执行器拿到行数据之后完成更新，比如某列N=N+1，并请求执行引擎更新行数据。\n  执行引擎将数据更新到内存中，然后写redo log，然后返回给执行引擎成功，表示进入prepare状态，随时可提交。\n 为什么不先写redolog，再写内存？\n没有实质区别吧，不都写了内存嘛。是担心数据不一致问题吗？别担心，mysql用了MVCC的，（可重复读级别）不会出现不可重复读的。\n   执行器收到正常响应后，生成binlog并写入磁盘binlog文件，然后对刚才的操作继续请求置引擎发起commit操作。\n 如果写binlog失败会怎样？mysql中有个选项binlog_error_action，用来控制如果binlog写失败：\n  上述变量，其默认值是ABORT_SERVER，即mysqld退出。需要排除binlog写失败原因（如磁盘满、inode耗光等）后再启动起来。\n  还可以将上述变量设置为IGNORE_ERROR，就是写binlog失败就失败，继续执行，此时就会导致没有生成binlog，无法同步给slave，master-slave数据就会变得不一致。而且也会影响到数据备份。一般是不太能接受的。\n  重启后，innodb中有prepare阶段的redo log（未commited），这个时候binlog中又没有对应的binlog，此时就会rollback掉。\n   执行引擎把刚才写入的redolog的状态修改为commit状态，更新完成。\n 万一这一步执行的时候，服务crash了怎么办？这个时候innodb也写了redo log了，服务层也写了binlog了，怎么办呢？\n  如果redo log里面已经修改成commited了，重启后，crash recover的时候innodb是可以恢复这个数据的；\n  如果redo log里面没有改成commited呢？以为都是两阶段提交，因为binlog里面有记录，但是redo log没有改成commited，所以可能要服务层发起commit操作？\nfixme 以后再确定下这个问题吧！\n     执行引擎在合适的（通常是空闲的）时候将redolog中数据同步到磁盘数据文件。\n  注意这里将 redolog 拆成两部分prepare+commit，这就是典型的两阶段提交。为什么要两阶段提交，是为了保持两份日志文件的完整性，让两份日志文件之间的逻辑一致。\n不妨从恢复数据库到半个月内任意一秒t的状态，从这个角度来思考这个问题？\n 如何恢复？首先t之前的最近的一次全量备份，先恢复到临时数据库中，然后找这次全量备份之后t之前的binlog，并恢复到临时数据库中。然后将临时数据库中的数据恢复到线上。 再看为什么用两阶段提交？不用就不能保证两个日志文件的完整性（c=c+1）：  假如先写完redolog再写binlog，redolog将c=0改成了1，但是binlog写成功前挂掉了，这样本地数据是c=1，但是归档日志同步给别人后丢了一个事务操作，或者自己重启后恢复的时候也丢了一个操作c变成了0。 假如先写完binlog后再写redolog，binlog中记录了c=c+1=1，但是redolog写失败了，此时库中数据其实是0，如果binlog同步给别人，按binlog恢复出的数据是1，而不是0，也不一致。如果是挂掉之后恢复，能一致都是1。    可见如果不适用prepare-commit两阶段提交的话，日志中记录的状态和真实的存储情况就会出现不一致。\n不只是数据库误删表之类的才会有恢复的需要，其实mysql集群扩容，比如多加几个读副本，也是需要这里的全量备份+binlog同步来完成“数据恢复”的。\nbinlog是mysql服务层面记录的原始操作日志，比如给某列+1，innodb的redolog是物理日志，记录的是在哪个物理页上写什么数据，binlog才是master-slave同步用的，这个在功能上是和raft中的wal log功能定位一致的。\nrelog的初衷，只是为了提高更新的效率，而非实现master-slave的数据一致性。binlog才是为了追求数据一致性的。wal只是一种操作上的描述，raft中的也是叫wal，但是也应该看到都叫wal，但是这只是一种策略，实现出来的实际功能、定位可能是完全不同的。\nredolog空间是有限的，毕竟它是为了提高更新效率用的，mysql是追加写的，写完一个binlog文件继续写下一个binlog文件，不会覆盖以前的，它的定位是要实现主从节点的数据同步，所以binlog日志也称为归档日志，是归档用的，用来实现主从间数据同步的。\n举一反三：\n联想到了raft算法中，为了保证数据强一致的效果，也采取了WAL的方式。比如master收到一个更新请求的时候，它会写本地log，并维护了几个索引值nextIndex、commitIndex，nextIndex是下次准备同步给slave节点的日志的索引位置，但是同步给很多slave节点的过程是并发的，可能有的日志索引项在某些节点上有冲突，没有收到多数投票，或者master更新比较快，这都会导致master这边的commitIndex\u0026lt;nextIndex。commitIndex表示收到了多数的投票master已经提交到状态机的日志项的索引位置。commitIndex也会同步给其他的节点，其他节点可以把commitIndex当做为一个可以可靠的对本地log进行持久化的参考值，commitIndex之前的日志项都可以提交到状态机，写入到磁盘数据文件，完成持久化。而commitIndex之后的日志条目，都是有可能会被作为的，这通常和分布式系统中出现分区有关系。\n我们可以看到，这里的wal日志，write ahead log，其本质就是在真正的完成一项操作之前，先日志记录成功，后续就可以有个保证，即出现失败后也可以进行可靠地重试，不至于数据出现丢失。\n两个比较关键的参数：\n  redo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。这个参数我建议你设置成 1，这样可以保证 MySQL 异常重启之后数据不丢失。\n  sync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。这个参数我也建议你设置成 1，这样可以保证 MySQL 异常重启之后 binlog 不丢失。\n  另外，“两阶段提交”也是分布式系统中保证“数据逻辑”一致性的常用方案。\n另外备份的频率怎么决定呢？一周一次全量备份，还是一天一次。这个要根据“业务重要性”、“成本”、以及“可允许的最长恢复时间”来决定。\n 业务重要，预算客观，那就尽量减少恢复时间，一天一次备份； 如果不是那么重要，预算吃紧，也对较长的数据恢复时间有一定的容忍度，那么就一会走一次备份。  "}),a.add({id:307,href:"/tags/update/",title:"update",description:"",content:""}),a.add({id:308,href:"/blog/01%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84%E4%B8%80%E6%9D%A1sql%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%E6%98%AF%E5%A6%82%E4%BD%95%E6%89%A7%E8%A1%8C%E7%9A%84/",title:"01一条SQL查询语句是如何执行的",description:"MySQL基础架构\nmysql基础架构示意图，及主要流程介绍\nmysql 连接及内存管理\nmysql 8.0删除了查询缓存，为什么：https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/\n优化器：存在多个索引，应该用哪一个？\nmysql select语句中不存在的列，是在哪个阶段分析出来的呢？分析器\nmysqld程序入口:\n main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/main.cc#L23:12 mysqld_main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/mysqld.cc#L7680:5  ",content:"MySQL基础架构\nmysql基础架构示意图，及主要流程介绍\nmysql 连接及内存管理\nmysql 8.0删除了查询缓存，为什么：https://mysqlserverteam.com/mysql-8-0-retiring-support-for-the-query-cache/\n优化器：存在多个索引，应该用哪一个？\nmysql select语句中不存在的列，是在哪个阶段分析出来的呢？分析器\nmysqld程序入口:\n main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/main.cc#L23:12 mysqld_main: https://sourcegraph.com/github.com/mysql/mysql-server/-/blob/sql/mysqld.cc#L7680:5  "}),a.add({id:309,href:"/tags/select/",title:"select",description:"",content:""}),a.add({id:310,href:"/tags/cas/",title:"cas",description:"",content:""}),a.add({id:311,href:"/tags/cmpxchg/",title:"cmpxchg",description:"",content:""}),a.add({id:312,href:"/tags/futex/",title:"futex",description:"",content:""}),a.add({id:313,href:"/categories/go%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"go设计实现",description:"",content:""}),a.add({id:314,href:"/blog/2021-04-17-locks%E5%AE%9E%E7%8E%B0%E9%82%A3%E4%BA%9B%E4%B8%8D%E4%B8%BA%E4%BA%BA%E7%9F%A5%E7%9A%84%E6%95%85%E4%BA%8B/",title:"Locks实现:背后不为人知的故事",description:"从事软件开发多年的你，真的了解locks背后的那些故事吗？锁是如何实现的，无锁真的是没有任何同步吗，为什么总是谈锁色变，锁究竟有哪些开销。本文将结合go sync.Mutex讨论下这些问题。",content:"从事软件开发多年的你，真的理解locks背后的那些故事吗？锁是如何实现的，无锁指的又是什么，无锁真的移除了任何同步操作吗？为什么大家总是谈锁色变，锁的开销真的有那么大吗，平时编码中又该注意些什么呢？本文将结合go sync.Mutex对这些问题进行讨论。\n并发：我们关心什么 # 并发编程，开发人员应该对原子性、指令重排有深刻的认识。\n原子性 # 大家都了解过数据库事务的原子性，类似地，程序中也经常有些操作也需要达到类似的效果——被某种类似事务的机制“保护”起来，要么全部执行要么全部不执行。通常我们将这样需要保护的代码段称为临界区。我们希望临界区内的代码要么全部执行要么全部不执行，达到这种原子性的效果。\n其实不只是代码段，给一个int变量赋值，也需要考虑原子性，因为在不同的操作系统、处理器平台上，可能一个简单的int变量赋值需要涉及多条机器指令，而在多条指令执行期间，则可能发生各种事件，比如被其他CPU核的赋值指令写乱了同一变量的数据。设想下一个int变量4字节，但是处理器平台只有16位mov指令。再或者执行i++（i为int类型）操作，实际上是包含了read-modify-write三个操作，这几个操作中间也可能插入其他指令执行。当然一条机器指令也可能不是原子的，比如 add src, dst，src和dst都是内存地址，这里就涉及到读取src和dst、计算、写回dst的多个操作……更不用说一个包含了多个字段的struct结构体的赋值了。\n这类原子性问题，可以通过一些相当低级的原子操作来保证，如int变量i++，可以考虑lock add指令（假定操作数位宽和int变量相同），稍复杂的数据结构（如struct）也可以使用一些“高级锁”来做同步保证，如go中的sync.Mutex。\n指令重排 # 指令重排的根源在于CPU的设计，古老的CPU只有一条取指、译码、执行、访存、写回的功能电路。联想下假如一个单线程程序执行阻塞网络IO的时候会发生什么，整个程序全阻塞在这里干不了其他的。CPU也存在类似问题，假如一条指令执行过程中因为数据没ready的问题不能执行，或者碰到多CPU多核间cache一致性同步，那CPU会stall，后续的指令都无法执行。\n所以CPU为了提高指令吞吐，增加了多条流水线设计，可以同时执行多条指令的取指、译码、执行、访存、写回，当然这其中有些指令是有数据依赖的，现代处理器支持寄存器重命名、指令乱序执行、重排序缓冲等功能，都是保证CPU执行效率的常用手段。如果想了解这方面的内容，see Computer Architecture: Dynamic Execution Core及系列课程Computer Architecture。这里贴一张超标量处理器的简图，方便大家理解这些优化手段所在的位置：\n 为什么要指令重排：\n为什么要指令重排呢？\n因为希望提高cpu指令吞吐，就要并行执行指令，要并行执行指令，就要分析出哪些指令之间有数据依赖的，表面上一个架构寄存器RAX可能被相邻多条指令使用，但是可能是一个伪数据依赖，就需要通过分析、寄存器重命名（如RAX重命名为物理寄存器R11）来消除伪数据依赖，从而允许其在执行阶段并行执行（out-of-order）。\n一条指令的执行过程，会分为多个阶段，有些阶段是按序执行的（in-order），有些则是乱序执行的（out-of-order）。在指令乱序执行之后，可能会对程序正确性造成影响？影响究竟有多大，就需要参考硬件内存一致性模型，比如Intel x86处理器采用的是TSO模型（Total Store Order）, see x86-TSO: A Rigorous and Usable Programmer's Model for x86 Multiprocessors。\n指令重排带来的问题：\n指令在CPU乱序执行，在某些并发场景下，可能会带来一些微妙的问题。比如：\ntype num struct { a int b int } n := \u0026amp;num{} go func() { n.a = 1; n.b = 2; }() // g1 go func() { n.a = 2; n.b = 1; }() // g2  你们说最终n.a，n.b的结果是多少呢？不确定的，虽然go现在支持64位系统，现在处理器基本也都有64位mov指令，对a、b单独赋值都是原子的，但是对n整体的赋值不是。由于没有对n做保护，g1、g2中的赋值指令也没有什么数据一来，到时候乱序执行，g1 g2执行完成后，\u0026lt;n.a,n.b\u0026gt;的可能结果是：\u0026lt;1, 2\u0026gt; \u0026lt;1, 1\u0026gt; \u0026lt;2,1\u0026gt; \u0026lt;2,2\u0026gt;，这几种都有可能，而不只是有\u0026lt;1,2\u0026gt; \u0026lt;2,1\u0026gt;两种可能。\n这就是指令重排造成的影响，如果我们在出现了指令重排的情况下，去做一些关键的判断逻辑，可能就会带来严重的bug。\n这里重新回顾了下原子性、指令重排的含义，以及对程序正确性可能带来的影响，下面我们将尝试进一步考虑如何解决这些问题。\n内存屏障：阻止指令重排 # 首先，我们看如何解决指令重排序问题，解铃还须系铃人，CPU流水线乱序执行带来的问题，还需要CPU自己提供解决方案。CPU如何阻止指令重排序呢？\n内存屏障，可以用来阻止屏障前后的指令共同参与重排序，保证屏障后的指令不会出现在屏障前执行，保证屏障前的指令不会在屏障后执行。相当于屏障之前和之后确立了happens-before关系，保证了屏障之前的操作对屏障之后的操作都是可见的。\nCPU中通常提供了如下几条指令，用以建立内存屏障：\n lock：指令前缀，修饰指令保证指令执行时的排他性、原子性和完全内存屏障 lock cmpxchg：cmpxchg比较并交换，配合lock前缀实现CAS mfence：完全内存屏障（load+store） lfence：读内存屏障（load） sfence：写内存屏障（store）  一些库函数或者编程语言提供的标准库，可以选择上述某汇编指令来实现内存屏障，或者实现CAS（基本是包装下lock cmpxchg），并进一步实现各种高级锁，如spinlock、sync.Mutex。\n在继续介绍内存屏障的内容之前，先说明下lock prefix的工作原理。lock prefix的使用，顾名思义，就是在一些涉及访存的指令时，编码时在指令前面添加一个前缀lock。\n这个前缀有什么用呢？处理器碰到lock前缀的指令时会生成一个lock信号，这个信号会发送到总线上对要访问的操作数地址进行锁定，意思就是在当前这条指令结束之前，其操作数所在的内存区域不允许被其他指令访问。\n通过这种方式保证了当前这条指令操作的原子性。\n ps: 前面提到了lock指令修饰、mfence指令都可以构建“完全内存屏障”，都涉及到cache invalidation的操作，自然能够保证多核多线程下的可见性问题。\n架构设计层面，关于lock prefix的功能描述，详细可以阅读《Intel Architecture Software Developer Manual》，其中有提到lock prefix能够确定total ordering。\n设计实现层面，我们可以结合当今一般处理器设计的部件store buffer、cache、invalidate queue、rob来推导下它可能会如何实现“架构设计”中设定的lock prefix的功能：\n1）很早的处理器是直接锁总线，\n2）现在处理器都支持cache，lock prefix的实现也更聪明了，通过cache locking以及cache coherency protocol来实现单条指令读写的原子性，另外lock prefix会drain store buffer（落到cache触发一致性协议，通知其他处理器invalidate），其他处理器上遇到lock prefix也会drain invalidate queue。\n因此，lock prefix + instruction如果从内存屏障的功能上来看的话，它其实就和 mfence 是一样的效果，构建的是完全内存屏障。关于这些，stackoverflow上也有相关的讨论，感兴趣可以查看：\nsee： https://stackoverflow.com/a/52910647/3817040 see：https://stackoverflow.com/questions/4232660/which-is-a-better-write-barrier-on-x86-lockaddl-or-xchgl see：https://stackoverflow.com/questions/40409297/does-lock-xchg-have-the-same-behavior-as-mfence\n 内存屏障：到底是什么 # 写并发程序，Happens-Before关系经常挂嘴边，Happens-Before关系是很容易理解的，因为它是一个编程语言的内存模型明确定义的，像Java、Go都有对内存模型的清晰定义，但是有的语言没有。举几个例子：go中包级别变量的初始化操作与包内 func init()之间存在Happens-Before关系，一个锁的Unlock和下次的Lock之间也存在HB关系，chan的send、recv之间也存在HB关系……\n我们想要理解的是Happens-Before定义好之后，是如何实现的？当然是借助内存屏障了。那内存屏障怎么实现的，通过处理器提供的上述几条指令。那我想再问下这几条指令干了啥，为什么这几条指令就可以实现内存屏障。\n计算机中包含了太多分层的设计思想，硬件对大多数软件开发人员来说是个黑盒，似乎管好分内的事，永远将它当做一个黑盒就好了。\nWell，处理器到底怎么实现内存屏障的还是比较吸引我，上面的所有回答，对我没有什么实质的帮助，那就来看看硬件层面是怎么实现的。如果不了解硬件设计、工作原理，只站在软件角度，是很难搞明白的，这个是很现实的问题，尽管了解了之后会发现很简单，但是钻到这里也确实需要时间。\n内存屏障类型 #  全内存屏障（mfence）：barrier之前的load/store操作均比之后的先完成，且前后的指令不能共同参与指令重排序； 读屏障（lfence）：barrier之前的load比之后的load先完成； 写屏障（sfence）：barrier之前的store比之后的store先完成；  不同的处理器，均提供了自己的屏障指令，但是这些指令不管有什么异同，最终都与硬件设计相关，所以来看下现代处理器的一个大致设计。\n处理器架构 # 下面是一个用来解释内存屏障的精简的处理器架构示意图，大约包含如下几部分。\n  多个CPU或CPU Core之间通过总线连接； CPU通过总线与主存（memory）连接； 每个CPU都有自己的本地cache，通过cache一致性协议（如MESI/MESIF）与其他CPU Core维护一个一致的数据视图；  说起这里的一致性视图，我建议读者尝试了解下，会更好：\n 硬件内存一致性模型 编程语言内存模型  下面结合上图，我们介绍下一此数据更新操作涉及的过程。\n引入store buffer # CPU对cacheline的修改，若直接落cache，一致性协议会引入不小的开销（执行cache一致性协议），CPU会stall执行的指令。为了提高指令吞吐，这里引入了store buffer。\n数据更新不直接写cacheline而是先写到store buffer，后面需要时再落cache并通知其他cache失效（执行cache一致性协议），这样CPU就可以减少stall继续执行指令。\n 引入invalidate queue # CPU cache更新cacheline后，通知其他CPU更新cache，需通过cache一致性协议，如MESI/MESIF消息invalidate。\n正常来说，收到此通知的CPU应从cache中将对应cacheline标记为无效，但是如果立即执行这个动作的话，CPU会频繁被阻断执行，所以CPU中引入了invalidate queue，收到invalidate通知后缓存起来并立即回复ACK，但延迟处理。\n必要性及引入的问题 # 这么设计的必要性：\n 减少CPU更新本地cacheline、响应一致性协议invalidate通知导致的CPU stall问题，提高CPU整体利用率。 另外storebuffer、invalidate queue使我们有了指令重排的契机。  这么设计引入的问题：\n store buffer：本地cache更新不能立即被其他CPU或者CPU core观测到了，写操作对外不可见； invalidate queue：本地cache没有立即更新数据，上层应用看不到其他CPU更新的数据； cache一致性协议：它就是用来解决多个CPU共享一致性视图而设计的，但它只是一个协议，具体不同硬件设计的时候，某些屏障指令实现的时候要通过这里的cache一致性协议来保证多CPU、多核数据视图的一致性（可以参考硬件内存一致性模型、cache一致性协议相关的知识，加深理解）；  处理器执行操作变化 # 如果没有store buffer、invalidate queue，MESI和cache如何工作？\n 当包含变量a的cacheline，其被CPU 0和CPU 1共享，当CPU 0更新该cacheline之后，会发送invalidate给CPU 1，CPU 1随即把对应的cacheline标记为invalidate； 当CPU 1下次读取变量a的cacheline时，发现标记为了无效，此时发出read请求，CPU 0观测到自己这边对应的cacheline是modified状态，cacheline是最新的，此时会将对应cacheline数据发送给CPU 1，这样CPU 1就观测到了最新的数据； CPU 0中cacheline何时写回主存？可能是被淘汰的时候，也可能是别人read的时候，这个我们先不关心。  如果引入了store buffer、invalidate queue之后，又该如何工作呢？\n 必须要有办法，将该store buffer中的更新，通知到其他CPU，这就是write barrier干的事情。它就是暂停CPU 0执行，并将CPU 0把store buffer中记录的一些更新应用到cache中，此时会触发cache一致性协议MESI通知CPU 1 cacheline invalidate； 必须要有办法，将CPU 1中invalidate queue记录下来的invalidate对应的cacheline及时清理掉，这就是read barrier干的事情。它就是暂停CPU 1执行，将其invalidate queue中的每个invalidate请求对应的cacheline全部标记为无效，下次读取时从内存或者CPU 0读取最新数据；  处理器屏障指令 # 总结一下：\n 这里的读写屏障要依赖处理器提供的屏障指令 在屏障指令之上，内核可以按需选择，如Linux在x86平台选择用 lock; addl来实现读写屏障 smp_mb/smp_rmb/smp_wmb，x86其实也提供了mfence、lfence、sfence。至于Linux为什么这么选择，应该是跟x86实现有关系，一条指令 lock;addl同时实现全屏障/读屏障/写屏障足矣。 其他编程语言内存模型，通常会定义一些Happens-Before关系，这里面就隐含了各种屏障的应用。基于屏障实现的各种同步原语如mutex、semaphore等就比较常见了。  gc屏障 isn\u0026rsquo;t 内存屏障 # ps：有些人还把GC Barrier和Memory Barrier搞混了，碰到不止一个同学了：\n GC Barrier，是编译器插入的一些代码片段，用来跟踪mutator对heap做的修改； Memory Barrier，则就是本文讨论涉及的内容，是处理器提供的一种低级的并发同步操作；  Lock prefix VS Locks # CAS，一般都是基于处理器指令 lock cmpxchg来实现的，这里一定要搞明白，这里虽然指令修饰前缀的字面含义也是lock，翻译过来也是锁，但这并非我们通俗意义上的锁。\n我们平时说的轻量级锁、重量级锁，比如spinlock、futex等，或者sync.Mutex, sync.RWMutex，这些锁都是“高级锁”，而处理器指令的lock prefix只是对单条指令执行的排他性进行控制。\n后者为前者实现提供了基础支持，但是不是一回事。比如，lock+cmpxchg基础上可以包装常用的cas操作，如golang中的atomic.CompareAndSwap(\u0026hellip;)，或者可以包装解决ABA问题的CAS操作。\n来看一下golang中CAS操作实现：\n# filename: atomic_amd64.go //go:noescape func Cas64(ptr *uint64, old, new uint64) bool # filename: atomic/doc.go func CompareAndSwapInt64(ptr *uint64, old, new uint64) bool # filename: atomic_amd64.s // bool	·Cas64(uint64 *val, uint64 old, uint64 new) // Atomically: //	if(*val == *old){ //	*val = new; //	return 1; //	} else { //	return 0; //	} TEXT ·Cas64(SB), NOSPLIT, $0-25 MOVQ	ptr+0(FP), BX MOVQ	old+8(FP), AX MOVQ	new+16(FP), CX LOCK # LOCK CMPXCHGQ, 排他性比较并交换 CMPXCHGQ	CX, 0(BX) SETEQ	ret+24(FP) RET TEXT ·CompareAndSwapInt64(SB),NOSPLIT,$0 JMP	runtime∕internal∕atomic·Cas64(SB) # 调用的是上面的Cas64  可以看到，它就是用 lock cmpxchg来实现的，常用的atomic.CompareAndSwap也差不多了多少，还是调用的Cas64。\n然后我们再来看几个atomic包下的操作，来强化下对lock指令前缀的理解，这里直接对ADDQ操作进行了lock实现了原子的加操作。\nTEXT ·AddInt64(SB),NOSPLIT,$0 JMP	runtime∕internal∕atomic·Xadd64(SB) // uint64 Xadd64(uint64 volatile *val, int64 delta) // Atomically: //	*val += delta; //	return *val; TEXT ·Xadd64(SB), NOSPLIT, $0-24 MOVQ	ptr+0(FP), BX MOVQ	delta+8(FP), AX MOVQ	AX, CX LOCK # LOCK XADDQ，排他性的add操作 XADDQ	AX, 0(BX) ADDQ	CX, AX MOVQ	AX, ret+16(FP) RET  通常我们自己要应用cas的话，比如实现一个metrics gauge，可能会这么写：\n// Gauge 时刻量 type Gauge struct { v uint64 } // IncrBy 时刻量+v func (g *gauge) IncrBy(v float64) { for { oldBits := atomic.LoadUint64(\u0026amp;g.valBits) fv := math.Float64frombits(oldBits) + v newBits := math.Float64bits(fv) if atomic.CompareAndSwapUint64(\u0026amp;g.valBits, oldBits, newBits) { atomic.StoreUint32(\u0026amp;g.dirty, 1) return } } } ...  先读取原始值，计算，然后准备写回，写回的时候用了CAS，一次CAS操作不一定成功，因为可能其他协程也在尝试更新，所以我们这里要结合一个循环（自旋，spin）来保证重试成功。基于CAS的玩法一般都是这么实现的。\nLocks VS Lock-free # 这里读者也应该意识到了，前面CAS也是基于底层处理器的lock cmpxchg实现的，所以并不是说CAS操作就没有任何的同步措施。\n有些lockfree的数据结构+算法，也是基于CAS实现的，也并不是就真的没有任何同步措施。只是没有用那些通俗意义上的“锁”（如没有用可能导致线程阻塞的互斥量、信号量）。\n多线程编程时，对locks和lock-free对比，一种比较好理解的说法是：\n locks，contention managed by 3rd party (OS Kernel) lock-free, contention managed by the users (threads)  CAS和通俗意义的锁，相比之下，它的临界区非常小（单条指令），且不存在“锁”那样导致进程、线程、协程的挂起、恢复操作，没有上下文切换所引入的开销、调度延迟，所以开销更小一点。\n能用CAS代替mutex之类锁的地方，还是用CAS，因为mutex之类的会把进程线程给挂起，即便是sync.Mutex只挂起协程，但是涉及到go runtime scheduler的介入，开销也是比单纯的CAS要大很多的。在锁竞争比较严重的情况下，sync.Mutex也会经历一个锁膨胀的过程，CAS-\u0026gt;Spin-\u0026gt;Semaphore-\u0026gt;futex (spin+block threads)。\n上面提了基于CAS实现一些lock-free算法，其实lock-free算法的思路有很多：\n State Machines CAS operations - However contention lurks here! @Contended Annotation - JEP 142 Wait-Free in addition to Lock-Free Algorithms Thread Affinity x86 and busy spinning and back-off TSX (Transactional Synchronization Extensions)  see https://youtu.be/_uUkApe_yIk?t=2451\n实现一个锁 # 理解了CPU lock+cmpxchg的作用以及应用之后，就可以在此基础上实现一个简单的锁。\n自旋：spinlock # type SpinLock struct{ v int64 } func (s *SpinLock) Lock() bool { for { if atomic.CompareAndSwap(\u0026amp;s.v, 0, 1) { return true } } } func (s *SpinLock) UnLock() { atomic.StoreInt64(\u0026amp;s.v, 0) }  现在就可以拿这个锁去当做一个简单的锁去用了，但是，这种忙轮询的方式对CPU是一个比较严重的浪费，可以考虑一下如果长时间持有不了锁，是不是可以让出CPU给其他协程执行呢？可以，为了利用好CPU干有价值的事情，就应该让出去。\nCAS ABA问题 # 在这里提一嘴吧，在使用CAS的时候，应该关注ABA问题。什么是ABA问题。假定有个volatile变量v（初始值5），现在我们并发地对其进行修改，假如出现了这样对v的一个操作序列：-1 +1，现在v的值还是5。\n 有些场景不能接受ABA问题  有些场景是不能接受ABA问题的，比如你要通过这个值的变化来判断是否有发生过什么+1 -1的操作，因为这里的值v的变化是非单调的，有增有减，这样肯定区分不了是否发生过什么，就得想其他办法。\n比如你的值v用32位足够，那你可以考虑用个64位的int64，其中多出来的32位用来记录数据版本，然后用Cas64操作来代替之前的Cas32操作。\n 有些场景可以接受ABA问题  你比如前面抢到的那个自旋锁实现，SpinLock.v的值一直在0 1 0 1的变化，但是无所谓，我们仅用它来做一个当前状态的判断，而不是用它的当前值来判断以前的操作历史，如现在为0，表示没有人持有锁，但我们并不会去关心以前有没有人持有过锁。\n剥夺CPU：futex？ # 现在我们想把不干活的任务挂起，这里的任务可能是进程、线程，也可能是协程。进程线程挂起可不是我们想要的，挂起、恢复的开销太重了。\n\u0026lt;img alt=\u0026quot;context switch cost\u0026quot; class=\u0026quot;myimg\u0026quot; src=\u0026quot;https://www.hitzhangjie.pro/libmill-book/assets/image%20%2815%29.png\u0026quot;/\u0026gt;\n上图是一个上下文切换开销测评对比，感兴趣的话可以参考这篇文章，see measuring context switching and memory overheads for linux threads。\n一般的锁实现，拿不到锁最后要么自旋，要么将当前任务给挂起，比如把进程、线程挂起，等后续锁被释放了才可以唤起等待队列中的某个进程、线程，恢复调度执行让其继续抢锁。上图中也看到了进程、线程、CPU亲和性不同场景下的上下文切换的开销，还是很明显的。\n所以比较聪明的锁，都不会一下子就挂起任务。\n混合锁实现 # 结合spin和futex的特点，实现一个混合锁：\n spinlock，自旋耗cpu，还不干活（无法推进程序执行）。自旋可以理解成为了不让出cpu让cpu一直干些杂活，比如将一个数从1加到100，加完了从头再加到100，多来几遍……纯粹是为了等锁被持有者释放。自旋锁就是自旋之后再CAS抢锁试下。但是锁竞争不严重的情况下，spinlock一般会成功，效率也高。 futex，阻塞线程，它是Linux内核为用户代码实现同步提供的一种支持，内部维护了一个waiters队列，支持等待、唤醒、定时唤醒，为实现锁提供了方便。开发自己写代码时一般不用这玩意，而是引用在运行时或者标准库在futex基础上封装的方法。 hybrid approach，先cas，不行再spinlock，再不行futex，分别适应没有锁竞争、少量锁竞争、严重锁竞争场景。  go语言中会怎么做呢，比如sync.Mutex？go中会做类似的处理吗？对锁的优化上大致思路差不多。只不过，go要支持轻量级协程，为了追求效率，会比常见的锁实现更细腻一点，不会在不该阻塞的时候把线程给阻塞了。\nsync.Mutex # 终于来到了go语言相关的设计实现，go中sync.Mutex的设计有些比较细腻的考量，本来我尝试解读下源码，发现源码mutex.Lock()/mutex.Unlock() slowpath篇幅比较长，很容易迷失在代码中抓不住主线。\n所以我把解释过的源码部分删除了，我们这里只总结下一些关键的点，感兴趣的读者可以自己读源码：see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L72\n首先，看下sync.Mutex定义：\ntype Mutex struct { state int32	// 锁状态，0:unlocked,1:locked,2:woken,4:starvation,高位 sema uint32	// 为什么是uint32? see 'man 2 futex' }  锁膨胀过程 # 对照着这个结构描述下 mutex.Lock()过程中可能发生的一些事情：\n  这里的state就是表示锁的状态，unlocked, locked, starvation等，首先会看CAS(old=unlocked,new=locked)是否成功。没有锁竞争时，这里大概率就枷锁成功了。反之，则会进入下面的lockSlow流程。\n  lockSlow流程中，首先也会先通过判断state是否可以通过CAS+Spin (runtime.procyield) 来加锁成功，这里不会挂起协程，更不会挂起线程。一般少量锁竞争时，这里大概率也能成功。反之，则会进入下面的sema处理流程。\n  sema是一道锁膨胀处理，这里的信号量(0 or 1)其效果就是一个互斥量，如果信号量acquire成功就是获得了锁，反之就是失败（semacquire函数来获得信号量）。为了避免不必要的协程挂起，一开始也是通过cansemacquire来通过cas+spin来获得信号量，成功了就等于sync.Mutex.Lock()成功，锁竞争严重些可能就会有些协程加锁失败，它们就需要继续走锁膨胀处理逻辑。此时它们将尝试加锁（更底层的一把锁runtime.mutex, lockWithRank(semaRoot.lock) ），这把锁在加锁时是遵循这样的膨胀过程：goroutine active spin (runtime.procyield) -\u0026gt; thread passive spin (runtime.osyield) -\u0026gt; linux syscall futex， 总的原则就是自旋有效的话就没必要挂起协程、线程。加锁(runtime.mutex)成功后，只是说明goroutine有资格继续抢信号量（抢到信号量就是抢到sync.Mutex）了，抢到的自然好，抢不到的怎么办呢？semaRoot上维护了一个waiters队列，抢不到的就semaRoot.queue去排队，goparkunlock会把当前协程挂起并释放掉持有的锁runtime.mutex，直到有人释放了锁并将其唤醒(sync.Mutex.UnLock-\u0026gt;unlockSlow-\u0026gt;semarelease-\u0026gt;lockWithRank...semaRoot.dequeue-\u0026gt;goready(gp))。sema这里用到的futex是一个linux系统调用（fast user-space mutex），如果你不了解futex，see https://eli.thegreenplace.net/2018/basics-of-futexes/，锁实现中常用的futex操作就是futex_wait将当前线程挂起，futex_wake将线程唤醒，涉及到线程的上下文切换，开销较大。sema虽然也是用了futex，但是其也细致考虑了不同锁竞争情况下的加锁优化，尽可能避免不必要的开销。\nps: sync.Mutex.sema这个信号量一开始时为0，假设g1是第一个申请加锁的，sema==0根本对其没影响，g1通过CAS直接可以加锁成功。假设g1释放锁前g2也申请加锁，g2将走到lockSlow，假设其在前期cas+spin阶段g1未释放锁，g2只能走到sema信号量处理这里的锁膨胀逻辑，其在cansemacquire通过cas+spin抢信号量时希望sema\u0026gt;0，在sync.Mutex场景下，sema要么是0要么是1，现在sema==0所以g2不可能成功，只能等到sema==1的时候，那么何时sema==1？只能等到g1调用sync.Mutex.Unlock的时候，如果没有其他协程申请加锁，g1能通过CAS直接完成，但是因为g2在申请加锁，锁的state已经被写入了一些标志信息，比如waiters!=0或者starvation，g1检测到state变化后感知到有人在等待这把锁，有可能这个waiter已经goroutine parked甚至thread挂起，所以g1要通过unlockSlow去做些额外的通知工作。unlockSlow-\u0026gt;semarelease-\u0026gt;semaRoot.dequeue会将等待这把锁的g2给出队并通过goready(g2)去唤醒它，之后g2就可以开始继续尝试获取信号量（again，取到信号量就是取到sync.Mutex，但是前提是它得先拿到runtime.mutex）。假设此时除了g2还有g3也在等待这把锁呢，而且g3可能已经通过futex让线程挂起了，怎么搞？g1执行semarelease过程中，也会执行unlock，这个就会通过futexwakeup唤醒阻塞的线程，被暂停的g3也就可以继续执行抢锁(runtime.mutex)的动作了，抢到runtime.mutex，再去抢信号量，抢到就ok了，抢不到就在信号量上排队。\nsema里面也是优先尝试走CAS、Spin路线，尽可能避免挂起协程，协程切换的开销也不能忽略。\nsee: https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/sema.go\ntype semaRoot struct{ lock mutex treap *sudog nwait uint32 } func (root *semaRoot) queue(addr *uint32, s *sudog, lifo bool) { ... } func (root *semaRoot) dequeue(addr *uint32) (found *sudog, now int64) { ... }    在没有锁竞争的时候，大概率一次CAS能成功；锁竞争不严重的时候，可能自旋几次也能成功，再不行挂起协程、唤醒后再去抢锁也说不定能成功。但是锁竞争很严重的时候，你就是抢不到，那线程抢什么呢？睡觉去吧，这个时候就会用上futex让线程睡眠。\n#include \u0026lt;linux/futex.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; int futex(int *uaddr, int futex_op, int val, const struct timespec *timeout, /* or: uint32_t val2 */ int *uaddr2, int val3); futex_op: - FUTEX_WAIT 保持挂起线程，除非 *uaddr != val，或者定时器超时 - FUTEX_WAKE 唤起阻塞在uaddr上的线程 - ...    这就是sync.Mutex锁膨胀的一个过程，sync.Mutex -\u0026gt; sema -\u0026gt; futex，其实每个阶段都是优先考虑cas+spin的逻辑来尽量避免挂起（协程or线程）。\n注意下图中最后，uses futexes -\u0026gt; uses spin-locks这里，这里是说，linux futex在实现的时候也是使用了spinlock的……都是在考虑不同锁竞争情况下哪种方案更高效。\nps: linux futex根据地址做hash后找到hash bucket，bucket里面有个spinlock_t，拿到这把锁后就可以修改上面的waiters链表，比如将当前线程放入waiters后将当前线程挂起。至于这里为什么用spinlock呢？对内核锁的理解不是很全面，猜测一下，首先这里调整waiters也不怎么花时间，lock很快就释放了，线程spin一下就能等到有人释放，可能没必要用mutex休眠唤醒后再试，而且mutex阻塞上下文切换开销可能更大，所以使用spinlock。对用户态应用程序出现阻塞挂起协程让出cpu可能是件好事，但是在内核里面阻塞线程可不是件好事。linux kernel里面的锁可以参考：http://retis.sssup.it/luca/KernelProgramming/Slides/kernel_locking.pdf(p12-13)。关于futex的使用的话，看着片就够了:http://www.rkoucha.fr/tech_corner/the_futex.html#Principle_futex。\n协程调度优化 # 另外，go sync.Mutex也做了些协程调度相关的优化，大致总结一下。sync.Mutex有两种工作模式：normal mode 和 starvation mode，两种模式对执行Lock、Unlock的goroutine会产生不同的影响。\n  normal mode\n该模式下，waiters（goroutines）会按照申请加锁的顺序进入一个FIFO的队列，一个被唤醒的waiter不一定能够立即持有锁，它要和所有新的发起加锁请求的goroutines竞争。新到达的goroutines通常有一个优势——它们已经在CPU上运行了，并且有很多，所以一个刚被唤醒的waiter大概率会竞争锁失败。\n这种情况下，这个失败的waiter会被加入到这个FIFO队列的队首，当有goroutine释放锁并尝试唤醒一个waiter时，就会优先唤醒队首的waiter，但是也只是将其标记为runnable之后丢到p.localqueue runnext里，如果放不进去会尝试放到global queue，什么时候被调度到还未可知。\n而如果一个waiter竞争锁超过1ms还没有成功，就会将mutex从normal mode切换为startvation mode，下次有goroutine释放锁时，会采取更激进的方法以便让队首的waiter快速得到执行。\n  starvation mode\n该模式下，当一个goroutine释放锁时，锁的拥有者立即从该goroutine转交给队首的waiter。新到达的goroutines不会尝试获得锁，尽管它能观察到锁好像被释放掉了。这种模式下，新到达的goroutines会追加到FIFO的队列的末尾。并且，这个拿到锁的队首的waiter，会被标记为runnable然后放入当前g.P的runnext中，并且把当前g的时间片也一并传给它使用，当前g执行goyield让出P、M之后，M将立即执行p.runnext。简言之，饥饿模式下释放锁的g直接将锁handleoff给队首的waiter，并让其更快地得到执行。\n  当一个waiter收到一个mutex的拥有者权限时，它会检查，如果：1）它是这个锁竞争等待队列中的最后一个waiter；或者 2）它的加锁等待时间小于1ms，此时将把mutex从starvation mode切换为normal mode。\n与饥饿模式相比，正常模式下的互斥锁能够提供更好的性能，饥饿模式则能缩减goroutine 由于等待获取锁过久造成的延时。\n总结 # 本文介绍了并发中重要的原子性、指令重排问题，以及带来的安全编码风险，然后介绍了处理器提供的一些屏障指令，以及从硬件角度介绍了屏障的工作原理，然后介绍了CAS及其使用，引出了进一步的锁、无锁、CAS的异同点，然后我们简单提了下futex重量级锁导致的进程线程挂起、恢复开销大家，最后引出了go sync.Mutex的设计实现及一系列针对协程调度延迟的优化。\n希望本文对加深大家对锁的认识有帮助！\n参考内容 #  Memory Barriers: a Hardware View for Software Hackers,http://www.puppetmastertrading.com/images/hwViewForSwHackers.pdf how cpu lock cmpxchg works: http://heather.cs.ucdavis.edu/~matloff/50/PLN/lock.pdf don\u0026rsquo;t mix high-level locks with low-level CPU feature that happened to be renamed LOCK,https://stackoverflow.com/a/27856649/3817040 cpu-memory, https://akkadia.org/drepper/cpumemory.pdf src/runtime/internal/atomic/atomic_386.s, https://sourcegraph.com/github.com/golang/go/-/blob/src/runtime/internal/atomic/atomic_386.s#L23 sync.Mutex, https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L81:4 Let\u0026rsquo;s talk locks, Kavya Joshi, https://www.youtube.com/watch?v=tjpncm3xTTc Atomic Operations in Hardware, https://courses.cs.washington.edu/courses/cse378/07au/lectures/L25-Atomic-Operations.pdf Atomic Operation, https://wiki.osdev.org/Atomic_operation Lock-free Algorithms for Ultimate Performance, https://www.youtube.com/watch?v=_uUkApe_yIk Fear and Loathing in Lock-Free Programming, https://medium.com/@tylerneely/fear-and-loathing-in-lock-free-programming-7158b1cdd50c measuring context switching and memory overheads for linux threads, https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/ basis of futexes, https://eli.thegreenplace.net/2018/basics-of-futexes/ Computer Architecture: Dynamic Execution Core, https://youtu.be/XuCu9EEHBtk?t=1087 x86-TSO: A Rigorous and Usable Programmer\u0026rsquo;s Model for x86 Multiprocessors, https://www.cl.cam.ac.uk/~pes20/weakmemory/cacm.pdf Memory Consistency Models: A Tutorial, https://www.cs.utexas.edu/~bornholt/post/memory-models.html Detailed approach of the futex: http://www.rkoucha.fr/tech_corner/the_futex.html#Principle_futex Kernel and Locking, http://retis.sssup.it/luca/KernelProgramming/Slides/kernel_locking.pdf  "}),a.add({id:315,href:"/tags/sync.mutex/",title:"sync.Mutex",description:"",content:""}),a.add({id:316,href:"/tags/exception/",title:"exception",description:"",content:""}),a.add({id:317,href:"/tags/panic/",title:"panic",description:"",content:""}),a.add({id:318,href:"/tags/try-catch/",title:"try-catch",description:"",content:""}),a.add({id:319,href:"/blog/2021-04-16-%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85gopanic%E5%8F%8A%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86/",title:"如何看待gopanic及异常处理",description:"最近发现有些同学对于go panic的理解有误，分不清什么时候用panic，什么时候用error，甚至是一些go老手也会出现不加选择乱用的情况，go panic有其明确的使用定位，但是不同于其他语言中的异常处理。",content:"Background # 最近有同学提问，大意是：“go中什么时候用panic、什么时候用error，能不能像其他语言中的try-catch一样用panic-recover来代替层层return err，或者应不应该recover一个panic之后转换为error？”\n这个问题引起了广泛的讨论，在对这几个问题的理解上，我本以为大家应该会认识到位的，没想到很多人认识很模糊。当然，好的地方就是总有有见识的同学站出来指出大家的问题。\n对于那些有灵性的同学，勤实践勤思考的同学，他会自然而然意识到哪种error handling pattern更好，也会有意识地去区分不同pattern的定位和应用场景。这类同学虽然没有什么理论术语支撑，但是他们的“经验”是贴近更好的设计思想、最佳实践的。如果更进一步，能愿意接受一些设计思想的洗礼，则可以将“经验”上升到“模式”，以指导更多人。\npanic != exception # go panic不同于其他语言中的exception，在设计、定位上是有明确的区别的，see: https://dave.cheney.net/2012/01/18/why-go-gets-exceptions-right。\n panics are always fatal to your program. In panicing you never assume that your caller can solve the problem. Hence panic is only used in exceptional circumstances, ones where it is not possible for your code, or anyone integrating your code to continue.\n go panic是用来表示程序出现了十分致命的错误，并且你不能假定这个错误能被解决。所以panic只在很少的场景下才会被用到，并且出现panic时，你的代码解决不了，引用这部分代码的其他代码也解决不了。\n所以，panic并非一般意义上的error，更不能用panic-recover代替层层向上传递error！\n对于，为了自身程序的健壮性，而在启动新的goroutine时，或者调用外部依赖的导出函数、方法时，可能选择recover一些预料之外的panic，并转换为error处理。\n有追求的开发人员，在panic的使用上应该始终遵循go设计理念，同时在程序的健壮性上也会采用些防御性编程的手段。\npanic vs exception # 我们很多开发人员都接触过多门语言，比如Java、C++，等等，这类语言都有异常处理机制，遇到一些意外事件时可以抛出一个异常，异常通常由try-catch block捕获并处理。\n初学者阶段，很多同学会努力去学习异常处理的正确编码方式，甚至是异常处理的实现原理，对性能的影响，等等，但是由于实际缺乏实际的大规模工程供锻炼实践，也很少有人会去思考一些问题，比如：\n  QA：我们为什么需要异常？\n 层层返回error，编码不方便，希望有统一的错误处理逻辑，保证主逻辑更清晰。    QA：异常解决了什么问题？\n 避免了层层传递error，异常在统一位置处理。    QA：异常引入了什么问题？\n  区分异常发生的位置，就要每个位置定义一个异常类型，这个数量应该挺大的。\n  而且由于实际编码中同一个异常会在多处被抛出，实际上看到代码中捕获一个异常类型时，你很难断定它是哪个操作抛出的。\n  而且每个可能捕获这个异常的地方，都需要拷贝异常处理代码。\n  如果没有捕获异常，通常进程会挂掉，能否识别一个函数是否会抛出异常，Java中有checked exception、unchecked exception，前者可以在编译时帮助确定是否有遗漏的try-catch，但是仍然有unchecked exception。\n    QA：异常真的解决了问题么？\n 异常表面解决了老问题，但是却有引入了新问题，而且新问题似乎更严重。    异常+try-catch，本质上将当前操作的错误处理逻辑转换为了caller要解决的问题，并没有少写多少错误处理代码，反而，同一异常处理代码在多个try-catch中被拷贝，而且可读性更差了。错误发生地、错误处理地分散在不同地方，能说是可读性好吗？我不这么认为。\ndon\u0026rsquo;t need exception? # 异常处理，真的是个好东西么？它真的解决了问题么？\n之前同困惑c++异常是解决了问题还是引入了新问题，为此也多方了解，直到后来看到zmq之父Martin Sustrik的文章，Why should I have written ZeroMQ in C, not C++。Martin详细介绍了在错误处理过程中，如果采用C++异常处理会带来怎样的麻烦，而如果直接使用error处理会有哪些好处。最终Martin在实现zmq时采用了 c++ minus exception的技术路线，即使用C++但是不适用C++异常处理。\n基于以前的沉思，Martin后面使用C有重新写了一个zmq的进化版本nanomsg ，C没有异常处理 :)\n这里不想引战，也不想做二元的判定，强烈推荐读者朋友们阅读下Dave、Martin Sustrik的文章，相信会对panic、error、exception的设计理解更透彻。\nReferences #  Why go gets exceptions right, https://dave.cheney.net/2012/01/18/why-go-gets-exceptions-right Why should I have written ZeroMQ in C, not C++, https://250bpm.com/blog:4/  "}),a.add({id:320,href:"/tags/cgo/",title:"cgo",description:"",content:""}),a.add({id:321,href:"/blog/2021-04-14-go%E7%A8%8B%E5%BA%8F%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D/",title:"Go程序内存泄露问题快速定位",description:".myimg { width: 680px; padding-bottom: 1rem; }  前几天有同学反馈了cgo内存泄露问题，自己也针对这个问题探索了一番，算是为以后解决类似问题提前攒点经验吧。也趁机整理了一下go开发过程中内存泄露问题的一些常用排查方法，也希望对新接触go的同学有所帮助。整理之余，bcc工具之丰富也让我有点惊讶，也希望对自己日后的工作有所帮助吧。\n内存泄漏 # 内存泄露，一个老生常谈的问题，但即便是老手也会犯一些低级错误。如果没有可靠的研发流程保证在测试阶段发现问题，问题就容易被带到线上。计算资源始终是有限的，问题也不会因为资源充裕就消失不见，产生影响只是时间问题。影响有多大，就要结合场景来说了。\n内存泄漏，最可能的影响就是内存申请失败。但实际上操作系统更聪明，结合系统整体负载情况，它会为每个进程计算一个oom_score，并在内存资源紧张时选择一个合适的进程杀死并回收内存资源，see how does the oom killer decide which process to kill first。\n所以，内存泄露的最终结果，大概率会被操作系统kill，通常进程挂掉后，确认其是否是因为oom问题被kill，可以通过查看 /proc/messages 来确认是否有对应日志。有的话，那就坐实了oom killed（但是被oom killed的进程不一定意味着存在内存泄露）。\n服务质量 # 结合运维手段的变化，来看看是否内存泄漏问题对服务质量造成的影响。\n 传统人工方式，通过感知告警、人为介入这种方式，效率低，要十几分钟； 通过虚拟机自动化部署的方式，感知异常自动重启虚拟机，耗时大约要分钟级； 通过docker容器化部署的方式，感知异常自动重启容器，耗时大约在秒级；  看上去现代运维方式一定程度上可以缓解这个问题，是，这也要分情况：\n 如果内存泄露的代码路径不容易被触发，那可能要跑很久才能触发oom kill，如一周；但是如果代码路径在关键代码路径上，且请求量大，频繁触发内存泄露，那可能跑个几分钟就会挂掉； 跟每次内存泄露的内存大小也有关系，如果泄露的少，多苟活一阵子，反之容易暴毙； 进程一旦挂掉，这段时间就不能响应了，服务的健康监测、名字服务、负载均衡等措施需要一段时间才能感知到，如果请求量大，服务不可用依然会带来比较大的影响。  服务质量保证是不变的，所以别管用了什么运维手段，问题终究是问题，也是要解决的。\nGo内存泄漏 # 垃圾回收 # 自动内存管理减轻了开发人员管理内存的复杂性，不需要像C\\C++开发者那样显示malloc、free，或者new、delete。垃圾回收借助于一些垃圾回收算法完成对无用内存的清理，垃圾回收算法有很多，比如：引用计数、标记清除、拷贝、分代等等。\nGo中垃圾回收器采用的是“并发三色标记清除”算法，see:\n Garbage Collection In Go : Part I - Semantics Garbage Collection In Go : Part II - GC Traces Garbage Collection In Go : Part III - GC Pacing  Go语言支持自动内存管理，那还存在内存泄漏问题吗？",content:" .myimg { width: 680px; padding-bottom: 1rem; }  前几天有同学反馈了cgo内存泄露问题，自己也针对这个问题探索了一番，算是为以后解决类似问题提前攒点经验吧。也趁机整理了一下go开发过程中内存泄露问题的一些常用排查方法，也希望对新接触go的同学有所帮助。整理之余，bcc工具之丰富也让我有点惊讶，也希望对自己日后的工作有所帮助吧。\n内存泄漏 # 内存泄露，一个老生常谈的问题，但即便是老手也会犯一些低级错误。如果没有可靠的研发流程保证在测试阶段发现问题，问题就容易被带到线上。计算资源始终是有限的，问题也不会因为资源充裕就消失不见，产生影响只是时间问题。影响有多大，就要结合场景来说了。\n内存泄漏，最可能的影响就是内存申请失败。但实际上操作系统更聪明，结合系统整体负载情况，它会为每个进程计算一个oom_score，并在内存资源紧张时选择一个合适的进程杀死并回收内存资源，see how does the oom killer decide which process to kill first。\n所以，内存泄露的最终结果，大概率会被操作系统kill，通常进程挂掉后，确认其是否是因为oom问题被kill，可以通过查看 /proc/messages 来确认是否有对应日志。有的话，那就坐实了oom killed（但是被oom killed的进程不一定意味着存在内存泄露）。\n服务质量 # 结合运维手段的变化，来看看是否内存泄漏问题对服务质量造成的影响。\n 传统人工方式，通过感知告警、人为介入这种方式，效率低，要十几分钟； 通过虚拟机自动化部署的方式，感知异常自动重启虚拟机，耗时大约要分钟级； 通过docker容器化部署的方式，感知异常自动重启容器，耗时大约在秒级；  看上去现代运维方式一定程度上可以缓解这个问题，是，这也要分情况：\n 如果内存泄露的代码路径不容易被触发，那可能要跑很久才能触发oom kill，如一周；但是如果代码路径在关键代码路径上，且请求量大，频繁触发内存泄露，那可能跑个几分钟就会挂掉； 跟每次内存泄露的内存大小也有关系，如果泄露的少，多苟活一阵子，反之容易暴毙； 进程一旦挂掉，这段时间就不能响应了，服务的健康监测、名字服务、负载均衡等措施需要一段时间才能感知到，如果请求量大，服务不可用依然会带来比较大的影响。  服务质量保证是不变的，所以别管用了什么运维手段，问题终究是问题，也是要解决的。\nGo内存泄漏 # 垃圾回收 # 自动内存管理减轻了开发人员管理内存的复杂性，不需要像C\\C++开发者那样显示malloc、free，或者new、delete。垃圾回收借助于一些垃圾回收算法完成对无用内存的清理，垃圾回收算法有很多，比如：引用计数、标记清除、拷贝、分代等等。\nGo中垃圾回收器采用的是“并发三色标记清除”算法，see:\n Garbage Collection In Go : Part I - Semantics Garbage Collection In Go : Part II - GC Traces Garbage Collection In Go : Part III - GC Pacing  Go语言支持自动内存管理，那还存在内存泄漏问题吗？\n理论上，垃圾回收（gc）算法能够对堆内存进行有效的清理，这个是没什么可质疑的。但是要理解，垃圾回收能够正常运行的前提是，程序中必须解除对内存的引用，这样垃圾回收才会将其判定为可回收内存并回收。\n内存泄漏场景 # 实际情况是，编码中确实存在一些场景，会造成“临时性”或者“永久性”内存泄露，是需要开发人员加深对编程语言设计实现、编译器特性的理解之后才能优化掉的，see：go memory leaking scenarios。\n即便是临时性内存泄漏，考虑到有限的内存资源、内存申请大小、申请频率、释放频率因素，也会造成进程oom killed的结果。所以，开发人员对待每一行代码还是要心存敬畏，对待内存资源也还是要慎重。\n常见的内存泄露场景，go101进行了讨论，总结了如下几种：\n Kind of memory leaking caused by substrings Kind of memory leaking caused by subslices Kind of memory leaking caused by not resetting pointers in lost slice elements Real memory leaking caused by hanging goroutines real memory leadking caused by not stopping time.Ticker values which are not used any more Real memory leaking caused by using finalizers improperly Kind of resource leaking by deferring function calls  简单归纳一下，还是“临时性”内存泄露和“永久性”内存泄露：\n 临时性泄露，指的是该释放的内存资源没有及时释放，对应的内存资源仍然有机会在更晚些时候被释放，即便如此在内存资源紧张情况下，也会是个问题。这类主要是string、slice底层buffer的错误共享，导致无用数据对象无法及时释放，或者defer函数导致的资源没有及时释放。 永久性泄露，指的是在进程后续生命周期内，泄露的内存都没有机会回收，如goroutine内部预期之外的for-loop或者chan select-case导致的无法退出的情况，导致协程栈及引用内存永久泄露问题。  内存泄露排查 # 初步怀疑程序存在内存泄露问题，可能是因为进程oom killed，或者是因为top显示内存占用持续增加无法稳定在一个合理值。不管如何发现的，明确存在这一问题之后，就需要及时选择合适的方法定位到问题的根源，并及时修复。\n借助pprof排查 # pprof类型 # go提供了pprof工具方便对运行中的go程序进行采样分析，支持对多种类型的采样分析：\n goroutine - stack traces of all current goroutines heap - a sampling of all heap allocations threadcreate - stack traces that led to the creation of new OS threads block - stack traces that led to blocking on synchronization primitives mutex - stack traces of holders of contended mutexes profile - cpu profile trace - allows collecting all the profiles for a certain duration  pprof操作 # 现在很多rpc框架有内置管理模块，允许访问管理端口通过/debug/pprof对服务进行采样分析（pprof会有一定的性能开销，最好分析前将负载均衡权重调低）。\n集成pprof非常简单，只需要在工程中引入如下代码即可：\nimport _ \u0026quot;net/http/pprof\u0026quot; go func() { log.Println(http.ListenAndServe(\u0026quot;localhost:6060\u0026quot;, nil)) }()  然后运行go tool pprof进行采样：\ngo tool pprof -seconds=10 -http=:9999 http://localhost:6060/debug/pprof/heap  有时可能存在网络隔离问题，不能直接从开发机访问测试机、线上机器，或者测试机、线上机器没有安装go，那也可以这么做：\ncurl http://localhost:6060/debug/pprof/heap?seconds=30 \u0026gt; heap.out # sz下载heap.out到本地 go tool pprof heap.out  go tool pprof可以收集两类采样数据：\n  in_use，收集进程当前仍在使用中的内存；   alloc，收集自进程启动后的总的内存分配情况，包括已经释放掉的内存；   go tool pprof展示采样信息时，申请内存以“红色”显示，释放内存以“绿色”显示。\n允许采样完成后打开一个浏览器页面（通过ip:port访问），交互式地查看采样结果信息，例如callgraph、flamegraph、top信息。\npprof示例：协程泄露 # 其中有2条红色的很醒目的路径，这是造成内存占用升高的主要路径，需要重点分析。以右边这条红色路径为例，最终走到了runtime.malg，碰到这个函数，联想前面总结的常见内存泄露场景，要有这样的意识：“这里可能涉及到goroutine泄露”，即goroutine创建了很多，但是goroutine没有正常执行结束，对应的协程使用的内存没有释放。\n此时根据上述callgraph中的线索检查程序中启动goroutine的地方，以及goroutine是否有正常退出的逻辑保证，就能比较方便地定位到泄露原因了。\n上述callgraph中展示了两条导致内存分配占用高的路径，但是其中左边一条可能是正常情况下的内存使用情况，而右边这条可能是异常情况。在分析阶段，我们需要有能力区分哪些内存分配是正常情况，哪些情况是异常情况。pprof提供了另外一个有用的选项-diff_base，我们可以在没有服务没有请求时采样30s生成一个采样文件，然后有请求时，我们再采样30s生成另一个采样文件，并将两个采样文件进行对比。这样就容易分析出请求出现时，到底发生了什么。\ngo tool pprof -http=':8081' \\ -diff_base heap-new-16:22:04:N.out \\ heap-new-17:32:38:N.out  这样问题看起来就更非常明确了，请求出现时处理请求的过程中启动了新协程执行处理。runtime.malg就是创建新协程，其内部会分配协程栈，这个栈在使用过程中会动态伸缩，并在协程退出时才会被销毁。\n由pprof heap确定了存在goroutine泄露问题，但我们还不知道此goroutine在何处启动的，为此，我们继续pprof goroutine。\ngo tool pprof -seconds=10 \\ -http=:8081 \\ http://localhost:6060/debug/pprof/goroutines  现在通过上述callgraph我们很容易定位到goroutine是在哪里启动的了，回到源码中进一步确认：\nvar ticker = time.NewTicker(time.Second) go func() { for { select { case \u0026lt;-ticker.C: // doSomething } } }() func somefunc(...) { ticker.Stop() }  原来当前协程因为ticker.C这个chan read操作阻塞了，需要注意的是time.Ticker.Stop()之后，ticker.C这个chan不会被关闭，最好在执行ticker.Stop()的时候，同时设置一个通知chan，close该chan来表示ticker停止。\nvar ticker = time.NewTicker(time.Second) var chdone = make(chan int, 1) go func() { for { select { case \u0026lt;-ticker.C: sa.read() case \u0026lt;- chdone: return } } }() func somefunc(...) { ticker.Stop() close(chdone) }  这里介绍了pprof的使用方法，pprof是每个go开发人员都应该掌握的。希望读者借助这里的示例能帮助读者了解pprof的操作、分析过程，达到灵活运用的程度还需要日常开发工作中多实践。\n借助bcc排查 # pprof：这个我干不了 # pprof对于分析纯go程序是非常有帮助的，但是对于cgo有点无能为力，cgo部分的代码已经跳出了go内存分配器的范围，采样也没用，那cgo部分出现内存泄露该如何排查呢？\n 要确定进程是否出现了内存泄露，可以观察进程运行期间的内存占用情况，如借助top、free -m，或者其他运维平台的监控系统，一般k8s都集成了prometheus对容器运行情况进行了监视。如果内存占用随着时间延长一直增长，没有在合理的内存占用值附近稳定下来，或者已经出现了oom killed、容器重启的问题出现，则可以初步判定进程存在内存泄露； 继续借助pprof工具排查go程序，如果pprof可以排查出明显的内存泄露问题，则内存泄漏问题可能是纯go部分代码引起，采用前面描述的分析、定位方法来解决； 如果pprof工具采样之后，没有发现明显的内存泄露的端倪，且程序中存在cgo部分的代码，怀疑cgo部分的代码存在内存泄露，此时则需借助其他手段（pprof无能为力了）来进一步分析cgo部分的可能异常；  库函数：hook库函数 # 要分析内存是否存在泄漏，也可以考虑自己hook一下库函数，自己实现这种我们就不展开讨论了。还是看看有没有趁手的好工具，能实实在在地、靠谱地帮我们解决实际问题（尽管趁手的工具也可能也是基于某种hook的能力实现的）。\nKernel：谁能逃脱我的法眼 # 内存分配操作，一般会借助一些库函数来完成，内存分配器也会做一些分配算法的优化，这里不关心这些，最终的内存申请操作还是要由操作系统来代劳，而请求内核服务的操作则是通过系统调用。\n操作系统提供了一些服务，允许对运行中的进程进行观测，以Linux为例，借助ptrace系统调用+PTRACE_SYSCALL，允许我们对一个运行中的进程执行的所有系统调用进行观测，ltrace、strace就是在此基础上实现的。\neBPF（extended BPF）的前辈是BPF（Berkeley Packet Filtering），BPF是一个ByteCode VM，它的数据模型限制于packet，经常用来做一些包分析，经典的如tcpdump。eBPF相比BPF，其数据模型不再受限于单一的packet，也不再只是用来分析packet的单一功能，可以利用它将eBPF program挂到任意的tracepoint或者kprobe去执行分析处理。这一下子打开了eBPF的万花筒，使得能够对内核各个子系统做观测、做性能分析，等等。\n各种测量、性能分析工具，真是亮瞎我的眼睛。\nBCC (eBPF toolkit)：测量、性能分析 # 如何基于eBPF写eBPF program来完成希望的测量、分析呢，see iovisor/bcc：\n BCC is a toolkit for creating efficient kernel tracing and manipulation programs, and includes several useful tools and examples. It makes use of extended BPF (Berkeley Packet Filters), formally known as eBPF, a new feature that was first added to Linux 3.15.\neBPF was described by Ingo Molnár as:\n One of the more interesting features in this cycle is the ability to attach eBPF programs (user-defined, sandboxed bytecode executed by the kernel) to kprobes. This allows user-defined instrumentation on a live kernel image that can never crash, hang or interfere with the kernel negatively.\n BCC makes BPF programs easier to write, with kernel instrumentation in C (and includes a C wrapper around LLVM), and front-ends in Python and lua. It is suited for many tasks, including performance analysis and network traffic control.\n BCC算是一个开发套件，在它基础上开发eBPF program会更简单，该仓库内当前已经拥有了非常丰富的测量、分析工具，工具之丰富，只差我能不能全部掌握了，也想成为像Brendan Gregg一样的性能分析专家。\n Brendan Gregg: Understanding all the Linux tracers to make a rational decision between them a huge undertaking. (I may be the only person who has come close to doing this.)\n 至于如何实现一个BCC工具，则非常简单，实际上就是写一个python文件，内部一个字符串包含一个c程序，c程序内调用封装的eBPF API，看一个简单的demo：\n#file: hello-open-world-1.py from bcc import BPF program = \u0026quot;\u0026quot;\u0026quot; #include \u0026lt;asm/ptrace.h\u0026gt; // for struct pt_regs #include \u0026lt;linux/types.h\u0026gt; // for mode_t int kprobe__sys_open(struct pt_regs *ctx, char __user* pathname, int flags, mode_t mode) { bpf_trace_printk(\u0026quot;sys_open called.\\\\n\u0026quot;); return 0; } \u0026quot;\u0026quot;\u0026quot; b = BPF(text=program) b.trace_print()  运行它：\n$ sudo python hello-open-world-1.py  OK，BCC套件里面提供了工具memleak，用来对内存泄露进行分析，下面结合一个cgo内存泄露的示例分析，来了解下如何是使用。\n建议能花点时间了解下linux tracing systems，see linux tracing systems \u0026amp; how they fit together ，理清下kprobe/uprobe/dtrace probes/kernel tracepoints的含义及工作原理，进而才能认识到eBPF的强大之处，不再展开了，看个示例。\nBCC：内存泄露示例 # 下面先看一个cgo示例工程是如何组织的，示例项目取自https://github.com/2Dou/cgo-example，您可以直接从这里下载。\nc-so/ ├── Makefile ├── add │ ├── Makefile │ ├── add.go │ └── src │ ├── add.c │ └── add.h └── main.go  上述工程中，add/src/下add.h/add.c实现了一个add函数，add/add.go中定义了可导出的函数Add(a, b int) int，内部通过cgo调用src下定义的int add(int, int)，add/Makefile将把add下的源文件整个编译构建打包成一个共享库文件libadd.so，供c-so/main.go调用。\nc-so/main.go引用目录add下定义的package add中的Add函数，c-so/Makefile只是简单的go build编译动作，编译完成后./c-so运行会提示库文件libadd.so不存在，这是因为库路径加载问题，执行LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$(pwd -p) ./c-so即可，程序正常运行。\nOK，现在简单地篡改下src/add.c，将其内容修改如下，插入了一段不停申请内存的代码：\n#include \u0026quot;add.h\u0026quot; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int add(int a, int b) { /******* insert memory leakage start ********/ int i = 0; int max = 0x7fffffff; for (; i\u0026lt;max; i++) { int *p = (int *)malloc(sizeof(int) * 8); sleep(1); if (i % 2 == 0) { free(p) } } /******* insert memory leakage end ********/ return a+b; }  现在重新执行make编译之后，再次运行，程序不断地malloc但是从来不free，内存一点点被泄露，现在我们看看如何借助memleak分析内存泄露的位置：\n$ /usr/share/bcc/tools/memleak -p $(pid of c-so)  运行一段时间以后，memleak报告了内存分配的情况，显示的是“top10的还没有释放的内存分配”的位置信息：\n Trace outstanding memory allocations that weren\u0026rsquo;t freed.\nSupports both user-mode allocations made with libc functions and kernel-mode allocations made with kmalloc/kmem_cache_alloc/get_free_pages and corresponding memory release functions.\n 从memleak报告的最后一条信息来看：\n c-so这个程序运行过程中，调用了共享库libadd.so中的add函数； 这个add函数执行了345+次内存分配操作，每次申请sizeof(int)*8 bytes，总共分配了11048次内存； 内存分配malloc操作的位置大约就是add函数起始处+0x28的指令位置，可以通过objdump -dS libadd.so求证。  现在我们可以看到内存分配的位置、次数、内存数量，但是这个报告中报道的并非实际泄露的内存数量，比如我们也有free，怎么没有统计到呢？运行memleak -h查看下有哪些选项吧！\n$ /usr/share/bcc/tools/memleak -p $(pid of c-so) -t  现在可以看到报告信息中包含了alloc entered/exited，free entered/exited，可以断定memleak也跟踪了内存释放，但是这里的报告还是不够直观，能否直接显示泄露的内存信息呢？可以但是要稍微修改下，下面看下实现，你会发现现有的报告信息也不妨碍分析。\nbcc/memleak实现 # 不看下源码，总感觉心里有点虚，看下memleak这个eBPF program中的部分逻辑：\n跟踪malloc：\nint malloc_enter(struct pt_regs *ctx, size_t size) \\-\u0026gt; static inline int gen_alloc_enter(struct pt_regs *ctx, size_t size) : 内部会更新被观测进程已分配的内存数量（sizes记录） int malloc_exit(struct pt_regs *ctx) \\-\u0026gt; static inline int gen_alloc_exit(struct pt_regs *ctx) \\-\u0026gt; static inline int gen_alloc_exit2(struct pt_regs *ctx, u64 address) ：内部会记录当前申请的内存地址（allocs记录） \\-\u0026gt; stack_traces.get_stackid(ctx, STACK_FLAGS) ：记录当前内存分配动作的调用栈信息（allocs中记录）  跟踪free：\nint free_enter(struct pt_regs *ctx, void *address) \\-\u0026gt; static inline int gen_free_enter(struct pt_regs *ctx, void *address) ：从allocs中删除已经释放的内存地址  memleak周期性地对allocs进行排序，并按照sizes分配内存多少降序排列打印出来，因为memleak同时跟踪了malloc、free，所以一段时间后，周期性打印的内存分配调用栈位置，即可以认为是没有释放掉（泄露掉）的内存分配位置。\n借助pmap/gdb排查 # 这也是一种比较通用的排查方式，在排查内存泄露问题时，根据实际情况（比如环境问题无法安装go，bcc之类分析工具等等）甚至可考虑先通过pmap这种方式来分析一下。总之，灵活选择合适的方式吧。\n内存及pmap基础 # 进程中的内存区域分类可以按下面几个维度来划分，如果对这个不熟，建议参考以下文章，see:\n Memory Types Understanding Process Memory Managing Memory      Private Shared     Anonymous stack\nmalloc\nmmap(anon+private)\nbrk/sbrk mmap(anon+shared)   File-backed mmap(fd, private)\nbinary/shared libraries mmap(fd, shared)    借助pmap可以查看进程内存空间分布情况，包括地址范围、大小、内存映射情况，如：\n$ pmap -p \u0026lt;pid\u0026gt; # /proc/\u0026lt;pid\u0026gt;/maps 3009: ./blah 0000000000400000 4K r-x-- /home/fruneau/blah 0000000000401000 4K rw--- /home/fruneau/blah 00007fbb5da87000 51200K rw-s- /dev/zero (deleted) 00007fbb60c87000 1536K r-x-- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb60e07000 2048K ----- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb61007000 16K r---- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb6100b000 4K rw--- /lib/x86_64-linux-gnu/libc-2.13.so 00007fbb6100c000 20K rw--- [ anon ] 00007fbb61011000 128K r-x-- /lib/x86_64-linux-gnu/ld-2.13.so 00007fbb61221000 12K rw--- [ anon ] 00007fbb6122e000 8K rw--- [ anon ] 00007fbb61230000 4K r---- /lib/x86_64-linux-gnu/ld-2.13.so 00007fbb61231000 4K rw--- /lib/x86_64-linux-gnu/ld-2.13.so 00007fbb61232000 4K rw--- [ anon ] 00007fff9350f000 132K rw--- [ stack ] 00007fff9356e000 4K r-x-- [ anon ] ffffffffff600000 4K r-x-- [ anon ] total 55132K  $ pmap -x -p \u0026lt;pid\u0026gt; # /proc/\u0026lt;pid\u0026gt;/smaps Address Kbytes RSS Dirty Mode Mapping 0000000000400000 4 4 4 r-x-- blah 0000000000401000 4 4 4 rw--- blah 00007fc3b50df000 51200 51200 51200 rw-s- zero (deleted) 00007fc3b82df000 1536 188 0 r-x-- libc-2.13.so 00007fc3b845f000 2048 0 0 ----- libc-2.13.so 00007fc3b865f000 16 16 16 r---- libc-2.13.so 00007fc3b8663000 4 4 4 rw--- libc-2.13.so 00007fc3b8664000 20 12 12 rw--- [ anon ] 00007fc3b8669000 128 108 0 r-x-- ld-2.13.so 00007fc3b8879000 12 12 12 rw--- [ anon ] 00007fc3b8886000 8 8 8 rw--- [ anon ] 00007fc3b8888000 4 4 4 r---- ld-2.13.so 00007fc3b8889000 4 4 4 rw--- ld-2.13.so 00007fc3b888a000 4 4 4 rw--- [ anon ] 00007fff7e6ef000 132 12 12 rw--- [ stack ] 00007fff7e773000 4 4 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ---------------- ------ ------ ------ total kB 55132 51584 51284  上述命令只是输出信息的详细程度不同，在我们理解了进程的内存类型、pmap的使用之后，就可以对发生内存泄露的程序进行一定的分析。\n排查示例：用例准备 # 比如现在写一个测试用的程序，目录结构如下：\nleaks |-- conf | `-- load.go |-- go.mod |-- leaks |-- main.go `-- task `-- load.go  file: main.go，该文件启动conf、task下的两个逻辑，conf.LoadConfig中启动一个循环，每次申请1KB内存并全部设置为字符C，task.NewTask启动一个循环，每次申请1KB内存并设置为字符T。 conf.LoadConfig循环体每次迭代间隔1s，task.NewTask循环体每次迭代间隔2s。\npackage main import ( \u0026quot;leaks/conf\u0026quot; \u0026quot;leaks/task\u0026quot; ) func main() { conf.LoadConfig(\u0026quot;aaa\u0026quot;) task.NewTask(\u0026quot;bbb\u0026quot;) select {} }  file: conf/load.go:\npackage conf import ( \u0026quot;time\u0026quot; ) type Config struct { A string B string C string } func LoadConfig(fp string) (*Config, error) { kb := 1 \u0026lt;\u0026lt; 10 go func() { for { p := make([]byte, kb, kb) for i := 0; i \u0026lt; kb; i++ { p[i] = 'C' } time.Sleep(time.Second * 1) println(\u0026quot;conf\u0026quot;) } }() return \u0026amp;Config{}, nil }  file: task/load.go\npackage task import ( \u0026quot;time\u0026quot; ) type Task struct { A string B string C string } func NewTask(name string) (*Task, error) { kb := 1 \u0026lt;\u0026lt; 10 // start async process go func() { for { p := make([]byte, kb, kb) for i := 0; i \u0026lt; kb; i++ { p[i] = 'T' } time.Sleep(time.Second * 2) println(\u0026quot;task\u0026quot;) } }() return \u0026amp;Task{}, nil }  然后编译构建 go build 输出可执行文件 leaks，大家可能注意到了，我这样的写法并没有什么特殊的，是会被garbage collector回收掉的，顶多是回收快慢而已。\n是的，为了方便我们解释pmap排查方法的运用，我们假定这里的内存泄露掉了，怎么个假定法呢？我们关闭gc，运行程序的时候 GOGC=off ./leaks.\n你可以用 top -p $(pidof leaks) 验证下RSS飞涨。\n排查示例：搜索可疑内存区 # 比如，你发现有段anon内存区域，它的占用内存数量在增加，或者这样的区段数量再增加（可以对比前后两次的pmap输出来发现）:\n$ pmap -x $(pidof leaks) \u0026gt; 1.txt $ pmap -x $(pidof leaks) \u0026gt; 2.txt 86754: ./leaks/leaks 86754: ./leaks/leaks Address Kbytes RSS Dirty Mode Mapping Address Kbytes RSS Dirty Mode Mapping 0000000000400000 372 372 0 r-x-- leaks 0000000000400000 372 372 0 r-x-- leaks 000000000045d000 496 476 0 r---- leaks 000000000045d000 496 476 0 r---- leaks 00000000004d9000 16 16 16 rw--- leaks 00000000004d9000 16 16 16 rw--- leaks 00000000004dd000 176 36 36 rw--- [ anon ] 00000000004dd000 176 36 36 rw--- [ anon ] 000000c000000000 131072 98508 98508 rw--- [ anon ] | 000000c000000000 131072 104652 104652 rw--- [ anon ] 00007f26010ad000 39816 3236 3236 rw--- [ anon ] | 00007f26010ad000 39816 3432 3432 rw--- [ anon ] 00007f260378f000 263680 0 0 ----- [ anon ] 00007f260378f000 263680 0 0 ----- [ anon ] 00007f261390f000 4 4 4 rw--- [ anon ] 00007f261390f000 4 4 4 rw--- [ anon ] 00007f2613910000 293564 0 0 ----- [ anon ] 00007f2613910000 293564 0 0 ----- [ anon ] 00007f26257bf000 4 4 4 rw--- [ anon ] 00007f26257bf000 4 4 4 rw--- [ anon ] 00007f26257c0000 36692 0 0 ----- [ anon ] 00007f26257c0000 36692 0 0 ----- [ anon ] 00007f2627b95000 4 4 4 rw--- [ anon ] 00007f2627b95000 4 4 4 rw--- [ anon ] 00007f2627b96000 4580 0 0 ----- [ anon ] 00007f2627b96000 4580 0 0 ----- [ anon ] 00007f262800f000 4 4 4 rw--- [ anon ] 00007f262800f000 4 4 4 rw--- [ anon ] 00007f2628010000 508 0 0 ----- [ anon ] 00007f2628010000 508 0 0 ----- [ anon ] 00007f262808f000 384 44 44 rw--- [ anon ] 00007f262808f000 384 44 44 rw--- [ anon ] 00007ffcdd81c000 132 12 12 rw--- [ stack ] 00007ffcdd81c000 132 12 12 rw--- [ stack ] 00007ffcdd86d000 12 0 0 r---- [ anon ] 00007ffcdd86d000 12 0 0 r---- [ anon ] 00007ffcdd870000 8 4 0 r-x-- [ anon ] 00007ffcdd870000 8 4 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ffffffffff600000 4 0 0 r-x-- [ anon ] ---------------- ------- ------- ------- ---------------- ------- ------- ------- total kB 771528 102720 101868 | total kB 771528 109060 108208  我们注意到起始地址为000000c000000000 和 00007f26010ad000的区间，RSS内存数量涨了，这说明这里物理内存占用增加了，在明确程序存在内存泄露的前提下，这样的内存区域可以作为可疑内存区去分析一下。或者，是有连续的大内存区块，也是待分析的可疑对象，或者这样的内存区块数量比较多，也应该作为可疑的分析对象。\n找到可疑内存区域之后，就尝试里面的内容导出，导出后再借助strings、hexdump等工具进行分析，通常会打印出一些字符串相关的信息，一般这些信息会帮我们联想起，这些数据大约对应着程序中的哪些数据结构、代码逻辑。\n先执行 gdb -p $(pidof leaks) attach 目标进程，然后执行下面两条命令导出可疑内存区：\ngdb\u0026gt; dump binary memory leaks.p1 0x000000c000000000 0x000000c000000000+131072*1024 gdb\u0026gt; dump binary memory leaks.p2 0x00007f26010ad000 0x00007f26010ad000+39816*1024  然后尝试用strings或者hexdump\n$ strings leaks.p1 ... e[0;34m\\]\\W\\[$(git_color)\\]$(git_branch) \\[\\e[0;37m\\]$\\[\\e[0m\\] SXPFD EXPF e[0;34m\\]\\W\\[$(git_color)\\]$(git_branch) \\[\\e[0;37m\\]$\\[\\e[0m\\] SXPFD EXPF TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT...CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT....CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC...TTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT ...  or\n$ hexdump -C leaks.p1 ... 0008e030 00 00 00 00 00 00 00 00 08 9d f0 00 35 43 00 00 |............5C..| 0008e040 01 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| 0008e050 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00090000 00 e0 08 00 c0 00 00 00 00 00 00 00 00 00 00 00 |................| 00090010 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 |................| * 00100000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00200000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00400000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00500000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00700000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00800000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00a00000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00b00000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 00d00000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * 00e00000 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 |CCCCCCCCCCCCCCCC| * 01000000 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 54 |TTTTTTTTTTTTTTTT| * ...  通过这里的输出，假定这里的输出的一些字符串信息CCCCCCC or TTTTTTTTT是一些更有意义的信息，那它可能帮助我们和程序中的一些数据结构、代码逻辑建立起联系，比如看到这里的字符串C，就想到了配置加载conf.LoadConfig，看到字符串T，就想到了task.NewTask，然后进去追查一下一般也能定位到问题所在。\n使用 gcore转储整个进程，原理类似，gcore会在转储完后立即detach进程，比手动dump速度快，对traced进程的影响时间短，但是转储文件一般比较大（记得ulimit -c设置下），core文件使用hexdump分析的时候也可以选择性跳过一些字节，以分析感兴趣的可疑内存区。\n其他方式 # 内存泄露的排查方式有很多，工具也有很多，比如比较有名的valgrind，但是我测试过程中，valgrind没有像bcc那样精确地定位到内存泄露的位置，可能是我的使用方式有问题。see debugging cgo memory leaks，感兴趣的可以自己研究下。这里就不再展开了。\n总结 # 本文介绍了内存泄露相关的定位分析方法，虽然是面向go开发介绍的，但是也不局限于go，特别是ebpf-memleak的应用，应用面应该会比较广。eBPF对Linux内核版本是有严格要求的，使用过程中也需要注意，eBPF的优势在于它为观测、测量提供了强大的基础支持，所以bcc才会有那么多的分析工具，是不可多得利器。\n本文也算是自己对eBPF的一个初步尝试吧，希望掌握它对自己以后的工作有帮助。开发人员手上可以用的工具不少，但是真的好用、省心的也没有那么多，如果能bcc一行代码定位到位置，我想我也不会愿意pmap、gdb gcore、gdb dump、strings+hexdump\u0026hellip;来分析内存泄露位置，当然如果情况不允许，比如内核版本不支持bcc，那还是灵活选择合适的方式。\n除了掌握上述分析方法，解决已经引入的内存泄露问题，研发流程上也应该多关注上线前测试、CR等基础的规范，尽量将一些问题前置，早发现早解决。\n参考内容 #  memory leaking, https://go101.org/article/memory-leaking.html golang memory leaks, https://yuriktech.com/2020/11/07/Golang-Memory-Leaks/#:~:text=A%20goroutine%20leak%20happens%20when,an%20out%20of%20memory%20exception. finding memory leak in cgo, https://kirshatrov.com/2019/11/04/finding-memory-leak-in-cgo/ dive-into-bpf, https://qmonnet.github.io/whirl-offload/2016/09/01/dive-into-bpf/ introduction to xdp and ebpf, https://blogs.igalia.com/dpino/2019/01/07/introduction-to-xdp-and-ebpf/ debugging cgo memory leaks, https://www.youtube.com/watch?v=jiSWxpcuGPw choosing a linux tracer, http://www.brendangregg.com/blog/2015-07-08/choosing-a-linux-tracer.html taming tracepoints in the linux kernel, https://blogs.oracle.com/linux/taming-tracepoints-in-the-linux-kernel linux tracing systems \u0026amp; how they fit together, https://jvns.ca/blog/2017/07/05/linux-tracing-systems/  "}),a.add({id:322,href:"/tags/pprof/",title:"pprof",description:"",content:""}),a.add({id:323,href:"/tags/%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2/",title:"内存泄露",description:"",content:""}),a.add({id:324,href:"/tags/clock/",title:"clock",description:"",content:""}),a.add({id:325,href:"/tags/clock-skew/",title:"clock skew",description:"",content:""}),a.add({id:326,href:"/tags/leap-second/",title:"leap second",description:"",content:""}),a.add({id:327,href:"/tags/%E6%97%B6%E9%92%9F/",title:"时钟",description:"",content:""}),a.add({id:328,href:"/tags/%E6%97%B6%E9%92%9F%E6%BC%82%E7%A7%BB/",title:"时钟漂移",description:"",content:""}),a.add({id:329,href:"/blog/2021-03-09-%E8%81%8A%E8%81%8A%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4/",title:"聊聊计算机系统中的时间",description:"我相信很多人都是时间管理大师，几乎所有人都知道生活中如何运用时间，但是我相信很多人并不知道这个世界的时间是如何工作的。\n你了解时间吗 # 如果不相信，那我问几个问题，看读者知道不？\n 你听说过石英晶体吗？ 你听说过晶振振荡周期吗？ 你听说过时钟中断吗？ 你听说过计时电路吗？ 你听说过时钟漂移吗？ 你听说过铯原子钟吗？ 你听说过BIH这个机构吗？ 你听说过闰秒吗？ 你听说过NTP协议吗？ etc.  如果，你不能一一回答上述问题，那这个地球上的时间是如何工作的，你可能并不太清楚 :)。\n我们日出而出、日落而息，我们规划工作事项，我们协调重要工作，我们安排计算机程序精密协作……时间是非常重要的，以至于我们生物进化过程中形成了“生物钟”来适应，它无影无形，它无处不在。\n我们如何测量时间的 # 凭感觉不靠谱 # 先介绍下，我们试如何测量时间的。这并不像大多数人想象的那样简单，烧一炷香？个时辰，或者来个沙漏一只椰子鸡炖熟了，这个有一定的实用价值，但是非常不精确，对于精度要求较高时更是如此。\n天文学测量方式 # 自动17世纪机械钟发明以来，我们就一直在用天文学的方法测量时间。每天太阳都是从东方地平线上升起，然后升到天空的最高处，最后再落到西边。太阳到达天空中的最高点时，称为“中天”（transit of the sun），它在每天正午达到最高点。两次连续的太阳中天之间的时间称为一个“太阳日”（solar day）。因为每天都会有24小时，每小时都有3600s，所以一个“太阳秒”（solar second）被精确定义为 1/86400 个太阳日。\n那么平均太阳日的几何算法，则可以由下图所示：\nps：有些人想为什么不地球自转一周算1天？其实这就是上图中的“恒星日”（sidereal day），以遥远的恒星为参考物，每天转到这个方位算是一个恒星日。但是我们自然万物向阳而生，以太阳这颗大恒星作为参考系似乎是更合理的计时方法。\n在20世纪40年代，科学家们证实了地球的自转周期并非常数（const value，固定值）。由于潮汐摩擦和大气的阻力，地球的自转速度正在变慢。基于对远古时代珊瑚的生长图案的研究，低质学家现在相信，在3亿年前每年大约有400天（太阳日）。年的长度（地球绕太阳一周的时间）被认为是不变的，那么每天的时间就简单地边长了。除了这种长期变化趋势，也存在一点长短的短期变化，这可能是是由于地球地核层熔岩的剧烈沸腾而引起的。\n这些发现，促使天文学家们在计算天的长度时要测量很多天的长度，然后再对它们取平均值，最后除以86400得到的结果称为“平均太阳秒”（mean solar second）。\n物理学测量方式 # 1948年的时候，原子钟诞生，它使更精确地测量时间成为可能。原子钟不受地球的摆动和振动的影响，而是通过铯133原子的跃迁来计时。物理学家从天文学家的手中接管了计时的工作，定义1秒是铯133原子做9192631770次跃迁所用的时间。选择9192631770是为了是原子秒与引入原子秒那一年的平均太阳秒相等。\n目前世界上大约有50个实验室拥有铯133原子钟。每个实验室都定期向巴黎的BIH（Bureau International Heure）报告其时钟滴答数。BIH将这些值平均起来产生“国际原子时间”（international atomic time，简称TAI）。这样TAI就是铯133原子钟从1958年1月1日午夜（起始时间）以来被9192631770除后的平均滴答数。\n尽管TAI相当稳定，并且任何人只要愿意，都可以买到一只铯原子钟，但是它仍然存在一个严重的问题，那就是86400个TAI秒比现在一个平均太阳日要少3微秒（因为平均太阳日越来越长了）。使用TAI计时将意味着多年以后，中午会出现地越来越早，直到最终出现在凌晨（太阳还不知道在哪睡觉，TAI秒却显示已经中午了）。\nUTC与闰秒 # 人们也许早晚会注意到这些变化，今后可能将会发生与1582年古罗马教皇Pope Gregory十三世宣布从日历中删除10天时类似的情况。这一事件导致了街头暴动，因为地主要收一个整月的地租，银行家要收一个整月的利息，而雇主拒绝向雇员支付他们没有工作的那10天的工资，这里只是提到了其中的几个冲突。在一些新教区，人们拒绝任何与教皇法令相关的事情，有长达170年不接受罗马教皇颁布的日历。\nBIH通过引入“闰秒”（leap second）来解决这个问题，避免以后出现类似罗马教皇一次删10天日历的情况，也避免造成世界范围内难以协调、预料的灾难。闰秒什么意思呢，即当TAI和太阳秒计时之间的差增加到800微秒的时候就要使用一次闰秒。闰秒的使用如下图所示。即在箭头指向的时刻处，TAI和太阳秒相差超过阈值时，在UTC中应用一次闰秒，使得UTC保持同步。\n这种修正，产生了一种时间系统，该时间系统基于恒定长度的TAI秒，并力求和太阳的运动保持一致，它被称为“统一协调时间”（universal coordinated time，简称UTC）。UTC是现代人计时的基础。它从根本上取代了原有的标准“格林尼治天文时间”（greenwich mean time），格林尼治天文时间是一种天文时间。\n闰秒的\u0026quot;阴暗面\u0026quot; # 值得一提的是，闰秒有正有负，因为地球自转受很多因素影响，有时变快有时变慢（显然我们很难直观察觉到），不同的时间段内情况也不同，比如从1972年到2020年平均每21个月就有一次闰秒出现，但是有的时间段内则没有闰秒。\n 闰秒为正的情况，UTC时间戳可能会出现这样的时间序列：23:59:59 -\u0026gt; 23:59:60 -\u0026gt; 00:00:00 闰秒为负的情况，UTC时间戳可能会出现这样的时间序列：23:59:58 -\u0026gt; 00:00:00   ps：自1970年后，这过去的几十年里基本上地球自转都是变慢的，所以出现的闰秒都是正闰秒，但是最近几年地球自转有变快的情况，如果一直持续下去，后面可能会出现负闰秒。不过现在也有很多提案希望废除闰秒，因为它确实带来太多问题了。",content:"我相信很多人都是时间管理大师，几乎所有人都知道生活中如何运用时间，但是我相信很多人并不知道这个世界的时间是如何工作的。\n你了解时间吗 # 如果不相信，那我问几个问题，看读者知道不？\n 你听说过石英晶体吗？ 你听说过晶振振荡周期吗？ 你听说过时钟中断吗？ 你听说过计时电路吗？ 你听说过时钟漂移吗？ 你听说过铯原子钟吗？ 你听说过BIH这个机构吗？ 你听说过闰秒吗？ 你听说过NTP协议吗？ etc.  如果，你不能一一回答上述问题，那这个地球上的时间是如何工作的，你可能并不太清楚 :)。\n我们日出而出、日落而息，我们规划工作事项，我们协调重要工作，我们安排计算机程序精密协作……时间是非常重要的，以至于我们生物进化过程中形成了“生物钟”来适应，它无影无形，它无处不在。\n我们如何测量时间的 # 凭感觉不靠谱 # 先介绍下，我们试如何测量时间的。这并不像大多数人想象的那样简单，烧一炷香？个时辰，或者来个沙漏一只椰子鸡炖熟了，这个有一定的实用价值，但是非常不精确，对于精度要求较高时更是如此。\n天文学测量方式 # 自动17世纪机械钟发明以来，我们就一直在用天文学的方法测量时间。每天太阳都是从东方地平线上升起，然后升到天空的最高处，最后再落到西边。太阳到达天空中的最高点时，称为“中天”（transit of the sun），它在每天正午达到最高点。两次连续的太阳中天之间的时间称为一个“太阳日”（solar day）。因为每天都会有24小时，每小时都有3600s，所以一个“太阳秒”（solar second）被精确定义为 1/86400 个太阳日。\n那么平均太阳日的几何算法，则可以由下图所示：\nps：有些人想为什么不地球自转一周算1天？其实这就是上图中的“恒星日”（sidereal day），以遥远的恒星为参考物，每天转到这个方位算是一个恒星日。但是我们自然万物向阳而生，以太阳这颗大恒星作为参考系似乎是更合理的计时方法。\n在20世纪40年代，科学家们证实了地球的自转周期并非常数（const value，固定值）。由于潮汐摩擦和大气的阻力，地球的自转速度正在变慢。基于对远古时代珊瑚的生长图案的研究，低质学家现在相信，在3亿年前每年大约有400天（太阳日）。年的长度（地球绕太阳一周的时间）被认为是不变的，那么每天的时间就简单地边长了。除了这种长期变化趋势，也存在一点长短的短期变化，这可能是是由于地球地核层熔岩的剧烈沸腾而引起的。\n这些发现，促使天文学家们在计算天的长度时要测量很多天的长度，然后再对它们取平均值，最后除以86400得到的结果称为“平均太阳秒”（mean solar second）。\n物理学测量方式 # 1948年的时候，原子钟诞生，它使更精确地测量时间成为可能。原子钟不受地球的摆动和振动的影响，而是通过铯133原子的跃迁来计时。物理学家从天文学家的手中接管了计时的工作，定义1秒是铯133原子做9192631770次跃迁所用的时间。选择9192631770是为了是原子秒与引入原子秒那一年的平均太阳秒相等。\n目前世界上大约有50个实验室拥有铯133原子钟。每个实验室都定期向巴黎的BIH（Bureau International Heure）报告其时钟滴答数。BIH将这些值平均起来产生“国际原子时间”（international atomic time，简称TAI）。这样TAI就是铯133原子钟从1958年1月1日午夜（起始时间）以来被9192631770除后的平均滴答数。\n尽管TAI相当稳定，并且任何人只要愿意，都可以买到一只铯原子钟，但是它仍然存在一个严重的问题，那就是86400个TAI秒比现在一个平均太阳日要少3微秒（因为平均太阳日越来越长了）。使用TAI计时将意味着多年以后，中午会出现地越来越早，直到最终出现在凌晨（太阳还不知道在哪睡觉，TAI秒却显示已经中午了）。\nUTC与闰秒 # 人们也许早晚会注意到这些变化，今后可能将会发生与1582年古罗马教皇Pope Gregory十三世宣布从日历中删除10天时类似的情况。这一事件导致了街头暴动，因为地主要收一个整月的地租，银行家要收一个整月的利息，而雇主拒绝向雇员支付他们没有工作的那10天的工资，这里只是提到了其中的几个冲突。在一些新教区，人们拒绝任何与教皇法令相关的事情，有长达170年不接受罗马教皇颁布的日历。\nBIH通过引入“闰秒”（leap second）来解决这个问题，避免以后出现类似罗马教皇一次删10天日历的情况，也避免造成世界范围内难以协调、预料的灾难。闰秒什么意思呢，即当TAI和太阳秒计时之间的差增加到800微秒的时候就要使用一次闰秒。闰秒的使用如下图所示。即在箭头指向的时刻处，TAI和太阳秒相差超过阈值时，在UTC中应用一次闰秒，使得UTC保持同步。\n这种修正，产生了一种时间系统，该时间系统基于恒定长度的TAI秒，并力求和太阳的运动保持一致，它被称为“统一协调时间”（universal coordinated time，简称UTC）。UTC是现代人计时的基础。它从根本上取代了原有的标准“格林尼治天文时间”（greenwich mean time），格林尼治天文时间是一种天文时间。\n闰秒的\u0026quot;阴暗面\u0026quot; # 值得一提的是，闰秒有正有负，因为地球自转受很多因素影响，有时变快有时变慢（显然我们很难直观察觉到），不同的时间段内情况也不同，比如从1972年到2020年平均每21个月就有一次闰秒出现，但是有的时间段内则没有闰秒。\n 闰秒为正的情况，UTC时间戳可能会出现这样的时间序列：23:59:59 -\u0026gt; 23:59:60 -\u0026gt; 00:00:00 闰秒为负的情况，UTC时间戳可能会出现这样的时间序列：23:59:58 -\u0026gt; 00:00:00   ps：自1970年后，这过去的几十年里基本上地球自转都是变慢的，所以出现的闰秒都是正闰秒，但是最近几年地球自转有变快的情况，如果一直持续下去，后面可能会出现负闰秒。不过现在也有很多提案希望废除闰秒，因为它确实带来太多问题了。\nsee：https://www.timeanddate.com/time/negative-leap-second.html\n 对于计算机系统中的石英晶体，由于其精度的问题，会导致时间上出现偏差（过快或过慢都有可能），计算机系统通过NTP协议（network time protocol）与时间服务器（time server）进行通信来同步最新的时间。当出现闰秒时，NTP服务器一般会告知客户端出现了闰秒（通过Leap Indicator告知客户端），客户端收到后要进行适当的处理，当然不同的操作系统处理方式不一样。\nUTC与Unix时间戳 # 再重复下，UTC是协调世界时（Coordinated Universal Time）的缩写，是一种国际标准的时间标准，用于协调全球各地的时间。UTC时间标准是基于原子钟的时间测量，它的秒长是固定的，每秒钟恒定为9192631770个周期的辐射。UTC时间标准是世界上最广泛使用的时间标准之一，它被广泛应用于科学、技术、航空、航天、通信、金融等领域。\n一个完整的UTC时间表示是“YYYY-MM-DDTHH:mm:ss.sssZ”，其中Z表示时区信息，当你拿到一个UTC时间之后，就可以转换成全球其他时区的时间，比如北京是东八区，和UTC时区差8个小时，可以zdump -v /usr/share/zoneinfo/Asia/Shanghai查看。\nUnix时间戳通常是一个整数，表示从1970年1月1日00:00:00 UTC开始到当前时间所经过的秒数，将其转换为Unix timestamp后，这个值是与timezone无关的，因为UTC包含了时区信息。既然是基于UTC时间1970-01-01 00:00:00+时区offset以后的秒数，那么就是与时区无关的了。see Do UNIX timestamps change across timezones?。\n闰秒与UTC、Unix时间戳 # 当出现闰秒时，会对UTC时间进行调整，导致计算出的Unix时间戳也会收到影响，比如下面这个例子，正闰秒1s以及紧跟着的1s，unix时间戳会重复。当从unix时间戳转换为UTC时间时会对应着2个时间，这就出现了歧义。\n要解决这个问题，就需要查闰秒表，通过这个来修正才能比较好地解决此问题。\n很多应用程序都是使用Unix时间戳（没有考虑闰秒的）来作为应用程序中的时间的，如果操作系统贸然插入1s或者减去1s都会对时间敏感的应用造成严重后果。用户先后发起了两个操作，修改订单、下单请求，请求里面都带有时间戳，但是如果取消订单时因为闰秒的原因导致时间向过去跳了1s，造成服务端看来用户是先下单，后修改订单，那么将导致订单修改失败（通常是下单后无法修改的）。\nps: 比这个问题严重的多的场景多的是，当然健壮的系统会考虑采用逻辑时钟等手段来解决，如向量时钟，这里不多说了。\n为了避免应用程序处理这个闰秒问题的复杂性，屏蔽不同操作系统的差异，有些大厂会自建NTP服务器，在收到上游NTP服务器的闰秒事件时，会通过leap smear的方式，将这个闰秒事件的影响均匀地打散到接下来的时间里，使得时间一直是只增不减的。这样公司内部从自建NTP服务器上同步过去的时间虽然可能会有点点不那么精准，但是却很有效地解决了闰秒可能带来的潜在的灾难。\nGoogle内部就是借助leap smear的方式来做的，当接收到通知某天有闰秒出现，自建NTP服务器（修改代码支持leap smear）将闰秒打散到全天，保证时间慢慢增加，内部服务器都用这个时间，就不用处理闰秒带来的跳变的问题了。Amazon采取了类似的方式，稍有不同，以及其他的一些做法，可以参考维基百科。\n鉴于UTC引入leap second所带来的的问题，比如对计算机系统、分布式系统等等，国际会议也在讨论要不要考虑更好的方式，比如应用程序中希望使用精确时间时总是使用TAI，而在希望人类可读的场景下将其转换成UTC显示。其实Google采用的leap smear的方式也是一种比较好的实践。\n计算机如何测量时间的 # 计算机的物理时钟 # 计算机中有一个计时电路，尽管通常使用“时钟”这个概念，但是用“计时器（timer）”更恰当一点。计算机的计时器通常是一个精密加工的石英晶体，石英晶体在其张力限度内以一定的频率振荡，这个频率取决于晶体本身如何被切割及其受到的张力的大小。\n有两个寄存器与每个石英晶体相关联，一个是计数器（counter），另一个是保持寄存器（holding register）。石英晶体的每次振荡使计数器-1，当减为0时则触发一个中断；然后，计数器从保持寄存器中重新装入初始值。每次中断称为一个时钟滴答。\n系统初次启动时，通常要求用户输入日期和时间，然后将它们转换成某一个已知起始时间后的时钟滴答次数，并将它存储在存储器中。许多计算机都有一个特殊的电池支持的CMOS RAM，其目的是为了以后启动时不再需要输入日期和时间。\n时钟每滴答一次，就产生一个时钟中断，时钟中断服务程序就使存储在存储器里面的时间值+1。用这种方法进行（软）时钟计时。\nps：多CPU系统中，每个CPU都有自己的时钟。\n大家了解到我们现在已经用原子钟测量时间了，我们不禁要问，这个晶振振荡周期规律么、精准吗？不精准！时间久了，计算机的物理时钟时间与世界真实时间就有了偏差，称之为”时间偏移“（time skew）。\n别担心，我们还有计算机网络，我们可以让计算机通过计算机网络与时间更精准的服务器进行通信，来同步时间。\n网络时间协议NTP # 我们可以让自己的服务器与时间服务器（time server）进行通信完成时间的同步。时间服务器可以精确地提供当前时间，因为它装备了一个WWV接收器或一个精确的时钟。\nps: WWV（shortwave radio station）接收器，使得安装有该设备的接收器可以通过GPS全球定位系统来同步时间，声称误差在20~35ns误差范围内，可以说是相当精确了。GPS卫星上也是安装的原子钟。如果想了解如何借助GPS全球定位系统实现时间同步，可以自行查阅相关资料，这里不再展开。\n当然，问题是，何时与该服务器联系，消息延时会使得报告的时间过时，这里有个技巧，就是给消息带上时间戳，好让我们对消息的传输延时做出很好的估计。比如像下图这样：\n要求client A、server B发送接收消息时都带上当时时刻的时间信息，这样我们就可以大致算出client A发送请求到server B接收的传输时延为T2-T1，同理可知server B发送响应给client A的传输时延为T4-T3，我们有理由相信这两次传输的时间应该相差无几，为了让传输时延影响更小，就取平均值作为传输时延吧。然后基于T3这个响应的时间点，我们相信T3是NTP server的准确时间，所以就可以计算出当前client A同步到的时间为：\nT = T3 + ((T2-T1)+(T4-T3))/2  这个很好理解。\n不要高兴太早，我们还需要意识到一个问题，就是时间不允许后退的问题。时间一旦出现后退，对无数的电子设备、计算机系统而言将是十足的灾难。\n这里的同步到的时间T相对本地当前时间而言，是更快的话，直接设置当前时间为T就行了？似乎没问题。那如果是慢了呢？直接调慢行吗，前面说了，不行，这回让时间倒退。\n实际上，计算机系统可以采用一种逐步调整的方式。比如，假设计时器设置为每秒产生100个中断。正常情况下，每个中断将添加10ms，当减慢时，每个中断例程只添加9ms，直到校正完成为止。同样的，通过在每个中断中添加11ms，时钟也可以逐步往前调快。\n网络时间协议在服务器之间创建了两条连接，比如上面讲了A可以参考B的时间调整自己的时间，原则上B也可以参照A的调整自己的呀！是这样吗，如果B上面装了WWV接收器或者原子钟，那么一个拥有精确时间的NTP去参考一个靠普通石英晶体维护时间的NTP，这不是犯傻吗？怎么解决这个问题呢？\nNTP服务器也是分层的，通常拥有WWV接收器或者原子钟的，称为1层服务器，那0层是谁？OK，0层指的是时钟本身。其他k层（k\u0026gt;1）服务器可以参考k-1层的服务器来完成时间同步，反过来则不行。如果一个NTP服务器是k层服务器，另一个服务器是k+2层服务器，其如果通过k层服务器调整后，它将从k+2层变为k+1层。\nNTP中还是有很多重要的特性的，并不是像我们想象的那么简单，感兴趣的话可以参考相关资料。\n如何解决时间漂移问题 # 前面我们介绍了测量时间的方式，从经验主义，到天文学测量，到物理学测量，以及兼顾物理学、天文学的测量，方式也一步步更加精确、完善、实用。我们还谈到了计算机系统中的时间系统是如何更新的。想必大家感觉对于这个星球上的时间系统的工作原理更清晰了。\n这里还有个问题，就是时间漂移问题。尽管我们前面提及了精确测量时间、时间同步协议等尽可能保证时间准确的方式，但是效果也是”尽可能”让其精确，我们还是不能百分百地保证全球所有电子设备、分布式系统中节点的时间是完全一致的，甚至是同一个计算机但是是多处理器系统中的多个时钟也不是完全一致的。\n这回带来什么问题呢？如果运行其上的系统，依赖“时间”对操作顺序执行先后做判断，那这样的系统很可能是存在问题的。\n在分布式系统设计中，一般会采用“逻辑时钟”、“向量时钟”等方式来代替真实时钟，来作为操作顺序执行先后的判断依据。这里的内容有很多，后面我们有机会再单独写一篇文章来介绍。\n总结 # 本文开头给大家泼了点冷水，很可能让部分读者对自信了解的时间没了信心 :) ，然后我们介绍了时间测量方式的一些演变，以及计算机系统中如何保持时间的同步，最后又抛出了另一个值得深思的问题，如何解决时间漂移问题在多处理器系统、分布式系统中带来的时序相关的问题。\n相信大家对时间有了一个更深的认识，也希望激发了大家对时间的进一步思考吧。\n参考文献：\n leap second five different ways handle leap seconds what is a leap second leapsecond.com interesting info on leap second gps network time synchonization what is a negative leap second Do UNIX timestamps change across timezones?  "}),a.add({id:330,href:"/tags/%E9%97%B0%E7%A7%92/",title:"闰秒",description:"",content:""}),a.add({id:331,href:"/tags/invalidate-queue/",title:"invalidate queue",description:"",content:""}),a.add({id:332,href:"/tags/memory-barrier/",title:"memory barrier",description:"",content:""}),a.add({id:333,href:"/tags/store-buffer/",title:"store buffer",description:"",content:""}),a.add({id:334,href:"/blog/2020-12-15-%E7%A1%AC%E4%BB%B6%E8%A7%86%E8%A7%92%E5%89%96%E6%9E%90%E5%86%85%E5%AD%98%E5%B1%8F%E9%9A%9C%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/",title:"硬件视角剖析内存屏障实现原理",description:"内存屏障类型 # 软件开发中创建屏障 # 硬件视角看屏障实现 # 总结 # text goes here",content:"内存屏障类型 # 软件开发中创建屏障 # 硬件视角看屏障实现 # 总结 # text goes here\n"}),a.add({id:335,href:"/tags/%E4%BB%A3%E7%A0%81%E8%A7%84%E8%8C%83/",title:"代码规范",description:"",content:""}),a.add({id:336,href:"/tags/%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F/",title:"代码质量",description:"",content:""}),a.add({id:337,href:"/tags/%E5%8F%AF%E8%AF%BB%E6%80%A7/",title:"可读性",description:"",content:""}),a.add({id:338,href:"/blog/2020-10-16-%E5%81%B7%E6%87%92%E4%BB%8E%E6%8F%90%E5%8D%87%E4%BB%A3%E7%A0%81%E8%B4%A8%E9%87%8F%E5%BC%80%E5%A7%8B/",title:"如何“偷懒”：从提升代码质量开始",description:"如果一件事情只需要做一次，我们可能怎么方便怎么来，但是如果一件事情要重复千百遍，怎么方便怎么来就会变成灾难。对身体，对时间，对团队。停下来想想过去做的一些事情，都是为了做好事情的同时，能让自己更好地慢下来，让身体可以偷懒。本文先从提升代码质量开始谈起。\nLinus Torvards在一次采访中，主持人贴了两个链表操作的实现，让其评价哪一种更好一点，Torvards说更喜欢消除了特殊逻辑的那种，并将这种偏好称为“taste”。每个人的taste不同，也不方便评价好与坏，但是“脑筋急转弯似”的做法一点都不“聪明”。好的思路很多都是相同的，不好的东西千差万别的厉害。\n站在巨人肩膀上 # 从什么时候开始，我开始思考如何在有限的时间里涉猎更多的东西，awesome、101、patterns、slideshare、best practices\u0026hellip;似乎有限的时间被延长了，我们没必要一个个坑的踩过来摸索中前进，别把别人头破血流总结出的经验教训不当回事。以前我奉行“纸上得来终觉浅、绝知此事要躬行”，很好，但是生命是有限的。\n想要更大的世界，必须懂得借力，吸收经验教训，好的坏的全部统统吸纳滋养自己。\n对异常关注不足，未养成安全编程习惯 # 经常看到 if ok {...} else {...} 这样的代码，没有养成优先处理异常的习惯。导致出现多余的if-else分支是小事，怕的是，这么习惯了容易产生下面的问题：if中先处理正常逻辑，else中再事后补异常处理逻辑，而对异常情景的细分，也可能会因为“功能已完成、异常哪有那么巧出现”的侥幸心理而有所倦怠，如rpc错误是网络错误、超时还是逻辑逻辑，每种该作何处理，可能会草草了事。不能说这种担心是多余的，人都是属驴的，自己也会有这种惰性。\n对输入不做校验，“不大可能”，这不能算是一个合理的理由，“调用方判断”，这更不合理。这就好比我想吃饭了，从商家买到过保质期的食物，那我作为活动的发起方（调用方）我肯定会检查下食物保质期，但是商家也不能不管保质期就卖给我吧。那这么看，是调用方检查，还是提供方检查，还是没必要。自己的函数坑自己的服务，也是坑。\n每每提及“高可用”、5个9，大家就竖起耳朵听，可是连基本的进程级的健壮性都不下功夫，又怎么去奢求诗和远方。\n写的虽然是代码，但其实是逻辑的表达 # 发明高级语言的目的，就是为了更好的表达，但是我们学会了编程语言，却忘了怎么表达。\n我想了想那些好的文章是怎么写的，我们需要一个吸睛的标题来惹人关注，需要时刻不忘中心思想避免论述过于涣散，还需要凤头猪肚豹尾来层层论述，每个段落也要有提纲挈领的中心句。如果说是一本书，也还是类似的，但是又有了其他的要求，章节并不是硬性的切割，有时候我们前言里会看到，您可以根据情况自主选择感兴趣的章节阅读，那是因为各个章节相对独立，结合起来又形成一个更完备的论述。\n那，代码该怎么写呢？\n一个服务的所有逻辑，平铺在一个工程下的源文件中，没有任何模块化的组织，比如go项目没有任何package，那我们的逻辑是变复杂了还是变简单了？ 函数、方法调用体现的是一种通信，当我们去和别人沟通时，我们一定是清晰地知道别人能提供我们需要的服务，才会去选择与其沟通，而且为了有效率的沟通，还要言简意赅。那一个package、receiver下的函数、方法不区分导出、非导出，那该选择哪个发起通信呢？而且内部的一些实现细节也不关心，我只关心能不能买到服务。 完成一项任务，总可以拆分成几个步骤，所以我们可以先写伪代码列出todolist，基本上每一项todo都是一个相对独立的逻辑，还可以为每个相对独立的逻辑加一行简单的注释，末尾加空行隔开，以体现出逻辑区块。难道从头撸到尾能将逻辑表达的更清晰？想象一篇没有标点的作文该怎样阅读？ …… 有时候，我们说编码好坏是习惯问题，是taste，但我觉得是思维习惯的问题。这样的习惯日积月累，负面影响可能会更大。\n简单点再简单点，简单可依赖 # 什么是简单？是方便，是省心？我觉得是诚实不隐瞒，是就是，不是就不是。最恨的就是那些表面光正背后搞小动作的代码。\n有些代码表里不一，表面是一套，背后是一套。命名说是做这个，结果背后不干这个，或者除了干这个还干别的。为什么我们使用一些标准库的api的时候就愿意选择相信它，但是看我们自己代码的时候就不得不频繁地跳来跳去呢？\n不相信写的代码，原因跟下面经常遇到的问题相关，经过了现实的捶打只能先“另眼相看”； 导出类型、方法、函数、变量、常量缺乏必要的注释，不得已只能跳过去看代码； 函数签名多返回值没有必要说明，如返回值变量名，除了最后一个是error不知其他干嘛的，只能跳过去看return，问题是还有多个return出口； 函数签名参数列表，shorter \u0026amp; simpler，如果有近10个、20来个参数，怎么记得住形参？传实参的时候会不会对应错误？哪些参数是必填、选填？命名是否能准确清晰地覆盖这些参数？ hack逻辑，如硬编码，这些损失的不只是灵活性，也植入了一些暗黑操作。一个好的软件架构师应该做到“make the invisible visible”，invisible的一个直观的害处就是，越俎代庖的事情会变得普遍，本来可以由调用方支配的一些控制参数，被独断专行了，本来应该上升到系统层面的问题，被一个模块偷偷代表了； …… 我的逻辑是，只要阅读代码的时候有非常频繁的跳转、推导、假设、验证的过程，那这个代码的可读性就真的不怎么样。\n公司代码规范 # 只要是规范，就有局限性、滞后性。我理解，规范不是让我们追求完美主义，而是追求better code，better practices。如果一个开发者有好的taste，他写出来的代码可能已经接近或达到规范的要求了。但是并不是每个开发者都有这样的taste，所以我们才需要规范来约束我们做一件共同的事情。\n遵守代码规范的一个明显的好处是，可读性会有比较明显的提升，这是很有意义的。可读性提升，意味着维护成本降低，意味着省下时间，意味着可以在正常工作时间做更多事情，可以早下班休息、充电。这可能不是对每个人都是个好事情，但是是对团队有意义的事情，对多数人有意义的事情，就应该坚持！\n最后 # 多年前翻阅Linux文档，Torvards解释为什么一个Tab非要8个空格而非通用的4个，他说，我就是要让那些爱写嵌套多层代码的人“难受”……\n省下大把自己、大家的时间，这难道不是一种很聪明的“偷懒”行为？",content:"如果一件事情只需要做一次，我们可能怎么方便怎么来，但是如果一件事情要重复千百遍，怎么方便怎么来就会变成灾难。对身体，对时间，对团队。停下来想想过去做的一些事情，都是为了做好事情的同时，能让自己更好地慢下来，让身体可以偷懒。本文先从提升代码质量开始谈起。\nLinus Torvards在一次采访中，主持人贴了两个链表操作的实现，让其评价哪一种更好一点，Torvards说更喜欢消除了特殊逻辑的那种，并将这种偏好称为“taste”。每个人的taste不同，也不方便评价好与坏，但是“脑筋急转弯似”的做法一点都不“聪明”。好的思路很多都是相同的，不好的东西千差万别的厉害。\n站在巨人肩膀上 # 从什么时候开始，我开始思考如何在有限的时间里涉猎更多的东西，awesome、101、patterns、slideshare、best practices\u0026hellip;似乎有限的时间被延长了，我们没必要一个个坑的踩过来摸索中前进，别把别人头破血流总结出的经验教训不当回事。以前我奉行“纸上得来终觉浅、绝知此事要躬行”，很好，但是生命是有限的。\n想要更大的世界，必须懂得借力，吸收经验教训，好的坏的全部统统吸纳滋养自己。\n对异常关注不足，未养成安全编程习惯 # 经常看到 if ok {...} else {...} 这样的代码，没有养成优先处理异常的习惯。导致出现多余的if-else分支是小事，怕的是，这么习惯了容易产生下面的问题：if中先处理正常逻辑，else中再事后补异常处理逻辑，而对异常情景的细分，也可能会因为“功能已完成、异常哪有那么巧出现”的侥幸心理而有所倦怠，如rpc错误是网络错误、超时还是逻辑逻辑，每种该作何处理，可能会草草了事。不能说这种担心是多余的，人都是属驴的，自己也会有这种惰性。\n对输入不做校验，“不大可能”，这不能算是一个合理的理由，“调用方判断”，这更不合理。这就好比我想吃饭了，从商家买到过保质期的食物，那我作为活动的发起方（调用方）我肯定会检查下食物保质期，但是商家也不能不管保质期就卖给我吧。那这么看，是调用方检查，还是提供方检查，还是没必要。自己的函数坑自己的服务，也是坑。\n每每提及“高可用”、5个9，大家就竖起耳朵听，可是连基本的进程级的健壮性都不下功夫，又怎么去奢求诗和远方。\n写的虽然是代码，但其实是逻辑的表达 # 发明高级语言的目的，就是为了更好的表达，但是我们学会了编程语言，却忘了怎么表达。\n我想了想那些好的文章是怎么写的，我们需要一个吸睛的标题来惹人关注，需要时刻不忘中心思想避免论述过于涣散，还需要凤头猪肚豹尾来层层论述，每个段落也要有提纲挈领的中心句。如果说是一本书，也还是类似的，但是又有了其他的要求，章节并不是硬性的切割，有时候我们前言里会看到，您可以根据情况自主选择感兴趣的章节阅读，那是因为各个章节相对独立，结合起来又形成一个更完备的论述。\n那，代码该怎么写呢？\n一个服务的所有逻辑，平铺在一个工程下的源文件中，没有任何模块化的组织，比如go项目没有任何package，那我们的逻辑是变复杂了还是变简单了？ 函数、方法调用体现的是一种通信，当我们去和别人沟通时，我们一定是清晰地知道别人能提供我们需要的服务，才会去选择与其沟通，而且为了有效率的沟通，还要言简意赅。那一个package、receiver下的函数、方法不区分导出、非导出，那该选择哪个发起通信呢？而且内部的一些实现细节也不关心，我只关心能不能买到服务。 完成一项任务，总可以拆分成几个步骤，所以我们可以先写伪代码列出todolist，基本上每一项todo都是一个相对独立的逻辑，还可以为每个相对独立的逻辑加一行简单的注释，末尾加空行隔开，以体现出逻辑区块。难道从头撸到尾能将逻辑表达的更清晰？想象一篇没有标点的作文该怎样阅读？ …… 有时候，我们说编码好坏是习惯问题，是taste，但我觉得是思维习惯的问题。这样的习惯日积月累，负面影响可能会更大。\n简单点再简单点，简单可依赖 # 什么是简单？是方便，是省心？我觉得是诚实不隐瞒，是就是，不是就不是。最恨的就是那些表面光正背后搞小动作的代码。\n有些代码表里不一，表面是一套，背后是一套。命名说是做这个，结果背后不干这个，或者除了干这个还干别的。为什么我们使用一些标准库的api的时候就愿意选择相信它，但是看我们自己代码的时候就不得不频繁地跳来跳去呢？\n不相信写的代码，原因跟下面经常遇到的问题相关，经过了现实的捶打只能先“另眼相看”； 导出类型、方法、函数、变量、常量缺乏必要的注释，不得已只能跳过去看代码； 函数签名多返回值没有必要说明，如返回值变量名，除了最后一个是error不知其他干嘛的，只能跳过去看return，问题是还有多个return出口； 函数签名参数列表，shorter \u0026amp; simpler，如果有近10个、20来个参数，怎么记得住形参？传实参的时候会不会对应错误？哪些参数是必填、选填？命名是否能准确清晰地覆盖这些参数？ hack逻辑，如硬编码，这些损失的不只是灵活性，也植入了一些暗黑操作。一个好的软件架构师应该做到“make the invisible visible”，invisible的一个直观的害处就是，越俎代庖的事情会变得普遍，本来可以由调用方支配的一些控制参数，被独断专行了，本来应该上升到系统层面的问题，被一个模块偷偷代表了； …… 我的逻辑是，只要阅读代码的时候有非常频繁的跳转、推导、假设、验证的过程，那这个代码的可读性就真的不怎么样。\n公司代码规范 # 只要是规范，就有局限性、滞后性。我理解，规范不是让我们追求完美主义，而是追求better code，better practices。如果一个开发者有好的taste，他写出来的代码可能已经接近或达到规范的要求了。但是并不是每个开发者都有这样的taste，所以我们才需要规范来约束我们做一件共同的事情。\n遵守代码规范的一个明显的好处是，可读性会有比较明显的提升，这是很有意义的。可读性提升，意味着维护成本降低，意味着省下时间，意味着可以在正常工作时间做更多事情，可以早下班休息、充电。这可能不是对每个人都是个好事情，但是是对团队有意义的事情，对多数人有意义的事情，就应该坚持！\n最后 # 多年前翻阅Linux文档，Torvards解释为什么一个Tab非要8个空格而非通用的4个，他说，我就是要让那些爱写嵌套多层代码的人“难受”……\n省下大把自己、大家的时间，这难道不是一种很聪明的“偷懒”行为？\n"}),a.add({id:339,href:"/tags/uml/",title:"uml",description:"",content:""}),a.add({id:340,href:"/tags/visualize/",title:"visualize",description:"",content:""}),a.add({id:341,href:"/blog/2020-10-06-visualizing-your-go-code/",title:"Visualizing Your Go Code",description:"代码可读性 # 作为一名开发人员，代码可读性是我们常常挂在嘴边的。代码写出来除了让计算机能够正常执行以外，终究还是要让人能够理解它，后续才能做进一步的维护工作。如果代码写出来，只有它的作者能够看得懂，那只能说明这个作者逻辑表达能力有问题，透过其代码难以看出解决问题的思路。这是软件工程中要尽力避免的。\n在软件工程方法论指导下，为了尽可能让代码可读性达标，我们往往会根据一些最佳实践拟定一些大多数人认可的标准，让所有开发人员遵守，然后通过代码评审、代码规范检查、持续集成交付流水线等综合起来，以尽可能逼近这一目标。当绝大多数人能够在约定的框架下，保质保量提交代码时，我们已经在代码可读性、可维护性方面前进了一大步。\n然而，这样足够了吗？我认为还不够。\n代码是思维的表达 # 代码，不过是通过一种大家都理解的语言书写出来的篇章。就好比写文章一样，要有中心思想，然后围绕中心思想要展开层层描述。写代码一样，中心思想就是我们要解决的问题，围绕中心思想的层层描述就是我们解决问题的思路。所以，代码没有什么神秘的，它是人类思维的表达。\n我们是如何快速理解一篇文章的呢？\n 先看标题，掌握其核心关键词； 看下第一段落的内容，往往第一段会引出问题； 看下其余段落的首句、末句，往往会给出该段落的中心思想； 看下最后一段的内容，一般会给出一个结论； 通篇串下，了解文章整体含义；  为什么我们会通过这种方式？因为一篇好的文章一定有承上启下、过渡。这种循序渐进的方式，步步逼近中心思想。\n那代码呢？某种程度上，代码也是类似的。\n 以go语言为例，通常对于一个package，我们会提供package注释来表示当前package要解决的问题； 每个package内部又包含了不同的types、variables、functions，它们结合起来来解决一个问题； 每一个function内部又分为多个步骤，每一步完成一个小功能，为下一步做好准备； 每一个小功能、步骤可能是if-else, switch-case, for-loop……之类的语言结构； 同时，我们还会提供测试用例，来验证上述方案的正确性。  有没有觉得很相似，或许我们应该采用已有的读书的经验来辅助更好地理解程序？\nOOP思想认识世界 # 代码，和文章不同的是，它虽然有明显的程序构造，但是却没有明显的段落之分。\n那我如何才能借鉴多年来养成的还不错的阅读习惯，来帮助我理解代码呢？当然不能盲目套用，不过俗话说，能工摹形，巧匠窃意，思想很多地方还是可以相通的。\n如何更好地理解这个世界，对各种各样的问题进行抽象呢？比如一辆摩托车，它有离合器、发动机、链条、轮毂、轮胎、减震、油箱、排气等很多部件构成，我听说宝马水鸟电子控制很厉害，可以实现无人驾驶，那可是两轮的400多斤的大机器。那它的电子控制系统怎么做到的？至少要能理解一个摩托车有核心部件，整体运转起来如何理解其状态，如何控制个别部件以影响其他部件进而控制整体状态。那它如何控制部件呢？电子操作或机械操作。\n扯远了，我只是有点喜欢水鸟而已。整个世界可以看做是一个个对象及其之间的联系所构成，代码也不例外。\n道法自然，OOP的思想不过是借鉴了人类认识世界的方式，将其运用到了软件工程领域，以更好地对问题进行抽象，从而构建出设计更合理的软件。那代码里面有哪些语言构造体现了OOP的思想呢。\n 类型与对象，生物学里区分物种、种群、个体，那是因为它们既有共性，也有个性； 通信的方式，自然界个体之间的交互也有多种方式，比如雄狮撒泡尿标记领地也不管入侵者认不认同，或者低吼驱赶入侵者离开，人和人用听得懂的语言沟通； 隐私与距离，每个人都有自己的隐私，如果你的朋友跟你借100块钱你可能给了，但是他如果问是你老婆给的还是你自己的，你可能就不想借给他了，给你就行了你管那么多干嘛呢，我还不想拿自家的借你呢，说不定借你老婆的给你的呢。每个人在一副外表下总有些不愿意被人触碰、靠近的地方。  了解一个人，其实你不需要深入他的家庭本身去了解，看看他天天接触什么人，说些什么话，你也就大致清楚了。感兴趣就继续了解，不感兴趣也就拉倒了。我想绝大多数人都不是窥视狂，在拥有一定判断力的基础上，通过一些局部的信息是可以了解大致的整体信息的。\n理解代码有相同之处？\n流程控制 + 组件交互 # 某种程度上，我认为理解代码也有相似之处。\n如果能够拎出那些比较重要的对象（objects），以及他们之间的通信（function call, chan send/recv），或者他们的私密信息（注释），是不是也能够大致有个了解呢？\n如果想更深入了解下，加上事情的脉络（控制结构，if-else, switch-case, for-loop）呢？\n其他信息? 我相信还有其他有用的有用信息，能够通过一些更加有效率的方式呈现出来。\n认识 go/ast # 计算机编程语言，有多少种？我认为只有一种，就是人类可以理解的语言。有趣的是，编程语言之多可以覆盖元素周期表，不信来瞧瞧。\n       语言是什么？语言有精确的数学定义，它不是胡编乱造，尤其是编程语言； 编程语言更精确？那倒未必，人类社会多姿多彩之处，就在于会演绎出更加丰富多彩的内容，包括对语言的破坏性“创造”，人脑纠错能力太强了，我们甚至没有察觉到自己犯了错误，如网上津津乐道的山东人倒装玩法； 我能发明一门语言吗？当然，只要你能给出严谨的数学定义，没有歧义，找到一群人学会并开始用它交流，姑且可以称为语言了，比如生活大爆炸谢耳朵他老婆； 语言不是主谓宾之类的吗？主谓宾也可以进一步形式化，数学之美也让我感到惊叹；  So\u0026hellip;假如我用编程语言写了一段代码，如何知道我有没有犯错误呢？那就是编译器的工作，词法分析、语法分析、语义分析，一切OK之后会进入中间代码生成、代码优化、生成最终代码。通常一般在语法分析会构建语法分析树AST（Abstract Syntax Tree），如果能够正常构建出AST，表示代码是按照语言对应生成规则来写的，就没什么大问题，反之则可能又自我“发挥”犯错了。",content:"代码可读性 # 作为一名开发人员，代码可读性是我们常常挂在嘴边的。代码写出来除了让计算机能够正常执行以外，终究还是要让人能够理解它，后续才能做进一步的维护工作。如果代码写出来，只有它的作者能够看得懂，那只能说明这个作者逻辑表达能力有问题，透过其代码难以看出解决问题的思路。这是软件工程中要尽力避免的。\n在软件工程方法论指导下，为了尽可能让代码可读性达标，我们往往会根据一些最佳实践拟定一些大多数人认可的标准，让所有开发人员遵守，然后通过代码评审、代码规范检查、持续集成交付流水线等综合起来，以尽可能逼近这一目标。当绝大多数人能够在约定的框架下，保质保量提交代码时，我们已经在代码可读性、可维护性方面前进了一大步。\n然而，这样足够了吗？我认为还不够。\n代码是思维的表达 # 代码，不过是通过一种大家都理解的语言书写出来的篇章。就好比写文章一样，要有中心思想，然后围绕中心思想要展开层层描述。写代码一样，中心思想就是我们要解决的问题，围绕中心思想的层层描述就是我们解决问题的思路。所以，代码没有什么神秘的，它是人类思维的表达。\n我们是如何快速理解一篇文章的呢？\n 先看标题，掌握其核心关键词； 看下第一段落的内容，往往第一段会引出问题； 看下其余段落的首句、末句，往往会给出该段落的中心思想； 看下最后一段的内容，一般会给出一个结论； 通篇串下，了解文章整体含义；  为什么我们会通过这种方式？因为一篇好的文章一定有承上启下、过渡。这种循序渐进的方式，步步逼近中心思想。\n那代码呢？某种程度上，代码也是类似的。\n 以go语言为例，通常对于一个package，我们会提供package注释来表示当前package要解决的问题； 每个package内部又包含了不同的types、variables、functions，它们结合起来来解决一个问题； 每一个function内部又分为多个步骤，每一步完成一个小功能，为下一步做好准备； 每一个小功能、步骤可能是if-else, switch-case, for-loop……之类的语言结构； 同时，我们还会提供测试用例，来验证上述方案的正确性。  有没有觉得很相似，或许我们应该采用已有的读书的经验来辅助更好地理解程序？\nOOP思想认识世界 # 代码，和文章不同的是，它虽然有明显的程序构造，但是却没有明显的段落之分。\n那我如何才能借鉴多年来养成的还不错的阅读习惯，来帮助我理解代码呢？当然不能盲目套用，不过俗话说，能工摹形，巧匠窃意，思想很多地方还是可以相通的。\n如何更好地理解这个世界，对各种各样的问题进行抽象呢？比如一辆摩托车，它有离合器、发动机、链条、轮毂、轮胎、减震、油箱、排气等很多部件构成，我听说宝马水鸟电子控制很厉害，可以实现无人驾驶，那可是两轮的400多斤的大机器。那它的电子控制系统怎么做到的？至少要能理解一个摩托车有核心部件，整体运转起来如何理解其状态，如何控制个别部件以影响其他部件进而控制整体状态。那它如何控制部件呢？电子操作或机械操作。\n扯远了，我只是有点喜欢水鸟而已。整个世界可以看做是一个个对象及其之间的联系所构成，代码也不例外。\n道法自然，OOP的思想不过是借鉴了人类认识世界的方式，将其运用到了软件工程领域，以更好地对问题进行抽象，从而构建出设计更合理的软件。那代码里面有哪些语言构造体现了OOP的思想呢。\n 类型与对象，生物学里区分物种、种群、个体，那是因为它们既有共性，也有个性； 通信的方式，自然界个体之间的交互也有多种方式，比如雄狮撒泡尿标记领地也不管入侵者认不认同，或者低吼驱赶入侵者离开，人和人用听得懂的语言沟通； 隐私与距离，每个人都有自己的隐私，如果你的朋友跟你借100块钱你可能给了，但是他如果问是你老婆给的还是你自己的，你可能就不想借给他了，给你就行了你管那么多干嘛呢，我还不想拿自家的借你呢，说不定借你老婆的给你的呢。每个人在一副外表下总有些不愿意被人触碰、靠近的地方。  了解一个人，其实你不需要深入他的家庭本身去了解，看看他天天接触什么人，说些什么话，你也就大致清楚了。感兴趣就继续了解，不感兴趣也就拉倒了。我想绝大多数人都不是窥视狂，在拥有一定判断力的基础上，通过一些局部的信息是可以了解大致的整体信息的。\n理解代码有相同之处？\n流程控制 + 组件交互 # 某种程度上，我认为理解代码也有相似之处。\n如果能够拎出那些比较重要的对象（objects），以及他们之间的通信（function call, chan send/recv），或者他们的私密信息（注释），是不是也能够大致有个了解呢？\n如果想更深入了解下，加上事情的脉络（控制结构，if-else, switch-case, for-loop）呢？\n其他信息? 我相信还有其他有用的有用信息，能够通过一些更加有效率的方式呈现出来。\n认识 go/ast # 计算机编程语言，有多少种？我认为只有一种，就是人类可以理解的语言。有趣的是，编程语言之多可以覆盖元素周期表，不信来瞧瞧。\n       语言是什么？语言有精确的数学定义，它不是胡编乱造，尤其是编程语言； 编程语言更精确？那倒未必，人类社会多姿多彩之处，就在于会演绎出更加丰富多彩的内容，包括对语言的破坏性“创造”，人脑纠错能力太强了，我们甚至没有察觉到自己犯了错误，如网上津津乐道的山东人倒装玩法； 我能发明一门语言吗？当然，只要你能给出严谨的数学定义，没有歧义，找到一群人学会并开始用它交流，姑且可以称为语言了，比如生活大爆炸谢耳朵他老婆； 语言不是主谓宾之类的吗？主谓宾也可以进一步形式化，数学之美也让我感到惊叹；  So\u0026hellip;假如我用编程语言写了一段代码，如何知道我有没有犯错误呢？那就是编译器的工作，词法分析、语法分析、语义分析，一切OK之后会进入中间代码生成、代码优化、生成最终代码。通常一般在语法分析会构建语法分析树AST（Abstract Syntax Tree），如果能够正常构建出AST，表示代码是按照语言对应生成规则来写的，就没什么大问题，反之则可能又自我“发挥”犯错了。\n以下面的go程序为例：\npackage main import ( \u0026quot;fmt\u0026quot; ) func add(a, b int) int { return a + b } func main() { c := add(1, 2) fmt.Printf(\u0026quot;1 + 2 = %d\\n\u0026quot;, c) }  以下是两个不错的ast可视化工具，可以将上述代码拷贝以下以查看对应的AST。\n ast-explorer goast-viewer  ps: 推荐前者，实现了类似chrome inspect element时选中区域查看对应代码的操作，光标移到对应代码区域，即可高亮显示对应的AST部分区域。\n比如现在我们选中了import相关的部分，对应右边展示出了import声明对应的AST中的部分子树，对应的就是一个GenDecl结构。函数声明也有对应的FuncDecl，类型也有对应的\u0026hellip;\nps: AST展示形式竟然不是一棵树？它确实是一棵树，只不过，AST是非常庞大的，如果通过树的形式来展示，篇幅太大，反而不方便查看。\ngo标准库提供了一个package go/ast，用它来对源码进行分析并构建出AST，然后基于AST可以对源码结构进行理解加工，举几个常见的用途：\n go标准库有频率不高的package迁移、方法签名变化、其他情况，go fix实现了旧代码像新代码的快速迁移，其实就是通过对AST操作实现的； 代码中检测error处理、是否有合理注释等，也可以基于AST进行分析，开发可能一不小心忽略对error处理、goroutine panic处理，有些三方库就可以基于AST分析有没有上述情况，以对源码中的问题进行自动修复； 提取关键操作信息进行可视化，如apitest.dev将HTTP操作、DB操作作为重点关注对象对代码中的相关交互进行提取、可视化展示，Ballerina框架中也有类似实现。 提取关键的网络调用操作，自动化opentracing埋点，Instrumenting Go code via AST。 其他；  可见了解 go/ast，将有助于我们更好地理解代码，并作出一些更有创意的工具。\n微服务可视化 # 我正在调研一些业界流行的微服务框架，吸收一些比较好的创意，在我从事的团队，现在基本都是采用微服务架构设计、开发、部署了，某种程度上，微服务一点都不微，有些逻辑也很复杂，而且业务代码真的没什么好看的。绝大多数时候，我希望1min了解其逻辑，超过10min我还看不懂的，心里已经开始在犯嘀咕了，这写的啥？\n是我“没耐心”？我倒是不这么认为，如果一个操作我每天要人肉重复几十遍，我就得想办法“偷偷懒”提高下效率了。身为工程师，卖肉是耻辱。\n再回想一下哪些语言构造比较重要，rpc、对象之间的通信（方法调用）、包方法调用、goroutine之间通信（chan send/recv），还有控制逻辑if-else、switch-case、for-loop。\n我们可以先从实用又简单点的开始，比如rpc、对象方法调用、包方法调用，其他的后续再完善。OK!\n找到关心的入口点 # 按照一些微服务框架的编码风格，通常main.go里面会注册service接口级实现，这里就可以作为一个入口，我们可以找出AST中main.go中注册的所有service及其实现，并分析service接口中定义的方法，然后再将service实现中的对应方法作为入口点。\n找到这些入口点之后，我们将可以从AST中遍历所有的方法定义，直到匹配到receiver type、method signature匹配的定义。\nfile: main.go\nfunc main() { s := gorpc.NewServer() pb.RegisterHelloService(s, \u0026amp;helloServiceImpl{}) if err := s.Serve(); err != nil { log.Fatal(err) } }  从入口点处开始层层展开 # 每个函数在AST中都有对应的结构，函数体内包括的每一条语句也是这样，那还有什么不能干的？\n我们可以递归地将一条语句层层展开，抽丝剥茧，直到看到关心的脉络。刚才我们说先只考虑rpc、对象方法调用、包导出函数调用就可以了，这类基本可以形式化成xxx.Func(args...)的形式，就覆盖了上面这几种情况。\n只要碰到这样的语句，我们就记录一下，并将其递归地展开，展开过程中依然记录所有xxx.Func(args...)形式的函数调用……直到没什么可继续展开为止。\n这样，我们就可以大致实现最初的设想：看到对象之间的所有通信过程。\n增加通信过程的说明信息 # 在go代码规范里面，对于导出方法、导出函数、导出类型通常都是需要添加godoc注释的，这些注释本身就具有一定的说明性。那当我们通过对象间的调用关系进行可视化时，是否可以将这些注释信息添加上，以提供更好的说明呢？当然。\n何时何地以及如何触发 # 何时何地以及如何触发了特定的函数调用？\n 何时何地？filename:lineno:columnno，每一个ast对象都有一个Pos()方法，配合token.Position(astobj.Pos())就可以计算出源码位置； 如何触发？函数调用时的参数信息，函数调用发生的作用域（function scope）；  Put It Together # 当我们将上述提及的操作全部组织在一起，就可以实现大致如下效果，篇幅以及时间原因，这里就不再一步步详细描述代码逻辑了。\n      如果您对这里的实现确实感兴趣，您可以查看这里的代码来进一步了解MR: gorpc support visualize subcmd。\nps: 我也在做一些gorpc101教程之类的材料准备，包括书籍、框架、工具、插件之类的小玩意，一方面是为了沉淀自己，一方面是为了验证想法，如果能有些许建议或者愿意参与进来，那我先表示欢迎。\n debugger101 gorpc101  "}),a.add({id:342,href:"/contributors/henk-verlinde/",title:"hitzhangjie",description:"Creator of Hyas.\n@hitzhangjie",content:"Creator of Hyas.\n@hitzhangjie\n"}),a.add({id:343,href:"/contributors/",title:"Contributors",description:"The Doks contributors.",content:"The Doks contributors.\n"}),a.add({id:344,href:"/blog/",title:"Blog",description:"The Doks Blog.",content:"🎶 欢迎来到 Kn\u0026rsquo;s Blog\u0026hellip; 这里记录着我的认识和思考\n 👀 所有分类 | 👀 所有标签\n "}),a.add({id:345,href:"/tags/debugger/",title:"debugger",description:"",content:""}),a.add({id:346,href:"/books/debugger101/",title:"Debugger101: Go调试器开发内幕",description:"授人以鱼不如授人以渔，调试器正是这样一款工具，它虽然不知道您程序中何处引入了bug或者理解不到位，但是当你想到它、捡起它，它就可以指引你一步步追根溯源。不仅要做授人以渔的工具，也要做授人以渔的人，不禁要问读者，你们可曾了解过调试器的内部实现？它是如何控制你程序执行的，它是如何知道指定内存地址处的指令或者数据类型的…本书旨在帮助读者打通对编译、调试工具链、调试信息标准以及操作系统之间的认识，使具备一定的调试器定制化开发的能力。",content:"授人以鱼不如授人以渔，调试器正是这样一款工具，它虽然不知道您程序中何处引入了bug或者理解不到位，但是当你想到它、捡起它，它就可以指引你一步步追根溯源。\n不仅要做授人以渔的工具，也要做授人以渔的人，不禁要问读者，你们可曾了解过调试器的内部实现？它是如何控制你程序执行的，它是如何知道指定内存地址处的指令或者数据类型的…本书旨在帮助读者打通对编译、调试工具链、调试信息标准以及操作系统之间的认识，使具备一定的调试器定制化开发的能力。\n 由于本书内容涉及大量系统原理、调试信息标准、设计实现、go源码分析内容，篇幅很大，很难用几篇博文讲述清楚，因此单独写一本电子书，《Debugger101：go调试器开发内幕》。\n欢迎阅读，如您在阅读过程中遇到错误、疏漏、建议，不要犹豫，请给我提issue。\n"}),a.add({id:347,href:"/books/gorpc101/",title:"GoRPC101: 微服务框架开发内幕",description:"如今微服务架构大行其道，微服务框架也层出不穷，如grpc、springcloud、vert.x、ballerina，等等，这也反映出技术团队对开发效率、运营质量的不断探索与追求。合格的工程师要熟练运用框架，有追求的工程师则应掌握更全面的技能，能对框架进行定制化开发。",content:"如今微服务架构大行其道，微服务框架也层出不穷，如grpc、springcloud、vert.x、ballerina，等等，这也反映出技术团队对开发效率、运营质量的不断探索与追求。合格的工程师要熟练运用框架，有追求的工程师则应掌握更全面的技能，能对框架进行定制化开发。\n 由于本内容涉及到大量的设计实现、系统原理、性能调优、研发流程、工程素养、社区维护等等诸多内容，几篇博文实在难以介绍清楚。为了保证内容的完整性，让读者能够感受到笔者微服务框架开发工作中的真实例程，还是决定单独写一本电子书，《GoRPC101：微服务框架开发内幕》。\n欢迎阅读，如果您在阅读过程中发现有错误、疏漏、建议，不要很犹豫，请给我提issue。\n"}),a.add({id:348,href:"/journey/",title:"Journey",description:"journey.",content:"CNCF Cloud Native Landscape Row 1 Col 1 Row 2 Col 1 Row 3 Col 1 Row 4 Col 1 Row 5 Col 1  Row 1 Col 2 Row 2 Col 2 Row 3 Col 2  Row 1 Col 3 Row 2 Col 3 Row 3 Col 3 Row 4 Col 3    .flex-container { display: flex; } div.w1 { flex: 1; } div.w2 { flex: 2; } div.w3 { flex: 3; } .column { flex: 1; } .row { display: flex; } .color1 { background-color: #6d3d8f; } .color2 { background-color: #255625; } .color3 { background-color: #8f583d; } .color4 { background-color: #2e616b; } .color5 { background-color: #b34d4d; }  "}),a.add({id:349,href:"/books/libmill/",title:"libmill: go风格协程库设计实现",description:"我们只想要一个协程化的开发能力以及基于CSP的数据共享，难道我们就需要一门新的语言，比如golang？有很多开发人员曾经提出类似的质疑，笔者刚接触go时也抱着类似的想法。那么不妨思考下如果用c/c++的话，如果要实现上述功能，我们应该如何实现呢？ZeroMQ之父Martin Sustrik就用1w多行代码实现了一个非常优雅的go风格协程库，不妨来一起学习下。",content:"我们只想要一个协程化的开发能力以及基于CSP的数据共享，难道我们就需要一门新的语言，比如golang？有很多开发人员曾经提出类似的质疑，笔者刚接触go时也抱着类似的想法。那么不妨思考下如果用c/c++的话，如果要实现上述功能，应该如何实现呢？\n ZeroMQ之父Martin Sustrik就用1w多行代码实现了一个非常优雅的go风格协程库，不妨来一起学习下。\n本内容涉及大量的系统基础知识、设计实现细节，为了保证知识点的系统性，单独写了一本电子书，《libmill：go风格协程库设计实现》。\n欢迎阅读，如果您在阅读过程中发现有错误、疏漏、建议，不要犹豫，请给我提issue。\n"}),a.add({id:350,href:"/books/",title:"My Books",description:"My Books.",content:""}),a.add({id:351,href:"/",title:"欢迎来到 Kn's Space",description:"好记性不如烂笔头，学习、实践、总结，塑造更好的自己",content:'$\u0026gt; Keep! 日出之时，再行万里! 🎶\n Your browser does not support the audio element.\n  var player = document.getElementById("music-player"); player.volume = 0.1;  -- '}),a.add({id:352,href:"/blog/2020-09-28-go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-go%E5%91%BD%E4%BB%A4/",title:"go源码剖析 - go命令",description:"1. 本文简介 # 首先我们看下go命令行有哪些功能，运行go help可以查看go命令的详细帮助信息，go命令有很多子命令，每个子命令有特定的功能。go命令功能之丰富涵盖了源文件编译、汇编、连接、反汇编、逃逸分析、代码生成、模块解析等等非常系统性的功能，了解go命令的实现将有助于系统性掌握整个go编译工具链。本文介绍下go命令的详细功能及大致实现，供后续参考。\n2. go子命令列表 # go支持的子命令列表如下，下面我们逐一来简单说下。\n bug, start a bug report build, compile packages and dependencies clean, remove object files and cached files doc, show documentation for package or symbol env, print Go environment information fix, update packages to use new APIs fmt, gofmt (reformat) package sources generate, generate Go files by processing source get, add dependencies to current module and install them install, compile and install packages and dependencies list, list packages or modules mod, module maintenance run, compile and run Go program test, test packages tool, run specified go tool version, print Go version vet, report likely mistakes in packages  3.",content:"1. 本文简介 # 首先我们看下go命令行有哪些功能，运行go help可以查看go命令的详细帮助信息，go命令有很多子命令，每个子命令有特定的功能。go命令功能之丰富涵盖了源文件编译、汇编、连接、反汇编、逃逸分析、代码生成、模块解析等等非常系统性的功能，了解go命令的实现将有助于系统性掌握整个go编译工具链。本文介绍下go命令的详细功能及大致实现，供后续参考。\n2. go子命令列表 # go支持的子命令列表如下，下面我们逐一来简单说下。\n bug, start a bug report build, compile packages and dependencies clean, remove object files and cached files doc, show documentation for package or symbol env, print Go environment information fix, update packages to use new APIs fmt, gofmt (reformat) package sources generate, generate Go files by processing source get, add dependencies to current module and install them install, compile and install packages and dependencies list, list packages or modules mod, module maintenance run, compile and run Go program test, test packages tool, run specified go tool version, print Go version vet, report likely mistakes in packages  3. go subcmds # go bug # go bug，用于快速创建bug report。\n作为开源项目的维护人员，非常希望开发人员“会”提问题！为什么这么说呢，就是因为如果不会提问题、问问题，沟通成本就会非常高，这对于开源项目维护人员来说，时间上是个极大的浪费。\n在腾讯我也参与维护了好几个比较大型的开源项目，经常受到一些同学的问题，很多时候我真的感谢求学阶段长时间泡stackoverflow的经历，stackoverflow上教会了我怎么提问题，这个在我后面学习、沟通、检索、开源协同中起到了很重要的作用。\n为了降低沟通成本，go bug内部定义了一个issue模板（其实github也支持定义模板），包括了几个部分：问题简述、go版本、go env信息、执行的操作、期望的结果、实际的结果。这里呢，为了保护go issuer的体验，go bug会自动获取go环境信息，填充到issue模板中，这里的内容将作为issue的body部分。\n接下来会判断go issuer当前系统信息，并决定如何打开web浏览器，浏览器打开一个issue创建页面，通过GET参数填充issue的body，一个简单的issue基本信息就填充完成了。go issuer只需要填充下标题、问题简述、执行操作、期望结果、实际结果就创建完成了。\ngo build # go build可以细分为如下几个操作：\n compile, src/cmd/compile/main.go asm, \u0026hellip; link, src/cmd/link/main.go ld, \u0026hellip;  go build过程分析，假定待编译的工程开启了go module：\n  初始化操作\n modload.Init(), 进行go module相关的初始化，如检查环境变量GO111MODULE决定是否启用go module、定位go.mod所在的目录、设置git等； instrumentInit()，代码织入初始化，什么是代码织入呢，比如go build -race对代码中的竞态条件进行检查，需要在原程序中加入一些特殊代码来统计对某些数据结构的并发读写操作，这就称之为代码织入，熟悉Java字节码织入的话应该很容易看懂这里的概念，比如Kilim、Quasa等字节码织入。go build -msan应该是启用与内存清理相关的操作。这里也就是检查一下flag的正确性（如-race、-msan不能同时指定），检查一下平台是否支持race检查、msan检查； buildModeInit()，构建模式初始化，包括决定是构建一个共享库，还是一个可执行程序，还是其他等，也会检查平台是否支持、是否开启go module等；    builder初始化: builder保存着一次构建过程中的全局状态，不保存package的全局状态，不同package的编译是并发进行的，builder是单例共享的\n 初始化打印函数 初始化action cache 初始化mkdir cache 初始化tool id cache 初始化build id cache 初始化临时构建目录 检查GOOS、GOARCH是否合法 检查指定的tag列表    加载要构建的路径对应的package信息\n 加载路径对应的pacakge 移除纯测试用的package    创建要执行的actions：一个action表示action图中的一个单独的动作\n 创建一个go build的action（根节点），我猜这个action是一个表示全局构建完成的action； 针对各个要构建的package创建一个auto action，都是前一步go build这个action的前置依赖； 这里的actions构成了一个dag，也称之为action graph；    b.Do()开始执行构建\n 从根节点执行扫描，按照深度优先搜索、后序遍历的方式进行遍历，正好符合前置（子节点）执行完成后，后置才可以执行的问题； 根据查看选项是否指定，决定是否输出action graph； action dag执行的时候，相当于先执行最底层的叶子节点，执行完再执行上一层的父节点\u0026hellip;以此类推，直到到达根节点； 根据action.Deps构建反向的触发关系，如a.Deps=b，那么b.Triggers=a，方便b执行完后驱动a执行； action.pending表示当前该action剩下的等待执行完成的前置依赖的数量，如果pending为0，表示无依赖或者依赖都已执行完成，当前action变为就绪状态，转移到b.ready这中，b.readySema信号量也ok了； 启动多个goroutine执行并发的构建任务，当b.readySema就绪后，从b.ready栈中取出要处理的action去执行，记录构建的时间之类的，应该是为了方便统计编译耗时信息； 这里要注意action.Func，默认是挺过(*Builder).build来构建的，层层展开，其实看得就是gc.go的gc方法，这个方法最终调用的其实是go tool compile来完成编译过程； go tool compile的代码位于src/cmd/compile/main.go下；    go tool compile逻辑实现：\n 我擦，一开始各种a#239?fafx8\u0026mdash; 构建语法树，不是用的go/ast包，而是syntax包，据说这是因为之前是用c写的，即便后面用go重写了，但基本上是翻译了一遍，工程结构没再改； 基于语法树进行语义分析，如检查类型是否正确，typecheck(node,...)，这里又分为几个步骤：  const、type、以及func的类型和名称的检查； 变量赋值检查； 函数体类型检查，检查返回值类型？ 类型检查完之后，检查map类型的keys   检查如何捕获closed的变量，需要在逃逸分析之前进行； 内联检查； 逃逸分析； 将闭包中对外部变量的引用，根据使用方式转换为按值捕获、按引用捕获的对应形式； 编译顶层函数，详见函数：funccompile(node)，这个函数就是根据函数定义（参数列表、返回值）以及语句，生成一系列的操作（操作码、操作数等）; \u0026hellip;. 写对象数据到磁盘，object data，翻译是“对象数据”，不是“目标文件数据”。详见函数dumpdata()，貌似是在函数compileSSA()中实现的，还要确认具体逻辑；  哇，好复杂!\ngo clean # 我们在编译构建的过程中，一般都会生成一些临时文件，比如.o文件，如果是使用Makefile管理工程构建的时候一般会定义个PHONY Target clean，通过make clean来清理临时文件、目标文件、程序等，MVN构建也会定义clean这样的target，go也不例外。\ngo build，编译输出可执行程序，go install还会将可执行程序安装到GOBIN或者GOPATH/bin，那现在要清理的话，go clean会清理当前module下的编译产物，go clean -i还会把安装到GOBIN或者GOPATH/bin下安装的程序给清理掉，另外go modules之间也有依赖关系，go clean -r还可以递归地清理依赖产物。\n举个例子，假如现在有个工程目录叫hello，那么在该工程目录下执行go clean，将清理目录下的下述文件：hello, hello.exe, hello.test, hello.test.exe, main, main.exe, main.test, main.test.exe。那假如hello目录下go.mod定义的module是a.b.c呢？会清理a.b.c, a.b.c.exe, a.b.c.test, a.b.c.test.exe吗？不会！但是go clean -i会从GOBIN或GOPATH/bin下清理这些文件。为啥？目前go clean就是这么实现的。\ngo clean之前实现的有bug，我稍微修改了下，实现了清理${module}, ${module}.exe的功能。\ngo doc # go doc 可以用来显示指定package下的类型、函数、方法及其注释信息，其用法比较多，如go doc、go doc pkg.symbol.fieldOrMethod、go doc pkg.Function等等。\n比如我们运行go doc os.Signal，会显示如下信息：\npackage os // import \u0026quot;os\u0026quot; type Signal interface { String() string Signal() // to distinguish from other Stringers } A Signal represents an operating system signal. The usual underlying implementation is operating system-dependent: on Unix it is syscall.Signal. var Interrupt Signal = syscall.SIGINT ...  从这里我们可以看到整个接口的定义，及其godoc注释信息，那么不禁要问，go doc 是如何准确找到这个符号os.Signal定义的呢？\n如果之前有了解过go/ast的用法、用途之后，应该就不难理解了。我还写过一篇讲微服务代码逻辑可视化的文章，也是使用了go/ast。\ngo doc的逻辑其实很简单，它首先会将os.Signal split一下，发现是os这个package，然后是Signal这个符号，然后它就会根据build package提供的信息来定位到os对应的目录，然后通过parser.ParseDir(...)来对目录下go文件进行语法分析。分析完之后就将得到AST，然后再基于AST去查找符号Symbol的定义，比如这里是个类型定义，找到AST中对应的节点之后，再提取出注释信息。最后将这些信息格式化输出到stdout。\ngo doc大致就是这样实现的。\ngo env # go env 命令用来查看、设置、取消设置go相关的一些环境变量。\n我们知道go env会显示出一个环境变量列表，这里面这些环境变量名称都是go envCmd里面预定义好的，比如要设置一个不相干的变量名go env -w xxx是会报错的。\ngo env 列出的环境变量一般都有一个默认值，如GOSUMDB=sum.golang.org，但是我们有时候希望对齐进行调整，那么可以通过go env -w GOSUMDB=off来进行设置，如果要取消设置恢复到原来的默认设置，则可以执行go env -u GOSUMDB。\n那这里不禁要问，用户手动设置的环境变量存储在哪里呢？其实是存储在环境变量GOENV对应的文件中，macOS下为/Users/zhangjie/Library/Application Support/go，linux下为~/.config/go/env，其实就是os.UserConfigDir()+/go/env路径下。当我们设置、取消设置的时候，会更新文件中的数据。\ngo env大致就是这么工作的。\ngo fix # 一门快速演进中的编程语言也会面临一些调整的时候，如果发生了变化，比如将golang.org/x/tools/net/context内容转移到标准库context中，可能已经存在一些存量代码了，或者说开发者已经习惯了使用老的import的包路径了，那怎么办呢？想让开发者付出最小的迁移成本而转到使用最新的标准库context上来。go fix就是干这个事情的。\nfix命令执行的时候会检查当前支持那些修复操作，每一个修复操作都指定了要搜索的代码，以及要替换成的代码，比如上面提及的context包导入路径的问题。fix命令会首先解析源文件得到抽象语法树AST，然后基于对AST的操作，搜索出可以修复的问题代码，然后将其替换成对应的新代码，然后再将AST转换成代码输出到源文件中。\n这大概就是go fix (go tool fix) 的一个执行过程，$GOROOT/pkg/tool/$GOOS_$GOARCH/下保存了go tool对应的一些工具，如fix，vet等，运行go vet, go fix就会最终转换成执行上述路径下的vet、fix命令。go fix的入口在$GOROOT/src/cmd/go/fix/fix.go，实际调用的是go tool fix，其入口在$GOROOT/src/cmd/fix/main.go。\nps: go fix的内部实现，是基于go/ast实现，通过对源码进行语法分析构建ast，通过对ast进行查找、修改，完成对代码的调整，最后再将ast转换为源码输出。\ngo fmt # go fmt实际上是调用的命令gofmt，它其实也是利用了package go/ast完成对特定源文件或者目录下所有源文件的语法分析，构建出语法树，然后基于对语法树的理解和操作，来最终完成对代码的格式化。\ngo fmt在使用的时候，有几个地方比较方便，选项-d可以将格式化后的代码打印到标准输出，-w则可以直接将文件写入到文件，-s则支持对代码进行简化。\n这里也没有特别多要强调的，继续看其他子命令的实现逻辑。\ngo generate # go提供了代码生成能力，在go源文件中通过//go:generate ....定义的注释，其实是一种特殊的指令，它告诉go工具可以提取出这些指令来生成代码。当然理论上通过go:generate可以执行任何指令，但是从go工具设计者的初衷来看，它主要是为了用来作为一种包开发者的工具，用来生成或者更新特定源文件的。\n比如一个代码生成工具可以通过代码模板来生成一个完整的服务工程，代码模板里面就可以包含这样的//go:generate mockgen ...指令来生成mock测试相关的桩代码。\ngo generate实现的逻辑比较简单，它就是遍历源文件，然后去逐行读取每个源文件，检查读取行是不是匹配//go:generate ...，是的话则解析出命令来，然后执行对应的命令。\ngo get # go get用来下载对应模块并安装，同时将该模块添加到当前模块的依赖文件go.mod中。当然go get也有很多一些常用选项，如-u用来更新模块等。这里可以通过go help get来了解详细的信息。\ngo install # go install，它主要是下载对应模块，并完成程序的构建、安装逻辑。需要注意的是，这里在go1.13前后发生了一点变化。\n在go1.13之前的版本中，是要通过go install来安装的，go1.13及之后的版本go get会自动下载、并构建、安装，go install只能安装本地已经下载下来的模块。\ngo list # go list列出packages或依赖，具体如何实现的呢？这个命令怎么实现的不是很感兴趣，先跳过了。\ngo mod # go mod主要是用来对依赖进行管理，常用操作包括go mod init, go mod tidy，go mod vendor等等吧。\n这个有时间再看，当前不是很感兴趣，先跳过了。\ngo run # go run一般用来快速执行一个go文件，这个go文件必须是package main下的，并且包含一个方法func main(){}。go run现在也支持指定一个package main的路径名，要求是一样的，就是这个目录下的go源文件必须是package main，并且有一个源文件中包含func main(){}的定义。\ngo run其实也需要进行编译、链接过程，只不过这个过程都在一个临时目录中完成，结果产物没有输出到源码目录或者命令执行时的工作目录下。并且go run执行完会后，会自动清理掉这些临时目录。执行完成前是怎么清理的呢？它这里模拟了c里面的函数atexit()来注册退出时要执行的函数，go run进程最终在调用os.Exit()之前会先将之前注册过的处理函数执行一遍，跟c库函数atexit的逻辑类似。这里注册的处理函数就包括清理go run触发编译、链接时生成的临时目录。\ngo test # go test主要是用来执行单元测试用的，它还比较牛，不仅仅可以用来支持\u0026quot;test.go\u0026quot;文件的单元测试，还支持像\u0026quot;cmd/go/testdata/scripts/\u0026ldquo;下的通过txt文件+自定义指令来实现的测试。这里还是有点创新点的。\n这里先说下\u0026quot;test.go\u0026quot;文件的单元测试是如何实现的吧。实际上是这样执行的，它会为当前package下的\u0026quot;test.go\u0026quot;文件，生成一个新的go文件，这个go文件的内容是根据预先定义好的go测试模板文件生成的，内部会通过-test.run选项来选择我们自定义的TestXXX(t)来执行。\n当然go test也支持覆盖率测试等等的操作，这个覆盖率测试实际上也简单，其实是把源文件重写了，每一行语句都对应了一个计数器，执行语句之后，紧跟着一条增加计数器的操作，最后测试程序跑完，检查所有语句的计数器就可以统计出覆盖率信息。\n\u0026hellip;\n其他的，当前也不是很关心了。\ngo tool # go这个命令行工具是一个集大成者，它内部其实也是调用了一些其他的工具的，如通过go fmt或go tool fmt来调用命令gofmt，还有一些其他的工具，这些工具可以在如下路径中找到：$GOROOT/pkg/tool/$GOOS_$GOARCH。\n这里的工具有很多，我在后面的文章中会有选择的进行介绍。\ngo version # go version就是打印当前go程序的版本信息，这个信息是在go编译构建期间由工具go tool dist生成的，详见runtime/sys/zversion.go。\n还有一种常见的做法，是设置好一个包级别的变量，然后通过go build -ldflags=\u0026quot;-X 'pkg.Varable=value'\u0026quot;，这也是一种办法。\ngo vet # go vet用来报道packages中可能的错误，之前有了解过并发map读写的问题，可以通过go vet检查出来，它是怎么检查的呢？它还能检查出什么其他的错误呢？\ngo vet默认使用的vet工具是go自带的vet工具，也可以通过go vet -vettool=$prog替换成自定义的vet工具。OK，现在我们来看一下go自带的vet分析工具都支持分析哪些类型的错误，以及怎么实现的。\ngo自带的vet工具，其实现位于：src/cmd/vet/main.go，从源码中不难看出，vet支持对如下类型的错误进行检查：\n asmdecl: reports mismatches between assembly files and Go declarations assign: detects useless assignments atomic: checks for common mistakes using the sync/atomic package bools: detects common mistakes involving boolean operators buildtag: check that +build tags are well-formed and correctly located cgocall: detect some violations of the cgo pointer passing rules composite: check for unkeyed composite literals copylock: check for locks erroneously passed by value errorsas: report passing non-pointer or non-error values to errors.As httpresponse: check for mistakes using HTTP response ifaceassert: detect impossible interface-to-interface type assertions loopclosure: check references to loop variables from within nested functions lostcancel: check cancel func returned by context.WithCancel is called nilfunc: check for useless comparisons between functions and nil printf: check consistency of Printf format strings and arguments shift: check for shifts that equal or exceed the width of the integer stdmethods: check signature of methods of well-known interfaces stringintconv: check for string(int) conversions structtag: check that struct field tags conform to reflect.StructTag.Get tests: check for common mistaken usages of tests and examples unmarshal: report passing non-pointer or non-interface values to unmarshal unreachable: check for unreachable code unsafeptr: check for invalid conversions of uintptr to unsafe.Pointer unusedresult: check for unused results of calls to some functions  如何实现的呢，单独查看各个analyzer的实现就可以了，举例copylock是基于go/ast语法分析来检测出来的。\n4. 总结 # "}),a.add({id:353,href:"/tags/toolchain/",title:"toolchain",description:"",content:""}),a.add({id:354,href:"/blog/2020-09-20-%E5%AE%B6%E4%BA%BA%E7%94%9F%E6%B4%BB%E6%AF%94%E5%B7%A5%E4%BD%9C%E9%87%8D%E8%A6%81/",title:"家人\u0026生活，比工作重要",description:"为什么工作不开心 # 2020上半年绩效考评出来了，Outerstanding，5星好评，技术通道晋升答辩结果也出来了，T10，算是同事们对自己工作的认可吧，对我自己来说也是个好事，尽管我并没有感觉多么开心。老婆说，虽然你没觉得多么开心，但是如果没过的话一定会觉得不开心……听着很有道理。\n这个5星的考核，我也没什么好开心的，因为业务团队这边一开始给的是4星，后面呢，因为在中台中的贡献比较突出，bg层面有绩效的加成，所以从4星提到了5星。leader告诉我这个好消息后，我并没有觉得开心或者不开心。我做的工作就摆在这里，为什么不是自己业务团队给我考核5星，反而是技术运营部反馈的bg层面的中台贡献，让我的绩效从4星提到了5星？\n年初3月份晋升T10没通过，原因一堆有的没的评语，其实这次评级在内容层面也并没有特别大的变化，只是补充了些业务数据、贡献获奖情况，PPT讲的时候微调了下目录结构，不过基本上没按流程讲下来，评委全程挑战，最后通过了。和上次答辩相比，答辩内容比上次进步了哪些呢，内容组织的更容易被听众接受了，列了些业务对比数据、系统未来规划，列了些获奖数据，上次评委挑战我要控制变量、给数据，哥我是在做工程，不是在做论文实验数据，没有数据就不能判断出我的方案是否可行？看不到我的贡献？评委的专业能力体现在哪呢？\n\u0026hellip;\n所以我纠结的问题是什么呢？自己的工作没有被看见。可能在向上管理上我没有花心思去做，评审时也没有花心思去展示。我还是倾向于对事情本身负责，对这种考核、评价体系，我是不很乐于去融入的。就如同一些评委提到现在评审存在很多缺陷一样，我也不想去融入，并不是不能。\nSo，我还是不开心，因为我无法影响更无法控制整个评价考核体系，我必须做出一些改变才可以去掉这些不开心的东西。再接再厉，但是也确实需要考虑“选择”的重要性，我不能一直因为欣赏个别领导而一直在没有前景的业务线耗着，我还想做些其他的，也需要进一步成长，也需要养家，必须更好地平衡工作和生活。\n旅行是消愁的良药 # 这几天，刚好中心有些小伙伴要外出团建，趁这个机会，我也想休息下，请了几天假，去看望下多年未见的老婆家人，也顺便调整下自己的情绪。这次一行，让我感觉，家人\u0026amp;生活，远远比工作重要。\n工作再忙再烦，也不能将这些负面信息带入到自己家庭、家人、生活中，工作就是工作，生活就是生活，工作就是为了生活，而不能将生活看做工作的附属品。不工作怎么生活，不加班怎么买房买车……竞争奋斗是一种成长方式，但是也不是成长的终点，直线虽然路径最短，但是并不定速度最快。大多数人走的路，肯定没什么新意，你没必要踩着别人脚印重走一遍，重新换条路走避开人流说不定能有突破。\n这几天，我看到各种各样工作的人，开着哈雷送外卖的，买土豆条的，打扫公共卫生的，商场导售员，政务工作人员，保安，街头卖唱的，景区卖票的，农家种地的，……他们似乎并没有因为职业问题而不开心，也应该不会有很多人因为自己不是开发人员而不开心，就好比我并没有因为自己不是一个设计师而后悔一样。我们羡慕别人并不是因为他的职业，而是因为他的待遇。\n羡慕什么样的待遇呢？简言之，我认为只有两个维度，时间和金钱。我们总是在做选择、权衡、取舍。工作时间越长，收入也更多些，反之就少些。有时候我们觉得自己时间可以多投入以换取金钱，所以我们加班，有时我们累了宁可想挣点钱已避免别人压榨自己的时间，于是我们就开始提前下班，或者休假以避免自己工作时疲倦消耗更多时间。\n看到没，我们并没有第一时间将健康摆在第一位，它几乎总是时间和金钱相持不下或者一方优势明显时才会想到的一个参考因素。不过能想到总比想不到好。我就经常没有考虑健康。\n这是自己对自己极端不负责任的行为，也是对自己的家庭不负责任。感谢这次“旅行”教会了我这么多。\n接下来做什么呢 # 要做的事情，在自己脑海里已经规划的差不多了，最近思考着思考着更坚定了自己的想法。还是要按照自己预先设定的目标去达成，我相信自己。\nps: 在我写完本文第二天，得知一个惊人的消息，一个大学同学诊断得了胶质瘤，马上两个孩子的爸爸了，结果遭此不幸。疾病并非离我们很远，努力奋斗的同时，也要注意保护好身体。",content:"为什么工作不开心 # 2020上半年绩效考评出来了，Outerstanding，5星好评，技术通道晋升答辩结果也出来了，T10，算是同事们对自己工作的认可吧，对我自己来说也是个好事，尽管我并没有感觉多么开心。老婆说，虽然你没觉得多么开心，但是如果没过的话一定会觉得不开心……听着很有道理。\n这个5星的考核，我也没什么好开心的，因为业务团队这边一开始给的是4星，后面呢，因为在中台中的贡献比较突出，bg层面有绩效的加成，所以从4星提到了5星。leader告诉我这个好消息后，我并没有觉得开心或者不开心。我做的工作就摆在这里，为什么不是自己业务团队给我考核5星，反而是技术运营部反馈的bg层面的中台贡献，让我的绩效从4星提到了5星？\n年初3月份晋升T10没通过，原因一堆有的没的评语，其实这次评级在内容层面也并没有特别大的变化，只是补充了些业务数据、贡献获奖情况，PPT讲的时候微调了下目录结构，不过基本上没按流程讲下来，评委全程挑战，最后通过了。和上次答辩相比，答辩内容比上次进步了哪些呢，内容组织的更容易被听众接受了，列了些业务对比数据、系统未来规划，列了些获奖数据，上次评委挑战我要控制变量、给数据，哥我是在做工程，不是在做论文实验数据，没有数据就不能判断出我的方案是否可行？看不到我的贡献？评委的专业能力体现在哪呢？\n\u0026hellip;\n所以我纠结的问题是什么呢？自己的工作没有被看见。可能在向上管理上我没有花心思去做，评审时也没有花心思去展示。我还是倾向于对事情本身负责，对这种考核、评价体系，我是不很乐于去融入的。就如同一些评委提到现在评审存在很多缺陷一样，我也不想去融入，并不是不能。\nSo，我还是不开心，因为我无法影响更无法控制整个评价考核体系，我必须做出一些改变才可以去掉这些不开心的东西。再接再厉，但是也确实需要考虑“选择”的重要性，我不能一直因为欣赏个别领导而一直在没有前景的业务线耗着，我还想做些其他的，也需要进一步成长，也需要养家，必须更好地平衡工作和生活。\n旅行是消愁的良药 # 这几天，刚好中心有些小伙伴要外出团建，趁这个机会，我也想休息下，请了几天假，去看望下多年未见的老婆家人，也顺便调整下自己的情绪。这次一行，让我感觉，家人\u0026amp;生活，远远比工作重要。\n工作再忙再烦，也不能将这些负面信息带入到自己家庭、家人、生活中，工作就是工作，生活就是生活，工作就是为了生活，而不能将生活看做工作的附属品。不工作怎么生活，不加班怎么买房买车……竞争奋斗是一种成长方式，但是也不是成长的终点，直线虽然路径最短，但是并不定速度最快。大多数人走的路，肯定没什么新意，你没必要踩着别人脚印重走一遍，重新换条路走避开人流说不定能有突破。\n这几天，我看到各种各样工作的人，开着哈雷送外卖的，买土豆条的，打扫公共卫生的，商场导售员，政务工作人员，保安，街头卖唱的，景区卖票的，农家种地的，……他们似乎并没有因为职业问题而不开心，也应该不会有很多人因为自己不是开发人员而不开心，就好比我并没有因为自己不是一个设计师而后悔一样。我们羡慕别人并不是因为他的职业，而是因为他的待遇。\n羡慕什么样的待遇呢？简言之，我认为只有两个维度，时间和金钱。我们总是在做选择、权衡、取舍。工作时间越长，收入也更多些，反之就少些。有时候我们觉得自己时间可以多投入以换取金钱，所以我们加班，有时我们累了宁可想挣点钱已避免别人压榨自己的时间，于是我们就开始提前下班，或者休假以避免自己工作时疲倦消耗更多时间。\n看到没，我们并没有第一时间将健康摆在第一位，它几乎总是时间和金钱相持不下或者一方优势明显时才会想到的一个参考因素。不过能想到总比想不到好。我就经常没有考虑健康。\n这是自己对自己极端不负责任的行为，也是对自己的家庭不负责任。感谢这次“旅行”教会了我这么多。\n接下来做什么呢 # 要做的事情，在自己脑海里已经规划的差不多了，最近思考着思考着更坚定了自己的想法。还是要按照自己预先设定的目标去达成，我相信自己。\nps: 在我写完本文第二天，得知一个惊人的消息，一个大学同学诊断得了胶质瘤，马上两个孩子的爸爸了，结果遭此不幸。疾病并非离我们很远，努力奋斗的同时，也要注意保护好身体。\n"}),a.add({id:355,href:"/tags/%E5%B9%B3%E8%A1%A1/",title:"平衡",description:"",content:""}),a.add({id:356,href:"/tags/%E7%94%9F%E6%B4%BB/",title:"生活",description:"",content:""}),a.add({id:357,href:"/tags/disassembler/",title:"disassembler",description:"",content:""}),a.add({id:358,href:"/tags/gapstone/",title:"gapstone",description:"",content:""}),a.add({id:359,href:"/blog/2020-09-06-%E5%89%96%E6%9E%90go%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6/",title:"剖析go二进制文件",description:"为什么要反汇编？ # 这篇文章介绍下反汇编的基本概念，以及如何用go语言写一个简单的反汇编器。本文的目标就是为了尽可能描述下反汇编的的相关概念，以及让读者朋友们了解go二进制程序内部大致是什么样的。\n汇编代码不会撒谎，阅读汇编代码能够让我们更细致地了解处理器执行的指令到底做了什么。这也是为什么反汇编很重要的原因之一。如果我们有一个二进制程序，并且怀疑它有一些恶意的行为，通过反汇编来研究它就是一种很好的途径。再或者，如果你分析代码难以发现性能瓶颈，那么反汇编也是一种可以简化分析的途径。\n如果你担心能不能阅读x86_64汇编代码的问题，其实不用担心，我们大部分都不能很顺畅地阅读。你也没有必要为了搞懂这篇文章去阅读其他任何的汇编代码，不过如果有汇编基础的话确实会感觉更有意思点。这里有一篇介绍汇编基础的文章 A fundamental introduction to x86 assembly programming。\n什么是反汇编？ # 那么，什么是反汇编呢？\n反汇编，其实是将已经编译好的二进制程序，重新转换为汇编代码的过程。为了解释清楚，我们先考虑下从源代码编译构建的过程：\n汇编代码，其实是一种介于源代码、机器指令之间的中间代码表示，虽然大多数汇编指令是和机器指令对应的，但是也不绝对，比如go汇编就是一种跟机器指令没有明显对应关系的汇编形式。详细地可以参考go assembler设计对应的go blog一文。ok，言归正传。编译器首先将源代码转换为OS/架构特定的汇编代码，然后再通过汇编器将汇编代码转换为机器指令。从字面上就可以看出disassemble是assemble的一个逆向的过程，俗称反汇编。\n庆幸地是，go语言有一个相对标准、完整的工具链，汇编、反汇编都会比较方便。我们可以直接将源码转换成汇编代码来查看，例如通过运行命令 go build -gcflags -S program.go。如果我们已经有了一个编译构建好的二进制程序，这个时候想查看汇编代码的话，就得通过反汇编，可以运行命令 go tool objdump binaryFile。\n如果想了解如何实现汇编、反汇编的话，这篇文章其实已经可以结束了。但是如果来解释下如何从0到1构建一个反汇编器的话，还是有意思的。\n从0到1构建反汇编器？ # 首先，为了构建一个反汇编器，我们需要先知道二进制程序对应的目标机器架构包含的所有的机器指令。为了实现这个，我们可能要参考特定架构的手册来查阅到底有多少机器指令。如果对这个不熟悉，这个过程其实是比较困难的。其实，有很多种微处理器架构、汇编语法、指令集、编码模式，而且一直在变。光掌握这些不同机器架构包含的指令集就是一个很困难的事情，至于如何困难可以参考下这篇文章 how many x86_64 instructions are there anyway。\n庆幸地是，这些繁重的工作应被解决了，反汇编框架Capstone就是干这个事情的。Capstone其实已经是一个事实上的标准了，在各种反汇编工具中应用广泛。重新实现一个反汇编框架，其实没必要，这个过程只会是一个学习性的、枯燥的、重复的任务，我们不会介绍如何实现一个Capstone反汇编框架，只会介绍如何借助Capstone来实现反汇编的能力。在go语言中使用Capstone也简单，有一个针对go的实现gapstone。\n通过下面的代码我们可以初始化一个gapstone反汇编框架引擎，用它来执行后续的反汇编任务。\nengine, err := gapstone.New( gapstone.CS_ARCH_X86, gapstone.CS_MODE_64, ) if err != nil { log.Fatal(err) }  例如，我们可以将下面的原始指令数据传递给Capstone反汇编框架，然后该反汇编框架将会将这些原始指令数据转换为对应的x86_64下的指令。\n0x64 0x48 0x8B 0xC 0x25 0xF8 0xFF 0xFF 0xFF | mov rcx, qword ptr fs:[0xfffffffffffffff8]  把上面的操作放在一起，如下：",content:"为什么要反汇编？ # 这篇文章介绍下反汇编的基本概念，以及如何用go语言写一个简单的反汇编器。本文的目标就是为了尽可能描述下反汇编的的相关概念，以及让读者朋友们了解go二进制程序内部大致是什么样的。\n汇编代码不会撒谎，阅读汇编代码能够让我们更细致地了解处理器执行的指令到底做了什么。这也是为什么反汇编很重要的原因之一。如果我们有一个二进制程序，并且怀疑它有一些恶意的行为，通过反汇编来研究它就是一种很好的途径。再或者，如果你分析代码难以发现性能瓶颈，那么反汇编也是一种可以简化分析的途径。\n如果你担心能不能阅读x86_64汇编代码的问题，其实不用担心，我们大部分都不能很顺畅地阅读。你也没有必要为了搞懂这篇文章去阅读其他任何的汇编代码，不过如果有汇编基础的话确实会感觉更有意思点。这里有一篇介绍汇编基础的文章 A fundamental introduction to x86 assembly programming。\n什么是反汇编？ # 那么，什么是反汇编呢？\n反汇编，其实是将已经编译好的二进制程序，重新转换为汇编代码的过程。为了解释清楚，我们先考虑下从源代码编译构建的过程：\n汇编代码，其实是一种介于源代码、机器指令之间的中间代码表示，虽然大多数汇编指令是和机器指令对应的，但是也不绝对，比如go汇编就是一种跟机器指令没有明显对应关系的汇编形式。详细地可以参考go assembler设计对应的go blog一文。ok，言归正传。编译器首先将源代码转换为OS/架构特定的汇编代码，然后再通过汇编器将汇编代码转换为机器指令。从字面上就可以看出disassemble是assemble的一个逆向的过程，俗称反汇编。\n庆幸地是，go语言有一个相对标准、完整的工具链，汇编、反汇编都会比较方便。我们可以直接将源码转换成汇编代码来查看，例如通过运行命令 go build -gcflags -S program.go。如果我们已经有了一个编译构建好的二进制程序，这个时候想查看汇编代码的话，就得通过反汇编，可以运行命令 go tool objdump binaryFile。\n如果想了解如何实现汇编、反汇编的话，这篇文章其实已经可以结束了。但是如果来解释下如何从0到1构建一个反汇编器的话，还是有意思的。\n从0到1构建反汇编器？ # 首先，为了构建一个反汇编器，我们需要先知道二进制程序对应的目标机器架构包含的所有的机器指令。为了实现这个，我们可能要参考特定架构的手册来查阅到底有多少机器指令。如果对这个不熟悉，这个过程其实是比较困难的。其实，有很多种微处理器架构、汇编语法、指令集、编码模式，而且一直在变。光掌握这些不同机器架构包含的指令集就是一个很困难的事情，至于如何困难可以参考下这篇文章 how many x86_64 instructions are there anyway。\n庆幸地是，这些繁重的工作应被解决了，反汇编框架Capstone就是干这个事情的。Capstone其实已经是一个事实上的标准了，在各种反汇编工具中应用广泛。重新实现一个反汇编框架，其实没必要，这个过程只会是一个学习性的、枯燥的、重复的任务，我们不会介绍如何实现一个Capstone反汇编框架，只会介绍如何借助Capstone来实现反汇编的能力。在go语言中使用Capstone也简单，有一个针对go的实现gapstone。\n通过下面的代码我们可以初始化一个gapstone反汇编框架引擎，用它来执行后续的反汇编任务。\nengine, err := gapstone.New( gapstone.CS_ARCH_X86, gapstone.CS_MODE_64, ) if err != nil { log.Fatal(err) }  例如，我们可以将下面的原始指令数据传递给Capstone反汇编框架，然后该反汇编框架将会将这些原始指令数据转换为对应的x86_64下的指令。\n0x64 0x48 0x8B 0xC 0x25 0xF8 0xFF 0xFF 0xFF | mov rcx, qword ptr fs:[0xfffffffffffffff8]  把上面的操作放在一起，如下：\nfile: main.go\ninput := []byte{0x64, 0x48, 0x8B, 0xC, 0x25, 0xF8, 0xFF, 0xFF, 0xFF} instructions, err := engine.Disasm(input, 0, 0) if err != nil { log.Fatal(err) } for _, instruction := range instructions { fmt.Printf(\u0026quot;0x%x:\\t%s\\t\\t%s\\n\u0026quot;, instruction.Address, instruction.Mnemonic, instruction.OpStr) }  测试下：\n$ go run main.go 0x0:	mov	rcx, qword ptr fs:[0xfffffffffffffff8]  有了这个反汇编框架Capstone之后，要实现一个反汇编器，我们还有一个剩下的工作要做，就是从二进制程序中提取指令对应的原始数据，然后将其传给Capstone翻译引擎就可以了。\n当你在一个笔记本上编译一个go程序、默认输出是64位ELF格式（Executable Linkable Format）。ELF内部其实是被组织成了多个不同的节（section），每一个section都有不同的目的，如存储版本信息、程序元数据信息、可执行代码等等。ELF是被广泛采用的一个二进制程序标准，go语言标准库里面提供了一个 debug/elf package用来进行ELF文件数据的读写。ELF其实有点复杂，但是要实现反汇编的话其实我们只关心两个section就可以了。一个是符号表section（.symtab），一个是指令section （.text）。\n首先，我们先来看下术语symbol的定义，其实它指的是代码中任何有名的东西，如变量、函数、类型、常量等都是symbols。go编译器会编译每一个符号，并存储对符号表中符号的引用信息。go标准库 debug/elf 中提供了对ELF文件的读写能力，每一个符号都通过结构体 Symbol 来表示，它包括了符号的名字、地址、原始数据的多少等等吧。\n// A Symbol represents an entry in an ELF symbol table section. type Symbol struct { Name string Info byte Other byte Section SectionIndex Value uint64 Size uint64 }  现在，如果我们想快速提取ELF文件中的所有符号的话，我们就可以这么实现：\n// Open the ELF file elfFile, err := elf.Open(path) if err != nil { log.Fatalf(\u0026quot;error while opening ELF file %s: %+s\u0026quot;, path, err.Error()) } // Extract the symbol table symbolTable, err := elfFile.Symbols() if err != nil { log.Fatalf(\u0026quot;could not extract symbol table: %s\u0026quot;, err.Error()) } // Traverse through each symbol in the symbol table for _, symbol := range symbolTable { /* symbol.Info lets us tell if this symbol is a function that we want to disassemble symbol.Value gives us the offset from the start of the .text section symbol.Size lets us calculate the full address range of this symbol in the .text section */ }  从Symbol各个字段的名字命名上看并不是很清晰，符号对应的内存偏移量其实是存储在Value字段中的。通过这个偏移量，可以通过计算与.text section的偏移量的差值，我们可以计算出符号对应的指令数据在.text section中的起始索引。通过进一步的Size我们可以计算出包含的指令数据对应的字节数量。还有一个就是Info字段，这个字段起始是类型的意思，在go里面Info=byte(2)表示的是函数，Info=byte(18)表示的是方法。所以，如果想实现对函数、方法的反汇编的话，我们只处理这两种类型的就可以了。\n有了这些之后，我们就可以快速的再完善一下了：\n// extract the .text section textSection := elfFile.Section(\u0026quot;.text\u0026quot;) if textSection == nil { log.Fatal(\u0026quot;No text section\u0026quot;) } // extract the raw bytes from the .text section textSectionData, err := textSection.Data() if err != nil { log.Fatal(err) } // traverse through the symbol table for _, symbol := range symbolTable { // skip over any symbols that aren't functinons/methods if symbol.Info != byte(2) \u0026amp;\u0026amp; symbol.Info != byte(18) { continue } // skip over empty symbols if symbol.Size == 0 { continue } // calculate starting and ending index of the symbol within the text section symbolStartingIndex := symbol.Value - textSection.Addr symbolEndingIndex := symbolStartingIndex + symbol.Size // collect the bytes of the symbol symbolBytes := textSectionData[symbolStartingIndex:symbolEndingIndex] // disasemble the symbol instructions, err := engine.Disasm(symbolBytes, symbol.Value, 0) if err != nil { log.Fatalf(\u0026quot;could not disasemble symbol: %s\u0026quot;, err) } // print out each instruction that's part of this symbol fmt.Printf(\u0026quot;\\n\\nSYMBOL %s\\n\u0026quot;, symbol.Name) for _, ins := range instructions { fmt.Printf(\u0026quot;0x%x:\\t%s\\t\\t%s\\n\u0026quot;, ins.Address, ins.Mnemonic, ins.OpStr) } }  完整的实例代码，详见 full disassembler。实现一个简单的反汇编器，实际上只用了70~80行代码而已。下面是一个简单的运行实例。\n 注意: 在测试的时候，需要注意下capstone的版本、gapstaone的版本，不然测试的时候可能会出错。这里先暂时不详细写了，遇到问题可以去repo下查issue。\n参考内容 # 1.dissecting go binaries, https://www.grant.pizza/dissecting-go-binaries\n"}),a.add({id:360,href:"/tags/forkexec/",title:"forkexec",description:"",content:""}),a.add({id:361,href:"/blog/2020-08-28-go%E7%A8%8B%E5%BA%8F%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E7%83%AD%E9%87%8D%E5%90%AF/",title:"go程序如何实现热重启",description:"服务器重启、发布时，应该如何做到平滑重启呢？这个问题可能很多人都思考过，本文就来详细说说……特别是go程序中如何实现热重启。",content:"最近在优化公司框架trpc时发现了一个热重启相关的问题，优化之余也总结沉淀下，对go如何实现热重启这方面的内容做一个简单的梳理。\n1.什么是热重启？ # 热重启（Hot Restart），是一项保证服务可用性的手段。它允许服务重启期间，不中断已经建立的连接，老服务进程不再接受新连接请求，新连接请求将在新服务进程中受理。对于原服务进程中已经建立的连接，也可以将其设为读关闭，等待平滑处理完连接上的请求及连接空闲后再行退出。通过这种方式，可以保证已建立的连接不中断，连接上的事务（请求、处理、响应）可以正常完成，新的服务进程也可以正常接受连接、处理连接上的请求。当然，热重启期间进程平滑退出涉及到的不止是连接上的事务，也有消息服务、自定义事务需要关注。\n这是我理解的热重启的一个大致描述。热重启现在还有没有存在的必要？我的理解是看场景。\n以后台开发为例，假如运维平台有能力在服务升级、重启时自动踢掉流量，服务就绪后又自动加回流量，假如能够合理预估服务QPS、请求处理时长，那么只要配置一个合理的停止前等待时间，是可以达到类似热重启的效果的。这样的话，在后台服务里面支持热重启就显得没什么必要。但是，如果我们开发一个微服务框架，不能对将来的部署平台、环境做这种假设，也有可能使用方只是部署在一两台物理机上，也没有其他的负载均衡设施，但不希望因为重启受干扰，热重启就很有必要。当然还有一些更复杂、要求更苛刻的场景，也需要热重启的能力。\n热重启是比较重要的一项保证服务质量的手段，还是值得了解下的，这也是本文介绍的初衷。\n2.如何实现热重启？ # 如何实现热重启，这里其实不能一概而论，要结合实际的场景来看（比如服务编程模型、对可用性要求的高低等）。大致的实现思路，可以先抛一下。\n一般要实现热重启，大致要包括如下步骤：\n 首先，要让老进程，这里称之为父进程了，先要fork出一个子进程来代替它工作； 然后，子进程就绪之后，通知父进程，正常接受新连接请求、处理连接上收到的请求； 再然后，父进程处理完已建立连接上的请求后、连接空闲后，平滑退出。  听上去是挺简单的\u0026hellip;\n2.1.认识fork # 大家都知道fork() 系统调用，父进程调用fork会创建一个进程副本，代码中还可以通过fork返回值是否为0来区分是子进程还是父进程。\nint main(char **argv, int argc) { pid_t pid = fork(); if (pid == 0) { printf(\u0026quot;i am child process\u0026quot;); } else { printf(\u0026quot;i am parent process, i have a child process named %d\u0026quot;, pid); } }  可能有些开发人员不知道fork的实现原理，或者不知道fork返回值为什么在父子进程中不同，或者不知道如何做到父子进程中返回值不同……了解这些是要有点知识积累的。\n2.2.返回值 # 简单概括下，ABI定义了进行函数调用时的一些规范，如何传递参数，如何返回值等等，以x86为例，如果返回值是rax寄存器能够容的一般都是通过rax寄存器返回的。\n如果rax寄存器位宽无法容纳下的返回值呢？也简单，编译器会安插些指令来完成这些神秘的操作，具体是什么指令，就跟语言编译器实现相关了。\n c语言，可能会将返回值的地址，传递到rdi或其他寄存器，被调函数内部呢，通过多条指令将返回值写入rdi代指的内存区； c语言，也可能在被调函数内部，用多个寄存器rax,rdx\u0026hellip;一起暂存返回结果，函数返回时再将多个寄存器的值赋值到变量中； 也可能会像golang这样，通过栈内存来返回；  2.3.fork返回值 # fork系统调用的返回值，有点特殊，在父进程和子进程中，这个函数返回的值是不同的，如何做到的呢？\n联想下父进程调用fork的时候，操作系统内核需要干些什么呢？分配进程控制块、分配pid、分配内存空间……肯定有很多东西啦，这里注意下进程的硬件上下文信息，这些是非常重要的，在进程被调度算法选中进行调度时，是需要还原硬件上下文信息的。\nLinux fork的时候，会对子进程的硬件上下文进行一定的修改，我就是让你fork之后拿到的pid是0，怎么办呢？前面2.2节提过了，对于那些小整数，rax寄存器存下绰绰有余，fork返回时就是将操作系统分配的pid放到rax寄存器的。\n那，对于子进程而言，我只要在fork的时候将它的硬件上下文rax寄存器清0，然后等其他设置全ok后，再将其状态从不可中断等待状态修改为可运行状态，等其被调度器调度时，会先还原其硬件上下文信息，包括PC、rax等等，这样fork返回后，rax中值为0，最终赋值给pid的值就是0。\n因此，也就可以通过这种判断 “pid是否等于0” 的方式来区分当前进程是父进程还是子进程了。\n2.4.局限性 # 很多人清楚fork可以创建一个进程的副本并继续往下执行，可以根据fork返回值来执行不同的分支逻辑。如果进程是多线程的，在一个线程中调用fork会复制整个进程吗？\nfork只能创建调用该函数的线程的副本，进程中其他运行的线程，fork不予处理。这就意味着，对于多线程程序而言，寄希望于通过fork来创建一个完整进程副本是不可行的。\n前面我们也提到了，fork是实现热重启的重要一环，fork这里的这个局限性，就制约着不同服务编程模型下的热重启实现方式。所以我们说具体问题具体分析，不同编程模型下实际上可以采用不同的实现方式。\n3.单进程单线程模型 # 单进程单线程模型，可能很多人一听觉得它已经被淘汰了，生产环境中不能用，真的么？强如redis，不就是单线程。强调下并非单线程模型没用，ok，收回来，现在关注下单进程单线程模型如何实现热重启。\n单进程单线程，实现热重启会比较简单些:\n fork一下就可以创建出子进程， 子进程可以继承父进程中的资源，如已经打开的文件描述符，包括父进程的listenfd、connfd， 父进程，可以选择关闭listenfd，后续接受连接的任务就交给子进程来完成了， 父进程，甚至也可以关闭connfd，让子进程处理连接上的请求、回包等，也可以自身处理完已建立的连接上的请求； 父进程，在合适的时间点选择退出，子进程开始变成顶梁柱。  核心思想就是这些，但是具体到实现，就有多种方法：\n 可以选择fork的方式让子进程拿到原来的listenfd、connfd， 也可以选择unixdomain socket的方式父进程将listenfd、connfd发送给子进程。  有同学可能会想，我不传递这些fd行吗？\n 比如我开启了reuseport，父进程直接处理完已建立连接connfd上的请求之后关闭，子进程里reuseport.Listen直接创建新的listenfd。  也可以！但是有些问题必须要提前考虑到：\n reuseport虽然允许多个进程在同一个端口上多次listen，似乎满足了要求，但是要知道只要euid相同，都可以在这个端口上listen！是不安全的！ reuseport实现和平台有关系，在Linux平台上在同一个address+port上listen多次，多个listenfd底层可以共享同一个连接队列，内核可以实现负载均衡，但是在darwin平台上却不会！  当然这里提到的这些问题，在多线程模型下肯定也存在。\n4.单进程多线程模型 # 前面提到的问题，在多线程模型中也会出现：\n fork只能复制calling thread，not whole process！ reuseport多次在相同地址+端口listen得到的多个fd，不同平台有不同的表现，可能无法做到接受连接时的load banlance！ 非reuseport情况下，多次listen会失败！ 不传递fd，直接通过reuseport来重新listen得到listenfd，不安全，不同服务进程实例可能会在同一个端口上监听，gg！ 父进程平滑退出的逻辑，关闭listenfd，等待connfd上请求处理结束，关闭connfd，一切妥当后，父进程退出，子进程挑大梁！  5. 其他线程模型 # 其他线程都基本上避不开上述3、4的实现或者组合，对应问题相仿，不再赘述。\n6. go实现热重启：触发时机 # 需要选择一个时机来触发热重启，什么时候触发呢？操作系统提供了信号机制，允许进程做出一些自定义的信号处理。\n杀死一个进程，一般会通过kill -9发送SIGKILL信号给进程，这个信号不允许捕获，SIGABORT也不允许捕获，这样可以允许进程所有者或者高权限用户控制进程生死，达到更好的管理效果。\nkill也可以用来发送其他信号给进程，如发送SIGUSR1、SIGUSR2、SIGINT等等，进程中可以接收这些信号，并针对性的做出处理。这里可以选择SIGUSR1或者SIGUSR2来通知进程热重启。\ngo func() { ch := make(chan os.Signal, 1) signal.Notify(ch, os.SIGUSR2) \u0026lt;- ch //接下来就可以做热重启相关的逻辑了 ... }()  7. 如何判断热重启 # 那一个go程序重新启动之后，所有运行时状态信息都是新的，那如何区分自己是否是子进程呢，或者说我是否要执行热重启逻辑呢？父进程可以通过设置子进程初始化时的环境变量，比如加个HOT_RESTART=1。\n这就要求代码中在合适的地方要先检测环境变量HOT_RESTART是否为1，如果成立，那就执行热重启逻辑，否则就执行全新的启动逻辑。\n8. ForkExec # 假如当前进程收到SIGUSR2信号之后，希望执行热重启逻辑，那么好，需要先执行syscall.ForkExec(\u0026hellip;)来创建一个子进程，注意go不同于cc++，它本身就是依赖多线程来调度协程的，天然就是多线程程序，只不过是他没有使用NPTL线程库来创建，而是通过clone系统调用来创建。\n前面提过了，如果单纯fork的话，只能复制调用fork函数的线程，对于进程中的其他线程无能为力，所以对于go这种天然的多线程程序，必须从头来一遍，再exec一下。所以go标准库提供的函数是syscall.ForkExec而不是syscall.Fork。\n9. go实现热重启: 传递listenfd # go里面传递fd的方式，有这么几种，父进程fork子进程的时候传递fd，或者后面通过unix domain socket传递。需要注意的是，我们传递的实际上是file description，而非file descriptor。\n附上一张类unix系统下file descriptor、file description、inode三者之间的关系图：\nfd分配都是从小到大分配的，父进程中的fd为10，传递到子进程中之后有可能就不是10。那么传递到子进程的fd是否是可以预测的呢？可以预测，但是不建议。所以我提供了两种实现方式。\n9.1 ForkExec+ProcAttr{Files: []uintptr{}} # 要传递一个listenfd很简单，假如是类型net.Listener，那就通过tcpln := ln.(*net.TCPListener); file, _ := tcpln.File(); fd := file.FD() 来拿到listener底层file description对应的fd。\n需要注意的是，这里的fd并非底层的file description对应的初始fd，而是被dup2复制出来的一个fd（调用tcpln.File()的时候就已经分配了），这样底层file description引用计数就会+1。如果后面想通过ln.Close()关闭监听套接字的话，sorry，关不掉。这里需要显示的执行 file.Close() 将新创建的fd关掉，使对应的file description引用计数-1，保证Close的时候引用计数为0，才可以正常关闭。\n试想下，我们想实现热重启，是一定要等连接上接收的请求处理完才可以退出进程的，但是这期间父进程不能再接收新的连接请求，如果这里不能正常关闭listener，那我们这个目标就无法实现。所以这里对dup出来的fd的处理要慎重些，不要遗忘。\nOK，接下来说下syscall.ProcAttr{Files: []uintptr{}}，这里就是要传递的父进程中的fd，比如要传递stdin、stdout、stderr给子进程，就需要将这几个对应的fd塞进去os.Stdin.FD(), os.Stdout.FD(), os.Stderr.FD()，如果要想传递刚才的listenfd，就需要将上面的file.FD()返回的fd塞进去。\n子进程中接收到这些fd之后，在类unix系统下一般会按照从0、1、2、3这样递增的顺序来分配fd，那么传递过去的fd是可以预测的，假如除了stdin, stdout, stderr再传两个listenfd，那么可以预测这两个的fd应该是3，4。在类unix系统下一般都是这么处理的，子进程中就可以根据传递fd的数量（比如通过环境变量传递给子进程FD_NUM=2），来从3开始计算，哦，这两个fd应该是3，4。\n父子进程可以通过一个约定的顺序，来组织传递的listenfd的顺序，以方便子进程中按相同的约定进行处理，当然也可以通过fd重建listener之后来判断对应的监听network+address，以区分该listener对应的是哪一个逻辑service。都是可以的！\n需要注意的是，file.FD()返回的fd是非阻塞的，会影响到底层的file description，在重建listener先将其设为nonblock, syscall.SetNonBlock(fd)，然后file, _ := os.NewFile(fd); tcplistener := net.FileListener(file)，或者是 udpconn := net.PacketConn(file)，然后可以获取tcplistener、udpconn的监听地址，来关联其对应的逻辑service。\n 前面提到file.FD()会将底层的file description设置为阻塞模式，这里再补充下，net.FileListener(f), net.PacketConn(f)内部会调用newFileFd()-\u0026gt;dupSocket()，这几个函数内部会将fd对应的file description重新设置为非阻塞。父子进程中共享了listener对应的file description，所以不需要显示设置为非阻塞。\n 有些微服务框架是支持对服务进行逻辑service分组的，google pb规范中也支持多service定义，这个在腾讯的goneat、trpc框架中也是有支持的。\n当然了，这里我不会写一个完整的包含上述所有描述的demo给大家，这有点占篇幅，这里只贴一个精简版的实例，其他的读者感兴趣可以自己编码测试。须知纸上得来终觉浅，还是要多实践。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;time\u0026quot; ) const envRestart = \u0026quot;RESTART\u0026quot; const envListenFD = \u0026quot;LISTENFD\u0026quot; func main() { v := os.Getenv(envRestart) if v != \u0026quot;1\u0026quot; { ln, err := net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;localhost:8888\u0026quot;) if err != nil { panic(err) } wg := sync.WaitGroup{} wg.Add(1) go func() { defer wg.Done() for { ln.Accept() } }() tcpln := ln.(*net.TCPListener) f, err := tcpln.File() if err != nil { panic(err) } os.Setenv(envRestart, \u0026quot;1\u0026quot;) os.Setenv(envListenFD, fmt.Sprintf(\u0026quot;%d\u0026quot;, f.Fd())) _, err = syscall.ForkExec(os.Args[0], os.Args, \u0026amp;syscall.ProcAttr{ Env: os.Environ(), Files: []uintptr{os.Stdin.Fd(), os.Stdout.Fd(), os.Stderr.Fd(), f.Fd()}, Sys: nil, }) if err != nil { panic(err) } log.Print(\u0026quot;parent pid:\u0026quot;, os.Getpid(), \u0026quot;, pass fd:\u0026quot;, f.Fd()) f.Close() wg.Wait() } else { v := os.Getenv(envListenFD) fd, err := strconv.ParseInt(v, 10, 64) if err != nil { panic(err) } log.Print(\u0026quot;child pid:\u0026quot;, os.Getpid(), \u0026quot;, recv fd:\u0026quot;, fd) // case1: 理解上面提及的file descriptor、file description的关系 // 这里子进程继承了父进程中传递过来的一些fd，但是fd数值与父进程中可能是不同的 // // 取消注释来测试... //ff := os.NewFile(uintptr(fd), \u0026quot;\u0026quot;) //if ff != nil { //	_, err := ff.Stat() //	if err != nil { //	log.Println(err) //	} //} // case2: 假定父进程中共享了fd 0\\1\\2\\listenfd给子进程，那再子进程中可以预测到listenfd=3 ff := os.NewFile(uintptr(3), \u0026quot;\u0026quot;) fmt.Println(\u0026quot;fd:\u0026quot;, ff.Fd()) if ff != nil { _, err := ff.Stat() if err != nil { panic(err) } // 这里pause, 运行命令lsof -P -p $pid，检查下有没有listenfd传过来，除了0，1，2，应该有看到3 // ctrl+d to continue ioutil.ReadAll(os.Stdin) fmt.Println(\u0026quot;....\u0026quot;) _, err = net.FileListener(ff) if err != nil { panic(err) } // 这里pause, 运行命令lsof -P -p $pid, 会发现有两个listenfd, // 因为前面调用了ff.FD() dup2了一个，如果这里不显示关闭，listener将无法关闭 ff.Close() time.Sleep(time.Minute) } time.Sleep(time.Minute) } }  这里用简单的代码大致解释了如何用ProcAttr来传递listenfd。这里有个问题，假如后续父进程中传递的fd修改了呢，比如不传stdin, stdout, stderr的fd了，怎么办？服务端是不是要开始预测应该从0开始编号了？我们可以通过环境变量通知子进程，比如传递的fd从哪个编号开始是listenfd，一共有几个listenfd，这样也是可以实现的。\n这种实现方式可以跨平台。\n感兴趣的话，可以看下facebook提供的这个实现grace。\n9.2 unix domain socket + cmsg # 另一种，思路就是通过unix domain socket + cmsg来传递，父进程启动的时候依然是通过ForkExec来创建子进程，但是并不通过ProcAttr来传递listenfd。\n父进程在创建子进程之前，创建一个unix domain socket并监听，等子进程启动之后，建立到这个unix domain socket的连接，父进程此时开始将listenfd通过cmsg发送给子进程，获取fd的方式与9.1相同，该注意的fd关闭问题也是一样的处理。\n子进程连接上unix domain socket，开始接收cmsg，内核帮子进程收消息的时候，发现里面有一个父进程的fd，内核找到对应的file description，并为子进程分配一个fd，将两者建立起映射关系。然后回到子进程中的时候，子进程拿到的就是对应该file description的fd了。通过os.NewFile(fd)就可以拿到file，然后再通过net.FileListener或者net.PacketConn就可以拿到tcplistener或者udpconn。\n剩下的获取监听地址，关联逻辑service的动作，就与9.1小结描述的一致了。\n这里我也提供一个可运行的精简版的demo，供大家了解、测试用。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;io/ioutil\u0026quot; \u0026quot;log\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;strconv\u0026quot; \u0026quot;sync\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;time\u0026quot; passfd \u0026quot;github.com/ftrvxmtrx/fd\u0026quot; ) const envRestart = \u0026quot;RESTART\u0026quot; const envListenFD = \u0026quot;LISTENFD\u0026quot; const unixsockname = \u0026quot;/tmp/xxxxxxxxxxxxxxxxx.sock\u0026quot; func main() { v := os.Getenv(envRestart) if v != \u0026quot;1\u0026quot; { ln, err := net.Listen(\u0026quot;tcp\u0026quot;, \u0026quot;localhost:8888\u0026quot;) if err != nil { panic(err) } wg := sync.WaitGroup{} wg.Add(1) go func() { defer wg.Done() for { ln.Accept() } }() tcpln := ln.(*net.TCPListener) f, err := tcpln.File() if err != nil { panic(err) } os.Setenv(envRestart, \u0026quot;1\u0026quot;) os.Setenv(envListenFD, fmt.Sprintf(\u0026quot;%d\u0026quot;, f.Fd())) _, err = syscall.ForkExec(os.Args[0], os.Args, \u0026amp;syscall.ProcAttr{ Env: os.Environ(), Files: []uintptr{os.Stdin.Fd(), os.Stdout.Fd(), os.Stderr.Fd(), /*f.Fd()*/}, // comment this when test unixsock Sys: nil, }) if err != nil { panic(err) } log.Print(\u0026quot;parent pid:\u0026quot;, os.Getpid(), \u0026quot;, pass fd:\u0026quot;, f.Fd()) os.Remove(unixsockname) unix, err := net.Listen(\u0026quot;unix\u0026quot;, unixsockname) if err != nil { panic(err) } unixconn, err := unix.Accept() if err != nil { panic(err) } err = passfd.Put(unixconn.(*net.UnixConn), f) if err != nil { panic(err) } f.Close() wg.Wait() } else { v := os.Getenv(envListenFD) fd, err := strconv.ParseInt(v, 10, 64) if err != nil { panic(err) } log.Print(\u0026quot;child pid:\u0026quot;, os.Getpid(), \u0026quot;, recv fd:\u0026quot;, fd) // case1: 有些同学觉得可以通过环境变量传fd，通过环境变量肯定是不行的，fd根本不对应子进程中的fd //ff := os.NewFile(uintptr(fd), \u0026quot;\u0026quot;) //if ff != nil { //	_, err := ff.Stat() //	if err != nil { //	log.Println(err) //	} //} // case2: 有些同学觉得如果只有一个listenfd的情况下，那如果fork子进程时保证只传0\\1\\2\\listenfd，那子进程中listenfd一定是3 //ff := os.NewFile(uintptr(3), \u0026quot;\u0026quot;) //if ff != nil { //	_, err := ff.Stat() //	if err != nil { //	panic(err) //	} // //	// pause, ctrl+d to continue //	ioutil.ReadAll(os.Stdin) //	fmt.Println(\u0026quot;....\u0026quot;) //	_, err = net.FileListener(ff) //会dup一个fd出来，有多个listener //	if err != nil { //	panic(err) //	} //	// lsof -P -p $pid, 会发现有两个listenfd //	time.Sleep(time.Minute) //} // 这里我们暂停下，方便运行系统命令来查看进程当前的一些状态 // run: lsof -P -p $pid，检查下listenfd情况 ioutil.ReadAll(os.Stdin) fmt.Println(\u0026quot;.....\u0026quot;) unixconn, err := net.Dial(\u0026quot;unix\u0026quot;, unixsockname) if err != nil { panic(err) } files, err := passfd.Get(unixconn.(*net.UnixConn), 1, nil) if err != nil { panic(err) } // 这里再运行命令：lsof -P -p $pid再检查下listenfd情况 f := files[0] f.Stat() time.Sleep(time.Minute) } }  这种实现方式，仅限类unix系统。\n如果有服务混布的情况存在，需要考虑下使用的unix domain socket的文件名，避免因为重名所引起的问题，可以考虑通过”进程名.pid“来作为unix domain socket的名字，并通过环境变量将其传递给子进程。\n10. go实现热重启: 子进程如何通过listenfd重建listener # 前面已经提过了，当拿到fd之后还不知道它对应的是tcp的listener，还是udpconn，那怎么办？都试下呗。\nfile, err := os.NewFile(fd) // check error tcpln, err := net.FileListener(file) // check error udpconn, err := net.PacketConn(file) // check error  11. go实现热重启：父进程平滑退出 # 父进程如何平滑退出呢，这个要看父进程中都有哪些逻辑要平滑停止了。\n11.1. 处理已建立连接上请求 # 可以从这两个方面入手：\n shutdown read，不再接受新的请求，对端继续写数据的时候会感知到失败； 继续处理连接上已经正常接收的请求，处理完成后，回包，close连接；  也可以考虑，不进行读端关闭，而是等连接空闲一段时间后再close，是否尽快关闭更符合要求就要结合场景、要求来看。\n如果对可用性要求比较苛刻，可能也会需要考虑将connfd、connfd上已经读取写入的buffer数据也一并传递给子进程处理。\n11.2. 消息服务 #  确认下自己服务的消息消费、确认机制是否合理 不再收新消息 处理完已收到的消息后，再退出  11.3. 自定义AtExit清理任务 # 有些任务会有些自定义任务，希望进程在退出之前，能够执行到，这种可以提供一个类似AtExit的注册函数，让进程退出之前能够执行业务自定义的清理逻辑。\n不管是平滑重启，还是其他正常退出，对该支持都是有一定需求的。\n12. 其他 # 有些场景下也希望传递connfd，包括connfd上对应的读写的数据。\n比如连接复用的场景，客户端可能会通过同一个连接发送多个请求，假如在中间某个时刻服务端执行热重启操作，服务端如果直接连接读关闭会导致后续客户端的数据发送失败，客户端关闭连接则可能导致之前已经接收的请求也无法正常响应。 这种情况下，可以考虑服务端继续处理连接上请求，等连接空闲再关闭。会不会一直不空闲呢？有可能。\n其实服务端不能预测客户端是否会采用连接复用模式，选择一个更可靠的处理方式会更好些，如果场景要求比较苛刻，并不希望通过上层重试来解决的话。这种可以考虑将connfd以及connfd上读写的buffer数据一并传递给子进程，交由子进程来处理，这个时候需要关注的点更多，处理起来更复杂，感兴趣的可以参考下mosn的实现。\n13. 总结 # 热重启作为一种保证服务平滑重启、升级的实现方式，在今天看来依然非常有价值。本文描述了实现热重启的一些大致思路，并且通过demo循序渐进地描述了在go服务中如何予以实现。虽然没有提供一个完整的热重启实例给大家，但是相信大家读完之后应该已经可以亲手实现了。\n由于作者本人水平有限，难免会有描述疏漏之处，欢迎大家指正。\n参考文章 #  Unix高级编程：进程间通信，W.Richard Stevens mosn启动流程，https://mosn.io/blog/code/mosn-startup/  "}),a.add({id:362,href:"/tags/unixsock/",title:"unixsock",description:"",content:""}),a.add({id:363,href:"/tags/%E7%83%AD%E9%87%8D%E5%90%AF/",title:"热重启",description:"",content:""}),a.add({id:364,href:"/tags/debug/",title:"debug",description:"",content:""}),a.add({id:365,href:"/blog/2020-08-25-delve%E8%B0%83%E8%AF%95%E5%99%A8%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"delve调试器设计实现",description:"研究调试器设计实现有段时间了，前几天在调试一个程序时，发现go调试器go-delve/delve竟然不支持类似gdb的x/FMT格式，于是在之前工作上又优化了一下。CR期间，也学习到一些之前理解不深的地方，也顺便了解了下delve的整体架构设计、大致实现，今天就来说道说道。\ndelve简介 # go-delve/delve是Derekparker发起的一个调试器项目，面向go语言的。为什么针对go语言要创建一个新的调试器呢？为什么不使用GDB呢？这里涉及到go的一些特性。\n作为符号级调试器，要能正常实现源码级调试，有这么几个事情必须要做的：\n 首先，就必须要有调试信息的支持，比如编译器、连接器在构建过程中插入DWARF相关的sections，以供后续调试器提取、解析以重建指令、地址与源码的映射关系，还有在活动记录中跳转等等。 此外，有了调试信息，还需要理解语言内部实现，比如go的类型系统、协程、运行时，这样你才能读写源码级的运行状态信息； 还没完，你还需要一些平台级实现相关的玩意，不同的语言在不同的平台上有不同的实现，调试器要理解这些差异并做针对性处理；  这些工作，在GDB里扩展插件来实现，不一定能很好地实现的，比如GDB支持的DWARF标准版本问题，和go编译器没有对齐之类的，比如GDB里面Target层（对tracee）控制层考虑的大多是进程、线程级别的，没有对goroutine类似的控制能力，诸如此类。\nAnyway，我们需要一款更理解go的调试器，delve就这么诞生了。现在大已经是go官方推荐的调试器了，也是GoLand、VSCode、vim-go中使用的调试器。能有幸了解一款调试器的实现、参与贡献还是很爽的一件事情。\ndelve整体架构 # delve大致实现 # ",content:"研究调试器设计实现有段时间了，前几天在调试一个程序时，发现go调试器go-delve/delve竟然不支持类似gdb的x/FMT格式，于是在之前工作上又优化了一下。CR期间，也学习到一些之前理解不深的地方，也顺便了解了下delve的整体架构设计、大致实现，今天就来说道说道。\ndelve简介 # go-delve/delve是Derekparker发起的一个调试器项目，面向go语言的。为什么针对go语言要创建一个新的调试器呢？为什么不使用GDB呢？这里涉及到go的一些特性。\n作为符号级调试器，要能正常实现源码级调试，有这么几个事情必须要做的：\n 首先，就必须要有调试信息的支持，比如编译器、连接器在构建过程中插入DWARF相关的sections，以供后续调试器提取、解析以重建指令、地址与源码的映射关系，还有在活动记录中跳转等等。 此外，有了调试信息，还需要理解语言内部实现，比如go的类型系统、协程、运行时，这样你才能读写源码级的运行状态信息； 还没完，你还需要一些平台级实现相关的玩意，不同的语言在不同的平台上有不同的实现，调试器要理解这些差异并做针对性处理；  这些工作，在GDB里扩展插件来实现，不一定能很好地实现的，比如GDB支持的DWARF标准版本问题，和go编译器没有对齐之类的，比如GDB里面Target层（对tracee）控制层考虑的大多是进程、线程级别的，没有对goroutine类似的控制能力，诸如此类。\nAnyway，我们需要一款更理解go的调试器，delve就这么诞生了。现在大已经是go官方推荐的调试器了，也是GoLand、VSCode、vim-go中使用的调试器。能有幸了解一款调试器的实现、参与贡献还是很爽的一件事情。\ndelve整体架构 # delve大致实现 # "}),a.add({id:366,href:"/tags/jsonrpc/",title:"jsonrpc",description:"",content:""}),a.add({id:367,href:"/tags/starlark/",title:"starlark",description:"",content:""}),a.add({id:368,href:"/tags/mock/",title:"mock",description:"",content:""}),a.add({id:369,href:"/blog/2020-08-23-monkey_patching_in_go/",title:"Monkey Patching in Go",description:"很多go开发者使用gomonkey来写mock测试，但是很多连原理都没搞明白，本文从0开始介绍如何实现monkey patching，希望读者能了解这里的实现原理，以及从原理认识到gomonkey的优缺点。",content:"前几天写了篇x64汇编开发介绍的文章，当时有提到接下来会介绍下go中如何实现monkey patching，嗯，今天就来说下这个事情。\nMonkey Patching 简介 # monkey patching，一说到这个，很多熟悉go的同学可能会联想起gomonkey这个mock测试框架。该术语的定义取决于使用它的社区。在Ruby，Python 和许多其他动态编程语言中，“monkey patching”一词仅指在运行时对类或模块的动态修改，其目的是为了修补现有的第三方代码，以此作为解决方法。错误或功能无法正常运行。根据其不同的意图，在运行时修改类的其他形式也具有不同的名称。例如，在Zope和Plone中，安全补丁通常是使用动态类修改来提供的，但它们被称为热修补程序(hot fixes)。\nmonkey patching，它常用于如下场景：\n 在运行时替换方法/类/属性/函数，例如在测试过程中取消功能； 修改/扩展第三方产品的行为，而无需维护源代码的私有副本； 在运行时将补丁程序的结果应用于内存中的状态，而不是磁盘上的源代码； 分发与原始源代码一起存在的安全性或行为修复程序（例如，将其作为Ruby on Rails平台的插件分发）； 探索各种自动修复程序以提供自我修复。  Monkey Patching in Go # 最近在写mock测试的时候，有些场景下用到了gomonkey，这个测试框架挺好用的，之前也简单了解过大致的实现，最近也在看些底层工具链相关的东西，就想整理分享下。\n首先我会简单介绍下go函数的实现、指令patching的概念，然后看下反汇编、指令级调试如何帮助快速定位问题，然后通过几个简单的demo来演示下如何实现指令patch，然后我们再回到go实现monkey patching。\n 如果不感兴趣就真的不要看了，就好像别人骑车摔破头也觉得很爽，但是有人觉得10几万的车也没啥吸引人的，所以我极少主动转发、群里推送这些文章，我更希望它是被主动发现的。\n Go函数表示 # demo1 # 下面定义了一个简单的函数a()，然后再main函数中调用它，然后调用通过print打印出它的返回值。\nfile: main.go\npackage main func a() int { return 1 } func main() { print(a()) }  这个函数非常简单，monkey patching离不开汇编，所以我们先看下其对应的汇编代码，了解这个程序干了些啥。\n这里顺便推荐几个工具:\n dlv，适用于go的调试器 radare2，静态分析工具，类似的还有IDA、Hopper  我这里就先试用radare2（下文简称r2）来演示如何操作了。\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main main.go $ r2 ./main -- give | and \u0026gt; a try piping and redirection [0x00454330]\u0026gt; s sym.main.main [0x00459270]\u0026gt; af [0x00459270]\u0026gt; pdf ; CODE XREF from sym.main.main @ 0x4592c2 ┌ 84: sym.main.main (); │ ; var int64_t var_10h @ rsp+0x8 │ ; var int64_t var_8h @ rsp+0x10 │ ┌─\u0026gt; 0x00459270 64488b0c25f8. mov rcx, qword fs:[0xfffffffffffffff8] ;; 这里是go函数栈检查 │ ╎ 0x00459279 483b6110 cmp rsp, qword [rcx + 0x10] │ ┌──\u0026lt; 0x0045927d 763e jbe 0x4592bd │ │╎ 0x0045927f 4883ec18 sub rsp, 0x18 ;; 栈没问题开始执行 │ │╎ 0x00459283 48896c2410 mov qword [var_8h], rbp │ │╎ 0x00459288 488d6c2410 lea rbp, qword [var_8h] │ │╎ 0x0045928d e8beffffff call sym.main.a ;; 调用函数sym.main.a │ │╎ 0x00459292 488b0424 mov rax, qword [rsp] │ │╎ 0x00459296 4889442408 mov qword [var_10h], rax │ │╎ 0x0045929b e83003fdff call sym.runtime.printlock │ │╎ 0x004592a0 488b442408 mov rax, qword [var_10h] │ │╎ 0x004592a5 48890424 mov qword [rsp], rax │ │╎ 0x004592a9 e8a20afdff call sym.runtime.printint │ │╎ 0x004592ae e89d03fdff call sym.runtime.printunlock │ │╎ 0x004592b3 488b6c2410 mov rbp, qword [var_8h] │ │╎ 0x004592b8 4883c418 add rsp, 0x18 │ │╎ 0x004592bc c3 ret │ └──\u0026gt; 0x004592bd e83e7affff call sym.runtime.morestack_noctxt └ └─\u0026lt; 0x004592c2 ebac jmp sym.main.main [0x00459270]\u0026gt; s sym.main.a ;; 查看sym.main.a地址为0x00459250 [0x00459250]\u0026gt;  函数main中调用函数a的过程就这么简单call sym.main.a，也就是call 0x00459250，再看下a这个函数，它很简单将返回值1存储到[arg_8h]中，就是前一个栈帧中的一个8字节空间，之后的我们就先不关心了。\n[0x00459250]\u0026gt; af [0x00459250]\u0026gt; pdf ; CALL XREF from sym.main.main @ 0x45928d ┌ 19: sym.main.a (int64_t arg_8h); │ ; arg int64_t arg_8h @ rsp+0x8 │ 0x00459250 48c744240800. mov qword [arg_8h], 0 │ 0x00459259 48c744240801. mov qword [arg_8h], 1 └ 0x00459262 c3 ret  demo2 # 看完上面这个，我们看点跟monkey patching相关的一个demo。\n这个demo也很简单，定义了一个函数a，然后定义了一个变量f，将a赋值给f。有过cc++基础的同学，会自然联想到函数指针，我也是写cc++过来的，所以很自然会想到，f是一个函数指针，它指向a这个函数。下面的打印语句呢，它应该打印出函数a的地址。\nfile: main2.go\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func main() { f := a fmt.Printf(\u0026quot;%p\\n\u0026quot;, a) fmt.Printf(\u0026quot;0x%x\\n\u0026quot;, *(*uintptr)(unsafe.Pointer(\u0026amp;f))) }  测试下看下结果：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main2 main2.go $ ./main2 0x4abf20 0x4ecc28  发现这两个地址并不相同，说明什么，说明我们对go函数值的理解有偏差，至少可以确定的是它不是一个函数指针。要想理解go的函数值表示，可以参考funcval表示。\n那这么看应该是一个指针的指针，验证一下：\n[0x0045c410]\u0026gt; px/1ag 0x4ecc28 0x004ecc28 0x004abf20 0x00000000 .J.....  px/1ag就是类似gdb调试器里面的x/FMT或者dlv里面的x -FMT hex -len 8 address。我们打印地址0x4ecc28地址处的一个8字节地址出来，发现刚好就是函数a的地址0x004abf20。所以，上述f := a 关于f结构的猜想就得到了验证，它就是一个funcval，并非cc++意义上的函数指针。\ndemo3 # 理解了funcval之后，再来一个demo，再来一个修改版的demo，这下应该可以打印出相同的地址了。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func main() { f := a fmt.Printf(\u0026quot;%p\\n\u0026quot;, a) fmt.Printf(\u0026quot;0x%x\\n\u0026quot;, **(**uintptr)(unsafe.Pointer(\u0026amp;f))) }  运行一下：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main3 main3.go $ ./main3 0x4abf20 0x4abf20  OK，到这里，我们理解了funcval，那么当我们调用 f() 的时候，编译器安插了什么指令来实现对a这个函数的调用呢？\nfile: main4.go\npackage main() func a() int { return 1 } func main() { f := a f() }  运行以下操作：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o main4 main4.go $ $ r2 ./main4 -- Enable ascii-art jump lines in disassembly by setting 'e asm.lines=true'. asm.lines.out and asm.linestyle may interest you as well [0x00454330]\u0026gt; s sym.main.main [0x00459270]\u0026gt; af [0x00459270]\u0026gt; pdf ; CODE XREF from sym.main.main @ 0x4592b1 ┌ 67: sym.main.main (); │ ; var int64_t var_10h @ rsp+0x8 │ ; var int64_t var_8h @ rsp+0x10 │ ┌─\u0026gt; 0x00459270 64488b0c25f8. mov rcx, qword fs:[0xfffffffffffffff8] │ ╎ 0x00459279 483b6110 cmp rsp, qword [rcx + 0x10] │ ┌──\u0026lt; 0x0045927d 762d jbe 0x4592ac │ │╎ 0x0045927f 4883ec18 sub rsp, 0x18 │ │╎ 0x00459283 48896c2410 mov qword [var_8h], rbp │ │╎ 0x00459288 488d6c2410 lea rbp, qword [var_8h] │ │╎ 0x0045928d 488d15fc7002. lea rdx, qword [0x00480390] │ │╎ 0x00459294 4889542408 mov qword [var_10h], rdx │ │╎ 0x00459299 488b05f07002. mov rax, qword [0x00480390] ; [0x480390:8]=0x459250 sym.main.a │ │╎ 0x004592a0 ffd0 call rax │ │╎ 0x004592a2 488b6c2410 mov rbp, qword [var_8h] │ │╎ 0x004592a7 4883c418 add rsp, 0x18 │ │╎ 0x004592ab c3 ret │ └──\u0026gt; 0x004592ac e84f7affff call sym.runtime.morestack_noctxt └ └─\u0026lt; 0x004592b1 ebbd jmp sym.main.main  这里其实可以确定的是，0x00480390 就是变量f这个funcval的地址，下面又取 [0x00480390] 这个内存单元中的内容送rax，此时rax中的内容也就是函数a的地址了，最后 call rax 完成函数调用。\n这里其实实现了一个操作，本来f也可以指向另一个函数b，但是我却通过赋值操作 f := a 将其执行了另一个函数a去执行。这样类似的操作，提炼下是否可以拿来用于实现monkey patching呢？可以。\n现在要在程序运行的时候，动态调整一个函数要执行的目的代码，其实也可以通过类似的操作。\n指令Patching # 指令patching是一个比monkey patching覆盖面更广的范畴，意思就是运行时修改程序执行的指令。其实，指令patching技术大家都已经用过无数次了，只不过不是你亲自操作的。\n比如，当你调试一个程序的时候，就需要指令patch让你的被调试任务（俗称tracee）停下来，这个时候就需要将tracee下一条要执行的指令的首字节篡改为0xcc，处理器遇到这个指令就会让你的程序停下来。通常int3用来生成一字节指令0xcc，处理器取值、译码、执行完之后就会停下来触发中断，然后内核提供的中断服务程序开始执行。正常BIOS提供的都是16位中断服务程序，以Linux为例，内核初始化的时候会重建保护模式下的32/64中断服务程序，意思也就是说，碰到这个指令之后，内核就相当于收到了通知来处理tracee的暂停工作。等tracee停下来之后就会通知tracer（也就是调试器），tracer就可以通过系统调用等手段来检查tracee的运行时信息，包括registers、ram等等。\n这里的monkey patching呢，其实也是有点类似，简单一句就是篡改指令而已。问题是这里该怎么篡改？\n其实这里的改法，也比较简单，假如我们有这样的一个函数 func a() int {return 1}，我们希望main函数中调用a()的时候，执行的是func b() int {return 2}，那怎么搞呢？我们可以写一个函数replace(a, b)将对a的调用替换成对b的调用。\npackage main func a() int { return 1 } func b() int { return 2 } func main() { replace(a, b) print(a()) }  大致实现 # 因为是在运行时修改，在运行时能干什么呢？我们不能修改a的地址，只能再a的地址处玩些花招：指令patch，篡改这里的指令。怎么篡改呢？\n 前面讲过，我们是可以拿到一个funcval变量中保存的目的函数地址的； 操作系统，提供了一些可以使用的系统调用来让我们修改进程地址空间中的数据；  两个条件都具备了，我们可以通过ptrace+peekdata/pokedata来读写指令，也可以获取函数对应的页面（注意对齐），然后申请对这个页面的读写执行权限。两种办法应该都可行。更安全、细粒度的控制，ptrace+peekdata/pokedata要好些，这里纯粹是为了演示，就用后面这个办法了。大致实现如下。\nfile5: main5.go\npackage main import ( \u0026quot;syscall\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func b() int { return 2 } func rawMemoryAccess(b uintptr) []byte { return (*(*[0xFF]byte)(unsafe.Pointer(b)))[:] } func assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) return []byte{ // TODO 动态生成跳转到函数funcval f目的地址的指令 // MOV rdx, funcVal // JMP [rdx] } } func replace(orig, replacement func() int) { bytes := assembleJump(replacement) functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig)) window := rawMemoryAccess(functionLocation) copy(window, bytes) } func main() { replace(a, b) // 将对a的调用替换成对b的调用 print(a()) // 这里输出的不是1，是2，注意禁用内联-gcflags=\u0026quot;all=-N -l\u0026quot; }  大致实现思路就是上面这样，replace内部：\n 会首先生成跳转到函数b的汇编指令， 然后再找到函数a的内存地址， 再将生成的跳转指令拷贝到函数a的地址处，覆盖a原来的指令；  这样当程序跑起来之后，跑到a的地址处，立即就JMP到函数b的地址处执行函数b的指令。我们这里不考虑将a数据恢复的问题，其实要做也很简单，你记录一下哪个地址，覆写了多少哪些数据就行了。调试器调试安插0xcc指令的时候都是需要做好保存、恢复类操作的，不然生成的端点（0xcc）就把指令弄乱套了。我们这里就不做这些了。\nOK，那这里的函数 assembleJump(f func() int) 如何动态生成它的跳转指令呢？这里可以先借助指令级调试先自己测试下。\n指令级调试 # 调试器，大家都熟悉吧？其实调试器也是可以分成好几类比较通俗的分类是源码级调试器、指令级调试器。\n指令级调试器，大家听说过的应该有IDA、OlleDbg、Hopper、Cutter、Radare2，指令级调试器一般工作在汇编指令层级，对上层高级语言的东西不怎么理解，它理解的就是一些最原始的信息，指令、数据、寄存器、内存，没有文件、源码、行号、变量名\u0026hellip;各自有各自的用途，一些符号级调试器如dlv、gdb、lldb等等的也会支持一些基础的指令级调试的能力，比如反汇编、step、step reverse等等的。\n我们这里希望在指令级完成调试，比如修改些指令看看效果之类的，一般的工具还是不方便的。Radare2支持指令级调试、指令修改、根据调用约定动态生成调用图等之类的，还是很方便的。\n今天就用Radare2来演示下这个如何操作，要调试的是下面这段代码。我们在函数跳转到a地址执行之后，将a地址处的指令篡改下，比如写个JMP到b函数地址的指令，看能不能正常跳转到b处执行，调试成功应该输出2 2。\nfile: mainx.go\npackage main func a() int { return 1 } func b() int { return 2 } func main() { println(a(), b()) }  运行以下操作：\n$ go build -gcflags=\u0026quot;all=-N -l\u0026quot; -o mainx mainx.go $ $ r2 -w ./mainx $ r2 -w ./mainx -- To debug a program, you can call r2 with 'dbg://\u0026lt;path-to-program\u0026gt;' or '-d \u0026lt;path..\u0026gt;' [0x00454330]\u0026gt; s sym.main. sym.main.a sym.main.b sym.main.main [0x00454330]\u0026gt; s sym.main.a ; 发现函数a的低质是0x00454330 [0x00459250]\u0026gt; af [0x00459250]\u0026gt; s sym.main.b ; 发现函数b的地址是0x00459250 [0x00459270]\u0026gt; af  好，我们接着操作看下在sym.main.a地址处写入个跳转到b的指令。\n[0x00459270]\u0026gt; s sym.main.a [0x00459250]\u0026gt; pdf ┌ 19: sym.main.a (int64_t arg_8h); │ ; arg int64_t arg_8h @ rsp+0x8 │ 0x00459250 48c744240800. mov qword [arg_8h], 0 │ 0x00459259 48c744240801. mov qword [arg_8h], 1 └ 0x00459262 c3 ret [0x00459250]\u0026gt;  我们看到函数a处的逻辑是返回值1，我们从起起始地址0x00459250处开始，用JMP bAddress的指令覆盖。\n我们希望写到此处的指令有：\nmov rdx, 0x00459270 ; 首先将函数b地址放到rdx寄存器 jmp rdx ; 然后直接跳转过去执行  这里有这么两个办法：\n r2 -w写模式下，直接用wa+汇编指令替换函数a的指令； r2附带工具生成汇编对应的16进制数据，用wx+16进制数来覆写指令； 其实你也可以用一些在线的汇编工具生成，再用其他16进制工具打开可执行程序，然后修改替换。  r2: wa+汇编指令 # 通过wa来直接写入汇编指令，这个比较省事，不用单独运行rasm2去得到汇编后的指令16禁止数据再去覆写。\n[root@centos test]# r2 -w ./mainx -- The '?' command can be used to evaluate math expressions. Like this: '? (0x34+22)*4' [0x00454330]\u0026gt; s sym.main.b [0x00459270]\u0026gt; af [0x00459270]\u0026gt; s sym.main.a [0x00459250]\u0026gt; af [0x00459250]\u0026gt; pdf ┌ 19: sym.main.a (int64_t arg_8h); │ ; arg int64_t arg_8h @ rsp+0x8 │ 0x00459250 48c744240800. mov qword [arg_8h], 0 │ 0x00459259 48c744240801. mov qword [arg_8h], 1 └ 0x00459262 c3 ret [0x00459250]\u0026gt; wa mov rdx, 0x00459270 ;; 写mov指令，提示成功，写入了7个字节 Written 7 byte(s) (mov rdx, 0x00459270) = wx 48c7c270924500 [0x00459250]\u0026gt; wa jmp rdx @0x00459257 ;; 写jmp指令，提示成功，写入了2个字节 Written 2 byte(s) (jmp rdx) = wx ffe2 [0x00459250]\u0026gt; px/20xb 0x00459250 ;; 校验一下写入的9个字节 [0x00459250]\u0026gt; wci ;; 保存退出 [0x00459250]\u0026gt; q  注意一下，就是我们写入指令之后，直接运行命令pdf（print disassembly function）看到的指令有些是没正常显示的，不过我们px/校验数据是成功写入的就ok。\n运行下patch之后的程序：\n$ ./mainx 2 2  完全符合预期。\nr2: wx+hex # 那我们得看下这些汇编指令对应的机器指令是啥样的，radare2也提供了工具来处理。\n汇编、机器指令都是平台相关的，汇编前先看下平台相关信息，好，我的是Intel x86_64, 64位。\n$ uname -a Linux centos 4.19.76-linuxkit #1 SMP Tue May 26 11:42:35 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux $ $ rasm2 -a x86 -b 64 'mov rdx, 0x00459270' 48c7c270924500 $ rasm2 -a x86 -b 64 'jump rdx' ffe2  生成机器指令后，在r2会话窗口中执行：\n[0x00459250] wx 48c7c270924500ffe2 [0x00459250]\u0026gt; px/9xb - offset - 0 1 2 3 4 5 6 7 8 9 A B C D E F 0123456789ABCDEF 0x00459250 48c7 c270 9245 00ff e2 H..p.E... ;; 写入成功了 [0x00459250]\u0026gt; wci ;; 保存退出 [0x00459250]\u0026gt; q  运行下patch之后的程序：\n$ ./mainx 2 2  上面只是为了测试下，行还是不行，肯定是行啊，我只是想炫耀下radare2有多强大好玩而已。\nMonkey Patching # 上面兜了个圈子，给大家演示了下radare2怎么使用，接下来我们运行时patch下指令测试下。还是mainx.go这个程序。\npackage main func a() int { return 1 } func b() int { return 2 } func main() { println(a(), b()) }  前面radare2都是运行在修改模式下，这次运行再调试模式下radare2 -d。\n执行如下操作：\n$ r2 -d ./mainx Process with PID 1243 started... ;; 显示已经attach到tracee = attach 1243 1243 bin.baddr 0x00400000 Using 0x400000 asm.bits 64 -- Use 'e' and 't' in Visual mode to edit configuration and track flags. [0x00454330]\u0026gt; s sym.main.b ;; 继续看下b函数地址 [0x00459270]\u0026gt; af [0x00459270]\u0026gt; s sym.main.a ;; 继续看下a函数地址 [0x00459250]\u0026gt; af [0x00459250]\u0026gt; pdf ;; 看下a函数包含的指令 ┌ 9: sym.main.a (); │ bp: 0 (vars 0, args 0) │ sp: 0 (vars 0, args 0) │ rg: 0 (vars 0, args 0) │ 0x00459250 48c7c2709245. mov rdx, sym.main.b ; 0x459270 ; \u0026quot;H\\xc7D$\\b\u0026quot; └ 0x00459257 ffe2 jmp rdx [0x00459250]\u0026gt; wx 48c7c270924500ffe2 ;; 跟前面讲的一样，指令patch，调到b去 [0x00459250]\u0026gt; [0x00459250]\u0026gt; s sym.main.main ;; 定位到main函数 [0x00459290]\u0026gt; af ;; 分析main函数 [0x00459290]\u0026gt; pdf ;; 看下main函数指令集调用关系 ; CODE XREF from sym.main.main @ 0x459308 ┌ 122: sym.main.main (); │ ; var int64_t var_18h @ rsp+0x8 │ ; var int64_t var_10h @ rsp+0x10 │ ; var int64_t var_8h @ rsp+0x18 │ ┌─\u0026gt; 0x00459290 64488b0c25f8. mov rcx, qword fs:[0xfffffffffffffff8] │ ╎ 0x00459299 483b6110 cmp rsp, qword [rcx + 0x10] │ ┌──\u0026lt; 0x0045929d 7664 jbe 0x459303 │ │╎ 0x0045929f 4883ec20 sub rsp, 0x20 │ │╎ 0x004592a3 48896c2418 mov qword [var_8h], rbp │ │╎ 0x004592a8 488d6c2418 lea rbp, qword [var_8h] │ │╎ 0x004592ad e89effffff call sym.main.a │ │╎ 0x004592b2 488b0424 mov rax, qword [rsp] │ │╎ 0x004592b6 4889442410 mov qword [var_10h], rax │ │╎ 0x004592bb e8b0ffffff call sym.main.b │ │╎ 0x004592c0 488b0424 mov rax, qword [rsp] │ │╎ 0x004592c4 4889442408 mov qword [var_18h], rax │ │╎ 0x004592c9 e80203fdff call sym.runtime.printlock │ │╎ 0x004592ce 488b442410 mov rax, qword [var_10h] │ │╎ 0x004592d3 48890424 mov qword [rsp], rax │ │╎ 0x004592d7 e8740afdff call sym.runtime.printint │ │╎ 0x004592dc e82f05fdff call sym.runtime.printsp │ │╎ 0x004592e1 488b442408 mov rax, qword [var_18h] │ │╎ 0x004592e6 48890424 mov qword [rsp], rax │ │╎ 0x004592ea e8610afdff call sym.runtime.printint │ │╎ 0x004592ef e86c05fdff call sym.runtime.printnl │ │╎ 0x004592f4 e85703fdff call sym.runtime.printunlock │ │╎ 0x004592f9 488b6c2418 mov rbp, qword [var_8h] │ │╎ 0x004592fe 4883c420 add rsp, 0x20 │ │╎ 0x00459302 c3 ret │ └──\u0026gt; 0x00459303 e8f879ffff call sym.runtime.morestack_noctxt └ └─\u0026lt; 0x00459308 eb86 jmp sym.main.main [0x00459290]\u0026gt; dc ;; 我们这里没有什么加断点的必要了，直接continue (1243) Created thread 1244 (1243) Created thread 1245 PTRACE_CONT: No such process (1243) Created thread 1246 PTRACE_CONT: No such process [+] SIGNAL 19 errno=0 addr=0x00000000 code=0 ret=0 [+] signal 19 aka SIGSTOP received 0 [0x004549f3]\u0026gt; dc ;; 再来一次，continue到tracee结束 2 2 ;; 输出了结果 `2 2`  OK，经过上面相关的演示之后，应该已经了解了我们patch的大致方法及实际效果了，也介绍了radare2的常用操作。\nPut It Together # 现在我们收一下，将前面掌握的技能点综合起来，来实现我们前面遗留的任务：\nfunc assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) return []byte{ // TODO 动态生成跳转到函数funcval f目的地址的指令 // MOV rdx, funcVal // JMP [rdx] } }  那这里就很简单了，就是填充这里的[]byte{}，构造出我们前面radare2 wx命令写入的数据而已。 多次测试下rasm2对jmp指令的编码你可以发现：\n mov操作码编码为48c7 rdx编码为为c2 接下来是要移动的数据funcval地址，这个通过移位运算符搞下就行了，多少个字节呢？看mov操作码知道操作数位宽32bits，所以4个字节  那么 MOV rdx, funcVal 对应的就是:\n[]byte{ 0x48, 0xC7, 0xC2, byte(funcVal \u0026gt;\u0026gt; 0), byte(funcVal \u0026gt;\u0026gt; 8), byte(funcVal \u0026gt;\u0026gt; 16), byte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal  再看下 JMP [rdx]，注意这里和我们前面举的例子不同，前面是对JMP rdx编码的，这两种方式涉及到处理器寻址方式的差异。\n JMP [rdx]，是说rdx中存储的是地址，取出这个地址对应内存单元中的数据作为有效地址； JMP rdx，是说rdx中存储的就是有效地址，前面的例子中我们是直接将func b的地址拿来用的；  这里的assembleJump函数接受的参数是funcVal，拿到的是funcVal的地址，需要再解一次引用，才能拿到func b的有效地址。\n说这么多，应该没有歧义了，使用rasm2继续对JMP [rdx]编码得到ff22:\n$ rasm2 -a x86 -b 64 'jmp [rdx]' $ ff22  那我们这个函数就可以写完了：\nfunc assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) return []byte{ // TODO 动态生成跳转到函数funcval f目的地址的指令 0x48, 0xC7, 0xC2, byte(funcVal \u0026gt;\u0026gt; 0), byte(funcVal \u0026gt;\u0026gt; 8), byte(funcVal \u0026gt;\u0026gt; 16), byte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal 0xff, 0x22, // JMP [rdx] } }  那最后的示例就是这样的，你可以直接运行下面的程序来测试下，期望的结果是输出2，而不是1。\n如果你测试的时候输出了1，说明你可能忽视了一个问题：这里的monkey patching是基于函数地址处的指令patch来实现的。如果编译过程中，不巧期望被patch的函数被go inline处理掉了，那这里的patch铁定就失效了。\n所以测试的时候记得禁用内联，比如go run -gcflags=\u0026quot;all=-N -l\u0026quot; jump.go。\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;syscall\u0026quot; \u0026quot;unsafe\u0026quot; ) func a() int { return 1 } func b() int { return 2 } func getPage(p uintptr) []byte { return (*(*[0xFFFFFF]byte)(unsafe.Pointer(p \u0026amp; ^uintptr(syscall.Getpagesize()-1))))[:syscall.Getpagesize()] } func rawMemoryAccess(b uintptr) []byte { return (*(*[0xFF]byte)(unsafe.Pointer(b)))[:] } func assembleJump(f func() int) []byte { funcVal := *(*uintptr)(unsafe.Pointer(\u0026amp;f)) fmt.Printf(\u0026quot;target address: %#x\\n\u0026quot;, funcVal) return []byte{ 0x48, 0xC7, 0xC2, byte(funcVal \u0026gt;\u0026gt; 0), byte(funcVal \u0026gt;\u0026gt; 8), byte(funcVal \u0026gt;\u0026gt; 16), byte(funcVal \u0026gt;\u0026gt; 24), // MOV rdx, funcVal 0xFF, 0x22, // JMP rdx } } func replace(orig, replacement func() int) { bytes := assembleJump(replacement) functionLocation := **(**uintptr)(unsafe.Pointer(\u0026amp;orig)) fmt.Printf(\u0026quot;orig address: %#x\\n\u0026quot;, functionLocation) window := rawMemoryAccess(functionLocation) page := getPage(functionLocation) syscall.Mprotect(page, syscall.PROT_READ|syscall.PROT_WRITE|syscall.PROT_EXEC) copy(window, bytes) fmt.Printf(\u0026quot;bytes: %v\\n\u0026quot;, bytes) fmt.Printf(\u0026quot;wind: %v\\n\u0026quot;, window[0:len(bytes)]) } func main() { fmt.Printf(\u0026quot;a address: %p\\n\u0026quot;, a) fmt.Printf(\u0026quot;b address: %p\\n\u0026quot;, b) replace(a, b) print(a()) }  运行测试下：\n$ go run -gcflags=\u0026quot;all=-N -l\u0026quot; jump.gomonkey 2  gomonkey写mock测试，对函数的处理大致就是这个这么实现的，这里就不继续说gomonkey的具体实现细节了。\n总结 # 本文所提内容并非原创，在了解gomonkey的过程中看到了《monkey-patching-in-go》这篇文章，结合自己的一些理解重新解释下背后的原理。\n其实本没有必要解释这么多，我可以一句话总结完，”go funcval + 指令patch“。但是呢，”纸上得来终觉浅”，没有经过实践检验的“懂”也只是自己骗自己罢了。\n大篇幅介绍了radare2调试器的一些使用，应该有读者会对调试器工作原理、底层实现比较感兴趣，这也是大篇幅介绍的一点小小的私心。\n从2018年开始陆续整理调试原理的一些知识，将这些整理的内容放在了github上golang-debugger-book。原理的部分大致已经介绍完了，现在还需要结合一个实现来辅助使内容更加详实一点，这里也会涉及到对go实现细节的一些知识点补充，感兴趣的可以一起来。\n时间精力实在有限，拖得久了，很没有成就感。\n参考文章 # 1.monkey-patching-in-go, https://bou.ke/blog/monkey-patching-in-go/\n2.a-journey-into-radare2, https://www.megabeets.net/a-journey-into-radare-2-part-1/\n3.monkey patching, https://en.wikipedia.org/wiki/Monkey_patch\n4.radare2 book, https://radare.gitbooks.io/radare2book/content/tools/rasm2/assemble.html\n"}),a.add({id:370,href:"/tags/monkey-patching/",title:"monkey-patching",description:"",content:""}),a.add({id:371,href:"/tags/assembly/",title:"assembly",description:"",content:""}),a.add({id:372,href:"/tags/intel/",title:"intel",description:"",content:""}),a.add({id:373,href:"/tags/x64/",title:"x64",description:"",content:""}),a.add({id:374,href:"/blog/2020-08-20-x64%E6%B1%87%E7%BC%96%E5%BC%80%E5%8F%91%E4%BB%8B%E7%BB%8D/",title:"x64汇编开发介绍",description:"最近在工作和学习中发现，其实汇编是非常重要的，即便现在高级语言已经非常方便了，但是了解汇编对于深入理解计算机系统，以及一些高深的知识点是不可或缺的。举几个例子，比如说Linux操作系统有一个系统调用函数叫Fork我们都知道Fork的返回值在子进程中是0，在父进程中是非0，那这个是如何实现的呢？对于不了解汇编的人也很难有能力去阅读Linux操作系统源码，只能道听途说了解到个大概原因。再比如接下来要讲的gomonkey测试框架实现的一些指令patching操作，这些都是与汇编操作分不开的。甚至你想了解下上下文切换开销，你都需要深入了解下指令执行周期等等的问题。\n不懂汇编，不妨碍你开发上层应用，但是对你的深度就是一道坎，你很难跨国这个鸿沟去窥探更底层的一些原理。\n有感而发，今天就回顾下intel官方开发发布的x64汇编知识，做一个简单的回顾，也为后面研究gomonkey指令patching等等做一些准备和铺垫。\n介绍 # 大家使用x86汇编来写一些对性能比较敏感的程序嗯，这个情况已经持续很多年了嗯，但是现在32位机器应逐渐被64位机器取代了，对应的汇编代码也发生了变化。这篇文章主要就是介绍x64汇编的，如果不了解x86汇编也没什么大碍，当然了解的话理解起来会更简单一点。\nx64是一个通用的名字，它表示的是对Intel以及AMD 32位指令集架构的一个64位扩展。AMD首先引入了x64指令集，最初叫x86-64，后面又改成了AMD64。Intel呢，将其支持64位指令集的架构称之为IA-32e，后面又改成了EMT64。这两个版本之间有一点细微的不兼容的地方，但是大部分指令在两个版本上都可以很好的工作，相关的细节可以参考Intel开发手册Intel 64 And IA-32 Architectures Software Developer\u0026rsquo;s Manuals，以及AMD64架构的技术文档。我们将这两个版本的交集部分称之为x64。不要将x64与64位Intel Itanium架构（称之为IA-64）混为一谈。\n这篇文章没有涉及硬件相关的细节，如caches、分支预测，以及其他高级话题。文章最后会给出一些这些领域的参考手册供了解更多。\n汇编语言，往往会用来编写对性能要求比较苛刻的程序或其中的一部分。但是对大部分普通程序员来说，与其让其写汇编，还不如写cc++然后配上一个好的编译器来的实在，后者编译器优化的性能可能比其写出的汇编代码质量更高。汇编语言对于调试代码也是有用的，有时一个编译器可能生成了一些不正确的汇编指令，通过调试器在程序中单步调试可以帮助定位到问题的原因。代码优化器，有时也会犯错。汇编的另外一个用途，你可以用它来研究没有源码的程序。反汇编让你能够改变、修复现有的可执行程序（推荐下几个工具hopper or cutter）。如果你想了解或者调查为什么某种编程语言比较慢，其他的比较快之类的问题，汇编也是你的好帮手。最后吧，掌握汇编知识，对于诊断一些恶意软件，也是必不可少的技能。\n架构 # 当要去学习特定平台的汇编时，首先应该学习的是，该平台的寄存器集合。\n通用架构 # 64位寄存器允许容纳更大的尺寸的数据，或者是地址，所以我们定义的更多的类型，将1个字节byte定义成8bits，将1个字word定义成16bits，将一个双字double word定义成32bits，将一个四字quadword定义成64位，将一个八字double quadword定义成128bits。关于字节序的问题，Intel是小端字节序，意味着低有效位存储在内存的低地址中。\n上图显示了16个64bits的通用目的寄存器，前8个被命名成rax、rbx、rcx、rdx、rbp、rsi、rdi、rsp，这个命名和历史原因有关系，后面8个被命名成了r8~r15。如果前8个自己存器名，将字符r换成e，就变成了对应的地位的32位寄存器，比如rax的低32位是eax。类似地，如果想访问低16位，就直接把前缀去掉，如AX就是访问的rax的低16位，如果低8位呢，那就是AL了，AH就是次低8位（8~15位）。新加的8个寄存器r8~r15可以用类似的方式来访问低位数据，如r8（qword），r8d（lower dword），r8w（lowest word）、r8b（lowest byte MASM风格，intel风格是r8l）。注意没有r8h这种表示法。\n使用REX操作码前缀去访问新添加的这8个通用寄存器的字节时，有一些限制，不能像访问之前的8个通用寄存器一样通过AH、BH、CH、DH来访问，并且一次只能访问一个（如R11B），但是可以使用AL、BL、CL、DL，为啥来，因为它就是强制要求将AH、BH、CH、DH转换成BPL、SPL、DIL、SIL来使用。\n64位指令指针寄存器RIP，指向下一条要执行的指令的低质，并且支持64位平坦内存模型，当前操作系统中的内存地址布局将在后面提及。\n栈指针寄存器RSP，指向当前刚push进栈的元素空间地址，也就是栈顶了，栈从高地址向低地址方向增长。栈用来存储调用例程（函数）的返回值、传递参数，或者用以支持ABI中的调用惯例（如保存调用方现场）。\nRFLAGS寄存器，用来存储一些标识信息，它用来标识一些操作的结果（如是否溢出、运算结果的正负等）或者控制处理器的执行。这在x86 32位寄存器EFLAGS中就已经形成了这些，现在在以前基础上又添加了高32位，用来预留支持扩展，当前是没有使用的。下表列出了最常使用的一些flags。大多数其他flags是用于操作系统级别的任务。\n   Symbol Bit Name Set if\u0026hellip;     CF 0 Carry Operation generated a carry or borrow   PF 2 Parity Last byte has even number of 1\u0026rsquo;s, else 0   AF 4 Adjust Denotes Binary Coded Decimal in-byte carry   ZF 6 Zero Result was 0   SF 7 Sign Most significant bit of result is 1   OF 11 Overflow Overflow on signed operation         DF 10 Direction Direction string instructions operate (increment or decrement)   ID 21 Identification Changeability denotes presence of CPUID instruction    浮点运算单元（FPU，Floating Point Unit）包含了8个寄存器FPR0-FPR7，还有状态寄存器、控制寄存器，以及其他的几个寄存器。FPR0-7这几个寄存器，每个都可以存储下表中列出的数据类型的值。浮点操作遵从IEEE 754标准。注意，大多数c/c++编译器支持32位和64位的float、double数据类型，但是没有支持80位的浮点数据类型，但是汇编是支持的。这8个寄存器和另外8个MMX？寄存器实际上是共享的同一组物理寄存器。",content:"最近在工作和学习中发现，其实汇编是非常重要的，即便现在高级语言已经非常方便了，但是了解汇编对于深入理解计算机系统，以及一些高深的知识点是不可或缺的。举几个例子，比如说Linux操作系统有一个系统调用函数叫Fork我们都知道Fork的返回值在子进程中是0，在父进程中是非0，那这个是如何实现的呢？对于不了解汇编的人也很难有能力去阅读Linux操作系统源码，只能道听途说了解到个大概原因。再比如接下来要讲的gomonkey测试框架实现的一些指令patching操作，这些都是与汇编操作分不开的。甚至你想了解下上下文切换开销，你都需要深入了解下指令执行周期等等的问题。\n不懂汇编，不妨碍你开发上层应用，但是对你的深度就是一道坎，你很难跨国这个鸿沟去窥探更底层的一些原理。\n有感而发，今天就回顾下intel官方开发发布的x64汇编知识，做一个简单的回顾，也为后面研究gomonkey指令patching等等做一些准备和铺垫。\n介绍 # 大家使用x86汇编来写一些对性能比较敏感的程序嗯，这个情况已经持续很多年了嗯，但是现在32位机器应逐渐被64位机器取代了，对应的汇编代码也发生了变化。这篇文章主要就是介绍x64汇编的，如果不了解x86汇编也没什么大碍，当然了解的话理解起来会更简单一点。\nx64是一个通用的名字，它表示的是对Intel以及AMD 32位指令集架构的一个64位扩展。AMD首先引入了x64指令集，最初叫x86-64，后面又改成了AMD64。Intel呢，将其支持64位指令集的架构称之为IA-32e，后面又改成了EMT64。这两个版本之间有一点细微的不兼容的地方，但是大部分指令在两个版本上都可以很好的工作，相关的细节可以参考Intel开发手册Intel 64 And IA-32 Architectures Software Developer\u0026rsquo;s Manuals，以及AMD64架构的技术文档。我们将这两个版本的交集部分称之为x64。不要将x64与64位Intel Itanium架构（称之为IA-64）混为一谈。\n这篇文章没有涉及硬件相关的细节，如caches、分支预测，以及其他高级话题。文章最后会给出一些这些领域的参考手册供了解更多。\n汇编语言，往往会用来编写对性能要求比较苛刻的程序或其中的一部分。但是对大部分普通程序员来说，与其让其写汇编，还不如写cc++然后配上一个好的编译器来的实在，后者编译器优化的性能可能比其写出的汇编代码质量更高。汇编语言对于调试代码也是有用的，有时一个编译器可能生成了一些不正确的汇编指令，通过调试器在程序中单步调试可以帮助定位到问题的原因。代码优化器，有时也会犯错。汇编的另外一个用途，你可以用它来研究没有源码的程序。反汇编让你能够改变、修复现有的可执行程序（推荐下几个工具hopper or cutter）。如果你想了解或者调查为什么某种编程语言比较慢，其他的比较快之类的问题，汇编也是你的好帮手。最后吧，掌握汇编知识，对于诊断一些恶意软件，也是必不可少的技能。\n架构 # 当要去学习特定平台的汇编时，首先应该学习的是，该平台的寄存器集合。\n通用架构 # 64位寄存器允许容纳更大的尺寸的数据，或者是地址，所以我们定义的更多的类型，将1个字节byte定义成8bits，将1个字word定义成16bits，将一个双字double word定义成32bits，将一个四字quadword定义成64位，将一个八字double quadword定义成128bits。关于字节序的问题，Intel是小端字节序，意味着低有效位存储在内存的低地址中。\n上图显示了16个64bits的通用目的寄存器，前8个被命名成rax、rbx、rcx、rdx、rbp、rsi、rdi、rsp，这个命名和历史原因有关系，后面8个被命名成了r8~r15。如果前8个自己存器名，将字符r换成e，就变成了对应的地位的32位寄存器，比如rax的低32位是eax。类似地，如果想访问低16位，就直接把前缀去掉，如AX就是访问的rax的低16位，如果低8位呢，那就是AL了，AH就是次低8位（8~15位）。新加的8个寄存器r8~r15可以用类似的方式来访问低位数据，如r8（qword），r8d（lower dword），r8w（lowest word）、r8b（lowest byte MASM风格，intel风格是r8l）。注意没有r8h这种表示法。\n使用REX操作码前缀去访问新添加的这8个通用寄存器的字节时，有一些限制，不能像访问之前的8个通用寄存器一样通过AH、BH、CH、DH来访问，并且一次只能访问一个（如R11B），但是可以使用AL、BL、CL、DL，为啥来，因为它就是强制要求将AH、BH、CH、DH转换成BPL、SPL、DIL、SIL来使用。\n64位指令指针寄存器RIP，指向下一条要执行的指令的低质，并且支持64位平坦内存模型，当前操作系统中的内存地址布局将在后面提及。\n栈指针寄存器RSP，指向当前刚push进栈的元素空间地址，也就是栈顶了，栈从高地址向低地址方向增长。栈用来存储调用例程（函数）的返回值、传递参数，或者用以支持ABI中的调用惯例（如保存调用方现场）。\nRFLAGS寄存器，用来存储一些标识信息，它用来标识一些操作的结果（如是否溢出、运算结果的正负等）或者控制处理器的执行。这在x86 32位寄存器EFLAGS中就已经形成了这些，现在在以前基础上又添加了高32位，用来预留支持扩展，当前是没有使用的。下表列出了最常使用的一些flags。大多数其他flags是用于操作系统级别的任务。\n   Symbol Bit Name Set if\u0026hellip;     CF 0 Carry Operation generated a carry or borrow   PF 2 Parity Last byte has even number of 1\u0026rsquo;s, else 0   AF 4 Adjust Denotes Binary Coded Decimal in-byte carry   ZF 6 Zero Result was 0   SF 7 Sign Most significant bit of result is 1   OF 11 Overflow Overflow on signed operation         DF 10 Direction Direction string instructions operate (increment or decrement)   ID 21 Identification Changeability denotes presence of CPUID instruction    浮点运算单元（FPU，Floating Point Unit）包含了8个寄存器FPR0-FPR7，还有状态寄存器、控制寄存器，以及其他的几个寄存器。FPR0-7这几个寄存器，每个都可以存储下表中列出的数据类型的值。浮点操作遵从IEEE 754标准。注意，大多数c/c++编译器支持32位和64位的float、double数据类型，但是没有支持80位的浮点数据类型，但是汇编是支持的。这8个寄存器和另外8个MMX？寄存器实际上是共享的同一组物理寄存器。\n   Data Type Length Precision (bits) Decimal digits Precision Decimal Range     Single Precision 32 24 7 1.1810^-38 to 3.4010^38   Double Precision 64 53 15 2.23 10^-308 to 1.7910^308   Extended Precision 80 64 19 3.3710^-4932 to 1.1810^4932    有几个8位指令支持二进制编码的十进制（BCD），浮点寄存器支持的奇特格式还提供了一种80位，17位的BCD类型。\n 不确定是否翻译有误，原文：Binary Coded Decimal (BCD) is supported by a few 8-bit instructions, and an oddball format supported on the floating point registers gives an 80 bit, 17 digit BCD type.\n 这16个128bits的XMM寄存器（比x86多了8个）后面会有更详细介绍。\n还有就是，段寄存器（在x64下大多数没有用）、控制寄存器、内存管理寄存器、调试寄存器、虚拟化寄存器、性能寄存器（跟踪记录各种类型的内部参数，如cache命中、miss，分支预测命中、miss，微码执行，定时等等）。最突出的性能相关的操作码就是RDTSC，它是用来技术处理器时钟周期的，经常通过它来测量一小段代码的执行耗时。通常c库里面提供的函数gettimeofday是比较耗时间的，所以在高频使用的时候会有性能问题，一般在网络框架里面做定时器、时间测量相关的任务，是会通过RDTSC来推送系统时间进而推算耗时的（在我的文章libmill定时器中也有提及，hitzhangjie.gitbook.io/libmill）。\n更多其他细节信息，可以参考全5卷 \u0026ldquo;Intel 64 And IA-32 Architectures Software Developer\u0026rsquo;s Manuals\u0026rdquo;，可以从这里免费下载，http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html。\nSIMD架构 # 单指令多数据（SIMD）指令对多条数据并行执行一条命令，这是汇编例程的常用用法。 MMX和SSE命令（分别使用MMX和XMM寄存器）支持SIMD操作，该操作可并行处理多达八段数据。例如，可以使用MMX在一条指令中将八个字节与另外八个字节相加。\n八个64位MMX寄存器MMX0-MMX7是FPR0-7的别名，这意味着任何将FPR和MMX混合起来操作的代码都必须小心，不要覆盖所需的值。 MMX指令对整数类型进行操作，允许对MMX寄存器中的值并行执行字节，字和双字操作。大多数MMX指令以“P”开头表示“packed”。算术，移位/旋转，比较，例如：PCMPGTB表示“比较packed的的有符号1字节整数是否大于”。\n16个128位XMM寄存器允许每条指令对四个单精度或两个双精度值进行并行运算。一些指令还适用于压缩字节，字，双字和四字整数。这些称为流式SIMD扩展（SSE）的指令具有多种形式：SSE，SSE2，SSE3，SSSE3，SSE4，以及在本文印制之时可能还会更多。英特尔已经宣布了这些扩展，称为英特尔®高级矢量扩展（Intel®AVX），具有新的256位宽数据路径。 SSE指令包含对浮点和整数类型的移动，算术，比较，重排和拆包以及按位运算。指令名称包括诸如PMULHUW和RSQRTPS之类的。最后，SSE引入了一些有关内存预取（出于性能）和内存屏障（出于多线程安全）的指令。\n下表列出了一些命令集，操作的寄存器类型，并行操作的项目数以及项目类型。例如，使用SSE3和128位XMM寄存器，您可以并行处理2个（必须为64位）浮点值，或者并行处理16个（必须为字节大小）整数值。\n为了找到给定芯片支持的技术，有一条CPUID指令返回特定于处理器的信息。\n   Technology Register size/type Item type Items in Parallel     MMX 64 MMX Integer 8, 4, 2, 1   SSE 64 MMX Integer 8,4,2,1   SSE 128 XMM Float 4   SSE2/SSE3/SSSE3\u0026hellip; 64 MMX Integer 2,1   SSE2/SSE3/SSSE3\u0026hellip; 128 XMM Float 2   SSE2/SSE3/SSSE3\u0026hellip; 128 XMM Integer 16,8,4,2,1    工具 # assemblers # 互联网搜索显示了具有x64功能的汇编程序，例如Netwide汇编程序NASM，在NASM基础上重写的YASM，快速的Flat Assembler FASM和传统的Microsoft MASM。甚至还有一个免费的用于x86和x64程序集的IDE，称为WinASM。每个汇编程序对其他汇编程序的宏和语法都有不同的支持，并不是完全兼容的。\n对于以下示例，我使用平台SDK中免费提供的MASM的64位版本ML64.EXE。对于以下示例，请注意，MASM语法的格式为：“指令 目标操作数或地址，源操作数或地址”，有些汇编器中的语法中的源操作、目的操作的顺序是反着的。请参考对应汇编器的语法说明。\nc/c++ compilers # C/C++编译器通常允许使用内联汇编将汇编嵌入代码中，但是Microsoft Visual Studio C/C++为x64代码删除了该汇编，这可能简化了代码优化器的工作。剩下两个选择：使用单独的汇编文件和外部汇编器，或使用头文件“ intrn.h”中的内在函数（请参见Birtolo和MSDN）。其他编译器具有类似的选项。\n使用启发式的理由：\n x64中不支持内联汇编了； 方便使用，你可以使用变量名，来代替对寄存器的手动分配； 启发式相比写汇编而言更容易实现跨平台，编译器会针对不同的平台做对应的启发式优化处理； 配合启发式操作，优化器工作的更好；  例如，Microsoft Visual Studio 2008就有启发式操作，unsigned short _rotr16(unsigned short_rot16 b, unsigned char c)，这个操作将一个16位操作数b中向右rotate c位，并返回结果。使用c来实现的话，可以这么写unsigned short a1 = (b\u0026gt;\u0026gt;c)|(b\u0026lt;\u0026lt;(16-c))，这个汇编完成后大约是15条指令（debug模式下，如果是release模式下的话也差不太多），但是如果使用启发式操作unsigned short a1 = _rotr16(b,c)的话呢，汇编完成后只有4条指令，你说哪个更牛逼呢？！\n指令基础 # 寻址模式 # 在学习之前，得先了解下寻址模式，寻址模式指明了指令访问寄存器或者内存的方式 ，以下是常见的几种寻址模式：\n  立即数寻址（immediate）：操作数就在指令中，如ADD EAX, 14 ;将操作数14与32位寄存器EAX中值相加并存储到EAX中\n  寄存器寻址（register to register）：操作数就在寄存器中，如ADD R8L, AL ;将AL中的值与R8L中的值相加\n  间接寻址（indirect）：就是指令中给出的不是操作数本身，也不是操作数本身所在的地址，而是存储操作数地址的地址，甚至有可能出现多重间址的情况。这样的寻址中允许使用8，16，32位偏移量，或者任何通用目的寄存器来作为基地址或者索引，也允许使用1，2，4，8来对索引进行乘积运算。也可以为其加上段前缀，如FS:, GS:等，但是比较少使用。下面是一个示例，MOV R8W, 1234[8*RAX+RCX] ;将地址8*RAX+RCX+1234处的一个word移动到R8W，这种方式常用来访问结构体数组中的成员，1234往往是数组起始地址，8表示数组元素大小，RAX表示数组索引，RCX表示结构体字段相对结构体起始地址的偏移量。\n这种寻址方式，起始有很多种写法了，下面这些都是等价的。\nMOV ECX, dword ptr table[RBX][RDI] MOV ECX, dword ptr table[RDI][RBX] MOV ECX, dword ptr table[RBX+RDI] MOV ECX, dword ptr [table+RBX+RDI]  这里的dword ptr告诉汇编器如何编码MOV指令。\n  RIP相对寻址：这是x64中新加的寻址模式，它允许访问相对当前指令地址某偏移量出的数据，使得实现位置无关的代码更加容易了。如MOV AL,[RIP] ;RIP指向下一条待执行指令的低质，aka NOP NOP。可是，并不是所有汇编器都支持这种操作，MASM就不支持，但是FASM、YASM支持。MASM隐式地嵌入了RIP相对寻址，如MOV EAX, TABLE ;使用RIP相对寻址来获取表地址。\n  其他比较特殊的寻址：有些操作码使用寄存器的方式比较不一样，例如，有符号整数除操作IDIV，128位操作数RDX:RAX除以一个64位的操作数，会将商存储到RAX中，将余数存储到RDX中。\n  指令集 # 下表列出了一些比较常见的指令，其中*表示改指令有多个操作码，*表示后缀的意思：\n   Opcode Meaning Opcode Meaning     MOV Move to/from/between memory and registers AND/OR/XOR/NOT Bitwise operations   CMOV* Various conditional moves SHR/SAR Shift right logical/arithmetic   XCHG Exchange SHL/SAL Shift left logical/arithmetic   BSWAP Byte swap ROR/ROL Rotate right/left   PUSH/POP Stack usage RCR/RCL Rotate right/left through carry bit   ADD/ADC Add/with carry BT/BTS/BTR Bit test/and set/and reset   SUB/SBC Subtract/with carry JMP Unconditional jump   MUL/IMUL Multiply/unsigned JE/JNE/JC/JNC/J* Jump if equal/not equal/carry/not carry/ many others   DIV/IDIV Divide/unsigned LOOP/LOOPE/LOOPNE Loop with ECX   INC/DEC Increment/Decrement CALL/RETCall subroutine/return   NEG Negate NOP No operation   CMP Compare CPUID CPU information    一个常见的指令就是LOOP指令，它将RCX，ECX或者CX的值减去1，然后如果结果不是0的话，就执行跳转，下面是个示例：\nXOR	EAX, EAX	; zero out eax MOV ECX, 10 ; loop 10 times Label:	; this is a label in assembly INX EAX ; increment eax LOOP Label	; decrement ECX, loop if not 0  不太常见的操作码可实现字符串操作，重复指令前缀，端口I / O指令，标志设置/清除/测试，浮点操作（通常以F开头，并支持move from一个整数、move to一个整数，算术，比较，先验，代数移入/移出）以及控制功能），用于多线程和性能问题的缓存和内存操作码等。英特尔®64和IA-32体系结构软件开发人员手册第2卷分为两部分，详细介绍了每个操作码。\n操作系统 # 从理论上讲，64位系统允许寻址2^64字节的数据，但是当前没有芯片允许访问所有16 EB字节（18,446,744,073,709,551,616字节）。例如，AMD体系结构仅使用地址的低48位，并且48至63位必须是47位的副本，否则处理器会引发异常。因此，地址为0到00007FFFFFFFFFFF，从FFFF800000000000到FFFFFFFFFFFFFFFF，总共有256 TB（281,474,976,710,656字节）的可用虚拟地址空间。另一个缺点是，要寻址所有64位内存，需要更多的页表供OS存储，需要使用宝贵的内存。请注意，这些是虚拟地址，而不是物理地址。\n结果，许多操作系统使用此空间的上半部分，从顶部开始，然后向下扩展；而用户程序则使用下半部分，从底部开始，然后向上扩展。当前的Windows *版本使用44位寻址（16 TB = 17,592,186,044,416字节）。结果地址如下图所示。由于地址是由OS分配的，因此结果地址对用户程序而言不太重要，但是用户地址和内核地址之间的区别对于调试很有用。\n最后一个与OS相关的问题与多线程编程有关，但是此主题太大，无法在此处讨论。唯一要提到的是，有内存屏障操作码可帮助保护共享资源不受破坏。\n调用约定 # 每种架构都有自己的例程（函数）调用的一些约束，操作系统与对应架构的CPU打交道都必须要考虑如何传递对应的参数、如何获取返回值的问题，这里的具体到某个平台的约束，就称为调用约定。\n常见的x64调用约定是用于C样式函数调用的Microsoft 64调用约定（请参阅MSDN，Chen和Pietrek）。在Linux下，也将其称为应用程序二进制接口（ABI）。\n请注意，此处涉及的调用约定与x64 Linux系统上使用的约定不同：对于Microsoft x64调用约定，附加的寄存器空间使fastcall成为唯一的调用约定（在x86下有很多：stdcall，thiscall，fastcall，cdecl等）。与C / C ++样式函数接口的规则：\n RCX, RDX, R8, R9 are used for integer and pointer arguments in that order left to right. XMM0, 1, 2, and 3 are used for floating point arguments. Additional arguments are pushed on the stack left to right. Parameters less than 64 bits long are not zero extended; the high bits contain garbage. It is the caller\u0026rsquo;s responsibility to allocate 32 bytes of \u0026ldquo;shadow space\u0026rdquo; (for storing RCX, RDX, R8, and R9 if needed) before calling the function. It is the caller\u0026rsquo;s responsibility to clean the stack after the call. Integer return values (similar to x86) are returned in RAX if 64 bits or less. Floating point return values are returned in XMM0. Larger return values (structs) have space allocated on the stack by the caller, and RCX then contains a pointer to the return space when the callee is called. Register usage for integer parameters is then pushed one to the right. RAX returns this address to the caller. The stack is 16-byte aligned. The \u0026ldquo;call\u0026rdquo; instruction pushes an 8-byte return value, so the all non-leaf functions must adjust the stack by a value of the form 16n+8 when allocating stack space. Registers RAX, RCX, RDX, R8, R9, R10, and R11 are considered volatile and must be considered destroyed on function calls. RBX, RBP, RDI, RSI, R12, R14, R14, and R15 must be saved in any function using them. Note there is no calling convention for the floating point (and thus MMX) registers. Further details (varargs, exception handling, stack unwinding) are at Microsoft\u0026rsquo;s site.  我们再看下Linux man手册，这里整理了两张调用约定相关的表: https://man7.org/linux/man-pages/man2/syscall.2.html，读后可以加深我们对调用约定 or ABI的认识。\n ## 示例 ### MessageBox 前面讲这么多，现在用上面讲过的内容来写一个demo展示下x64汇编的使用，第一个demo是一个x64独立可运行的程序，运行之后会弹出一个Windows MessageBox。 ```asm ; Sample x64 Assembly Program ; Chris Lomont 2009 www.lomont.org extrn ExitProcess: PROC ; external functions in system libraries extrn MessageBoxA: PROC .data caption db '64-bit hello!', 0 message db 'Hello World!', 0 .code Start PROC sub rsp,28h ; shadow space, aligns stack mov rcx, 0 ; hWnd = HWND_DESKTOP lea rdx, message ; LPCSTR lpText lea r8, caption ; LPCSTR lpCaption mov r9d, 0 ; uType = MB_OK call MessageBoxA ; call MessageBox API function mov ecx, eax ; uExitCode = MessageBox(...) call ExitProcess Start ENDP End  将上述汇编程序保存为hello.asm，然后使用ML64进行编译，在Microsoft Windows x64 SDK中有这个程序的，这么编译：\nml64 hello.asm /link /subsystem:windows /defaultlib:kernel32.lib /defaultlib:user32.lib /entry:Start  执行完成后会构建出一个可执行程序（已经链接好库函数、启动代码了），运行这个程序hello.exe，就会看到弹出一个消息窗口。\n# 第二个示例，是在Visual Studio 2008这个IDE中，在C/C++文件中引用一个x64汇编文件中的代码，还记得Visual Studio后续删除了对支持内联汇编的支持吧。好。\n Create a new empty C++ console project. Create a function you\u0026rsquo;d like to port to assembly, and call it from main. To change the default 32-bit build, select Build/Configuration Manager. Under Active Platform, select New\u0026hellip; Under Platform, select x64. If it does not appear figure out how to add the 64-bit SDK tools and repeat. Compile and step into the code. Look under Debug/Windows/Disassembly to see the resulting code and interface needed for your assembly function. Create an assembly file, and add it to the project. It defaults to a 32 bit assembler which is fine. Open the assembly file properties, select all configurations, and edit the custom build step. Put command line ml64.exe /DWIN_X64 /Zi /c /Cp /Fl /Fo $(IntDir)\\$(InputName).obj $(InputName).asm j:w    ok，下面开始，我们先写一个c++文件，如下，main里面会调用两个函数CombineC、CombineA先后打印出计算的结果，实际上我们准备让CombineA和CombineC实现完全一致的逻辑，区别就是CombineA是在外部的汇编文件中实现的。\n// C++ code to demonstrate x64 assembly file linking #include \u0026lt;iostream\u0026gt; using namespace std; double CombineC(int a, int b, int c, int d, int e, double f) { return (a+b+c+d+e)/(f+1.5); } // NOTE: 这里必须加上extern \u0026quot;C\u0026quot;来阻止C++ name mangling，否则连接的时候会出现符号解析错误 extern \u0026quot;C\u0026quot; double CombineA(int a, int b, int c, int d, int e, double f); int main(void) { cout \u0026lt;\u0026lt; \u0026quot;CombineC: \u0026quot; \u0026lt;\u0026lt; CombineC(1,2,3,4, 5, 6.1) \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026quot;CombineA: \u0026quot; \u0026lt;\u0026lt; CombineA(1,2,3,4, 5, 6.1) \u0026lt;\u0026lt; endl; return 0; }  好的，下面继续写汇编文件：\nfile: CombineA.asm\n.code PUBLIC CombineA CombineA PROC ADD ECX, DWORD PTR [RSP+28H] ; add overflow parameter to first parameter ADD ECX, R9D ; add other three register parameters ADD ECX, R8D ; ADD ECX, EDX ; MOVD XMM0, ECX ; move doubleword ECX into XMM0 CVTDQ2PD XMM0, XMM0 ; convert doubleword to floating point MOVSD XMM1, realVal ; load 1.5 ADDSD XMM1, MMWORD PTR [RSP+30H] ; add parameter DIVSD XMM0, XMM1 ; do division, answer in xmm0 RET ; return CombineA ENDP End  编译并运行上述程序，会发现输出了两次1.97368，第一次是CombineC的运算结果，第二次就是汇编实现的CombineA的运算结果\n总结 # 这是对x64汇编编程的必要的简要介绍。下一步是浏览《英特尔®64和IA-32架构软件开发人员手册》。第1卷包含体系结构的详细信息，如果您知道汇编的话，这是一个很好的开始。其他地方是汇编书籍或在线汇编教程。为了了解代码的执行方式，指导您在调试器中逐步执行代码，查看反汇编，直到您可以阅读汇编代码以及您喜欢的语言为止，这对您很有帮助。对于C / C ++编译器，调试版本比发行版本更容易阅读，因此请确保从此处开始。最后，阅读masm32.com上的论坛以获取大量材料。\n参考内容 #  原文地址: https://software.intel.com/content/www/us/en/develop/articles/introduction-to-x64-assembly.html NASM: http://www.nasm.us/ YASM: http://www.tortall.net/projects/yasm/ Flat Assembler (FASM): http://www.flatassembler.net/ \u0026ldquo;Intel® 64 and IA-32 Architectures Software Developer\u0026rsquo;s Manuals,\u0026rdquo; available online at http://www.intel.com/content/www/us/en/processors/architectures-software-developer-manuals.html \u0026ldquo;Compiler Intrinsics\u0026rdquo;, available online at http://msdn.microsoft.com/en-us/library/26td21ds.aspx Matt Pietrek, \u0026ldquo;Everything You Need To Know To Start Programming 64-Bit Windows Systems\u0026rdquo;, available online at http://msdn.microsoft.com/en-us/magazine/cc300794.aspx, 2009. Intel® 64 and IA-32 Architectures Software Developer Manuals  "}),a.add({id:375,href:"/tags/goconvey/",title:"goconvey",description:"",content:""}),a.add({id:376,href:"/tags/gomonkey/",title:"gomonkey",description:"",content:""}),a.add({id:377,href:"/tags/gostub/",title:"gostub",description:"",content:""}),a.add({id:378,href:"/tags/gotest/",title:"gotest",description:"",content:""}),a.add({id:379,href:"/tags/test/",title:"test",description:"",content:""}),a.add({id:380,href:"/blog/2020-08-19-go%E5%BC%80%E5%8F%91%E5%A6%82%E4%BD%95%E5%81%9A%E6%B5%8B%E8%AF%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6/",title:"选择合适的测试框架",description:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。这篇主要总结下常见的测试框架的优缺点。",content:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。这篇主要总结下常见的测试框架的优缺点。\n如何做好测试，是一门系统性的方法学，而不只是一些零零散散的经验。根据测试目的的不同，对测试方法可以作如下分类：\n 稳定性测试 压力测试 回归测试 冒烟测试 性能测试 功能测试 安全测试 可用性测试 \u0026hellip;  这么多的测试方法，最初我还是在填写一项IntelliJ IDEA发起的问卷调查时了解到的，后面在研发过程中也渐渐加深了对这些测试方法的认识。这里面的每一项测试，我认为开发都是应该去了解的。\n很多测试方法是通用的，和具体语言无关，这篇文章只重点关注go开发如何做单元测试。这是每位开发首先应该掌握起来的，它是其他测试得以顺利展开的基础。\n开发在编码阶段，应该在本地完成单测相关的工作，保证测试用例通过，在自动化构建阶段应该有能力执行一些跑单测、BVT测试的任务，通过后才允许提交给测试团队。当然现在EPC实行起来之后，大部分团队都是这么执行的了。\n研发效能要求提升代码库的测试覆盖率，要提高测试的价值，我们得先学些下掌握比较好的测试的方法。\n参考了下go测试的一些实践，业务中肯定会遇到如下这些情况，或多或少：\n 新老服务都有比较多的外部依赖，比如网络调用、读db等 存量服务维护、开发，有些不适合大范围重构的 测试不要侵入业务代码，不能为了测试写太多不相干的东西  go单测中使用的比较多的，大致有如下这些选择， gomock+gostub+gomonkey+goconvey，现在go用的比较多的就是这几个，我比较推荐gomock、gomonkey，看情况，灵活组合使用吧，先总结下这几个的使用方式、优缺点。\n gomock是基于interface的，mockgen生成interface对应的mock桩代码，然后再去写mock代码。 如果前期没这些interface设计的话，也不方便测试。有的话，看起来也不是特别方便。 gostub支持对变量、方法、过程进行mock，但是用上它，存量代码的话就要做些调整，对代码有侵入， 因为它是基于变量去作mock，比如func Hello(\u0026hellip;)要改成var Hello=func(\u0026hellip;)才能用 gomonkey也支持对变量、方法、过程进行mock，我现在感觉这个比较好用，简单，对代码无侵入， 和gostub实现原理不太一样，比如函数，它通过汇编调整跳转地址，这么着对内联函数就支持不到了，就得-gcflags=\u0026ldquo;all=-l\u0026quot;禁用内联 goconvey主要是用来更好地管理测试用例，可以根据情况用或者不用  这里有几篇文章，感兴趣的可以先看下：\n 组合灵活使用，gomock+gostub+gomonkey+goconvey：https://www.jianshu.com/p/2f675d5e334e gomonkey实现原理：https://bouk.co/blog/monkey-patching-in-go/  在深度使用上述几个测试框架之后，个人感觉gomonkey+goconvery组合是比较合适的，goconvey也可以考虑用go testing框架t.Run代替来维护子测试。\n很多同学对开发阶段写单测，多少还是有些抵触的，常见的理由大多是没时间写单测。我的理解是，这里有个因果倒置的问题，写单测的目的并不是为了写而写，写单侧的目的是为了验证你的逻辑或者测试先行驱动逻辑开发，甚至还会为后续的修改保驾护航。\n在开发阶段写单测，客观上会花些时间，但是也会节省频繁提交构建、部署、测试的时间，开发阶段在上述操作中频繁切换的次数会大幅减少。\n我的体验是这样的，仅供参考。\n"}),a.add({id:381,href:"/blog/2020-08-19-go%E5%BC%80%E5%8F%91%E5%A6%82%E4%BD%95%E5%81%9A%E6%B5%8B%E8%AF%95%E8%A1%A8%E9%A9%B1%E5%8A%A8%E6%B5%8B%E8%AF%95/",title:"go开发如何做测试：表驱动测试",description:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。本文转自Dave Cheney的表驱动测试一文，这篇文章写得挺好的。",content:"开发除了编写代码，也应该关注如何保证代码的可测试性，以及维护有效的测试用例。最近团队对单测要求不断提高，也将之前收集、积累的一点测试相关的内容记录分享下。本文转自Dave Cheney的表驱动测试一文，这篇文章写得挺好的。\nPrefer table driven tests # I’m a big fan of testing, specifically unit testing and TDD (done correctly, of course). A practice that has grown around Go projects is the idea of a table driven test. This post explores the how and why of writing a table driven test.\nLet’s say we have a function that splits strings:\n// Split slices s into all substrings separated by sep and // returns a slice of the substrings between those separators. func Split(s, sep string) []string { var result []string i := strings.Index(s, sep) for i \u0026gt; -1 { result = append(result, s[:i]) s = s[i+len(sep):] i = strings.Index(s, sep) } return append(result, s) }  In Go, unit tests are just regular Go functions (with a few rules) so we write a unit test for this function starting with a file in the same directory, with the same package name, strings.\npackage split import ( \u0026quot;reflect\u0026quot; \u0026quot;testing\u0026quot; ) func TestSplit(t *testing.T) { got := Split(\u0026quot;a/b/c\u0026quot;, \u0026quot;/\u0026quot;) want := []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;} if !reflect.DeepEqual(want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, want, got) } }  Tests are just regular Go functions with a few rules:\n The name of the test function must start with Test. The test function must take one argument of type *testing.T. A *testing.T is a type injected by the testing package itself, to provide ways to print, skip, and fail the test.  In our test we call Split with some inputs, then compare it to the result we expected.\nCode coverage # The next question is, what is the coverage of this package? Luckily the go tool has a built in branch coverage. We can invoke it like this:\n% go test -coverprofile=c.out PASS coverage: 100.0% of statements ok split 0.010s  Which tells us we have 100% branch coverage, which isn’t really surprising, there’s only one branch in this code.\nIf we want to dig in to the coverage report the go tool has several options to print the coverage report. We can use go tool cover -func to break down the coverage per function:\n% go tool cover -func=c.out split/split.go:8: Split 100.0% total: (statements) 100.0%  Which isn’t that exciting as we only have one function in this package, but I’m sure you’ll find more exciting packages to test.\nSpray some .bashrc on that # This pair of commands is so useful for me I have a shell alias which runs the test coverage and the report in one command:\ncover () { local t=$(mktemp -t cover) go test $COVERFLAGS -coverprofile=$t $@ \\ \u0026amp;\u0026amp; go tool cover -func=$t \\ \u0026amp;\u0026amp; unlink $t }  Going beyond 100% coverage # So, we wrote one test case, got 100% coverage, but this isn’t really the end of the story. We have good branch coverage but we probably need to test some of the boundary conditions. For example, what happens if we try to split it on comma?\nfunc TestSplitWrongSep(t *testing.T) { got := Split(\u0026quot;a/b/c\u0026quot;, \u0026quot;,\u0026quot;) want := []string{\u0026quot;a/b/c\u0026quot;} if !reflect.DeepEqual(want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, want, got) } }  Or, what happens if there are no separators in the source string?\nfunc TestSplitNoSep(t *testing.T) { got := Split(\u0026quot;abc\u0026quot;, \u0026quot;/\u0026quot;) want := []string{\u0026quot;abc\u0026quot;} if !reflect.DeepEqual(want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, want, got) } }  We’re starting build a set of test cases that exercise boundary conditions. This is good.\nIntroducing table driven tests # However the there is a lot of duplication in our tests. For each test case only the input, the expected output, and name of the test case change. Everything else is boilerplate. What we’d like to to set up all the inputs and expected outputs and feel them to a single test harness. This is a great time to introduce table driven testing.\nfunc TestSplit(t *testing.T) { type test struct { input string sep string want []string } tests := []test{ {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, } for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, tc.want, got) } } }  We declare a structure to hold our test inputs and expected outputs. This is our table. The tests structure is usually a local declaration because we want to reuse this name for other tests in this package.\nIn fact, we don’t even need to give the type a name, we can use an anonymous struct literal to reduce the boilerplate like this:\nfunc TestSplit(t *testing.T) { tests := []struct { input string sep string want []string }{ {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, } for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, tc.want, got) } } }  Now, adding a new test is a straight forward matter; simply add another line the tests structure. For example, what will happen if our input string has a trailing separator?\n{input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, // trailing sep  But, when we run go test, we get\n% go test --- FAIL: TestSplit (0.00s) split_test.go:24: expected: [a b c], got: [a b c ]  Putting aside the test failure, there are a few problems to talk about.\nThe first is by rewriting each test from a function to a row in a table we’ve lost the name of the failing test. We added a comment in the test file to call out this case, but we don’t have access to that comment in the go test output.\nThere are a few ways to resolve this. You’ll see a mix of styles in use in Go code bases because the table testing idiom is evolving as people continue to experiment with the form.\nEnumerating test cases # As tests are stored in a slice we can print out the index of the test case in the failure message:\nfunc TestSplit(t *testing.T) { tests := []struct { input string sep . string want []string }{ {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for i, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;test %d: expected: %v, got: %v\u0026quot;, i+1, tc.want, got) } } }  Now when we run go test we get this\n% go test --- FAIL: TestSplit (0.00s) split_test.go:24: test 4: expected: [a b c], got: [a b c ]  Which is a little better. Now we know that the fourth test is failing, although we have to do a little bit of fudging because slice indexing—and range iteration—is zero based. This requires consistency across your test cases; if some use zero base reporting and others use one based, it’s going to be confusing. And, if the list of test cases is long, it could be difficult to count braces to figure out exactly which fixture constitutes test case number four.\nGive your test cases names # Another common pattern is to include a name field in the test fixture.\nfunc TestSplit(t *testing.T) { tests := []struct { name string input string sep string want []string }{ {name: \u0026quot;simple\u0026quot;, input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, {name: \u0026quot;wrong sep\u0026quot;, input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, {name: \u0026quot;no sep\u0026quot;, input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, {name: \u0026quot;trailing sep\u0026quot;, input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for _, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;%s: expected: %v, got: %v\u0026quot;, tc.name, tc.want, got) } } }  Now when the test fails we have a descriptive name for what the test was doing. We no longer have to try to figure it out from the output—also, now have a string we can search on.\n% go test --- FAIL: TestSplit (0.00s) split_test.go:25: trailing sep: expected: [a b c], got: [a b c ]  We can dry this up even more using a map literal syntax:\nfunc TestSplit(t *testing.T) { tests := map[string]struct { input string sep string want []string }{ \u0026quot;simple\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, \u0026quot;wrong sep\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, \u0026quot;no sep\u0026quot;: {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, \u0026quot;trailing sep\u0026quot;: {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for name, tc := range tests { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;%s: expected: %v, got: %v\u0026quot;, name, tc.want, got) } } }  Using a map literal syntax we define our test cases not as a slice of structs, but as map of test names to test fixtures. There’s also a side benefit of using a map that is going to potentially improve the utility of our tests.\nMap iteration order is undefined 1 This means each time we run go test, our tests are going to be potentially run in a different order.\nThis is super useful for spotting conditions where test pass when run in statement order, but not otherwise. If you find that happens you probably have some global state that is being mutated by one test with subsequent tests depending on that modification.\nIntroducing sub tests # Before we fix the failing test there are a few other issues to address in our table driven test harness.\nThe first is we’re calling t.Fatalf when one of the test cases fails. This means after the first failing test case we stop testing the other cases. Because test cases are run in an undefined order, if there is a test failure, it would be nice to know if it was the only failure or just the first.\nThe testing package would do this for us if we go to the effort to write out each test case as its own function, but that’s quite verbose. The good news is since Go 1.7 a new feature was added that lets us do this easily for table driven tests. They’re called sub tests.\nfunc TestSplit(t *testing.T) { tests := map[string]struct { input string sep string want []string }{ \u0026quot;simple\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, \u0026quot;wrong sep\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, \u0026quot;no sep\u0026quot;: {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, \u0026quot;trailing sep\u0026quot;: {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for name, tc := range tests { t.Run(name, func(t *testing.T) { got := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %v, got: %v\u0026quot;, tc.want, got) } }) } }  As each sub test now has a name we get that name automatically printed out in any test runs.\n% go test --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: [a b c], got: [a b c ]  Each subtest is its own anonymous function, therefore we can use t.Fatalf, t.Skipf, and all the other testing.Thelpers, while retaining the compactness of a table driven test.\nIndividual sub test cases can be executed directly # Because sub tests have a name, you can run a selection of sub tests by name using the go test -run flag.\n% go test -run=.*/trailing -v === RUN TestSplit === RUN TestSplit/trailing_sep --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: [a b c], got: [a b c ]  Comparing what we got with what we wanted # Now we’re ready to fix the test case. Let’s look at the error.\n--- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: [a b c], got: [a b c ]  Can you spot the problem? Clearly the slices are different, that’s what reflect.DeepEqual is upset about. But spotting the actual difference isn’t easy, you have to spot that extra space after c. This might look simple in this simple example, but it is any thing but when you’re comparing two complicated deeply nested gRPC structures.\nWe can improve the output if we switch to the %#v syntax to view the value as a Go(ish) declaration:\ngot := Split(tc.input, tc.sep) if !reflect.DeepEqual(tc.want, got) { t.Fatalf(\u0026quot;expected: %#v, got: %#v\u0026quot;, tc.want, got) }  Now when we run our test it’s clear that the problem is there is an extra blank element in the slice.\n% go test --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:25: expected: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}, got: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;, \u0026quot;\u0026quot;}  But before we go to fix our test failure I want to talk a little bit more about choosing the right way to present test failures. Our Split function is simple, it takes a primitive string and returns a slice of strings, but what if it worked with structs, or worse, pointers to structs?\nHere is an example where %#v does not work as well:\nfunc main() { type T struct { I int } x := []*T{{1}, {2}, {3}} y := []*T{{1}, {2}, {4}} fmt.Printf(\u0026quot;%v %v\\n\u0026quot;, x, y) fmt.Printf(\u0026quot;%#v %#v\\n\u0026quot;, x, y) }  The first fmt.Printfprints the unhelpful, but expected slice of addresses; [0xc000096000 0xc000096008 0xc000096010] [0xc000096018 0xc000096020 0xc000096028]. However our %#v version doesn’t fare any better, printing a slice of addresses cast to *main.T;[]*main.T{(*main.T)(0xc000096000), (*main.T)(0xc000096008), (*main.T)(0xc000096010)} []*main.T{(*main.T)(0xc000096018), (*main.T)(0xc000096020), (*main.T)(0xc000096028)}\nBecause of the limitations in using any fmt.Printf verb, I want to introduce the go-cmp library from Google.\nThe goal of the cmp library is it is specifically to compare two values. This is similar to reflect.DeepEqual, but it has more capabilities. Using the cmp pacakge you can, of course, write:\nfunc main() { type T struct { I int } x := []*T{{1}, {2}, {3}} y := []*T{{1}, {2}, {4}} fmt.Println(cmp.Equal(x, y)) // false }  But far more useful for us with our test function is the cmp.Diff function which will produce a textual description of what is different between the two values, recursively.\nfunc main() { type T struct { I int } x := []*T{{1}, {2}, {3}} y := []*T{{1}, {2}, {4}} diff := cmp.Diff(x, y) fmt.Printf(diff) }  Which instead produces:\n% go run {[]*main.T}[2].I: -: 3 +: 4  Telling us that at element 2 of the slice of Ts the Ifield was expected to be 3, but was actually 4.\nPutting this all together we have our table driven go-cmp test\nfunc TestSplit(t *testing.T) { tests := map[string]struct { input string sep string want []string }{ \u0026quot;simple\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, \u0026quot;wrong sep\u0026quot;: {input: \u0026quot;a/b/c\u0026quot;, sep: \u0026quot;,\u0026quot;, want: []string{\u0026quot;a/b/c\u0026quot;}}, \u0026quot;no sep\u0026quot;: {input: \u0026quot;abc\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;abc\u0026quot;}}, \u0026quot;trailing sep\u0026quot;: {input: \u0026quot;a/b/c/\u0026quot;, sep: \u0026quot;/\u0026quot;, want: []string{\u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot;}}, } for name, tc := range tests { t.Run(name, func(t *testing.T) { got := Split(tc.input, tc.sep) diff := cmp.Diff(tc.want, got) if diff != \u0026quot;\u0026quot; { t.Fatalf(diff) } }) } }  Running this we get\n% go test --- FAIL: TestSplit (0.00s) --- FAIL: TestSplit/trailing_sep (0.00s) split_test.go:27: {[]string}[?-\u0026gt;3]: -: \u0026lt;non-existent\u0026gt; +: \u0026quot;\u0026quot; FAIL exit status 1 FAIL split 0.006s  Using cmp.Diff our test harness isn’t just telling us that what we got and what we wanted were different. Our test is telling us that the strings are different lengths, the third index in the fixture shouldn’t exist, but the actual output we got an empty string, “”. From here fixing the test failure is straight forward.\n Please don’t email me to argue that map iteration order is random. It’s not.  Related Posts: #  Writing table driven tests in Go Internets of Interest #7: Ian Cooper on Test Driven Development Automatically run your package’s tests with inotifywait How to write benchmarks in Go  This entry was posted in Go, Programming and tagged testing, unit test on May 7, 2019.\n"}),a.add({id:382,href:"/tags/life/",title:"life",description:"",content:""}),a.add({id:383,href:"/blog/2020-08-13-%E9%AA%91%E8%87%AA%E8%A1%8C%E8%BD%A6%E4%B8%80%E7%82%B9%E9%83%BD%E4%B8%8D%E8%88%92%E6%9C%8D%E4%BD%86%E6%98%AF%E5%BE%88%E7%88%BD/",title:"骑自行车一点都不舒服，但是很爽",description:'/* Three image containers (use 25% for four, and 50% for two, etc) */ .column { float: left; width: 50%; padding: 5px; } /* Clear floats after image containers */ .row::after { content: ""; clear: both; display: table; } .fixsize { width: 340px; height: 280px; } .fullsize { width: 680px; }  19年5月底，时长感觉身体疲倦，想锻炼下身体，我想买辆自行车骑着上班。左看右看，还是想买一辆公路赛自行车，太享受那种“破风”的感觉了。左看右看，看上了Giant OCR 5700，买的时候这两自行车已经几近停产了，但是因为它黑白色的涂装，实在是太招人喜欢了，简单又不失美感。几乎没什么犹豫的，就买了一辆，然后几天之后收到车，自己组装完毕，满心欢喜。\n将其立在落地窗边，忍不住这么看那么看，真的是太漂亮了，这里还保留了一张刚开始组装好后的照片。\n其实，这并不是我买的第一辆公路赛自行车，本科读书时，就买了一辆，那时候下课没事、周末的时候，就喜欢骑车去跑个环海路、逛逛这座小城、探探周边的校园，很是惬意。直到现在，我还依稀记得沿着环海路骑行时的场景，那扑面而来带着点腥味的海风，那静谧又干净的大马路，那一望无边的大海，听着海浪拍打着海滩、岩石，吹着海风，就这么走啊走，真想一直这么走下去……\n   读研究生时，又买了一辆，时不时就围着学校、九眼桥、大熊猫繁育基地等周边地方来一圈。成都市区热闹非凡，交通也堵，骑着车从图书馆附近的东门窜出，到九眼桥听听急流的水声，感受下那股潮湿的新鲜，心情就会很舒畅。这辆车骑了没多久，被小偷偷走了，那几年真的是不停地换自行车，买了丢丢了买。随着共享单车的兴起，我想学校周边的小偷们应该没什么可偷的了吧。\n   为什么几番买公路赛自行车呢？看它的造型，每个男同学应该都会喜欢它线条中透出的那股动感吧！另外，和我的性格也有关系，我比较喜欢独行。骑上它，想去哪就去哪，不用担心堵车，不用担心错过公交、地铁，骑行在大街小巷、公园绿道等等，就尽情享受和自然融为一体的那种快感吧。骑车一时爽，一直骑车一直爽，哈哈！\n骑车虽然有时候不太舒服，但是爽还是挺爽的。现在我每天从宝安体育馆附近出发，到腾讯万利达大厦上班，沿途9公里左右，交通状况好的话大概25分钟左右能到。如果是交通不好的情况呢，多等上几个红绿灯，那可能要40分钟左右。我们中心下班有点晚，很多时候都是11点左右才下班，有的时候走到半夜之后的也不少。那么晚了，相比打车，我还是愿意骑车回家。那种被汗水浸透、长时间带来的身体素质的提升、想冲就能冲的体能，让整个人都会很兴奋，心情也好。所以，尽管那么晚了，我还是选择骑车回家。当然，这里是深圳，深圳的夜晚灯火通明……\n附上两个上班、下班路上的视频，哦，对了，配上一副好的蓝牙耳机，会更让你获得骑行的乐趣。我用的是韶音 Aftershokz AS 650，这是一款骨传导耳机，可以让你在路上感知到周边环境的重要声音，比如骑车喇叭声等等，完全入耳的设计在这种场景下有点不安全。最开始有个同学觉得，1200块钱买这个”音质”的耳机有点不值，嗯，我追求的不是音质，我想要的是感觉（追求音质我有BOSE）……PS，Aftershokz AS 650之前丢了一个，现在已经是第二个了。',content:'/* Three image containers (use 25% for four, and 50% for two, etc) */ .column { float: left; width: 50%; padding: 5px; } /* Clear floats after image containers */ .row::after { content: ""; clear: both; display: table; } .fixsize { width: 340px; height: 280px; } .fullsize { width: 680px; }  19年5月底，时长感觉身体疲倦，想锻炼下身体，我想买辆自行车骑着上班。左看右看，还是想买一辆公路赛自行车，太享受那种“破风”的感觉了。左看右看，看上了Giant OCR 5700，买的时候这两自行车已经几近停产了，但是因为它黑白色的涂装，实在是太招人喜欢了，简单又不失美感。几乎没什么犹豫的，就买了一辆，然后几天之后收到车，自己组装完毕，满心欢喜。\n将其立在落地窗边，忍不住这么看那么看，真的是太漂亮了，这里还保留了一张刚开始组装好后的照片。\n其实，这并不是我买的第一辆公路赛自行车，本科读书时，就买了一辆，那时候下课没事、周末的时候，就喜欢骑车去跑个环海路、逛逛这座小城、探探周边的校园，很是惬意。直到现在，我还依稀记得沿着环海路骑行时的场景，那扑面而来带着点腥味的海风，那静谧又干净的大马路，那一望无边的大海，听着海浪拍打着海滩、岩石，吹着海风，就这么走啊走，真想一直这么走下去……\n   读研究生时，又买了一辆，时不时就围着学校、九眼桥、大熊猫繁育基地等周边地方来一圈。成都市区热闹非凡，交通也堵，骑着车从图书馆附近的东门窜出，到九眼桥听听急流的水声，感受下那股潮湿的新鲜，心情就会很舒畅。这辆车骑了没多久，被小偷偷走了，那几年真的是不停地换自行车，买了丢丢了买。随着共享单车的兴起，我想学校周边的小偷们应该没什么可偷的了吧。\n   为什么几番买公路赛自行车呢？看它的造型，每个男同学应该都会喜欢它线条中透出的那股动感吧！另外，和我的性格也有关系，我比较喜欢独行。骑上它，想去哪就去哪，不用担心堵车，不用担心错过公交、地铁，骑行在大街小巷、公园绿道等等，就尽情享受和自然融为一体的那种快感吧。骑车一时爽，一直骑车一直爽，哈哈！\n骑车虽然有时候不太舒服，但是爽还是挺爽的。现在我每天从宝安体育馆附近出发，到腾讯万利达大厦上班，沿途9公里左右，交通状况好的话大概25分钟左右能到。如果是交通不好的情况呢，多等上几个红绿灯，那可能要40分钟左右。我们中心下班有点晚，很多时候都是11点左右才下班，有的时候走到半夜之后的也不少。那么晚了，相比打车，我还是愿意骑车回家。那种被汗水浸透、长时间带来的身体素质的提升、想冲就能冲的体能，让整个人都会很兴奋，心情也好。所以，尽管那么晚了，我还是选择骑车回家。当然，这里是深圳，深圳的夜晚灯火通明……\n附上两个上班、下班路上的视频，哦，对了，配上一副好的蓝牙耳机，会更让你获得骑行的乐趣。我用的是韶音 Aftershokz AS 650，这是一款骨传导耳机，可以让你在路上感知到周边环境的重要声音，比如骑车喇叭声等等，完全入耳的设计在这种场景下有点不安全。最开始有个同学觉得，1200块钱买这个”音质”的耳机有点不值，嗯，我追求的不是音质，我想要的是感觉（追求音质我有BOSE）……PS，Aftershokz AS 650之前丢了一个，现在已经是第二个了。\n附上上下班路上的两个视频，感受一下骑行带来的快感：\n     '}),a.add({id:384,href:"/tags/alfred/",title:"alfred",description:"",content:""}),a.add({id:385,href:"/tags/awgo/",title:"awgo",description:"",content:""}),a.add({id:386,href:"/tags/workflow/",title:"workflow",description:"",content:""}),a.add({id:387,href:"/blog/2020-07-31-%E4%BD%BF%E7%94%A8awgo%E5%BC%80%E5%8F%91alfred.workflow/",title:"使用awgo开发alfred.workflow",description:"Alfred是macOS下非常方便的一款效率工具，它集成了很多功能，包括websearch、snippets、workflow等等，本文讲述的就是如何借助开发workflow来提效。本文以一个简单的datex命令实现时间戳、字符串之间的转换功能为例，介绍下如何开发workflow。",content:" img { width: 680px; }  本文简介 # 该workflow主要是为了对 \u0026ldquo;时间戳\u0026rdquo; \u0026amp;\u0026amp; \u0026ldquo;格式化日期+时间字符串\u0026rdquo; 进行快速转换，方便使用。\n开发人员，经常会涉及到时间相关的转换操作，有个趁手的工具还是很有必要的。\n我平时使用alfred比较多，自然就想通过workflow的方式来实现，当然用hammerspoon、pet等其他工具也可以。\nalfred workflow和alfred本身的交互是通过管道方式进行连接的：\n alfred将用户输入的信息转发给匹配的workflow； workflow对接收到的参数进行处理，并将处理的结果按照指定格式输出到stdout； alfred读取stdout中的数据作为响应展示到用户界面；  这里主要使用了awgo来编写workflow，实现逻辑可以参考下代码，逻辑很简单。下面主要介绍下如何使用。\n如何安装？ # 下载项目下 workflow/Date Formats Go.alfredworkflow，双击即可安装。\n如何使用？ #   运行 datex 唤起workflow\n  常用转换操作: 获取当前时间对应的Unix时间戳，以及格式化字符串\ndatex now，将当前时间转换为时间戳以及格式化后的字符串(多种日期格式)。\n可以用上下键移动进行选择，当按下回车键时，会将对应的结果拷贝到剪贴板，方便粘贴使用。   常用转换操作: 将时间戳转换为对应的格式化字符串\n以时间戳1596137272为例，datex 1596137272，此时会将时间戳转换为格式化后的字符串。\n选择、复制数据操作类似。   常用转换操作: 将格式化字符串转换为时间戳，或其他格式\n以字符串2020-07-30为例，datex 2020-07-30，此时会先将其与候选的格式化字符串进行匹配。\n并转换成一个有效的时间戳。 然后再根据此时间戳，转换为其他格式对应的字符串。选择、复制数据操作类似。   这大致就是该workflow的使用方式。\n关于日期时间格式转换的workflow，github上已经有几个比较好的实现了，轮子不好用就得自己造。\n 实现对timezone支持不好; 采用的时间格式不符合国人习惯; 掌握awgo开发alfred workflow以后可以写更多效率工具;  希望这个小工具能帮助到有需要的同学，也给准备开发alfred workflow或使用awgo开发workflow的同学提供一个示例。\n如何实现？ # 流程图梳理下逻辑 # 先画个流程图，简单理下思路，思路理清楚了，写代码就快了。\nalfred.workflow编排 # 好，理清楚思路之后，我们开始尝试对worklow进行编排，如下所示：\nworkflow中包含2个节点：\n  节点1，是一个script filter，我们可以配置一个关键字datex来激活它，当然还可以继续输入参数。激活该script filter之后，它将调用我们编写的时间转换程序alfred-datetime-workflow，程序返回的结果将在alfred界面上进行展示，展示的样式是列表。如我们输入datex now，将显示现在的时间戳以及其他格式的datetime字符串。\n  节点2，是Copy to Clipboard，它干什么呢？节点1中显示了列表之后，用户选择一个列表项+回车之后，选中的列表项对应的参数值将被传递给该节点作为参数，Copy to Clipboard就是将参数拷贝到剪贴板；\n   如果希望在workflow各节点中传递参数，则可以通过 workflow.Var(envname, value) 来设置变量，通过 workflow.Config.Get${Type}(envname) 来获取变量。\n 好的，下面来看下这里的时间转换程序怎么写，怎么与alfred衔接起来。\nalfred.workflow时间转换程序 # 这里的时间转换程序，可以是任意语言编写构建的二进制程序，也可以是shell脚本，都可以，只要能解析alfred传递的输入参数、返回alfred指定格式的结果就可以。awgo这个库简化了和alfred交互的部分，我们用这个库主要是简化和alfred数据格式的衔接。\n主体逻辑很简单，实例化awgo.Workflow，然后注册回调函数，等待用户输入后唤醒执行。这里的回调函数，就是这里的run方法，在该方法内部完成时间的转换逻辑即可。\npackage main import ( aw \u0026quot;github.com/deanishe/awgo\u0026quot; ) func main() { workflow = aw.New() workflow.Run(run) }  实现时间转换逻辑 # 前面我们给出的流程图，大部分是run方法的逻辑，照着流程图来写代码逻辑，基本上一遍完成。so easy!\npackage main import ( ... aw \u0026quot;github.com/deanishe/awgo\u0026quot; ) var ( workflow *aw.Workflow icon = \u0026amp;aw.Icon{ Value: aw.IconClock.Value, Type: aw.IconClock.Type, } layouts = []string{ \u0026quot;2006-01-02 15:04:05.999 MST\u0026quot;, \u0026quot;2006-01-02 15:04:05.999 -0700\u0026quot;, time.RFC3339, time.RFC3339Nano, time.UnixDate, time.RubyDate, time.RFC1123Z, } moreLayouts = []string{ \u0026quot;2006-01-02\u0026quot;, \u0026quot;2006-01-02 15:04\u0026quot;, \u0026quot;2006-01-02 15:04:05\u0026quot;, \u0026quot;2006-01-02 15:04:05.999\u0026quot;, } regexpTimestamp = regexp.MustCompile(`^[1-9]{1}\\d+$`) ) func run() { var err error args := workflow.Args() if len(args) == 0 { return } defer func() { if err == nil { workflow.SendFeedback() return } }() // 处理 now input := strings.Join(args, \u0026quot; \u0026quot;) if input == \u0026quot;now\u0026quot; { processNow() return } // 处理时间戳 if regexpTimestamp.MatchString(input) { v, e := strconv.ParseInt(args[0], 10, 32) if e == nil { processTimestamp(time.Unix(v, 0)) return } err = e return } // 处理时间字符串 err = processTimeStr(input) } func processNow() { now := time.Now() // prepend unix timestamp secs := fmt.Sprintf(\u0026quot;%d\u0026quot;, now.Unix()) workflow.NewItem(secs). Subtitle(\u0026quot;unix timestamp\u0026quot;). Icon(icon). Arg(secs). Valid(true) // process all time layouts processTimestamp(now) } // process all time layouts func processTimestamp(timestamp time.Time) { for _, layout := range layouts { v := timestamp.Format(layout) workflow.NewItem(v). Subtitle(layout). Icon(icon). Arg(v). Valid(true) } } func processTimeStr(timestr string) error { timestamp := time.Time{} layoutMatch := \u0026quot;\u0026quot; layoutMatch, timestamp, ok := matchedLayout(layouts, timestr) if !ok { layoutMatch, timestamp, ok = matchedLayout(moreLayouts, timestr) if !ok { return errors.New(\u0026quot;no matched time layout found\u0026quot;) } } // prepend unix timestamp secs := fmt.Sprintf(\u0026quot;%d\u0026quot;, timestamp.Unix()) workflow.NewItem(secs). Subtitle(\u0026quot;unix timestamp\u0026quot;). Icon(icon). Arg(secs). Valid(true) // other time layouts for _, layout := range layouts { if layout == layoutMatch { continue } v := timestamp.Format(layout) workflow.NewItem(v). Subtitle(layout). Icon(icon). Arg(v). Valid(true) } return nil } func matchedLayout(layouts []string, timestr string) (matched string, timestamp time.Time, ok bool) { for _, layout := range layouts { v, err := time.Parse(layout, timestr) if err == nil { return layout, v, true } } return }  导出alfred.workflow # 开发、测试、验证，一切ok之后，就可以在alfred内部将workflow整个导出了，导出后的文件以*.alfredworkflow作为扩展名，这个文件是可以拿来分发的文件，使用者直接双击就可以安装使用。\nawgo试用小结 # 这是使用awgo编写的第一个workflow程序，整体感觉来说，开发者可以专注于功能的实现，不用过度关注alfred数据格式方面的问题。\nalfred本身很强大，支持各种各样的workflow算子，awgo到底能支持到什么程度，这个还要在后续使用中逐渐探索。\n感兴趣的话，不妨一试，至少比写apple script脚本、bash脚本等要方便多了。\n"}),a.add({id:388,href:"/tags/bindata/",title:"bindata",description:"",content:""}),a.add({id:389,href:"/blog/2020-07-25-%E5%A6%82%E4%BD%95%E5%9C%A8go%E4%BA%8C%E8%BF%9B%E5%88%B6%E7%A8%8B%E5%BA%8F%E4%B8%AD%E6%89%93%E5%8C%85%E9%9D%99%E6%80%81%E8%B5%84%E6%BA%90%E6%96%87%E4%BB%B6/",title:"如何在go二进制程序中打包静态资源文件",description:"如何在go程序里面打包一些静态资源文件呢，然后方便在程序里面使用它？今天介绍一种方案。",content:"Why? # 有时我们希望在go二进制程序中打包一些静态资源文件，目的可能有多种，比较常见的是为了简化安装。通常我们安装一个go编写的工具，更倾向于使用 go get $repo 的方式来完成，这似乎已经成为了一种共识。当然，也有些项目还依赖一些静态资源文件，这些静态资源文件是不会被自动安装的，就需要借助其他方式来完成静态资源的安装，比如通过install.sh脚本，后者Makefile构建脚本等等。\n今天，我想讨论下，如何简单快速地支持静态资源打包到二进制程序中，以及在二进制程序中对这些静态资源加以引用。\nHow? # github上已经有不少开发者在探索，方法其实都比较雷同，大致思路就是：\n 读取静态资源文件，转换成bytes数据； 内部提供一些类似文件系统的接口，提供文件名，返回文件数据； blabla\u0026hellip;  开发者的需求，可能不完全一致，比如：\n 我想像遍历本地文件系统一样遍历文件目录，不只是提供一个文件名返回一个文件； 我的代码已经写完了，我只想做最小修改，将静态资源文件打包到二进制程序中，而后还原回文件系统； 我的代码不需要支持类似文件服务器的功能，不需要那么多华丽呼哨的功能；  开发者提供了很多类似的实现，这里有篇文章可供参考：https://tech.townsourced.com/post/embedding-static-files-in-go/。能工模形，巧匠窃意。其实在大致了解了实现的方式之后，就懒得再去学如何使用这些五花八门的第三方工具了。说真的，真的没几个好用的，至少从我的角度来说。可能它设计的比较通用，但是与我来说没有用处，我追求极简。\n而且，go官方是有意来支持打包静态资源的，关于这一点，已经有issue在跟进讨论：https://github.com/golang/go/issues/35950。\n尽管现在的状态还是Proposal-Hold状态，但是我觉得这个feature的到来也不会等很久了，anyway，我不想在这些即将被淘汰的三方工具上浪费学习的时间、改写代码的时间。\n所以呢，为什么不简单一点，自己写一个当下比较适用项目本身的？写这个东西花不了二十分钟时间！\nLet\u0026rsquo;s Do it! # 功能分析 # 我理解实现打包静态资源文件，有这么几个点需要考虑：\n 提供一个小工具，通过它可以反复执行类似的静态资源打包的操作； 可以指定一个文件或者目录，将其转换成一个go文件放入项目中，允许编译时连接； go文件可以通过导出变量的形式，导出文件数据，允许在其他go代码中引用文件的内容； 静态资源文件可能有很多，希望能对文件内容进行压缩，以便减小go binary文件尺寸； 通常是本地组织好静态资源文件，写代码、测试ok、最后发布前希望将其打包到go binary，打包、解包、使用静态资源要最小化项目代码修改；  功能实现 # 我们先实现这个打包静态资源的工具，需要这几个参数：input、output，分别代表输入文件（or 目录）、输出文件名（go文件），gopkg代表输出go文件的包名（默认gobin）。\npackage main var ( input = flag.String(\u0026quot;input\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;read data from input, which could be a regular file or directory\u0026quot;) output = flag.String(\u0026quot;output\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;write transformed data to named *.go, which could be linked with binary\u0026quot;) gopkg = flag.String(\u0026quot;gopkg\u0026quot;, \u0026quot;gobin\u0026quot;, \u0026quot;write transformed data to *.go, whose package is $package\u0026quot;) )  我们的工具将从input对应的文件中读取文件内容，并转换成一个output对应的go文件中的导出变量。如果input是一个目录呢，我们则需要对目录下文件进行遍历处理。由于静态资源文件数据可能较大，这里需要进行gzip压缩（对于文本压缩率可高达80%左右）有助于减少go binary文件尺寸。\n那读取到文件内容之后，如何将其转换成go文件中的导出变量呢？很简单，我们定义一个go模板，将读取到的文件内容gzip压缩后转换成bytes数组传递给模板引擎就可以了。模板中的{{.GoPackage}}将引用命令选项$gopkg的值，{{.Variable}}即为导出变量的值，这里我们会使用选项$input对应的CamelCase转换之后的文件名（或目录名），{{.Data}}即为gzip压缩后的文件数据。\nvar tpl = `package {{.GoPackage}} var {{.Variable}} = []uint8{ {{ range $idx, $val := .Data }}{{$val}},{{ end }} }`  接下来，我们看下怎么读取文件的内容，再强调下，要读取的内容可能是单个文件，也可能是一个目录。\n// ReadFromInputSource 从输入读取内容，可以是一个文件，也可以是一个目录（会先gzip压缩然后再返回内容） func ReadFromInputSource(inputSource string) (data []byte, err error) { _, err := os.Lstat(inputSource) if err != nil { return nil, err } buf := bytes.Buffer{} err = compress.Tar(inputSource, \u0026amp;buf) if err != nil { return nil, err } return buf.Bytes(), nil }  gzip对文件数据进行压缩，篇幅原因，这里只贴个链接地址，感兴趣的可以自行查看：https://github.com/hitzhangjie/codemaster/blob/master/compress/compress.go。\n好，现在我们将这个打包工具的完整逻辑再完整梳理一下。\nfunc main() { // 输入输出参数校验 if len(*input) == 0 || len(*gopkg) == 0 { fmt.Println(\u0026quot;invalid argument: invalid input\u0026quot;) os.Exit(1) } // 读取输入内容 buf, err := ReadFromInputSource(*input) if err != nil { fmt.Errorf(\u0026quot;read data error: %v\\n\u0026quot;, err) os.Exit(1) } // 将内容转换成go文件写出 inputBaseName := filepath.Base(*input) if len(*output) == 0 { *output = fmt.Sprintf(\u0026quot;%s_bindata.go\u0026quot;, inputBaseName) } outputDir, outputBaseName := filepath.Split(*output) tplInstance, err := template.New(outputBaseName).Parse(tpl) if err != nil { fmt.Printf(\u0026quot;parse template error: %v\\n\u0026quot;, err) os.Exit(1) } _ = os.MkdirAll(outputDir, 0777) fout, err := os.OpenFile(*output, os.O_CREATE|os.O_TRUNC|os.O_WRONLY, 0666) if err != nil { fmt.Printf(\u0026quot;open input error: %v\u0026quot;, err) os.Exit(1) } err = tplInstance.Execute(fout, \u0026amp;struct { GoPackage string Variable string Data []uint8 }{ GoPackage: *gopkg, Variable: strcase.ToCamel(outputBaseName), Data: buf, }) if err != nil { panic(fmt.Errorf(\u0026quot;template execute error: %v\u0026quot;, err)) } fmt.Printf(\u0026quot;ok, filedata stored to %s\\n\u0026quot;, *output) }  下面我们演示下如何使用这个工具来对静态资源打包。\n假定存在如下静态资源目录static，其下包含了多个文件，现在我想将其全部打包到一个go文件中。\n$ tree . . |- static |- file1.txt |- file2.txt |- file3.txt  运行 go build -v bindata 编译我们之前写的工具，然后运行 bindata -input=path/to/static -output=goin/static.go -gopkg=gobin。\n$ tree . . |- static |- file1.txt |- file2.txt |- file3.txt |- gobin |- static.go  我们看到当前目录下多生成了一个gobin目录，其下多了个go文件static.go，查看下文件内容：\n$ cat gobin/static.go package gobin var StaticGo = []uint8{ 31,139,8,0,0,0,0,0,0,255,236,213,193,10,194,48,12,128,225,158,125,138,62,129,36,77,219,60,79,15,171,171,136,7,91,65,124,122,105,39,131,29,244,182,58,89,190,75,24,140,209,145,253,44,166,203,128,199,242,40,106,61,0,0,222,218,54,217,187,54,193,76,215,13,178,66,98,240,236,25,136,21,32,121,100,165,97,197,51,205,238,185,132,155,2,120,142,225,122,58,167,225,211,125,185,132,24,191,60,231,253,42,243,252,19,101,76,89,167,172,235,119,160,241,240,235,227,136,206,234,222,205,150,250,183,78,250,239,104,209,191,145,254,247,166,238,157,182,212,191,155,254,255,134,164,255,30,22,253,147,244,47,132,16,123,241,10,0,0,255,255,106,242,211,179,0,16,0,0, }  哈哈，现在看到static目录及其下的文件已经被完整打包到一个go文件中了，且通过导出变量进行了导出，后续使用的时候，可以先将其还原到本地文件系统，以前已经写好的代码不用做任何修改，怎么还原到本地文件系统呢，并使用呢？\n// 在你需要引用这些静态资源的package中释放这些静态资源文件到本地文件系统 func init() { compress.UnTar(path/to/static, bytes.NewBuffer(gobin.StaticGo)) val := config.Read(path/to/static/file1.go, \u0026quot;section\u0026quot;, \u0026quot;property\u0026quot;, defaultValue) ... }  现在，是不是感觉超级简单呢？:)\n"}),a.add({id:390,href:"/tags/cache/",title:"cache",description:"",content:""}),a.add({id:391,href:"/tags/cc++/",title:"cc++",description:"",content:""}),a.add({id:392,href:"/blog/2019-01-07-%E4%BD%A0%E4%B8%8D%E8%AE%A4%E8%AF%86%E7%9A%84cc-volatile/",title:"你不认识的cc++ volatile",description:"学习c语言时初始volatile，学习java时认识了不一样的volatile，但是对它们的理解还是没那么详细。后台来有次学习Linux内核时读到了torvalds关于使用volatile可能潜藏了隐患的评论，开始重视并深入学习了这个问题……有一次参加中心的技术分享听到大佬降到volatile可以解决线程可见性问题，我顿时感觉不太对吧，但是作为一个新人……后面几番求证之后，终于发现大佬们认识也不到位啊，这个问题其实要把别人真的讲明白牵扯的知识还挺多挺细的，希望对感兴趣同学有帮助。",content:" img { width: 680px; }  1. 令人困惑的volatile # volatile字面意思是“不稳定的、易变的”，不少编程语言中存在volatile关键字，也有共同之处，如“表示程序执行期间数据可能会被外部操作修改”，如被外设修改或者被其他线程修改等。这只是字面上给我们的一般性认识，然而具体到不同的编程语言中volatile的语义可能相差甚远。\n很多人以为自己精通CC++，但是被问起volatile的时候却无法清晰、果断地表明态度，那只能说明还是处在“从入门到精通”的路上，如果了解一门语言常见特性的使用、能够写健壮高效的程序就算精通的话，那实在是太藐视“大师”的存在了。从一个volatile关键字折射出了对CC++标准、编译器、操作系统、处理器、MMU各个方面的掌握程度。\n几十年的发展，很多开发者因为自己的偏见、误解，或者对某些语言特性（如Java中的volatile语义）的根深蒂固的认识，赋予了CC++ volatile本不属于它的能力，自己却浑然不知自己犯了多大的一个错误。\n我曾经以为CC++中volatile可以保证线程可见性，因为Java中是这样的，直到后来阅读Linux内核看到Linus Torvards的一篇文档，他强调了volatile可能带来的坏处“任何使用volatile的地方，都可能潜藏了一个bug”，我为他的“危言耸听”感到吃惊，所以我当时搜索了不少资料来求证CC++ volatile的能力，事后我认为CC++ volatile不能保证线程可见性。但是后来部门内一次分享，分享中提到了volatile来保证线程可见性，我当时心存疑虑，事后验证时犯了一个错误导致我错误地认为volatile可以保证线程可见性。直到我最近翻阅以前的笔记，翻到了几年前对volatile的疑虑……我决定深入研究下这个问题，以便能顺利入眠。\n2. 从规范认识volatile # 以常见的编程语言C、C++、Java为例，它们都有一个关键字volatile，但是对volatile的定义却并非完全相同。\n  Java中对volatile的定义：\n 8.3.1.4. volatile Fields\nThe Java programming language allows threads to access shared variables (§17.1). As a rule, to ensure that shared variables are consistently and reliably updated, a thread should ensure that it has exclusive use of such variables by obtaining a lock that, conventionally, enforces mutual exclusion for those shared variables.\nThe Java programming language provides a second mechanism, volatile fields, that is more convenient than locking for some purposes.\nA field may be declared volatile, in which case the Java Memory Model ensures that all threads see a consistent value for the variable (§17.4).\n Java清晰地表达了这样一个观点，Java内存模型中会保证volatile变量的线程可见性，接触过Java并发编程的开发者应该都清楚，这是一个不争的事实。\n  CC++中对volatile的定义：\n 6.7.3 Type qualifiers\nvolatile: No cacheing through this lvalue: each operation in the abstract semantics must be performed (that is, no cacheing assumptions may be made, since the location is not guaranteed to contain any previous value). In the absence of this qualifier, the contents of the designated location may be assumed to be unchanged except for possible aliasing.\n C99中也清晰地表名了volatile的语义，不要做cache之类的优化。这里的cache指的是software cacheing，即编译器生成指令将内存数据缓存到cpu寄存器，后续访问内存变量使用寄存器中的值；需要与之作出区分的是hardware cacheing，即cpu访问内存时将内存数据缓存到cpu cache，硬件操作完全对上层应用程序透明。大家请将这两个点铭记在心，要想搞清楚CC++ volatile必须要先理解这里cache的区别。\nC99清晰吗？上述解释看上去很清晰，但是要想彻底理解volatile的语义，绝非上述一句话就可以讲得清的，C99中定义了abstract machine以及sequence points，与volatile相关的描述有多处，篇幅原因这里就不一一列举了，其中与volatile相关的abstract machine行为描述共同确定了volatile的语义。\n  3. 对volatile持何观点 # 为了引起大家对CC++ volatile的重视并及时表明观点，先贴一个页面“Is-Volatile-Useful-with-Threads”，网站中简明扼要的告知大家，“Friends don’t let friends use volatile for inter-thread communication in C and C++”。But why？\nisocpp专门挂了这么个页面来强调volatile在不同编程语言中的差异，可见它是一个多么难缠的问题。即便是有这么个页面，要彻底搞清楚volatile，也不是说读完上面列出的几个技术博客就能解决，那也太轻描淡写了，所以我搜索、整理、讨论，希望能将学到的内容总结下来供其他开发者参考，我也不想再因为这个问题而困扰。\n结合CC++ volatile qualifier以及abstract machine中对volatile相关sequence points的描述，可以确定volatile的语义：\n 不可优化性：不要做任何软件cache之类的优化，即多次访问内存对象时，编译器不能优化为cache内存对象到寄存器、后续访问内存对象转为访问寄存器 [6.7.3 Type qualifiers - volatile]； 顺序性：对volatile变量的多次读写操作，编译器不能以预测数据不变为借口优化掉读写操作，并且要保证前面的读写操作先于后面的读写操作完成 [5.1.2.3 Program execution]； 易变性：从不可优化性、顺序性语义要求，不难体会出其隐含着数据“易变性”，这也是volatile字面上的意思，也是不少开发者学习volatile时最熟知的语义；  CC++规范没有显示要求volatile支持线程可见性，gcc也没有在标准允许的空间内做什么“发挥”去安插什么保证线程可见性的处理器指令（Java中volatile会使用lock指令使其他处理器cache失效强制读内存保证线程可见性）。而关于CPU cache一致性协议，x86原先采用MESI协议，后改用效率更高的MESIF，都是强一致性协议，在x86这等支持强一致的CPU上，CC++中结合volatile是可以“获得”线程可见性的，在非强一致CPU上则不然。\n但是CC++ volatile确实是有价值的，很多地方都要使用它，而且不少场景下似乎没有比它更简单的替代方法，下面首先列举CC++ volatile的通用适用场景，方便大家认识volatile，然后我们再研究为什么CC++ volatile不能保证线程可见性。CC++标准中确实没有说volatile要支持线程可见性，大家可以选择就此打住，但是我怀疑的是gcc在标准允许的空间内是怎么做的？操作系统、MMU、处理器是怎么做的？“标准中没有显示列出”，这样的理由还不足以让我停下探索的脚步。\n4. CC++ need volatile # CC++ volatile语义“不可优化型”、“顺序性”、“易变性”，如何直观感受它的价值呢？看C99中给出的适用场景吧。\n  setjmp、longjmp用于实现函数内、函数间跳转（goto只能在函数内跳转），C Spec规定longjmp之后希望跳到的栈帧中的局部变量的值是最新值，而不是setjmp时的值，考虑编译器可能作出一些优化，将auto变量cache到寄存器中，假如setjmp保存硬件上下文的时候恰巧保存了存有该局部变量值的寄存器信息，等longjmp回来的时候就用了旧值。这违背了C Spec的规定，所以这个时候可以使用volatile来避免编译器优化，满足C Spec！\n  signal handler用于处理进程捕获到的信号，与setjmp、longjmp类似，进程捕获、处理信号时需要保存当前上下文再去处理信号，信号处理完成再恢复上下文继续执行。信号处理函数中也可能会修改某些共享变量，假如共享变量在收到信号时加载到了寄存器，并且保存硬件上下文时也保存起来了，那么信号处理函数执行完毕返回（可能会修改该变量）恢复上下文后，访问到的还是旧值。因此将信号处理函数中要修改的共享变量声明为volatile是必要的。\n  设备驱动、Memory-Mapped IO、DMA。 我们先看一个示例，假如不使用volatile，编译器会做什么。编译器生成代码可能会将内存变量sum、i放在寄存器中，循环执行过程中，编译器可能认为这个循环可以直接优化掉，sum直接得到了最终的a[0]+a[1]+…a[N]的值，循环体执行次数大大减少。\nsum = 0; for (i=0; i\u0026lt;N; ++i) sum += a[i];  这种优化对于面向硬件的程序开发（如设备驱动开发、内存映射IO）来说有点过头了，而且会导致错误的行为。下面的代码使用了volatile qualifer，其他与上述代码基本相同。如果不存在volatile修饰，编译器会认为最终*ttyport的值就是a[N-1]，前N-1次赋值都是没必要的，所以直接优化成*ttyport = a[N-1]。但是ttyport是外设的设备端口通过内存映射IO得到的虚拟内存地址，编译器发现存在volatile修饰，便不会对循环体中*ttyport = a[i]进行优化，循环体会执行N次赋值，且保证每次赋值操作都与前一次、后一次赋值存在严格的顺序性保证。\nvolatile short *ttyport; for (i=0; i\u0026lt;N; ++i) *ttyport = a[i];  可能大家会有疑问，volatile只是避免编译器将内存变量存储到寄存器，对cpu cache却束手无策，谁能保证每次对*ttyport的写操作都确定写回内存了呢？这里就涉及到cpu cache policy问题了。\n对于外设IO而言，有两种常用方式：\n Memory-Mapped IO，简称MMIO，将设备端口（寄存器）映射到进程地址空间。以x86为例，对映射内存区域的读写操作通过普通的load、store访存指令来完成，处理器通过内存类型范围寄存器（MTRR，Memory Type Range Regsiters）和页面属性表（PAT，Page Attribute Table）对不同的内存范围设置不同的CPU cache policy，内核设置MMIO类型范围的cpu cache策略为uncacheable，其他RAM类型范围的cpu cache策略为write-back！即直接绕过cpu cache读写内存，但实际上并没有物理内存参与，而是将读写操作转发到外设，上述代码中*ttyport = a[i]这个赋值操作绕过CPU cache直达外设。 Port IO，此时外设端口（寄存器）采用独立编址，而非Memory-Mapped IO这种统一编址方式，需要通过专门的cpu指令来对设备端口进行读写，如x86上采用的是指令in、out来完成设备端口的读写。  而如果是**DMA（Direct Memory Access）**操作模式的话，它绕过cpu直接对内存进行操作，期间不中断cpu执行，DMA操作内存方式上与cpu类似，都会考虑cpu cache一致性问题。假如DMA对内存进行读写操作，总线上也会对事件进行广播，cpu cache也会观测到并采取相应的动作。如DMA对内存进行写操作，cpu cache也会将相同内存地址的cache line设置为invalidate，后续读取时就可以重新从内存加载最新数据；假如DMA进行内存读操作，数据可能从其他cpu cache中直接获取而非从内存中。这种情况下DMA操作的内存区域，对应的内存变量也应该使用volatile修饰，避免编译器优化从寄存器中读到旧值。\n以上示例摘自C99规范，通过上述示例、解释，可以体会到volatile的语义特点：“不可优化型、易变性、顺序性”。\n下面这个示例摘自网络，也比较容易表现volatile的语义特点：\n// 应为 volatile unsigned int *p = .... unsigned int *p = GetMagicAddress(); unsigned int a, b; a = *p; b = *p; *p = a; *p = b;  GetMagicAddress()返回一个外设的内存映射IO地址，由于unsigned int *p指针没有volatile修饰，编译器认为*p中的内容不是“易变的”因此可能会作出如下优化。首先从p读取一个字节到寄存器，然后将其赋值给a，然后认为*p内容不变，就直接将寄存器中内容再赋值给b。写*p的时候认为a == b，写两次没必要就只写了一次。\n而如果通过volatile对*p进行修饰，则就是另一个结果了，编译器会认为*p中内容是易变的，每次读取操作都不会沿用上次加载到寄存器中的旧值，而内存映射IO内存区域对应的cpu cache模式又是被uncacheable的，所以会保证从内存读取到最新写入的数据，成功连续读取两个字节a、b，也保证按顺序写入两个字节a、b。\n  相信读到这里大家对CC++ volatile的适用场景有所了解了，它确实是有用的。那接下来我们针对开发者误解很严重的一个问题“volatile能否支持线程可见性”再探索一番，不能！不能！不能！\n5. CC++ thread visibility # 5.1. 线程可见性问题 # 多线程编程中经常会通过修改共享变量的方式来通知另一个线程发生了某种状态的变化，希望线程能及时感知到这种变化，因此我们关心“线程可见性问题”。\n在对称多处理器架构中（SMP），多处理器、核心通过总线共享相同的内存，但是各个处理器核心有自己的cache，线程执行过程中，一般会将内存数据加载到cache中，也可能会加载到寄存器中，以便实现访问效率的提升，但这也带来了问题，比如我们提到的线程可见性问题。某个线程对共享变量做了修改，线程可能只是修改了寄存器中的值或者cpu cache中的值，修改并不会立即同步回内存。即便同步回内存，运行在其他处理器核心上的线程，访问该共享数据时也不会立即去内存中读取最新的数据，无法感知到共享数据的变化。\n5.2. diff volatile in java、cc++ # 有些编程语言中定义了关键字volatile，如Java、C、C++等，对比下Java volatile和CC++ volatile，差异简直是太大了，我们只讨论线程可见性相关的部分。\nJava中语言规范明确指出volatile保证内存可见性，JMM存在“本地内存”的概念，线程对“主存”变量的访问都是先加载到本地内存，后续写操作再同步回主存。volatile可以保证一个线程的写操作对其他线程立即可见，首先是保证volatile变量写操作必须要更新到主存，然后还要保证其他线程volatile变量读取必须从主存中读取。处理器中提供了MFENCE指令来创建一个屏障，可以保证MFENCE之前的操作对后续操作可见，用MFENCE可以实现volatile，但是考虑到AMD处理器中耗时问题以及Intel处理器中流水线问题，JVM从MFENCE修改成了LOCK: ADD 0。\n但是在C、C++规范里面没有要求volatile具备线程可见性语义，只要求其保证“不可优化性、顺序性、易变性”。\n5.3. how gcc handle volatile # 这里做个简单的测试：\n#include \u0026lt;stdio.h\u0026gt; int main() { // volatile int a = 0; int a = 0; while(1) { a++; printf(\u0026quot;%d\\n\u0026quot;, a); } return 0; }  不开优化的话，有没有volatile gcc生成的汇编指令基本是一致的，volatile变量读写都是针对内存进行，而非寄存器。开gcc -O2优化时，不加volatile情况下读写操作通过寄存器，加了volatile则通过内存。\n1）不加volatile ：gcc -g -O2 -o main main.c\n这里重点看下对变量a的操作，xor %ebx,%ebx将寄存器%ebx设为0，也就是将变量a=0存储到了%ebx，nopl不做任何操作，然后循环体里面每次读取a的值都是直接在%ebx+1，加完之后也没有写回内存。假如有个共享变量是多个线程共享的，并且没有加volatile，多个线程访问这个变量的时候就是用的物理线程跑的处理器核心寄存器中的数据，是无法保证内存可见性的。\n2）加volatile：gcc -g -O2 -o main main.c\n这里变量a的值首先被设置到了0xc(%rsp)中，nopl空操作，然后a++时是将内存中的值移动到了寄存器%eax中，然后执行%eax+1再写回内存0xc(%rsp)中，while循环中每次循环执行都是先从内存里面取值，更新后再写回内存。但是这样就可以保证线程可见性了吗？No！\n5.4. how cpu cache works # 是否有这样的疑问？CC++中对volatile变量读写，发出的内存读写指令不会被CPU转换成读写CPU cache吗？这个属于硬件层面内容，对上层透明，编译器生成的汇编指令也无法反映实际执行情况！因此，只看上述反汇编示例是不能确定CC++ volatile支持线程可见性的，当然也不能排除这种可能性？\nStack Overflow上Dietmar Kühl提到，‘volatile’阻止了对变量的优化，例如对于频繁访问的变量，会阻止编译器对其进行编译时优化，避免将其放入寄存器中（注意是寄存器而不是cpu的cache）。编译器优化内存访问时，会生成将内存数据缓存到寄存器、后续访问内存操作转换为访问寄存器，这称为“software cacheing”；而CPU实际执行时硬件层面将内存数据缓存到CPU cache中，这称为“hardware cacheing”，是对上层完全透明的。现在已经确定CC++ volatile不会再作出“将内存数据缓存到CPU寄存器”这样的优化，那上述CPU hardware caching技术就成了我们下一个怀疑的对象。\n保证CPU cache一致性的方法，主要包括write-through（写直达）或者write-back（写回），write-back并不是当cache中数据更新时立即写回，而是在稍后的某个时机再写回。写直达会严重降低cpu吞吐量，所以现如今的主流处理器中通常采用写回法，而写回法又包括了write-invalidate和write-update两种方式，可先跳过。\n write-back：\n write-invalidate，当某个core（如core 1）的cache被修改为最新数据后，总线观测到更新，将写事件同步到其他core（如core n），将其他core对应相同内存地址的cache entry标记为invalidate，后续core n继续读取相同内存地址数据时，发现已经invalidate，会再次请求内存中最新数据。 write-update，当某个core（如core 1）的cache被修改为最新数据后，将写事件同步到其他core，此时其他core（如core n）立即读取最新数据（如更新为core 1中数据）。   write-back（写回法）中非常有名的cache一致性算法MESI，它是典型的强一致算法，intel就凭借MESI优雅地实现了强一致CPU，现在intel优化了下MESI，得到了MESIF，它有效减少了广播中req/rsp数量，减少了带宽占用，提高了处理器处理的吞吐量。关于MESI，这里有个可视化的MESI交互演示程序可以帮助理解其工作原理，查看MESI可视化交互程序。\n我们就先结合简单的MESI这个强一致性协议来试着理解下“x86下为什么就可以保证可见性”，结合多线程场景分析：\n 一个volatile共享变量被多个线程读取，假定这几个线程跑在不同的cpu核心上，每个核心有自己的cache，线程1跑在core1上，线程2跑在core2上。 现在线程1准备修改变量值，这个时候会先修改cache中的值然后稍后某个时刻写回主存或者被其他core读取。cache同步策略“write-back”，MESI就是其中的一种。处理器所有的读写操作都能被总线观测到，snoop based cache coherency，当线程2准备读取这个变量时： 假定之前没读取过，发现自己的cache里面没有，就通过总线向内存请求，为了保证cpu cache高吞吐量，总线上所有的事务都能被其他core观测到，core1发现core2要读取内存值，这个数据刚好在我的cache里面，但是处于dirty状态。core1可能灰采取两种动作，一种是将dirty数据直接丢给core2（至少是最新的），或者告知core2延迟read，等我先写回主存，然后core2再尝试read内存。 假定之前读取过了，core1对变量的修改也会被core2观测到，core1应该将其cache line标记为modified，将core2 cache line标记为invalidate使其失效，下次core2读取时从core1获取或内存获取（触发core1将dirty数据写回主存）。  这么看来只要处理器的cache一致性算法支持，并且结合volatile避免寄存器相关优化，就能轻松保证线程可见行。真的是这样吗？并不是。\n认为有了MESIF volatile就可以在x86平台上实现可见性，这种理解是有问题的：\n volatile只是避免了software caching，不能避免hardware caching； 现在x86处理器中都引入了store buffer，volatile变量更新操作会先放入store buffer中； store buffer中的更新操作会尽可能快地更新到cache，有多快不确定，反正不是立即（过段时间或者有write barrier都可以清空）； store buffer中的更新落到L1 cache后会触发MESIF操作，如将当前cache的cacheline修改为Modified，并广播给其他核MESIF invalidate请求，其他核将其放入invalidate queue中，回复ack但不立即处理； 等其他核下次读取时，如果还没处理完invalidate queue中的请求，就会从本地的cacheline中读取到旧值，因为此时cacheline的状态是Shared，还是可以读取的； 如果已经处理完了invalidate queue中的事件（过一段时间或者有read barrier都可以清空），会将对应cacheline状态修改为Invalidated，此时会重试从总线读取该cacheline对应内存块的最新数据。其他核也会observe/snoop其它核发送到总线的内存读取事件，如果它知道该内存块对应的cacheline自己的才是最新的（Modified），就会将其最新数据作为响应并写回主存，此时两边的cacheline全部改为Shared状态。  从基于对现代CPU架构、cache一致性协议的了解，我不认为x86平台下volatile就可以保证线程可见性。我甚至怀疑当时跟我提“我们用volatile之前有问题用了之后OK了”的同学是不是真的验证没问题了，还是说用的其实是atomic或者其他barriers。总之我在Intel Core i7上没有构造出合适的用例来证明volatile可以保证线程可见性，可能硬件store buffer和invalidate queue处理还是很快的，我们构造两三个线程并发读写volatile不容易复现这个问题。\n而且，不同的处理器设计不一样，我们只是以MESI协议来粗略了解了x86的处理方式，对于其他弱一致性CPU，即便使用了volatile也不一定能保证线程可见性。\n但若是对volatile变量读写时安插了类似MFENCE、LOCK指令也是可以保证可见性的，如何进一步判断编译器有没有生成类似barriers指令呢？还需要判断编译器（如gcc）是否有对volatile来做特殊处理，如安插MFENCE、LOCK指令之类的。上面编写的反汇编测试示例中，gcc生成的汇编没有看到lock相关的指令，但是因为我是在x86上测试的，而x86刚好是强一致CPU，我也不确定是不是因为这个原因，gcc直接图省事略掉了lock指令？所以现在要验证下，在其他非x86平台上，gcc -O2优化时做了何种处理。如果安插了类似指令，问题就解决了，我们也可以得出结论，c、c++中volatile在gcc处理下可以保证线程可见性，反之则不能得到这样的结论！\n我在网站godbolt.org交叉编译测试了一下上面gcc处理的代码，换了几个不同的硬件平台也没发现有生成特定的类似MFENCE或者LOCK相关的致使处理器cache失效后重新从内存加载的指令。\n 备注：在某些处理器架构下，gcc确实有提供一些特殊的编译选项允许绕过CPU cache直接对内存进行读写，可参考gcc man手册“-mcache-volatile”、“-mcache-bypass”选项的描述。\n 想了解下CC++中volatile的真实设计“意图”，然后，在stack overflow上我又找到了这样一个回答：https://stackoverflow.com/a/12878500，重点内容已加粗显示。\n[Nicol Bolas](https://stackoverflow.com/users/734069/nicol-bolas)回答中提到：\n What volatile tells the compiler is that it can\u0026rsquo;t optimize memory reads from that variable. However, CPU cores have different caches, and most memory writes do not immediately go out to main memory. They get stored in that core\u0026rsquo;s local cache, and may be written\u0026hellip; eventually.**\nCPUs have ways to force cache lines out into memory and to synchronize memory access among different cores. These memory barriers allow two threads to communicate effectively. Merely reading from memory in one core that was written in another core isn\u0026rsquo;t enough; the core that wrote the memory needs to issue a barrier, and the core that\u0026rsquo;s reading it needs to have had that barrier complete before reading it to actually get the data.\nvolatile guarantees none of this. Volatile works with \u0026ldquo;hardware, mapped memory and stuff\u0026rdquo; because the hardware that writes that memory makes sure that the cache issue is taken care of. If CPU cores issued a memory barrier after every write, you can basically kiss any hope of performance goodbye. So C++11 has specific language saying when constructs are required to issue a barrier.\n Dietmar Kühl回答中提到:\n The volatile keyword has nothing to do with concurrency in C++ at all! It is used to have the compiler prevented from making use of the previous value, i.e., the compiler will generate code accessing a volatile value every time is accessed in the code. The main purpose are things like memory mapped I/O. However, use of volatile has no affect on what the CPU does when reading normal memory: If the CPU has no reason to believe that the value changed in memory, e.g., because there is no synchronization directive, it can just use the value from its cache. To communicate between threads you need some synchronization, e.g., an std::atomic, lock a std::mutex, etc.\n 最后看了标准委员会对volatile的讨论：http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2006/n2016.html 简而言之，就是CC++中当然也想提供java中volatile一样的线程可见性、阻止指令重排序，但是考虑到现有代码已经那么多了，突然改变volatile的语义，可能会导致现有代码的诸多问题，所以必须要再权衡一下，到底值不值得为volatile增加上述语义，当前C++标准委员会建议不改变volatile语义，而是通过新的std::atmoic等来支持上述语义。\n结合自己的实际操作、他人的回答以及CC++相关标准的描述，我认为CC++ volatile确实不能保证线程可见性。但是由于历史的原因、其他语言的影响、开发者自己的误解，这些共同导致开发者赋予了CC++ volatile很多本不属于它的能力，甚至大错特错，就连Linus Torvards也在内核文档中描述volatile时说，建议尽量用memory barrier替换掉volatile，他认为几乎所有可能出现volatile的地方都可能会潜藏着一个bug，并提醒开发者一定小心谨慎。\n6. 实践中如何操作 #  开发者应该尽量编写可移植的代码，像x86这种强一致CPU，虽然结合volatile也可以保证线程可见性，但是既然提供了类似memory barrier()、std::atomic等更加靠谱的用法，为什么要编写这种兼顾volatile、x86特性的代码呢？ 开发者应该编写可维护的代码，对于这种容易引起开发者误会的代码、特性，应该尽量少用，这虽然不能说成是语言设计上的缺陷，但是确实也不能算是一个优势。  凡事都没有绝对的，用不用volatile、怎么用volatile需要开发者自己权衡，本文的目的主要是想总结CC++ volatile的“能”与“不能”以及背后的原因。由于个人认识的局限性，难免会出现错误，也请大家指正。\n 本文撰写于 2019-01-07, 现在拿出来分享给感兴趣的技术同行，一起学习交流。\n 关于对volatile的理解，会引出对内存模型的理解，即便看完一些针对内存模型的描述之后，还是会有一些开发者提出更深入细微的问题，比如lock, lock cmpxchg如何实现的，mfence、lfence、sfence如何实现的。陷入细节是可怕的，它会让我们感觉无法适可而止。\n补充一篇文章，我觉得挺不错的，Memory Barrier: A Hardware View for Software Hackers。\n它介绍了现在处理器的cache结构设计（包括指令cache、数据cache、cacheline、store buffer、多级cache）、cache一致性协议MESI，以及所谓的内存屏障与cache设计中cache一致性协议、store buffer、invalidate queue之间的关系。理解下这篇文章，大致搞明白硬件的工作过程，非常有助于加深这部分的理解。\n 本文最后更新于 2020-12-15, 补充了上述内存屏障相关的描述及参考资料。\n 这里还少了一层，在cpu执行更新操作时，为了避免cpu stall提高指令吞吐，写更新其实是落store buffer中的，cache中并没有立即体现出更新，cache一致性协议也还没工作……所以这个时候还需要内存屏障来讲storebuffer中的更新刷到cache，读的核上还需要通过内存屏障处理invalidate queue才能观察到新值。\n那x86+volatile没有应用内存屏障，又是怎么能实现可见性的呢？\n首先上述理解及质疑都是正确的思考路径，我们需要考虑的是x86体系结构里面是否有我们所不知道的东西，这篇论文也许能解答我们的问题：x86 tso model：\n Moreover, different processors or hardware threads do not observably share store buffers. This is in sharp contrast to x86-CC, where each processor has a separate view order of its memory accesses and other processors' writes.\n 意思大概就是说x86的设计，每个处理器核心不仅有自己的内存访问视图，还有一个其他处理器的write操作的视图，这样它就能感知到谁有真正的最新的数据。所以x86上面只要c程序加了volatile避免寄存器优化就可以保证线程可见性。\n参考资料 #  Memory Barrier: A Hardware View for Software Hackers x86 TSO: A Programmer\u0026rsquo;s Model for x86 Multiprocessors x86-TSO: A Rigorous and Usable Programmer’s Model for x86 Multiprocessors  "}),a.add({id:393,href:"/blog/2020-07-01-%E5%BC%80%E5%8F%91%E8%80%85%E5%BA%94%E6%8E%8C%E6%8F%A1%E7%9A%84%E7%B3%BB%E7%BB%9F%E6%80%A7%E6%B5%8B%E8%AF%95%E6%96%B9%E6%B3%95/",title:"开发者应掌握的系统性测试方法",description:"很多人觉得测试是徒劳的，这种情况只有可能是问题规模比较小、肉眼可分析的情境下才会为true",content:'/* Three image containers (use 25% for four, and 50% for two, etc) */ .column { float: left; width: 50%; padding: 5px; } /* Clear floats after image containers */ .row::after { content: ""; clear: both; display: table; } .fixsize { width: 400px; } .fullsize { width: 680px; }  如何做好测试，是一门系统性的方法学，而不只是一些零零散散的经验。了解并掌握各种测试的目的、方法是非常有必要的。\n最近工作中也在推动测试相关的一些事项，有一点感触，这里先简单总结下常见测试方法的目的，大致包括如下几类。\n1. 研发流程中构建环节\n 冒烟测试\n该术语，取自集成电路开发领域，集成电路在测试之前，先要加电检查，如果没有冒烟才能进行后续的测试。冒烟测试并不是测试过程的一个阶段，它是软件构建过程中的一个环节，它包含一些非常基础的测试，如保证编译通过、部分核心用例通过，它随每次构建触发，处于持续集成的一个环节。英文表述为BVT测试，Build Verification Testing，从中更能感受的到。将其理解为测试的一个阶段，是一个巨大的误区。  2. 功能性指标相关测试\n  功能测试\n软件需求说明中对软件需要的功能进行了描述，软件需求分析阶段会对需求说明进行详细分析，并整理出相关的规格说明，包括每个用例的输入、输出等等。功能测试，其实也就是对这里的软件需求规格说明进行测试用例的覆盖，考察的是对各个点、异常路径的把控程度。在实际研发过程中，开发人员一般会先自测通过后，再转给测试团队进行进一步的测试。\n  回归测试\n之前已经测试过的用例，可以沉淀下来，供以后进行回归，已发现软件变更、升级期间是否引入了bug。\n  其他\n  3. 非功能性指标相关测试\n     性能测试 (how much + how fast)\n对软件的性能指标进行测试，以验证是否达到预期设计的性能要求。在软件设计之初，需求方一般会提出明确的性能要求，如希望支撑N个用户的并发访问请求，希望响应时间能控制在2s以内等等。除了用户提出的性能指标要求，软件设计人员在系统设计的时候，也会对系统中交互的各个子系统、组件之间的性能有一定要求，如各组件通信响应时间在100ms以内等。\n性能测试，是对系统的一个检验，检验是否达到了预期的设计标准。性能测试，通常可以参考系统最大吞吐量时的请求量级、响应时间，来确定系统的最佳运行点，科学合理地部署设备资源来平衡性能和成本。\n性能测试，通常会和负载测试、压力测试等结合起来，以获得系统的最佳运行点、系统最大负载点、系统崩溃点。\n  负载测试 (how much)\n在性能测试请求量基础上进一步增大请求量，直到系统吞吐量不随请求量增加而增加（而是下降）。这个临界点就是最大负载点，表示系统当前已经满负荷运行，继续增大请求量的话，请求处理就会变得更慢。\n  压力测试 (how much)\n在压力测试的基础上，继续增大请求量，以检验系统的耐压能力，请求量的继续增大，意味着会消耗更多的系统资源，如内存、CPU、网卡等等，资源不足肯定会影响到请求处理，服务本身需要具备一定的过载保护能力，如限制入连接数、入请求数等，服务本身如果不够健壮的话，极有可能会导致拒绝响应，如内存不足频繁GC甚至影响到了正常请求处理无法响应。\n系统无法做出响应的点，即为系统崩溃点，请求量继续增加系统将无法做出响应。\n  可用性测试\n系统的可用性，表示系统在任意指定的时间点，系统是否可用，通常有N个9来表示，如系统达到5个9的可用性，表示系统全年只有365x24x3600x(1-0.99999)=315s=5min的不可用时间。\n服务级别协议（service-level agreement，缩写SLA）也称服务等级协议、服务水平协议，是服务提供商与客户之间定义的正式承诺。服务提供商与受服务用户之间具体达成了承诺的服务指标——质量、可用性、责任。SLA最常见的组成部分是以合同约定向客户提供的服务。例如，互联网服务供应商（ISP）和电信公司通常在与客户的合同条款内包含简单定义的服务级别协议。在此事例下，SLA通常定义有平均故障间隔（MTBF）、平均修复时间或平均修复时间（MTTR）；哪一方负责报告错误与支付费用；吞吐量；抖动；或类似的可衡量细节。 通常，服务提供商需要有SLA保证客户权益。\n  稳定性测试\n稳定性测试，是用来验证产品在一定的负载下，是否能够长时间的稳定性运行，其主要目的是验证能力，并在验证过程中发现系统不稳定的因素并进行分析解决。\n  安全测试\n对系统进行安全性相关的测试，如敏感权限、sql注入、csrf供给、api鉴权、有漏洞的不安全组件等等，通常这是一个系统性的工程，需要有专业团队来支撑，并提供安全相关的服务供业务团队接入使用。\n  软件研发流程中的各个阶段，仔细观察之后你会发现，每一环都与软件最终交付质量息息相关。了解并掌握各个阶段常见的一些系统性测试方法，是非常有必要的。\n'}),a.add({id:394,href:"/blog/2020-06-27-%E4%B8%AD%E5%9B%BD%E4%BA%BA%E8%A6%81%E5%AD%A6%E7%9D%80%E5%8B%87%E6%95%A2%E8%AE%B2%E7%9C%9F%E8%AF%9D/",title:"中国人要学着勇敢讲真话",description:"中国人什么时候都敢于讲话、讲真话、敢质疑的时候，再谈屹立于世界民族之林。",content:"最近苟晶被冒名顶替上大学的事情，成为社会关注焦点，作为山东老乡，也忍不住回想起求学时的一些经历，一些从内心里颠覆我认知、改变我看法的经历。有时，我会觉得自己是不是过于理想主义，是不是有点愤世嫉俗，不接地气，就算是吧。一个人思想的转变，肯定也是有原因的。\n那年我还上初中，当时学校正在搞数学竞赛吧，我对这玩意真的不是很感兴趣，也没有认真去准备，学校组织考试的时候也没有竞争过其他同学，也不出我意外。但是，我数学应该还挺好的吧，也比较聪明吧，但是我对这种无脑地做题竞赛真的不感兴趣。当时，我的数学老师找到我希望我继续参加后续相关的培训、竞赛，我说我没通过筛选。老师劝我说之前也有同学开始成绩不好后面取得好成绩的，还答应说给我争取一个名额，怎么争取呢？就是让一个通过筛选的女同学让给我，额，被我婉言拒绝了……\n这只是发生在我身上的一个老师私自做主、让度学生利益的一个案例，为了“出成绩”，老师似乎并不是很在乎个别学生的利益。现在已经13年过去了，我不想评价当年老师的做法有多么不好，我只是想指出这样的情况发生在学生身上，是有多么地轻描淡写。不要觉得这是个小事，“度”严重到一定程度，也可能会酿成像受害人苟晶一样的恶性事件，本属于你的教育经历被偷走，人生被乱涂一笔，你会不会愤怒？\n上高二那年，大家应该有相似的经历，就是上午上完第二节课是要跑操的。上午第三节课，我们班刚好是体育课，所以跑完操就直接带队到了操场。操场里面有个同学仰面躺在地上，穿着一身运动服，脸色苍白，没有任何喘息……他的时间停止在了那一天。没有校医的急救，大家都在等医院的医生到来，包括周围围观的几名体育老师。过了15~20分钟吧，医生来了，做了下心肺按压后，医生说，有点晚了可能不行了。医生让我们周围几名同学把这位同学抬上救护车想再抢救一下……\n我亲手将这名同学抬上救护车，也还记得他穿着一身黄色的运动服，已经记不清他的脸，比我低一届吧。我也不知道他是因何而死，学校要求师生统一口径“先天性心脏病”。后面听说是因为在网吧通宵，后面跑操时猝死，跟老师请假不参加跑操老师没同意。这个事情很难评价，作为一名老师也很难预见这样的情况。至于学校统一口径的做法，我一开始并没过多思考，但是当我看到去世学生的父母跪在学校门口，哭喊着还我孩子的时候，我开始慢慢产生了一些质疑。\n大一那年，百度首页有条消息，是关于我们高中的，“邹平一中谈话死”。事情大致是这样的，一名高中生在课外活动时观看班主任老师打篮球，班主任一个球没投进，这个球在很多打球的同学来看应该是很容易进的一个球,这名同学随手说了句“臭手”。其班主任听到后在操场当着很多人的面直接扇耳光教训，还不解气，又在晚自习时，将该同学叫到偏僻处继续体罚。这名班主任踹了学生一脚，力有多大就不讨论了，总之学生倒地后头部严重受伤死亡……但是，学校还是那老一套做法，先天性心脏病。当我看到多方爆料的消息之后，一下子就联想起当年那位低我一届、冰冷地躺在地上、没有施加任何急救措施、也是以“先天性心脏病”被了事的同学，我觉得学校是不是在做缺德事了？\n这次，我选择站在学生这边，积极地跟进相关事态的报道，了解相关的信息发展。一开始我就没有选择继续相信学校，或者说继续盲目地相信学校，这些都源于我此前的经历在我内心深处埋下的质疑。我不相信一名身体健康的学生兼班长，会犯什么罪大恶极的事情，也不会来个突然猝死，更不会相信一个身体部位严重受伤的同学是因为先天性心脏病。我只有一种想法，那就是这名班主任老师、学校领导们背后达成了某种“默契”，选择继续做一次缺德事。最后随着关注度的提高，陆陆续续地消息被爆料出来，医院、警察、社区论坛、新闻媒体，有些被金钱利益收买，有些选择了良知……最后，涉事老师自首了！\n那些为死去同学争夺真相、尊严的同学们，我这辈子都对他们表示敬佩，如果没有他们的良知、不屈，这名意外去世的同学也只能是作为一粒尘埃淹没在一浪又一浪的谎言中。\n现在，应该有很多人能理解我内心深处的一些愤世嫉俗，或者傲慢，或者偏见了，并非我见不得和谐社会好，并非我不知理想与现实有差距，并非我不知发展要循序渐进。只是，我不再愿意轻易说妥协，尤其是你明明做了才60分，却天天彪炳千秋、延迟或拒绝改变的时候！父母离开之后，你将直面死亡，我们二三十来岁的人，很多人对死亡是没有什么特别的感受的，可能很多人没有见过在病魔面前，一个健壮的成年人是如何一步步走向衰弱离开，大致上也不知道生命有多脆弱，或者有多坚韧。\n我其实不想经历这些，他对我来说是挫折，另一方面也淬炼了我，我用我的生命做赌注，我永远压在真相这边！也希望，中国的年轻人不要怕事，要敢于讲出自己的想法，社会发展、国家未来靠的是创新，如果你们都不敢发声，难道我们要靠80、90岁的老爷爷们吗，还是要去刨祖坟把敢说真话的人刨出来？当一个社会只有一种声音的时候，不被理解的人也就成了另类，像什么思辨、创意、创造，也就基本与未来无缘了。今天的你们选择闭嘴，明天你们的孩子就只能把嘴缝起来才会安全了！\n"}),a.add({id:395,href:"/tags/%E4%BA%BA%E6%80%A7/",title:"人性",description:"",content:""}),a.add({id:396,href:"/tags/%E6%96%87%E6%98%8E/",title:"文明",description:"",content:""}),a.add({id:397,href:"/tags/%E6%AD%A3%E7%9B%B4/",title:"正直",description:"",content:""}),a.add({id:398,href:"/tags/cmd/",title:"cmd",description:"",content:""}),a.add({id:399,href:"/tags/cobra/",title:"cobra",description:"",content:""}),a.add({id:400,href:"/tags/flag/",title:"flag",description:"",content:""}),a.add({id:401,href:"/tags/flagset/",title:"flagset",description:"",content:""}),a.add({id:402,href:"/blog/2020-06-26-%E5%A6%82%E4%BD%95%E9%AB%98%E6%95%88%E5%BC%80%E5%8F%91%E4%B8%80%E4%B8%AA%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/",title:"如何高效开发一个命令行工具",description:"如何高效开发一个命令行工具呢？需要能支持子命令，选项要支持长短两种形式，需要能自动生成help信息，包括对命令的说明、选项的说明，需要支持不分选项可走配置文件，需要能很方便地扩展新功能……别慌，听我慢慢道来。",content:"我经常会开发一些命令行工具来协助处理一些事情，如开发一个代码生成工具快速生成服务代码，或者开发一个工具来方便管理github上的工具，或者开发一个工具rm来替换掉不安全的rm，等等。\n命令行工具开发过程中，比较常见的一个问题就是对功能进行分组，开发多个命令不利于使用，在命令中支持子命令是一个更常见、更友好的做法，如go build，go tool，go pprof，等等。我们还希望为不同的子命令添加不同的命令行选项，如go build -gcflags=，go pprof --seconds=，等等。\n如何支持子命令字呢？ # 假如我们开发一个命令行程序 gox，我们希望能为它添加一个子命令gox create来创建一个完整的服务工程，包括自动生成工程下的代码。\n那如何为命令行程序gox添加这个子命令字呢？\ngox是shell搜索路径定位到的程序，create只能是shell传递给进程的一个普通参数，在gox程序启动之后只能从os.Args来获取该参数，以及后续gox create -protofile= -protodir的参数-protofile及-protodir。\n然后呢，为了方便以后扩展其他子命令，我们最好将subcmd进行一下抽象，通过一个Command interface{}约定好一个subcmd必须要完成那些操作。接口并不是为了抽象而抽象，而是用来清晰地表明要做什么。\n// Command what does a command do type Command interface{ // PreRun run before the command logic execution PreRun() error // Run run the command logic Run() error // PostRun run after the command logic execution PostRun() error } // BaseCommand basic implemention // // this BaseCommand could be embeded into a customized subcmd type BaseCommand struct{ } func (bc *BaseCommand) PreRun() error { return nil } func (bc *BaseCommand) Run() error { panic(\u0026quot;implement me\u0026quot;) } func (bc *BaseCommand) PostRun() error { return nil }  Command接口定义了一个command应该干什么，然后也可以提供一个基本的Command实现BaseCommand，它提供了一些基本的操作可以供后续复用，后面我们要扩展其他子命令字的时候，通过将该BaseCommand嵌入，可以少实现几个函数，这也是go里面提倡的通过组合来实现继承。\n现在我们实现一个CreateCmd：\ntype CreateCmd struct { *BaseCommand } func NewCreateCmd() Command { return \u0026amp;CreateCmd{ \u0026amp;BaseCommand{}, } } func (c *CreateCmd) Run() error { println(\u0026quot;create cmd running\u0026quot;) // execute the logic of create cmd println(\u0026quot;create cmd finished\u0026quot;) }  那我们怎么在执行gox create的时候运行CreateCmd.Run()方法呢？\nvar cmds map[string]Command = { \u0026quot;create\u0026quot;: NewCreateCmd, } func main() { args := os.Args[1:] if len(args) == 0 { panic(\u0026quot;invalid subcmd\u0026quot;) } cmd, ok := cmds[args[0]] if !ok { panic(fmt.Errorf(\u0026quot;cmd: %s not registered\u0026quot;, args[0])) } if err := cmd.PreRun(); err != nil { panic(err) } if err := cmd.Run(); err != nil { panic(err) } if err := cmd.PostRun(); err != nil { panic(err) } }  是不是很简单？本来就很简单 :)\n如何为子命令字添加不同的选项呢？ # 那现在要给各个子命令字添加独立的命令行选项怎么办呢？比如gox create的命令参数和gox update的命令行参数是不同的，那怎么办呢？你当然可以根据os.Args[1:]来解析，想怎么解析都可以，我们这里讨论如何借助go标准库提供的flag包来解析。\n大家可能都使用过flag.Parse()来解析命令行参数，这个函数其实是将os.Args[1:]中的参数解析完后填充到一个默认的flagset。如果要为不同的子命令添加不同的命令行选项，那么为每个子命令创建独立的flagset就可以了。各个子命令使用自己的flagset来执行flagset.Parse()代替flag.Parse()就可以了。\n就这么简单，我们对前面的程序进行一点调整：\nCommand接口增加命令参数解析接口：\n// Command what does a command do type Command interface{ // ParseFlags parse flags into command's own flagset ParseFlags(os.Args) ... }  BaseCommand 添加一个参数解析的方法，给自定义子命令字复用\n// BaseCommand basic implemention // // this BaseCommand could be embeded into a customized subcmd type BaseCommand struct{ flagSet *flag.FlagSet } func (bc *BaseCommand) ParseFlags(args os.Args) error { return bc.flagset.Parse(args) } ...  为create子命令创建独立的flagset来解析参数\nfunc NewCreateCmd() error { fs := flag.NewFlagSet(\u0026quot;create\u0026quot;, flag.PanicOnError), fs.String(\u0026quot;protofile\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to process\u0026quot;) fs.String(\u0026quot;protodir\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to search）\u0026quot; return \u0026amp;CreateCmd{ \u0026amp;BaseCommand{ flagSet: fs, } } }  程序启动的时候统一解析命令行参数：\nfunc main() { ... // parse the flags if err := cmd.ParseFlags(args[1:]; err != nil { panic(err) } ... }  这样就完成了，是不是很简单，本来就很简单。\n如何显示命令帮助信息？ # 当然了，只能运行命令还不行，有多少注册的子命令可执行？每个子命令有什么命令行参数呢？我们还需要能够显示命令行的帮助信息。\n这个怎么实现呢？各个子命令需要能够指明命令的使用帮助：\n 一个简单的表述，以供我们显示gox包含的各个子命令字的使用信息； 一个详细的描述，以供我们显示gox help create时的各个选项的帮助信息；  我们的代码简单做下调整就可以支持到。\n添加Usage、UsageLong方法：\ntype Command interface{ ... // 返回简单的帮助信息 Usage() string // 返回详细的帮助信息 UsageLong() string }  然后为BaseCommand添加两个字段：\ntype BaseCommand struct{ ... Usage string UsageLong string } ... func (bc *BaseCommand) Usage() string { return bc.Usage } func (bc *BaseCommand) UsageLong() string { return bc.UsageLong }  为createCmd添加帮助信息：\nfunc NewCreateCmd() Command { fs := flag.NewFlagSet(\u0026quot;create\u0026quot;, flag.PanicOnError), fs.String(\u0026quot;protofile\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to process\u0026quot;) fs.String(\u0026quot;protodir\u0026quot;, \u0026quot;\u0026quot;, \u0026quot;protofile to search）\u0026quot; return \u0026amp;CreateCmd{ \u0026amp;BaseCommand{ flagSet: fs, Usage: 'create a project', UsageLong: 'create a project quickly.\\n\\n'+ fs.FlagUsages(), } } }  然后呢，为了能够使用帮助信息，我们需要添加一个help命令字：\ntype HelpCmd struct{ cmd string } func NewHelpCmd() Command { return \u0026amp;HelpCmd{ \u0026amp;BaseCommand{}, } } func (c *HelpCmd) ParseFlags(args os.Args) error { cmd = args[1:] } func (c *HelpCmd) Run() error { // help specific subcmd if len(c.cmd) != 0 { v, ok := cmds[c.cmd] if !ok { return fmt.Errorf(\u0026quot;cmd: %s not registered\u0026quot;, c.cmd) } println(v.UsageLong()) } // help all subcmds for _, v := range cmds { println(v.Usage()) } }  然后呢，我们主程序启动的时候执行gox 或 gox help都执行help命令：\nfunc main() { args := os.Args[1:] if len(args) == 0 { cmds[\u0026quot;help\u0026quot;].Run() } ... }  嗯，就这些了，是不是很简单？本来就很简单。\n小结 # 当然，除了这些，我们可能还希望为命令行工具添加shell auto-completion输入补全功能，提示信息的国际化、本地化，命令字扩展时的便利程度等，还是有些问题需要进一步考虑的。\n我这里只是介绍下实现的一个大致思路，具体实践的时候倒并不一定要这么去实现，可以考虑下cobra，通过cobra来实现posix风格的命令行是很方便的。这些内容感兴趣的话可以自己了解下。\n和本文内容接近的，可以参考我的一个工具rm-safe，希望对读者朋友有帮助！\n"}),a.add({id:403,href:"/tags/%E4%BA%BA%E7%94%9F/",title:"人生",description:"",content:""}),a.add({id:404,href:"/tags/%E7%88%B6%E4%BA%B2/",title:"父亲",description:"",content:""}),a.add({id:405,href:"/blog/2020-06-21-%E7%88%B6%E4%BA%B2%E8%8A%82%E4%BA%8E%E6%88%91%E5%B7%B2%E6%98%AF%E7%A7%8D%E5%A5%A2%E4%BE%88/",title:"父亲节，于我已是种奢侈",description:"img {width:640px;}  昨天是周六，优化了一下代码生成工具gorpc，解决了几个遗留的问题，总算是做了点有意思的事情，心里有点窃喜。临睡前，掏出手机，惯例地刷了刷推送的消息，原来明天是父亲节了。心里忍不住被扎了一下，父亲节，于我已是种奢侈。30岁的年纪，或好或坏，或小有成绩或满怀迷茫，不管怎样，至少你们还有父亲，我只能在一个人的时候才能去享受下那久违的回忆，那些有父亲的时光。\n在我还很小的时候，家里很是拮据，父母很辛苦，为了维持一家人生活，父母付出了很多。父母的辛苦，在我很小的时候就埋进了心底……如今，二三十年过去，那每逢下雨就要滴滴答答漏水的矮旧房子不见了，那为了维持生计的小卖部柜台、一斤一两积攒收入的称也不见了，那些养过兔子的笼子、养过猪马的破旧草房、人力打水的小压井、黑咕隆咚的饭屋（厨房），还有那棵一人抱不过腰身的大槐树，大槐树下的狗屋（小黑的屋），都不见了。现在依稀还能回想起它们的样子，甚至还记得，那个拿着鞭炮吓唬小黑的我，那个压不动小压井、跳起来压水的我。它们都不见了，变成了现在宽敞明亮、便利方便的大房子，那是父母一点一滴打拼的结果，现在却唯独少了他。",content:" img {width:640px;}  昨天是周六，优化了一下代码生成工具gorpc，解决了几个遗留的问题，总算是做了点有意思的事情，心里有点窃喜。临睡前，掏出手机，惯例地刷了刷推送的消息，原来明天是父亲节了。心里忍不住被扎了一下，父亲节，于我已是种奢侈。30岁的年纪，或好或坏，或小有成绩或满怀迷茫，不管怎样，至少你们还有父亲，我只能在一个人的时候才能去享受下那久违的回忆，那些有父亲的时光。\n在我还很小的时候，家里很是拮据，父母很辛苦，为了维持一家人生活，父母付出了很多。父母的辛苦，在我很小的时候就埋进了心底……如今，二三十年过去，那每逢下雨就要滴滴答答漏水的矮旧房子不见了，那为了维持生计的小卖部柜台、一斤一两积攒收入的称也不见了，那些养过兔子的笼子、养过猪马的破旧草房、人力打水的小压井、黑咕隆咚的饭屋（厨房），还有那棵一人抱不过腰身的大槐树，大槐树下的狗屋（小黑的屋），都不见了。现在依稀还能回想起它们的样子，甚至还记得，那个拿着鞭炮吓唬小黑的我，那个压不动小压井、跳起来压水的我。它们都不见了，变成了现在宽敞明亮、便利方便的大房子，那是父母一点一滴打拼的结果，现在却唯独少了他。\n"}),a.add({id:406,href:"/blog/2020-06-09-a-golang-debugger-book/",title:"A Golang Debugger Book",description:"18年开始学习go时，发现了一款调试器delve，陆陆续续地看了些源码、调试标准的东西，发现调试器是一个很好的切入视角来认识计算机系统，就想把这些东西理顺、分享一下。到现在为止，对开发工具链的认识都还有些认识上的不足，关键还是，觉得调试器就好比一个放大镜，放大一倍看清内存变量，放大两倍看清类型系统，放大三倍看清机器物理结构……这是简单的，涉及到运行时、操作系统、硬件等的特性，我是觉得很有意思，尤其是对部分想了解这些知识的人来说，还是有一定的参考意义的。\nhttps://github.com/hitzhangjie/golang-debugger-book。\n后来工作变动没有持续投入了，19年下半年支持trpc也没太多时间投入，19年年底的时候买了ipad花了连续几个周末啃了300页dwarf标准，坚持写完了dwarf相关的部分。后面开始支持epc又没时间了……\n现在各项工作陆陆陆续续有了眉目，也想把之前放下的东西再捡起来，感兴趣可以简单翻下，如果有小伙伴也有兴趣的话，欢迎业余时间一起继续下去，倒不是觉得是项多么出彩的内容，就是觉得有些值得深究的东西想去探索一下，还有就是一项工作搁置太久会有很浓的挫败感。\n腾讯的小伙伴们很优秀，如果能有小伙伴们助攻，这个应该会加速很多。\n  dwarf v4标准解析 已完成\n  dwarf数据提取 go标准库已提供\n  delve源码解析 一小部分\n  go类型系统、运行时、调试器结合 待补充\n  go新版本准备切换dwarf v5、更好的linker，有些相关的知识，涉及到compiler、linker、debugger的协作\u0026hellip;\n  其他\n  其实，还有很多内容要补充，我也不知道最终会变成啥样，可能就是现在这样……曾经试图邀请几个小伙伴来搞下，可能本身没什么吸引力吧，最终还是这样。\n感兴趣才能坚持下去，每次想到它，都有种立即想投入的冲动，一个人的周末有点有限 :)",content:"18年开始学习go时，发现了一款调试器delve，陆陆续续地看了些源码、调试标准的东西，发现调试器是一个很好的切入视角来认识计算机系统，就想把这些东西理顺、分享一下。到现在为止，对开发工具链的认识都还有些认识上的不足，关键还是，觉得调试器就好比一个放大镜，放大一倍看清内存变量，放大两倍看清类型系统，放大三倍看清机器物理结构……这是简单的，涉及到运行时、操作系统、硬件等的特性，我是觉得很有意思，尤其是对部分想了解这些知识的人来说，还是有一定的参考意义的。\nhttps://github.com/hitzhangjie/golang-debugger-book。\n后来工作变动没有持续投入了，19年下半年支持trpc也没太多时间投入，19年年底的时候买了ipad花了连续几个周末啃了300页dwarf标准，坚持写完了dwarf相关的部分。后面开始支持epc又没时间了……\n现在各项工作陆陆陆续续有了眉目，也想把之前放下的东西再捡起来，感兴趣可以简单翻下，如果有小伙伴也有兴趣的话，欢迎业余时间一起继续下去，倒不是觉得是项多么出彩的内容，就是觉得有些值得深究的东西想去探索一下，还有就是一项工作搁置太久会有很浓的挫败感。\n腾讯的小伙伴们很优秀，如果能有小伙伴们助攻，这个应该会加速很多。\n  dwarf v4标准解析 已完成\n  dwarf数据提取 go标准库已提供\n  delve源码解析 一小部分\n  go类型系统、运行时、调试器结合 待补充\n  go新版本准备切换dwarf v5、更好的linker，有些相关的知识，涉及到compiler、linker、debugger的协作\u0026hellip;\n  其他\n  其实，还有很多内容要补充，我也不知道最终会变成啥样，可能就是现在这样……曾经试图邀请几个小伙伴来搞下，可能本身没什么吸引力吧，最终还是这样。\n感兴趣才能坚持下去，每次想到它，都有种立即想投入的冲动，一个人的周末有点有限 :)\n"}),a.add({id:407,href:"/tags/golang/",title:"golang",description:"",content:""}),a.add({id:408,href:"/tags/tencent/",title:"tencent",description:"",content:""}),a.add({id:409,href:"/tags/work/",title:"work",description:"",content:""}),a.add({id:410,href:"/blog/2020-06-05-%E6%88%91%E5%9C%A8%E8%85%BE%E8%AE%AF%E8%BF%99%E5%87%A0%E5%B9%B4/",title:"我在腾讯这几年",description:"img {width:680px;} video {width:680px;}  写在前面 # 很长一段时间没有更新个人博客了，回头一看竟然有一年没更新，这一年工作上确实比以前忙了很多。有点时间也拿来体验生活、钻研感兴趣的技术了。感兴趣也可以看下我的github，这一年几乎也在不停地探索、尝试，因为兴趣和那份好奇，还有就是，想做点有深度的东西取悦自己。\n自从2016年7月份入职腾讯以来，也算是勤勤恳恳地工作，至少不让自己成为团队的瓶颈吧，事实上做的应该还可以吧。当然和自己的兴趣、领导的指点、工作项的安排，也有密切的关系，绝大部分工作时间，我还是比较开心的。\n今天收拾房间，无意中发现了腾讯学院的一个笔记本，翻开一看，原来是16年刚入职时培训用的材料，里面还有自己的笔记，字迹还清晰，算不上太工整。翻开新的一页，忍不住想写点什么，有感激，有欣赏，有郁闷，也有质疑，最后竟也无法落笔。\n2016年7月，我入职了 # 最早想来腾讯还是一次实习生招聘会上，自己也没有准备，就大大咧咧去了，结果挂了。面试官我感觉还算比较专业吧，当时就想着毕业后去腾讯锻炼下吧。校招季，自己也没怎么认真准备，但是还是拿了好几个offer，新浪（SP？面试官很喜欢我还愿意替我和HR沟通薪资，最终因为新浪发offer太慢没去）、去哪儿（SP？当天给的offer，不太想去北京最后没去）、阿里天猫（没认真准备，给了个B+，被各种寒酸最后没去）、华为（我就是想去搞内核，凭学习能力应该没问题，但是去了估计也不是这个方向，没去）\u0026hellip;最后我想到腾讯上次实习给我挂了，在腾讯校招补录阶段的时候过了（SP）。\n我也不知道当初面这么多是为了什么，只是想证明下自己可以通过某些公司的面试？可能吧，人缺乏自信的时候，就容易做这些傻事，总是希望从别人口中的评价来认识自己。\n入职之前，我问早进来的同学，正式入职那天，我需要穿正装吗？结果当天来的时候发现有些人等电梯的时候，穿拖鞋的小哥，为了凉快，直接把脚踩地上。暗自庆幸，穿正装来了反而是个另类。\n 2016.7.24 入职+破冰 2016.7.25 开班典礼 + \u0026ldquo;腾讯用户导向\u0026quot;培训 2016.7.26 走进腾讯与腾讯文化 \u0026hellip;  十几天的封培，认识了很多同事，也大概了解了腾讯的一些文化、工作方式，这期间吃的也不错，我还想会不会我这常年120斤的体重也可以增重下了。\n封培结束时，也有部分总办领导来参加了闭幕式，还跳了一段。当时我觉得领导和一线工作人员能这么互动，应该工作氛围很不错，应该很有活力，当时对腾讯有很高的期望值，自己也愿意加入其中，贡献一点力量。\nYour browser doesn't support the video tag.  2016年8月，来到组织 # 封培结束后，来到当时的即通应用部/互动视频产品部，我就成了这里的一名后台开发，开始写自己的代码。当时我的导师磊哥，对我还是挺照顾的，还有leader，周围的小伙伴，他们的帮助下，我快速融入了团队。不过嘛，我来了快一周的时候，就忍不住想吐槽，当时做个消息推送的工具，调用的API竟然连个文档说明也没有。我是比较喜欢写文档的，一个是比较专业，一个是能减少不必要的沟通，何乐而不为。关键当时的API的负责人还贼难沟通，我也是服气，从那开始，就陆陆续续地认识了真实的腾讯，褒贬参半，比较真实。\n2016年10月，邀父母来深圳玩 # 我东西差不多准备好了之后，自己也开始挣钱了，想着父母一直勤勤恳恳工作，供我上学工作，现在可以请他们来深圳玩玩，以前父母也没有舍得出去玩过。我内心里是特别希望他们出来走走的，我也尽尽孝心。\n那时候家里面也挺忙的，爸爸没有过来，妈妈一个人过来了，我当时心里略有点遗憾，还想着爸爸你也不来，那就只能看妈妈在这玩的照片了，只能有羡慕的份了。和妈妈逛了深圳的几个比较好玩的地方，世界之窗、锦绣中华、动物园、深圳湾公园……妈妈走的那天，妈妈很开心，觉得我长大了，可以自己闯荡了，在这里呆了两周也想回家了。\n那次爸爸没有来，本来我想着后面有的是机会，可没想到竟然成了永远的遗憾。17年爸爸就走了，病痛折磨地父亲不轻，我第一次觉得生命是脆弱的，又是坚强的，生命是短暂的，又是无限的，正如我的父亲走了，但是他永远活在我心里，直到我也离开，直到这些文字丢失，淹没在互联网信息的大海里。\n2016年10月，组织架构调整 # 那天我发高烧，请了个病假，晚上导师给我电话说，我们组织架构调整，把我调到一个新的组里面了，我有点错愕。不过也还好，新leader、组内同事，都很不错，工作上对我指导都不少，特别是leader，是我学习计算机以来，少有的几个真心佩服的人，不管是领导能力，还是沟通、技术，都非常值得学习。\n2017年X月，最痛苦的一年 # 2017年，是我经历过的最痛苦的一年，我想可能也是我以后几十年中最痛苦的一年。如果人的记忆可以像日历那样，翻来翻去，我愿意撕去我的2017年。\n17年我看到爸爸被病魔折磨，爸爸走后，多少次做梦，不论前面的故事多好，最后总会变成父亲哭着不舍离开的画面，一次又一次从梦里醒来。我们平日里既没有单独晒过朋友圈，也没有留下多少照片。我感谢Apple创造的live photos，让我还能未来几十年间一遍又一遍地看到父亲的音容笑貌，我的设备里还有2段爸爸的音频，那是我仅有的贵重的东西，担心它丢失，所有的设备、移动硬盘、云存储、微信、qq中都做了备份。这些，就是我仅有的东西，是我最重要的东西……其他的钱、房、股票，I don\u0026rsquo;t care.\n爸爸的离开，对于他来说，是种解脱，作为儿子，面对我深爱着的父亲，我说不出任何安慰的话，任何安慰的话都显得苍白无力，任何安慰的话都显得是对生命的不敬，更何况那是我的父亲，我能做的就是陪在他身旁，减轻他的疼痛、想念，也让他放心，让他放心我会照顾好妈妈。最开始，我想着，我需要挣钱给爸爸治病，陪爸爸做了第一次手术休养了一周，感觉好像在变好。我内心里充满了希望，回来更卖力的工作挣钱。让我感觉到绝望的不是自己没准备好，是在我充满希望的时候，现实一次次突破我希望的底线，一次又一次，从充满希望，到有一丁点希望，到没有希望想去试一下，到最后不愿接受不得不接受的事实真相……\n我从小到大，第一次感觉那么挫败，我没有能力挽救爸爸，脑海里无数次飘过父亲会怎样离开我们，我以为我做了最坏的打算，我以为我准备好了，事实上没有。爸爸，一定去了天堂，如果真的有天堂，有上帝，上帝一定会让他这样的好人去天堂！天堂不再有痛苦！\n不知不觉中，我的手机壁纸已经3年没有更换了！3年了！从来没有更换过！我已经习惯了每次拿出手机，都可以看到爸爸，我已经习惯了那个手机号码，多花了几千块钱把爸爸的手机号码转到了自己名下。家里爸爸用过的工具、躺椅、推车、扳手等，也都成了我视如生命的遗产。我不想家里有一丝一毫的改变，最好是封存这一切。有人说我还没走出来，其实不是，我的内心很强大，我只是选择了习惯有爸爸的生活，而不是像多数人一样扔掉烧掉来淡忘。我并没有往过去的伤口上撒盐，我只是想让这些疤痕更清晰一些，清晰到我看到摸到身边的东西时，就可以置身于2017年以前的时段，那里有我熟悉得不能再熟悉的爸爸。\n爸爸走后，我变成了家里的顶梁柱，我会努力丢掉小性子，成为他期望我成为的样子。18年春节回到家，翻看爸爸以前的记账本，第一页写着“干干净净做人，利利索索做事”，朴实中透漏出他的人格。我是他的儿子，那也是我的座右铭，“堂堂正正做人，踏踏实实做事”，这是06年读初中时，我的物理老师口授给我的，我一直印在心里。想想，也是种缘分，好像10来年后，我和爸爸一对暗号，原来是一样的！果然是父子俩！\n此后，也更全身心地投入到了工作当中，努力工作，努力挣钱，照顾家人，我觉得自己算是相对比较努力的了，希望爸爸在天之灵不会对我失望。\n17年，有同事参与赌博，拆东墙补西墙，向我借钱，结果还没偿还一分，就被公安带走了，自己才得知真相。17年各种事情，各种不确定性下，我决定先买套房做个后路，现在也没增值多少，不过也还可以。借了姨妈、姐姐他们些钱，也都还清了，没什么压力了。现在也陆陆续续地有了积蓄。\n17年下半年就是努力工作吧，尽力做到对的起领导的栽培、同事这段时间的帮助、包容，感谢了！\n2018年X月 # 认真工作，做好业务+学习技术 # 上半年，也算是认认真真的工作，认真做好产品的业务需求，认真维护好常用的管理后台，包括相关的后端框架jungle-admin的维护、前端使用体验的优化，我自己觉得还是做了些工作的，方便了大家的开发效率，提升了使用体验。\n我们leader（现在已经是总监了），对技术很有钻研，也很有创新能力，经常带领我们高些比较有建设性的东西，比如接口测试工具、代码生成工具、微服务框架设计开发等等吧，很多。在这期间，自己也锻炼了很多，成长了很多。当然也很开心，学到东西就很开心。\n这一次，我收获了来腾讯后的第一个四星，很开心。\n拥抱变化，加入内容平台中心 # 18年上半年，互动视频相关的建设基本比较稳定了，业务上也没有那么紧张了，7月份之后吧，我们又拥抱变化，加入了内容平台中心来支持信息流相关的内容中台建设，直到现在。",content:" img {width:680px;} video {width:680px;}  写在前面 # 很长一段时间没有更新个人博客了，回头一看竟然有一年没更新，这一年工作上确实比以前忙了很多。有点时间也拿来体验生活、钻研感兴趣的技术了。感兴趣也可以看下我的github，这一年几乎也在不停地探索、尝试，因为兴趣和那份好奇，还有就是，想做点有深度的东西取悦自己。\n自从2016年7月份入职腾讯以来，也算是勤勤恳恳地工作，至少不让自己成为团队的瓶颈吧，事实上做的应该还可以吧。当然和自己的兴趣、领导的指点、工作项的安排，也有密切的关系，绝大部分工作时间，我还是比较开心的。\n今天收拾房间，无意中发现了腾讯学院的一个笔记本，翻开一看，原来是16年刚入职时培训用的材料，里面还有自己的笔记，字迹还清晰，算不上太工整。翻开新的一页，忍不住想写点什么，有感激，有欣赏，有郁闷，也有质疑，最后竟也无法落笔。\n2016年7月，我入职了 # 最早想来腾讯还是一次实习生招聘会上，自己也没有准备，就大大咧咧去了，结果挂了。面试官我感觉还算比较专业吧，当时就想着毕业后去腾讯锻炼下吧。校招季，自己也没怎么认真准备，但是还是拿了好几个offer，新浪（SP？面试官很喜欢我还愿意替我和HR沟通薪资，最终因为新浪发offer太慢没去）、去哪儿（SP？当天给的offer，不太想去北京最后没去）、阿里天猫（没认真准备，给了个B+，被各种寒酸最后没去）、华为（我就是想去搞内核，凭学习能力应该没问题，但是去了估计也不是这个方向，没去）\u0026hellip;最后我想到腾讯上次实习给我挂了，在腾讯校招补录阶段的时候过了（SP）。\n我也不知道当初面这么多是为了什么，只是想证明下自己可以通过某些公司的面试？可能吧，人缺乏自信的时候，就容易做这些傻事，总是希望从别人口中的评价来认识自己。\n入职之前，我问早进来的同学，正式入职那天，我需要穿正装吗？结果当天来的时候发现有些人等电梯的时候，穿拖鞋的小哥，为了凉快，直接把脚踩地上。暗自庆幸，穿正装来了反而是个另类。\n 2016.7.24 入职+破冰 2016.7.25 开班典礼 + \u0026ldquo;腾讯用户导向\u0026quot;培训 2016.7.26 走进腾讯与腾讯文化 \u0026hellip;  十几天的封培，认识了很多同事，也大概了解了腾讯的一些文化、工作方式，这期间吃的也不错，我还想会不会我这常年120斤的体重也可以增重下了。\n封培结束时，也有部分总办领导来参加了闭幕式，还跳了一段。当时我觉得领导和一线工作人员能这么互动，应该工作氛围很不错，应该很有活力，当时对腾讯有很高的期望值，自己也愿意加入其中，贡献一点力量。\nYour browser doesn't support the video tag.  2016年8月，来到组织 # 封培结束后，来到当时的即通应用部/互动视频产品部，我就成了这里的一名后台开发，开始写自己的代码。当时我的导师磊哥，对我还是挺照顾的，还有leader，周围的小伙伴，他们的帮助下，我快速融入了团队。不过嘛，我来了快一周的时候，就忍不住想吐槽，当时做个消息推送的工具，调用的API竟然连个文档说明也没有。我是比较喜欢写文档的，一个是比较专业，一个是能减少不必要的沟通，何乐而不为。关键当时的API的负责人还贼难沟通，我也是服气，从那开始，就陆陆续续地认识了真实的腾讯，褒贬参半，比较真实。\n2016年10月，邀父母来深圳玩 # 我东西差不多准备好了之后，自己也开始挣钱了，想着父母一直勤勤恳恳工作，供我上学工作，现在可以请他们来深圳玩玩，以前父母也没有舍得出去玩过。我内心里是特别希望他们出来走走的，我也尽尽孝心。\n那时候家里面也挺忙的，爸爸没有过来，妈妈一个人过来了，我当时心里略有点遗憾，还想着爸爸你也不来，那就只能看妈妈在这玩的照片了，只能有羡慕的份了。和妈妈逛了深圳的几个比较好玩的地方，世界之窗、锦绣中华、动物园、深圳湾公园……妈妈走的那天，妈妈很开心，觉得我长大了，可以自己闯荡了，在这里呆了两周也想回家了。\n那次爸爸没有来，本来我想着后面有的是机会，可没想到竟然成了永远的遗憾。17年爸爸就走了，病痛折磨地父亲不轻，我第一次觉得生命是脆弱的，又是坚强的，生命是短暂的，又是无限的，正如我的父亲走了，但是他永远活在我心里，直到我也离开，直到这些文字丢失，淹没在互联网信息的大海里。\n2016年10月，组织架构调整 # 那天我发高烧，请了个病假，晚上导师给我电话说，我们组织架构调整，把我调到一个新的组里面了，我有点错愕。不过也还好，新leader、组内同事，都很不错，工作上对我指导都不少，特别是leader，是我学习计算机以来，少有的几个真心佩服的人，不管是领导能力，还是沟通、技术，都非常值得学习。\n2017年X月，最痛苦的一年 # 2017年，是我经历过的最痛苦的一年，我想可能也是我以后几十年中最痛苦的一年。如果人的记忆可以像日历那样，翻来翻去，我愿意撕去我的2017年。\n17年我看到爸爸被病魔折磨，爸爸走后，多少次做梦，不论前面的故事多好，最后总会变成父亲哭着不舍离开的画面，一次又一次从梦里醒来。我们平日里既没有单独晒过朋友圈，也没有留下多少照片。我感谢Apple创造的live photos，让我还能未来几十年间一遍又一遍地看到父亲的音容笑貌，我的设备里还有2段爸爸的音频，那是我仅有的贵重的东西，担心它丢失，所有的设备、移动硬盘、云存储、微信、qq中都做了备份。这些，就是我仅有的东西，是我最重要的东西……其他的钱、房、股票，I don\u0026rsquo;t care.\n爸爸的离开，对于他来说，是种解脱，作为儿子，面对我深爱着的父亲，我说不出任何安慰的话，任何安慰的话都显得苍白无力，任何安慰的话都显得是对生命的不敬，更何况那是我的父亲，我能做的就是陪在他身旁，减轻他的疼痛、想念，也让他放心，让他放心我会照顾好妈妈。最开始，我想着，我需要挣钱给爸爸治病，陪爸爸做了第一次手术休养了一周，感觉好像在变好。我内心里充满了希望，回来更卖力的工作挣钱。让我感觉到绝望的不是自己没准备好，是在我充满希望的时候，现实一次次突破我希望的底线，一次又一次，从充满希望，到有一丁点希望，到没有希望想去试一下，到最后不愿接受不得不接受的事实真相……\n我从小到大，第一次感觉那么挫败，我没有能力挽救爸爸，脑海里无数次飘过父亲会怎样离开我们，我以为我做了最坏的打算，我以为我准备好了，事实上没有。爸爸，一定去了天堂，如果真的有天堂，有上帝，上帝一定会让他这样的好人去天堂！天堂不再有痛苦！\n不知不觉中，我的手机壁纸已经3年没有更换了！3年了！从来没有更换过！我已经习惯了每次拿出手机，都可以看到爸爸，我已经习惯了那个手机号码，多花了几千块钱把爸爸的手机号码转到了自己名下。家里爸爸用过的工具、躺椅、推车、扳手等，也都成了我视如生命的遗产。我不想家里有一丝一毫的改变，最好是封存这一切。有人说我还没走出来，其实不是，我的内心很强大，我只是选择了习惯有爸爸的生活，而不是像多数人一样扔掉烧掉来淡忘。我并没有往过去的伤口上撒盐，我只是想让这些疤痕更清晰一些，清晰到我看到摸到身边的东西时，就可以置身于2017年以前的时段，那里有我熟悉得不能再熟悉的爸爸。\n爸爸走后，我变成了家里的顶梁柱，我会努力丢掉小性子，成为他期望我成为的样子。18年春节回到家，翻看爸爸以前的记账本，第一页写着“干干净净做人，利利索索做事”，朴实中透漏出他的人格。我是他的儿子，那也是我的座右铭，“堂堂正正做人，踏踏实实做事”，这是06年读初中时，我的物理老师口授给我的，我一直印在心里。想想，也是种缘分，好像10来年后，我和爸爸一对暗号，原来是一样的！果然是父子俩！\n此后，也更全身心地投入到了工作当中，努力工作，努力挣钱，照顾家人，我觉得自己算是相对比较努力的了，希望爸爸在天之灵不会对我失望。\n17年，有同事参与赌博，拆东墙补西墙，向我借钱，结果还没偿还一分，就被公安带走了，自己才得知真相。17年各种事情，各种不确定性下，我决定先买套房做个后路，现在也没增值多少，不过也还可以。借了姨妈、姐姐他们些钱，也都还清了，没什么压力了。现在也陆陆续续地有了积蓄。\n17年下半年就是努力工作吧，尽力做到对的起领导的栽培、同事这段时间的帮助、包容，感谢了！\n2018年X月 # 认真工作，做好业务+学习技术 # 上半年，也算是认认真真的工作，认真做好产品的业务需求，认真维护好常用的管理后台，包括相关的后端框架jungle-admin的维护、前端使用体验的优化，我自己觉得还是做了些工作的，方便了大家的开发效率，提升了使用体验。\n我们leader（现在已经是总监了），对技术很有钻研，也很有创新能力，经常带领我们高些比较有建设性的东西，比如接口测试工具、代码生成工具、微服务框架设计开发等等吧，很多。在这期间，自己也锻炼了很多，成长了很多。当然也很开心，学到东西就很开心。\n这一次，我收获了来腾讯后的第一个四星，很开心。\n拥抱变化，加入内容平台中心 # 18年上半年，互动视频相关的建设基本比较稳定了，业务上也没有那么紧张了，7月份之后吧，我们又拥抱变化，加入了内容平台中心来支持信息流相关的内容中台建设，直到现在。\n清理了很多历史遗留问题，也做了一些架构设计、优化方面的工作，也得到了些锻炼。\n下半年，由于内部团队技术栈不统一，存在各种各样的问题，为了提升大家的开发效率、开发质量，我们开始准备把上半年自研的微服务框架goneat给打磨地更好。这半年，我们在这里面投入了很多，我自己也乐在其中，经常晚上一两点钟了，还在那里写代码。但是看到自己写的代码能够支撑团队技术同学稳定上线一个服务，心里就很开心。遇到问题，也乐于及时去帮助定位，去解决。\n截止到现在为止，goneat框架已经支撑了线上1k+多个服务的稳定运行了，感觉就有点成就感。\n2019年X月 # 计划持续打磨goneat并推广 # 19年上半年，我给自己定了点KPI，就是好好打磨goneat并做一个比较大范围的推广。我确实很想把这个事情做成，让投入其中的同学也都有获得感、成就感，当然更希望它能解决公司内部开发框架的一些问题。\n公司内有很多框架，相对来说，我觉得goneat是设计的比较好的，虽然也有这样那样的问题吧，但是相对来说，有些设计理念还是比较好的。\n然后，上半年我和小伙伴花了很多时间做了框架文档、网站方面的建设，有的小伙伴喜欢建网站，我比较喜欢写文档、分析源码，有的支持下demo，我们感觉做的也算是如火如荼。因为我们投入的比较好，协作的一些数据什么的都挺不错，代码、文档都不错，还拿了2019年5月刊的公司级代码文华奖。\n感觉很有成就感，下面准备再进一步建设、推广的时候，却被一下子喊停了，因为bg层面要牵头做一个更好的微服务框架了。\n支持公司级微服务框架建设 # 19年下半年，就投入了公司级微服务框架trpc的设计、开发，在设计的过程中，我们也参考了很多开源框架的设计，然后参与核心架构设计的同学也大多是参与过框架相关建设的，各个语言层面统一设计、规划、协调、开发、推广，做的还是很不错的。\n在这期间呢，也少不了讨论，有的时候会演变为辩论。现在觉得程序员Show me the code是非常有必要的！对于框架设计而言，有时候说show me the code并不是为了炫耀你很厉害，而是阐述你的思想是不是行的通。当时针对协议编解码支持方面，我就有比较大的意见，和大多数同学意见不一致，最后也是少数服从多数按照大家的意思进行支持的。我为此愤懑了很久，为什么就get不到我的思路呢。\n现在我其实也想通了，如果当时我及时show me the code，那这里的设计可能就不是这个样子！即便是现在，我对这里的设计也是不满意的，因为它的问题很明显，只是很多业务开发的同学，或者没有挑剔眼光的框架开发者，感觉不到它的存在罢了。\n发现问题，从混乱中抽象出更清晰的设计脉络，本身就是种特殊的能力。不过我已经不那么愤懑了，相比一个点的设计优劣而言，能有一个靠谱的全局落地计划，会更重要一些。毕竟我们是来解决问题的，而不是要创造一个什么完美的东西！追求better code，而非perfect code！better and better，会慢慢趋近perfect！\n这期间有成长，有郁闷，有认可，有质疑，这并不是一个多么轻松的活，坚持下来，从0到1，也算是我从头到尾跟完的一个比较大型的项目了。期间也进一步加深了自己对架构设计、微服务架构设计、项目管理、代码质量、推广运营等相关方面的一些理解。我将在我的书 go-rpc-book 中讲述我的心得体会，敬请关注。\n2020年X月 # 如今2020年已经过半，来到这个档口，又多了一些思考。从公司组织架构调整以来，公司的很多团队在整合优势资源，通过开源协同去共建一些优秀项目，而不再是抱残守缺似的闭门造车。\n我相信，腾讯的技术在未来几年肯定会越来越好的，但是因为有很多存量系统的选型、实践，这个还是要时间来消化的，业务上势必会经历一段时间的阵痛，这些阵痛一定会落在研发同学身上。或长或短，看技术建设推进的力度和领导的魄力，一线开发的自主选择能力。如果大家都选择闭嘴，只唯上不唯是，那这样的技术推进，也有可能剑走偏锋，有弊无利。这半年吧，一直在承担trpc框架的应用推广、研发效能提升方面的工作，我非常认同这背后的理念，只是落地的计划上我觉得是可以改善的。\n说真的，这半年我觉得有点累，心累、身体累、没有成就感，包括答辩晋升在内吧，心里有点不甘，对评委专业能力、评审合理性也有质疑。\n总结一句话，没有达到自己想要的那种成长吧。\n还有，原本想按计划推进下业务方面的建设，突然来个研发效能提升，但是工具平台建设，半年多了还是一团糟，我很难知道团队现状到底好在哪里，坏在哪里。继续这么干下去，慢腾腾的，下半年多半还是这样的工作。\n我想做出一些改变，思维上，行动上，自己为自己做主，不能被动地等待机会或外部改变。\n客观上房子是全款买的，有存款，没有经济上的压力。自己对现在工作状态不满，也许工作就是这样吧，但是我想做更多有价值的东西，而不是替别人频繁擦屁股。虽然自己没强到那么强，但是学习谁不会，而且我觉得自己学习能力很强呢，只是我不愿意和这种做事的人一起鬼混了而已了。\n最最重要的，我有一些想法，感觉很不错，想去尝试一下。万一成功了呢，就可以摆脱这种猪狗不如的日子了。到时候我就可以开开心心地写写自己想写的代码。也没必要因为评委不专业、评审规则的问题来等他们评审晋升，不值得。更没必要因为一些合作方的懒惰、不作为，搞的自己婚假期间还要为了他们的KPI去做一些老板面子上的事情。谁的时间不是时间！\n现在，我也知道自己有哪些优点和不足，通过一些学习、对比也能清晰地认识到未来自己的可能发展路径，我也不会因为别人一时的评价、工作的不如意，再反过来质疑自己。看上去一切都已经慢慢变得更好，但我真的不满足于这样了，我想挑战更多，体验更多。时间不应该这样被浪费掉。\n现在的工作、生活、时间，都与我个人的目标产生了激烈的对抗和冲突。人和人还是不一样的，毕竟不是每个人都想机械地工作，原封不动地按照前辈们踩出的脚印重新走一遍人生……有些人说，你应该知足，相比老家很多人工作都发愁，你这工作不风吹雨晒坐办公室的，怎么还不知足呢？不是不知足，追求的东西不一样而已，自己喜欢的东西，就不要去问别人好不好，因为在别人看来可能根本就毫无意义。有次和朋友开玩笑说，我可能会放弃技术这条线，他感觉很不理解，认为我做技术很不错、钻研的也不错，不是太可惜了吗？有什么可惜的，相比某些人认为的成功，我宁可去争取骑个摩托，跑遍中国。\n最后 # 既然已经考虑的这么清楚了，无论结果如何，都应该行动起来。最后，我坚定地落下了笔，做一个对自己负责的舵手！\n"}),a.add({id:411,href:"/tags/gatsby/",title:"gatsby",description:"",content:""}),a.add({id:412,href:"/tags/generator/",title:"generator",description:"",content:""}),a.add({id:413,href:"/tags/gitbook/",title:"gitbook",description:"",content:""}),a.add({id:414,href:"/tags/hugo/",title:"hugo",description:"",content:""}),a.add({id:415,href:"/tags/jekyll/",title:"jekyll",description:"",content:""}),a.add({id:416,href:"/tags/mkdocs/",title:"mkdocs",description:"",content:""}),a.add({id:417,href:"/tags/readthedocs/",title:"readthedocs",description:"",content:""}),a.add({id:418,href:"/tags/static-site/",title:"static site",description:"",content:""}),a.add({id:419,href:"/blog/2020-05-30-%E9%9D%99%E6%80%81%E7%AB%99%E7%82%B9%E7%94%9F%E6%88%90%E5%99%A8/",title:"静态站点生成器，为什么选择hugo？",description:"技术人没个自己的技术博客怎么行，及时总结分享一下自己学习的东西，不仅仅是对自己现阶段的工作总结，对别人也可能是一种无形的帮助，没准有需要的人接触到了什么问题刚好能获得帮助。那么有什么工具可以帮助开发人员快速建立技术博客呢？结合技术人的技术栈、常用工具，技术人用的比较多的就是markdown，如果能有工具迅速将markdown以web页面的形式进行发布并提供一致便捷的阅读体验就好了。本文就来介绍相关的工具。",content:" img {width:680px;} video {width:680px;}  Hugo 是一个静态站点生成器，是评测最快的静态站点生成器，采用golang编写，依赖bep、spf13、friends这几个第三方库来实现。Hugo是一个不错的静态站点生成器，类似的还有readthedoc、gitbook、jekyll、gatsby等等，谈谈我对这几个流行的站点生成器的看法。\njekyll # jekyll，是我使用的第一个静态站点生成器，用于我的 github pages， 它有比较丰富的主题，这个是我当时选择的一个原因，我可以专心于文档的编写，文档也是markdown格式。但是由于它对markdown的支持比较鸡肋，比如缺乏对图片引用、图表、plantuml、flowchart等的良好的支持，最终让我觉得通过jekyll来维护一个静态站点比较痛苦。\ngitbook # gitbook，是我平时经常使用的一个编辑工具吧，特别是涉及到类似书籍章节的大量内容组织的时候，现在依旧是我常用的编辑工具之一。gitbook-cli是其配套的一个工具，现在已经不再更新、维护，离线编辑已经不再被支持，现在转为线上服务。我还是比较倾向于离线编辑，不得不寻求其他可替代方案。\nreadthedoc # 见名知意，readthedoc确实比较用来写技术文档，其本身也是为了给python写api文档的，其用来构建类似的技术文档、手册还比较合适，但是用来构建一个更通用点的静态站点的话就有些不合适，不管多大的屏幕，它展示的区域总是那么小，有点死守每行N个字符的味道。\ngatsby # 这个也是一个比较好用的静态站点生成器，网上也有很多它和hugo的对比，由于我对背后的实现js等不太熟悉，而我本人也经常有些定制化的修改需求，我还是有可能会去改下源码为自己所用的，所以选型阶段直接放弃。\nmkdocs # mkdocs和gitbook类似，使用都比较简单，但是其风格定制化比较难操作，如果你对它的默认风格不太满意，又想定制主题，而不想沾染什么前端相关的工作，mkdocs可能并不一定合适。\nhugo # hugo的支持、维护、更新都还不错，生态也不错，也有很多使用hugo的公司、团队、个人用它来维护自己产品、个人的文档、博客等等，也有比较丰富的主题可供选择。hugo的好处是它的主题是完整的，包括各种各样的插件，可以体验、下载安装、应用中意的主题，后续切换主题也比较方便。而且hugo也提供了一些命令行操作来快速发布静态站点。还有就是对golang的偏爱，意味着我可以在有需要的时候了解其实现，修改其源码进行定制化，或者做贡献。\n综合上述考虑和对比，现在呢，我更倾向于使用hugo来作为接下来的静态站点生成器。\n"}),a.add({id:420,href:"/tags/hammerspoon/",title:"hammerspoon",description:"",content:""}),a.add({id:421,href:"/tags/ical/",title:"iCal",description:"",content:""}),a.add({id:422,href:"/tags/mac/",title:"mac",description:"",content:""}),a.add({id:423,href:"/tags/shortcuts/",title:"shortcuts",description:"",content:""}),a.add({id:424,href:"/tags/spotlight/",title:"spotlight",description:"",content:""}),a.add({id:425,href:"/blog/2020-04-25-%E4%BD%A0%E7%9A%84mac%E6%9C%89%E5%93%AA%E4%BA%9B%E8%B6%81%E6%89%8B%E7%9A%84%E9%85%8D%E7%BD%AE/",title:"你的mac有哪些“趁手”的配置呢？",description:"每个人的习惯不一样，每个人电脑到手后要做的定制化配置也不一样，比如常用的软件、快捷键、效率工具等等的，程序员可能会开发些常用的工具来增强操作效率等等。我就感觉我老婆mac操作效率挺低效的，实际工作中据我观察很多同事的操作效率都很低效，于是有此文，分享下自己在mac使用方面上的一点心得。效率低也无所谓，完成工作就可以，但是我不行，我不能忍受无休止的体力劳动，所以我会想办法来提效，如果我每天要重复一个操作很多次以上。",content:" img {width:680px;} video {width:680px;}  这阵子上班在同事之间走动比较多，发现基本上已经人手一台mac，但是对系统的配置、使用却大不同。也有新同学估计是windows转过来的，适应起来也有困难。听物资管理的同事提起过，有同学因为不习惯mac重新换机器的也不少。\n前几天生日，买了台新设备送自己（原本打算买Aprilia 150，先放放），恰好生日前一天到😃。刚好也在做一些配置的事，就把过程中觉得比较有分享价值的整理分享下。\n回想起16年参加工作刚领工资那个月，兴冲冲地买了mbp，端端正正的16:10屏幕，细腻的分辨率，舒服的键盘，人性化的键盘灯，灵敏的触控板……哇，硬件完美，这就是我想要的工具。试用了一天之后，发现很难适应。狂吐槽，经常拿它和Linux桌面做对比，过了一段时间的调教，发现还是可以的😃。\n自己老设备也没使用time machine来做快照，没那么大硬盘分区了，而且有很多垃圾，还是干干净净从头来一遍吧，也把过程中值得分享的记录下（尽量做到合适的归类）。\n1 Spotlight\n以前，搜索引擎是大家了解信息的主要入口，搜索、热门词条等，spotlight是一个类似的东西，它提供了一个入口让用户可以快速触达待访问的内容，可能是启动一个应用程序，进入一个文件路径，打开一个文件，翻译一个单词，进行一段科学计算，执行一个工作流，全文搜索，OCR搜索你的网页批注……网络搜索……\n听起来很美好是吧，这个玩意也不是什么新鲜的东西，在Windows、Linux上都有类似的工具，比如KDE上按键F2 进入搜索基本上是同样的效果，Unity、GNOME上都有类似的，特别是XBuntu上对spotlight进行了高度“抄袭”😃。\n调整原因：默认command+space是启动spotlight，与输入法切换冲突\n调整推荐：快捷键调整成 command+/，这个组合键简单，又避免冲突\n2 Launchpad\nLaunchpad有点类似于windows下的开始菜单，这里可以搜索安装的应用程序，和windows相比一个好点的地方是，可以对应用进行分组，现在Android、iOS都支持，大家应该不陌生，好处就是避免了冗长的程序列表，定位也更快。\n因为有了Spotlight、Alfred（下面会提到），Launchpad并不算是一个高频操作，所以我把Option按键用来分配组合键，Option+W。\n另外，Launchpad偶尔会抽风，将应用顺序、组合全部搞的错乱，这个也不用怕，安装Launchpad Manager来管理Launchpad布局，并将最新布局导出到icloud进行备份，如果哪天抽风了，拿出来恢复一下就可以。CleanMyMac扫描大文件的时候偶尔会干掉Launchpad对应的数据文件，从CleanMyMac的搜索路径里屏蔽掉就可以了。\n3. Desktops\n现代的桌面操作系统都支持多任务，一边听着音乐，一边写着文档等等，这是常有的事情，然而每个人理解的多任务可能不太一样。\n可能有的用户真的没那么多任务要处理，也就是一边公放着音乐，一遍斗地主，诸如此类，那一个桌面可能就够了。但是，多任务也可能是下面这样的，甚至更多。如果真的只能通过Alt+Tab来切换简直是噩梦。\n多个虚拟桌面的好处就体现出来了，Ubuntu Unity里面的workspace，KDE里面的Pages，macOS里面的Desktop，Windows 10里面的taskview，anyway，总之都是一个意思，无非就是为了方便用户进行任务管理。按照任务类别适当将任务组织到不同的Desktop，并按照就近原则将常用的任务放在切换时更快速访问到的Desktop，是个比较好的做法。\n通过触控板可以方便地在上述虚拟Desktop间进行切换，也可以将窗口移动到其他的Desktop。说到这里就不得不提触控板、窗口拖动、快捷键的设置，嗯，这里先只讲快捷键设置吧。\n快捷键快速切换Desktop，默认改成了Ctrl+Command+ Left Arrow，其实用触控板也可以，至于为什么想用快捷键？可能电脑大小比例不符合人体工程学，经常性地触控板左右滑动之后，会感觉手腕很累……所以键盘、触控板交替着用，会舒服一点。\n如果左右切换都嫌累，嫌麻烦，拖拽窗口到其他Desktop就更麻烦了，比如有的时候你在Desktop1打开了一个编辑器，但是你后面意识到它应该移动到其他Desktop2中去（KDE里面有种更好的管理方式叫Activity），那你就得手动移动过去，问题是如果Desktop2中窗口比较多，你移动过去发现，唉，移动错了，应该移动到Desktop3中去，然后你又开始拖动……\n效率是什么，效率就是短小精悍，让响应跟上思维的速度，这种看似不起眼的事情，我是不愿意让它悄悄消耗掉自己的时间。如果支持快捷键快速将一个窗口移动到另一个Desktop会方便一点，因为快捷键可以连续触发，而不用再次拖拽来个位移。KDE里面pages管理，是有考虑到这些的，macOS里面没有，当然也可以做到，只不过嘛就要自己动手了。\nHammerspoon（下文会提到）是针对macOS提供的一个可扩展的工具，通过lua脚本封装了大多数的macOS系统编程接口，如果你想定制化一些操作，只要看着hammerspoon的文档写lua脚本就可以了，论一个开发者的好处。\n写这么一段lua脚本，放置到~/.hammerspoon目录下，就支持快捷键Shift+Ctrl+Cmd+Arrow Keys来快速移动窗口了，至于为什么选择这个快捷键，习惯，KDE下面多年养成的习惯。\n4 Trackpad\n触控板还需要设置吗，要设置，适合自己的才是最好的。\nTap to click，点选这个勾上，这样就不用每次“按”一下才触发单击操作。\nScroll direction: Natural，这个滚动方向，现在虽然不用鼠标了，但是习惯养成了。比如浏览网页的时候，想从页面底部回到顶部，或者希望向上滚动，我想的是，把页面往下拽一下页面顶部的位置就展示在眼前了。这里的natural滚动方向我就很难适应，有相似的可以取消勾选。\n我不想知道自己干什么的时候该用几根手指，我只想完成想干的事情。所以我几乎都设置成了四指操作，有的最多只有三指的，那就三指好了，反正四指也可以触发，去掉这些记忆负担。\n使用触摸板拖动窗口，默认设置是先点按窗口标题栏，按住不放，再一只手将其拖动，这个操作很不方便，设置下可以直接三指窗口拖动。现实场景中，一般我是通过hammerspoon自定义脚本来完成的：最大化、最小化、居中、左半屏、右半屏等。但是，移动窗口的需求还是有的。\n5 Keyboard\n键盘设置，默认键盘设置，对经常需要文字编辑工作的朋友来讲不算友好，主要有几个方面我觉得要调整。\n中英文切换方面\n搜狗输入法用了很多年，也是国内厂商比较早支持Linux的全拼输入法，对其印象很好，而且支持个人词库同步，这么多年录入的词库也是愿意继续使用的主要原因，没有使用系统自带的拼音输入法。\n搜狗输入法shift按键支持快速在中英文之间进行切换，这个想必大家都知道。作为一名开发者，快速在中英文之间进行切换是常有的事，但是切换输入法也要细分场景。\n比如现在要准备写一大段代码了，那可能这段时间内全是英文比较好，那按shift切换成英文就不太合适，因为一不小心再按下shift可能会让我误输入中文；\n再比如现在准备切成中文写几行注释，写完立即接着写代码，那可能按shift切换就比较合适；\n再比如编辑期间涉及到窗口切换，比如去参考下文档、资料……然后回来接着继续刚才的工作，你会发现输入法中英文你已经不记得了，如何确保现在输入英文或中文；\n这都是影响文字编辑效率的问题，我是这么解决的，也很简单：\nCommand+Space执行切换时，总是会将搜狗切换到中文输入法，而Ctrl+Space不一定，还有另一个区别，前者进行输入法切换时，如果按键释放时间稍长，会提示当前正切换到的输入法名称。一举三得！\n文字输入速度方面\n影响文字输入的，不仅有实际的击键速度、准确率，还有这玩意。Key Repeat、Delay Until Repeat这两个选项一个是用于控制按键重复重发的速率，一个是用于控制按键初始延迟，默认值是考虑到用户误输入的情景，减小了前者，增大了后者。\n不过，对有特殊需求的开发者、文字工作者，可能就没那么友好了，直接将Key Repeat调到最大，Delay Until Repeat调到最低。\n修改完成后，如果感觉还是不满意，那只能通过defaults命令来修改配置了，不对这里的设置进行优化，会让Vim党很抓狂，绝对暴躁的起来（想象下hjkl怎么玩）。\ndefaults write NSGlobalDomain KeyRepeat -int 3 defaults write NSGlobalDomain InitialKeyRepeat -int 12 defaults write -g ApplePressAndHoldEnabled -bool false  快捷键方面\n新版的mbp都带了touchbar，touchbar有时候有用，有时候没用，对实际经常需要用到F1~F12快捷键的同学来说，touchbar还真有点没那么实用。所以touchbar上面默认显示F1, F2, etc. Keys。\n截屏操作：算是个比较常用的快捷键吧，一个是截屏指定区域到剪贴板，一个是截屏指定区域保存到本地。\nFinder搜索：Finder中搜索文件也是常见操作？不会吧，已经有spotlight了，但是打开Finder应该是个常见操作，但是macOS没有提供这样的快捷键，可以通过这里的Show Finder search window来代替下，快捷键保持了与windows一致，Ctrl+F。\n那如果真的只想快速打开Finder新窗口呢？比如Option+E打开Finder窗口，定位到home目录？一样可以通过hammerspoon lua脚本搞定。\n再或者，通过Ctrl+Cmd+T打开一个新的终端，也可以通过hs lua脚本搞定。\n嗯，还有个不得不提的问题，那就是Command+H这个快捷键，macOS下默认是Hide Window，这个不行，我在IDE里面希望用这个快捷键来唤出API说明信息，你给我隐藏了不行。那怎么办，把这个Command+H快捷键重新映射，不让它执行系统默认的操作。一样的通过hs lua脚本来完成。\n当用户按下Command+H这个动作的时候，实际上应用程序看到的是Command+M，一般Command+M应用程序没这个快捷键的话，也就没有任何动作，就屏蔽掉了“Hide Window”这个动作，如果你真的想通过Command+H来唤出API说明的话，那么只要将这个动作绑定到Command+M上就可以了😃。\n此外，还有很多应用程序也需要定制快捷键，Chrome提供的默认快捷键真的是反人类，让我觉得要多长几只手才够用，4个按键分布在一只手的区域，怎么按过来，或者我的手指能多拐几个弯？哈哈，搞不了，必须改。\n但是普通应用程序快捷键，可能会有很多，怎么同步呢？几十个肯定是有的！对照着老的机器全部设置一遍也不是不行，问题是不想这么机械地搞一遍呢。macOS里面要一个菜单名一个菜单名这样的录入，才能再绑定快捷键。并不是说只是重新换个快捷键组合就完事，所以这还是体力活。\n这里先在老机器上，通过defaults find命令找到用户所有的快捷键设置，比如：\ndefaults find NSUserKeyEquivalents Found 1 keys in domain 'abnerworks.Typora': { NSUserKeyEquivalents = { Articles = \u0026quot;\\\\Uf706\u0026quot;; Code = \u0026quot;@k\u0026quot;; \u0026quot;Code Fences\u0026quot; = \u0026quot;@^k\u0026quot;; \u0026quot;File Tree\u0026quot; = \u0026quot;\\\\Uf704\u0026quot;; \u0026quot;Focus Mode\u0026quot; = \u0026quot;@$f\u0026quot;; \u0026quot;Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; Outline = \u0026quot;\\\\Uf705\u0026quot;; \u0026quot;Rename...\u0026quot; = \u0026quot;$\\\\Uf709\u0026quot;; Search = \u0026quot;@^f\u0026quot;; \u0026quot;Source Code Mode\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Toggle Sidebar\u0026quot; = \u0026quot;\\\\Uf707\u0026quot;; \u0026quot;Typewriter Mode\u0026quot; = \u0026quot;@$t\u0026quot;; }; } Found 1 keys in domain 'com.apple.Preview': { NSUserKeyEquivalents = { Bookmarks = \u0026quot;@3\u0026quot;; \u0026quot;Hide Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Hide Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Highlights and Notes\u0026quot; = \u0026quot;@2\u0026quot;; \u0026quot;Show Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Show Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Table of Contents\u0026quot; = \u0026quot;@1\u0026quot;; }; } Found 1 keys in domain 'com.google.Chrome': { NSUserKeyEquivalents = { \u0026quot;Always Show Bookmarks Bar\u0026quot; = \u0026quot;^$b\u0026quot;; \u0026quot;Close Window\u0026quot; = \u0026quot;@w\u0026quot;; \u0026quot;Developer Tools\u0026quot; = \u0026quot;\\\\Uf70f\u0026quot;; Downloads = \u0026quot;^j\u0026quot;; \u0026quot;Force Reload This Page\u0026quot; = \u0026quot;\\\\Uf708\u0026quot;; \u0026quot;New Incognito Window\u0026quot; = \u0026quot;^i\u0026quot;; \u0026quot;Open Location...\u0026quot; = \u0026quot;\\\\Uf709\u0026quot;; Redo = \u0026quot;@y\u0026quot;; \u0026quot;Reload This Page\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Reopen Closed Tab\u0026quot; = \u0026quot;^$t\u0026quot;; \u0026quot;Show Full History\u0026quot; = \u0026quot;^h\u0026quot;; }; } ...  把这个导出来，写一个bash脚本，用defaults write命令来更新系统中应用的默认设置：\n#!/bin/bash defaults write Apple Global Domain NSUserKeyEquivalents ' { \u0026quot;Enter Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; \u0026quot;Exit Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; Hyperlink = \u0026quot;@l\u0026quot;; Minimize = \u0026quot;~^\\\\U2193\u0026quot;; }' defaults write com.apple.Preview NSUserKeyEquivalents ' { Bookmarks = \u0026quot;@3\u0026quot;; \u0026quot;Hide Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Hide Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Highlights and Notes\u0026quot; = \u0026quot;@2\u0026quot;; \u0026quot;Show Markup Toolbar\u0026quot; = \u0026quot;@^m\u0026quot;; \u0026quot;Show Sidebar\u0026quot; = \u0026quot;@0\u0026quot;; \u0026quot;Table of Contents\u0026quot; = \u0026quot;@1\u0026quot;; }' defaults write com.google.Chrome NSUserKeyEquivalents ' { \u0026quot;Always Show Bookmarks Bar\u0026quot; = \u0026quot;^$b\u0026quot;; \u0026quot;Close Window\u0026quot; = \u0026quot;@w\u0026quot;; \u0026quot;Developer Tools\u0026quot; = \u0026quot;\\\\Uf70f\u0026quot;; Downloads = \u0026quot;^j\u0026quot;; \u0026quot;Force Reload This Page\u0026quot; = \u0026quot;\\\\Uf708\u0026quot;; \u0026quot;New Incognito Window\u0026quot; = \u0026quot;^i\u0026quot;; \u0026quot;Open Location...\u0026quot; = \u0026quot;\\\\Uf709\u0026quot;; Redo = \u0026quot;@y\u0026quot;; \u0026quot;Reload This Page\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Reopen Closed Tab\u0026quot; = \u0026quot;^$t\u0026quot;; \u0026quot;Show Full History\u0026quot; = \u0026quot;^h\u0026quot;; }' defaults write abnerworks.Typora NSUserKeyEquivalents ' { Articles = \u0026quot;\\\\Uf706\u0026quot;; Code = \u0026quot;@k\u0026quot;; \u0026quot;Code Fences\u0026quot; = \u0026quot;@^k\u0026quot;; \u0026quot;File Tree\u0026quot; = \u0026quot;\\\\Uf704\u0026quot;; \u0026quot;Focus Mode\u0026quot; = \u0026quot;@$f\u0026quot;; \u0026quot;Full Screen\u0026quot; = \u0026quot;\\\\Uf70e\u0026quot;; Outline = \u0026quot;\\\\Uf705\u0026quot;; \u0026quot;Rename...\u0026quot; = \u0026quot;$\\\\Uf709\u0026quot;; Search = \u0026quot;@^f\u0026quot;; \u0026quot;Source Code Mode\u0026quot; = \u0026quot;@r\u0026quot;; \u0026quot;Toggle Sidebar\u0026quot; = \u0026quot;\\\\Uf707\u0026quot;; \u0026quot;Typewriter Mode\u0026quot; = \u0026quot;@$t\u0026quot;; }' ... killall cfprefsd  在新机器上，把bash脚本执行下就可以了，so easy! 下次如果有需要拿来重跑下就可以，应用程序快捷键设置很快就能搞定。\n快捷键到这里就差不多了。\n6 效率工具\nHammerspoon\nHammerspoon，前面不止一次提到了，它的强大自不必多言，看文档https://www.hammerspoon.org/docs/index.html，支持的操作涉及到了系统的方方面面，只要会看着文档拼积木就可以。我用它来实现复杂的键映射处理、窗口管理、桌面管理等定制的操作。\n对普通用户没那么友好，但是一些难搞的问题，特别是个人的定制化，往往也要自己来搞了，用它撸几行代码就可以搞定。\nAlfred\nAlfred，是一个非常好的效率工具，可以说它和Spotlight有异曲同工之妙，我们前面先提了Spotlight的原因是，如果你认同Spotlight的价值，那么花时间去探索Alfred才有意义。\nAlfred在Spotlight功能的基础上，提供了额外的定制能力，它能干什么呢？\n定制Web Search\n这样你就可以通过关键字快速打开（浏览器收藏夹是个好东西，但绝不是最好的东西），然后输入的关键字会被当做搜索参数传入，例如让google帮你搜索，当然也可以当做浏览器收藏夹来用。\n定制Workflow\niOS上面的捷径，大家体验过没，大致上是一样的东西，macOS上本身是有Automation的，Alfred的好处就是提供了一个统一的管理、可视化配置、同步配置，而且还要比较好的用户生态，你可以搜索到他人贡献的workflow，也可以自己写。\n比如下面gist是一个支持gist搜索、创建的workflow，当你想使用以前积累的代码snippet，或者创建新的备用的时候，非常方便。\n再比如，这是一个强密码生成器，想靠人肉记住的密码都算不上什么强密码，安全的做法就是随机生成一个，连自己也不知道是什么，然后交给keychain来管理。\n时间久了，这里的设置就会比较多，如果涉及到多台设备的话，如何同步也需要考虑。这里不建议使用icloud此类进行存储，因为一旦出现多台设备Alfred版本不一致，有可能因为无法正常解析配置而重建配置，到时候如果icloud同步了多台设备上的数据，就玩完了（遇到过一次）。\n建议通过github等支持版本管理的第三方平台进行配置托管，我现在是通过github 仓库进行版本管理。\n7 浏览器\n浏览器你选哪款？iOS设备我选Safari，macOS我选Chrome，为啥，我当然想全部用Safari，移动端Safari体验比Chrome强太多，电脑上不行，没那么多extensions、apps来扩展浏览器功能，Chrome在桌面上很强大。\n我的常用扩展列表，屏蔽广告、代理、油猴扩展脚本、vim党专属vimium。之前有个同学问我你的百度页面怎么没广告啊，因为被Adblock屏蔽了啊。油猴上脚本多的了不得，下载视频啊等等等。\n我比较喜欢vimium，它让我可以用vim的操作方式来操作Chrome页面。比如：\nx: 关闭当前标签页\nyt: 创建新标签页\n/: 开始页面内搜索\nhjkl：页面内上下左右滚动\ngg：回到页面顶部\nf: 将页面中超链接全部高亮显示，并按字母编号，然后你可以通过编号触发链接，网页浏览的时候可以忘掉触摸板了\ni：直接进入搜索框，tab在多个文本框之间切换\n\u0026hellip;\n当然Chrome Web Store里面也有一些离线可以使用的Apps，想象一下ChromeBook能搞起来就知道Web Store里面应用有多丰富。\n当然你也可以自己写插件、应用，以开发者模式离线加载使用，也可以发布到Web Store。比如我自己写了个插件分屏阅读代码。\n上述一些配置优化方面的分享，对macOS的普通用户、高频用户、开发者等，应该都是通用的，这里分享一下，也欢迎大家分享自己的一些使用心得、技巧。\n关于开发相关的一些特定配置，后面有时间了整理后再分享。\n"}),a.add({id:426,href:"/blog/2020-02-23-go%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90-gotest%E5%AE%9E%E7%8E%B0/",title:"go源码剖析-gotest实现",description:"写了这么多年go，你了解go test是如何工作的吗？",content:"问题背景 # 在go1.13出来后不久，有不少同学遇到了go test报错的问题 “flag -test.timeout provided but not defined”。这个问题是如何引起的呢？\n 公司微服务代码，通常是借助代码生成工具统一生成的，包括针对接口的测试用例； 在生成单元测试文件时，如helloworld_test.go中，在该文件中定义了一些测试选项如-timeout、-service、-method、-target、-req、-rsp等； 上述定义的选项，在helloworld_test.go中的func init()中执行flag.Parse()操作完成选项解析。  这是被测试代码的一点背景信息，上述测试代码在go1.12中是没有问题的，但是当升级到go1.13后，就出现了上述“flag \u0026hellip; provided but not defined”的错误。\n实现细节 # go test实现细节，需要跟踪一下命令go test的执行过程，具体对应这个源文件：src/cmd/go/internal/test/test.go。\n假如现在，我们创建一个package名为xxxx的go文件，然后创建一个package名为xxxx_test的_test文件，如：\nfile: helloworld_test.go\npackage xxxx_test import \u0026quot;testing\u0026quot; import \u0026quot;xxxx\u0026quot; func TestHelloWorld(t *testing.T) { xxxx.Hello() } /* func init() { flag.Parse() } */ /* func TestMain(m *testing.M) { os.Exit(m.Run()) } */  file: helloworld.go\npackage xxxx func Hello() { }  这里的实例代码，做了适当的简化，方便大家查看。为了更好地跟踪go test过程，我们可以以调试模式运行go test，如GOTMPDIR=$(pwd)/xxx dlv exec $(which go) -- test -c：\n 首先指定了临时目录GOTMPDIR为当前目录下的xxx，在执行编译构建过程中的临时文件将生成到该目录下； dlv执行的时候，在--后面添加传递给被调试程序的命令行参数，如这里传递给go的参数是test -c；  此外，我们可以执行fswatch $(pwd)/xxx来跟踪文件系统的变化，从而帮助我们分析go test到底干了什么，这样比较直观，直接看源码，代码量有点多，容易抓不住头绪。\n接下来只需要执行next、next、next步进的形式执行go test的代码逻辑就可以了。过程中，我们看到fswatch输出了如下信息：\nzhangjie@knight test $ fswatch . /Users/zhangjie/test/test/xxx/go-build3964143485 /Users/zhangjie/test/test/xxx/go-build3964143485/b001 /Users/zhangjie/test/test/xxx/go-build3964143485/b001/_testmain.go  此时查看下_testmain.go的文件内容：\nfile: _testmain.go\n// Code generated by 'go test'. DO NOT EDIT. package main import ( \u0026quot;os\u0026quot; \u0026quot;testing\u0026quot; \u0026quot;testing/internal/testdeps\u0026quot; _ \u0026quot;xxxx\u0026quot; _xtest \u0026quot;xxxx_test\u0026quot; ) var tests = []testing.InternalTest{ {\u0026quot;TestHelloWorld\u0026quot;, _xtest.TestHelloWorld}, } var benchmarks = []testing.InternalBenchmark{ } var examples = []testing.InternalExample{ } func init() { testdeps.ImportPath = \u0026quot;xxxx\u0026quot; } func main() { m := testing.MainStart(testdeps.TestDeps{}, tests, benchmarks, examples) os.Exit(m.Run()) }  上述文件中包含了一个main函数，是go test -c生成的测试程序的入口函数。\n  上述文件中，import了我们自己编写的两个package，如import _ \u0026quot;xxxx\u0026quot;，以及import _xtest \u0026quot;xxxx_test\u0026quot;，这两个package的代码就是我们上面给出的，一个Hello函数定义，一个对Hello函数的单元测试，没有什么复杂的。在helloworld_test.go中我们注释掉了两段代码，一个是func init()逻辑，一个是func TestMain()逻辑。我们稍后再说这个。\n  func init()中也没有什么需要关注的。\n  func main中，先执行了一个testing.MainStart(\u0026hellip;)初始化逻辑，这里面赶了什么呢？它执行了一个testing.Init()函数，来初始化go testing这个package中自定义的一些flags，如-test.timeout之类的。主意这些flags的注册逻辑是在所有package的func init()执行之后才发起的。\n  func main中，接着执行了一个os.Exit(m.Run())来执行测试，展开m.Run()能够看到根据-test.run选择性运行测试用例，或执行所有测试用例的逻辑。注意，当我们在测试文件中定义了TestMain方法之后，这里生成的代码就不是os.Exit(m.Run())了，而是_xtest.TestMain(m),这将允许先执行我们自己的测试代码设置逻辑。如在TestMain中执行一些准备测试数据、工作目录、注册命令选项 逻辑。\n  该问题产生原因 # 好，事情至此，我们先来解答本文开头遇到的问题？\n go1.13中对testing package的初始化逻辑做了一点调整，它将flags的初始化逻辑放在了main程序中，所有的其他package的func init()执行之后； go官方其实不建议在func init()中定义一些flags的，除非是main package。但是我们很多开发并不了解这个背景，经常在func init()中定义一些flags并Parse，甚至是在_test.go文件中; go1.13做了上述调整之后，在func init()中执行flag.Parse()时，如果go test传递了一些还没有来得及注册的选项，如-test.timeout是在func main()执行后注册，就会报错\u0026quot;flag -test.timeout provided but not defined\u0026quot;。  到这，我们解释了问题产生的原因了。\n如何规避该问题 # 现在，我们再来看下如何规避上述问题，有些情况下，确实有需要在_test.go中定义一些flags进行精细化控制的情况。\n我们了解到，如果我们自定义了TestMain函数，go test就会生成这样的代码:\nfile: _testmain.go\nfunc main() { m := testing.MainStart(testdeps.TestDeps(), tests, benchmarks, examples) _xtest.TestMain(m) }  在testing.MainStart中执行testing框架的选项注册逻辑，如-test.run、-test.timeout等等，我们可以在_xtest这个导入别名对应package中定义好flags，可以在package级别定义，也可以在func init()中定义，也可以在func TestMain()中定义，只要保证，执行flag.Parse()的时候是在TestMain或者更之后的单元测试函数中就可以。\n这个时候，所有的package的选项都正常注册了，包括testing package的，在TestMain中执行flag.Parse()就不会再出现“flag \u0026hellip; provided but not defined\u0026quot;的奇葩情况。\n区分testing flags以及自定义flags # 另外，关于自定义flag与testing package定义的重名的问题，其实go test是有考虑到的，用参数\u0026ndash;args分开就可以了，前面的是给testing解析的，后面是给自定义的解析的，testing自己的flag名带“test.”前缀，其实是可以省略掉的。\n再看go test代码生成 # 下面是问题的回归，及定位过程中的源码分析！\n_testmain.go的生成，是通过go模板来生成的，模板路径详见：src/cmd/go/internal/load/test.go，搜索变量’testmainTmpl’：\n// Code generated by 'go test'. DO NOT EDIT. package main import ( \u0026quot;os\u0026quot; {{if .TestMain}} \u0026quot;reflect\u0026quot; {{end}} \u0026quot;testing\u0026quot; \u0026quot;testing/internal/testdeps\u0026quot; {{if .ImportTest}} {{if .NeedTest}}_test{{else}}_{{end}} {{.Package.ImportPath | printf \u0026quot;%q\u0026quot;}} {{end}} {{if .ImportXtest}} {{if .NeedXtest}}_xtest{{else}}_{{end}} {{.Package.ImportPath | printf \u0026quot;%s_test\u0026quot; | printf \u0026quot;%q\u0026quot;}} {{end}} ... ) var tests = []testing.InternalTest{ {{range .Tests}} {\u0026quot;{{.Name}}\u0026quot;, {{.Package}}.{{.Name}}}, {{end}} } var benchmarks = []testing.InternalBenchmark{ {{range .Benchmarks}} {\u0026quot;{{.Name}}\u0026quot;, {{.Package}}.{{.Name}}}, {{end}} } var examples = []testing.InternalExample{ {{range .Examples}} {\u0026quot;{{.Name}}\u0026quot;, {{.Package}}.{{.Name}}, {{.Output | printf \u0026quot;%q\u0026quot;}}, {{.Unordered}}}, {{end}} } func init() { testdeps.ImportPath = {{.ImportPath | printf \u0026quot;%q\u0026quot;}} } ... func main() { ... m := testing.MainStart(testdeps.TestDeps{}, tests, benchmarks, examples) {{with .TestMain}} {{.Package}}.{{.Name}}(m) os.Exit(int(reflect.ValueOf(m).Elem().FieldByName(\u0026quot;exitCode\u0026quot;).Int())) {{else}} os.Exit(m.Run()) {{end}} }  结合前面给出的测试用例helloworld.go、helloworld_test.go，以及go test生成的_testmain.go，只要对go模板稍有认识，就很容易建立起模板和代码生成的联系，是很容易理解的。\n总结 # go1.13 testing package初始化flags顺序发生改变，引起了一些go test时\u0026quot;flag \u0026hellip; provided but not defined\u0026quot;的错误，暴露了我们一些开发者对go test不熟悉、对go flags官方推荐用法不熟悉。本文解释了go test的大致处理逻辑、问题产生原因以及规避该问题的建议。\n"}),a.add({id:427,href:"/tags/framework/",title:"framework",description:"",content:""}),a.add({id:428,href:"/tags/goneat/",title:"goneat",description:"",content:""}),a.add({id:429,href:"/blog/2020-02-04-goneat-rpc%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1%E8%AF%A6%E8%A7%A3/",title:"GoNeat RPC框架设计详解",description:"GoNeat框架是一款在腾讯期间开发的RPC框架，支撑了团队几千个微服务，后续PCG建设tRPC框架后，GoNeat框架也最终走向了停止后续开发的命运。虽然未来难免被遗忘，但是它过去也曾经”繁荣“过，几十人的活跃开发组织，几百个的issue沟通讨论、几千的commit、很多次技术分享，沉淀下来的东西也可以对新同学成长起到些指引帮助作用，对后续框架设计开发者也具有一定的参考价值，希望本文能对框架设计实现感兴趣的同学有帮助。",content:" img { width: 680px; padding-bottom: 1rem; }  GoNeat框架一直持续演进中，抽时间整理了下框架从服务启动到结束退出这一连串流程中涉及到的设计、实现细节，希望能对想了解GoNeat框架设计、实现感兴趣的同学有帮助。 本文初衷是为了介绍GoNeat框架的设计，本人觉得按照一个服务的生命周期进行介绍，读者会比较容易接受、介绍起来也没那么枯燥，缺点是一个模块的多个实现细节可能会在不同的地方提及，读者可能需要一定的前后联想。内容比较多，也可以直接跳过部分内容阅读感兴趣的章节。 由于语言功底不是特别好，在用词、句式、断句、篇章组织上难免存在不尽如人意的地方，请多多包涵。\nGoNeat RPC框架设计详解 # GoNeat，追求“小而美”的设计，是基于golang开发的面向后台开发的微服务框架，旨在提升后台开发效率，让大家摆脱各种琐碎的细节，转而更加专注于服务质量本身。Simple \u0026amp; Powerful，是我们始终追求的设计理念。\n本文从整体上介绍GoNeat的设计，GoNeat包括哪些核心部件，它们又是是如何协作的，服务运行期间涉及到哪些处理流程，等等。如果读者想更深入地了解，可以在本文基础上再阅读相关源码，或与我们开发者交流。\nGoNeat 整体架构 # 下图展示了GoNeat的整体架构设计，包括其核心组成部分，以及不同组成部分之间的交互： GoNeat包括如下核心组成部分：\n Server，代表一个服务实例，一个Server可以插入多个ServerModule； ServerModule，代表一个服务模块，实现包括StreamServer、PacketServer、HttpServer、HippoServer； NHandler，即Codec Handler，代表一个协议Handler，实现包括nrpc、ilive、sso、http等协议Handler；  不同port上可以分别提供不同协议的服务，如8000端口提供tcp/udp的nrpc服务，而8080提供http服务； 不同port上到达的请求，经协议Handler解析出请求，并根据请求中的命令字，找到注册的CmdHandler；   Server将请求以函数参数的形式递交给注册的CmdHandler处理，处理完毕返回结果给调用方；  介绍完框架的核心组件之后，下面结合一个服务示例，介绍下服务启动、请求处理、服务退出的详细流程及设计细节。\nGoNeat 服务示例 # 我们仍然使用“test_nrpc.proto”作为示例服务pb（您可以在 go-neat/demo/quickstart 中找到该示例）：\nfile: test_nrpc.proto\nsyntax = \u0026quot;proto2\u0026quot;; package test_nrpc; // BuyApple message BuyAppleReq { optional uint32 num = 1; }; message BuyAppleRsp { optional uint32 errcode = 1; optional string errmsg = 2; }; // SellApple message SellAppleReq { optional uint32 num = 1; }; message SellAppleRsp { optional uint32 errcode = 1; optional string errmsg = 2; }; // service test_nrpc service test_nrpc { rpc BuyApple(BuyAppleReq) returns(BuyAppleRsp); // CMD_BuyApple rpc SellApple(SellAppleReq) returns(SellAppleRsp); // CMD_SellApple }  使用goneat命令行工具来创建一个新的go-neat服务：\ngoneat create -protocol=nrpc -protofile=test_nrpc.proto -httpon  与“Program Your Next Server in GoNeat”章节不同的是，这里额外加了一个参数“-httpon”，目的是介绍支持多协议的相关处理。运行上述命令后，应生成如下目录结构的服务模板。\ntest_nrpc ├── Makefile ├── README.md ├── client │ └── test_nrpc_client.go ├── conf │ ├── log.ini │ ├── monitor.ini │ ├── service.ini │ └── trace.ini ├── deploy.ini ├── log └── src ├── exec │ ├── exec_test_nrpc.go │ ├── exec_test_nrpc_impl.go │ └── exec_test_nrpc_init.go └── test_nrpc.go 5 directories, 12 files  GoNeat 内部设计 # 一直没想清楚，该以什么样的方式来描述GoNeat的内部设计，想了两种叙述方式：\n  按照核心组件单独拎出来挨个介绍下？\n这种方式比较容易介绍，但是读者不容易理解这玩意在哪些场景下用、怎么用。因为核心组件可能功能比较多，大而全地介绍反而有点虚，一次性介绍完不光读者头大，介绍的人也头大。\n  按照执行流程中涉及到的组件逐个介绍？\n这种方式比较容易让读者明白什么场景下用到了什么组件，对组件的介绍也可以适可而止，但是同一个组件可能在多个不同的流程中被提到，需要读者适当地对思路进行下梳理。不过GoNeat框架内组件实现一般都比较简单。\n  综合考虑以后，决定用第二种方式进行叙述，既方便读者理解，介绍过程本身也不至于过于枯燥。\nGoNeat框架是按照如下方式进行组织的，相关子工程托管在git.code.oa.com/groups/go-neat：\n core，是核心框架逻辑，负责框架整体流程处理，即某些通用能力的抽象，如监控、分布式跟踪、日志能力； tencent，提供了公司常用中间件，如ckv、hippo、monitor、tnm、dc、habo、l5、cmlb等等； common，提供了框架中一些常用的工具类实现，如共享内存操作等等； tool，提供了GoNeat开发所需要的一些外围工具，如代码生成工具、monitor监控打点工具等；  为大家方便使用第三方组件，也创建了components方便大家在goneat服务开发中使用：\n components，提供了第三方的一些支持，如etcd、zookeeper等等；  此外，为了方便大家理解GoNeat框架的设计，以及快速上手开发，也提供了wiki和demo：\n wiki，也就是您正在看的这份文档，所有的文档都在这里维护，如果对文档有疑问或建议，也可在此提issue； demo，提供了一些示例代码，助力大家快速上手goneat开发；   为方便大家在公司内网体验GoNeat，减少解决外部依赖所需要的时间（如访问github可能要申请外网访问权限等），我们也维护了go-neat/deps来维护框架的依赖（库+版本），install.sh搭建的时候会自动拉取这里的依赖。\n我们建议您使用go module对依赖进行管理，goneat相关依赖已经补充在go.mod，请知悉。\n GoNeat - 初始化 # 初始化：配置说明 # GoNeat框架读取的配置文件，主要包括：\n test_nrpc/conf/service.ini，包含服务的核心配置； test_nrpc/conf/monitor.ini，包含服务不同接口的耗时分布的monitorid； test_nrpc/conf/log.ini，包含日志文件滚动方式、日志级别的相关定义； test_nrpc/conf/trace.ini，包含分布式跟踪相关backend的定义；  如果您已经对GoNeat配置项很熟悉，可以选择跳过该小节，当然我们还是建议通读一下以尽可能全面地了解不同的配置项，当后续您有需求要对框架做出约束或者改变的时候，有助于判断现有框架能力能否满足您的需要。\n下面对各个日志文件中的配置项进行介绍：\n  test_nrpc/conf/service.ini，包括框架核心配置项，以及habo、业务协议、rpc相关配置项：\n[service] 框架核心配置项：\n  日志相关：日志级别，保留日志文件数量，单日志文件的大小；\n  性能相关：允许的最大入tcp连接数，允许的最大并发请求数，\n  内存调优：workerpool允许创建最大协程数，udp收包buffer大小；\n  服务质量：服务接口的超时时间，处理请求时进行全局超时控制；\n  服务名称：分布式跟踪时用于追踪span节点；\n[service] name = test_nrpc #服务名称 log.level = 1 #框架日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR log.size = 64MB #日志文件大小,默认64MB,可以指定单位B/KB/MB/GB log.num = 10 #日志文件数量,默认10个 limit.reqs = 100000 #服务允许最大qps limit.conns = 100000 #允许最大入连接数 workerpool.size = 20000 #worker数量 udp.buffer.size = 4096 #udp接收缓冲大小(B),默认1KB,请注意收发包尺寸 BuyApple.cmd.timeout = 5000 #服务接口BuyApple超时时间(ms) SellApple.cmd.timeout = 5000 #服务接口SellApple超时时间(ms)    [habo] 哈勃监控配置项：\n  是否启用哈勃监控；\n  申请的dcid，dc上报数据同步到habo；\n  dc上报测试环境，还是线上环境；\n[habo] enabled = true #是否开启模调上报 caller = content_strike_svr #主调服务名称 dcid = dc04125 #罗盘id env = 0 #0:现网(入库tdw), 1:测试(不入库tdw)    [nrpc-service] 协议handler配置项：\n  nrpc协议handler监听的tcp端口；\n  nrpc协议handler监听的udp端口；\n[nrpc-service] tcp.port = 8000 #tcp监听端口 udp.port = 8000 #udp监听端口    [http-service] 协议http配置项：\n  http协议监听的端口；\n  http请求URL前缀；\n[http-service] http.port = 8080 #监听http端口 http.prefix = /cgi-bin/web #httpUrl前缀    [rpc-test_nrpc] rpc配置项：\n  rpc调用地址，支持ip://ip:port、l5://mid:cid、cmlb://appid（“服务发现”正在开发验证中）\n  传输模式，支持UDP、UDP全双工、TCP短连接、TCP长连接、TCP全双工，TCP/UDP SendOnly\n  rpc超时时间，包括默认的timeout以及细化到各个接口的超时时间；\n  rpc监控monitorid，包括总请求、成功、失败、耗时分布monitor id；\n[rpc-test_nrpc] addr = ip://127.0.0.1:8000 #rpc调用地址 proto = 3 #网络传输模式, #1:UDP, #2:TCP_SHORT, #3:TCP_KEEPALIVE, #4:TCP_FULL_DUPLEX, #5:UDP_FULL_DUPLEX, #6:UDP_WITHOUT_RECV timeout = 1000 #rpc全局默认timeout BuyApple.timeout = 1000 #rpc-BuyApple超时时间(ms) SellApple.timeout = 1000 #rpc-SellApple超时时间(ms) monitor.BuyApple.timecost10 = 10001 #耗时\u0026lt;10ms monitor.BuyApple.timecost20 = 10002	#耗时\u0026lt;20ms monitor.BuyApple.timecost50 = 10003	#耗时\u0026lt;50ms ... monitor.BuyApple.timecost2000 = 10005	#耗时\u0026lt;2000ms monitor.BuyApple.timecostover2000 = 10006	#耗时\u0026gt;=2000ms ...      test_nrpc/conf/monitor.ini，用于监控服务接口本身的总请求量、处理成功、处理失败量，以及处理耗时分布情况：\n[test_nrpc] 服务接口本身监控打点monitor id：\n[test_nrpc] //服务接口-BuyApple monitor.BuyApple.timecost10=0 #接口BuyApple延时10ms monitor.BuyApple.timecost20=0 #接口BuyApple延时20ms monitor.BuyApple.timecost50=0 #接口BuyApple延时50ms ... monitor.BuyApple.timecost3000=0 #接口BuyApple延时3000ms monitor.BuyApple.timecostover3000=0 #接口BuyApple延时\u0026gt;3000ms //	服务接口-SellApple monitor.SellApple.timecost10=0 #接口SellApple延时10ms monitor.SellApple.timecost20=0 #接口SellApple延时20ms monitor.SellApple.timecost50=0 #接口SellApple延时50ms ... monitor.SellApple.timecost3000=0 #接口SellApple延时3000ms monitor.SellApple.timecostover3000=0 #接口SellApple延时\u0026gt;3000ms    test_nrpc/conf/log.ini，代替service.ini中logging相关配置，用来支持工厂模式获取logger：\n这里默认配置了三个logger：\n 框架处理日志log，go_neat_frame.log，最多保留5个日志文件，单文件上限100MB，写满则滚动； 框架请求流水log，go_neat_access.log，最多保留5个日志文件，单文件无上限，按天滚动； 默认log，default.log，最多保留5个日志文件，单文件上限100MB，写满则滚动；  #框架内部日志 [log-go_neat_frame] level = 1 #日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR logwrite = rolling logFileAndLine = 1 rolling.filename = go_neat_frame.log rolling.type = size rolling.filesize = 100m rolling.lognum = 5 #框架流水日志 [log-go_neat_access] level = 1 #日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR) logwrite = rolling logFileAndLine = 0 rolling.filename = go_neat_access.log rolling.type = daily rolling.lognum = 5 #服务默认日志 [log-default] level = 1 #日志级别,0:DEBUG,1:INFO,2:WARN,3:ERROR) logwrite = rolling logFileAndLine = 0 rolling.filename = default.log rolling.type = size rolling.filesize = 100m rolling.lognum = 5    test_nrpc/conf/trace.ini，用于分布式跟踪相关的配置：\nGoNeat框架通过opentracing api支持分布式跟踪，支持三种backend实现，zipkin、jaeger、天机阁：\n  [zipkin] 配置\n[zipkin] enabled = true #是否启用zipkin trace service.name = test_nrpc #当前服务名称(span endpoint) service.addr = *:8000 #当前服务地址(span endpoint) collector.addr = http://9.24.146.130:8080/api/v1/spans #zipkin collector接口地址 traceId128bits = true #是否启用128bits traceId    [jaeger] 配置\n[jaeger] enabled = false #是否启用jaeger trace(暂未验证兼容性) service.name = test_nrpc #当前服务名称(span endpoint) service.addr = *:8000 #当前服务地址(span endpoint) collector.addr = http://9.24.146.130:8080/api/v1/spans #jaeger collector接口地址 traceId128bits = true #是否启用128bits traceId    [天机阁] 配置\n[tianjige] enabled = false #是否启用天机阁 trace service.name = test_nrpc #当前服务名称(span endpoint) service.addr = *:8000 #当前服务地址(span endpoint) collector.addr = 10.101.192.79:9092 #天机阁 collector接口地址 traceId128bits = true #是否启用128bits traceId appid = ${your_applied_appid} #天机阁申请的appid      初始化：配置加载 # 在介绍了GoNeat依赖的配置文件及各个配置项之后，继续介绍下GoNeat的配置解析、加载过程。\nGoNeat支持两种格式的配置文件:\n 一种是“ini格式”的配置文件， 一种是“json格式”的配置文件。  配置加载，发生在Server实例化过程中，default_nserver.NewNServer()，此时会加载service.ini、monitor.ini、log.ini，并根据配置信息完成Server实例化。 初始化：logging # Server实例化过程中，会创建三个logger对象：\n go_neat_frame，框架处理逻辑日志，对应log.ini中的[go_neat_frame]； go_neat_access，框架请求流水日志，对应log.ini中的[go_neat_access]； default，框架默认日志，对应log.ini中的[default]；  每个logger对象的创建都是按照如下流程去执行的，nlog.GetLogger(logger)，会首先检查loggerCache中key=$logger的logger对象是否已经存在，如果存在则直接返回，反之，加载log.ini中的配置[$logger]，检查logwrite配置项，logwrite指定了日志输出的目的地，如：\n console，输出到控制台； simple，普通日志文件，不支持滚动； rolling，支持滚动的日志文件，包括按照日期滚动、文件大小滚动；  logwrite允许逗号分隔多个输出，如logwrite = console, rolling，那么此时logger.Info(…)输出的信息将同时输出到控制台和滚动日志文件，详细可参考nlog.MultiWriterLogWriter实现。\n nlog.MultiWriterLogWriter可以进一步重构，如支持将日志信息上报到elasticsearch、天机阁等其他远程日志系统，现在的实现稍作修改就可以支持第三方日志组件实现，elasticsearch、天机阁等远程日志组件只要实现nlog.NLog接口并完成该实现的注册即可。  初始化：tracing # 分布式调用链对GoNeat框架来说是可插拔的，回想一下trace.ini，我们支持三种调用链backend实现，包括zipkin、jaeger以及公司内部的天机阁，如果希望在服务中使用tracing：\n 使用zipkin，那么在程序中import _ “git.code.oa.com/go-neat/core/depmod/trace/zipkin即可； 使用jaeger，那么在程序中import _ “git.code.oa.com/go-neat/core/depmod/trace/jaeger即可； 使用天机阁，那么在程序中import _ “git.code.oa.com/go-neat/core/depmod/trace/tianjige即可；  当然除了import对应的调用链实现，也要对配置文件做调整：\n 使用zipkin，trace.ini里面设置zipkin.enabled = true； 使用jaeger，trace.ini里面设置jaeger.enabled = true; 使用天机阁，trace.ini里面设置tianjige.enabled = true;   如果后续想要扩展tracing backend，只需要提供对应的tracer初始化方法就可以了，类似于zipkin、jaeger、天机阁初始化方式。如果要在项目中使用该tracing实现，通过import对应实现+配置文件激活就可以。import对应的tracing backend初始化，并添加对应的初始化配置，that’s it!\n 初始化：协议handler # 不同的业务协议，其字段定义、编解码方式可能不同，协议handler就是对业务协议的编解码进行处理。目前，GoNeat框架支持公司内大多数业务协议，如nrpc、sso、simplesso、ilive、qconn、taf等等。\n协议处理方面的亮点？ # GoNeat框架支持在单个进程中同时支持多种业务协议，如：\n 在port 8000提供nrpc服务； 在port 8001提供ilive协议； 在port 8080提供http服务；  同一份业务处理代码，可以通过不同的业务协议对外提供服务，在涉及到多端、多业务方交互的时候会很方便。\n服务中如何支持nrpc协议？ # 以提供nrpc服务为例，只需要做3件事情，包括：\n 配置文件service.ini中增加[nrpc-service]配置项，指明业务协议nrpc绑定的端口，如tcp.port = 8000； 代码中引入对应协议handler，如import _ \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nprc_svr/default_nrpc_handler\u0026quot;； 代码注册nrpc命令字及处理方法，如default_nserver.AddExec(“BuyApple”, BuyApple)；  如果要在此基础上继续支持http服务呢，一样的三件事，包括：\n  配置文件service.ini中增加[http-service]配置项，指明要绑定的端口及url前缀，如：\n[http-service] http.port = 8080 http.prefix = /cgi-bin/web    代码引入协议handler，如import _ “git.code.oa.com/go-neat/core/proto/http/dft_httpsvr”；\n  代码注册http uri，如default_nserver.AddExec(“/BuyApple”, BuyApple)；\n  That’s all！GoNeat要支持常用的业务协议，只需要做上述修改即可，是不是看上去还挺简单方便！\n 还记得写一个spp服务同时支持多种协议，需要在spp_handle_input里面区分端口来源，然后再调用对应的解包函数，判断请求命令字，转给对应的函数处理，每次有这种需要都需要写一堆这样的代码，好啰嗦！\n 框架做了什么？ # 读者是否注意到前文中AddExec(cmd,BuyApple)，nrpc命令字BuyApple，http请求$host:8080/cgi-bin/web/BuyApple，这两种不同的请求最终是被路由到了相同的方法BuyApple进行处理，意味着开发人员无需针对不同的协议做任何其他处理，GoNeat框架帮你搞定这一切，业务代码零侵入。\n真的业务代码零侵入吗？http请求参数Get、POST方式呢？nrpc协议是protbuf格式呢？同一份业务代码如何兼容？\nGoNeat对不同的业务协议抽象为如下几层：\n 协议定义，如nrpc、ilive、simplesso、http包格式； 协议handler，完成协议的编码、解码操作（接口由NHandler定义）； 会话session，维持客户端请求、会话信息（接口由NSession定义）；  当希望扩展GoNeat的协议时，需要提供协议的包结构定义、协议的编解码实现、协议会话实现，nrpc协议对应的会话实现为NRPCSession、http协议对应的会话实现时HttpSession。\n好，现在介绍下GoNeat中同一份代码func BuyApple(ctx context.Context, session nsession.NSession) (interface{}, error)如何支持多种业务协议。\nfile: test_nrpc/src/exec/test_nrpc.go：\nfunc BuyApple(ctx context.Context, session nsession.NSession) (interface{}, error) { req := \u0026amp;test_nrpc.BuyAppleReq{} err := session.ParseRequestBody(req) ... rsp := \u0026amp;test_nrpc.BuyAppleRsp{} err = BuyAppleImpl(ctx, session, req, rsp) ... return rsp, nil }  file: test_nrpc/src/exec/test_nrpc_impl.go：\nfunc BuyAppleImpl(ctx context.Context, session nsession.NSession, req *test_nrpc.BuyAppleReq, rsp *test_nrpc.BuyAppleRsp) error { // business logic return nil }  从上面的代码中 test_nrpc.go 不难看出，秘密在于不同协议会话对NSession.ParseRequestBody(…)的实现：\n 如果是pb协议，session里面会直接通过proto.Unmarshal(data []byte, v interface{})来实现请求解析； 如果是http协议，session里面会多做些工作：  如果是POST方法，且Content-Type=“application/json”，则读取请求体然后json.Unmarshal(...)接口；   其他情况下，读取GET/POST请求参数转成map[param]=value，编码为json再反序列化为目标结构体；  Google Protocol Buffer是一种具有自描述性的消息格式，凭借良好的编码、解码速度以及数据压缩效果，越来越多的开发团队选择使用pb来作为服务间通信的消息格式，GoNeat框架也推荐使用pb作为首选的消息格式。\n由于其自描述性，pb文件被用来描述一个后台服务是再合适不过了，基于此也衍生出一些周边工具，如自动化代码生成工具goneat（由gogen重命名而来）用来快速生成服务模板、client测试程序等等。\nGoNeat - 服务启动 # 前面零零散散地介绍了不少东西，配置文件、配置加载、logging初始化、tracing集成、协议handler注册，了解了这些之后，现在我们从整体上来认识下GoNeat服务的启动过程。\n说是从整体上来认识启动流程，并不意味着这里没有新的细节要引入。中间还是会涉及到一些比较细节的问题，如tcp、udp监听如何处理的，为什么要支持端口重用，为支持平滑退出需要做哪些准备等等。这里章节划分的可能不太科学，希望按照一个GoNeat服务的生命周期来叙述，能尽可能多地覆盖到那些必要的设计和细节。\n启动：实例化Server # 一个GoNeat服务对应着一个Server实例，为了方便快速裸写一个GoNeat服务，go-neat/core内部提供了一个package default_nserver，代码中只需要添加如下两行代码就可以快速启动一个GoNeat服务：\npackage main import ( “git.code.oa.com/go-neat/core/nserver/default_nserver” ) func main() { default_nserver.Serve() }  当然，该Server实例会直接退出，因为该实例没有注册要处理的业务协议，需要注册协议handler服务才能工作。当我们创建一个pb文件，并通过命令goneat -protofile=*.proto -protocol=nrpc创建工程时，goneat自动在生成代码中包含了nrpc协议对应的协议handler，这里的协议handler做了什么呢？或者说import这个协议handler时，发生了什么呢？\nimport ( _ \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nrpc_svr/default_nrpc_handler\u0026quot; )   Server实例化过程中，会涉及到配置加载、logger实例化相关的操作，这里在GoNeat - 初始化一节中已有提及，这里相关内容不再赘述。\n 启动：加入协议handler # 以nrpc协议handler为例：\nfile: go-neat/core/proto/nrpc/nrpc_svr/default_nrpc_handler/nrpc_svr_init.go\npackage default_nrpc_handler import ( \u0026quot;git.code.oa.com/go-neat/core/nserver/default_nserver\u0026quot; \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nrpc_svr\u0026quot; ) func init() { default_nserver.RegisterHandler(nrpc_svr.NewNRPCHandler()) }  当import default_nrpc_handler时，func init()会自动执行，它会向上述Server实例中注册协议handler，注册过程中发生了什么呢？可参考如下简化版的代码，它主要做这些事情：\n 读取service.ini中的配置[nrpc-service]section下的tcp.port，如果大于0创建一个StreamServer； 读取service.ini中的配置[nrpc-service]section下的udp.port，如果大于0创建一个PacketServer； 将上述新创建的StreamServer和PacketServer添加到Server实例的ServerModule集合中；  file: go-neat/core/nserver/neat_svr.go\nfunc (svr *NServer) RegisterHandler(handler NHandler) { ... moduleNode := handler.GetProto() + \u0026quot;-service\u0026quot; if svr.config.ReadInt32(moduleNode, \u0026quot;tcp.port\u0026quot;, 0) \u0026gt; 0 { nserverModule := \u0026amp;StreamServer{protoHandler: handler} svr.serverModule = append(svr.serverModule, nserverModule) } if svr.config.ReadInt32(moduleNode, \u0026quot;udp.port\u0026quot;, 0) \u0026gt; 0 { nserverModule := \u0026amp;PacketServer{protoHandler: handler} svr.serverModule = append(svr.serverModule, nserverModule) } ... }  file: test_nrpc/conf/service.ini\n[nrpc-service] tcp.port = 8000 #tcp监听端口 udp.port = 8000 #udp监听端口  启动：Server启动 # default_nserver.Serve()发起了Server实例的启动，Server实例会遍历其上注册的所有ServerModule，然后逐一启动各个ServerModule，如tcp服务模块StreamServer、udp服务模块PacketServer。\nfile: test_nrpc/src/test_nrpc.go\npackage main import ( \u0026quot;git.code.oa.com/go-neat/core/nserver/default_nserver\u0026quot; _ \u0026quot;git.code.oa.com/go-neat/core/proto/nrpc/nrpc_svr/default_nrpc_handler\u0026quot; _ \u0026quot;git.code.oa.com/go-neat/core/proto/http/dft_httpsvr\u0026quot; _ \u0026quot;exec\u0026quot; ) func main() { default_nserver.Serve() }  file: go-neat/core/nserver/neat_svr.go\nfunc (svr *NServer) Serve() { ... for _, serverModule := range svr.serverModule { if e := serverModule.Serve(); e != nil { ... } } ... }  以下是Server实例启动过程图解：\n package default_nserver实例化了一个Server实例，package main只需要import这个包即可完成实例化； package main中import对应的协议handler，协议handler将向默认Server实例注册handler； 每个协议handler又有协议之分，如支持tcp、udp、http，要为不同的协议创建ServerModule并注册到Server； Server实例调用Serve()开始启动，该方法逐一启动已注册的所有ServerModule；   下面介绍下框架中实现的几个ServerModule，了解下它们的设计细节。\n启动：ServerModule # Server允许插入多个ServerModule实现，来扩展Server的能力，如支持不同协议的ServerModule实现：tcp（StreamServer）、udp（PacketServer）、http（HttpServer）。\nfile: go-neat/core/nserver/neat_svr.go\ntype NServer struct { serverName string serverModule []NServerModule ... }  file: go-neat/core/nserver/neat_comm.go\ntype NServerModule interface { Init(nserver *NServer, module string, cfg *config.Ini, log *nlog.NLog) error SetHandler(requestHandler RequestHandler) GetProto() string Serve() error Close() }  Module：StreamServer # StreamServer是GoNeat封装的面向字节流（SOCK_STREAM）的服务模块，支持tcp和unix服务。\nStreamServer的创建时刻，我们在前面描述“服务启动”的部分已有提及，这里描述其启动的过程。\n启动监听，处理入连接请求 # func (svr *StreamServer) Serve() error { tcpListener, err := net.Listen(svr.Network, svr.Addr) if nil != err { panic(fmt.Errorf(\u0026quot;listen tcp error %s\u0026quot;, err.Error())) } svr.ctx, svr.cancel = context.WithCancel(context.Background()) if nil != tcpListener { go svr.tcpAccept(svr.protoHandler, tcpListener) } return nil }  StreamServer启动的逻辑简单明了，它监听svr.Addr（传输层协议svr.Network）创建一个监听套接字，然后为该svr.ctx创建一个CancelContext，然后启动一个协程负责执行svr.tcpAccept(…)，处理tcp入连接请求。\n广播事件，支持平滑退出 # 这里提一下svr.ctx, svr.cancel，服务有自己的生命周期，有启动也有停止，服务停止的时候，存在某些未完结的任务需要清理，如HippoServer中可能拉取了一批消息但是还未处理完成，服务重启会造成消息丢失。类似这样的场景的存在，要求框架必须有能力对服务停止事件进行广播，广播给服务内的所有组件，各个组件根据需要自行执行清理动作，如HippoServer可能会选择停止继续收消息、处理完收取消息后退出。\n这里的svr.ctx, svr.cancel就是负责对服务停止事件进行广播的，当Server实例停止时，会遍历其上注册的所有ServerModule并调用其Close()方法，以StreamServer为例：\n// Close shutdown StreamServer func (svr *StreamServer) Close() { if svr.cancel != nil { svr.cancel() } }  StreamServer.Close()调用了svr.cancel()来取消svr.ctx的所有child context，因为svr.ctx是整个tcp服务处理的root context，所有后续的请求处理的context都是派生自svr.ctx，当执行svr.cancel()的时候，所有派生出来的请求处理，都可以通过各个child context的Done()方法来检测StreamServer是否已经准备停止，从而采取必要的清理动作。\n这里的设计，也为GoNeat服务能够优雅地“实现平滑退出”打下了基石。\n建立连接，全双工处理 # func (svr *StreamServer) tcpAccept(handler NHandler, listener net.Listener) { defer listener.Close() ctx := svr.ctx for { select { case \u0026lt;-ctx.Done():	//服务停止，不再接受入连接请求 return default:	//建立新连接，并处理 conn, ex := listener.Accept() if ex != nil { log.Error(\u0026quot;accept error:%s\u0026quot;, ex) } else { if svr.connLimiter.TakeTicket() { //自我防护，对入连接数量进行限制 if tcpConn, ok := conn.(*net.TCPConn); ok { tcpConn.SetKeepAlive(true) tcpConn.SetKeepAlivePeriod(10 * time.Second) } endpoint := newEndPoint(svr, conn) go endpoint.tcpReader()	//全双工模式处理，收包、处理、回包以并发的方式进行 go endpoint.tcpWriter()	//充分发挥tcp全双工的特点和优势 } else { conn.Close()	//入连接数量超过上限，关闭连接 } } } } }  对于创建好的tcp连接，StreamServer充分发挥了tcp全双工的特点和优势：\n 启动一个goroutine专门负责收包 启动一个goroutine专门负责回包 针对连接上到达的请求包，则通过协程池进行处理 同一个连接上的收包、处理、回包是并发的  回想下我们写C++服务端的经历，通过epoll监听每个连接套接字上的读写就绪事件，read-ready的时候要及时从连接中取出数据放到请求队列中，write-ready的时候如果请求处理完就回包。单进程多线程模型，往往有专门的io线程来进行数据包的收发，逻辑处理线程从请求队列中取走请求赶紧处理并准备好回包数据，io线程取走回包执行响应动作；如果是单进程单线程模型，io事件未就绪的情况下就要赶紧执行逻辑处理；多进程模型，则可能会采用类似spp的架构，proxy负责io，请求放入共享内存，worker进程从共享内存获取请求并写入响应，proxy再负责回包。\n使用go进行开发呢？go对阻塞型系统调用进行了完整的解剖，所有的网络io、请求处理，都显得那么简单、自然，以至于都已经淡忘了C++服务端开发中存在的不同网络模型。当然，网络模型的思想在，但已经无需关注多进程单进程、多线程单线程了，只需要铭记 “tcp是全双工模式”，借助golang这一强大的基础设施来最优化tcp服务性能即可。\n关于 go endpoint.tcpReader() 和 go endpoint.tcpWriter() 的细节，我们在后面服务怠速、请求处理中介绍。\n过载保护，限制入连接数 # StreamServer循环执行Accept()方法来建立连接，当然由于计算资源有限，服务能处理的连接数、请求数是有限的，服务需要进行一定的防护避免过载、雪崩。当svr.connLimiter.TakeTicket()成功时表示连接数未超限，可以继续处理，反之表示超出入连接数上限，关闭连接。\n循环Accept()过程中，如果检测到StreamServer停止ctx.Done()，关闭监听套接字不再接受入连接请求。\n过载保护，限制入请求数 # 除了对入tcp连接数进行限制，StreamServer也对入请求数进行限制，这部分在后续“请求处理”中介绍。\nModule：PacketServer # PacketServer是GoNeat封装的面向数据报（SOCK_PACKET）的服务模块，支持udp服务。\n与介绍StreamServer的方式类似，PacketServer实例化的部分前文已介绍过，这里只介绍其启动的过程。\n启动监听，处理入udp请求 # PacketServer.Server()中调用 reuseport.ListenPacket(...) 或者 net.ListenPacket(...) 监听svr.Addr（传输层协议类型svr.Network）创建监听套接字，并从中接收udp请求、处理请求、响应，详见svr.udpRead(…)，我们会在后续“请求处理”小节中进行介绍。\n// Serve start the PacketServer func (svr *PacketServer) Serve() error { svr.ctx, svr.cancel = context.WithCancel(context.Background()) if svr.shouldReusePort() {	//如果支持重用端口，linux+darwin reuseNum := runtime.NumCPU() for i := 0; i \u0026lt; reuseNum; i++ { udpConn, err := reuseport.ListenPacket(svr.Network, svr.Addr) if nil != err { panic(fmt.Errorf(\u0026quot;listen udp error %s\u0026quot;, err.Error())) } if nil != udpConn { go svr.udpRead(svr.protoHandler, udpConn) } } } else {	//如果不支持端口重用，windows udpConn, err := net.ListenPacket(svr.Network, svr.Addr) if nil != err { panic(fmt.Errorf(\u0026quot;listen udp error %s\u0026quot;, err.Error())) } if nil != udpConn { go svr.udpRead(svr.protoHandler, udpConn) } } return nil }  端口重用，加速udp收包 # 阅读上述代码，您一定关注到了这么一点， reuseport.ListenPacket(...) 和 net.ListenPacket(...) 。在继续描述之前，需要对比下tcp收包和udp收包的区别。\n tcp是面向连接的，往往为每一个连接创建一个专门的goroutine进行收包； udp是无连接的，要分配多少个协程进行收包呢？1个或者N个？对同一个fd进行操作，开多个goroutine是没有价值的，那么1个的话呢，收包效率和tcp对比又有点低效。这就是PacketServer重用端口reuseport的由来了，借此提高udp收包的效率。  重用端口（REUSEPORT）和重用地址（REUSEADDR），二者诞生的初衷和作用是不同的：\n TCP/UDP连接（UDP无连接但可以connect），由五元组表示：\u0026lt;协议类型，源ip，源端口，目的ip，目的端口\u0026gt;； REUSEADDR解决的是监听本地任意地址0.0.0.0:port与另一个监听本地特定地址相同端口a.b.c.d:port的问题； REUSEPORT解决多个sockets（可能归属于相同或者不同的进程）是否允许bind到相同端口的问题，  Linux下为了避免port hijack，只允许euid相同的进程bind到相同的port（bind设置socket源port，connect设置socket目的端口），同时对于tcp listen socket、udp socket还会进行“均匀的”流量分发，也是一个轻量的负载均衡方案。\ngolang标准库中暂没有提供reuseport的能力，这里是引入了第三方实现，目前支持Linux+Darwin平台下的udp reuseport，Windows暂不支持。\n过载保护，限制入请求数 # 与StreamServer类似，PacketServer也有过载保护机制，就是限制入udp请求数，我们在后续“请求处理”小节中介绍。\nModule：HttpServer # HttpServer是GoNeat在golang标准库基础上封装的http服务模块，支持与StreamServer、PacketServer一样的接口注册、接口路由、接口处理逻辑。\n标准库http基础上实现 # 从下面代码不难看出，HttpServer，该ServerModule的实现时基于标准库http package实现的，对大家来说应该都比较熟悉，但是这里也有个适配GoNeat的地方，也就是请求路由这里。\n// Serve start HttpServer func (svr *HttpServer) Serve() error { svr.serve() return nil } // serve start HttpServer func (svr *HttpServer) serve() { var h http.Handler = http.HandlerFunc(svr.doService) listener, err := net.Listen(\u0026quot;tcp\u0026quot;, fmt.Sprintf(\u0026quot;:%d\u0026quot;, svr.port)) if err != nil { panic(err) } server := \u0026amp;http.Server{ Addr: fmt.Sprintf(\u0026quot;:%d\u0026quot;, svr.port), Handler: http.StripPrefix(svr.prefix, h), } go func() { err := server.Serve(listener) if err != nil { svr.log.Error(\u0026quot;http svr start failed, err: %v\u0026quot;, err) } }() }  httpserver请求路由转发 # 借助标准库实例化 http.Server{} 时，指定了将请求URI Prefix为svr.prefix的请求，交由handler h处理。而h是svr.doService(…)强制类型转换成的http.HandlerFunc。\n看doService的定义，可知它确实是一个http.HandlerFunc（满足HandlerFunc的定义），这样请求就递交给了doService进行处理，doService中调用svr.requestHandler(req.Context(), httpSession)对请求进行处理，注意这里为请求专门创建了一个HttpSession，而这里的svr.requestHandler(…)是在哪里设置呢？\nsvr.requestHandler字段的设置，要追溯到HttpServer这个ServerModule实例化的时候，default_nserver示例会调用serverModule.SetHandler(nserver.process)方法将HttpServer.requestHandler设置为nserver.process(…)，即：func process(svr *NServer, ctx Context, NSession) error才是请求处理的核心逻辑之一，涉及到鉴权、命令字路由、请求处理、tracing、耗时监控等，稍后在“请求处理”部分进行介绍。\n// HttpServer defines the http NServerModule implementation type HttpServer struct { nserver *NServer port int32 log *nlog.NLog prefix string requestHandler RequestHandler enableGzip bool svr *http.Server } ... // doService process http request `req` func (svr *HttpServer) doService(w http.ResponseWriter, req *http.Request) { requestLimiter := svr.nserver.reqLimiter if requestLimiter.TakeTicket() { addr := svr.getClientAddr(req) defer func() { requestLimiter.ReleaseTicket() }() httpSession := NewHttpSession(addr, svr.log, req, w) ex := svr.requestHandler(req.Context(), httpSession) if ex != nil { w.WriteHeader(505) return } if httpSession.retcode == errCodeCmdNotFound { w.WriteHeader(404) } else { if len(httpSession.rspData) \u0026gt; 0 { w.Write(httpSession.rspData) } } } else { svr.log.Error(\u0026quot;http svr req overload\u0026quot;) } }  过载保护，限制入http请求数 # HttpServer也对入请求数进行了限制，实现对自身的过载保护，采用的方式与之前tcp、udp的处理方式类似。\nModule：ScheduleServer # ScheduleServer是GoNeat为定时任务封装的一个服务模块，简化定时任务实现逻辑。\n由于这里的实现逻辑比较简单、清晰，这里读者可以自己阅读代码进行了解。\nModule：HippoServer # HippoServer是针对消息驱动的业务场景封装的一个消费者服务，简化消息消费的任务处理。\n由于这里的实现逻辑比较简单、清晰，这里读者可以自己阅读代码进行了解。\nGoNeat - 请求处理 # 前文描述了Server实例及各个ServerModule启动的过程，至此服务已经完全启动，可以进行请求处理了。\n这里选择StreamServer、PacketServer、HttpServer作为重点描述对象，这几个ServerModule是日常业务开发中使用最频繁的，应该也是读者最希望了解的。在逐一描述之前，先介绍下用到的重要“基础设施”。\n基础设施：协程池 # 对于操作系统而言，进程是资源分配的基本单位，线程是任务调度的基本单位。协程是相比于线程而言更加轻量的调度实体，它的轻量体现在创建、任务切换、销毁时的代价，如初始分配的栈帧大小、任务切换时保存恢复的寄存器数量等。\ngo官方声称可以轻松创建几百万的协程，初始协程栈大小2KB，100w的话也就是2GB，尽管当前的服务主流机器配置应该都可以支持到，但是有些问题我们却不能不去不考虑。\n  一个请求创建一个协程，请求量大时协程数大涨，会因为OOM Kill被操作系统杀死；\n请求量上涨、协程数上涨、吃内存严重，操作系统可能会判定OOM分值时将其率先列入死亡名单，进程挂掉服务不可用，这是不可接受的。服务允许出现过载、处理超时、丢弃请求自保，但是不能挂掉。\n  尽管协程的创建、销毁更加轻量，但是开销还是存在；\n协程池，预先创建一定数量的协程备用，协程从任务队列中获取请求进行处理，避免频繁创建、销毁的开销。同时，为了避免单一锁竞争，为每个协程分配单独的一个chan作为任务队列。\n  尽管协程的切换代价更小，当协程数量很多时，协程切换的代价就不能忽略了；\nio事件就绪引起协程g1被唤醒，我们期望g1继续执行处理，结果协程g2的io事件就绪又唤醒协程g2，runtime scheduler可能在某个时刻（如g1进入function prologue时）将g1切换为g2……程序执行路径类似于多重中断处理，那什么时候被中断的协程g1可以继续恢复执行呢？如果协程数量很多，上下文切换的代价就需要引起关注。\n特别是希望尽可能并发处理连接上的多个请求的时候，可能会比一个连接一个协程创建更多的协程。又想并发处理连接上的多个请求，又想降低协程数过多带来的上下文切换开销，通过协程池限制协程数量，也是一种选择。\n  其他考虑；\n  鉴于上述考虑，我们采用协程池来处理并发请求，而不是为每个请求创建一个协程进行处理。\n基础设施：内存池 # go自带内存管理，内存分配、逃逸分析、垃圾回收，内存分配算法如何提高分配效率、减少碎片是一个常被提及的问题，即便go在这方面基于tcmalloc和go自身特性做了优化，框架开发仍需要关注内存分配问题，此外还要关注gc。\n考虑内存分配的情景，如果我们频繁在heap中申请内存（逃逸分析会决定分配在heap上还是stack上），不仅会增加内存分配的开销，也会增加gc扫描、回收时的压力。\n内存分配次数增加引入额外开销不难理解，使用sync.Pool可以在两次gc cycle间隙返回已分配的内存来复用以减轻内存分配的次数，自然也会减轻gc扫描、标记、回收的压力。\n每次 gcStart(){...} 开始新一轮gc时，会首先清理sync.Pools，清理逻辑也比较简单暴力，sync.Pools中的空闲内存块都会被清空，进入后续垃圾回收，所以内存池不适合用作连接池等有状态的对象池。\n在GoNeat框架中我们将其用作收发包buffer池，用完即释放，不存在上述有状态对象被清理的问题。\nModule：StreamServer # StreamServer，提供tcp网络服务，前文已经介绍了StreamServer整个生命周期的一个大致情况，包括启动监听、建立连接、接收请求、过载保护、退出等，现在我们把视角锁定在“请求处理”这个环节，进一步了解其工作过程。\n再简单回顾一下，服务端StreamServer已经启动，现在正调用listener.Accept()等待客户端连接。\nfunc (svr *StreamServer) tcpAccept(handler NHandler, listener net.Listener) { ... for { ... conn, ex := listener.Accept() endpoint := newEndPoint(svr, conn) go endpoint.tcpReader() go endpoint.tcpWriter() } }  客户端发起建立连接请求，listener.Accept()将返回建立的连接，并为连接创建两个协程，一个负责收包，一个负责回包。下面我们就看下收包、解包、请求处理、组包、回包的完整过程。\n收包解包 # go endpoint.tcpReader() 创建了一个协程从连接上读取请求数据。由于tcp是面向字节流的无边界协议，客户端可能会同时发送多个请求包过来，这些包与包之间没有明显的数据边界，即所谓的粘包。tcp服务必须根据业务协议编解码规则处理粘包问题，否则会导致请求解码失败，更无法正常处理请求。\n下面看下框架是如何进行收包解包的，网络交互过程涉及到大量的错误处理（先不展开），这里只截取了收包、解包的部分代码，方便大家理解。\nfunc (endpoint *EndPoint) tcpReader() { ... // 回忆下，不同的协议都有注册对应的协议handler，如nrpc协议对应NRPCHandler handler := svr.protoHandler // resizable buffer是网络收包过程非常倚重的一种存储结构，其大小可伸缩 // 同时为了减少内存分配、回收压力，采用了内存池的方式，预先分配特定大小的buffer用于收包， // 如果收包数据当前buffer不够用的情况下，buffer就会动态增长以满足对存储空间的要求 buf := bufPool.Get() defer bufPool.Put(buf) OUT: for { select { case \u0026lt;-ctx.Done(): return default: // 读取连接上到达的数据，这里设置一个读超时时间 // 如果连续一段时间(默认5min)连接上没有数据到达，则认为连接空闲，服务端为节省资源可以主动断开连接 ex := conn.SetReadDeadline(time.Now().Add(time.Millisecond * time.Duration(timeout))) // 读取连接上的请求数据，一次读取可能遇到如下情形： // - 完全没有读取到数据，这种会出现读取超时，for循环continue OUT，继续执行下次读取 // - 读取到了不足一个包的数据，这种会返回io.ErrUnexpectedEOF，for循环continue OUT继续收取包的剩余数据 // - 刚好读取到了一个完整包的数据，这种handler.Input(...)会返回一个请求session处理， // - 读取到了不止一个请求包的数据，这种会返回最前面请求对应的session，剩余数据参考上述情形之一继续处理 _, ex = buf.ReadFromOnce(conn) // 可能一次读取了多个请求包，需要循环处理 for { buf.MarkReadIndex() // 这里使用协议handler对buf中接收的数据进行解码操作，如果能成功解出一个请求体，则返回对应的session nSession, ex := handler.Input(remoteAddr, buf) // 包不完整不全直接忽略，继续收包 if io.ErrUnexpectedEOF == ex { buf.ResetReadIndex() continue OUT } // 如果包不合法，如校验发现严重错误（非收包补全）如幻数、长度校验失败，关闭连接 if ex != nil { return } } } ... }  请求处理 # 假定从连接上读取的数据，经协议handler校验并解码出了一个完整的请求包，此时协议handler会创建一个匹配的session（如nrpc协议对应NRPCSession），见 nSession,ex := handler.Input(remoteAddr, buf 。创建的session用于跟踪一个请求的完整生命周期，session记录了客户端请求、服务端响应、服务处理过程中的错误事件、分布式跟踪、日志信息等等。\n当StreamServer成功从连接上读取到一个请求准备开始处理之前，需要检查下当前是否已经超过了服务允许同时处理的最大请求数，如果服务端将触发过载保护动作，直接丢弃请求。\nfunc (endpoint *EndPoint) tcpReader() { ... OUT: for { select { ... //可能一次收到多个请求包，需要循环处理 for { buf.MarkReadIndex() nSession, ex := handler.Input(remoteAddr, buf) ... if requestLimiter.TakeTicket() { svr.nserver.workpool.Submit(func() { //process defer func() { requestLimiter.ReleaseTicket() }() ex := svr.requestHandler(ctx, nSession) if ex != nil { svr.log.Error(\u0026quot;[tcp-%s] handler Process error:%s\u0026quot;, handler.GetProto(), ex.Error()) return } endpoint.sendChan \u0026lt;- nSession.GetResponseData() cost := time.Since(nSession.ProcessStartTime()).Nanoseconds() / 1000000 svr.nserver.monitorCost(nSession.GetCmdString(), cost) }) } else { //过载了直接关闭连接 log.Error(\u0026quot;[tcp-%s] [!!close conn!!] nserver reqs overload\u0026quot;, handler.GetProto()) return } } } } }  在请求没有触发服务过载保护的前提下，即 requestLimiter.TakeTicket() == true 时，此时会将请求递交给协程池处理，svr.nserver.workerpool.Submit(func(){…})。协程池的大致实现逻辑前面已有提及，它负责执行我们提交的任务，也就是这里workerpool.Submit(f func(){…})的参数f。注意到参数f中包含了这样一段代码：\nfunc f() { defer func() { requestLimiter.ReleaseTicket() }() ex := svr.requestHandler(ctx, nSession) if ex != nil { return } endpoint.sendChan \u0026lt;- nSession.GetResponseData() cost := time.Since(nSession.ProcessStartTime()).Nanoseconds/1000000 svr.nserver.monitorCost(nSession.GetCmdString(), cost) }  收包处理流程结束之后，需要释放ticket，见defer函数。关于请求的正常处理流程的入口则是 svr.requestHandler(ctx, nSession) ，这里的svr.requestHandler其实就是 cmd_handler.go:process(…) 方法，在 neat_svr.go:NewNServer() 方法体中 svr.requestHandler = NewRequestHandler()，而NewRequestHandler的返回值则是cmd_handler.go:process(…) 方法。\ncmd_handler.go:process(ctx context.Context, session nserver.NSession)请求处理的核心逻辑，包括请求命令字与处理方法的路由控制策略、调用用户自定义处理函数，方法执行完成后nSession中将包含该请求对应的响应结果。\n组包回包 # 回包协程，执行下面的逻辑，循环从endpoint.sendChan中取出响应包，并发送给请求方。\nfunc (endpoint *EndPoint) tcpWriter() { ... for { select { case \u0026lt;-ctx.Done(): return case dataRsp := \u0026lt;-endpoint.sendChan: conn.SetWriteDeadline(time.Now().Add(time.Millisecond * time.Duration(timeout))) dataLen, ex := conn.Write(dataRsp) } } }  StreamServer的大致执行逻辑就介绍到此，更多细节信息，可以阅读下相关代码。\nModule：PacketServer # PacketServer，提供udp网络服务，前文已经介绍了PacketServer整个生命周期的一个大致情况，包括启动监听、端口重用、过载保护、退出等，现在我们把视角锁定在“请求处理”这个环节，进一步了解其工作过程。\nREUSEPORT # UDP是无连接协议，不存在TCP数据传输过程中的粘包问题，在收包、解包方面的处理逻辑会简单一点。与TCP不同的是，tcpClient和tcpServer建立连接的时候，tcpServer端会创建连接套接字， 我们每个连接套接字创建了一个专门的协程进行收包、解包。相比之下，UDP本身没有连接的概念，udpServer收包就是通过监听套接字，如果我们只创建一个协程来进行数据包的收包、解包操作，和tcpServer相比，在性能上就会有点逊色。\n为此，udpServer的收包，这里利用了reuseport相关的能力。socket选项SO_REUSEPORT允许多线程或者多进程bind到相同的端口，网络数据包到达的时候，内核会在这些线程或进程之间进行分发，具备一定的负载均衡的能力。目前框架是基于当前CPU核数N来决定reuseport的次数，每reuseport.ListenPacket(…)一次，都会创建一个udpsocket，此时再创建一个协程用于udpsocket的收包、解包操作。这种方式和单纯从一个监听套接字上收包、解包相比，提高了收包、解包的效率。\n其实TCP、UDP都可以基于reuseport进一步提升性能，框架目前将其应用在UDP上。\n收包解包 # 相比较TCP收包而言，UDP收包的逻辑就简单了很多。\n在监听套接字上循环收包，一旦检测到ctx.Done上游超时、cancel事件，则执行退出逻辑，关闭udp监听套接字。反之，则读取请求体，注意，这里有个允许同时处理请求数限制，因此会先检查 requestLimiter.TakeTicket() 是否成功，如果成功则执行实际的收包、处理逻辑，反之框架认为当前请求量过载，执行丢弃逻辑，调用方会感知到超时。\n未过载的情况下，框架会从内存池里面分配或者复用一个以前分配的buffer，用来接收UDP请求体，并构建一个协议匹配的session，此时buffer已经完成了当前次的使命，将其放回内存池备用。\n详细的UDP收包处理逻辑如下所示：\nfunc (svr *PacketServer) udpRead(handler NHandler, udpConn net.PacketConn) { defer udpConn.Close() ctx, cancel := context.WithCancel(svr.ctx) ... requestLimiter := svr.nserver.reqLimiter for { select { case \u0026lt;-ctx.Done(): return default: if requestLimiter.TakeTicket() { data := udpRecvBufPool.Get().([]byte) n, remoteAddr, ex := udpConn.ReadFrom(data) ... r := bytes.NewBuffer(data[:n]) nSession, ex := handler.Input(remoteAddr, r) udpRecvBufPool.Put(data) ... } else { udpSvrReceiveExceedMax.Inc(1) //udp-svr 收包过载丢弃 } } } }  请求处理 # 与TCP的处理方式类似，当正确收取了一个UDP请求，并为之构建好协议匹配的session之后，就会将其一个任务处理的闭包函数作为一个task递交给workerpool进行处理，svr.nserver.workpool.Submit(func() {…})，该闭包函数执行完毕后也要注意释放requestLimiter，闭包函数中的 svr.requestHandler(ctx, nSession) 就是 cmd_handler.go:process(ctx, session) 方法，与TCP的处理逻辑是一致的。之所以在svr.requestHandler和cmd_handler.go:process(…)中间再加一层抽象，是考虑到业务开发者可能希望定制化requestHandler的能力，cmd_handler.go:process(\u0026hellip;)方法只是提供了一个还不错的默认实现。\nsvr.requestHandler(ctx, nSession)执行完成后，nSession中将包含请求体的响应结果，响应结果将写入sendChan中，由负责回包的协程 go svr.udpWrite(...) 执行回包操作。\nfunc (svr *PacketServer) udpRead(handler NHandler, udpConn net.PacketConn) { ... sendChan := make(chan *packet, 1000) go svr.udpWrite(ctx, cancel, udpConn, sendChan) ... for { select { case \u0026lt;-ctx.Done(): ... default: if requestLimiter.TakeTicket() { nSession, ex := handler.Input(remoteAddr, r) svr.nserver.workpool.Submit(func() { defer func() { requestLimiter.ReleaseTicket() }() ex = svr.requestHandler(ctx, nSession) dataRsp := nSession.GetResponseData() ... sendChan \u0026lt;- \u0026amp;packet{dataRsp, remoteAddr} }) } else { ... } } } }  组包回包 # 回包协程执行下面的逻辑，它循环从sendChan中收取UDP请求对应的响应，并检查响应数据是否超过64KB，超过则丢弃，反之则将响应返回给请求方。\nfunc (svr *PacketServer) udpWrite(ctx context.Context, cancel context.CancelFunc, conn net.PacketConn, sendChan chan *packet) { defer cancel() for { select { case \u0026lt;-ctx.Done(): return case p := \u0026lt;-sendChan: if len(p.data) \u0026gt; 65536 { udpRspExceed64k.Inc(1) //udp回包超过64k continue } conn.SetWriteDeadline(time.Now().Add(time.Millisecond * time.Duration(timeout))) datalen, ex := conn.WriteTo(p.data, p.addr) ... } } }  PacketServer的大致执行逻辑就介绍到此，更多细节信息，可以阅读下相关代码。\nModule：HttpServer # HttpServer中有没有使用worker池（协程池）进行处理呢？该ServerModule是建立在标准库http实现之上的，GoNeat只是将请求处理的Handler传给了标准库http实现，并没有对标准库具体如何处理该请求做什么干预，比如是否采用worker池（协程池）。关于这一点，答案是否，可以查看下go标准库源码。\n为每个连接创建一个协程进行处理 # 标准库实现中，建立监听套接字之后，调用 svr.Serve(listener) 开始接受入连接请求，该方法循环 Accept() 取出建立好的tcp连接并进行处理。标准库实现针对每一个连接都启动了一个goroutine进行处理，这与我们StreamServer的实现方式是类似的，所不同的是处理连接上并发请求的方式。\nnet/http/server.go:\n// After Shutdown or Close, the returned error is ErrServerClosed. func (srv *Server) Serve(l net.Listener) error { ... for { rw, e := l.Accept() ... c := srv.newConn(rw) ... go c.serve(ctx) } }  同一连接，串行收包、处理、回包 # 注意 c.Serve(ctx context.Context) 的注释部分，其中有提到HTTP/1.x pipelining的处理局限性，一个连接上可能会有多个http请求，标准库当前实现逻辑是读取一个请求、处理一个请求、发送一个响应，然后才能继续读取下一个请求并执行处理、响应，所以多个http请求的处理是串行的。\n注释中也有提到，可以收取多个请求，并发处理，然后按照pipeling请求顺序按序返回结果（http协议头并没有类似我们业务协议seqno的字段），但是当前没有这么做。\n连接上请求的读取、处理、回包都是在同一个连接中完成处理的，并没有像我们StreamServer、PacketServer那样将请求递交给worker池（协程池）进行处理。\nnet/http/server.go:\n// Serve a new connection. func (c *conn) serve(ctx context.Context) { ... // HTTP/1.x from here on. c.r = \u0026amp;connReader{conn: c} for { // 读取连接上的请求 w, err := c.readRequest(ctx) // 读取一个请求，串行处理一个请求 // HTTP cannot have multiple simultaneous active requests.[*] // Until the server replies to this request, it can't read another, // so we might as well run the handler in this goroutine. // [*] Not strictly true: HTTP pipelining. We could let them all process // in parallel even if their responses need to be serialized. // But we're not going to implement HTTP pipelining because it // was never deployed in the wild and the answer is HTTP/2. serverHandler{c.server}.ServeHTTP(w, w.req) // 请求处理结束，finishRequest flush响应数据 w.cancelCtx() w.finishRequest() ... } } func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { handler := sh.srv.Handler if handler == nil { handler = DefaultServeMux } if req.RequestURI == \u0026quot;*\u0026quot; \u0026amp;\u0026amp; req.Method == \u0026quot;OPTIONS\u0026quot; { handler = globalOptionsHandler{} } handler.ServeHTTP(rw, req) }  sh.svr.Handler其实就是nserver.HttpServer.doService()方法。\nnserver/neat_http.go:\n// doService process http request `req` func (svr *HttpServer) doService(w http.ResponseWriter, req *http.Request) { ... }  接管标准库Request URI路由转发 # HttpServer只是在标准库http实现基础上自定义了请求Handler，所有Request URI匹配http.prefix的请求将递交给doService(…)方法处理，在doService方法内再调用nserver.process()方法转入GoNeat框架内置的命令字路由逻辑，与StreamServer、PacketServer不同的是，这里的命令字不再是rpc方法名、命令字拼接字符串，而是Request URI。\nprocess()方法内通过URI路由到对应的处理函数Exec，并完成Exec的调用，拿到处理结果，process()方法返回处理结果，doService方法负责将响应结果写入连接中，c.Serve()中w.finishRequest()负责将响应数据flush。\n至此，一次http请求、处理、响应就结束了。\n而关于HTTP/2中pipelining的处理情况，与之类似，读者可以自行查阅、跟进标准库实现了解相关细节，这里不再赘述。\nHttpServer的大致执行逻辑就介绍到此，更多细节信息，可以阅读下相关代码。\nGoNeat - 服务怠速 # 前文描述了Server实例及各个ServerModule启动、请求处理的过程，当服务空闲的时候会发生什么呢？为这个阶段起了一个好听的名字”怠速”，“怠速”意味着并不是停止服务，服务依旧在空跑，那空跑阶段会发生什么呢？\nGoNeat框架还是会做些事情的，比如清理、释放一些不必要的资源占用，为后续请求处理再次做好准备。\nsync.Pool # 前文提到，在两次gc cycle间隔期，sync.Pool可以有效提升内存分配效率，sync.Pool.Get()申请新内存或者复用已分配的内存，sync.Pool.Put(buf)重新将sync.Pool.Get()返回的buf放回池子以备复用，如果gc来临，sync.Pool中遗留的未使用的内存区将被释放掉。\nfunc poolCleanup() { // This function is called with the world stopped, at the beginning of a garbage collection. // It must not allocate and probably should not call any runtime functions. // Defensively zero out everything, 2 reasons: // 1. To prevent false retention of whole Pools. // 2. If GC happens while a goroutine works with l.shared in Put/Get, // it will retain whole Pool. So next cycle memory consumption would be doubled. for i, p := range allPools { allPools[i] = nil for i := 0; i \u0026lt; int(p.localSize); i++ { l := indexLocal(p.local, i) l.private = nil for j := range l.shared { l.shared[j] = nil } l.shared = nil } p.local = nil p.localSize = 0 } allPools = []*Pool{} }  虽然这部分不是框架本身所施加的，这里列出来也是为了强调下，希望开发者对计算资源保持足够的敏感度，即便是在使用自带gc机制的编程语言条件下，也应该保持这种敏感度。gc不是万能的，可以找出一种case将gc阈值推高进而将内存撑爆。\nworkerpool # 一个workerpool的内部构造大致如下，每个worker其实就是一个goroutine，每个goroutine都绑定了一个独占的任务队列。当请求量上涨的时候，在workers都处于busy状态的情况下，workerpool会检查workers数量是否已经超过指定的上限，如果没有就继续创建worker，如此worker数量会越来越多……\nworkerpool |--worker1 ---- tasks|t1|t2|t3|..| |--worker2 ---- tasks|t4|t5|..| |--worker3 ---- tasks|| |--worker? ---- tasks|| |--workerN ---- tasks|tx|ty|tz|  当请求量降低，甚至是空闲的时候呢？这些worker（goroutine）难道还会存在？似乎没有必要。workerpool也会定时检查workers空闲时间，每次workerpool.Submit(task)的时候，会更新实际接收该task的worker的最近使用时间lastUsedTime，如果currentTime.Since(lastUsedTime) \u0026gt; maxIdleDuration，则认为worker空闲，终止worker执行就可以了。\n空闲连接 # 连接保活，是一个容易引起争论的话题，当前TCP协议本身支持连接保活，每隔一定时间发送一个TCP探针，但是也有人认为这加重了网络拥塞，保活应该在应用层自己实现，如通过心跳机制。\n尽管存在这些争议，TCP保活机制仍然是首选的保活机制之一，因为它不需要引入额外的开发、保活策略。连接保活可以在客户端做，也可以在服务端做，其作用只是为了探测连接是否还健康地保持着。框架中在服务端进行保活，对于短连接的情况，继续保活显得有点多余，那为什么框架实现时选择了在服务端进行保活呢？\n因为框架中对TCP完全是以双工的方式进行处理的，如在一个连接上循环收包、处理、回包，并没有做客户端是TCP短连接的假设，客户端不管是TCP短连接、长连接，StreamServer都是一样的处理逻辑，也可以理解成StreamServer鼓励客户端使用TCP长连接，所以在服务端发起保活机制也是很自然的选择。\n一个进程允许打开的文件描述符（fd数量）是有限的，Linux下可以通过ulimit -s进行设置。允许打开的fd数量有限代表什么呢？在Linux下，一切皆文件，几乎所有的资源都被抽象成了文件，而每个文件”句柄“基本上都对应着一个fd。fd数量有限，意味着允许创建的socket数量也是有限的。\n而ulimit -s可能给到了一个很高的值，但是如果我们不小心，也极容易泄露fd。笔者就曾经见过Web服务中client实例化没有使用单例、并且client销毁时没有close(fd)而导致fd泄露，进而迅速拖垮了现网几十台Web服务器的案例。\n考虑到这种种因素，框架还是需要做些事情，将这些服务端空闲的TCP连接及时销毁，并且为了适应不同的业务场景，允许自定义连接空闲时间（记为T）。当连接上连续时间T没有请求到达，服务端认为连接空闲，并关闭连接释放系统资源。\nserver端关闭空闲连接，对client端来说，client收到TCP FIN包，client认为server端只是关闭了连接的写端、读端并未关闭，所以下次client继续向server发送数据时，网络io也已经设置为非阻塞，此时conn.Write(…)返回成功，但其实稍后请求到达server端，server端请求的端口早就已经没有进程使用了，因此会返回TCP RST，此时client端意识到对端已经关闭连接了，但是这个错误client如何能感知到？只能通过额外的conn.Read(…)来感知！\n这里会影响到客户端TCP连接池的实现，要想实现一个可靠的TCP连接池，必须意识到这个问题的存在，我们会在后续client相关实现中继续描述。\n其他问题 # 其他的一些不可或缺，但是可能没那么重要的点，这里先暂时不列出。\nGoNeat - 监控上报 #   Metric\n框架支持metric，将框架属性监控能力与公司组件进行了解耦，metric当前支持4个维度：counter、gauge、timer、histogram，也提供了适配monitor的metric reporter。框架上报了自身的一些关键指标，方便业务开发人员及时根据框架监控，感知业务中潜伏的问题。\n  Tracing\n框架支持分布式跟踪，对rpc调用自动植入trace数据，业务开发无感知，只需部署或者接入相关的tracing backend（如zipkin、jaeger或者天机阁即可），可以很方便地对全链路进行跟踪、错误回溯。\n  Monitor\n作为公司常用监控组件，go-neat/tencent/attr提供了monitor相关的封装，业务开发人员可以方便地拿来使用，并提供了批量申请monitor的工具，简轻业务开发人员监控打点的负担。\n  Habo\n哈勃作为公司级下一代监控平台，框架层也进行了尝试，目前对模调信息进行了上报，可以很方便地对服务成功率、耗时分布进行统计，可以作为服务运营质量的一个参考指标。\n  GoNeat - 平滑退出 #   监听信号，平滑退出\n框架支持监听指定信号执行平滑退出逻辑，目前来看框架退出时，会完成log刷盘、等待指定时长后再退出，等待退出期间server端可以尽力处理入队请求，但是不保证100%处理完。\n  context.Context超时\n框架设计时对context.Context的使用场景非常明确，将其用于全局超时控制，而不用来传值。给到一个context，想了解它里面携带了什么数据，除了明确知道key没有什么更加直观的方法，而key可能分散在多个文件、同一个文件的不同地方，这非常不直观、不友好。我们不希望业务开发者来猜测，我们会在context里面塞入什么特殊的东西，我们什么都不塞，仅仅是全局超时控制。\nnserver.ctx是root context，框架中ServerModule、Endpoint、收发包实现、业务逻辑处理中等等出现的context，默认都是派生自nserver.ctx，这意味着当框架收到信号执行退出逻辑时，取消nserver.ctx将取消所有的child context，我们在ServerModule、Endpoint、收发包实现、业务逻辑处理代码中等等，都植入了检测context.Done()的判断逻辑，以让系统中各个零部件及时作出步调一致的动作，如logger组件快速刷盘后退出、StreamServer关闭监听套接字尽最大努力处理已入队请求等。\n  还没有那么平滑？\n可能看到这里，不少开发者认为，似乎还没有那么平滑，关于平滑退出的设计可以在go-neat/core issues中进行更详细地讨论。\n  GoNeat - More # 其实还有很多地方没有介绍，如ClientAdapter实现、高并发写操作Map实现、Json Map WeakDecode、限频措施、客户端连接池更可靠地连接活性检测、可靠的应用层协议设计等，这里感兴趣的朋友可以先查阅下相关代码，稍后我们会继续补充。\n写在最后，GoNeat框架一直处于比较活跃的开发状态，框架代码一直在小幅度、不间断地优化中，文档和框架比较起来，可能会略显滞后，如果您发现文档有问题，也请反馈给我们。\n感谢如下同学为框架开发作出的贡献：脱敏处理 :)\n GoNeat - End of Life :( # 2020年7月份开始，PCG开始组织大规模的技术治理，其中就包括事实上的公司级的微服务框架tRPC的建设，自此以后我便将人力投入到了tRPC的建设、贡献中，GoNeat自这个时间点开始开始停止新特性更新。\nGoNeat框架是一款在2018.3月开始陆陆续续编写的框架，到2018.8月份开始小规模测试，之后的两年里成为了团队的核心开发框架，支撑了团队几千个微服务，直到PCG建设tRPC框架后，GoNeat框架也最终走向了停止后续开发的命运。\n虽然未来难免被遗忘、废弃，但是它过去也曾经”繁荣“过，几十人的活跃开发组织，几百个的issue沟通讨论、几千的commit、很多次技术分享，沉淀下来的东西也可以对新同学成长起到些指引帮助作用，对后续框架设计开发者也具有一定的参考价值，希望本文能对框架设计实现感兴趣的同学有帮助。\n"}),a.add({id:430,href:"/tags/microservice/",title:"microservice",description:"",content:""}),a.add({id:431,href:"/tags/rpc/",title:"rpc",description:"",content:""}),a.add({id:432,href:"/tags/trpc/",title:"trpc",description:"",content:""}),a.add({id:433,href:"/tags/rm/",title:"rm",description:"",content:""}),a.add({id:434,href:"/tags/rm-safe/",title:"rm-safe",description:"",content:""}),a.add({id:435,href:"/blog/2019-10-18-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E4%B8%80%E4%B8%AA%E6%9B%B4%E5%AE%89%E5%85%A8%E7%9A%84%E5%88%A0%E9%99%A4%E5%91%BD%E4%BB%A4rm/",title:"如何实现一个更安全的删除命令rm",description:"rm -rf，这个命令乍一看浑身起鸡皮疙瘩，很多操作过Linux服务器的人都对此小心翼翼。前不久一不小心在macOS上执行了rm -rf，命令执行过程中看着闪过的文件，我竟然删除了HOME下的东西，眼睁睁看着文件被删除，ctrl+c已经失去响应……于是便有了本文介绍的rm-safe工具，避免以后误删除重要文件。",content:" img { width: 680px; padding-bottom: 1rem; }  背景 # 大家有没有因为一时大意，错误地执行了rm -rf而导致重要文件被删除的情况？一定有那么一次两次的吧。前几天，我又犯了这一次这样的错误。本来是要删除当前目录下的一个文件，于是执行 rm -rf .，这里还没有输入完，因为我调整了KeyRepeat设置项的原因吧，按键延迟很短，结果命令变成了 rm -rf ..，这个时候..已经指向了HOME目录……额，没关注右手，左手还没有tab候选，右手已经键入了回车，gg，眼睁睁地看着大量文件被删除，ctrl+c已经太晚了 :( 。\n多亏macOS默认对Desktop、Document等目录下的文件做了自动地备份，不然就真的要苦了，虽然对重要文件、数据也有做过备份，但是也不能做到按月、按天的备份，哪怕是最近几个月的数据、配置的丢失，对我来说也是挺伤的。果不其然，后续几天陆陆续续发现丢失了各种各样的配置，IDE的、bash的、git的、pet的……各种各样的！\n不幸中的万幸，一些自己认为真的很重要的数据，一般在Document中交给icloud做了备份，这些数据倒是可以恢复，虽然慢了点，但是能恢复总还是好的！感谢icloud提供的云存储服务！\n如何避免误删除文件 # 经此一役之后，我还是思考了一些如何规避的问题，我有多年的Linux使用经验，竟然也会犯这样的错误，我将其归因于：过失问题，虽然像我这样的有经验的开发者极少会犯这样的错误，但是还是会偶尔发生！很多开发者都提出了自己的一些想法，如何规避rm造成的文件误删问题，我们这里不考虑如何恢复的问题，如果是私人笔记本单硬盘单分区的话，恢复的困难度是比较高的。\n  删除只用系统gui删除，如macOS、windows、kde下删除文件到垃圾箱，误删的话还是可以从垃圾箱恢复的；\n不适用：执行删除动作是很常见的，作为一名开发者，我不大可能使用gui来频繁切换目录后才删除文件。\n  自定义bash中的alias，如alias rm=\u0026ldquo;function rm() {\u0026hellip;.}\u0026quot;，该函数内部做一些检查，以决定是否删除文件；\n不适用：这也是一个解决问题的思路，但是能否与原生的/bin/rm命令完全兼容是一个问题，而且检查逻辑可能要频繁改动才能胜任各种避免误删的场景，使用起来不是那么灵活。\n  使用第三方的删除工具，如github上的一些类似rm-safe的工具，代替原生的/bin/rm命令；\n不适用：这些工具不能完全与/bin/rm兼容，尤其是那些命令选项不完全兼容，而/bin/rm是一个非常好用的工具，我们只是想尽力规避下误删除的风险而已。\n  看上去没有一个现有工具能够完全满足自己的选择，那就自己按自己的需要开发一个吧！\n设计更安全的rm工具 # 分析/bin/rm # 首先，不得不说，/bin/rm是一个非常好用的命令，删除文件、删除没目录等等，可以说使用频率非常高，它也确实很好用。说白了，我们只是要在它的基础上做些安全方面的风险规避就能满足需求。\n/bin/rm，它有一系列的命令选项，且是POSIX风格的。\n 如果我们开发一个工具，或者在/bin/rm基础上包一层的话，我们最好也使用POSIX风格的命令选项来解析; 涉及到rm相关的选项，原来rm有的我们也要有，而且功能必须保持一致；  说白了就是，我们要保证用户使用的时候，习惯保持不变，甚至没有意识到自己在使用一个安全增强的rm。\n如何安全增强 # rm动作是用户自己执行的，除了用户自己清楚目标文件是否重要，没有其他人可以做出胜过文件拥有者的决定，所以安全增强的决定还是交给用户自己来做出，我们的工具只是协助用户完成这样的动作。\n设计一个安全增强的rm：\n 支持pin命令，如rm pin Documents，保护Documents目录及其下的文件；  当执行rm -rf Documents时，发现有.pinLock文件存在，表示Documents目录及其下的文件、子目录受保护，拒绝删除； 当执行rm -rf Documents/dir/file时，会递归地回溯目录层级，如果路径上任一父目录受保护，该文件不能被删除；   支持unpin命令，如rm unpin Documents，取消Documents当前一级目录的保护；  当执行rm -rf Documents/dir/file时，如果Documents处于unpin状态，但是dir处于pin状态，file也是受保护的，不能删除；   支持-r选项，允许递归地添加、移除保护；  实现该rm命令 # 以下是大致的rm命令操作的help信息，它有3个子命令，help显示帮助信息，pin用来对目录添加保护，unpin移除保护。\n$ rm help hitzhangjie/rm is an security-enhanced version of /bin/rm, which could avoid the deletion of files by mistake. rm help: display help info rm pin: -r, pin target recursively rm unpin: -r, unpin target recursively  当传递给rm的选项，不是rm help/pin/unpin这样的选项时，会将选项当做/bin/rm的选项，进而执行rm相关的动作，所不同的是，这里的删除并不是由/bin/rm来执行，而是由我们重写的一个rmCmd来执行，其内部会首先检查待删除文件、目录是否正在被保护。\n该安全增强的rm工具的代码，请戳 hitzhangjie/rm 查看。\n代码量不多，有几个重要的点阐述下：\n 执行rm命令时，给用户必要的提示信息，让用户知道这是一个安全增强版的rm命令，并非shell原生的rm； 执行rm pin时，创建文件锁.pinLock，该文件的存在表示其所在的目录及目录下的文件、子目录统统受保护，执行rm时不能删除； 执行rm unpin时，删除文件锁.pinLock，改文件备移除之后，表示所属目录及目录下的同级文件、目录不再受保护，但是若子目录中有.pinLock文件仍受保护； 执行rm时，因为rm是POSIX风格的命令选项，意味着实现pin、unpin时，最好就别再使用go标准库提供的选项风格进行解析，不然两种风格的选项混在一起，使用起来多有不便； 这里我们使用的是pflags这一基于POSIX风格的flags解析库。  代码量不多，感兴趣的话，可以自行查看源码，了解具体的实现细节。\n如果希望自己也能避免因为手贱带来的文件误删问题，欢迎使用体验该工具！\n小结 # 从日常使用角度出发，思考了靠人来避免误删除文件的操作是基本行不通的，还是要提供有效的工具去协助人来对重要文件进行保护。经历过一两次这样的文件误删除操作之后，痛得难受，就醒了，于是自己开发了这个安全增强版本的rm工具，其实寥寥数行代码而已，但是却帮了我大忙。现在偶尔也是会敲出很可怕的命令，但是因为我已经提前对重要文件目录做了保护，再没发生过重要文件被rm误删除的场景了。\n我不能保证自己以后不会手贱，但是有这个工具的存在，很大程度上减轻了我的心理压力，哈哈！希望对读者们有帮助! :)\n"}),a.add({id:436,href:"/tags/code-reivew/",title:"code reivew",description:"",content:""}),a.add({id:437,href:"/tags/cr/",title:"cr",description:"",content:""}),a.add({id:438,href:"/tags/google/",title:"google",description:"",content:""}),a.add({id:439,href:"/blog/2019-09-10-%E5%A6%82%E4%BD%95%E6%9B%B4%E5%A5%BD%E5%9C%B0%E8%BF%9B%E8%A1%8C%E4%BB%A3%E7%A0%81review/",title:"Google CR指引, 如何推进代码评审",description:"代码评审，是一种协作的方式，也是一种做事的方式，也是一种思想交流、对待错误的态度……但是要想把代码评审做好，却不是一件简单的事情。代码评审不能太功利、太敷衍、太随意，需要好的“实践经验”来指导。",content:"最近学习了Google的CodeReview指引，整理了其中一些比较有价值的点，分享给大家。\nGoogle Code Review Guidelines # Google积累了很多最佳实践，涉及不同的开发语言、项目，这些文档，将Google工程师多年来积攒的一些最佳实践经验进行了总结并分享给众开发者。学习下这里的经验，我们在进行项目开发、开源协同的过程中，相信也可以从中受益。\nGoogle目前公开的最佳实践相关文档，目前包括：\n Google\u0026rsquo;s Code Review Guidelines，Google代码review指引，包含以下两个系列的内容：  The Code Reviewer\u0026rsquo;s Guide The Change Author\u0026rsquo;s Guide    这了涉及到Google内部使用的一些术语，先提下：\n  CL: 代表changelist，表示一个提交到VCS的修改，或者等待review的修改，也有组织称之为change或patch；\n  LGTM：代表Looks Good to ME，负责代码review的开发者对没有问题的CL进行的评论，表明代码看上去OK；\n  The Code Reviewer\u0026rsquo;s Guide # 从代码reviewer的角度出发，介绍下Google内部积累的一些good practices。\nIntroduction # Code Review（代码评审）指的是让第三者来阅读作者修改的代码，以发现代码中存在的问题。包括Google在内的很多公司会通能过Code Review的方式来保证代码和产品的质量。\n前文已有提及，CR相关内容主要包括如下两个系列：\n The Code Reviewer\u0026rsquo;s Guide The Change Author\u0026rsquo;s Guide  这里先介绍下CR过程中应该做什么，或者CR的目标是什么。\nWhat Do Code Reviewers Look For? # Code review应该关注如下方面：\n Design：程序设计、架构设计是否设计合理 Functionality：代码功能是否符合作者预期，代码行为是否用户友好 Complexity：实现是否能简化，代码可读性是否良好，接口是否易用 Tests：是否提供了正确、设计良好的自动化测试、单元测试 Naming：变量名、类名、方法名等字面量的选择是否清晰、精炼 Comments：是否编写了清晰的、有用的注释 Style：代码风格是否符合规范 Documentation：修改代码的同时，是否同步更新了相关文档  Picking the Best Reviewers # 一般，Code review之前，我们应该确定谁才是最好的、最合适的reviewer，这个reviewer应该**“有能力在比较合理的时间内对代码修改是否OK做出透彻、全面的判断”**。通常reviewer应该是编写被修改代码的owner，可能他是相关项目、相关源文件、相关代码行的创建者或者修改者，意味着我们发起Code review时，同一个项目可能需要涉及到多个reviewer进行Code review，让不同的、最合适的reviewer来review CL中涉及到的不同部分。\n如果你心目中有一个合适的reviewer人选，但是这个人当前无法review，那么我们至少应该“@”或者“邮件抄送”该reviewer。\nIn-Person Reviews # 如果是结对编程的话，A写的代码B应该有能力进行代码review，那么直接找B进行review就可以了。\n也可以进行现场评审（In-Person Reviews），一般是开发者介绍本次CL的主要内容、逻辑，其他reviewer对代码中年可能的问题、疑惑进行提问，本次CL的开发者进行解答，这种方式来发现CL中的问题也是常见的一种方式。较大型、急速上线的项目，这种方式团队内部用的还是比较多的。\nHow to Do a Code Review # 这里总计了一些Code review的建议，主要包括如下一些方面：\n The Standard of Code Review What to Look For In a Code Review Navigating a CL in Review Speed of Code Reviews How to Write Code Review Comments Handling Pushback in Code Reviews  The Standard of Code Review # 代码review的主要目的就是为了保证代码质量、产品质量，另外Google的大部分代码都是内部公开的，一个统一的大仓库，通过代码review的方式来保证未来Google代码仓库的质量，Google设计的代码review工具以及一系列的review规范也都是为了这个目的。\n为了实现这个目标，某些方面需要做一些权衡和取舍。\n首先，开发者必须能够持续优化。如果开发者从来不对代码做优化，那么最终代码仓库一定会烂掉。如果一个reviewer进行代码review时很难快速投入，如不知道做了哪些变更，那么代码reviewer也会变得很沮丧。这样就不利于整体代码质量的提高。\n另外，代码reviewer有责任维护CL中涉及到的修改的质量，要保证代码质量不会出现下降，时间久了也不至于烂尾。有的时候，某些团队可能由于时间有限、赶项目，代码质量就可能会出现一定的下降。\n还有，代码reviewer对自己review过的代码拥有owner权限，并要为代码后续出现的问题承担责任。通过这种方式来进一步强化代码质量、一致性、可维护性。\n基于上述考虑，Google制定了如下规定来作为Code review的内部标准：\n In general, reviewers should favor approving a CL once it is in a state where it definitely improves the overall code health of the system being worked on, even if the CL isn’t perfect.\n一般，reviewers对CL进行review的时候，达到approved的条件是，CL本身可能不是完美的，但是它至少应保证不会导致系统整体代码质量的下降。\n 当然，也有一些限制，例如，如果一个CL添加了一个新特性，reviewer目前不想将其添加到系统中，尽管这个CL设计良好、编码良好，reviewer可能也会拒绝掉。\n值得一提的是，没有所谓的perfect code，只有better code。\n 代码reviewers应该要求开发者对CL中每一行代码进行精雕细琢，然后再予以通过，这个要求并不过分。 或者，代码reviewers需要权衡下他们建议的“精雕细琢”的必要性和重要性。代码reviewers应该追求代码的持续优化，不能一味地追求完美。对于提升系统可维护性、可读性、可理解性的代码CL，reviewers应该尽快给出答复，不能因为一味追求完美主义将其搁置几天或者几周。  Mentoring # Code review对于教授开发者一些新的东西，如编程语言、框架、软件设计原则等是非常重要的手段。进行代码review的时候添加一些comments有助于帮助开发者之间分享、学习一些新东西。分享知识也是持续改进代码质量的重要一环。\n需要注意的是，如果comments内容是纯教育性的、分享性的，不是我们前面提到的强制性的必须应该做出优化的，那么最好在comments内容里面添加前缀“Nit (Not Important)”，这样的评论表示当前CL中不一定非要做出对应的优化、修改，只是一个建议、分享。\nPrinciples #  技术本身、数据至上，以及一些个人偏好 代码风格的重要性，力求代码风格的一致，如果没有明确的代码风格，就用之前作者的风格 业内的代码风格、个人偏好，需要在二者之间适当平衡，reviewer也应该在代码风格上注意 如果没有明确的一些规定，reviewer可以要求CL作者遵循当前代码库中的一些惯用的做法  上述各条，均以不降低系统整体代码质量为度量标准。\nResolving Conflicts # 如果在代码review中出现了冲突的意见、观点，首先，开发者、reviewer应尽可能基于之前的代码、现在CL的代码达成一个共识，如果仍然达不成共识，或者很困难，最好能进行面对面沟通，或者将当前CL升级一下，供更多的人员进行讨论。可以考虑将技术Leader、项目经理拉进来一起讨论下。\n这种面对面的方式比单纯地通过comments进行讨论要高效、友好地多，如果条件不允许只能通过comments方式进行，那么对于讨论的结果，应进行适当的总结，给出一个结论，方便之后的开发者能够了解之前的讨论结果。\n目标就是，不要因为代码reviewer和CL作者之间达不成一致，就长时间将CL搁置。\nWhat to Look For In a Code Review # 结合前面提到的一些Code review标准，将Code review中应该关注的点进一步细化，主要以下内容。\nDesign # Code review过程中最重要的事情就是看CL的整体设计是否合理，如CL中涉及到的各个部分的代码之间的接口、交互、衔接是否合理，是业务代码修改还是库的修改，和系统整体的集成是否合理，现在这个时间点添加这个新特性是否合理等等。\nFunctionality # CL的功能是否符合开发者预期，开发者期望的这部分修改是否对用户友好，这里的用户包括产品用户（实际使用产品的人员）和开发者（将来可能使用这部分代码的人员，如CL修改的库代码）。\n一般，我们希望开发者发起Code review之前，能够对CL进行充分的测试确保功能是符合预期的。但作为reviewer，还是要检查下边界条件的处理是否到位，比如并发中的data race问题，确保代码中不存在“可能”的bug。\nreviewer有条件的话，也可以亲自验证下CL，比如CL是面向用户的产品（如UI改变），单纯看代码不能直觉地感受到做的调整，reviewer可以亲自patch这部分代码、编译构建、安装之后来体验下具体的改变。如果不是特别方便的话，也可以找相应的开发者提供一个demo演示下CL中涉及的变化。\n另一个非常重要的点是，要检查CL中是否存在某种类型的并发问题，如deadlocks、race conditions等。这些问题也不是运行一下代码就能发现的，往往需要reviewer来细致地考虑下相关的操作，才能判定是否有引入该类问题。\nComplexity # CL是否过于复杂，这个需要对CL中的不同层次的内容进行逐一检查，如每行代码是否过于复杂，函数实现是否过于复杂，类实现是否过于复杂等。“过于复杂”意味着，不能被其他开发者快速吸收、理解。也有个笑话，开发者在调用、修改自己编写的代码的时候容易引入引入bug。这些都说明了复杂性的问题所在。\n过度设计也是Complexity中的一种，开发人员可能对当前需要解决的问题进行了解决，但是在此基础上进行了过度的、不必要的延伸。reviewers需要小心判断，识别出一个CL中是否存在过度设计的问题。reviewers应鼓励开发人员解决当前已经存在的、明确的问题，避免开发人员做些主观上认为未来可能需要的某些功能。\nTests # CL中应该包含必要的单元测试、集成测试等必要的测试用例，除非这个CL是为了紧急解决线上问题，这种情况下未能及时添加可以原谅。\n确保CL中包含的测试用例是正确的、有意义的、有效的，不要为了写测试用例而写测试用例，测试用例是为了辅助验证我们的代码是否符合预期的，因此几乎任何时候，确保测试用例有效都是至关重要的，测试用例也是代码维护工作的一部分。\nNaming # 命名（变量名、函数名、类名等等）是否合理，一个好的名字应该长度适中，又能够清晰地表达其代表什么。\nComments # 开发者是否提供了清晰、易于理解的英文注释。\n提供的注释是否是必要的，注释不是笔记，注释应该用来解释某段代码为什么存在，不需要解释这段代码要干什么，这样的注释才有意义。如果不提供该注释将无法理解该代码，请考虑一下设计、编码实现复杂度等是否有问题，是否可以简化。也有一些例外情况，如正则表达式或者复杂的算法，提供注释注明其作用是有价值的。\n当前CL之前的注释，也需要检查一下，可能当前CL解决了一个问题，对应的某个TODO可以删除了。\n注：这里的注释不同于类注释、模块注释、函数注释，这些注释需要表明其存在的目的、功能、如何使用、有什么行为或副作用。\nStyle # 代码风格问题，Google也提供了一些代码规范，这里的规范涵盖了多种编程语言的规范，请确认CL遵循此规范。\n如果某些地方没有明确的代码规范指引，而你有觉得开发者这种写法不太好，你想提出点建议的话，review的时候请在意见里面加个前缀“Nit:”，Not Import Pick，以表明这是个非强制性的建议。不要因为个人偏好问题，阻塞CL的代码review过程。\nCL里面不要既做代码逻辑修改，又做大范围格式化的操作，这可能让review、merge、rollback等变得复杂，如果确实有必要做这样的调整，请提供两个CL。第一个用来格式化，第二个在此基础上再进行代码逻辑的修改。反过来也可以，但是不要一次做两件“变动巨大”的事情。\nDocumentation # 如果一个CL改变了用户build、test、interact with、release code的方式，请同步检查下文档是否也要更新，包含READMEs、g3doc pages以及其他一些生成的reference docs。如果CL删除了或者废弃了某些代码，考虑下是否对应的文档内容也有需要删除的。\n如果发现缺少某些文档内容，请联系开发者补齐。\nEvery Line # 检查review任务中你分配的每一行代码。对于某些自动化生成的数据文件、代码文件（如*.pb.go）、大型数据结构，你可以快速扫过去，但是如果是开发者自己写的class、function、block of code，这种不能扫一下就过去了，需要仔细检查。\n开发者自己写的代码，也有重要的、不重要的之分，某些代码片段需要更仔细地review，比如某些分支判断逻辑，reviewer需要培养这方面的识别重要代码路径的能力。如果目前没有这种识别关键路径的能力，也至少应该确保你看懂了这些代码。\n如果review过程中，你发现某些代码实在是费解，严重拖慢了review进度，这种情况下不要犹豫，直接联系代码作者来解释它是干什么的、能否简化实现，然后再review。在Google雇佣了很多优秀的开发者，如果某位看不懂，那么其他人可能也看不懂，随着业务需求变更，将来新加入的开发者更可能看不懂。在Tencent以及其他公司，这种情况也是一样的，reviewer应该直接联系代码作者来解释、优化代码实现，某种意义上这也是为提升整体代码质量做贡献了。\n如果你理解了代码逻辑，但是对于某些部分你拿不准，请邀请另一位资历更深的reviewer来review，特别是对于那些安全、并发、可用、国际化等方面复杂的问题。\nContext # review过程中查看CL相关代码上文是有帮助的。代码review的时候，代码review工具只会显示几行修改的代码，但是前后与之相关的代码却可能大范围折叠。有时，你不得不查看整个文件内容来确保CL是有意义的。再比如，有时review工具只显示了4行代码，但是这四行代码位于一个几十上百行的方法中，如果你查看了CL的上下文，就会意识到这个函数的实现需要适当拆分成几个小的函数。\n将整个系统的代码作为Context来判定CL代码质量也是有必要的，如果这个CL中的代码质量低于系统整体代码的质量，请不要接受这样的代码，这回导致整体代码质量的下降。\nGood Things # 如果CL中有比较好的做法，请告诉开发者，特别是对于你的修改建议开发者很好地完成的时候。代码review通常是聚焦于可能的错误，但是这个过程也给了我们鼓励、学习good practices的机会。Mentoring机制，我们Tencent也有，去鼓励新人如何做的更好，比告诉他们哪里错了，更有价值。\nSummary # 简单总结下，Code review的时候也确保如下几点：\n 代码是否设计良好 功能对于代码的使用者而言更友好 UI的改变是有意义的 并发处理是安全的 不进行过度设计，没有演变到那种不必要的复杂 没有去实现一些将来可能需要但是现在不需要的东西 提供了有效的测试用例，包括单元测试等 测试是有用的，测试是经过精心设计的，不要写一堆没用的测试 命名选择都是合理的，如变量名、函数名等 注释是有价值的、有用的，注释解释了why而不是what，当然也有例外 文档中对代码变更也进行了合理的补充 代码遵循制定好的代码规范  确保逐行review分配的代码（代码生成工具生成的可以快速浏览），当然你可以合理分配review时间对部分代码进行重点review，但请确保你看懂了每行代码。注意code context，确保提升整体代码质量，对于review过程中发现的good practices适当鼓励开发者。\nNavigating a CL in Review # 现在我们知道了What to look for，如果review涉及到多个文件，如何最高效地进行review呢？\n review之前，查看CL的整体表述，确认是否有意义 首先，看CL中最有价值的部分，整体设计是否良好 然后，再根据合理顺序看CL中剩余的部分  Step One: Take a broad view of the change # 查看CL描述，先理解CL是做了什么工作，这个CL是否有意义。如果reviewer觉得这个修改没有意义，并决定拒绝该CL的时候，请选择合适的措辞向开发者解释清楚。\n例如，reviewer：“哇看上去你做了很多工作，非常感谢，但是我们未来方向是要移除你这里修改的FooWidget组件，如果你有时间，可以帮忙重构下BarWidget组件吗？”\n通能过这种方式，reviewer既向developer or contributor表明了立场、态度，也不失礼貌，保持礼貌是重要的，特别是对于开源项目，即便是你不认同贡献者的CL，也至少应看到他尝试进行付出。保持礼貌的review、讨论、沟通有助于维护开源协同的氛围。\n如果你收到了不少CLs，但是这些都不是你想要的，可能就需要从更高角度出发来解决这个问题，比如完善下Contributing文档，告知开发者项目需要什么，哪些方面鼓励优先解决等等。\nStep Two: Examine the main parts of the CL # 找到CL涉及的最主要修改部分，优先进行review。CL中逻辑的变动可能主要集中在少数几个文件中，找到这些changes优先进行review，这有助于聚焦修改的主要部分，加速整体的review进度。如果CL涉及代码太多，很难识别哪部分是主要部分，那可以先问下开发者哪部分是主要修改，或者让开发者把当前这次CL拆分成多个CLs，然后再发起review。\n如果在review CL主要部分的时候，发现设计上明显存在不合理的地方，reviewer应该立即发送review comments给开发者，其他的代码可以不用review了，继续review纯粹是浪费时间。因为既然存在明显的设计问题，等开发者修改之后，剩余的要review的代码可能根本不存在了。\n发现有明显设计问题，立即发送design review comments，还有两个好处：\n 开发者可能会发起一个CL之后，会立即在这个CL的基础上继续进行其他的修改工作。如果前面的CL存在明显的设计问题，那么很可能会将这里的问题继续带入到后续的CL中，并继续发起新的Code review。所以尽快发送设计上的review意见一定程度上会避免、减少这类问题的发生，避免后续review重复解决同一类问题。 主要的设计变更，比其他小修小补，花费的时间更多，每个开发者排需求都是有deadline的，及时发送review意见有助于在deadline之前，让开发者仍然由机会对设计做出调整，以保证项目进度，又能兼顾整体代码质量。  Step Three: Look through the rest of the CL in an appropriate sequence # 一旦确定CL中主体代码没有明显的设计问题，就可以按照合理的顺序review剩下的部分，比如按照逻辑处理的顺序来review，reviewer可以根据逻辑处理中的过程、分支判断来review相关的代码，从而确保不遗漏每一行变更。\n通常review完CL的主体部分之后，review剩下的部分就相对简单多了。有时阅读测试用例对于review代码也是有帮助的，比如，通过测试用例你能清楚地知道各个函数参数的含义，如何使用该函数，当然你可以联想到一些边界条件，带着这些问题去review CL主体代码效果也不错。\nSpeed of Code Reviews # Why Should Code Reviews Be Fast? # Google对于Speed的追求，更期望的是团队能够更快更好地生产一个好的产品的速度，而不是个人开发者编码的速度，当然这并不是说开发者的开发效率就不重要。团队整体推进的速度是非常重要的，它关系到产品迭代的进度，关系到团队的氛围，关系到每个开发者的感受，设置是他们的日常生活。\n在追求速度的过程中，Code review的速度扮演者一个比较重要的角色。如果review速度很慢，可能会发生：\n  团队整体推进的速度被严重拖慢。\n如果reviewer没有对CL进行快速的响应，可能就会耽误CL作者的其他后续工作，因为它可能要在此CL上开展其他工作。如果这里的修改是解决一个线上bug、重要的features等，如果搁置换一个几天、周、月，这种项目速度是不可接受的。\n  开发者开始抗议或者不重视Code review。\n如果一个reviewer每隔几天才回复一次CL review意见，但是每次review意见都要求CL作者进行修改，对于CL作者这种体验是非常沮丧的，开发者可能会抱怨这样的reviewer，为什么这么review个代码这么苛刻。但是如果reviewer能够快速、及时地回复review意见，这种抱怨往往会消失了。大家在意的不是CL有没有问题，而是reviewer的怠慢、反应迟缓。所以reviewer要尽快回复review意见。\n  代码整体健康度会受到影响。\n如果review速度过慢，就会给开发人员、reviewer人员持续带来更多的压力，这意味着开发人员会提交更多不符合标准的CLs，reviewer人员需要回复、拒绝、解释、二次review的工作做会更多。进一步，也会降低开发者代码清理、重构、优化的积极性，导致整体代码质量下降。\n  How Fast Should Code Reviews Be? # 如果当前没有对专注度要求很高的任务的话，reviewer应该立即或者稍后进行review。\n一个工作日，这个是Google内部指定的上限，在Code review发起的一个工作日内，reviewer必须进行review。\n如果一个CL进行review之后，提出了修改意见，并且CL作者进行了修改，那一天之内可能要进行多轮review，尽量不要拖到第二天，跨天就不太好了。\nSpeed vs. Interruption # 对于review速度和个人工作专注度之间需要做个权衡，如果正在进行某些对专注度要求比较高的任务，如正在写代码，这个时候还是不要让自己的工作中断。研究表明开发者被中断之后，再回到之前的工作，是需要比较长的时间的，为了追求review进度反而拖慢了个体开发进度，反过来也可能会拖慢项目整体进度。\n所以建议在当前没有对专注度要求很高的时间进行review，比如你写完一段关键代码之后，或者吃完午饭、午休之后，等等，这个就要根据自己情况选择了。\nFast Responses # 我们谈论Code review的速度，其实强调的是CL的review意见的回复速度，而不是CL最终通过的速度。当然，如果review意见回复速度够快，CL作者修改也会更快，CL整体通过速度也会快些。\n尽管CL整体通过耗时可能比较久，维持比较快的CL review意见还是很重要，CL作者不会因为review过慢而沮丧。\n如果你现在太忙了，实在没有时间对CL进行完整的review，你也可以发送一个回复信息让开发者知道你大约会在什么时间段进行review，好让他心理有底，他也可以继续安排自己接下来的工作。或者你也可以邀请其他合适的review代你进行review。这里并不是说你就要立即放下手里的编码工作立即去回复，你可以选个稍微可以放松难点的时间去回复，比如你刚刚写完一段关键代码，大脑可以稍微休息几分钟的时候。\nreviewers花费足够的时间进行review是很重要的，时间充足，reviewer回复“LGTM”才更有底气。CL中每个意见的回复还是要能快就快。\nCross-Time-Zone Reviews # 如果review涉及到多地的、不同时区的开发人员，reviewer最好能在CL作者还在公司工作的时候给到回复review意见，如果开发人员已经下班回家了，尽量在隔日开发人员上班前完成review，尽量不要中断、delay他人的工作。\nLGTM With Comments # 为了加速Code review整体通过进度，有些场景下，即便开发者没有完全完成reviewer的修改意见，reviewer可能也会给通过“LGTM” or “Approval”，这几种情况下是允许的：\n reviewer有信心，开发者会在之后不久完成提及的修改意见 剩余的还未修改之处，是些微小的修改，可以后面改，或者不一定要当前开发者来修改  reviewer针对上述两个情况，在LGTM的时候应该注明是哪种情况。LGTM With Comments对于多地、跨时区的开发者而言，是比较有价值的，因为reviewer最终给LGTM或者Approval可能要隔一天的时间呢，这个时候会比较久，如果是LGTM的同时附带上reviewer对开发者的一点小期望，开发者后续再修改、优化，也是可以的，毕竟这两种情况都是无伤大雅的事情。\nLarge CLs # 如果开发者提交的一个CL非常大，以至于你不知道要从哪开始看起，这个时候可以要求开发者将这个大的CL拆分成几个小的CL，CL2 build on CL1， CL3 build on CL2\u0026hellip; 然后再进行review。这对reviewer而言是比较有帮助的，对开发者而言可能需要额外的一点工作。\n如果换一个CL无法拆分成多个小的CLs，并且你眼下也没有时间去快速地完成整体的review，可以考虑看下整体设计，回复下对整体设计的意见，开发者可以先进行适当的优化。reviewer的目标，就是激励开发者持续地对代码质量进行提升。\nCode Review Improvements Over Time # 持续地遵循上述的Code review流程，坚持下去，就会发现自己在review代码的时候，处理地越来越好、越来越快。开发者也能够学习到符合代码质量要求的代码应该是什么样子的，后续提交的CLs也会变得越来越合理，花费的reviewer的时间也会越来越少。reviewer也会更快地进行review意见回复，对于整体review进度delay的时间也会越来越少。\n但是，但是，但是……不要为了“快”而降低Code review标准或者破坏整体代码的质量。\nEmergencies # 也存在一些非常紧急的情况，这些情况下CLs可能必须非常快地通过review过程，这种情况下review时的要求可以适当放低。在应用这里的Emergencies指引之前，先了解下What is An Emergency?，区分什么是紧急场景，什么不是，避免滥用。\nHow to Write Code Review Comments # Summary #  保持友好 解释原因 权衡“给出可能的方案并指出问题”、“给出可能的方案让开发者自主决策”两种方式 鼓励开发者简化代码，鼓励开发者添加注释，而不是解释问题有多复杂  Courtesy # review别人代码的时候，保持礼貌、尊重是非常重要的，至少不要让开发者、贡献者感觉到明显的不适，如何做到这点呢？一个比较好的办法就是在写review意见的时候，只对code本身进行评论，不要对开发者本人进行评论，对于某些人称代词是否有必要出现，也需要斟酌下。\n举个例子：\nBad：“%#@!$ 这个场景下多线程并不会有太大的性能提升，为什么你要用多线程？”\nGood：“多线程并发增加了复杂性，但%#@!$ 场景下收到的性能提升并不明显，最好用单线程模型代替多线程。”\nExplain Why # 上面展示的这个good example向开发者解释了review不通过的原因，同时也解释了为什么多线程模型在这个场景 %#@!$ 下并不好，开发者就会从中学习，意识到自己的方案存在的问题，并进行优化。\n当然不需要每次review的时候都进行大篇幅的解释，但是适当的解释是有必要的。\nGiving Guidance # 修复一个CL中存在的问题，是CL开发者的责任，而不是reviewer的责任。没有要求reviewer要代替开发者给出一个完整的详细设计，或者亲自帮助其写代码。\n但是这并不意味着reviewer可以无视，不去主动帮助他人，特别是在CL开发者确实get不到reviewer的点或者束手无策的时候，reviewer可以选择性的指出问题，并给出一个直接的指引，或者给出几个备选方案让开发者去对比、选择，或者给一个简单的设计让开发者去进一步细化、完善，或者可以写一个简单的demo以供开发者参考。这也是Mentoring精神的一种发扬吧，这可以帮助开发者学习，使得Code review变得更加简单、正向、积极。最终达成的结果也往往更好。\nCode review追求的第一目标就是尽可能高质量的CL，第二目标就是提升开发者的技能，这样后续的开发、Code review工作都会变得越来越简单、积极，技术传承也更加温和、有效。\nAccepting Explanations # 如果reviewer有段代码不太懂，并请开发者进行解释的话，最终的结果往往是开发者需要重写这段不清晰的代码。偶尔，代码中添加注释也是一种类似于“解释”的回应，但是如果代码实现太过复杂，该重写还是要重写，不能用注释解释，套逃脱应该简化、重构的工作。\n代码review工具中填写的解释（对reviewer疑问的解释）对将来阅读代码的人的帮助微乎其微，这个很好理解，阅读工程代码时，别人很少会去翻之前的review意见，而要等到翻review意见的时候，意味着这里的代码可能已经需要重写了。\n通过注释的方式来解释代码的行为，往往只在很少的几种场景下有效，比如在review一个自己不太熟悉的领域的代码时，如果有注释reviewer更容易理解，但是对于熟知这个领域的人而言，这些注释可能都是些常识，是多余的。\nHandling Pushback in Code Reviews # Handling Pushback in Code Reviews # 有时候，reviewer的意见开发者会“怼”回来，可能是开发者不同意reviewer的建议，也可能是抱怨reviewer过于苛刻。\nWho is Right? # 当开发者不同意reviewer的建议时，reviewer应该停下来先想想他们的想法是不是对的。通常，开发者可能比reviewer更加熟悉相关代码，可能在某些方面他们理解的比reviewer更清楚。那么，他们的争论是否有意义?从代码健康度的角度考虑，他们的修改是否有意义？如果确实有意义，让他们知道他们是对的，并且解决掉issue。\n然而，开发者也不都是对的。有些情况下，reviewer应该更透彻地解释为什么他们给出的建议时正确的。一个好的解释应该能展示出开发者角度的理解、reviewer角度的理解，以及reviewer的修改建议为什么是有价值的。\n某些情况下，reviewer可能要与开发者进行好几轮的沟通、解释，不管怎么样，保持礼貌的态度，应该让开发者感觉到“你一直在倾听他们在说什么，你只是不同意他们的做法”。\nUpsetting Developers # reviewers有时会觉得自己一直坚持CL代码的优化，开发者本人会不会觉得有点沮丧。有时，开发者可能会，或者刚开始时，开发者可能会，但是当他们觉得reviewer的建议有效确实帮助他提升了代码质量的时候，他就不会觉得沮丧了。\n通常，只要在review的时候保持礼貌的沟通，开发者可能根本不会感觉到沮丧，这里的担心可能只是reviewer自己头脑中的一种直觉而已。\nCleaning it Up Later # 开发者针对reviewer的建议，有时会用这样的方式，“这次先review通过吧，我后面再优化下”，确实有些开发者会这么做，他们这么做的原因，无非是不想再经过一轮新的耗时的review过程。\nreviewer可能会给通过，有些开发者确实会在本次CL通过后，继续写一个新的CL来解决上次reviewer提到的问题，大部分是这样的。但是也有不少开发者事后就忘了这些，并没有提交新的CL cleanup之前遗留的问题。并不是说这些开发者就是不负责任，很可能是因为他们被其他工作填满了，时间被挤占了之后人就会失忆或者“选择性”失忆，最终慢慢地就忘了cleanup。\n因此，一个好的做法是，CL通过之后，reviewer应该立即通过开发者、督促开发者cleanup遗留的问题。\nGeneral Complaints About Strictness # 如果之前Code review都比较松，后面Code review比较严的话，开发者刚开始肯定不适应，他们可能会抱怨多起来，这个时候，提升下Code review的速度有助于减少大家的抱怨。\n对于一个团队而言，如果是Code review从松到严，大家抱怨的时间可能持续的比较久，几个月都有可能，但是最终开发者会看到严格执行Code review的好处，抗议声最高的开发者可能会变成最有力的支持者，只要他能感受到严格之上的价值。\nResolving Conflicts # 如果在review代码时遵循了上述Code review的建议，但是仍然遇到了一些和开发者之间难以解决的问题，请参考 前面的章节 The Standard of Code Review来浏览下相关的指引和原则，应该有助于解决遇到的问题或冲突。\nThe Change Author\u0026rsquo;s Guide # 从代码CL开发者的角度出发，介绍下Google内部积累的一些good practices。\nWriting Good CL Descriptions # CL描述用来记录做了什么改变、为什么做这个改变，它会作为VCS中的提交历史记录下来，之后可能会有更多的开发者阅读到这里的CL描述。\n将来，开发者也可能根据一些关键词来搜索这里的CL描述，如果CL相关的关键信息只记录在代码中，在CL描述中不能予以体现的话，那么别人定位你的CL就会异常困难。\nFirst Line #  需要对修改进行一个精炼的总结 描述应该是一个完整的句子 描述后跟一个空行  CL描述的首行应该对做的修改进行一个精炼的总结、概括，然后后面跟一个空行。大部分情况下，开发者查看、检索CL描述信息（log信息）是看的这些内容，所以CL描述的首行信息是至关重要的。\n通常，首行信息应该是一个完整的句子，例如，一个好的首行表述：\u0026quot;Delete the FizzBuzz RPC and replace it with the new system.\u0026quot;, 下面这个则是一个不好的示例：\u0026quot;Deleting the FizzBuzz RPC and replacing it with the new system.\u0026quot;\nBody is Informative # CL描述的剩余部分应该详细一点，可以包含对要解决问题的描述，以及为什么CL中的实现是比较好的或者是最优的方案。如果该方法有什么不足，也应该提一下。如果有一些bug编号、性能结果、设计文档之类的背景信息，也应该包含进来，方便后来者查看。\n即使CLs涉及到的改动不多，有必要的话，也需要在body部分描述下。\nBad CL Descriptions # “Fix bug”不是一个足够充分的CL描述，修的什么bug？为了修bug做了哪些修改？其他类似的不良CL表述包括：\n Fix build Add patch Moving code from A to B Add convennience functions kill weired URLs  上面这些是Google代码仓库中捞出来的真实CL描述，作者可能认为他们的描述比较清晰了，但是实际上这样的CL描述没有任何意义，完全没有起到CL描述应有的作用。\nGood CL Descriptions # 下面是一些比较好的CL描述示例。\nFunctionality change #  rpc: remove size limit on RPC server message freelist.\nServers like FizzBuzz have very large messages and would benefit from reuse. Make the freelist larger, and add a goroutine that frees the freelist entries slowly over time, so that idle servers eventually release all freelist entries.\n 这个CL描述的首行信息概述了做的修改，后面body部分又解释了为什么做这个修改，以及自己是怎么做的，有什么好处，还提供了实现相关的一些信息。\nRefactoring #  Construct a Task with a TimeKeeper to use its TimeStr and Now methods.\nAdd a Now method to Task, so the borglet() getter method can be removed (which was only used by OOMCandidate to call borglet’s Now method). This replaces the methods on Borglet that delegate to a TimeKeeper.\nAllowing Tasks to supply Now is a step toward eliminating the dependency on Borglet. Eventually, collaborators that depend on getting Now from the Task should be changed to use a TimeKeeper directly, but this has been an accommodation to refactoring in small steps.\nContinuing the long-range goal of refactoring the Borglet Hierarchy.\n 这个CL描述的首行信息指出了CL做了什么，相对于以前的实现做了哪些修改。body部分介绍了实现细节、CL的context，也指出了虽然这个方案没有那么理想，但是也指出了未来的改进方向。同时也解释了为什么需要做这里的重构。\nSmall CL that needs some context #  Create a Python3 build rule for status.py.\nThis allows consumers who are already using this as in Python3 to depend on a rule that is next to the original status build rule instead of somewhere in their own tree. It encourages new consumers to use Python3 if they can, instead of Python2, and significantly simplifies some automated build file refactoring tools being worked on currently.\n 这个CL的首行信息描述了做了什么，body部分解释了为什么要做这里的修改，并且给reviewer提供了充分的context（领域相关知识）信息。\nReview the description before submitting the CL # CLs在review过程中可能会再次修改，再次review的时候，CL描述信息可能会与最新的修改不符，在提交CL之前review一下描述信息是否与代码修改仍然一致，这个是有必要的。\nSmall CLs # Why Write Small CLs? # Small, simple CLs有这样的好处：\n **Review更快。**如果提交一个大的CL，reviewer可能要专门抽30分钟才能完成review过程，这个可能比较困难，但是如果CL拆的都比较小，reviewer每次抽个5分钟完成一次review，多次review，回比前者更快完成。 **Review更充分。**如果提交一个大的CL，改动东西很多情况下，reviewer需要游走在更多代码中，心理上会倾向于关注更加重要的代码，难免某些代码会被降权，review可能不那么充分。如果CL比较小，很容易就能看懂，也不需要来回翻代码，review的会更充分。 **不易引入bug。**因为每次改动都比较小，CL作者不容易引入bug，reviewer也更容易发现bug。 **如果被拒绝，可减少无谓的工作。**CL可能会被拒绝，如果一次做大量修改，被拒绝的话，CL中的所有修改动作可能都要重新来过，不管是合理的、不合理的，相当于做了更多无谓的工作。 **更易merge。**如果提交一个大的CL，涉及修改比较多，冲突可能也会比较多，那么解决冲突花费的时间会更多，不容易merge。小的CL在merge的时候就简单多了。 **设计不至于出大问题。**如果CL涉及修改比较少，那么很容易把修改优化到最佳，对于reviewer的建议也更容易完成，如果CL比较大，reviewer意见、建议比较多，就很难一次完成了。 **后续工作不至于阻塞在review上。**CL作者可能希望基于这个CL做更多工作，如果CL比较小那么review可以很快通过，但是如果CL比较大，那么CL作者将不得不等待更多的时间 **merge后有问题，更易回退。**merge之后有时候也会意识到merge的代码有问题，如果要回退的话，小的CL更容易回退，如果CL很大，哇，涉及到的代码多，回退就比较痛苦、复杂。  reviewer不会因为某个CL很大，我不review了，然后给你拒绝掉，通常他们会表现的比较礼貌，告知你将这个大的CL拆分成几个小的CLs。当你已经完成了一个CL时，再将其拆分成几个小的CLs，其实这里的工作量可能不少的，当然和reviewer争辩为什么要求拆分成多个CLs花的时间可能也会很长。最省力的做法就是，一开始就坚持写小的CL，多次CLs。\nWhat is Small? # 一般，CL一般建议的大小：\n CL包含最少内容，一次只做一件事情，比如新增feature，CL只包含feature的一个部分，而不是所有的部分。也可以与reviewer进行沟通，确定合适的CL大小，不同的reviewer习惯也不一样，对reviewer而言，CL太大太小都是负担。我们的建议是CL一次只做一件事情。 reviewer需要看到的任何东西都已经包含在了CL中，这些信息可能位于CL代码中、描述中、已经存在的代码中、reviewer之前review过的CL中。 当把这个CL合入之后，系统仍然能够工作的很好。 CL也不小到隐晦难懂的程度。比如新增了一个API，应该同时包含API的使用示例，这样reviewer能够更好地理解API的使用方式，这样也可以避免引入没有用的API。  也没有硬性的规定指明CL多大才算大，一般100行代码是一个比较合理的CL尺寸，1000行有点太大了，主要还是要看reviewer的态度。CL中涉及到的文件的数量也是CL大小的一个度量维度，如果CL中包含了一个文件，文件修改了200行代码，这个感觉还是OK的，但是如果同样是修改了200行代码但是散落在50个文件中，那CL有点太大了。\n体会一下，我们写代码的时候是有了解对应的背景的，但是reviewer可能了解比较少或者完全不知道。一个可接受的CL大小，对reviewer而言是很重要的。如果你不确定reviewer期待的CL大小是怎样的，那就尽量写一个比自己预期中的合理大小更小点的，很少有reviewer会嫌弃CL太小。\nWhen are Large CLs OK? # 下面这些场景，如果CL比较大也还OK，不算坏：\n 删除整个文件的内容，或者删除大段内容，可以看做是一行修改，因为它不会花费reviewer太多时间review。 有时一个大的CL是有自动化refactor工具生成的，而我们信任这些工具，reviewer的工作就是检查并确认这里的修改没问题。这样的CL很大，但是对reviewer而言仍然不会花太多时间。  Splitting by Files # 另一种拆分大的CL的方式是，将修改的文件进行适当分组，并将不同分组的文件做成CL并提交不同的reviewer进行review。\n例如：你发送了一个CL修改，同时包含了对protocol buffer文件的修改，另一个CL是业务代码修改但是使用了这里修改后的protocol buffer文件。首先我们要先提交proto文件对应的CL，然后再提交引用它的业务代码CL。虽然提交的时候有先后，但是review过程可以是同时进行的。这么做的同时，最好也知会下reviewer另一个CL中的存在以及与当前CL的关系。\nSeparate Out Refactorings # 一般将CL中的重构之类的工作和其中包含的feature开发、bug修改区分开是比较好的做法。例如，将CL中包含的移动、重命名类名之类的操作单独放在一个CL中，这样reviewer能够更容易理解每个CL中的修改。\n不过，一个小的变量名修改的也可以包含在另一个feature change或者bugfix相关的CL中。如果一个CL中包含了一些重构之类的修改，让开发者、reviewer判断这部分重构相关的修改是否对当前CL来说太大了，太大了会让review变得更加困难，开发者应该据此作出一些调整。\nKeep related test code in the same CL # 避免将相关的测试代码单独放在另一个CL中。测试代码验证代码修改的正确性，所以和代码修改相关的测试代码，应该放置在一个相同的CL中，尽管测试代码增加了修改代码的行数。\n不相关的测试代码修改，可以放到另一个CL中，类似于 Separate Out Refactorings， 包含：\n 验证已经存在的、提交过的代码，当前只是新增、完善测试代码； 重构测试代码（如引入了新的helper函数） 引入了更大的测试框架（如集成测试）  Don\u0026rsquo;t Break the Build # 如果多个CLs互相依赖，需要找一个办法来确保这几个CL每提交一个，系统整体仍然能够正常工作，不能因为提交了一个CL就导致系统构建失败或者工作不正常。比如，可以考虑将几个依赖的小的CL修改合并。\nCan\u0026rsquo;t Make it Small Enough # 有时会遇到这种情况，看上去CL会无可避免地变得很大，其实，这种情况几乎是不存在的。只要开发者尝试练习去写小的CLs多次code review，习惯了之后开发者总能找到合适的办法来将一个大的修改分解成几个小的修改。\n在开发者动手进行一个很大的CL之前，开发者应考虑下是否先来一次只包含重构（只修改设计，不变动功能）的CL然后在此基础上再做修改，这样是不是会更好一点。如果一个CL中既包含重构代码，又包含逻辑变动代码，这个修改就很重。多数情况下，先来一次只包含重构的CL会为后续的修改扫清障碍，后续的修改会更clean。\n如果因为某些客观原因，无法做到上述这些，那就先提前向reviewer说明情况，让reviewer做好心理准备，准备好review一个大的CL，review可能花费比较长的时间，请务必小心引入bug、务必添加好测试用例并通过测试，reviewer在这么大的CL中review的效果可能会大打折扣。\nHow to Handle Reviewer Comments # 当开发者针对CL发起Code review时，reviewer一般会通过comments写一些意见、建议，那开发者该如何处理reviewer comments呢？\nDon\u0026rsquo;t Take it Personally # Code review的初衷是为了维护代码的质量、产品的质量，当一个reviewer对开发者代码写了些意见时，开发者应该将其看作是来自reviewer的帮助，不要将其看做是对开发者个人、个人能力的人身攻击。\n有时，reviewers会变得很沮丧，并且可能将沮丧、不满情绪在评论中体现出来。一个好的reviewer是不会这么做的，但是作为一个好的开发者，应该做好面对这种情况的准备。开发者可以反问下自己，当reviewer的评论到底是在描述一个什么代码问题，然后尝试去修改就可以了。\n**对于别人的review意见，永远不要用愤怒去回应！**这违反了Code review或者开源协同的精神，并且这样的负面信息可能会永远留存在review历史中。如果你心里面很愤怒，并且想愤怒地做出回应，请尝试离开你的电脑、键盘，或者先干点别的，直到你内心平静下来再礼貌地做出回应。\n一般，如果reviewer回复的评审意见不是建设性的，或者没有礼貌，可以试着向reviewer私下里诉说下你的看法。如果能面对面交流最好，不能就尝试发一封私人邮件，向reviewer说下你不喜欢他的这种review方式，你期望他能做出好的改变。如果对方还是拒绝做出改变，那就不要浪费时间了，升级一下知会你的项目经理。\nFix the Code # 如果reviewer说他看不懂你的代码中的某个部分，首先你应该尝试简化这里的代码实现。如果代码已经无法再精简实现，那就在代码中添加合适的注释来解释。如果添加额外的注释没有什么太大意义，只有这种情况下，可以尝试通过code review工具添加一些comments来解释。\n如果某个reviewer看不懂这里的代码，那么将来可能其他开发者阅读代码的时候，也是看不懂的。但是通过code review工具添加comments进行解释，对将来的开发者是没有帮助的，但是精简代码实现、代码添加注释是有帮助的。\n"}),a.add({id:440,href:"/tags/float/",title:"float",description:"",content:""}),a.add({id:441,href:"/blog/2019-05-23-%E5%88%AB%E7%94%A8float%E4%BD%9C%E4%B8%BAmap%E7%9A%84key/",title:"别用float作为map的key",description:"使用float作为map的key，非常容易留坑",content:"遇到个好玩的问题，使用float类型作为go map的key，示例代码如下： 其实就是浮点数精度的问题，随手翻了下go map的源码，备忘下。这里要涉及到几个问题：\n  golang如何针对key计算hash的，阅读源码后发现就是有个key *_type，h.key.alg.hash(key)来计算得到hash，问题就出在这里的hash计算过程，可以阅读下alg.go，里面针对不同的key类型定义了计算hash的方法：\nvar algarray = [alg_max]typeAlg{ alg_NOEQ: {nil, nil}, alg_MEM0: {memhash0, memequal0}, alg_MEM8: {memhash8, memequal8}, alg_MEM16: {memhash16, memequal16}, alg_MEM32: {memhash32, memequal32}, alg_MEM64: {memhash64, memequal64}, alg_MEM128: {memhash128, memequal128}, alg_STRING: {strhash, strequal}, alg_INTER: {interhash, interequal}, alg_NILINTER: {nilinterhash, nilinterequal}, alg_FLOAT32: {f32hash, f32equal}, alg_FLOAT64: {f64hash, f64equal}, alg_CPLX64: {c64hash, c64equal}, alg_CPLX128: {c128hash, c128equal}, }  float64就是要使用f64hash这个方法来计算hash值。\n  golang里面利用计算得到的hash值的后5位作为hmap的bucket index，先定位到bucket，然后再根据hash的前8位作为与bucket内部\u0026lt;k,v\u0026gt; entries的hash进行比较找到对应的entry。\n  下面我们看下f64hash的实现：\nfunc f64hash(p unsafe.Pointer, h uintptr) uintptr { f := *(*float64)(p) switch { case f == 0: return c1 * (c0 ^ h) // +0, -0 case f != f: return c1 * (c0 ^ h ^ uintptr(fastrand())) // any kind of NaN default: return memhash(p, h, 8) } }  f==0或者f!=f是两种极端情况，不考虑直接看f64hash里面调用方法memhash(p, h, 8)，memhash实现，省略无关代码：\nfunc memhash(p unsafe.Pointer, seed, s uintptr) uintptr { if (GOARCH == \u0026quot;amd64\u0026quot; || GOARCH == \u0026quot;arm64\u0026quot;) \u0026amp;\u0026amp; GOOS != \u0026quot;nacl\u0026quot; \u0026amp;\u0026amp; useAeshash { return aeshash(p, seed, s) } h := uint64(seed + s*hashkey[0]) tail: switch { case s == 0: case s \u0026lt; 4: ... case s \u0026lt;= 8: h ^= uint64(readUnaligned32(p)) h ^= uint64(readUnaligned32(add(p, s-4))) \u0026lt;\u0026lt; 32 h = rotl_31(h*m1) * m2 case s \u0026lt;= 16: ... case s \u0026lt;= 32: ... default: ... } h ^= h \u0026gt;\u0026gt; 29 h *= m3 h ^= h \u0026gt;\u0026gt; 32 return uintptr(h) }  现在可以看到它其实是把浮点数的内存表示（IEEE 754 double encoding format) 当做一个普通的数字来计算的，先读4字节计算，再读剩下的4字节计算，再做其他计算。\n两个浮点数最终hash值相同，其实就是浮点数精度导致的，写代码的时候，看上去我们定义了两个完全不同的浮点数，但是内存中按照IEEE 754 double的规范进行内存表示的时候，很可能就是一样的。\n上面是IEEE 754 double的格式，1位符号位，11位阶码，52位尾数，像NaN、Inf的定义也都跟这些不同的组成部分有关。这里只关心尾数部分就好了，只有52位，当超过52 bits可以表示的精度之后，代码里面定义的数值就被截断了。\n示例代码中，看似数值上有一两位末尾数字不同的浮点数，内存表示是相同的，hash值也相同，就会出现map赋值时值被覆盖的问题。\n浮点数的更多细节如符号位、阶码（bias）、尾数，以及NaN、Inf的定义等，可以参考wikipedia了解更多细节。\n"}),a.add({id:442,href:"/tags/%E6%B3%A2%E9%9F%B3737/",title:"波音737",description:"",content:""}),a.add({id:443,href:"/blog/2019-03-17-%E6%B3%A2%E9%9F%B3737%E5%9D%A0%E6%AF%81%E4%BA%8B%E6%95%85%E7%9A%84%E8%83%8C%E5%90%8E/",title:"波音737坠毁事故的背后",description:"波音，从诞生到现在，一直都是全球空客市场的强有力竞争者，然而，就是这么一家顶尖的企业，却接连制造了惨不忍睹的杀人事故。波音737 Max，在人们心目中已然成为了一款“杀人”机器，几百个家庭就此陷入无尽的悲伤，即便能获取高额赔偿，又有什么用呢？忍不住内心的怒火，忍不住要追问，究竟是谁导致了这一系列事故的发生！\n波音737 Max机型事故回顾\n2019年3月10日，一架载有149名乘客和8位机组人员的波音737 Max，从埃色俄比亚的亚的斯亚贝巴机场起飞后大约6分钟坠毁。飞机起飞后，垂直速度一直不稳定，机长也非常警觉地发现了问题请求返航，但是他没想到的是，他驾驶的是一架杀人机器，而不是受飞行员控制的飞机，在其几次与飞控系统组件MCAS（强制压低机头软件系统）抢夺控制权后还是失败了，157条生命就此销声匿迹。\n波音737 Max机型事故原因\n然而，在全世界人民关注的目光中，在全世界人民表达哀悼、同情的同时，波音公司却丑陋地站在了利益的一边，而完全将责任、道义抛之不顾。波音发表声明称，对737 Max的技术足够自信，并表示如果埃航空公司有需要，会协助其恢复机队人员的新人。完全没有自我审视的意识，这是极其不应该的！因为这款机型737 Max在此之前，已经出现了两次坠机事故，且坠机过程中表现的异常极为相似！这完全是基于波音自身利益考量，宁可为了多卖出几架飞机，也不愿意为本次事故承担责任、赔偿、安抚遇难者家属！\n2018年10月29日，印度尼西亚狮航737 Max 8起飞13分钟后坠入爪哇海，而同年12月14日，挪威航空公司737 Max 8起飞后也被迫做出紧急迫降。可笑的是，狮航事故发生之后波音才马后炮似的向狮航提供了一份操作手册，用来解决错误的驾驶舱读数问题，从这个时候开始，MCAS（强制压低机头软件系统）才被揭露于飞行员面前，而波音对这个软件的隐瞒更加凸显了在利益面前波音的胡作非为。\nMCAS（强制压低机头软件系统）是在设计737 Max机型时引入的，由于为了更好地与欧洲空中客车航空公司进行竞争，波音在原来的737机型上进行了改进，一是为了载客量，一是为了省油，飞机后端进行了窄体设计，并增高了起落架高度，以方便在飞机前端挂装性能更好的发动机。但这一设计存在一个致命缺陷，飞机起飞时容易仰角过大导致飞机坠毁。为此波音引入了软件系统MCAS，在飞机速度比较低时（如起飞过程中）强制压低机头。\n波音处于自身利益的考虑，并没有在一开始就外界告知有这样的一个软件系统存在，而且更加糟糕的是，该软件系统对飞机的操控权限，比飞行员还要高，即便飞行员很有经验，意识到出现了危险，如飞机压低机头坠向地面，飞行员也没办法将机头拉高回归至正常飞行状态，飞机也就会表现出垂直高度不稳定，直至坠毁。\n波音在整个过程中极端不负责任，已经发生了多起事故，自己不去召回并修正设计上的缺陷，反而继续签订了更多的订单，全球订单量5500+，已出货350+。被全世界各国相继停飞、拒单，简直是活该！谁愿意花重金买一个机器回来“残害”自己的人民呢？\n美国政府在当中扮演的角色\n在埃航坠机事故发生后，先前发生过类似事故的狮航高度敏感，整件事情也愈演愈烈，被完整地曝光于世界面前。各国相继停飞737 Max机型，并出现了大量拒单的情况。美国政府最终也不得不宣布停飞，还有跟屁虫加拿大！波音公司对事故的处理过程，让我们寒心，美国政府在世界人民面前表现出来的冷漠也让我们坚信，美国并没有那么美，在人民面前，还是本国政府最关心自己的人民。\n最后希望我国商飞能挺起民族的脊梁，自古以来“领袖”从来都是有能者居之，希望商飞能在不远的将来，在航空市场上傲视群雄。",content:"波音，从诞生到现在，一直都是全球空客市场的强有力竞争者，然而，就是这么一家顶尖的企业，却接连制造了惨不忍睹的杀人事故。波音737 Max，在人们心目中已然成为了一款“杀人”机器，几百个家庭就此陷入无尽的悲伤，即便能获取高额赔偿，又有什么用呢？忍不住内心的怒火，忍不住要追问，究竟是谁导致了这一系列事故的发生！\n波音737 Max机型事故回顾\n2019年3月10日，一架载有149名乘客和8位机组人员的波音737 Max，从埃色俄比亚的亚的斯亚贝巴机场起飞后大约6分钟坠毁。飞机起飞后，垂直速度一直不稳定，机长也非常警觉地发现了问题请求返航，但是他没想到的是，他驾驶的是一架杀人机器，而不是受飞行员控制的飞机，在其几次与飞控系统组件MCAS（强制压低机头软件系统）抢夺控制权后还是失败了，157条生命就此销声匿迹。\n波音737 Max机型事故原因\n然而，在全世界人民关注的目光中，在全世界人民表达哀悼、同情的同时，波音公司却丑陋地站在了利益的一边，而完全将责任、道义抛之不顾。波音发表声明称，对737 Max的技术足够自信，并表示如果埃航空公司有需要，会协助其恢复机队人员的新人。完全没有自我审视的意识，这是极其不应该的！因为这款机型737 Max在此之前，已经出现了两次坠机事故，且坠机过程中表现的异常极为相似！这完全是基于波音自身利益考量，宁可为了多卖出几架飞机，也不愿意为本次事故承担责任、赔偿、安抚遇难者家属！\n2018年10月29日，印度尼西亚狮航737 Max 8起飞13分钟后坠入爪哇海，而同年12月14日，挪威航空公司737 Max 8起飞后也被迫做出紧急迫降。可笑的是，狮航事故发生之后波音才马后炮似的向狮航提供了一份操作手册，用来解决错误的驾驶舱读数问题，从这个时候开始，MCAS（强制压低机头软件系统）才被揭露于飞行员面前，而波音对这个软件的隐瞒更加凸显了在利益面前波音的胡作非为。\nMCAS（强制压低机头软件系统）是在设计737 Max机型时引入的，由于为了更好地与欧洲空中客车航空公司进行竞争，波音在原来的737机型上进行了改进，一是为了载客量，一是为了省油，飞机后端进行了窄体设计，并增高了起落架高度，以方便在飞机前端挂装性能更好的发动机。但这一设计存在一个致命缺陷，飞机起飞时容易仰角过大导致飞机坠毁。为此波音引入了软件系统MCAS，在飞机速度比较低时（如起飞过程中）强制压低机头。\n波音处于自身利益的考虑，并没有在一开始就外界告知有这样的一个软件系统存在，而且更加糟糕的是，该软件系统对飞机的操控权限，比飞行员还要高，即便飞行员很有经验，意识到出现了危险，如飞机压低机头坠向地面，飞行员也没办法将机头拉高回归至正常飞行状态，飞机也就会表现出垂直高度不稳定，直至坠毁。\n波音在整个过程中极端不负责任，已经发生了多起事故，自己不去召回并修正设计上的缺陷，反而继续签订了更多的订单，全球订单量5500+，已出货350+。被全世界各国相继停飞、拒单，简直是活该！谁愿意花重金买一个机器回来“残害”自己的人民呢？\n美国政府在当中扮演的角色\n在埃航坠机事故发生后，先前发生过类似事故的狮航高度敏感，整件事情也愈演愈烈，被完整地曝光于世界面前。各国相继停飞737 Max机型，并出现了大量拒单的情况。美国政府最终也不得不宣布停飞，还有跟屁虫加拿大！波音公司对事故的处理过程，让我们寒心，美国政府在世界人民面前表现出来的冷漠也让我们坚信，美国并没有那么美，在人民面前，还是本国政府最关心自己的人民。\n最后希望我国商飞能挺起民族的脊梁，自古以来“领袖”从来都是有能者居之，希望商飞能在不远的将来，在航空市场上傲视群雄。\n"}),a.add({id:444,href:"/tags/%E7%A7%91%E6%8A%80/",title:"科技",description:"",content:""}),a.add({id:445,href:"/tags/calendar/",title:"calendar",description:"",content:""}),a.add({id:446,href:"/tags/macos/",title:"macOS",description:"",content:""}),a.add({id:447,href:"/blog/2019-02-23-macos%E5%AE%9E%E7%8E%B0%E9%AB%98%E6%95%88todolist/",title:"macOS实现高效todolist",description:"macOS的日历其实做的挺方便的，可以纵览所有的日程安排，还可以生成提醒，如果能很方便的通过alfred添加待办事项到日历中，岂不是妙哉？那么如何写一个alfred workflow来实现此功能呢？",content:" img { width: 680px; padding-bottom: 1rem; }  高效 “Todo” # Apple设备上有一个非常好的效率工具“Calendar.app（日历）”，在日历中可以添加待办事项，并且支持按天、周、月、年视图进行快速浏览，是工作、学习的好帮手。工作中，自己的想法、他人的反馈、问题要点等需要快速记录下来，每次唤醒日历进行手动添加还是有点低效，能不能实现更高效地“Todo”呢？ 想象一下手动打开日历，定位到今天，滑动到下方找一个合适的时间点添加待办事项，输入描述信息再回到原来的工作，麻烦！结合Alfred+AppleScript编写了一个Workflow，现在方便多了，实现了如下效果。快捷键快速呼出Alfred交互输入框，然后键入“todo 待办事项描述信息，然后键入“回车”，此时就可以自动添加一条新的待办事项到日历中，是不是方便多了！ 执行上述操作之后：\n 若日历程序没启动，添加成功会启动日历并提到前台，展示当前添加的待办事项； 若日历程序已启动，添加成功不会再将日历提到前台，在通知中心发一条添加成功的通知；   我想要的高效“Todo”是近似这样的，目前能基本满足我的要求。这里的实现方式是，打开Alfred-\u0026gt;Preferences-\u0026gt;Workflows，新建一个Blank Flow，然后配置如下： workflow中todo节点获取输入的待办事项，并将输入信息通过脚本参数的形式传递给后续的osacript进行处理，该脚本负责添加待办事项到日历。workflow中两个节点的配置如下所示： 完整的脚本代码如下：\non run set theQuery to \u0026quot;{query}\u0026quot; -------------------------------------------------------------------------- -- 今天的开始、结束，用于筛选今天的事件列表 set todayStart to (current date) set time of todayStart to 0 copy todayStart to todayEnd set time of todayEnd to 86400 -- 待添加事件的开始、结束时间，我喜欢按照时间顺序追加的添加方式 copy todayStart to todoStart set minutes of todoStart to 0 set seconds of todoStart to 0 -- 启动Calendar筛选今天内添加的todo事件列表 tell application \u0026quot;Calendar\u0026quot; tell calendar \u0026quot;todo\u0026quot; -- 遍历todo事件列表找到最后添加的事件 set allEvents to (every event where its start date is greater than or equal to todayStart and end date is less than todayEnd) repeat with e in allEvents set t to start date of e if t ≥ todoStart then copy t to todoStart end if end repeat -- 继续追加新todo事件 if hours of todoStart is equal to 0 then set hours of todoStart to 8 else set todoStart to todoStart + (1 * hours) end if set todoEnd to todoStart + (1 * hours) make new event with properties {summary:theQuery, start date:todoStart, end date:todoEnd} end tell -- 启动Calendar显示 if not running then run delay 0.25 activate else set msg to \u0026quot;添加成功：\u0026quot; \u0026amp; theQuery display notification msg end if end tell ---------------------------------------------------------------------- return theQuery end run  AppleScript不太熟，东拼西凑攒出来这个小工具，还攒了一些其他小工具\u0026hellip; 希望对大家有帮助！\n"}),a.add({id:448,href:"/tags/todo/",title:"todo",description:"",content:""}),a.add({id:449,href:"/tags/todolist/",title:"todolist",description:"",content:""}),a.add({id:450,href:"/tags/mermaid/",title:"mermaid",description:"",content:""}),a.add({id:451,href:"/tags/plantuml/",title:"plantuml",description:"",content:""}),a.add({id:452,href:"/blog/2019-01-03-%E8%AE%BE%E8%AE%A1%E5%B7%A5%E5%85%B7mermaid/",title:"设计工具Mermaid",description:"Mermaid 是一个用于生成图表和流程图的工具。它支持多种图表类型和流程图布局，并提供在线编辑器和本地生成器。Mermaid 的简便易用性使它成为文档和博客文章中数据可视化的理想选择。它的专业图表可以提高文档的清晰度和可读性。",content:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是Mermaid语法和使用，用以在markdown文档中绘制各类图表。\nMermaid # 1 Flow Chart # graph LR A[Hard edge] --\u0026gt;B(Round edge) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result one] C --\u0026gt;|Two| E[Result two]  2 Sequence Diagram # sequenceDiagram participant Alice participant Bob Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts\u0026lt;br/\u0026gt;prevail... John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good!  3 Gantt Diagram # gantt dateFormat YYYY-MM-DD title Adding GANTT diagram functionality to mermaid section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d section Critical tasks Completed task in the critical line :crit, done, 2014-01-06,24h Implement parser and jison :crit, done, after des1, 2d Create tests for parser :crit, active, 3d Future task in critical line :crit, 5d Create tests for renderer :2d Add to mermaid :1d section Documentation Describe gantt syntax :active, a1, after des1, 3d Add gantt diagram to demo page :after a1 , 20h Add another diagram to demo page :doc1, after a1 , 48h section Last section Describe gantt syntax :after doc1, 3d Add gantt diagram to demo page : 20h Add another diagram to demo page : 48h  4 Class Diagram # classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 \u0026lt;--\u0026gt; C2: Cool label  "}),a.add({id:453,href:"/categories/%E8%BF%87%E5%8E%BB%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/",title:"过去的学习笔记",description:"",content:""}),a.add({id:454,href:"/tags/eof/",title:"eof",description:"",content:""}),a.add({id:455,href:"/tags/fin/",title:"fin",description:"",content:""}),a.add({id:456,href:"/tags/half-closed/",title:"half closed",description:"",content:""}),a.add({id:457,href:"/tags/tcp/",title:"tcp",description:"",content:""}),a.add({id:458,href:"/blog/2018-12-20-write-closed-tcpconn/",title:"write closed tcpconn",description:"TCP连接管理向来是高性能服务器开发所需要掌握的内容，服务器通常会检测客户端连接是否空闲，为了节省资源会在连接空闲一段时间后主动清理空闲的连接。在TCPServer主动close连接时，会发生什么呢？与其是TCPClient使用了连接池时会发生什么呢？在维护RPC框架过程中遇到不少类似的反馈，优化框架之余，于是有此文来解释下。",content:"问题背景 # tcp client: write to a half-closed tcp connection!\n这里探讨一下这个问题，Write to a closed tcp connection的问题。在深入讨论这些问题之前，首先要了解tcp state diagram，为此文末特地附上了经典的tcp状态转换图。\n我们的场景是这样的，tcp server已经启动，然后tcp client主动建立连接请求，连接成功建立后，tcp client并不立即发送数据而是等待一段时间之后才会发送数据（这种在client端的tcp连接池中非常常见），tcp server端为了防止连接被滥用，会每隔30s钟检查一下tcp连接是否空闲，如果两次检查都发现tcp连接空闲则主动将连接关闭。\n原因分析 # 此时tcp server端会调用conn.Close()方法，该方法最终会导致传输层发送tcp FIN包给对端，tcp client这边的机器收到FIN包后会回一个ACK，然后呢？tcp client不会继续发FIN包给tcp server吗？不会！仅此而已。问题就是这么诞生的，什么问题呢，tcp client仍然可以发包，但是n, err := tcpconn.Write(...)这个时候并不会检测到err != nil，只有等到n, err := tcpconn.Read(...)的时候才会发现err为io.EOF，这个时候才能判断得知tcp server已经把连接销毁了。\n从RPC框架角度而言，希望为client维护的tcp连接池是高效可用的，所以想对上述情况下的客户端连接进行检测，避免连接池中存在上述被tcp server关闭的连接。\n再简单总结下tcp server、tcp client两端的不同处理逻辑：\n  从tcp server的视角来看，\ntcp server调用的conn.Close()，对应的是系统调用close，tcp server端认为它已经彻底关闭这个连接了！\n  从tcp client的视角来看，\n这个连接是我主动建立的，我还没有给你发送FIN包发起关闭序列呢，因此这个连接仍然是可以使用的。tcp client认为tcp server只是关闭了写端，没有关闭读端，因此tcp client仍然是可写的，并且socket被设置成了nonblocking，conn.Write()仍然是成功返回的，返回的err == nil。但是当真正传输层执行数据发送的时候，tcp server端认为这个连接已销毁，因此会返回RST！这个时候上层go代码因为已经返回已经感知不到写的时候存在错误，这个RST会将tcp client端的socket标记为已关闭。下次tcpconn.Read的时候就能感知到io.EOF错误了，如果再发起一次tcpconn.Write也可以立即返回错误。\n  关于close与shutdown # 假如tcp server调用的不是conn.Close()，而是conn.CloseWrite()，这个对应的系统调用shutdown(SHUT_WR)，那只表示写端关闭，这个时候tcp client发送数据过去，tcp server端返回的就不是RST了，而是正常的ACK，因为tcp server端也认为这个连接只是关闭了写端。\n本质上来说，内核在处理系统调用close、shutdown的时候对套接字的处理是有差异的，close的时候对fd引用计数减1，如果引用计数为0了，那么就直接销毁套接字，认为对应的连接不再有效了（所以收到tcp client发来的数据会回RST）。但是shutdown(SHUT_WR)的时候，不会减引用计数，内核并不会直接销毁套接字，虽然也会发FIN包，但也只是认为这个连接是写端关闭、读端正常，所以还可以正常接收数据！\nRPC框架关心这个问题 # 问题出现：\n对于上层应用程序来说，conn.Write()返回nil就认为是返回成功了，但是实际包并没有发送出去，所以后续等待接收响应的时候conn.Read()就会返回io.EOF错误显示对端连接已关闭。\n假如满足下面几个条件，那么tcp client请求tcp server失败的概率就会很大了！\n tcp client请求tcp server是通过连接池来实现的； tcp client请求tcp server并不频繁的情况下； tcp server又存在主动销毁空闲连接的时候；  如何避免这里的问题呢？在go里面tcp client中的连接池实现，可以定期地检查tcp连接是否有效，实现方法就是conn.Read()一下，如果返回的是io.EOF错误则表示连接已关闭，执行conn.Close()并重新获取连接即可。conn.Write()是不会返回这个io.EOF错误的，会想上面的场景来看，tcp client端现在还认为tcp连接是有效的呢，所以conn.Write()是肯定不会返回io.EOF错误的。\ngo网络库为什么这么设计 # 这里再延伸一下，为什么go里面conn.Write()的时候不去检查一下连接是否已关闭呢？比如显示地conn.Read()一下？这要考虑tcp的设计宗旨了，tcp本身就是支持全双工模式的，tcp连接的任意一端都有权利关闭读端或者写端，所以从go api设计者的角度来看，conn.Write()就只是单纯地认为我这段tcpconn的写端未关闭即可！对端是否写关闭根本无需考虑，而从更通用的角度来考虑，有些服务端逻辑上可以只收请求不回响应。为了通用性，conn.Write()不可能去检查对端是否写关闭！\n那从一个网络框架设计或者一个应用程序开发者角度来说呢？我们关心一个请求是否能拿到对应的响应！如果我们要避免这个问题，以c、c++为例，我们完全可以借助epoll_wait来轮询是否有EPOLLRDHUP事件就绪，有就认为连接关闭销毁就可以了，或者轮询EPOLLIN事件就绪接着read(fd, buf, 0)返回0==EOF就可以了。但是每次write之前都这样检查一下，还是很蛋疼的，要陷入多次系统调用，而且即便在epoll_wait返回之后、write之前这段时间内，仍然对端可能会发一个FIN包过来！所以说这样也并不能一劳永逸地解决问题！\n如何更好地解决问题 # 再回到问题的起点，其实我们不想关心这些网络细节，我们只想关心，我发送出去的请求是否得到了可靠的响应！\n失败重试！失败后重试一次、两次已经成为了大家写代码时候的常态，但是一个网络框架，是否应该减少这种负担？可能上面我们讨论的情形在线上环境中并不多见，但它确实是一个已知的问题！如果请求量比较大，连接不会因为空闲被关掉，那么这个问题出现的概率很少，但是假如请求量确实不大，这个问题就会凸显出来了。\n连接池连接活性检测优化 # 为此我们想了一种改良的方法来检测是否出现了对端关闭连接的情况，思路是这样的，因为不方便再去poll类似的EPOLLIN、EPOLLRDHUP事件，这里再从连接池获取空闲连接时，借助系统调用n, err := syscall.Read(fd, buf)直接去非阻塞读一下，如果返回err == nil 并且 n==0，那么就可以判定对端连接写关闭（refer to poll/fd_unix.go:145~180, fd.eofError(n, err)）。\nfunc (nci *NConnItem) readClosed(conn net.Conn) bool { var ( readClosed bool rawConn syscall.RawConn err error ) f := func(fd uintptr) bool { one := []byte{0} n, e := syscall.Read(int(fd), one) if e != nil \u0026amp;\u0026amp; e != syscall.EAGAIN { // connection broken, close it readClosed = true } if e == nil \u0026amp;\u0026amp; n == 0 { // peer half-close connection, refer to poll/fd_unix.go:145~180, fd.eofError(n, err) readClosed = true } // only detect whether peer half-close connection, don't block to wait read-ready. return true } switch conn.(type) { case *net.TCPConn: tcpconn, _ := conn.(*net.TCPConn) rawConn, err = tcpconn.SyscallConn() case *net.UnixConn: unixconn, _ := conn.(*net.UnixConn) rawConn, err = unixconn.SyscallConn() default: return false } err = rawConn.Read(f) if err != nil { return true } if readClosed { return true } return false }  如果我们利用tcp全双工能力，实现client、server的全双工通信模式，一边发送多个请求、一边接收多个响应，假如接收响应的时候发现io.EOF，那么后续的发送直接返回失败就行了。但是假如网络抖动的情况下，这种全双工通信模式容易出现失败激增的毛刺。\n这种情境下，貌似UDP会是更好的选择，当然也要考虑服务端是否支持UDP。\n在RPC级别支持重试对冲 # 还有一种更优雅的做法，在RPC框架设计上支持interceptor扩展，包括前置interceptor、后置interceptor，比如grpc框架的interceptor是以递归的形式形成了一个链条，前面interceptor的完成驱动后一个执行，最后的interceptor驱动真正的RPC方法执行。\n我们可以在interceptor层面上支持重试对冲，比如本文提及的失败重试，我们可以不用过度优化tcp连接池连接活性检测，而是将关注重点放在如何更好地解决失败后的重试上：\n 立即重试 重试次数 指数退避 etc  RPC方法中，在tcpconn.Write发送请求成功后，继续通过tcpconn.Read读取响应，此时读取到io.EOF则返回错误，此时驱动该RPC方法执行的重试interceptor会根据配置的重试策略进行重试，从而更优雅地解决这里write closed tcpconn的问题。\n附录 # 1 测试tcp server close空闲连接\nmac下测试方法：\n 服务端：nc -kl 5555 -w 2 客户端：go run client.go，client.go代码如附录3。  linux下测试方法：\n 服务端：nc -kl 5555 -i 2（与mac下参数不同，效果相同，都是2s后close连接） 客户端：go run client.go，client.go代码如附录3。  2 测试tcp server shutdown(SHUT_WR)空闲连接\n服务端：go run server.go\n3 测试代码server.go+client.go\nfile server.go\npackage main import ( \u0026quot;fmt\u0026quot; \u0026quot;net\u0026quot; \u0026quot;os\u0026quot; \u0026quot;time\u0026quot; ) func init() { log.SetFlags(log.LstdFlags | log.Lshortfile) } func main() { listener, err := net.Listen(\u0026quot;tcp4\u0026quot;, \u0026quot;:5555\u0026quot;) if err != nil { fmt.Println(err) os.Exit(1) } for { conn, err := listener.Accept() if err != nil { fmt.Println(err) continue } go func() { go func() { time.Sleep(time.Second * time.Duration(2)) tcpconn, ok := conn.(*net.TCPConn) if !ok { fmt.Println(err) return } tcpconn.CloseWrite() }() time.Sleep(time.Second * time.Duration(4)) buf := make([]byte, 1024) n, err := conn.Read(buf) if err != nil { fmt.Println(err) return } fmt.Println(\u0026quot;read bytes size:%v, data:%s\u0026quot;, n, string(buf)) }() } }  file: client.go\npackage main import ( \u0026quot;os\u0026quot; \u0026quot;net\u0026quot; \u0026quot;time\u0026quot; ) func main() { strEcho := \u0026quot;Halo\u0026quot; servAddr := \u0026quot;localhost:5555\u0026quot; tcpAddr, err := net.ResolveTCPAddr(\u0026quot;tcp\u0026quot;, servAddr) if err != nil { println(\u0026quot;ResolveTCPAddr failed:\u0026quot;, err.Error()) os.Exit(1) } println(\u0026quot;connection established\u0026quot;) conn, err := net.DialTCP(\u0026quot;tcp\u0026quot;, nil, tcpAddr) if err != nil { println(\u0026quot;Dial failed:\u0026quot;, err.Error()) os.Exit(1) } // sleep until connection closed time.Sleep(3000 * time.Millisecond) // first write to half-closed connection time.Sleep(3000 * time.Millisecond) _, err = conn.Write([]byte(strEcho)) if err != nil { println(\u0026quot;Write to server failed:\u0026quot;, err.Error()) os.Exit(1) } println(\u0026quot;writen to server = \u0026quot;, strEcho) // second write to half-closed connection time.Sleep(3000 * time.Millisecond) strEcho = \u0026quot;Halo2\u0026quot; _, err = conn.Write([]byte(strEcho)) if err != nil { println(\u0026quot;Write to server failed:\u0026quot;, err.Error()) os.Exit(1) } println(\u0026quot;writen to server = \u0026quot;, strEcho) conn.Close() }  4 c++版的tcp client\n一个类似上述go版tcp client的c++版实现，看看要多少代码吧。\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;netdb.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;netinet/in.h\u0026gt; #include \u0026lt;sys/un.h\u0026gt; #include \u0026lt;sys/socket.h\u0026gt; #include \u0026lt;sys/unistd.h\u0026gt; #include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;signal.h\u0026gt; #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; #define MAX_EVENTS 1024 static int processClient(); int main(int argc, char *argv[]) { int fd; int ret; struct sockaddr_in addr = { 0 }; struct in_addr x; inet_aton(\u0026quot;127.0.0.1\u0026quot;, \u0026amp;x); addr.sin_family = AF_INET; addr.sin_addr = x; addr.sin_port = htons(5555); int set = 30; int i = 0; int fdFlag = 0; int epollFd = epoll_create(MAX_EVENTS); if (epollFd == -1) { printf(\u0026quot;epoll_create failed\\n\u0026quot;); return -1; } struct epoll_event ev; // epollÊ¼þ½ṹÌ struct epoll_event events[MAX_EVENTS]; // Ê¼þ¼à¶ÓÐ // connect to server fd = socket(AF_INET, SOCK_STREAM, 0); if (fd == -1) { printf(\u0026quot;error:%s\\n\u0026quot;, strerror(errno)); return -1; } // set timer is valid ? //setsockopt(fd, SOL_SOCKET, SO_KEEPALIVE, \u0026amp;set, sizeof(set)); // set socket non block? if ((fdFlag = fcntl(fd, F_GETFL, 0)) \u0026lt; 0) printf(\u0026quot;F_GETFL error\u0026quot;); fdFlag |= O_NONBLOCK; if (fcntl(fd, F_SETFL, fdFlag) \u0026lt; 0) printf(\u0026quot;F_SETFL error\u0026quot;); // connect to server ret = connect(fd, (struct sockaddr *)\u0026amp;addr, sizeof(addr)); if (ret == -1) { if (errno == EINPROGRESS) { printf(\u0026quot; connect error:%s\\n\u0026quot;, strerror(errno)); //return -1; } else { printf(\u0026quot; connect error:%s\\n\u0026quot;, strerror(errno)); return -1; } } // epoll watch socket EPOLLOUT ev.events = EPOLLOUT; ev.data.fd = fd; if (epoll_ctl(epollFd, EPOLL_CTL_ADD, fd, \u0026amp;ev) == -1) { printf(\u0026quot;epoll_ctl:server_sockfd register failed\u0026quot;); return -1; } int nfds; // check whether tcpconn established, howto? write-ready! while (1) { nfds = epoll_wait(epollFd, events, MAX_EVENTS, -1); if (nfds == -1) { printf(\u0026quot;start epoll_wait failed\u0026quot;); return -1; } if (nfds == 0) { continue; } if (events[0].events \u0026amp; EPOLLOUT) { printf(\u0026quot; connection is established\\n\u0026quot;); break; } } // sleep 3 seconds, before wakeup let the server close connection! // run `nc -kl 5555 -w 1` to start a tcp server. sleep(3); char sendbuf[512] = { 0 }; char recvbuf[5120] = { 0 }; int count = 0; // check whether epoll_wait can detect half-open tcpconn ev.events = EPOLLIN | EPOLLET | EPOLLRDHUP; ev.data.fd = fd; if (epoll_ctl(epollFd, EPOLL_CTL_MOD, fd, \u0026amp;ev) == -1) { printf(\u0026quot;epoll_ctl:server_sockfd register failed\\n\u0026quot;); return -1; } while (1) { nfds = epoll_wait(epollFd, events, MAX_EVENTS, -1); if (nfds == -1) { printf(\u0026quot;start epoll_wait failed\\n\u0026quot;); return -1; } if (nfds == 0) { printf(\u0026quot;epoll_wait: no events ready\\n\u0026quot;); continue; } int i = 0; for (i=0; i\u0026lt;nfds; i++) { /* if (events[i].events \u0026amp; EPOLLRDHUP) { printf(\u0026quot; epoll_wait: EPOLLRDHUP, peer close connection\\n\u0026quot;); close(events[i].data.fd); return -1; } */ if (events[i].events \u0026amp; EPOLLIN) { printf(\u0026quot; epoll_wait: read-ready\\n\u0026quot;); memset(recvbuf, 0, sizeof(recvbuf)); count = recv(events[i].data.fd, recvbuf, sizeof(recvbuf), 0); printf(\u0026quot;read bytes size:%d, data:%s\\n\u0026quot;, count, recvbuf); if (count == -1) { /* If errno == EAGAIN, that means we have read all data. So go back to the main loop. */ if (errno != EAGAIN) { printf(\u0026quot;read error\\n\u0026quot;); close(events[i].data.fd); return -1; } } else if (count == 0) { /* End of file. The remote has closed the connection. */ close(events[i].data.fd); printf(\u0026quot;tcpconn is closed by peer\\n\u0026quot;); return -1; } } } } // when write-ready, send data to server // when read-ready, read data from server int token_length = 5; char *token_str = \u0026quot;12345\u0026quot;; char *ch = \u0026quot;yumgkevin\u0026quot;; char socketId[10] = { 0 }; while (1) { nfds = epoll_wait(epollFd, events, MAX_EVENTS, -1); if (nfds == -1) { printf(\u0026quot;start epoll_wait failed\u0026quot;); return -1; } for (i = 0; i \u0026lt; nfds; i++) { /* if ((events[i].events \u0026amp; EPOLLERR) || (events[i].events \u0026amp; EPOLLHUP) || (!(events[i].events \u0026amp; EPOLLIN)) || (!(events[i].events \u0026amp; EPOLLOUT)) ) { printf(\u0026quot;enter 1\u0026quot;); fprintf (stderr, \u0026quot;epoll error\\n\u0026quot;); close (events[i].data.fd); continue; } */ if (events[i].events \u0026amp; EPOLLOUT) { printf(\u0026quot;write-ready, send data to server\\n\u0026quot;); memset(sendbuf, 0, sizeof(sendbuf)); memset(socketId, 0, sizeof(socketId)); strcpy(sendbuf, token_str); strcat(sendbuf, \u0026quot;hellow, world\u0026quot;); strcat(sendbuf, ch); sprintf(socketId, \u0026quot;%d\u0026quot;, events[i].data.fd); strcat(sendbuf, socketId); strcat(sendbuf, \u0026quot;\\r\\n\u0026quot;); ret = send(events[i].data.fd, sendbuf, strlen(sendbuf), 0); if (ret == -1) { if (errno != EAGAIN) { printf(\u0026quot;error:%s\\n\u0026quot;, strerror(errno)); close(events[i].data.fd); } continue; } printf(\u0026quot;send buf content is %s, size is %d\\n\u0026quot;, sendbuf, ret); // add revelant socket read event ev.data.fd = events[i].data.fd; ev.events = EPOLLIN | EPOLLET; epoll_ctl(epollFd, EPOLL_CTL_MOD, events[i].data.fd, \u0026amp;ev); } else if (events[i].events \u0026amp; EPOLLIN) { printf(\u0026quot;read-ready, read data from server\\n\u0026quot;); count = 0; memset(recvbuf, 0, sizeof(recvbuf)); count = recv(events[i].data.fd, recvbuf, sizeof(recvbuf), 0); if (count == -1) { /* If errno == EAGAIN, that means we have read all data. So go back to the main loop. */ if (errno != EAGAIN) { printf(\u0026quot;read error\\n\u0026quot;); close(events[i].data.fd); } continue; } else if (count == 0) { /* End of file. The remote has closed the connection. */ close(events[i].data.fd); continue; } printf(\u0026quot;receive data is:%s\u0026quot;, recvbuf); // add revelant socket write event ev.data.fd = events[i].data.fd; ev.events = EPOLLOUT; epoll_ctl(epollFd, EPOLL_CTL_MOD, events[i].data.fd, \u0026amp;ev); } } } // close socket close(fd); return 0; }  5 tcp状态转换图 "}),a.add({id:459,href:"/tags/dapper/",title:"dapper",description:"",content:""}),a.add({id:460,href:"/tags/opentracing/",title:"opentracing",description:"",content:""}),a.add({id:461,href:"/tags/tracing/",title:"tracing",description:"",content:""}),a.add({id:462,href:"/blog/2018-10-03-%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%88%86%E5%B8%83%E5%BC%8F%E8%B7%9F%E8%B8%AA%E7%B3%BB%E7%BB%9Fdapper/",title:"大规模分布式跟踪系统dapper",description:"dapper，大规模分布式跟踪系统，现在有不少开源实现是基于dapper的核心思想来设计的，如zipkin、jaeger、lightstep、appdash等。了解dapper的工作原理，也方便理解zipkin、jaeger这几个常用的分布式跟踪实现，使用opentracing来集成不同的backend的时候也不至于一头雾水。所以又把dapper的论文阅读了几遍，梳理了下其核心思想。网上也有不少这篇论文的中文译文，但是翻译的蹩脚，理解起来很晦涩，所以还是自己梳理下方便以后查阅，也希望对大家有帮助。",content:" img { width: 680px; padding-bottom: 1rem; }  dapper，大规模分布式跟踪系统，现在有不少开源实现是基于dapper的核心思想来设计的，如zipkin、jaeger、lightstep、appdash等。了解dapper的工作原理，也方便理解zipkin、jaeger这几个常用的分布式跟踪实现，使用opentracing来集成不同的backend的时候也不至于一头雾水。所以又把dapper的论文阅读了几遍，梳理了下其核心思想。网上也有不少这篇论文的中文译文，但是翻译的蹩脚，理解起来很晦涩，所以还是自己梳理下方便以后查阅，也希望对大家有帮助。\n[TOC]\n分布式跟踪 # 分布式跟踪系统，能够将系统中各个服务之间的调用关系（依赖关系）、请求耗时情况、请求方式（串行、并发）等等清晰地展示出来，对于快速定位系统调用链路中出现的异常问题有着非常重要的作用。不管是普通程序开发人员，还是web、rpc或其他框架开发人员，都希望能集成分布式跟踪的能力。\ndapper简介 # 现在主流的分布式跟踪系统，基本都是基于google发布的论文dapper来进行后续开发的，论文中详细解释了dapper实现分布式跟踪的原理，点击查看 dapper：大规模分布式跟踪系统。\n设计初衷 # 分布式跟踪系统，其职责就是“无所不在的部署，持续的监控”，这也是真正提现分布式跟踪能力的前提。“无所不在的部署”，这非常重要，因为即使一小部分监控没有监控到，也会让人对整个跟踪结果产生质疑。“持续的监控”，监控应该是7x24小时不间断的，对于某些小概率事件或者难以重现的事件，如果不能做到持续监控就有可能遗漏这部分异常。\n设计目标 # dapper将“无所不在的部署，持续的监控”作为大的方向，由此也确定了具体的3个设计目标。\n 低开销，跟踪系统对在线服务的影响应该足够小 有些服务是经过开发人员高度优化后的，如果跟踪系统引入的overhead比较大，就可能抵消掉之前优化工作带来的性能提升，开发人员不得不关停分布式跟踪能力。 应用透明，分布式跟踪的实现细节应该对应用开发人员透明 应用开发人员是不需要知道有分布式跟踪这回事的，如果一个跟踪系统不能屏蔽这些细节、需要开发者配合的话，这种业务侵入性很强的跟踪系统是难以大力推广的，也就难以实现“无所不在的部署”这样的能力，也就不能实现全面细致的跟踪。 可伸缩性，面对未来N年服务集群扩大的趋势，都应该能对其进行有力地把控 分布式跟踪系统不只是跟踪几个、十几个服务，它在设计上要能够对大规模的服务集群进行全局把控。这就要求其必须保持足够的可伸缩性，在服务集群扩大之后要通过某种形式的“扩容”来保证分布式跟踪能力的线性增长。这里的扩容可能是机器级别的、网络级别的、存储级别的。  这3个设计目标之外，还有另一个设计目标，“信息处理的速度要足够快”。如果信息处理的速度足够快，就可以近乎实时地发现线上系统中存在的异常问题。\n实现方案 # dapper在许多高阶的设计思想上吸取了pinpoint和Magpie的研究成果，但在分布式跟踪领域中，dapper的实现包含了许多新的贡献。例如为了保证对业务服务的“低开销”，引入了“采样率”。dapper的另一个特征就是在足够低的层级实现分布式跟踪，以对应用级透明。\n跟踪树 # dapper的分布式跟踪方案可以借助下图来一探究竟，其核心思想是从客户端（user）发起的请求一直到接入层服务A，再到后端服务B、C，再从C到D、E，整个请求处理链路可以借由一个树形结构来表示出来。可以通过将服务器上发生的每一次请求、响应作为一个记录收集起来，收集信息包括跟踪标识符（message identifier）和时间戳（timestamped events）。通过添加标注（annotation），依赖于应用程序或中间件明确地标记一个全局id，从而连接每一条收集的记录和用户发起的请求。显然这里需要代码植入，不过我们可以代码植入的范围收敛到框架层，保证对应用层透明。\n下面对dapper的设计思想进行更深入的了解，我们将先从上图中涉及到的几个关键概念开始。\n跟踪（trace） # 在dapper跟踪树结构中，树节点是整个架构的基本单元，而每一个节点是一个span，它又包含了对其他span的引用。节点之间的连线表示的是当前span与它的父span或者派生出的子span之间的关系。span在日志文件中的表示只是简单的记录请求开始时间、请求结束时间，span在整个树形结构中它们是相对独立的。\n)\n上图是一个分布式跟踪过程的示意图，图中说明了span在一个完整的跟踪过程中是什么样的，dapper记录了span的名称、span-id、父span-id，以重建一次跟踪过程中不同span之间的关系。如果一个span没有父span-id那么它是root span，也就是整个调用链的起始点。所有span都挂在一个特定的跟踪链上，也共用同一个跟踪id，即trace-id（图中未标出）。所有这些id（trace-id、span-id）都是全局唯一的64位整数表示。\n在一个典型的dapper跟踪中，我们希望为每一个rpc对应到一个单一的span上，而且每一个额外的组件层都对应到一个跟踪树型结构的层级。\n跨度（span） # 下图中给出了一个更加详细的dapper跟踪中span记录点的视图，其实每个span记录点都包含了两个不同的视角（client端RPC视角，server端RPC视角），图中也画出了rpc Helper.Call的client、server端视角，如client发送请求、server接收请求、server处理、server发送响应、client接收响应的过程。span的开始、结束时间，以及任何rpc的时间信息都可以通过dapper在rpc组件库中植入代码以记录下来。\n如果应用程序开发者希望在跟踪中增加自己的注释信息（业务数据），如图中的“foo”，这些信息也会和其他span一样记录下来。\n此外，任何一个span记录点都包括了来自rpc client、rpc server端的主机信息。每一个span记录点可以包含来自client、server两端的注释信息，使得span记录点能够记录请求方、响应方这两个主机的信息。另外由于记录的时间戳来自不同的主机，不同的主机上的时间可能存在一定的时间偏差（时钟漂移），必须考虑时间偏差带来的影响，因为它会影响到我们判断某个span的发生时间的先后顺序。我们可以基于这样的一个事实，就是rpc client发送一个请求之后server才可以收到，对于响应也是一样，server响应之后client才能收到响应，这样一来rpc server端的接收响应时间戳、发送响应时间戳就确定了一个上下限。\n植入点（instrumentation point） # dapper可以对应用开发者以近乎零侵入的成本对分布式控制路径进行跟踪，几乎完全依赖于少量通用组件库的改造，如在框架层对现有rpc代码进行改造，植入分布式跟踪相关的代码。\n如何记录跟踪上下文信息呢（trace-id、parent span-id、span-id）？不同的rpc框架可能基于不同的网络服务模型（同步、异步、多进程、多线程、协程）实现，需要考虑清楚如何保存这里的跟踪上下文，可以结合不同的编程语言提供的语言特性来辅助实现，如基于java多线程模型实现的rpc框架可能会考虑通过ThreadLocal来存储跟踪上下文信息，golang可以通过goroutine局部变量来寄存跟踪上下文信息，C++可以通过一个全局map结构来维护请求seq与跟踪上下文的映射关系等，这只是一种保存跟踪上下文信息的思路，具体的场景还需要具体分析。\n注释（annotation） # 下面是通过c++和java向跟踪中span记录点添加注释的方法：\n上述植入点可以帮助推导出复杂的分布式系统的跟踪细节，使得dapper可以在不改动应用代码的情境下就可以发挥其核心功能。然而，dapper还允许应用开发人员在跟踪的过程中添加额外的信息，以监控更高级别的系统行为，或帮助调试问题。\ndapper允许用户通过一个简单的api来定义时间戳的annotation，核心代码如上图所示，这些annotation可以添加任意内容，为了避免dapper使用者过分热衷于添加注释，dapper也添加了一些限制，即单个span有一个可配置的annotation数量上限。\n除了上图中展示的添加的文本annotation，dapper也支持添加key-value形式的annotation，提供给开发人员更强的跟踪能力。\n采样率（sampling） # 低开销是dapper的关键设计目标之一，如果这个工具一开始设计的时候其价值还未被充分认可，而又对性能有明显开销的话，其他开发人员、运维人员是肯定不愿意去应用、推广这个玩意的。况且，dapper希望能够让开发人员通过使用annotation的方式来增强跟踪能力，而又不用担心性能方面的开销。而在开发过程中也发现，某些类型的web服务性能对植入代码确实比较明显。因此dapper开发人员除了把dapper的收集工作进一步优化，使其对应用性能影响尽可能小之外，还引入了进一步控制性能开销的方法，那就是当遇到大量请求时只记录其中一小部分。我们在文章的后续部分会进一步描述采样率方案更多的细节。\n跟踪的收集 # 下图展示了dapper的跟踪的收集过程，大致可以分为图中1、2、3三个过程。\n 应用程序通过dapper api将span数据写入本地日志文件中 dapper守护进程和收集组件把这些日志信息从生产环境的日志文件中拉取出来 dapper守护进程和收集组件将拉取到的日志信息整理，并写入BigTable仓库中  一次跟踪，被设计成BigTable中的一行 每行中的每一列都代表了一个span 不同跟踪涉及到的span数量可能不同，BigTable支持稀疏表格，很适合这种场景    dapper还提供了额外的api来帮助我们快速访问BigTable仓库中的跟踪数据。\n安全和隐私 # 前面提到了应用程序中可以在当前span中添加一定数量的annotation来进一步增强跟踪能力（因为trace分析工具可以在收集到的日志数据中提取出这些信息），这些annotation可以帮助定位系统为何表现异常的原因。然而，有些情况下，这些数据中可能包含了敏感信息，这些信息不应该暴露给未经授权的用户（包括正在debug的工程师）。\n安全和隐私问题应予以足够的重视，dapper中可以记录rpc的名称，但是不记录任何有效载荷数据，如请求体、响应体信息。相反，应用程序级别的annotation提供了一个方便的可选机制：应用程序开发人员可以在span中选择关联那些为以后分析提供价值的注释信息。\ndapper还提供了一些安全上的便利，这是dapper的设计者所始料未及的。通过跟踪公开的安全协议参数，dapper可以过检相应级别的认证或加密系统，来监视应用程序是否满足安全策略。dapper还可以提供信息来决定是否启用期望的系统隔离策略，例如支撑敏感数据的应用程序不得与未经授权的系统组件进行交互。这样的措施提供了比源码审核更强大的安全保障。\n部署状况 # 无处不在的部署，持续监控，应用级透明！dapper在谷歌使用已经有多年，通过了线上环境的检验。\ndapper运行库 # 在谷歌内部，dapper主要是被植入到了一些通用的基础rpc框架、线程控制和流程控制组件库中，其中包括span的创建、采样率设置，以及把日志写入本地磁盘中。除了做到轻量级，植入的代码更需要稳定和健壮，因为它与海量的应用对接，一旦植入代码有问题，将使得维护和修复bug变得很困难。实际植入的代码是由未超过1000行的c++和不超过800行的java代码组成。为了支持key-value形式的annotation还额外植入了500行左右代码。\ndapper覆盖情况 # dapper的推广是从两个维度进行，一个是在生产环境应用中生成dapper traces（这里的应用链接了前面提到的dapper运行库），另一个是收dapper traces colletion daemon来收集生成的这些dapper traces。dapper daemon是我们的机器安装的OS镜像的一部分，因此几乎谷歌内部的所有的线上服务器都支持dapper跟踪。\n在某些情况下dapper可能不能够正确地跟踪控制路径，这可能是因为使用了非标准的控制流操作，或者是dapper错误地将跟踪信息归类到不相关的事件上。dapper提供了一个简单的库来帮助开发人员手动控制跟踪的传播信息，也算是一种上述问题的办法吧。当前大约有40多个c++程序和33个java程序需要手动控制跟踪信息传播，只是google线上应用的九牛一毛，足可以忽略不计。还有一部分是因为没有使用dapper运行时库，如使用原生的tcp socket、soap rpc进行通信，这种dapper肯定也是无法跟踪的。\n早期部署的时候，dapper还没有那么稳定，所以默认是关闭的， 直到dapper开发人员对其稳定性和开销有了足够的信心之后才将其修改为默认开启。\n注释使用情况 # 程序员倾向于将应用层级的一些dapper annotation作为一种分布式调试日志使用，或者用来对dapper traces进行分类。例如，所有的BigTable请求都添加了要访问的表名来作为annotation。当前几乎70%的dapper spans以及90%的dapper traces包括了至少1个dapper annotation信息。\n41个java应用、68个c++应用添加了自定义应用层级的annotation来更好地理解span内的活动信息。现在来看java开发人员在span内添加的annotation比c++开发人员要多一些，这可能是因为c++服务更偏底层，java应用更接近用户，逻辑更重一些，其中涉及到的各种服务器请求更多一些。\n管理跟踪开销 # 跟踪系统的开销主要有两部分组成，一是被监控系统生成trace数据和trace daemon收集这部分trace数据所带来的系统性能下降，二是需要使用一部分资源来存储和分析trace数据。虽然说我们认为对一个有价值的中间件植入跟踪带来一部分性能开销是值得，但是如果能讲这里的开销降低到可以忽略的程度，那是最好不过了，推广该跟踪系统也会变得更加简单。\n从3个方面展示跟踪系统的开销情况：dapper组件操作的开销，跟踪收集的开销，dapper对生产环境负载的影响。这里也会介绍dapper的可变采样率机制如何帮助降低开销，以及如何在低开销和获得代表性的跟踪二者之间获得平衡。\n生成跟踪的开销 # 生成trace数据的开销是dapper性能影响中最关键的部分，因为收集、分析trace数据的工作可以在紧急情况下更容易被关闭。dapper运行库中生成trace数据的开销，主要是创建和销毁span、annotation，并将其记录到磁盘供后续收集而引入的。root span的创建和销毁平均需要消耗204ns的事件，创建、销毁其他span则只需要大约176ns，这是因为root span的创建需要生成一个全局唯一的id，开销稍大些。\n如果一个span没有被采样的话，这个span下创建annotation的成本几乎可以忽略不计，平均只需要9ns。如果被纳入采样的话，会用一个字符串来进行标注，平均需要40ns。这些数据都是在2.2GHz的x86服务器上采集的。\n在dapper运行期将trace数据写入到本地磁盘是开销最大的操作，但是他们的可见开销大大减少了，因为写入日志文件的操作相对于被跟踪的应用系统来说是一个异步的操作。不过，如果请求量特别大的情况下，尤其是采样率很高的情况下，日志写入的操作仍然是开销比较大的操作。后面会展示一个web搜索的负载下的的性能开销示例。\n跟踪收集的开销 # 读取生成的trace数据也会对负载产生一定的干扰，下表展示了最坏情况下，dapper trace collector daemon在高于实际情况负载情况下进行trace收集过程中cpu使用率情况。在生产环境中，这个守护进程从来没有超过0.3%的单核cpu使用率，而且只有很少量的内存使用（以及堆碎片噪音）。我们还限制了dapper守护进程的调度优先级为最低优先级，以避免在一台高负载的服务器上出现cpu竞争。\ndapper也是一个带宽资源的轻量级消费者，每一个span在传输到BigTable仓库过程中平均只占用了426个字节。作为网络行为中的极小部分，dapper的trace数据收集在谷歌的生产环境中只占用了0.01%的网络资源。\n生产环境的开销 # 每个用户请求可能会牵扯到对大量的高吞吐量的线上服务的请求调用，这也是为了进行分布式跟踪的原因之一。这种情况下会生成大量的trace数据，并且他们对性能的影响是最敏感的。在下表中我们用集群下的网络搜索作为例子，通过调整采样率来衡量dapper在延迟和吞吐量方面对线上服务性能的影响。\n从表中可以看到，采样率的变化对服务吞吐量的影响不是很明显，但是对服务延迟的影响还是比较大的，因此也可以得出这样的结论，对trace数据进行采样还是很有必要的。\n当我们把采样率调整到1/16之后，引入的服务延迟和吞吐量的开销就全部在实验误差范围内了。在实践中，我们还发现即便采样率调整到1/1024后仍然有足够量的trace数据来跟踪大量服务。保持dapper的性能开销基准在一个非常低的水平是非常重要的，因为它为哪些应用提供了一个宽松的环境来使用完整的annotation api来增强跟踪能力的同时而无需担心性能损失。使用较低的采样率也是有额外的好处的，可以让持久化到硬盘中的trace数据在垃圾回收机制处理之前保留更长的事件，这样为dapper的收集组件保留了更多的灵活性。\n可变采样 # 进程中dapper所引入的开销与采样率成正比。dapper的第一个生产版本统一将采样率设置为了1/1024。这个简单的方案对高吞吐量的线上服务是很有用的，因为那些感兴趣的事件在吞吐量大了之后通常可能会经常出现，容易被再次捕捉到。\n但是，这种较低的采样率，对于吞吐量比较小的线上服务可能就不太明智了，会很容易错过一些事件，这个时候可能希望配置成较高的采样率，如1，但是又可能要担心引入的性能开销。关键的是，这种情况下要覆盖默认的采样率1/1024还需要人工进行干预，这可不是dapper设计者所期望的，这样就引入了可变采样。\n在部署可变采样(也称自适应采样)的过程中，参数化配置采样率时，不再使用一个统一的采样方案，而是使用一个采样期望率来标识单位时间内采样的trace数量。例如希望1min内采样100条记录，在高吞吐量的线上服务中就多丢弃一些trace数据，在低吞吐量的线上服务中就少丢弃一些trace数据。这样一来，高吞吐量的将自动降低采样率，低吞吐量的将自动提高采样率，从而使得开销一直低于开销基准以下。实际使用的采样率会随着跟踪本身记录下来，有利于trace分析工具进行准确的分析。\n应对积极采样 # 在高吞吐量的线上服务中往往采样率会低至0.01%，新的dapper用户往往会觉得这不利于他们的分析。但我们在谷歌的实践经验使我们相信，对于高吞吐量服务，如果一个显著的操作在系统出发生了一次，那它就会出现成千上万次，因此积极采样（agreessive sampling）（指的应该是可变采样动态调整采样率）并不会妨碍他们的分析。低吞吐量的服务，也许每秒就几十次请求，而不是几十万，即便采样率为100%也可以负担的起每一个请求。综合这两种情况，积极采样（可变采样而非固定采样率不变）没什么问题，这是促使我们决心使用可变采样的原因。\n额外采样 # 上述采样策略描述的是应用程序生成trace数据时是否记录到本地磁盘中，通过可变采样减少性能开销的同时不丢失过多的跟踪事件以保证跟踪能力。dapper的团队还需要将收集到的trace数据写入中央资料库的BigTable仓库中，需要控制写入规模，因此为了达到这个目的，还需要结合“二级采样”。\n目前我们的生产集群每天产生超过1TB的trace数据，dapper的用户希望生产环境下的进程的跟踪数据从被记录之后能够保存至少两周的事件。逐渐增长的trace数据密度必须和dapper中央仓库锁消耗的服务器及硬盘存储进行权衡。高采样率还使得dapper收集器写入BigTable中央仓库的速率接近了BigTable写吞吐量上限。\n为了维持所需的硬件成本和渐增的BigTable写吞吐量之间的灵活性，我们在trace数据收集系统自身中增加了额外的采样控制。这里充分利用了所有span都来自一个特定的trace并共享同一个trace-id这个事实，有些span可能横跨了数千个主机。对于收集系统中的每一个span，我们用hash算法把trace-id转成一个标量z，这里0\u0026lt;=z\u0026lt;=1。如果z比我们收集系统中指定的系数（阈值）低的话，我们就保留这个span信息，并写入到BigTable仓库中；反之，我们就丢弃它。trace-id唯一标识了一个trace，我们要么保存整个跟踪信息，要么全部丢弃，而不是单独处理trace数据内的某个span。\n有了这个额外的“全局写入率参数”之后，使我们的收集管道变得简单多了，因为我们可以很容易地在配置文件中调整它来控制写入率。\n总结 # dapper结合两种采样策略，来平衡开销、跟踪效果、硬件成本之间的关系：\n 应用程序中生成trace数据并记录到本地磁盘，此过程应用“可变采样策略”； trace数据收集系统收集数据写入BigTable中央仓库，此过程应用“额外采样策略”；  dapper工具 # 关于dapper的配套工具，这里只给一个dapper操作界面的展示，方便大家了解大致上具备哪些能力，如下图所示。\n大家可以了解下zipkin、jaeger，他们都是基于dapper演化而来，这里我们就再详细介绍dapper自身的工具了，因为我们也无法使用它，只能用开源实现zipkin、jaeger之类的。\n本文主要是为了阐述dapper的设计思想，方便我们大家了解分布式跟踪系统的工作原理，然后方便我们将现有的开源实现zipkin、jaeger集成到我们自身的框架中，方便自己的业务开发人员定位线上问题。\n如果对谷歌dapper的工具感兴趣的话，可以参考这里的说明，点击查看 dapper：大规模分布式跟踪系统。\ndapper使用 # dapper在谷歌被广泛使用，一部分直接通过dapper的用户界面，另一部分间接地通过对dapper api的二次开发或者在现有的api基础上建立的应用。\n原dapper论文中列举了一些成功的dapper使用场景，大家也可以参考下，决定将dapper，或者zipkin、jaeger用在什么场景下呢？能够通过二次开发定制化一些自己需要的可视化工具出来呢？这个是我们要思考的，也是对我们的应用开发人员、维护人员最优价值的部分。\n在开发中使用dapper # Google AdWords借助dapper来优化自己的系统，发现系统中延迟过高的服务调用，发现不必要的串行请求并推动团队修复，以改善性能问题等等。\n与异常监控的集成 # Google维护了一个不断从进程中收集异常信息并集中异常信息报告的服务，如果这些异常发生在跟踪采样的过程中，对应的trace-id和span-id也会被记录到异常记录中，后续借助可视化工具可以容易定位异常发生在链路中的哪一个环节，并借助annotation来进一步定位问题。\n解决延迟的长尾效应 # 当一个系统不仅涉及数个子系统，而是几十个开发团队的涉及到的系统的情况下，端到端性能较差的根本原因到底在哪，这个问题即使是我们最好的和最有经验的工程师也无法正确回答。在这种情况下，Dapper可以提供急需的数据，而且可以对许多重要的性能问题得出结论。\n推断服务依赖 # 线上服务基本都是集群部署，每一个服务上运行的任务可能依赖了其他的很多服务，而不同的任务依赖的服务也是是动态改变的，所以不可能仅从配置信息上推断出所有这些服务之间的依赖关系。dapper核心组件与dapper跟踪annotation一并使用的情况下，“Service Dependencies”项目能够推算出任务各自之间的依赖，以及任务和其他软件组件之间的依赖。在公司内部的各个流程需要准确的服务依赖关系信息，以确定瓶颈所在，以及指导服务的迁移计划。\n不同服务的网络使用率 # 谷歌投入了大量的人力和物力优化其网络，以前网络管理员只能关注独立的硬件信息、常用工具及以及搭建出的各种全局网络鸟瞰图的dashboard上的信息。网络管理员确实可以一览整个网络的健康状况，但是，当遇到问题时，他们很少有工具可以及时准确地定位到导致网络负载高的应用程序级别的罪魁祸首。 虽然dapper不是设计用来做链路级的监控的，但我们发现，它非常适合去做集群之间应用级网络活动的分析。谷歌利用dapper这个平台，建立一个不断更新的控制台，来显示集群之间最活跃的应用级网络流量热点。此外，使用dapper我们能够为昂贵的网络请求指出具体到应用级的原因，而不是面对不同服务器之间的信息孤岛无所适从。\n分层和共享存储系统 # 在Google的许多存储系统是由多重独立复杂层级的分布式基础设备组成的。例如，Google的App Engine就是搭建在一个可扩展的实体存储系统上的，该实体存储系统在BigTable基础上封装、暴露了某些RDBMS功能。 BigTable呢，又同时使用了Chubby（分布式锁系统）及GFS。 在这种分层的系统中，并不总是很容易确定最终用户资源的消费模式。例如，针对一个给定的BigTable单元格的大量GFS请求主要来自于一个用户或是由多个用户，但是在GFS层面，这两种明显的使用场景是很难界定的。而且，如果缺乏一个像dapper一样的工具的情况下，对共享服务的竞争可能会同样难于调试。 dapper的用户界面可以聚合那些调用任意公共服务的多个客户端的跟踪的性能信息。这就很容易让提供这些服务从多个维度给他们的用户排名，例如，入站的网络负载，出站的网络负载，或服务请求的总时间。这样就便于对一个共享服务确定其上游服务对其造成的负载情况进行界定，便于后续推动上游优化服务调用逻辑或者独立部署共享服务等等吧。\ndapper的救火能力 # 对于一些“救火”任务，dapper可以处理其中的一部分。对于那些高延迟，不，可能在正常负载下都会响应超时的服务，Dapper用户界面通常会把这些瓶颈的位置隔离出来。通过与dapper收集跟踪的守护进程的直接通信，那些特定的高延迟的跟踪数据轻易的就能收集到。当出现灾难性故障时，通常是没有必要去看统计数据以确定根本原因的，只查看示例跟踪就足够了。 但是，除非收集到的dapper数据的批量分析能在问题出现10分钟之内完成，否则dapper就不能处理这样的“救火”任务。\n总结 # 本文中，我们介绍了谷歌dapper分布式跟踪系统，并汇报了谷歌内部的开发、使用经验。 dapper几乎部署在所有的谷歌线上系统上，并可以在不需要应用级修改的情况下进行跟踪，而且没有明显的性能开销。dapper对于开发人员和运维团队带来的好处，可以从大家对跟踪用户界面的广泛使用上看出来，另外我们还列举了一些dapper的使用案例来说明dapper的作用，这些案例有些甚至都没有dapper开发团队参与，而是被应用的开发者设计、开发出来的。\n据我们所知，这是第一篇汇报生产环境下分布式系统跟踪框架的论文。事实上，我们的主要贡献源于这个事实：论文中回顾的这个系统已经运行两年之久。我们发现，结合对开发人员提供简单API和对应用系统完全透明来增强跟踪的这个决定，是非常值得的。\n我们相信，Dapper比以前的基于Annotation的分布式跟踪达到更高的应用透明度，这一点已经通过只需要少量人工干预的工作量得以证明。虽然一定程度上得益于我们的系统的同质性，但它本身仍然是一个重大的挑战。最重要的是，我们的设计提出了一些实现应用级透明性的充分条件，对此我们希望能够对更错杂环境下的解决方案的开发有所帮助。\n最后，通过开放dapper跟踪仓库的代码给内部开发者，促使了更多的基于跟踪仓库的分析工具的产生，而仅仅由dapper团队埋头苦干的是远远不能达到现在这么大规模的，这个决定促使了设计和实施的展开。\n参考文献：\n Dapper, a Large-Scale Distributed Systems Tracing Infrastructure Dapper，大规模分布式系统的跟踪系统  "}),a.add({id:463,href:"/tags/bloom-filter/",title:"bloom filter",description:"",content:""}),a.add({id:464,href:"/tags/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/",title:"布隆过滤器",description:"",content:""}),a.add({id:465,href:"/blog/2018-09-29-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8%E5%8E%9F%E7%90%86%E5%8F%8A%E5%BA%94%E7%94%A8/",title:"布隆过滤器的原理及应用",description:"布隆过滤器在很多场景中都有应用，如根据发件人过滤垃圾邮件、避免已浏览视频的重复推荐、避免分布式缓存中不存在key的访问穿透，等等，布隆过滤器发挥了非常大的作用，布隆过滤器其实也存在很多的变体。本文就来结合作者业务中遇到的问题、布隆过滤器的应用来详细了解下布隆过滤器的原理及应用。",content:" img { width: 680px; padding-bottom: 1rem; }  布隆过滤器在很多场景中都有应用，如根据发件人过滤垃圾邮件、避免已浏览视频的重复推荐、避免分布式缓存中不存在key的访问穿透，等等，布隆过滤器发挥了非常大的作用，布隆过滤器其实也存在很多的变体。本文就来结合作者业务中遇到的问题、布隆过滤器的应用来详细了解下布隆过滤器的原理及应用。\n布隆过滤器 # 描述布隆过滤器之前，首先描述下背景，经常遇到“快速查询、插入”等操作的场景，这个时候第一时间想到的可能是set、map数据结构，因为它的时间复杂度为O(1)，是首选的数据结构。但是当要记录的数据量非常大时，set、map可能并不是一种合适的选择。\n假如我们有一个短视频推荐的场景，用户每次拉取短视频列表时都只返回用户没有看过的短视频，短视频通过短视频id（uint32）唯一标识，假如我们用map来存储，一个短视频id就需要4字节，假如一个用户一天可以观看50个短视频，1个月就是1500个，1年就是18000个，这样一个用户1年就需要占用存储72KB，假如我们有100w用户，那就是72GB，这些信息是要放在内存里面进行计算的，什么样的机型才可以拥有72GB大小的内存啊？要尽量做到“低成本、高性能”的方案设计，这种选型是有问题的。\n布隆过滤器（bloom filter），其实就是一种折中的设计方案。内存是按字节寻址，但是1个字节是8位，存储1个短视频id，比如值1，1bit就可以表示的情况下却需要多占用31个bit，岂不是极大的浪费？布隆过滤器的底层存储其实也就是一段连续的内存空间，所有的查询、插入操作都转换成对bit的查询、写入操作。比如要写入一个短视频id，将通过多轮hash(短视频id)计算出多个bit offset，如b1~b8，然后存储操作就转换为将b1~b8全部设置为1，查询操作就转换为查询b1~b8是否全部为1。\n布隆过滤器，以接近O(1)的性能进行查询、插入操作，但是由于hash碰撞的存在，会引入一定的误差率。存在这样的问题，本来短视频id NNN没有存储，但是却由于多轮hash(NNN)得到的b1~b8与其他某个短视频id MMM计算得到的b1~b8完全相同，更可能由于之前存储多个短视频id A、B、C、D时将b1~b8设置为1，此时就会导致判断NNN已存储。这种情况就引入了“误差率”的概念。\n误差率： 布隆过滤器现在要存储N个元素，存储指定元素e时，先进行多轮hash计算得到b1~bn，然后依次检查offset为b1~bn的bit位是否已经设置为1，如果全部为1则表示布隆过滤器中已存储该元素。当不全为1时认为没有存储过元素e，将b1~bn设置为1。 由于写入操作时，我们总是遵循test、set的方式，所以当我们逐次将N个元素写入布隆过滤器时，假如test时发现元素已存储，这种情况下一定是由于hash碰撞引起，引入了误差。 所以如果要求写入N个元素却只成功写入了M个元素（M\u0026lt;=N），误差率=(N-M)/N。\n优缺点： 优点：速度快，又节省存储空间。 缺点：存在一定的误差 \u0026amp;\u0026amp; 不支持删除操作。\n如果应用场景允许一定的判定误差，例如短视频推荐场景、信息流推荐场景等，那么布隆过滤器也不失为一种合适的选择。刚才提到set、map占用内存空间大，那么布隆过滤能占用多少呢，这里就涉及到误差率和存储成本之间的权衡了。\n误差率 \u0026amp; 存储空间 # 误差率，一般是根据应用场景或者产品体验、产品表现来指定的，如用布隆过滤器记录用户观看过的短视频id误差率不超过1/1000。\n其实指定了误差率之后，一般也就可以确定存储1个这样的短视频id所需要的大致bit数量了，简称bpe（bits per element），double bpe = - (log(error) / (ln(2)^2))，但是到底需要多少bit数量（bpe是浮点型），还需要进一步确定，int hashes = (int)ceil(ln(2) * bpe)，这表名要计算得到hashes个hash值，然后用这个值对布隆过滤器内存空间bits数量取模，从而得到hashes个bit offset。\ndouble denom = 0.480453013918201; // ln(2)^2 double bpe = -(log(error) / denom); int hashes = (int)ceil(0.693147180559945 * bpe); // ln(2)  假如希望存储entries个元素的话，在满足上述误差率的情况下，布隆过滤器需要分配内存空间为int bits = (int)(bpe * entries)。\nint bits = (int)(bpe * entries)  murmurhash算法 # 前面描述了在预期误差率的情况下，存储一个元素所需要的平均存储空间是多少bpe，以及实际存储时需要设置的bits数量，也就是需要计算的hash轮数。现在描述下hash算法，murmurhash是现在比较常用的一种hash算法，不少开源的布隆过滤器实现都是采用了murmurhash算法来实现。\nmurmurhash算法的名字来源于它的两个重要操作MU（multiply）以及R（Rotate），它在设计上并不是为了密码学上增加单向加密的难度，所以它不适用于安全领域。如果是向做一个快速的hash且希望hash碰撞满足预设指标的话，murmurhash是一个不错的hash算法。\n详细信息可以参考wikipedia，点击查看 MurmurHash算法。\n多分区布隆过滤器 # 上述描述了一个布隆过滤器的大致原理、如何确定误差率以及bpe和hash轮数、依赖的hash算法等，在实际应用中，我们可能会遇到更多的问题。\n仍以短视频推荐场景为例，假定我们设计容量是为每个用户记录最近访问过的2000个短视频，假定需要的存储空间是m，随着时间的推移，布隆过滤器中的bit=1的bits越来越多，我们不能将所有的bits写的过多，更不能写满，以为会导致误差率急剧升高，甚至超过预设的误差率。\n那么写多少bits算是合理的呢？这个可以通过实测进行计算，看看写了多少bits后误差率升高到预设值，当布隆过滤器所有bits的1/2都是1时可以看做是“写满”的标识。这个时候该如何操作呢？\n1）一种方式是清空布隆过滤器（全部设为0），但是会导致用户最近看过的短视频被重复拉取到，会直接影响用户体验。\n2）另一种思路是，布隆过滤器内部存储由一块固定内存修改为可动态增加的多块分区（slice）形式，当一个slice写满，创建一个新的slice用来执行写入操作，查询操作在新、旧slice同时查询，任一个slice命中则认为命中。等新的slice也写满时清空旧的，继续用来写入，也可以继续创建新的slice。这种带来了查询操作耗时稍微增加，存储占用有所增加，但是可以避免对用户体验造成影响，对于推荐这种要求保证用户体验的场景，特别是保证不重复观看同一个内容，这种思路也是可取的。\n3）还需要考虑的一个问题是，产品策略是随时会进行调整的，当产品希望进一步降低误差率时，该如何操作呢？可以创建一个新的布隆过滤器实例来适配错误率调整，并增加一个过渡期，在这个过渡期内，新旧两个布隆过滤器实例同时执行查询，新布隆过滤器负责写入，等过渡期结束之后，废弃旧的布隆过滤器，新的布隆过滤器单独工作。这样可以动态支持产品策略调整，不足是误差率在过渡期内可能会发生短暂波动。\n在上述2）3）思路的基础上，在项目开发中我设计开发了一个bloom实例支持多分区的布隆过滤器，并提供了序列化、反序列化能力，是对普通布隆过滤器的一种改进型设计，感兴趣的可以参考，点击查看 一种改进的布隆过滤器实现。\n计数布隆过滤器 # 上述所描述的布隆过滤器是不支持删除操作的，但是某些情境下我们是有删除需求的（这里我们就不举例了），如果要增加删除的能力，还需要额外增加一些overhead。\n考虑一下，标准的布隆过滤器不能支持删除操作的原因，很简单，就是因为要clear的bits可能同时被多个元素所使用了，直接clear bits将影响到对其他已存储元素的判断逻辑。那么又想删除当前元素，又不影响到共用该bits的其他元素，怎么办？\n判断内存对象是否被使用经常通过引用计数的方式来解决，布隆过滤器也可以借助引用计数的方式来标志某个bits是否是否被使用。我们为每个bit位额外维护一个引用计数值，当该bit被set为1时，引用计数+1，当该bit被clear为0时，引用计数-1。这样就解决了直接clear该bit所带来的问题。\n有一个非常重要的点，要回忆一下，我们数据结构选型不选用set、map是为了节省内存存储空间，现在我们却为每一个bit来额外分配了一个引用计数值，这里的值又要占用一定的存储空间。这不是又绕回以前了吗？\n这里就要考虑下引用计数值占用bits数量的问题了，这里也可以引出另一种布隆过滤器变体了，Counting Bloom Filter，简称CBF。CBF将标准的布隆过滤器位数组的每一位扩展为一个小的计数器（Counter），在插入元素时给对应的k（k为哈希函数个数）个Counter的值分别加1，删除元素时给对应的k个Counter的值分别减1。Counting Bloom Filter通过多占用几倍的存储空间的代价，给Bloom Filter增加了删除操作。下一个问题自然就是，到底要多占用几倍呢？\n我们先计算第i个Counter被增加j次的概率，其中n为集合元素个数，k为哈希函数个数，m为Counter个数（对应着原来位数组的大小）：\n上面等式右端的表达式中，前一部分表示从nk次哈希中选择j次，中间部分表示j次哈希都选中了第i个Counter，后一部分表示其它nk – j次哈希都没有选中第i个Counter。因此，第i个Counter的值大于j的概率可以限定为：\n上式第二步缩放中应用了估计阶乘的斯特林公式：\n在Bloom Filter概念和原理一文中，我们提到过k的最优值为(ln2)m/n，现在我们限制k ≤ (ln2)m/n，就可以得到如下结论：\n如果每个Counter分配4位，那么当Counter的值达到16时就会溢出。这个概率为：\n这个值足够小，因此对于大多数应用程序来说，4位就足够了。\n其他布隆过滤器变体 # 由于现实应用场景多样，布隆过滤器变体也非常多。维基百科中列出了很多布隆过滤器变体，例如：\n Cache Filtering Avoiding False Positives in a Finite Universe Counting filters Decentralized aggregation Data synchronization Bloomier filters Compact approximators Stable Bloom filters Scalable Bloom filters Spatial Bloom filters Layered Bloom filters Attenuated Bloom filters Chemical structure searching  感兴趣的可以参考维基百科中的相关描述，这里权做抛砖引玉了，点击查看 布隆过滤器。\n布隆过滤器设计实现 # 作者在工作过程中，写过一个C++版本的分段式的布隆过滤器，支持指定误差率来推算容量，并能支持后期的扩容需求，感兴趣请点击hitzhangjie/bloomfilter。\n"}),a.add({id:466,href:"/tags/comment/",title:"comment",description:"",content:""}),a.add({id:467,href:"/tags/godoc/",title:"godoc",description:"",content:""}),a.add({id:468,href:"/blog/2018-06-29-godoc%E6%96%87%E6%A1%A3/",title:"godoc文档",description:"了解godoc文档的作用，以及如何为你的项目生成godoc文档，应该如何编写godoc注释。",content:"godoc文档 # 标准库文档 # 当要查看go标准库文档时，可借助godoc命令进行查询，如godoc container/list，也可以在本地开启一个web服务来查询，如godoc -http=:6060。\n非标注库文档 # 当要查看非标准库（如自建项目）的文档时，我们也是借助godoc来查看，但是执行godoc命令之前需要做些准备工作。\n希望在文档中看到什么信息 #  package介绍 type介绍 func介绍 示例代码 针对package的示例代码 针对type的示例代码  上述几种希望看到的信息，我们首先需要在代码中按照godoc约定的方式提供上述信息，godoc才能找到这些信息展示出来。下面就分别描述下如何在代码中包含上述信息。\npackage \u0026amp; type \u0026amp; func 介绍 # 这里对package、type、func的介绍是以leading comments的方式在代码中直接提供的，就是package声明、type声明、func声明前面紧邻的注释，该注释与声明之间没有空行分隔。\n以如下文件$GOPATH/src/kisslulu/conf/conf.go为例：\n// Package conf provides support for loading json, ini, properties configuration. package conf // JsonCfg type JsonCfg struct { } // IniCfg type IniCfg struct { } // PropCfg type PropCfg struct { } // Load json config from filepath func LoadJsonCfg(filepath string) (*JsonCfg, error) { } // Load Ini config from filePath func LoadIniCfg(filepath string) (*IniCfg, error) { } // Load PropCfg from filepath func LoadPropCfg(filepath string) (*PropCfg, error) { }  运行godoc -http=:6060找到对应的package kisslulu/conf即可预览文档中对package、type、func的介绍。\npackage \u0026amp; type 示例代码 # godoc中的示例代码是存放在一个独立的文件“example_test.go”中的，这个文件名是固定的。以上文中这个conf package为例，为其编写相应的package示例代码和type示例代码。\nexample_test.go # 这个示例代码文件的包名定义为package conf_test或者package conf都可以，其他包的话go install会提示error: can't load package...，godoc运行时会对example_test.go中的示例代码进行加载并渲染。\npackage示例代码 # package示例代码是编写在在func example() {...}函数里面，只能包含一个package示例代码，通常在package示例代码里面详细描述该package的使用方法，比如完整package conf解析json、ini、prop配置文件的方法。\n以下是一个示例：\npackage conf_test import \u0026quot;fmt\u0026quot; func example() { fmt.Println(\u0026quot;hello world\u0026quot;) // how to load json cfg fp1 := \u0026quot;path1\u0026quot; cfg1, _ := LoadJsonCfg(fp1) // how to load ini cfg fp2 := \u0026quot;path2\u0026quot; cfg2,_ := LoadIniCfg(fp2) // how to load prop cfg fp3 := \u0026quot;path3\u0026quot; cfg3,_ := LoadPropCfg(fp3) fmt.Println(\u0026quot;cfg1:\u0026quot;, cfg1) fmt.Println(\u0026quot;cfg2:\u0026quot;, cfg2) fmt.Println(\u0026quot;cfg3:\u0026quot;, cfg3) // Output: {\u0026quot;port\u0026quot;:8000,\u0026quot;timeout\u0026quot;:2000} // Output: \u0026quot;ilive-service.port\u0026quot;:8000, \u0026quot;ilive-service.timeout\u0026quot;:2000 // Output: port=8000, timeout=2000 }  type示例代码 # 每中类型下往往定义了多个方法，可能有需要对多个方法提供示例代码，所以可以godoc约定允许通过函数“func Example${type}_${testcase} {\u0026hellip;}”提供多个示例代码，需要注意的是${testcase}必须首字母小写，否则godoc会忽略。\n以type JsonCfg为例：\npackage conf_test import \u0026quot;fmt\u0026quot; func example() { // ... } func ExampleJsonCfg_testcase1 () { // here is the testcase 1 } func ExampleJsonCfg_testcase2 () { // here is the testcase 2 }  看下文档效果 # 运行godoc -http=:6060，然后浏览器中打开localhost:6060，定位到package kisslulu/conf即可查看文档效果，如下图所示。 "}),a.add({id:469,href:"/blog/2018-05-21-golang-method-receiver-type%E7%9A%84%E6%A2%97/",title:"golang method receiver-type的梗",description:"golang中方法为什么receiver-type不能为指针类型、接口类型",content:"这里来聊聊method receiver type为什么不能是pointer和interface类型。\n1 receiver-type必须满足的条件 # golang里面提供了一定的面向对象支持，比如我们可以为类型T或者*T定义成员方法（类型T称为成员方法的receiver-type），但是这里的类型T必须满足如下几个条件：\n T必须是已经定义过的类型； T与当前方法定义必须在同一个package下面； T不能是指针； T不能是接口类型；  前面两点都比较容易理解，下面两点是什么梗？为什么就不能在指针类型上添加方法？为什么就不能在interface上添加方法？当然可以一句话待过，golang不支持，但是我想问下为什么？\n2 receiver-type为什么不能是指针类型？ # golang允许为 类型指针*T 添加方法，但是不允许为 指针类型本身 添加方法。按现有golang的实现方式，为指针类型添加方法会导致方法调用时的歧义。\n看下面这个示例程序。\ntype T int func (t *T) Get() T { return *t + 1 } type P *T func (p P) Get() T { return *p + 2 } func F() { var v1 T var v2 = \u0026amp;v1 var v3 P = \u0026amp;v1 fmt.Println(v1.Get(), v2.Get(), v3.Get()) }  示例程序中 v3.Get() 存在调用歧义，编译器不知道该调用哪个方法了。如果要支持在指针这种receiver-type上定义方法，golang编译器势必要实现地更复杂才能支持到，指针本来就比较容易破坏可读性，还要在一种指针类型上定义方法，对使用者、编译器开发者而言可能都是件费力不讨好的事情。\n3 receiver-type为什么不能是接口类型？ # 这没有什么好揣测的，只是golang runtime不支持而已。golang现在的实现里，interface内部结构只能表示方法原型，但是不包括方法定义，struct才可以包括方法定义（这部分内容感兴趣的可以翻下golang的源码，这里不展开了）。\n当一个类型实现了某个接口声明的全部方法时，就说这个类型实现了这个接口，就可以将这个类型的值赋值给该接口类型的值，此时会更新接口值的 dynamic value和dynamic type 字段。这里需要 根据接口中是否定义了方法列表 来进一步分析，可以细分为 接口方法列表为空 和 接口方法列表不空 两种情况讨论。\n下面以这里的示例代码为例进行分析：\n// - 接口类型1 type EmptyIface interface{ } // - 接口类型2 type Stringer interface { String() string } // - 类型Binary实现了接口Stringer，也实现了EmptyIface type Binary uint64 func (i Binary) String() string { return strconv.Uitob64(i.Get(), 2) } func (i Binary) Get() uint64 { return uint64(i) } // - 为接口值赋值 var b Binary = Binary(1) var eface EmptyIface = b var iface Stringer = b fmt.Println(iface)  3.1 空接口interface # eface对应接口类型是interface{}，并且Binary值b小于等于sizeof(uintptr)，那么eface的dynamic value就是直接拷贝b；如果这里是eface := anyBigStruct {\u0026hellip;.}，并且anyBigStruct size大于sizeof(uintptr)，那么就需要开辟内存拷贝anyBigStruct的值，并将新开辟内存的地址设置到dynamic value字段。dynamic type就指向对应类型的定义了。\n此时的接口类型可以表示为：\ntype eface struct { _type *_type data unsafe.Pointer }  此时的接口值可以表示为： 3.2 非空接口interface{ method-list } # 如果iface对应接口类型interface{methods-list}，这个时候dynamic value还是与1）中同样的处理，但是dynamic type处理方式不同，需要对运行时接口方法的调用地址进行处理。\n这时会创建一个 itable（类似c++虚函数vtable），这个itable里面保存了iface的接口类型以及接口中声明的各个方法原型对应的调用地址，调用地址从何而来？这里的调用地址也就是接口值动态类型中实现的方法的调用地址。设置完接口方法的所有调用地址后，itable构建完成，然后将iface接口值里面的tab字段指向该itable。\n此时的接口类型可以表示为：\ntype iface struct { tab *itab data unsafe.Pointer }  此时的接口值可以表示为： 3.3 接口方法调用 # 通过接口值调用方法的时候，需要根据 “该接口值类型、接口值对应的动态类型” 查询对应的接口方法实际的调用地址。如果该接口类型里面根本就没有方法列表，那肯定就报错了也不会查询tab，eface里面也没这个字段；如果接口类型里面有这个方法定义，那就根据iface.tab指向的itable去查询对应该接口类型、动态类型的对应方法的调用地址，然后执行目标地址处的方法体。\n从将Binary值b赋值给iface，再到通过iface查询动态类型Binary中实现的方法Stringer调用地址，最终执行Binary中实现的方法String()，这整个逻辑处理过程中如何对接口类型声明方法列表、动态类型实现方法列表进行处理，我们应该清楚了。\n总而言之，现在golang实现中interface的内部表示不包含“方法定义”相关的字段，无法表示为interface添加的方法定义，编译器当然也不允许。\n不同的编程语言对函数调用的多态实现有不同的思路，c++是通过填充基本类型的虚函数表的方式，golang是通过类似的这样一种查询表的形式。总结一下就是并非golang无法通过扩展支持在接口上添加方法，只是这样是否真的有必要，值得商榷。至少非空接口是用来定义一种明确的行为（contract）的，在上面又加个方法，是什么意思呢？因此不允许将接口类型定义为receiver type也是与接口的定位相对应的吧。\n4 总结 # receiver-type不允许为指针类型和接口类型，对其中原因进行了一点思考和总结。\n参考资料\n Russ Cox, “接口与itable关系”, https://research.swtch.com/interfaces  参考图片\n"}),a.add({id:470,href:"/tags/method/",title:"method",description:"",content:""}),a.add({id:471,href:"/tags/receiver/",title:"receiver",description:"",content:""}),a.add({id:472,href:"/tags/closure/",title:"closure",description:"",content:""}),a.add({id:473,href:"/blog/2018-05-19-golang-function-closure%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/",title:"golang function-closure 实现机制",description:"理解了go闭包的设计实现细节之后，就更容易明白闭包的工作原理，也更容易在编码时绕过一些最佳实践所没有展开讨论的神坑，比如for循环变量被闭包引用问题，比如是值捕获还是引用捕获问题。",content:"golang里面函数时first-class citizen，可以作为值进行参数传递，不管是普通函数“func abc()”，还是成员方法“func (x X) xxx()”，还是一个闭包“func () { return func(){\u0026hellip;.}}”……看上去很方便，不禁要问，golang里面funciton和closure是如何实现的呢？扒拉了下源码，这里简单总结下。\n1 golang中函数内部表示是什么样子的？ # 看下golang cmd/compile/internal/types/type.go中对Func类型的定义：\n// Func contains Type fields specific to func types. type Func struct { Receiver *Type // function receiver，接受者类型，每个函数定义都包括该字段，可以为nil或non-nil Results *Type // function results，返回值类型 Params *Type // function params，参数列表类型 Nname *Node // function name，函数名 // Argwid is the total width of the function receiver, params, and results. // It gets calculated via a temporary TFUNCARGS type. // Note that TFUNC's Width is Widthptr. Argwid int64 Outnamed bool // 是否是可导出的？ }  通过这个Func定义来看，其可以覆盖golang里面所有的函数类型声明了，不管是普通函数，还是成员方法等等。\n2 golang中闭包是怎么实现的？ # 前端时间组内分享闭包使用的时候，觉得这玩意虽然轻巧但是太容易出错了，究其原因是因为不了解闭包的实现原理。那么闭包是如何实现的呢，抽时间扒拉了一下golang中实现闭包的代码，看完后瞬间觉得闭包很简单。\n来简单总结一下，闭包就是函数+环境，问题是这里的环境是如何与函数进行绑定的呢？\n remark: 一开始看了上面的Func类型定义之后，我以为是golang创建了一个虚拟的类型（里面各个字段值为闭包捕获的变量值）然后将该虚拟类型作为receiver-type来实现的呢，可是仔细一想这种思路站不住脚，因为闭包是golang里面的first-class citizen，闭包实现应该非常轻量才对，如果像我最初这种想法那实在是太复杂了，想想要创建多少虚拟类型及其对象吧。\n 看了下源代码，总结一下golang中的实现思路，考虑到闭包对象是否能重复使用，分为两个场景进行处理：\n1) 假如闭包定义后立即被调用 因为只会被使用一次，所以应该力图避免闭包对象的内存分配操作，那怎么优化一下呢，以下面的示例代码为例。\nfunc(a int) { println(byval) byref++ }(42)  上面的闭包将被转换为简单函数调用的形式：\nfunc(byval int, \u0026amp;byref *int, a int) { println(byval) (*\u0026amp;byref)++ }(byval, \u0026amp;byref, 42)  注意看函数原型的变化，原来闭包里面捕获的变量都被转换成了通过函数参数来供值：\n 因为println操作不涉及对byval变量的修改操作，所以是按值捕获； 而byref++涉及到对捕获变量的修改，所以是按引用捕获，对于按引用捕获的变量会进行特殊处理，golang编译器会在编译时将按引用捕获的变量名byref转换成“\u0026amp;byref”，同时将其类型转换成pointer类型，捕获变量对应的写操作也会转换为通过pointer来操作。  2） 假如闭包定以后并不是立即调用 闭包定义后不是立即使用，而是后续调用，这种情况下同一个闭包可能调用多次，这种情况下就需要创建闭包对象，如何实现呢？\n 如果变量是按值捕获，并且该变量占用存储空间小于2*sizeof(int)，那么就通过在函数体内创建局部变量的形式来shadow捕获的变量，相比于通过引用捕获，这么做的好处应该是考虑到减少引用数量、减少逃逸分析相关的计算。 如果变量是按引用捕获，或者按值捕获但是捕获的变量占用存储空间较大（拷贝到本地做局部变量代价太大），这种情况下就将捕获的变量var转换成pointer类型的“\u0026amp;var”，并在函数prologue阶段将其初始化为捕获变量的值。  这部分的代码详见：cmd/compile/gc/closure.go中的方法transformclosure(\u0026hellip;)。 闭包就是函数体+环境，环境就是像这样绑定的。\n3 总结 # 本文简要描述了golang中对函数的内部定义，以及闭包的大致实现思路，加深了理解。\n附：golang闭包处理关键代码 # func transformclosure(xfunc *Node) { lno := lineno lineno = xfunc.Pos func_ := xfunc.Func.Closure if func_.Func.Top\u0026amp;Ecall != 0 { // If the closure is directly called, we transform it to a plain function call // with variables passed as args. This avoids allocation of a closure object. // Here we do only a part of the transformation. Walk of OCALLFUNC(OCLOSURE) // will complete the transformation later. // For illustration, the following closure: //	func(a int) { //	println(byval) //	byref++ //	}(42) // becomes: //	func(byval int, \u0026amp;byref *int, a int) { //	println(byval) //	(*\u0026amp;byref)++ //	}(byval, \u0026amp;byref, 42) // f is ONAME of the actual function. f := xfunc.Func.Nname // We are going to insert captured variables before input args. var params []*types.Field var decls []*Node for _, v := range func_.Func.Cvars.Slice() { if v.Op == OXXX { continue } fld := types.NewField() fld.Funarg = types.FunargParams if v.Name.Byval() { // If v is captured by value, we merely downgrade it to PPARAM. v.SetClass(PPARAM) fld.Nname = asTypesNode(v) } else { // If v of type T is captured by reference, // we introduce function param \u0026amp;v *T // and v remains PAUTOHEAP with \u0026amp;v heapaddr // (accesses will implicitly deref \u0026amp;v). addr := newname(lookup(\u0026quot;\u0026amp;\u0026quot; + v.Sym.Name)) addr.Type = types.NewPtr(v.Type) addr.SetClass(PPARAM) v.Name.Param.Heapaddr = addr fld.Nname = asTypesNode(addr) } fld.Type = asNode(fld.Nname).Type fld.Sym = asNode(fld.Nname).Sym params = append(params, fld) decls = append(decls, asNode(fld.Nname)) } if len(params) \u0026gt; 0 { // Prepend params and decls. f.Type.Params().SetFields(append(params, f.Type.Params().FieldSlice()...)) xfunc.Func.Dcl = append(decls, xfunc.Func.Dcl...) } dowidth(f.Type) xfunc.Type = f.Type // update type of ODCLFUNC } else { // The closure is not called, so it is going to stay as closure. var body []*Node offset := int64(Widthptr) for _, v := range func_.Func.Cvars.Slice() { if v.Op == OXXX { continue } // cv refers to the field inside of closure OSTRUCTLIT. cv := nod(OCLOSUREVAR, nil, nil) cv.Type = v.Type if !v.Name.Byval() { cv.Type = types.NewPtr(v.Type) } offset = Rnd(offset, int64(cv.Type.Align)) cv.Xoffset = offset offset += cv.Type.Width if v.Name.Byval() \u0026amp;\u0026amp; v.Type.Width \u0026lt;= int64(2*Widthptr) { // If it is a small variable captured by value, downgrade it to PAUTO. v.SetClass(PAUTO) xfunc.Func.Dcl = append(xfunc.Func.Dcl, v) body = append(body, nod(OAS, v, cv)) } else { // Declare variable holding addresses taken from closure // and initialize in entry prologue. addr := newname(lookup(\u0026quot;\u0026amp;\u0026quot; + v.Sym.Name)) addr.Type = types.NewPtr(v.Type) addr.SetClass(PAUTO) addr.Name.SetUsed(true) addr.Name.Curfn = xfunc xfunc.Func.Dcl = append(xfunc.Func.Dcl, addr) v.Name.Param.Heapaddr = addr if v.Name.Byval() { cv = nod(OADDR, cv, nil) } body = append(body, nod(OAS, addr, cv)) } } if len(body) \u0026gt; 0 { typecheckslice(body, Etop) walkstmtlist(body) xfunc.Func.Enter.Set(body) xfunc.Func.SetNeedctxt(true) } } lineno = lno }  "}),a.add({id:474,href:"/tags/chann/",title:"chann",description:"",content:""}),a.add({id:475,href:"/blog/2018-05-19-golang-select-case%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/",title:"golang select-case 实现机制",description:"golang chan select-case设计实现",content:"1 chan操作规则 # 在介绍select-case实现机制之前，最好先了解下chan操作规则，明白goroutine何时阻塞，又在什么时机被唤醒，这对后续理解select-case实现有帮助。所以接下来先介绍chan操作规则，然后再介绍select-case的实现。\n1.1 chan操作规则1 # 当一个goroutine要从一个non-nil \u0026amp; non-closed chan上接收数据时，goroutine首先会去获取chan上的锁，然后执行如下操作直到某个条件被满足：\n1）如果chan上的value buffer不空，这也意味着chan上的recv goroutine queue也一定是空的，该接收goroutine将从value buffer中unshift出一个value。这个时候，如果send goroutine队列不空的情况下，因为刚才value buffer中空出了一个位置，有位置可写，所以这个时候会从send goroutine queue中unshift出一个发送goroutine并让其恢复执行，让其执行把数据写入chan的操作，实际上是恢复该发送该goroutine执行，并把该发送goroutine要发送的数据push到value buffer中。然后呢，该接收goroutine也拿到了数据了，就继续执行。这种情景，channel的接收操作称为non-blocking操作。\n2）另一种情况，如果value buffer是空的，但是send goroutine queue不空，这种情况下，该chan一定是unbufferred chan，不然value buffer肯定有数据嘛，这个时候接收goroutine将从send goroutine queue中unshift出一个发送goroutine，并将该发送goroutine要发送的数据接收过来（两个goroutine一个有发送数据地址，一个有接收数据地址，拷贝过来就ok），然后这个取出的发送goroutine将恢复执行，这个接收goroutine也可以继续执行。这种情况下，chan接收操作也是non-blocking操作。\n3）另一种情况，如果value buffer和send goroutine queue都是空的，没有数据可接收，将把该接收goroutine push到chan的recv goroutine queue，该接收goroutine将转入blocking状态，什么时候恢复期执行呢，要等到有一个goroutine尝试向chan发送数据的时候了。这种场景下，chan接收操作是blocking操作。\n1.2 chan操作规则2 # 当一个goroutine常识向一个non-nil \u0026amp; non-closed chan发送数据的时候，该goroutine将先尝试获取chan上的锁，然后执行如下操作直到满足其中一种情况。\n1）如果chan的recv goroutine queue不空，这种情况下，value buffer一定是空的。发送goroutine将从recv goroutine queue中unshift出一个recv goroutine，然后直接将自己要发送的数据拷贝到该recv goroutine的接收地址处，然后恢复该recv goroutine的运行，当前发送goroutine也继续执行。这种情况下，chan send操作是non-blocking操作。\n2）如果chan的recv goroutine queue是空的，并且value buffer不满，这种情况下，send goroutine queue一定是空的，因为value buffer不满发送goroutine可以发送完成不可能会阻塞。该发送goroutine将要发送的数据push到value buffer中然后继续执行。这种情况下，chan send操作是non-blocking操作。\n3）如果chan的recv goroutine queue是空的，并且value buffer是满的，发送goroutine将被push到send goroutine queue中进入阻塞状态。等到有其他goroutine尝试从chan接收数据的时候才能将其唤醒恢复执行。这种情况下，chan send操作是blocking操作。\n1.3 chan操作规则3 # 当一个goroutine尝试close一个non-nil \u0026amp; non-closed chan的时候，close操作将依次执行如下操作。\n1）如果chan的recv goroutine queue不空，这种情况下value buffer一定是空的，因为如果value buffer如果不空，一定会继续unshift recv goroutine queue中的goroutine接收数据，直到value buffer为空（这里可以看下chan send操作，chan send写入数据之前，一定会从recv goroutine queue中unshift出一个recv goroutine）。recv goroutine queue里面所有的goroutine将一个个unshift出来并返回一个val=0值和sentBeforeClosed=false。\n2）如果chan的send goroutine queue不空，所有的goroutine将被依次取出并生成一个panic for closing a close chan。在这close之前发送到chan的数据仍然在chan的value buffer中存着。\n1.4 chan操作规则4 # 一旦chan被关闭了，chan recv操作就永远也不会阻塞，chan的value buffer中在close之前写入的数据仍然存在。一旦value buffer中close之前写入的数据都被取出之后，后续的接收操作将会返回val=0和sentBeforeClosed=true。\n1.5 小结 # 理解这里的goroutine的blocking、non-blocking操作对于理解针对chan的select-case操作是很有帮助的。下面介绍select-case实现机制。\n2 select-case实现 # 2.1 select-case原理简述 # select-case中假如没有default分支的话，一定要等到某个case分支满足条件然后将对应的goroutine唤醒恢复执行才可以继续执行，否则代码就会阻塞在这里，即将当前goroutine push到各个case分支对应的ch的recv或者send goroutine queue中，对同一个chan也可能将当前goroutine同时push到recv、send goroutine queue这两个队列中。\n不管是普通的chan send、recv操作，还是select chan send、recv操作，因为chan操作阻塞的goroutine都是依靠其他goroutine对chan的send、recv操作来唤醒的。前面我们已经讲过了goroutine被唤醒的时机，这里还要再细分一下。\nchan的send、recv goroutine queue中存储的其实是一个结构体指针*sudog，成员gp *g指向对应的goroutine，elem unsafe.Pointer指向待读写的变量地址，c *hchan指向goroutine阻塞在哪个chan上，isSelect为true表示select chan send、recv，反之表示chan send、recv。g.selectDone表示select操作是否处理完成，即是否有某个case分支已经成立。\n2 select-case执行流程 # 2.1 chan操作阻塞的goroutine唤醒时执行逻辑 # 下面我们先描述下chan上某个goroutine被唤醒时的处理逻辑，假如现在有个goroutine因为select chan 操作阻塞在了ch1、ch2上，那么会创建对应的sudog对象，并将对应的指针*sudog push到各个case分支对应的ch1、ch2上的send、recv goroutine queue中，等待其他协程执行(select) chan send、recv操作时将其唤醒： 1）源码文件chan.go，假如现在有另外一个goroutine对ch1进行了操作，然后对ch1的goroutine执行unshift操作取出一个阻塞的goroutine，在unshift时要执行方法 **func (q waitq) dequeue() sudog，这个方法从ch1的等待队列中返回一个阻塞的goroutine。\nfunc (q *waitq) dequeue() *sudog { for { sgp := q.first if sgp == nil { return nil } y := sgp.next if y == nil { q.first = nil q.last = nil } else { y.prev = nil q.first = y sgp.next = nil // mark as removed (see dequeueSudog) } // if a goroutine was put on this queue because of a // select, there is a small window between the goroutine // being woken up by a different case and it grabbing the // channel locks. Once it has the lock // it removes itself from the queue, so we won't see it after that. // We use a flag in the G struct to tell us when someone // else has won the race to signal this goroutine but the goroutine // hasn't removed itself from the queue yet. if sgp.isSelect { if !atomic.Cas(\u0026amp;sgp.g.selectDone, 0, 1) { continue } } return sgp } }  假如队首元素就是之前阻塞的goroutine，那么检测到其sgp.isSelect=true，就知道这是一个因为select chan send、recv阻塞的goroutine，然后通过CAS操作将sgp.g.selectDone设为true标识当前goroutine的select操作已经处理完成，之后就可以将该goroutine返回用于从value buffer读或者向value buffer写数据了，或者直接与唤醒它的goroutine交换数据，然后该阻塞的goroutine就可以恢复执行了。\n这里将sgp.g.selectDone设为true，相当于传达了该sgp.g已经从刚才阻塞它的select-case块中退出了，对应的select-case块可以作废了。有必要提提一下为什么要把这里的sgp.g.selectDone设为true呢？直接将该goroutine出队不就完了吗？不行！考虑以下对chan的操作dequeue是需要先拿到chan上的lock的，但是在尝试lock chan之前有可能同时有多个case分支对应的chan准备就绪。看个示例代码：\n// g1 go func() { ch1 \u0026lt;- 1\u2028}() // g2 go func() { ch2 \u0026lt;- 2 } select { case \u0026lt;- ch1: doSomething() case \u0026lt;- ch2: doSomething() }  协程g1在 chan.chansend方法中执行了一般，准备lock ch1，协程g2也执行了一半，也准备lock ch2; 协程g1成功lock ch1执行dequeue操作，协程g2页成功lock ch2执行deq	ueue操作； 因为同一个select-case块中只能有一个case分支允许激活，所以在协程g里面加了个成员g.selectDone来标识该协程对应的select-case是否已经成功执行结束（一个协程在某个时刻只可能有一个select-case块在处理，要么阻塞没执行完，要么立即执行完），因此dequeue时要通过CAS操作来更新g.selectDone的值，更新成功者完成出队操作激活case分支，CAS失败的则认为该select-case已经有其他分支被激活，当前case分支作废，select-case结束。\n这里的CAS操作也就是说的多个分支满足条件时，golang会随机选择一个分支执行的道理。\n2.2 select-case块golang是如何执行处理的 # 源文件select.go中方法 *selectgo(sel hselect) ，实现了对select-case块的处理逻辑，但是由于代码篇幅较长，这里不再复制粘贴代码，感兴趣的可以自己查看，这里只简要描述下其执行流程。\nselectgo逻辑处理简述：\n 预处理部分 对各个case分支按照ch地址排序，保证后续按序加锁，避免产生死锁问题； pass 1 部分处理各个case分支的判断逻辑，依次检查各个case分支是否有立即可满足ch读写操作的。如果当前分支有则立即执行ch读写并回，select处理结束；没有则继续处理下一分支；如果所有分支均不满足继续执行以下流程。 pass 2 没有一个case分支上chan操作立即可就绪，当前goroutine需要阻塞，遍历所有的case分支，分别构建goroutine对应的sudog并push到case分支对应chan的对应goroutine queue中。然后gopark挂起当前goroutine，等待某个分支上chan操作完成来唤醒当前goroutine。怎么被唤醒呢？前面提到了chan.waitq.dequeue()方法中通过CAS将sudog.g.selectDone设为1之后将该sudog返回并恢复执行，其实也就是借助这个操作来唤醒。 pass 3 整个select-case块已经结束使命，之前阻塞的goroutine已被唤醒，其他case分支没什么作用了，需要废弃掉，pass 3部分会将该goroutine从之前阻塞它的select-case块中各case分支对应的chan recv、send goroutine queue中移除，通过方法chan.waitq.dequeueSudog(sgp *sudog)来从队列中移除，队列是双向链表，通过sudog.prev和sudog.next删除sudog时间复杂度为O(1)。  3 总结 # 本文简要描述了golang中select-case的实现逻辑，介绍了goroutine与chan操作之间的协作关系。之前ZMQ作者Martin Sustrik仿着golang写过一个面向c的库，libmill，实际实现思路差不多，感兴趣的也可以翻翻看，libmill源码分析。\n"}),a.add({id:476,href:"/tags/chrome/",title:"chrome",description:"",content:""}),a.add({id:477,href:"/blog/2018-03-02-chrome%E5%88%86%E5%B1%8F%E9%98%85%E8%AF%BB%E6%8F%92%E4%BB%B6pagesplit/",title:"chrome分屏阅读插件：pagesplit",description:"chrome优秀的扩展性使得它成为很多开发人员的首选浏览器，不少开发人员在使用Vim或者IDE阅读源码时，都存在vsplit/hsplit分屏的习惯，那么在通过浏览器浏览网络上的代码或者页面时，如何在浏览器页面中实现类似Vim的分屏功能呢？本文结合作者的个人项目pagesplit来介绍下如何开发一个chrome分屏阅读插件。",content:" img { width: 680px; padding-bottom: 1rem; }  前言 # 这几天在钻研golang，经常在网上看些源码分析的文章，既然是源码分析就少不了code和分析的各种穿插描述，文章篇幅一长或者code block块比较长，经常需要滚动鼠标上下翻页，这种阅读体验好差劲。心想要是能够将web页面进行类似于vim的vsplit或者lsplit就好了。于是就有了这个chrome扩展。\n产品调研 # chrome网上应用商店中搜索了一下，找到了几个类似功能的插件“split tabs”、“tab resize”，体验之后不太满足个人需要。原因是：这两个扩展都是通过创建一个新的浏览器窗口来打开当前web页面，然后并排显示（支持水平、垂直并排显示），如下图。 这种实现方式，实际使用时存在如下几个缺点：\n  工作中，我们打开的应用程序窗口可能会很多，比如rtx，各种ide，各种终端……这样alt+tab切几次之后就难受了，需要手动将两个浏览器窗口给选择出来并排显示。不好用！\n  工作中，可能工作用的web标签页有很多，各种运维平台，各种视图，各种管理后台……如果在浏览器窗口中选择了其他的tab，再次切换回之前的tab比较困难，也不容易回到初始的并排显示状态。不好用！\n  解决方案 # 个人感觉还是同一个tab下能够vsplit、split比较方便，chrome网上应用商店找不到合适的了，google了一下，找到另一款扩展：\u0026ldquo;Frame two pages\u0026rdquo;，这个插件在功能上能满足需要，能够实现同一个tab下vsplit、split，如下图所示：\n但是其在使用时比较繁琐，当我们打开一个web页面，希望对其进行vsplit操作时，页面会弹出一个提示窗口，输入split方式，然后会执行对应的分割方式，看上去不错，但是有几个问题让人用起来很难受：\n 没有考虑浏览器的X-Frame-Options对iframe的影响，使用过程中会“莫名其妙”地split失败，比如我正在写这篇文章，来测试一下vsplit什么效果，如下图，并没有成功vsplit；   不实用，如果选择的tab索引index大于0，会将index-1和index进行并排展示，至少与我的页面分割的初衷不一致；  于是乎，我想改进下这个插件为我所用，说不定也可以方便大家，本着不重复造轮子的原则，安装上了这个Frame two pages扩展看了下它的代码，了解了chrome扩展的大致写法，然后对其进行了一些修改，基本符合我的功能性要求。\n设计实现 # 现在实现的功能包括：\n1）点击插件按钮，选择split方式，支持对当前已经打开的web页面进行split、vsplit分割。\n以垂直分割当前web页面为例，首先点击扩展图标，选择分割方式为vertical分割。\n就得到了如下效果的分割页面，这个页面是在原页面tab之后创建的一个tab，不影响原来的tab。\n2）忽略所有页面的X-Frame-Options选项，保证可以打开页面（为了安全使用者自己决定用不用吧），为了使用方便我我忽略掉了所有的X-Frame-Options，使得iframe可以正常加载。\n3）某些情况下可能希望分割的两部分分别展示不同的页面，也是支持的，需要在一个空白的tab页上点击页面分割，此时会展示出如下输入url的输入框，然后点击下方的按钮就可以了。\n比如一个进百度，一个进google。\n4）我觉得存在这样的使用情景，比如正在看一个博客时，希望打开搜索引擎检索部分信息，一般我们都是打开一个新的标签页进搜索引擎，看完搜索结果后再跳回原来的tab……阅读期间可能要多次跳来跳去……希望能在已经成功vsplit、split的页面里面，将其中一个reset允许我们重新输入url打开新的页面。\n于是为这个插件加了菜单：\n以重置vsplit后的左半部分页面为例，选择“Split Page -\u0026gt; Reset left/top page”。\n左半部分就被重置到重新输入url的状态了，比如希望进入google，输入google网址，点击跳转按钮即可。\n总结 # 简要了解了chrome extension的开发过程，chrome不同的版本迭代过程中增加了很多安全限制，开发、调试过程中要多注意。这只是为了平时阅读代码方便二次开发的一个小工具，另外对js了解的不多，可能存在bug，也欢迎反馈。\n感兴趣的可以从github下载进行体验，仓库地址：https://github.com/hitzhangjie/PageSplit。\n"}),a.add({id:478,href:"/tags/extension/",title:"extension",description:"",content:""}),a.add({id:479,href:"/tags/hsplit/",title:"hsplit",description:"",content:""}),a.add({id:480,href:"/tags/pagesplit/",title:"pagesplit",description:"",content:""}),a.add({id:481,href:"/tags/vsplit/",title:"vsplit",description:"",content:""}),a.add({id:482,href:"/blog/2017-10-14-assembly-language/",title:"Assembly Language",description:"现在高级语言这么方便、编译器这么牛，还需要掌握汇编语言吗？我认为需要，至少要能看懂，有些对性能要求很高、希望调优的场景下，可能要直接用汇编来实现，如字符串拷贝，等等。而且高级语言借助系统调用的方式，有时也存在局限性，比如有需要开关中断的场景，就必须要借助内联汇编。所以掌握汇编至少不是一件坏事。",content:"处理器是算逻运算、控制操作的执行部件，它只能识别机器指令并执行动作。机器指令是一系列的0、1字符串，本质上对应了总线上的高低电平信号，所以机器语言都是特定于硬件的。\n由于0、1字符串很难记忆，用机器语言开发是一个老大难的问题，汇编语言因此被开发出来用于代替机器语言。汇编指令只是机器指令中操作码的助记符，因此汇编语言仍然是机器强相关的，不同的处理器其对应的汇编指令也不同。\n学习汇编语言有助于理解：\n 程序是如何与操作系统、处理器、bios进行交互的； 数据如何在内存中以及外设中表示的； 处理器如何访问、执行指令； 指令如何访问、处理数据； 程序如何访问外设；  其他使用汇编语言的优势：\n 消耗更少的内存和处理器执行时间； 允许以更简单的方式来完成硬件特定的复杂作业； 适用于时间敏感的作业； 适用于编写中断服务程序和内存驻留程序；  1.1 PC硬件的基本特征 # 机器指令是0、1字符串，分别表示ON、OFF，对应数字信号的高低电平。机器中的最低存储单位是bit，通常8bit构成一个byte，为了对数据传输过程中传输数据的有效性进行检查，通常会在数据byte发送之后再追加一个奇偶校验bit。\n 奇校验：保证8bit数据+1bit校验位中的1的个数为奇数； 偶校验：保证8bit数据+1bit校验位中的1的个数为偶数；  发送方、接收方遵循相同的奇偶校验规则，如果接收方收到数据后发现奇偶校验不正确，则表示可能硬件出错，或者出现了电平扰动。\n处理器支持如下数据尺寸：\n|:\u0026mdash;|:\u0026mdash;\u0026mdash;| |Word|2 bytes| |Doubleword|4 bytes| |Quadword|8 bytes| |Paragraph|16 bytes| |Kilobyte|2^10 bytes| |Megabyte|2^20 bytes|\n二进制 \u0026amp; 十六进制系统：\n二进制天然适用于计算机计算领域，0、1刚好代表数字电路中的高低电平；而十六进制是用于对比较长的二进制数值进行更加优雅地简写，使我们表示起来更加清晰、简单。\n二进制、十六进制的相关运算，特别是涉及到原码、反码、补码、移码的运算，需要重点了解下，建议参考《计算机组成原理》相关章节。\n访问内存中的数据：\n处理器控制指令执行的过程可以简化为”取指令-指令移码-指令执行“的循环体，一个”取指令-指令译码-指令执行“周期称之为一个机器周期。\n 取指周期：根据CS、IP从内存指定位置取指令，并存储到指令寄存器IR； 译码周期：根据IR中的指令，分析出操作码OP、操作数或操作数地址； 执行周期：根据分析出的OP、操作数或操作地址信息执行相应的动作；  Intel架构的处理器在内存中存储时是采用的小端字节序，意味着一个多字节数值的低字节部分将在低地址存储，高字节部分将在高地址存储，但是在处理器寄存器中存储时低字节部分就在低字节，高字节部分就在高字节，所以在处理器寄存器、内存之间存储、加载数据时需要做字节序方面的转换。\n以处理器寄存器中数值0x1234为例，现在要将其存储到内存中，处理器先将0x34存储到内存低地址，然后再见0x12存储到内存高地址；假如内存中有数据0xabcd，现在要将其加载到处理器寄存器中，加载时也会做对应的处理，将0xab放在寄存器高位，将0xcd放在寄存器低位。\n指令中的操作数地址，又有多种不同的寻址方式，立即数寻址、直接寻址、间接寻址、寄存器寻址等，这里后面会做相应的介绍。\n1.2 开发环境配置 # 汇编指令特定于处理器的，因此不同的处理器系列、型号对应的汇编指令可能也会有差异，这里使用的是Intel-32架构的处理器，使用汇编器NASM进行汇编操作，其他可选的汇编器还有MASM、TASM、GAS等。\n1.3 基本语法 # 汇编程序通常包括3个节，分别是data、bss、text节：\n data，用于声明初始化的变量和常量； bss，用于声明未初始化的变量，这部分不会出现在编译后的程序中； text，用于保存程序指令；  text节中必须包括\u0026quot;global ${entry}\u0026ldquo;声明，${entry}是程序入口，通常定义未_start，见文生义嘛。\n汇编程序中的注释均以\u0026rdquo;;\u0026ldquo;开头，直到所在行结束。\n汇编语言程序包括3种不同类型的语句：\n 可执行汇编指令； 传递给汇编器的指令或伪操作； 宏；  汇编语言语句遵循如下结构：\n[标识] 助记符 [操作数] [;注释]   []内部的部分是可选的，尤其是标识和注释部分，根据汇编指令的不同，有无操作数、操作数个数、操作数类型等均有所不同。汇编指令中包括了操作码和操作数相关信息，这里的助记符其实就是操作码的符号表示。\n 下面是应用了上述基本语法的示例程序：\nhello.asm\nsection	.text global _start ;must be declared for linker (ld) _start:	;tells linker entry point mov	edx,len ;message length mov	ecx,msg ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data msg db 'Hello, world!', 0xa ;string to be printed len equ $ - msg ;length of the string  在Linux平台下由汇编文件构建可执行程序包括如下两个步骤：\n 汇编，nasm -f elf -o hello.o hello.asm 连接，ld -m elf_i386 -e _start -o hello hello.o  构建完成，即可在命令行执行./hello来进行测试。\n1.4 内存分段 # 前面一节介绍了汇编语言中的section（节），这些节也代表着各种各样的内存segment（段）。将前面示例代码hello.asm中的section关键字用segment代替，依然可以用相同的方法构建成功并得到相同的测试结果。\n汇编语言中常见的segment（段）包括：\n data segment，数据段代表了data section和bss section。其中data section用于存储初始化后的全局变量和全局变量；bss section用于声明未初始化的全局变量和静态变量，在程序运行时会被初始化未0值。 code segment，代码段也就是text节，用于存储程序指令； stack segment，堆栈段用于分配临时变量、调用函数时传递参数信息等；  1.5 寄存器 # 处理器主要是用来进行计算，计算所需要的数据来自于内存，但是处理器存取内存数据需要的时间比较长，为了ALU加速存取操作数，处理器里面内置了寄存器，将内存中的数据先加载到寄存器中，然后ALU对寄存器中的数据进行计算，最后再将计算结果搬回内存。\n处理器中的寄存器主要包括如下几类：\n 通用目的寄存器，包括数据寄存器（EAX、EBX、ECX、EDX）、指针寄存器（EIP、ESP、EBP）、索引寄存器（ESI、EDI）；   函数调用过程中会形成栈帧，ebp寄存器指向的是栈帧的栈底，esp指向的值栈帧的栈顶。通过ebp便于定位传递给函数的参数、返回地址信息，栈帧开始构建的时候，首先就会将caller的ebp压栈，然后将当前栈帧栈顶esp赋值给ebp作为新的栈帧的栈底，后面esp减去一个值N,[esp-N,ebp）就是新的栈空间。\n  段寄存器，包括ECS、ESS、EDS；   8086里面，CS包括代码段的起始地址，从80386进入保护模式开始，CS里面变成了段选择符，具体的代码段起始地址要到gdb里面去查。DS存储数据段的起始地址，SS存储堆栈段的起始地址。\n  控制寄存器，32位flags寄存器和32位指令指针寄存器共同称为控制寄存器。   常见的flag标志位包括：OF（溢出）、DF（字符串比较方向）、IF（是否允许中断）、TF（是否单步执行）、SF（符号位）、ZF（比较结果）、AF（辅助进位）、PF（1数量是否为奇数）、CF（是否进位）。\n 下面是一个使用多个寄存器的示例程序：\nsection	.text global _start	;must be declared for linker (gcc) _start:	;tell linker entry point mov	edx,len ;message length mov	ecx,msg ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	edx,9 ;message length mov	ecx,s2 ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data msg db 'Displaying 9 stars',0xa ;a message len equ $ - msg ;length of message s2 times 9 db '*'  1.6 系统调用 # 系统调用是操作系统内核提供的用户态、内核态之间的接口，用户态通过系统调用访问内核服务。\n如何通过在汇编程序里面使用系统调用呢？\n 在EAX寄存器里面设置系统调用号； 在EBX、ECX、EDX、ESI、EDI、EBP中设置系统调用参数（如果参数数量超过6个，则需特殊处理）； 调用中断服务int 0x80（系统调用都是通过中断服务的形式实现，int指令使得处理器从ring3切换到ring0，iret使处理器从ring0切换回ring3）； 系统调用的返回值通常保存在EAX中；  Linux下的系统调用定义在/usr/include/asm/unistd.h中，可以从中查看系统调用名称以及编号。下面是一个综合使用系统调用read、write、exit的例子，程序提示用户输入一个数字并读取用户输入，然后回显该数字。\nsection .data ;Data segment userMsg db 'Please enter a number: ' ;Ask the user to enter a number lenUserMsg equ $-userMsg ;The length of the message dispMsg db 'You have entered: ' lenDispMsg equ $-dispMsg section .bss ;Uninitialized data num resb 5 section .text ;Code Segment global _start _start: ;User prompt mov eax, 4 mov ebx, 1 mov ecx, userMsg mov edx, lenUserMsg int 80h ;Read and store the user input mov eax, 3 mov ebx, 2 mov ecx, num mov edx, 5 ;5 bytes (numeric, 1 for sign) of that information int 80h ;Output the message 'The entered number is: ' mov eax, 4 mov ebx, 1 mov ecx, dispMsg mov edx, lenDispMsg int 80h ;Output the number entered mov eax, 4 mov ebx, 1 mov ecx, num mov edx, 5 int 80h ; Exit code mov eax, 1 mov ebx, 0 int 80h  1.7 寻址模式 # 汇编语言中的寻址模式可以分为两类，一类是指令寻址，一类是数据寻址：\n 指令寻址：处理器要执行的指令如何寻址，分为顺序寻址（顺序执行，pc+=1）、跳跃寻址（jmp）； 数据寻址：根据数据所在存储位置的不同（内存或寄存器），以及地址提供方式的不同，数据寻址方式多种多样。  数据寻址方式虽然多样，但是都遵从如下指令格式：\n|:\u0026ndash;:|:\u0026ndash;:|:\u0026ndash;:| |操作码OP|寻址特征|形式地址A|\n根据寻址特征以及形式地址A，可以计算出操作数的有效地址EA，不同的寻址特征对形式地址A施加的计算规则也不一样。下面总结一下常见的数据寻址方式。\n 立即寻址，A是立即数（常量），EA=A； 寄存器寻址，A是寄存器编号，EA=A=Ri； 直接内存寻址，A为数据在内存中的有效地址，即EA=A； 直接内存偏移量寻址，类似于基址寻址方式，EBX做基地址，A为offset； 间接内存寻址，(A)为数据在内存中的有效地址，即EA=(A),间接内存寻址可能还会涉及到多重间址；   计算机组成原理中可能提到的数据寻址方式更加偏重于理论，寻址方式也更加多样，实际的汇编语言实现中可能并没有逐一实现，或者区分不明显，我们这里从实践出发，更加侧重于实用而不是理论，因此在使用术语的选择上也更加偏重于业内人员的偏好。\n 在汇编语言中，获取一个内存变量的有效地址的方式是：[varname]。\n下面是一个综合使用了上述多种寻址方式的示例程序：\nsection	.text global_start ;must be declared for linker (ld) _start: ;tell linker entry point ;writing the name 'Zara Ali' mov	edx,9 ;message length mov	ecx, name ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	[name], dword 'Nuha' ; Changed the name to Nuha Ali ;writing the name 'Nuha Ali' mov	edx,8 ;message length mov	ecx,name ;message to write mov	ebx,1 ;file descriptor (stdout) mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data name db 'Zara Ali '  1.8 定义变量 # 汇编语言中提供了多个汇编器指令用于定义变量、预留内存空间。\nsection .data，为初始化的数据分配存储空间:\nvarname define-directive initial-value[,initial-value2]  常用的define-directive包括DB、DW、DD、DQ、DT，分别用于定义1byte、1word、1doubleword、1quadword、10bytesd并进行初始化操作。\nsection .bss，为未初始化的数据分配存储空间：\n[varname] reserve-directive quantity  常用的reserve-directie指令包括RESB、RESW、RESD、RESQ、REST，分别用于分配1byte、1word、1doubleword、1quadword、10bytes的存储空间，结合操作数quantity可以计算出需要分配多少空间。\n.bss节每一个对应的define-directive语句都有一个对应的reserve-directive与之对应，reserve-directive也可以单独存在，如下所示：\nsection .bss age db resb 1 ;只预留空间没关联变量 num resb 1 ;预留空间并绑定变量  times directive允许多个变量初始化为相同的值：\nvarname times quantity define-directive [intiail-val]  注意times指令也可以用于.bss节，但是.bss节汇编的时候不会进行初始化，程序启动的时候才会进行0初始化。\n 如果没有提供initial-val，会提示没有初始值不进行初始化； 如果提供了intiail-val，会提示.bss节忽略了初始值不进行初始化操作；  1.9 定义常量 # 汇编语言中定义常量的指令包括3个，分别是EQU、%assign、%define。\nconst-name EQU value ;可以定义字符串或者数值常量 %assign const-name value ;只可以定义数值常量，可以重定义 %define const-name value ;可以定义字符串或者数值常量  前面曾多次使用EQU进行常量定义，这里就不再提供其他示例程序了。\n1.10 算术指令 # 汇编语言中的算术运算指令包括：\n INC、DEC，自增、自减一个寄存器或者内存变量的值，结果保存到当前操作数； ADD、SUB，加、减一个寄存器或者内存变量的值，结果保存到第一个操作数； MUL、IMUL，分别处理无符号、有符号数的乘法，保存存储遵循如下规则：  8位乘法，如：AL * 8bit_source = AH AL，结果高8位保存到AH、低8位保存到AL； 16位乘法，如：AX * 16bit_source = DX AX，结果高16位保存到DX，低16位保存到AX； 32位乘法，如：EAX * 32bit_source = EDX EAX，结果高32位保存到EDX，低32位保存到EAX；   DIV、IDIV，分别处理无符号、有符号数的除法，结果存储遵循如下规则：  16位除法，如：AX / 8bit_source = AL\u0026hellip;AH，商保存到AL，余数保存到AH； 32位除法，如：DX AX / 16bit_source = AX\u0026hellip;DX，被除数高16位在DX、低16位在AX，结果商在AX、余数在DX； 64位除法，如：EDX EAX / 32bit_source = EAX\u0026hellip;EDX，被除数高32位在EAX、低32位在EAX，结果商在EAX、余数在EDX；    1.11 逻辑指令 # 汇编语言中的逻辑运算指令包括：\n AND，逻辑与运算，结果保存到第一个操作数； OR，逻辑或运算，结果保存到第一个操作数； NOT，对当前操作数求反，结果保存到当前操作数； XOR，异或运算，结果保存到第一个操作数； TEST，测试运算，不会改变操作数的值，但运算会影响ZF标识；  1.12 分支控制 # 通过某些循环、分支指令可以实现分支语句，这里对应的汇编指令主要都是基于处理器中的标识寄存器来实现的。\n常用指令包括：\n 比较指令\nCMP，比较两个操作数是否相同、谁大谁小，需结合其他条件转移指令使用； 无条件转移指令\nJMP，无条件跳转到制定的指令地址处执行； 条件转移指令 有符号数、无符号数通用的包括：JE/JZ，JNE/JNZ； 无符号数特有的包括：JG、JGE、JL、JLE等； 有符号数特有的包括：JA、JAE、JB、JBE等； 特殊用途的包括：JC、JNC、JO、JNO、JS、JNS等；  这里涉及到的条件转移指令比较多，这里不一一进行描述了，有需要的话读者朋友可以参考”分支控制指令“，或者可以参考intel指令集了解更多的细节。\n1.13 循环控制 # 借助条件转移指令实现循环\n条件转移指令可以用于实现循环控制，循环控制次数可以存储在ECX寄存器中，循环体内动作每执行一次将ECX值减1，根据ECX值是否为0决定是否进行循环。下面就是一个根据这个简单思路实现的循环体：\nMOV	CL, 10 L1: \u0026lt;LOOP-BODY\u0026gt; DEC	CL JNZ	L1  借助内置的loop指令实现循环\n汇编语言内部提供了指令loop来实现循环，起实现方式跟我们上面说的是一样的，loop指令会检查当前ECX寄存器的值是否为0，为0则退出循环，大于0则执行DEC ECX并继续执行循环体。\n下面是一个借助loop指令实现的循环体版本，书写上也更加简练：\nMOV	CL, 10 L1: \u0026lt;LOOP-BODY\u0026gt; loop L1  1.14 数字 # 前面我们读入一个数位数值的时候需要将其减去'0\u0026rsquo;之后得到其真实数值，运算结果写出之前也需要将数位数值加上'0\u0026rsquo;再写出，为啥？这里涉及到ASCII码与数值之间的转换。\n上述处理方式虽然比较直观，但是负载比较大，汇编语言中有更加高效的处理方式，即以二进制形式对其进行处理。\n十进制数字有两种表示形式：\n ASCII码形式\n输入的十进制数字每个数位都用ASCII来表示，十进制数字1234的4个数位分别被编码为对应的ASCII码字符，各个字符对应的十进制值分别为：31 32 33 34，共占用了4个字节； BCD码形式  如果是unpacked BCD编码形式，输入的十进制数字每个数位都用1字节的二进制形式来表示，十进制数字1234的4个数位分别被编码为：01 02 03 04，共占用4个字节。 如果是packed BCD编码形式，输入的十进制数字每个数位用4bit来表示，十进制数字1234的4个数位被编码为：12 34，共占用2个字节。    运算完成之后，可能会涉及到某些ASCII、BCD码之间的转换动作，可以借助于对应的汇编调整指令来实现。\n1.15 字符串 # 计算字符串长度\n前面我们指定一个字符串的长度的时候，可以通过变量来显示地指明，也可以通过**”$-msg“**来计算出来，使用后者的时候我们需要为msg字符串尾部添加一个哨兵字符，例如：\nmsg db 'hello world',0xa len db $-msg  $代表的是当前的offset，offset-db正好是msg中字符的数量，不包括0xa，如果不添加0xa这个字符哨兵的话，len就应该定义成**\u0026quot;$-msg+1\u0026rdquo;**。\n字符串操作指令：\n MOVS，移动一个字符串； LODS，从内存中装载字符串； STOS，存储字符串到内存； CMPS，比较字符串； SCAS，比较寄存器和内存中的字符串； REP/REPZ/REPNZ，便利字符串并针对各个字符重复执行某个操作；  1.16 数组 # 定义数组，主要有如下几种方式，我们以定义一个byte数组为例分别说明。\n定义数组方式一：\nnumbers db 0,1,2,3,4,5  定义数组方式二：\nnumbers db 0 db 1 db 2 db 3 db 4 db 5  这种方式应该比较少用，方式一其实是这种方式的简化版。\n定义数组方式三：\nnumbers times 6 db 0  这种方式定义的6个byte都被初始化为相同的值0。\n还是要根据自己的需要来选择合适的数组定义方式。\n下面示例程序定义了一个数组byte数组x，然后以循环的形式遍历x中的元素并求和：\nsection	.text global _start ;must be declared for linker (ld) _start:	mov eax,3 ;number bytes to be summed mov ebx,0 ;EBX will store the sum mov ecx, x ;ECX will point to the current element to be summed top: add ebx, [ecx] add ecx,1 ;move pointer to next element dec eax ;decrement counter jnz top ;if counter not 0, then loop again done: add ebx, '0' mov [sum], ebx ;done, store result in \u0026quot;sum\u0026quot; display: mov edx,1 ;message length mov ecx, sum ;message to write mov ebx, 1 ;file descriptor (stdout) mov eax, 4 ;system call number (sys_write) int 0x80 ;call kernel mov eax, 1 ;system call number (sys_exit) int 0x80 ;call kernel section	.data global x x: db 2 db 4 db 3 sum: db 0  1.17 函数 # 汇编语言中函数是非常重要的一个组成部分，定义函数的语法如下：\nfunction_name: \u0026lt;function_body\u0026gt; ret  程序中调用一个函数的指令为call：\ncall \u0026lt;function_name\u0026gt;  下面示例代码总定义了一个求和函数：\nsection	.text global _start ;must be declared for using gcc _start:	;tell linker entry point mov	ecx,'4' sub ecx, '0' mov edx, '5' sub edx, '0' call sum ;call sum procedure mov [res], eax mov	ecx, msg	mov	edx, len mov	ebx,1	;file descriptor (stdout) mov	eax,4	;system call number (sys_write) int	0x80	;call kernel mov	ecx, res mov	edx, 1 mov	ebx, 1	;file descriptor (stdout) mov	eax, 4	;system call number (sys_write) int	0x80	;call kernel mov	eax,1	;system call number (sys_exit) int	0x80	;call kernel sum: mov eax, ecx add eax, edx add eax, '0' ret section .data msg db \u0026quot;The sum is:\u0026quot;, 0xA,0xD len equ $- msg segment .bss res resb 1  栈stack，是一种后进先出LIFO的数据结构，汇编语言提供了指令push、pop来进行入栈、出栈操作。\n1.18 递归 # 递归操作，指的是一个函数func在执行过程中会调用这个函数自身的情况。递归又可以细分为直接递归和间接递归。\n 直接递归，函数func的函数体中会调用自身； 间接递归，函数func的函数体中调用了其他的函数，而这个被调用的函数中又调用了函数func；  有些问题适合用递归算法来解决，递归比较容易理解，但是对栈空间消耗可能会超出系统允许的上限导致栈溢出问题，此时需要将递归算法转换为非递归算法。\n1.19 宏 # 汇编语言中可以将常用的、可能多次重复使用的指令序列以宏macro的形式进行封装，在程序中可以多次调用。\n定义宏的形式为：\n%macro macro_name params_quantity \u0026lt;macro_body\u0026gt; %endmacro  调用宏的形式为：\nmacro_name param1, param2  下面的示例程序中，将输出字符串的指令序列以宏的形式进行了封装：\n; A macro with two parameters ; Implements the write system call %macro write_string 2 mov eax, 4 ;sys_write mov ebx, 1 ;stdout mov ecx, %1 ;param1, buf mov edx, %2 ;param2, buf_len int 80h ;call kernel %endmacro section	.text global _start ;must be declared for using gcc _start: ;tell linker entry point write_string msg1, len1 write_string msg2, len2 write_string msg3, len3 mov eax,1 ;sys_exit int 0x80 ;call kernel section	.data msg1 db	'Hello, programmers!',0xA,0xD len1 equ $ - msg1	msg2 db 'Welcome to the world of,', 0xA,0xD len2 equ $- msg2 msg3 db 'Linux assembly programming! ' len3 equ $- msg3  1.20 文件操作 # Linux内核提供了一系列文件操作的系统调用，常用的几个系统调用如下：\n sys_open sys_close sys_creat sys_read sys_write sys_lseek   系统调用编号可以在/usr/include/asm/unistd.h中检查到，系统调用参数、返回值信息可以借助Linux man手册进行查询。\n 汇编语言里面对于上述系统调用的调用与前面sys_read、sys_write示例程序中的使用方式是一致的，都按照如下几个步骤进行调用：\n 将系统调用的编号设置到EAX； 将系统调用的参数依次设置到EBX、ECX、EDX、ESI、EDI、EBX； 触发内核中断int 80h； 检查EAX中保存的系统调用返回值；  如下示例程序对文件相关的系统调用进行了组合使用，首先创建一个文件并写入数据，然后关闭，再重新打开文件并读取文件内容，最后在stdout上打印文件内容。\nsection	.text global _start ;must be declared for using gcc _start: ;tell linker entry point ;create the file mov eax, 8 mov ebx, file_name mov ecx, 0777 ;read, write and execute by all int 0x80 ;call kernel mov [fd_out], eax ; write into the file mov	edx,len ;number of bytes mov	ecx, msg ;message to write mov	ebx, [fd_out] ;file descriptor mov	eax,4 ;system call number (sys_write) int	0x80 ;call kernel ; close the file mov eax, 6 mov ebx, [fd_out] ; write the message indicating end of file write mov eax, 4 mov ebx, 1 mov ecx, msg_done mov edx, len_done int 0x80 ;open the file for reading mov eax, 5 mov ebx, file_name mov ecx, 0 ;for read only access mov edx, 0777 ;read, write and execute by all int 0x80 mov [fd_in], eax ;read from file mov eax, 3 mov ebx, [fd_in] mov ecx, info mov edx, 26 int 0x80 ; close the file mov eax, 6 mov ebx, [fd_in] ; print the info mov eax, 4 mov ebx, 1 mov ecx, info mov edx, 26 int 0x80 mov	eax,1 ;system call number (sys_exit) int	0x80 ;call kernel section	.data file_name db 'myfile.txt' msg db 'Welcome to Tutorials Point' len equ $-msg msg_done db 'Written to file', 0xa len_done equ $-msg_done section .bss fd_out resb 1 fd_in resb 1 info resb 26  1.21 内存管理 # Linux内核提供了系统调用sys_brk来分配堆内存区域，sys_brk实际上是增加了进程最大可动态申请的内存地址的上限，brk分配的内存区域（堆）仅仅挨着.data节，系统调用sys_brk参数为0时会返回当前可申请内存的最大地址，参数不为0时会调整当前brk边界。\n下面的示例程序通过系统调用sys_brk来动态分配了16KB的内存空间：\nsection	.text global _start ;must be declared for using gcc _start:	;tell linker entry point mov	eax, 45	;sys_brk xor	ebx, ebx int	80h add	eax, 16384	;number of bytes to be reserved mov	ebx, eax mov	eax, 45	;sys_brk int	80h cmp	eax, 0 jl	exit	;exit, if error mov	edi, eax	;EDI = highest available address sub	edi, 4	;pointing to the last DWORD mov	ecx, 4096	;number of DWORDs allocated xor	eax, eax	;clear eax std	;backward rep	stosd ;repete for entire allocated area cld	;put DF flag to normal state mov	eax, 4 mov	ebx, 1 mov	ecx, msg mov	edx, len int	80h	;print a message exit: mov	eax, 1 xor	ebx, ebx int	80h section	.data msg db	\u0026quot;Allocated 16 kb of memory!\u0026quot;, 10 len equ	$ - msg  1.22 总结 # 这里结合tutorialspoint上的汇编语言教程对相关的知识点进行了简要回顾，也有所收获，这里也分享给需要的同学。\n"}),a.add({id:483,href:"/tags/cpp/",title:"cpp",description:"",content:""}),a.add({id:484,href:"/blog/2022-07-09-gdb%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/",title:"gdb调试常用操作",description:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是gdb调试的常用操作。\n### execute and trace step by step help \u0026lt;topic/cmd\u0026gt; list list -	: list lines before last printed list +	: list lines after last printed list 3 list 3,7 list filename:3,7 list function list filename:function list *address n/ni/next : next s/si/step : next exactly rni : reverse ni, see also mozilla rr sni	: reverse si, see also mozilla rr r/run start finish	: finish current function bt/backtrace : look stack frame and parameters f/frame 2 : select stack frame i/info locals : show local vars p/print var/expression	: print var value set var varname=value ### breakpoints display var undisplay varNum b/break lineNum/function b/break lineNum/function [if expression] delete breakpoints	: delete all breakpoints delete breakpoints bpNum	: delete specified breakpoint disable breakpoints bpNum enable breakpoints bpNum c/continue info breakpoints ### watchpoints x/7b baseAddress	: print mem data watch varName/expression i/info watchpoints ### backtrace segmentation faults generally are caused by addresses of memory spaces.",content:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是gdb调试的常用操作。\n### execute and trace step by step help \u0026lt;topic/cmd\u0026gt; list list -	: list lines before last printed list +	: list lines after last printed list 3 list 3,7 list filename:3,7 list function list filename:function list *address n/ni/next : next s/si/step : next exactly rni : reverse ni, see also mozilla rr sni	: reverse si, see also mozilla rr r/run start finish	: finish current function bt/backtrace : look stack frame and parameters f/frame 2 : select stack frame i/info locals : show local vars p/print var/expression	: print var value set var varname=value ### breakpoints display var undisplay varNum b/break lineNum/function b/break lineNum/function [if expression] delete breakpoints	: delete all breakpoints delete breakpoints bpNum	: delete specified breakpoint disable breakpoints bpNum enable breakpoints bpNum c/continue info breakpoints ### watchpoints x/7b baseAddress	: print mem data watch varName/expression i/info watchpoints ### backtrace segmentation faults generally are caused by addresses of memory spaces. bt/backtrace : to find out which stack frame caused the error #0,#1,#2,...,#N : #N call some function,then #N-1 created,...,#1 call some function,then #0 created,..., if error occur in #0,it maybe caused in #1,#2,or #3,...,or #N. ### trace and debug multi-process app fork():	how to trace and debug multi-process app gdb: (1) set follow-fork-mode child (2) break linenumber note: before 'run',finish (1)(2),then 'run',we can see the output information of parent process after '(gdb)' prompt. but app is interrupted by breakpoints of child process,now we can use 'n','c',... to debug the child process. similarly,we can use 'set follow-fork-mode parent' to trace the parent process. ps: sometimes, we may find the proper function name. `strace` may help us trace all system calls, its parameters and returned values: `strace ./a.out`.  "}),a.add({id:485,href:"/tags/protobuf/",title:"protobuf",description:"",content:""}),a.add({id:486,href:"/tags/protoc/",title:"protoc",description:"",content:""}),a.add({id:487,href:"/tags/protoc-gen-go/",title:"protoc-gen-go",description:"",content:""}),a.add({id:488,href:"/blog/2017-05-23-protoc%E5%8F%8A%E6%8F%92%E4%BB%B6%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E7%B2%BE%E5%8D%8E%E7%89%88/",title:"Protoc及其插件工作原理分析(精华版)",description:"团队经常使用protobuf作为消息交换格式，由于protobuf具有很强的自描述性，非常适合对一个服务进行建模。结合配套的编译器protoc，可以轻松理解服务信息，在此基础上可以开发一些脚手架工具（如protoc-gen-go）来完成代码生成、接口自动测试、生成api文档等等工作。本文就来介绍下protoc及其插件的工作原理，读完后读者将具备定制化protoc插件开发的能力。",content:"在进行protoc插件开发之前，首先要了解protoc的工作原理。protobuf具有诸多优点被广泛使用，由于protoc对proto文件的强大解析能力使我们可以更进一步来开发一些插件，通过插件快速生成特定于proto文件的工具类、配置文件等，从而提高开发效率。\n本文首先会介绍一下protoc的整体工作原理，然后详细介绍一下protoc对proto文件的解析过程，最后给出编写protoc插件来扩展protoc功能的一个示例（这里以protoc-gen-go插件为例）。\n1. protoc工作原理分析 # 1.0. protoc源代码准备 # 要想了解protoc的工作机制，查看其源代码了解其核心流程是最靠谱的方法。\n获取程序源代码的方式如下：\ngit co https://github.com/google/protobuf  由于我们工程中常用的protoc版本是v2.5.0，所以这里检出对应版本的tag。\ngit ck v2.5.0  考虑到可能会进行测试、修改、注释等学习过程，这里最好创建一个新的分支来操作。\ngit branch -b ${new-branch-name}  现在源代码准备好了，下面可以阅读protoc的源码梳理一下其工作原理了。\n上述git检出后的protobuf路径，记为${protobuf}，后面如果出现${protobuf}请知晓其含义。如果在描述源代码时没有提及代码起始路径${protobuf}，那么起始路径均为${protobuf}。\n1.1. protoc执行流程说明 # protoc执行流程的相关源码，主要包括如下两个部分。\n1.1.1. protoc程序入口 # protoc程序入口为以下源文件main函数，该入口函数中完成protoc命令行接口初始化、编程语言及代码生成器注册后，调用cli.Run(argc,argv)解析proto文件并生成特定语言的源代码。\nfile: src/google/protobuf/compiler/main.cc\n// Author: kenton@google.com (Kenton Varda) // 这个头文件定义了protoc的命令行接口 #include \u0026lt;google/protobuf/compiler/command_line_interface.h\u0026gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include \u0026lt;google/protobuf/compiler/cpp/cpp_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/python/python_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/java/java_generator.h\u0026gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件 // - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头 // - 假定protoc --foo_out，那么实际调用的插件是protoc-foo google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(\u0026quot;protoc-\u0026quot;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator) google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026quot;--cpp_opt\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ header and source.\u0026quot;); // Proto2 Java (指定了--java_out将调用java::Generator) google::protobuf::compiler::java::JavaGenerator java_generator; cli.RegisterGenerator(\u0026quot;--java_out\u0026quot;, \u0026amp;java_generator, \u0026quot;Generate Java source file.\u0026quot;); // Proto2 Python (指定了python_out将调用python::Generator) google::protobuf::compiler::python::Generator py_generator; cli.RegisterGenerator(\u0026quot;--python_out\u0026quot;, \u0026amp;py_generator, \u0026quot;Generate Python source file.\u0026quot;); return cli.Run(argc, argv); }  1.1.2. 命令接口cli.Run(argc,argv)执行流程 # cli.Run(\u0026hellip;)中，完成对proto文件的读取、解析，并通过注册的代码生成器或者protoc插件生成特定语言源代码，并最终完成源代码文件的创建。\nint CommandLineInterface::Run(int argc, const char* const argv[]) { Clear(); // 解析命令行参数 switch (ParseArguments(argc, argv)) { case PARSE_ARGUMENT_DONE_AND_EXIT: return 0; case PARSE_ARGUMENT_FAIL: return 1; case PARSE_ARGUMENT_DONE_AND_CONTINUE: break; } // 设置源码树 DiskSourceTree source_tree; for (int i = 0; i \u0026lt; proto_path_.size(); i++) { source_tree.MapPath(proto_path_[i].first, proto_path_[i].second); } ... // 分配一个importer(负责解析proto文件并创建对应的FileDescriptor对象) Importer importer(\u0026amp;source_tree, \u0026amp;error_collector); // 解析成功后的proto文件都会通过一个对应的FileDescriptor来表示 vector\u0026lt;const FileDescriptor*\u0026gt; parsed_files; // 解析输入的proto文件 for (int i = 0; i \u0026lt; input_files_.size(); i++) { // 解析单个proto文件 const FileDescriptor* parsed_file = importer.Import(input_files_[i]); if (parsed_file == NULL) return 1; parsed_files.push_back(parsed_file); // 如果指定了--disallow_services则拒绝处理proto中service定义 if (disallow_services_ \u0026amp;\u0026amp; parsed_file-\u0026gt;service_count() \u0026gt; 0) { cerr \u0026lt;\u0026lt; parsed_file-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: This file contains services, but \u0026quot; \u0026quot;--disallow_services was used.\u0026quot; \u0026lt;\u0026lt; endl; return 1; } } // 为每个输出位置构造一个单独的GeneratorContext对象，有可能多个代码生成器的输出 // 位置是相同的，这种情况下，多个代码生成器应该共用同一个GeneratorContext对象以 // 使得OpenForInsert()能正常工作 typedef hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; GeneratorContextMap; GeneratorContextMap output_directories; // 针对proto文件生成特定语言的源代码 if (mode_ == MODE_COMPILE) { // 一次处理一个输出指令(--foo_out=params:dir) for (int i = 0; i \u0026lt; output_directives_.size(); i++) { string output_location = output_directives_[i].output_location; if (!HasSuffixString(output_location, \u0026quot;.zip\u0026quot;) \u0026amp;\u0026amp; !HasSuffixString(output_location, \u0026quot;.jar\u0026quot;)) { AddTrailingSlash(\u0026amp;output_location); } // 当前输出指令中的输出目录可能已经被记录下来了 GeneratorContextImpl** map_slot = \u0026amp;output_directories[output_location]; // - 如果没有记录下来则分配一个关联的GeneratorContextImpl对象 if (*map_slot == NULL) { *map_slot = new GeneratorContextImpl(parsed_files); } // - 参考输出指令，将解析成功的proto文件，生成对应的源代码信息， // 这些信息会被记录在GeneratorContextImpl *map_slot中 if (!GenerateOutput(parsed_files, output_directives_[i], *map_slot)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } // 创建源代码文件，并将生成的源代码信息写会磁盘 for (GeneratorContextMap::iterator iter = output_directories.begin(); iter != output_directories.end(); ++iter) { const string\u0026amp; location = iter-\u0026gt;first; GeneratorContextImpl* directory = iter-\u0026gt;second; if (HasSuffixString(location, \u0026quot;/\u0026quot;)) { // 创建当前目录下所有的源代码文件 if (!directory-\u0026gt;WriteAllToDisk(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } else { if (HasSuffixString(location, \u0026quot;.jar\u0026quot;)) { directory-\u0026gt;AddJarManifest(); } if (!directory-\u0026gt;WriteAllToZip(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } ... return 0; }  1.1.3. protoc执行逻辑总结 # 通过查看2.1.1、2.1.2两部分代码，可以对protoc的执行流程做一个简单的概括：\n  protoc main中初始化命令行参数接口cli;\n  开启以protoc-为前缀的插件作为第三方代码生成器使用，cli.AllowPlugins(\u0026ldquo;protoc-\u0026quot;)；\n  注册编程语言cpp、java、python及对应的代码生成器，cli.RegisterGenerator(\u0026hellip;)；\n  解析proto文件并运行代码生成器或者protoc插件生成特定语言源代码、创建源代码文件，cli.Run(argc, argv);\n Clear()清空所有的数据备用； ParseArguments(argc,argv)解析参数，对于protoc的某些内置参数的检查，对某些插件相关的\u0026ndash;${lang}_out参数的检查等，将\u0026ndash;${lang}_out作为输出指令保存起来；  struct OutputDirective { string name; // E.g. \u0026quot;--foo_out\u0026quot; CodeGenerator* generator; // NULL for plugins string parameter; string output_location; };  ``\n 参数解析成功之后，继续执行处理，设置源代码树、映射输入文件到虚拟路径、分配importer； 针对每个输入的proto文件进行解析，const FileDescriptor* parsed_file = importer.Import(input_files_[i])，解析成功后的文件会被加入到vector\u0026lt;FileDescriptor*\u0026gt; parsed_files中记录，每一个proto文件解析后都可以用一个FileDescriptor结构体来表示；   备注： 这里解析proto文件的过程是这样的，首先将proto文件中的内容分割成一个个的token，将内容拆分成一个个词素并检查有效性，也就是词法分析。如果词法分析检查无误则进入后续的语法分析过程，parser对输入token串进行文法相关的分析检查是否可以构成一棵有效的语法分析树，如果可以则表示语法正确。\n // Token定义如下 struct Token { TokenType type; string text; // The exact text of the token as it appeared in // the input. e.g. tokens of TYPE_STRING will still // be escaped and in quotes. // \u0026quot;line\u0026quot; and \u0026quot;column\u0026quot; specify the position of the first character of // the token within the input stream. They are zero-based. int line; int column; int end_column; }; // Token类型定义如下 enum TokenType { TYPE_START, // Next() has not yet been called. TYPE_END, // End of input reached. \u0026quot;text\u0026quot; is empty. TYPE_IDENTIFIER, // A sequence of letters, digits, and underscores, not // starting with a digit. It is an error for a number // to be followed by an identifier with no space in // between. TYPE_INTEGER, // A sequence of digits representing an integer. Normally // the digits are decimal, but a prefix of \u0026quot;0x\u0026quot; indicates // a hex number and a leading zero indicates octal, just // like with C numeric literals. A leading negative sign // is NOT included in the token; it's up to the parser to // interpret the unary minus operator on its own. TYPE_FLOAT, // A floating point literal, with a fractional part and/or // an exponent. Always in decimal. Again, never // negative. TYPE_STRING, // A quoted sequence of escaped characters. Either single // or double quotes can be used, but they must match. // A string literal cannot cross a line break. TYPE_SYMBOL, // Any other printable character, like '!' or '+'. // Symbols are always a single character, so \u0026quot;!+$%\u0026quot; is // four tokens. };  `` 语法分析的过程这里就不解释了，感兴趣的可以看一下protobuf中grammar的定义，无非也就是些规约的事情，只要能够按照grammar将词法分析输出的token串构建出一棵完整的语法分析树proto文件就是合法的，否则就是不合法的，至于语法分析过程中伴随的语义分析过程，语义分析过程中执行哪些语义动作，不说也知道，肯定是生成某些“中间代码”之类的鬼东西。学过编译原理的这些处理过程应该都是比较清楚的，这里就不再展开了。语法分析成功之后就得到了proto对应的FileDescriptor对象，因为可能输入的是多个proto，所以多个FileDescriptor就用vector来存储了。\n 遍历之前记录下来的输出指令OutputDirective output_directives[]，output_directives[i].output_location指明了输出目录，针对输出目录创建GeneratorContextImpl，并记录到hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; output_directories这个map中，key为flag_out,如\u0026ndash;foo_out，value为GeneratorContextImpl。由于可能多个\u0026ndash;${lang}_out都指向相同的输出目录，所以同一个GeneratorContextImpl也存在复用的情况。每个GeneratorContextImpl记录了一个输出目录、所有该目录下的待创建的源代码文件的信息，待创建的源代码文件信息记录在map\u0026lt;string,string*\u0026gt; files_里面，key为源代码文件名，val为源代码文件的内容，另外还包括了一个vector\u0026lt;FileDescriptor*\u0026gt; parsed_files记录了所有解析成功的proto文件信息。 遍历output_directives的同时，因为同一个output_directives[i]对应的输出目录下可能有多个源代码文件要输出，并且不管flag_name是什么，要处理的proto文件都是相同的，所以每个output_directives[i]都会对其调用GenerateOutput(parsed_files, output_directives[i], *map_slot)，output_directives[i].plugin指明了语言的代码生成器(为NULL则使用插件)，对所有的解析成功的proto文件parsed_files[i]生成源代码，源代码全部输出到output_directive[i].output_location下，源代码的文件名都记录在parsed_files[i].name()里面，而最终生成的源代码信息都存储在这里的CodeGeneratorImpl **map_slot中，也就相当于存储在了output_directories[]中。 最后遍历output_directories[]，将每个输出目录下要写的所有文件的数据全部写出到磁盘，即output_directories[i]-\u0026gt;WriteAllToDisk()。 done！    了解从proto到源代码生成的关键之处就是2.1.2节中cli.Run(\u0026hellip;)方法中调用的GenerateOutput是怎么实现的，接着看。\n1.1.4 protoc CommandLineInterface::GenerateOutput(\u0026hellip;)实现 # 下面看下GenerateOutput方法到底执行了哪些操作。\n// 根据输出指示, 为解析成功的proto文件调用代码生成器生成对应的代码并存储到generator_context //@param parsed_files 所有解析成功的proto文件，每个解析成功的proto文件都用一个FileDescriptor来表示 //@param output_directive 输出指示，其指明了目标语言、语言对应的代码生成器、输出目录等 //@param generator_context 代码生成器上下文，可记录生成的代码 bool CommandLineInterface::GenerateOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const OutputDirective\u0026amp; output_directive, GeneratorContext* generator_context) { string error; // 如果输出指令中没有设置对应的代码生成器，表明没有在protoc main中注册语言对应的代码生成器， // 这种情况下需要继续搜索是否存在对应的protoc插件来支持，若存在则调用该插件来充当代码生成器 if (output_directive.generator == NULL) { // 这种情况下使用的是${PATH}中可搜索到的protoc插件 GOOGLE_CHECK(HasPrefixString(output_directive.name, \u0026quot;--\u0026quot;) \u0026amp;\u0026amp; HasSuffixString(output_directive.name, \u0026quot;_out\u0026quot;)) \u0026lt;\u0026lt; \u0026quot;Bad name for plugin generator: \u0026quot; \u0026lt;\u0026lt; output_directive.name; // 实际上protoc搜索插件对应的可执行程序的时候，搜索的名称是“protoc-gen-”+“语言”， // 如果我们调用的是protoc --foo_out，那么实际搜索的就是protoc-gen-foo。 string plugin_name = plugin_prefix_ + \u0026quot;gen-\u0026quot; + output_directive.name.substr(2, output_directive.name.size() - 6); // 调用protoc插件来生成代码，这是我们要重点看的，我们就是要实现自己的protoc插件 if (!GeneratePluginOutput(parsed_files, plugin_name, output_directive.parameter, generator_context, \u0026amp;error)) { cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } else { // 这种是protoc main函数中正常注册的编程语言对应的代码生成器 string parameters = output_directive.parameter; if (!generator_parameters_[output_directive.name].empty()) { if (!parameters.empty()) { parameters.append(\u0026quot;,\u0026quot;); } parameters.append(generator_parameters_[output_directive.name]); } // 为每个解析成功的proto文件生成代码 for (int i = 0; i \u0026lt; parsed_files.size(); i++) { if (!output_directive.generator-\u0026gt;Generate(parsed_files[i], parameters, generator_context, \u0026amp;error)) { // Generator returned an error. cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; parsed_files[i]-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } } return true; }  1.1.5. protoc调用插件生成代码的执行逻辑 # 下面再来看一下GeneratePluginOutput是如何工作的。\n// 调用protoc插件为解析成功的proto文件生成代码 //@param parsed_files 解析成功的文件 //@param plugin_name protoc插件名称（这个是拼接出来的protoc-gen-${lang}） //@param parameter 传给插件的参数 //@param generator_context 代码生成器上下文，可记录生成的代码 //@param error 代码生成过程中的错误信息 bool CommandLineInterface::GeneratePluginOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const string\u0026amp; plugin_name, const string\u0026amp; parameter, GeneratorContext* generator_context, string* error) { // protoc生成一个代码生成请求，并发送给插件 CodeGeneratorRequest request; // protoc插件根据接收到的代码生成请求生成代码，并发送响应给protoc CodeGeneratorResponse response; // Build the request. if (!parameter.empty()) { request.set_parameter(parameter); } set\u0026lt;const FileDescriptor*\u0026gt; already_seen; for (int i = 0; i \u0026lt; parsed_files.size(); i++) { request.add_file_to_generate(parsed_files[i]-\u0026gt;name()); GetTransitiveDependencies(parsed_files[i], true, // Include source code info. \u0026amp;already_seen, request.mutable_proto_file()); } // fork出一个子进程，子进程来执行插件完成代码生成工作， // 父子进程之间是通过管道通信完成请求、响应过程，如何控制子进程的stdin、stdout， // 这个可以通过dup2或者dup3来控制间fd 0、1分别设置到管道的读端、写端。 // 事实上protobuf的开发人员也是这么来实现的。 // 子进程通过exec来搜索执行插件程序 Subprocess subprocess; if (plugins_.count(plugin_name) \u0026gt; 0) { subprocess.Start(plugins_[plugin_name], Subprocess::EXACT_NAME); } else { subprocess.Start(plugin_name, Subprocess::SEARCH_PATH); } string communicate_error; // 请求插件生成代码 if (!subprocess.Communicate(request, \u0026amp;response, \u0026amp;communicate_error)) { *error = strings::Substitute(\u0026quot;$0: $1\u0026quot;, plugin_name, communicate_error); return false; } // Write the files. We do this even if there was a generator error in order // to match the behavior of a compiled-in generator. scoped_ptr\u0026lt;io::ZeroCopyOutputStream\u0026gt; current_output; for (int i = 0; i \u0026lt; response.file_size(); i++) { const CodeGeneratorResponse::File\u0026amp; output_file = response.file(i); if (!output_file.insertion_point().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据已经存在，定位到准确的插入点位置执行写入，然后关闭文件 // - 这里的插入点如何定义，我们在后面再进行说明。具体可参考plugin.proto和plugin.pb.h。 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;OpenForInsert(output_file.name(), output_file.insertion_point())); } else if (!output_file.name().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据不存在，不存在插入点信息，从开始处执行写入 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;Open(output_file.name())); } else if (current_output == NULL) { *error = strings::Substitute( \u0026quot;$0: First file chunk returned by plugin did not specify a file name.\u0026quot;, plugin_name); return false; } // 从CodeGeneratorResponse中获取输出流，写出，这里输出流中的数据时存储在GeneratorContextImpl中的， // GenerateOutput调用成功之后后面会遍历每一个GenerateContextImpl完成WriteAllToDisk()的操作。 // Use CodedOutputStream for convenience; otherwise we'd need to provide // our own buffer-copying loop. io::CodedOutputStream writer(current_output.get()); writer.WriteString(output_file.content()); } // 检查有没有错误 if (!response.error().empty()) { // Generator returned an error. *error = response.error(); return false; } return true; }  1.1.6. protoc \u0026amp; protoc插件数据交互的执行逻辑 # 整体执行逻辑差不多理清楚了，然后这里我们需要看一下父进程给子进程发送的代码生成请求是什么，收到的代码生成的响应又是什么，以及父子进程通信的细节、子进程对请求的处理过程等。\n先来看下plugin.proto的定义，protoc内置的支持语言里面并不包含go，我们后面需要用go来编写我们自己的插件，所以必须使用protoc的go插件来生成go对应的plugin.go代码，然后我们自己写一些业务类插件（非语言插件）的时候才能用上plugin.go。扯这么多是为了让大家明白这里为什么需要看下plugin.proto，而不是误解为只是在堆砌内容。看了这里的plugin.proto之后才能理解到protoc中的插件机制的边界时什么，我们就可以明白利用protoc的插件机制，我们可以做到什么程度，哪些功能能实现，哪些实现不了，这个是很重要的。\nfile: src/google/protobuf/compiler/plugin.proto\n// protoc (aka the Protocol Compiler) can be extended via plugins. A plugin is // just a program that reads a CodeGeneratorRequest from stdin and writes a // CodeGeneratorResponse to stdout. // // Plugins written using C++ can use google/protobuf/compiler/plugin.h instead // of dealing with the raw protocol defined here. // // A plugin executable needs only to be placed somewhere in the path. The // plugin should be named \u0026quot;protoc-gen-$NAME\u0026quot;, and will then be used when the // flag \u0026quot;--${NAME}_out\u0026quot; is passed to protoc. package google.protobuf.compiler; option java_package = \u0026quot;com.google.protobuf.compiler\u0026quot;; option java_outer_classname = \u0026quot;PluginProtos\u0026quot;; import \u0026quot;google/protobuf/descriptor.proto\u0026quot;; // 发送给插件的代码生成请求 // An encoded CodeGeneratorRequest is written to the plugin's stdin. message CodeGeneratorRequest { // The .proto files that were explicitly listed on the command-line. The // code generator should generate code only for these files. Each file's // descriptor will be included in proto_file, below. //proto文件列表对应的要生成的文件的源代码文件的名字 repeated string file_to_generate = 1; // The generator parameter passed on the command-line. //传递给插件代码生成器的参数 optional string parameter = 2; // FileDescriptorProtos for all files in files_to_generate and everything // they import. The files will appear in topological order, so each file // appears before any file that imports it. // // protoc guarantees that all proto_files will be written after // the fields above, even though this is not technically guaranteed by the // protobuf wire format. This theoretically could allow a plugin to stream // in the FileDescriptorProtos and handle them one by one rather than read // the entire set into memory at once. However, as of this writing, this // is not similarly optimized on protoc's end -- it will store all fields in // memory at once before sending them to the plugin. // 每一个正确解析的proto文件都用一个FileDescriptorProto来表示； // 这里的FileDescriptorProto与FileDescriptor其实是对应的，在请求插件进行代码 // 生成的时候直接就有这样的代码FileDescriptor::CopyTo(FileDescriptorProto\u0026amp;) // 的用法。而在descriptor.h和descriptor.proto中查看二者的描述时，其注释清清 // 楚楚地写着都是描述的一个完整的proto文件。 repeated FileDescriptorProto proto_file = 15; } // 插件返回的代码生成响应 // The plugin writes an encoded CodeGeneratorResponse to stdout. message CodeGeneratorResponse { // Error message. If non-empty, code generation failed. The plugin process // should exit with status code zero even if it reports an error in this way. // // This should be used to indicate errors in .proto files which prevent the // code generator from generating correct code. Errors which indicate a // problem in protoc itself -- such as the input CodeGeneratorRequest being // unparseable -- should be reported by writing a message to stderr and // exiting with a non-zero status code. // 错误信息 optional string error = 1; // Represents a single generated file. // 生成的源代码文件消息类型，注意这里是一个内部类型 message File { // 待生成的源代码文件名（相对于输出目录），文件名中不能包括.或者..，路径是 // 相对输出目录的路径，不能用绝对路径，另分隔符必须用/。 // 如果name没有指定，那么输出的内容将追加到前一个输出的源代码文件中，这种 // 方式使得代码生成器能够将一个大文件的生成分多次写入来完成，不用一次性将很 // 大数据量的数据放在内存中。这里需要指出的是，protoc中并没有针对这种情况 // 进行特殊的优化，它等待读取完整的CodeGeneratorResponse再写出到磁盘。 optional string name = 1; // 如果insertion_point不空的话，name字段也不能为空，并且假定name字段指定的 // 文件已经存在了。这里的内容将被插入到name指定的文件中的特定插入点（注解）的 // 上一行。这有助于扩展代码生成器输出的内容。在一次protoc调用中，可能会同 // 时指定多个protoc插件，前面的插件可能会在输出的内容中指定插入点，后面的 // 插件可能会在这些指定的插入点的位置继续扩展代码内容。 // 例如，前面的一个插件在输出的代码内容中增加了这样一行注解： // @@protoc_insertion_point(NAME) // 这样就定义了一个插入点，插入点前面、后面可以包含任意的文本内容，即使在 // 注释里面也是可以的。这里的插入点定义中的NAME应该可以唯一标识一个插入点 // 才可以，类似于标识符，以供其他的插件使用，插件插入代码的时候将从插入点 // 的上一行开始自行插入。如果包含多个插入点的话，插入点的内容将被插件依次 // 扩展。 // // 一开始创建这个源代码文件的代码生成器或者插件与后面的继续扩展源代码插入 // 点位置内容的代码生成器或者插件，必须在protoc的同一次调用中，代码生成器 // 或者插件按照protoc命令行调用过程中指定的顺序依次调用。 optional string insertion_point = 2; // 待写入到源代码中的内容 optional string content = 15; } // 一次要处理的 proto文件可能有多个，所以插件处理后这里的file是一个list repeated File file = 15; }  下面看一下protoc与protoc插件这对父子进程之间是怎么通信的。\nclass LIBPROTOC_EXPORT Subprocess { public: Subprocess(); ~Subprocess(); enum SearchMode { SEARCH_PATH, // Use PATH environment variable. EXACT_NAME // Program is an exact file name; don't use the PATH. }; // Start the subprocess. Currently we don't provide a way to specify // arguments as protoc plugins don't have any. void Start(const string\u0026amp; program, SearchMode search_mode); // Serialize the input message and pipe it to the subprocess's stdin, then // close the pipe. Meanwhile, read from the subprocess's stdout and parse // the data into *output. All this is done carefully to avoid deadlocks. // Returns true if successful. On any sort of error, returns false and sets // *error to a description of the problem. bool Communicate(const Message\u0026amp; input, Message* output, string* error); // win32 relevant ... neglect private: #ifdef _WIN32 // ... #else // !_WIN32 pid_t child_pid_; // The file descriptors for our end of the child's pipes. We close each and // set it to -1 when no longer needed. int child_stdin_; int child_stdout_; #endif };  下面是Linux平台下的子进程启动处理逻辑。\nvoid Subprocess::Start(const string\u0026amp; program, SearchMode search_mode) { // Note that we assume that there are no other threads, thus we don't have to // do crazy stuff like using socket pairs or avoiding libc locks. // [0] is read end, [1] is write end. int stdin_pipe[2]; int stdout_pipe[2]; GOOGLE_CHECK(pipe(stdin_pipe) != -1); GOOGLE_CHECK(pipe(stdout_pipe) != -1); char* argv[2] = { strdup(program.c_str()), NULL }; child_pid_ = fork(); if (child_pid_ == -1) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;fork: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } else if (child_pid_ == 0) { // We are the child. // 将子进程的stdin重定向到stdin_pipe的读端 dup2(stdin_pipe[0], STDIN_FILENO); // 将子进程的stdout重定向到stdout_pipe的写端 dup2(stdout_pipe[1], STDOUT_FILENO); // 子进程通过0、1对管道进行操作就够了，释放多余的fd close(stdin_pipe[0]); close(stdin_pipe[1]); close(stdout_pipe[0]); close(stdout_pipe[1]); // 根据程序搜索模式调用exec族函数来调用插件执行，exec族函数通过替换当前进 // 程的代码段、数据段等内存数据信息，然后调整寄存器信息，使得进程转而去执 // 行插件的代码。插件代码执行之前进程就已经将fd 0、1重定向到父进程clone过 // 来的管道了，因此插件程序的输出将直接被输出到父进程创建的管道中。 // 正常情况下，exec一旦执行成功，那么久绝不对执行switch后续的代码了，只有 // 出错才可能会执行到后续的代码。 switch (search_mode) { case SEARCH_PATH: execvp(argv[0], argv); break; case EXACT_NAME: execv(argv[0], argv); break; } // 只有出错才可能会执行到这里的代码。 // Write directly to STDERR_FILENO to avoid stdio code paths that may do // stuff that is unsafe here. int ignored; ignored = write(STDERR_FILENO, argv[0], strlen(argv[0])); const char* message = \u0026quot;: program not found or is not executable\\n\u0026quot;; ignored = write(STDERR_FILENO, message, strlen(message)); (void) ignored; // Must use _exit() rather than exit() to avoid flushing output buffers // that will also be flushed by the parent. _exit(1); } else { free(argv[0]); // 父进程释放无用的fd close(stdin_pipe[0]); close(stdout_pipe[1]); // 子进程的stdin，对父进程来说也就是管道stdin_pipe的写端，CodeGeneratorRequest将通过这个fd写给子进程 child_stdin_ = stdin_pipe[1]; // 子进程的stdout，对父进程来说也就是管道stdout_pipe的读端，CodeGeneratorResponse将通过这个fd从子进程读取 child_stdout_ = stdout_pipe[0]; } }  下面接着看父进程读取子进程返回的CodeGeneratorResponse的执行逻辑。\n//protoc进程和protoc插件进程通信 // //@param protoc进程发送到protoc插件进程的代码生成请求 //@param protoc插件进程返回给protoc进程的代码生成响应 //@param error 错误信息 bool Subprocess::Communicate(const Message\u0026amp; input, Message* output, string* error) { GOOGLE_CHECK_NE(child_stdin_, -1) \u0026lt;\u0026lt; \u0026quot;Must call Start() first.\u0026quot;; // The \u0026quot;sighandler_t\u0026quot; typedef is GNU-specific, so define our own. typedef void SignalHandler(int); // 屏蔽信号SIGPIPE，防止没有指定信号处理函数的情况下被kill掉 SignalHandler* old_pipe_handler = signal(SIGPIPE, SIG_IGN); string input_data = input.SerializeAsString(); string output_data; int input_pos = 0; int max_fd = max(child_stdin_, child_stdout_); // child_stdout==-1的时候表示子进程返回的数据已经读取完毕了，可以gg了 while (child_stdout_ != -1) { fd_set read_fds; fd_set write_fds; FD_ZERO(\u0026amp;read_fds); FD_ZERO(\u0026amp;write_fds); if (child_stdout_ != -1) { FD_SET(child_stdout_, \u0026amp;read_fds); } if (child_stdin_ != -1) { FD_SET(child_stdin_, \u0026amp;write_fds); } // 这种情景下也用select，果然很google！ if (select(max_fd + 1, \u0026amp;read_fds, \u0026amp;write_fds, NULL, NULL) \u0026lt; 0) { if (errno == EINTR) { // 被信号中断了，再次尝试 continue; } else { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;select: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // stdout_pipe写事件就绪，写请求CodeGeneratorRequest给子进程 if (child_stdin_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdin_, \u0026amp;write_fds)) { int n = write(child_stdin_, input_data.data() + input_pos, input_data.size() - input_pos); if (n \u0026lt; 0) { // Child closed pipe. Presumably it will report an error later. // Pretend we're done for now. input_pos = input_data.size(); } else { input_pos += n; } // 代码生成请求已经成功写给子进程了，关闭相关的fd if (input_pos == input_data.size()) { // We're done writing. Close. close(child_stdin_); child_stdin_ = -1; } } // stdin_pipe读事件就绪，读取子进程返回的CodeGeneratorResponse if (child_stdout_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdout_, \u0026amp;read_fds)) { char buffer[4096]; int n = read(child_stdout_, buffer, sizeof(buffer)); if (n \u0026gt; 0) { output_data.append(buffer, n); } else { // 子进程返回的CodeGeneratorResponse已经读取完毕，关闭相关的fd close(child_stdout_); child_stdout_ = -1; } } } // 子进程还没有读取CodeGeneratorRequest完毕，就关闭了输出，这种情况下也不可 // 能读取到返回的CodeGeneratorResponse了，这种情况很可能是出现了异常。 if (child_stdin_ != -1) { // Child did not finish reading input before it closed the output. // Presumably it exited with an error. close(child_stdin_); child_stdin_ = -1; } // 等待子进程结束，子进程退出之后，需要父进程来清理子进程占用的部分资源。 // 如果当前父进程不waitpid的话，子进程的父进程会变为init或者systemd进程，同 样也会被清理的。 int status; while (waitpid(child_pid_, \u0026amp;status, 0) == -1) { if (errno != EINTR) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;waitpid: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // 刚才为了阻止SIGPIPE信号到达时导致进程终止，我们修改了SIGPIPE的信号处理函 // 数，这里可以恢复之前的SIGPIPE的信号处理函数。 signal(SIGPIPE, old_pipe_handler); // 根据子进程的退出状态执行后续的处理逻辑 // - 异常处理 if (WIFEXITED(status)) { if (WEXITSTATUS(status) != 0) { int error_code = WEXITSTATUS(status); *error = strings::Substitute(\u0026quot;Plugin failed with status code $0.\u0026quot;, error_code); return false; } } else if (WIFSIGNALED(status)) { int signal = WTERMSIG(status); *error = strings::Substitute(\u0026quot;Plugin killed by signal $0.\u0026quot;, signal); return false; } else { *error = \u0026quot;Neither WEXITSTATUS nor WTERMSIG is true?\u0026quot;; return false; } // 将子进程返回的串行化之后的CodeGeneratorResponse数据进行反串行化，反串行化 // 成Message对象，实际上这里的Message::ParseFromString(const string\u0026amp;)是个虚 // 函数，是被CodeGeneratorResponse这个类重写了的，反串行化过程与具体的类密切 // 相关，也必须在派生类中予以实现。 if (!output-\u0026gt;ParseFromString(output_data)) { *error = \u0026quot;Plugin output is unparseable.\u0026quot;; return false; } return true; }  到这里为止protoc进程的具体执行逻辑描述地已经很清楚了吧？下面再看下插件的执行逻辑。\n支持不同语言的插件的执行逻辑，总体上来讲都包括下面的执行逻辑，只是生成的目标源代码不同而已。插件就只是从stdin读取串行化之后的CodeGeneratorRequest请求，然后执行反串行化得到一个完整的CodeGeneratorRequest对象，然后根据请求进行必要的代码生成逻辑，确定要生成的源代码信息，并将其设置到CodeGeneratorResponse中并串行化后写入到stdout，插件的执行逻辑就这么简单。\n2. protoc插件工作原理分析 # 在第1节中结合protoc源代码对protoc的工作原理进行了较为详细地介绍，也重点介绍了采用protoc插件生成源代码的情况下protoc与protoc插件的交互过程。下面我们将以protoc-gen-go作为一个学习的范例来进一步理解一下插件的工作原理，也可以为我们后续开发protoc插件提供参考。\n2.1. protoc-gen-go源代码准备 # protoc-gen-go的源代码可以通过通过如下方式获取：\ngit co https://github.com/golang/protobuf git branch -b ${new-branch}  进行protoc插件开发，无非是基于解析后的proto文件生成特定语言（不一定是语言）的目标代码，要想正确地生成目标代码，首要条件就是要能够正确提取proto文件中的内容，而proto文件中定义的内容都可以通过descriptor.proto来描述。所以在我们深入protoc-gen-go的源代码之前，不妨先看下descriptor.proto的定义来看下protobuf是如何抽象、描述一个proto文件的。\n2.2. descriptor.proto，对proto文件的抽象\u0026amp;描述 # proto文件中的数据类型都是在descriptor.proto中定义好的，为了更好地帮助我们对proto文件中的数据类型进行解析，为了在插件开发过程中更加方便快速地获得与数据类型、变量、rpc等相关的相关内容，我们都需要深入地理解descriptor.proto中的相关定义以及从它延伸出来的一些概念、算法等。\n这部分的内容还不少，在不影响理解的大前提下，我还是稍微删减了些代码，避免对大家理解造成不必要的干扰。\nfile: src/google/protobuf/descriptor.proto\n// Author: kenton@google.com (Kenton Varda) // Based on original Protocol Buffers design by // Sanjay Ghemawat, Jeff Dean, and others. // descriptor.proto文件中的messages定义了proto文件中所能见到的所有的定义，一个有效的.proto文件在不提供其他信息（甚至不需要读取它的imports）能够直接被转换成一个FileDescriptorProto对象。 package google.protobuf; option java_package = \u0026quot;com.google.protobuf\u0026quot;; option java_outer_classname = \u0026quot;DescriptorProtos\u0026quot;; // descriptor.proto必须在速度方面优化，因为在启动过程中基于反射的算法不起作用 option optimize_for = SPEED; // protoc可以将解析的proto文件中的descriptor添加到FileDescriptorSet并输出到文件 message FileDescriptorSet { repeated FileDescriptorProto file = 1; } // 下面的message FileDescriptorProto可以用于描述一个完整的proto文件 message FileDescriptorProto { optional string name = 1; // proto文件名，file name，相对于源代码根目录 optional string package = 2; // proto包名，例如 \u0026quot;foo\u0026quot;、\u0026quot;foo.bar\u0026quot; repeated string dependency = 3; // proto文件中import进来的其他proto文件列表 repeated int32 public_dependency = 10; // 上面public import的proto文件在proto文件列表中的索引 // Indexes of the weak imported files in the dependency list. repeated int32 weak_dependency = 11; // 上面weak import的proto文件在proto文件列表中的索引，不要使用，只用于google内部的迁移 // proto文件中的所有顶层定义信息 repeated DescriptorProto message_type = 4; // 所有的消息(message)类型定义 repeated EnumDescriptorProto enum_type = 5; // 所有的枚举(enum)类型定义 repeated ServiceDescriptorProto service = 6; // 所有的服务(service)类型定义 repeated FieldDescriptorProto extension = 7; // 所有的扩展字段定义 optional FileOptions options = 8; // 文件选项 // 这个字段包括了源代码的相关信息，这里的信息可以给开发工具使用，也仅应该提供给开发工具使用； // 可以选择将这个字段中的信息删除，在程序运行期间并不会造成破坏。 optional SourceCodeInfo source_code_info = 9; } // 描述消息类型Message message DescriptorProto { optional string name = 1; // Message的类型名称 repeated FieldDescriptorProto field = 2; // Message中包括的字段列表 repeated FieldDescriptorProto extension = 6; // Message中包括的扩展列表 repeated DescriptorProto nested_type = 3; // Message中嵌套的Message类型列表 repeated EnumDescriptorProto enum_type = 4; // Message中嵌套的枚举类型列表 message ExtensionRange { optional int32 start = 1; optional int32 end = 2; } repeated ExtensionRange extension_range = 5; optional MessageOptions options = 7; } // 描述一个字段（字段可以是Message中的，也可以是某些扩展字段） message FieldDescriptorProto { // 字段数据类型 enum Type { // 0 is reserved for errors. // 由于历史方面的原因，这里的枚举值的顺序有点奇怪 TYPE_DOUBLE = 1; TYPE_FLOAT = 2; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT64 if // negative values are likely. TYPE_INT64 = 3; TYPE_UINT64 = 4; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT32 if // negative values are likely. TYPE_INT32 = 5; TYPE_FIXED64 = 6; TYPE_FIXED32 = 7; TYPE_BOOL = 8; TYPE_STRING = 9; TYPE_GROUP = 10; // Tag-delimited aggregate. TYPE_MESSAGE = 11; // Length-delimited aggregate. // New in version 2. TYPE_BYTES = 12; TYPE_UINT32 = 13; TYPE_ENUM = 14; TYPE_SFIXED32 = 15; TYPE_SFIXED64 = 16; TYPE_SINT32 = 17; // Uses ZigZag encoding. TYPE_SINT64 = 18; // Uses ZigZag encoding. }; // 字段修饰符optional、required、repeated enum Label { // 0 is reserved for errors LABEL_OPTIONAL = 1; LABEL_REQUIRED = 2; LABEL_REPEATED = 3; // TODO(sanjay): Should we add LABEL_MAP? }; optional string name = 1; // 字段名称 optional int32 number = 3; // 字段tag编号 optional Label label = 4; // 字段修饰符 // 如果type_name已设置，这个字段无须设置； // 如果这两个字段都设置了，这里的type字段必须是TYPE_ENUM类型或者TYPE_MESSAGE类型 optional Type type = 5; // 对于TYPE_ENUM或者TYPE_MESSAGE类型，type_name就是type的名字。 // 如果name以“.”开头那么它是完全保留的。对于C++来说，其作用域规则要求首先搜 // 索当前Message类型的嵌套类型，然后才是parent namespace中的类型，一直到root // namespace。 optional string type_name = 6; // 对于扩展，它就是被扩展的类型的名字，对它的解析与对type_name的解析时一样的 optional string extendee = 2; // 对于数值类型，存储了数值的文本表示形式； // 对于布尔类型，存储字符串\u0026quot;true\u0026quot;或\u0026quot;false\u0026quot;； // 对于字符串类型，存储原始的文本内容（未转义的） // 对于字节，存储了c转义后的值（所有\u0026gt;=128的字节都会被转义） // TODO(kenton)，基于base64编码的? optional string default_value = 7; optional FieldOptions options = 8; // 字段选项 } // 描述一个枚举类型enum message EnumDescriptorProto { optional string name = 1; // 枚举类型名称 repeated EnumValueDescriptorProto value = 2; // 枚举类型中包括的枚举值列表 optional EnumOptions options = 3; // 枚举类型选项 } // 描述一个枚举类型中的一个枚举值 message EnumValueDescriptorProto { optional string name = 1; // 枚举值对应的name optional int32 number = 2; // 枚举值对应的number（默认为0，依次递增） optional EnumValueOptions options = 3; // 枚举值选项 } // 描述一个rpc service. message ServiceDescriptorProto { optional string name = 1; // 服务名称 repeated MethodDescriptorProto method = 2; // 服务对应的方法列表 optional ServiceOptions options = 3; // 服务选项 } // 描述一个服务的方法 message MethodDescriptorProto { optional string name = 1; // 方法名称 optional string input_type = 2; // 方法入参类型 optional string output_type = 3; // 方法出参类型 optional MethodOptions options = 4; // 方法选项 } // =================================================================== // Options // 上面的每一个定义基本上都包括了选项option相关的字段，这些选项字段仅仅是一些 // 注解，这些注解会影响代码的生成，使得生成的代码稍有不同，注解也可能包含了操作 // message的代码的一些提示信息、说明信息。 // // clients可能会定义一些自定义的选项来作为*Options message的extensions，这些 // extensions在parsing阶段可能还无法确定下来，所以parser不能存储他们的值，而是 // 将这些自定义的选项先存储到一个*Options message里面，称之为 // uinterpreted_option。这个字段的名字在所有的*Options message里面都必须保证是 // 相同的。之后在我们构建descriptor的时候，这个时候所有的proto文件也都解析完了、 // 所有的extensions也都知道了，这个时候我们再用这里的uinterpreted_option字段去 // 填充那些extensions。 // // 用于自定义选项的extensions编号的选择一般遵循下面的方法： // * 对于只在一个应用程序或者组织内使用的选项，或者用于实验目的的选项，使用字 // 段编号50000~99999范围内的。对于多个选项，用户需要确保不使用相同的编号。 // * 对于可能被多个互不依赖的实体所共同使用的选项，需要给 // protobuf-global-extension-registry@google.com发邮件来申请预留扩展编号。需 // 要提供工程名称、工程站点，没必要解释为什么需要申请预留某个特定的编号。通 // 常只需要一个扩展编号，可以声明多个选项但是只使用这一个相同的扩展编号。如 // 果申请公共的扩展编号是个刚需，google可能会发布一个web service接口来自动分 // 配选项编号。 message FileOptions { // java包名，当前proto文件中生成的java类将位于这个package下 optional string java_package = 1; // 指定一个外部类名称，当前proto文件中生成的所有的类将被封装在这个外部类当中 optional string java_outer_classname = 8; // 如果设置为true，java代码生成器将为每个顶层message、enum、service定义生成 // 单独的java文件，默认为false optional bool java_multiple_files = 10 [default=false]; // 如果设置为true，java代码生成器将未每个message定义生成equals()、hashCode() // 方法，默认为false。本来AbstractMessage基类经包括了一个基于反射的equals()、 // hashCode()方法实现，这里的这个设置项是一个性能方面的优化 optional bool java_generate_equals_and_hash = 20 [default=false]; // 优化类型，生成的类可以进行速度优化、代码尺寸优化 enum OptimizeMode { SPEED = 1; // Generate complete code for parsing, serialization, // etc. CODE_SIZE = 2; // Use ReflectionOps to implement these methods. LITE_RUNTIME = 3; // Generate code using MessageLite and the lite runtime. } optional OptimizeMode optimize_for = 9 [default=SPEED]; // 设置go代码的包名 optional string go_package = 11; // 是否应该针对每一门语言都生成generice services？generic服务并不特定于任何 // 的rpc系统，它是由每个语言的注代码生成器来生成的，不借助于额外的插件。 // generic services是早期protoo2这个版本说支持的唯一一种服务类型。 // // 由于现在推崇使用plugins，plugins可以生成针对特定rpc系统的代码，generic // services现在可以看做是被废弃了。因此，以前proto2总的generice services的默 // 认设置默认为false，早期的依赖于generic services的代码需要显示设置这些选项 // 为true。 optional bool cc_generic_services = 16 [default=false]; optional bool java_generic_services = 17 [default=false]; optional bool py_generic_services = 18 [default=false]; // parser将不识别的选项存储在这里的uinterpreted_option repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message MessageOptions { // 设为true则使用老的proto1 MessageSet wire format……兼容性目的，没必要使用 optional bool message_set_wire_format = 1 [default=false]; // 禁用标准的descriptor()方法的生成，因为如果有个字段名是descriptor的话会生 // 成一个同名的函数，会冲突。这使得从proto1迁移到后续版本更简单，但是新版本 // 中还是应该避免使用字段descriptor。 optional bool no_standard_descriptor_accessor = 2 [default=false]; // parser将不识别的选项存储在这个字段里 repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message FieldOptions { // 开启packed选项之后，对于repeated基本数据类型字段的表示会更加高效。不再针 // 对repeated字段中的各个元素执行写tag、类型操作，而是将整个数组作为一个固定 // 长度的blob来存储。 optional bool packed = 2; // 当前字段是否需要lazy parsing？只是建议，lazy为true，protoc不一定lazy parsing optional bool lazy = 5 [default=false]; // 当前字段是否已经被废弃，跟目标平台相关，这个字段可以为生成的accessor方法 // 生成Deprecated注解，如果目标平台不支持就会忽略这个选项。不管目标平台是否 // 支持，proto里面要想废弃一个字段加deprecated选项还是非常正确的做法。 optional bool deprecated = 3 [default=false]; // map字段，目前还未完全实现，应避免使用 optional string experimental_map_key = 9; // google内部迁移使用，因避免使用 optional bool weak = 10 [default=false]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumOptions { // 不允许将多个不同的tag names映射到一个相同的值 // - 意思是说不允许多个字段的编号相同 optional bool allow_alias = 2 [default=true]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumValueOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message ServiceOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message MethodOptions { // 注意：字段编号1~32被保留给google内部rpc框架使用，google的解释是，在 // protobuf被公开给外部使用之前内部就已经大量使用了，且1~32倍使用的很多，也 // 是不得已的事情，总不能为了开源、推广一个内部组件就把自己的生意砸了吧。 // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } // 描述一个parser不认识的option message // - UninterpretedOption只会出现在compiler::Parser类创建的options protos中； // - 构建Descriptor对象的时候DescriptorPool会解析UninterpretedOptions； // 因此，descriptor对象中的options protos（通过Descriptor::options()返回，或者 // 通过Descriptor::CopyTo()生成）是不会包括UinterpretedOptions的。 message UninterpretedOption { // uinterpreted选项的名字，name中每个元素的name_part字段都表示name中的点分字 // 符串的一段，如果name_part是一个扩展（通过在字符串两端用括号括起来表示）， // is_extension字段为true。 // 例如，{[\u0026quot;foo\u0026quot;, false], [\u0026quot;bar.baz\u0026quot;,true], [\u0026quot;qux\u0026quot;,false]}表示\u0026quot;foo.(bar.baz).qux\u0026quot;。 message NamePart { required string name_part = 1; required bool is_extension = 2; } repeated NamePart name = 2; // uinterpreted选项的值，会设置下面字段中其中一个的值 optional string identifier_value = 3; optional uint64 positive_int_value = 4; optional int64 negative_int_value = 5; optional double double_value = 6; optional bytes string_value = 7; optional string aggregate_value = 8; } // =================================================================== // Optional source code info // FileDescriptorProto是从之前的source file中生成的（source file指的是proto文 // 件），这里的SourceCodeInfo指的是proto中的“源代码”信息。 message SourceCodeInfo { // Location用于识别proto文件中的源代码片段，往往对应着一个特定的定义。这些 // Location信息对于IDE、代码索引工具、文档生成工具等是非常重要的。 // // 下面说明一下Location的概念和作用，以下面这个message为例： // message Foo { // optional string foo = 1; // } // 我们先只看上面这个message中的字段定义： // optional string foo = 1; // ^ ^^ ^^ ^ ^^^ // a bc de f ghi // 我们可以得到下面这几个Location： // span path represents // [a,i) [ 4, 0, 2, 0 ] The whole field definition. // [a,b) [ 4, 0, 2, 0, 4 ] The label (optional). // [c,d) [ 4, 0, 2, 0, 5 ] The type (string). // [e,f) [ 4, 0, 2, 0, 1 ] The name (foo). // [g,h) [ 4, 0, 2, 0, 3 ] The number (1). // // 每个proto文件解析之后用一个FileDescriptorProto来表示，所以Lcoation路径位 // 置从FileDescriptorProto开始。 // - 因为message Foo是一个message，proto中所有顶层message类型定义都在 // FileDescriptorProto中message_type字段存储，这个字段的tag是4，所以Location为[4]； // - 又因为message_type是repeated DescriptorProto类型，因为当前proto示例中 // Foo为第一个message，所以其在message_type列表中的索引值为0，所以Location为[4,0]； // - 因为我们现在看的“源代码”是“optional string foo = 1;”，我们需要定位到 // message中的字段位置，message Foo中的所有字段都在DescriptorProto中的field字 // 段中记录，这个字段的tag=2，所以Location变为[4,0,2]； // - 又因为这个DescriptorProto中的field为repeated FieldDescriptorProto field， // 因为这个message中只有一个字段foo，所以foo在field列表中的索引值为0，Location变为[4,0,2,0]; // 上面解释了定位到完整的“optional string foo = 1”定义这个field的Location变 // 化过程，下面再说一下label、type、name、number的Location如何进一步确定。 // FieldDescriptorProto中label的tag位4，type的tag为5，name的tag为1，number的 // tag为3，Location对应的追加索引4、5、1、3。gg! // // proto文件中的源代码信息就是由一系列的Location来寻址的。 repeated Location location = 1; message Location { // 前面已经描述了Location的确定过程，一个Location如[4,0,2,0]其中的数字要么 // 是字段的tag编号要么是repeated列表中的索引值，这里的数字构成的数组保存在 // path中。 repeated int32 path = 1 [packed=true]; // 该字段span总是包括3个或者4个元素，依次表示startline、startcolumn、endline、endcolumn repeated int32 span = 2 [packed=true]; // 如果这个SourceCodeInfo代表一个完整的声明的话，可能在这个声明的前面或者 // 后面可能有一些attached的注释。 // // 连续的多个行注释看做是一个单独的注释。 // // 这个字段只记录了注释内容，不包括注释内容开头的注释符号//。对于块注释， // 注释前面的空白字符、*这几种符号也会被清理掉。但是会包括换行符。 // // Examples: // // optional int32 foo = 1; // Comment attached to foo. // // Comment attached to bar. // optional int32 bar = 2; // // optional string baz = 3; // // Comment attached to baz. // // Another line attached to baz. // // // Comment attached to qux. // // // // Another line attached to qux. // optional double qux = 4; // // optional string corge = 5; // /* Block comment attached // * to corge. Leading asterisks // * will be removed. */ // /* Block comment attached to // * grault. */ // optional int32 grault = 6; // Location前面的注释信息 optional string leading_comments = 3; // Location后面的注释信息 optional string trailing_comments = 4; } }  2.3. 可以提取proto文件中的哪些信息 \u0026amp; 如何提取 # 前一节2.2中对descriptor.proto进行了详细地描述，可以说在proto文件中写的每一行内容都可以通过解析FileDescriptorProto来访问到。proto文件只是一种自描述的消息格式，基于这种格式生成面向特定编程语言的源代码文件时，我们想获取的信息不外乎如下几个：\n 待生成的源文件的包名； 待生成的源文件的wrapper class类名； proto文件中定义的各个类型，包括枚举enum、消息message、服务service； 对于枚举enum需要知道枚举类型名、列出的枚举值（包括字段、值、注释信息）、注释信息； 对于消息message需要知道类型名、类成员（包括成员类型、成员名称、定义顺序、默认值、注释信息）、注释信息； 对于服务service需要知道服务名称、服务rpc接口（rpc接口的请求参数、返回值类型、注释信息）、注释信息； proto中可以添加注解吗？注解可以提取出来吗？  如何提取上述信息呢？可以肯定地是，只要能拿到当前proto文件对应的FileDescriptorProto，上述内容几乎都可以获取到。但是如何获取到对应的proto文件对应的这个FileDescriptorProto对象呢？下面我们先来看一个protoc-gen-go这个插件的示例代码吧，看完之后，大家也就了解了如何获取proto对应的FileDescriptorProto以及如何从中提取想要的上述1~7部分的信息，生成源代码文件也就简单了。\n2.4. proto-gen-go源代码分析 # 2.4.1. protoc-gen-go入口函数 # file: protobuf/protoc-gen-go/main.go\npackage main import ( \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; \u0026quot;github.com/c4pt0r/proto\u0026quot; \u0026quot;github.com/c4pt0r/protoc-gen-go/generator\u0026quot; ) func main() { // 首先创建一个代码生成器generator，CodeGeneratorRequest、CodeGeneratorResponse // 结构体都被保存在generator中，CodeGenerateResponse中保存着代码生成过程中 // 的错误状态信息，因此我们可以通过这个结构体提取错误状态并进行错误处理 g := generator.New() // 从标准输入中读取CodeGeneratorRequest信息（标准输入已经被重定向到了父进程 // protoc进程创建的管道stdout_pipe的读端，父进程会从管道的写端写入该请求信息） data, err := ioutil.ReadAll(os.Stdin) if err != nil { g.Error(err, \u0026quot;reading input\u0026quot;) } // 读取到的数据时串行化之后的CodeGeneratorRequest，将其反串行化成CodeGeneratorRequest if err := proto.Unmarshal(data, g.Request); err != nil { g.Error(err, \u0026quot;parsing input proto\u0026quot;) } // 检查CodeGeneratorRequest中待生成的源代码文件数量，数量为0则无需生成 if len(g.Request.FileToGenerate) == 0 { g.Fail(\u0026quot;no files to generate\u0026quot;) } // 将CodeGeneratorRequest中传递给代码生成器的参数设置到protoc插件的代码生成器中 g.CommandLineParameters(g.Request.GetParameter()) // 前面的proto.Unmarshal(...)操作将stdin中的请求反串行化成了CodeGeneratorRequest， // 这里的g.WrapTypes()将请求中的一些descriptors进行进一步封装，方便后面引用 g.WrapTypes() g.SetPackageNames() g.BuildTypeNameMap() // 生成所有的源代码文件 g.GenerateAllFiles() // 将CodeGeneratorResponse对象进行串行化处理 data, err = proto.Marshal(g.Response) if err != nil { g.Error(err, \u0026quot;failed to marshal output proto\u0026quot;) } // 将串行化之后的CodeGenerateResponse对象数据写入标准输出（标准输出已经被 // 重定向到了父进程protoc进程创建的管道stdin_pipe的写端，父进程从管道的读 // 端读取这里的响应） _, err = os.Stdout.Write(data) if err != nil { g.Error(err, \u0026quot;failed to write output proto\u0026quot;) } }  2.4.2. 回顾一下CodeGeneratorRequest \u0026amp; CodeGeneratorResponse的定义 # 下面看下CodeGeneratorRequest和CodeGeneratorResponse的定义。\nfile: ${protobuf}/src/google/protobuf/compiler/plugin.go\n// 串行化后的CodeGeneratorRequest信息会被写入到插件程序的stdin message CodeGeneratorRequest { // protoc命令执行时，我们在命令行中列出了需要进行处理的.proto文件的名称，代 // 码生成器应该只为这些.proto文件生成源代码文件。每一个.proto文件成功解析之 // 后会生成一个FileDescriptorProto对象，这个对象会被加入到字段proto_file中 repeated string file_to_generate = 1; // protoc命令行程序中传递给插件程序代码生成器的参数信息 optional string parameter = 2; // protoc命令行中列出的所有的.proto文件被添加到了字段file_to_generate中，这 // 些.proto文件中通过import引入进来的文件，这两部分文件解析成功后对应的 // FileDescriptorProto对象都会被加入到这里的proto_file中，添加后的顺序是按照 // 拓扑顺序排序的，怎么讲？就是被import的proto文件会出现在import它们的 proto // 文件前面。 repeated FileDescriptorProto proto_file = 15; } // 串行化后的CodeGeneratorResponse信息会被写入到插件的stdout message CodeGeneratorResponse { // 如果错误信息非空，表示代码生成失败。这种情况下尽管代码生成失败，插件进程 // 仍然应该返回一个状态0。 // // 这个字段用于指示.proto文件错误，.proto文件中的错误将使得代码生成器无法生 // 成正确的代码。指示protoc本身的错误，例如CodeGeneratorRequest数据无法被正 // 确地反串行化，这种情况应该被报告，错误信息应该写到stderr并且插件进程应该 // 返回一个非0状态码 optional string error = 1; // 描述一个待生成的源代码文件 message File { // 待生成的源代码文件相对于输出目录的文件名 optional string name = 1; // 写入到源代码文件中的插入点信息，方便后面的插件在插入点处进行扩展其他内容 optional string insertion_point = 2; // 写入到文件或者文件插入点位置的内容 optional string content = 15; } // 所有的待生成的源代码文件列表 repeated File file = 15; }  2.4.3. proto-gen-go generator实现分析 # main.go中调用了generator的几个关键方法，我们先来看下这几个方法都做了些什么，然 后再跟进一步看看generator的详细实现过程。\n2.4.3.1. generator.New() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// Generator类型的方法能够输出源代码，这些输出的源代码信息存储在Response成员中 type Generator struct { *bytes.Buffer Request *plugin.CodeGeneratorRequest // The input. Response *plugin.CodeGeneratorResponse // The output. Param map[string]string // Command-line parameters. PackageImportPath string // Go import path of the package we're generating code for ImportPrefix string // String to prefix to imported package file names. ImportMap map[string]string // Mapping from .proto file name to import path Pkg map[string]string // The names under which we import support packages packageName string // What we're calling ourselves. allFiles []*FileDescriptor // All files in the tree allFilesByName map[string]*FileDescriptor // All files by filename. genFiles []*FileDescriptor // Those files we will generate output for. file *FileDescriptor // The file we are compiling now. usedPackages map[string]bool // Names of packages used in current file. typeNameToObject map[string]Object // Key is a fully-qualified name in input syntax. init []string // Lines to emit in the init function. indent string writeOutput bool } // 创建一个新的代码生成器，并创建请求、响应对象 func New() *Generator { g := new(Generator) g.Buffer = new(bytes.Buffer) g.Request = new(plugin.CodeGeneratorRequest) g.Response = new(plugin.CodeGeneratorResponse) return g }  2.4.3.2. generator.CommandLineParameters(\u0026hellip;) # 这个函数是负责解析protoc传递过来的命令行参数信息的。\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 将都好分隔的key=value列表解析成\u0026lt;key,value\u0026gt; map func (g *Generator) CommandLineParameters(parameter string) { g.Param = make(map[string]string) for _, p := range strings.Split(parameter, \u0026quot;,\u0026quot;) { if i := strings.Index(p, \u0026quot;=\u0026quot;); i \u0026lt; 0 { g.Param[p] = \u0026quot;\u0026quot; } else { g.Param[p[0:i]] = p[i+1:] } } g.ImportMap = make(map[string]string) pluginList := \u0026quot;none\u0026quot; // Default list of plugin names to enable (empty means all). for k, v := range g.Param { switch k { case \u0026quot;import_prefix\u0026quot;: g.ImportPrefix = v case \u0026quot;import_path\u0026quot;: g.PackageImportPath = v // --go_out=plugins=grpc:.，解析这里的参数plugins=grpc case \u0026quot;plugins\u0026quot;: pluginList = v default: if len(k) \u0026gt; 0 \u0026amp;\u0026amp; k[0] == 'M' { g.ImportMap[k[1:]] = v } } } // 在protoc-gen-go的某个地方已经将grpc插件注册到了当前generator（也就是添 // 加到plugins []Plugin中），但是到底是在哪里注册的呢？只有注册并激活（参 // 数中通过--go_out=plugins=grpc:.)grpc子插件，该子插件才能被使用于后续的 // 代码生成过程中（生成rpc相关的go源代码）。 // // 其实这里的grpc子插件注册是利用了link_grpc.go里面的import _操作来隐式地 // 调用了grpc.init()方法，该初始化方法中负责完成向generator的注册操作，即 // generator.RegisterPlugin(new(grpc))，这里的RegisterPlugin其实就是将指定 // 的子插件加入到plugins []Plugin slice中。 // 为了能够在protoc-gen-go中正确地将grpc link进去，在构建protoc-gen-go的时 // 候需要执行命令： // cd protoc-gen-go \u0026amp; go build main.go link_grpc.go // go build的时候如果没有列出link_grpc.go，那么grpc是不会被link进 // protoc-gen-go这个插件的，这样处理.proto文件中的service时插件是不会生成 // service相关的go源代码的。 // 根据--go_out=plugins=?+?+?:.，更新激活的插件列表 if pluginList != \u0026quot;\u0026quot; { // Amend the set of plugins. enabled := make(map[string]bool) for _, name := range strings.Split(pluginList, \u0026quot;+\u0026quot;) { enabled[name] = true } var nplugins []Plugin for _, p := range plugins { if enabled[p.Name()] { nplugins = append(nplugins, p) } } plugins = nplugins } }  2.4.3.3. generator.WrapTypes() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// WrapTypes walks the incoming data, wrapping DescriptorProtos, EnumDescriptorProtos // and FileDescriptorProtos into file-referenced objects within the Generator. // It also creates the list of files to generate and so should be called before GenerateAllFiles. func (g *Generator) WrapTypes() { g.allFiles = make([]*FileDescriptor, 0, len(g.Request.ProtoFile)) g.allFilesByName = make(map[string]*FileDescriptor, len(g.allFiles)) for _, f := range g.Request.ProtoFile { // We must wrap the descriptors before we wrap the enums descs := wrapDescriptors(f) g.buildNestedDescriptors(descs) enums := wrapEnumDescriptors(f, descs) g.buildNestedEnums(descs, enums) exts := wrapExtensions(f) fd := \u0026amp;FileDescriptor{ FileDescriptorProto: f, desc: descs, enum: enums, ext: exts, exported: make(map[Object][]symbol), proto3: fileIsProto3(f), } extractComments(fd) g.allFiles = append(g.allFiles, fd) g.allFilesByName[f.GetName()] = fd } for _, fd := range g.allFiles { fd.imp = wrapImported(fd.FileDescriptorProto, g) } g.genFiles = make([]*FileDescriptor, 0, len(g.Request.FileToGenerate)) for _, fileName := range g.Request.FileToGenerate { fd := g.allFilesByName[fileName] if fd == nil { g.Fail(\u0026quot;could not find file named\u0026quot;, fileName) } fd.index = len(g.genFiles) g.genFiles = append(g.genFiles, fd) } }  2.4.3.4. generator.GenerateAllFiles() # 调用generator针对所有解析成功的proto文件生成所有的go源代码\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 生成所有.proto文件对应的go源代码，这里只是将源代码内容存储到g.Response中， // 并没有直接创建源代码文件，插件将Response传递给protoc进程后由protoc进程来负 // 责创建源代码文件 func (g *Generator) GenerateAllFiles() { // Initialize the plugins for _, p := range plugins { p.Init(g) } // Generate the output. The generator runs for every file, even the files // that we don't generate output for, so that we can collate the full list // of exported symbols to support public imports. genFileMap := make(map[*FileDescriptor]bool, len(g.genFiles)) for _, file := range g.genFiles { genFileMap[file] = true } for _, file := range g.allFiles { g.Reset() g.writeOutput = genFileMap[file] // 调用generator的generate(...)方法来生成该proto文件的 // FileDescriptorProto描述对应的go源代码 g.generate(file) if !g.writeOutput { continue } g.Response.File = append(g.Response.File, \u0026amp;plugin.CodeGeneratorResponse_File{ Name: proto.String(file.goFileName()), Content: proto.String(g.String()), }) } }  再看下generator.generate(\u0026hellip;)方法是如何实现的。\n// 针对.proto文件（由FileDescriptor表示）生成对应的go源代码 func (g *Generator) generate(file *FileDescriptor) { g.file = g.FileOf(file.FileDescriptorProto) g.usedPackages = make(map[string]bool) // 要生成源代码的首个proto文件对应的go源代码，这部分代码顶部插入版权信息 if g.file.index == 0 { // For one file in the package, assert version compatibility. g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the proto package it is being compiled against.\u0026quot;) g.P(\u0026quot;// A compilation error at this line likely means your copy of the\u0026quot;) g.P(\u0026quot;// proto package needs to be updated.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, g.Pkg[\u0026quot;proto\u0026quot;], \u0026quot;.ProtoPackageIsVersion\u0026quot;, generatedCodeVersion, \u0026quot; // please upgrade the proto package\u0026quot;) g.P() } // 生成import语句 for _, td := range g.file.imp { g.generateImported(td) } // 生成enum类型定义语句 for _, enum := range g.file.enum { g.generateEnum(enum) } // 生成message类型定义语句 for _, desc := range g.file.desc { // Don't generate virtual messages for maps. if desc.GetOptions().GetMapEntry() { continue } g.generateMessage(desc) } // 生成extension类型定义语句 for _, ext := range g.file.ext { g.generateExtension(ext) } // 生成初始化函数语句 g.generateInitFunction() // 前面生成enum、message、extension等的方式都基本类似，后面我们只给出一个 // 生成枚举类型方法的说明，生成message、extension的实现方法可以执行查看 // generator.go中的实现。 // // 需要注意的是，前面的各个生成源代码的方法不能处理service服务定义的rpc接 // 口代码，这部分rpc代码的生成需要借助于grpc子插件来完成，即下面的g.runPlugins(...) g.runPlugins(file) g.generateFileDescriptor(file) // 待输出的源代码需要知道哪些package是需要import的，哪些不需要，因此先运行 // 插件生成go代码中除import之外的其他部分代码，然后知道了哪些package需要 // import，再插入具体的import语句。 // // 最后在go源代码中插入header、import rem := g.Buffer g.Buffer = new(bytes.Buffer) g.generateHeader() g.generateImports() if !g.writeOutput { return } g.Write(rem.Bytes()) // 重新格式化生成的go源代码（gofmt） fset := token.NewFileSet() raw := g.Bytes() ast, err := parser.ParseFile(fset, \u0026quot;\u0026quot;, g, parser.ParseComments) if err != nil { // Print out the bad code with line numbers. // This should never happen in practice, but it can while changing generated code, // so consider this a debugging aid. var src bytes.Buffer s := bufio.NewScanner(bytes.NewReader(raw)) for line := 1; s.Scan(); line++ { fmt.Fprintf(\u0026amp;src, \u0026quot;%5d\\t%s\\n\u0026quot;, line, s.Bytes()) } g.Fail(\u0026quot;bad Go source code was generated:\u0026quot;, err.Error(), \u0026quot;\\n\u0026quot;+src.String()) } g.Reset() err = (\u0026amp;printer.Config{Mode: printer.TabIndent | printer.UseSpaces, Tabwidth: 8}).Fprint(g, fset, ast) if err != nil { g.Fail(\u0026quot;generated Go source code could not be reformatted:\u0026quot;, err.Error()) } }  上面generate.generate(\u0026hellip;)方法中generateEnum()、generateMessage()方法与其他几个方法都是非常类似的，由于大家使用protobuf过程中使用enum、message比较多，并且generateEnum()、generateMessage()方法执行逻辑非常相似，考虑到篇幅方面generateEnum()比generateMessage()简短，这里我们就只以generateEnum()的源代码作为示例进行分析。相信如果看懂了generateEnum的实现思路，generateMessage的实现思路也很容易搞明白，读者也具备了自己实现子插件的能力。\n// 生成指定enum类型的go源代码 func (g *Generator) generateEnum(enum *EnumDescriptor) { // enum类型的完整类型名 typeName := enum.TypeName() // CamelCased之后的完整类型名 ccTypeName := CamelCaseSlice(typeName) ccPrefix := enum.prefix() // 打印enum类型定义之前的leading comments // - 提取源代码信息SourceCodeInfo都是通过Location path来获取的； // - 提取注释信息也不例外，下面我们会介绍PrintComments(path)如何通过 // Location path来生成注释信息； g.PrintComments(enum.path) // 生成枚举类型的定义起始部分：type 枚举类型名 int32 g.P(\u0026quot;type \u0026quot;, ccTypeName, \u0026quot; int32\u0026quot;) g.file.addExport(enum, enumSymbol{ccTypeName, enum.proto3()}) // 枚举类型里面的各个枚举值都作为const int32常量来定义 g.P(\u0026quot;const (\u0026quot;) // 枚举值定义之前缩进一下 g.In() // 针对枚举类型里面的所有枚举值进行源代码生成 for i, e := range enum.Value { // 生成枚举值前面的leading comments g.PrintComments(fmt.Sprintf(\u0026quot;%s,%d,%d\u0026quot;, enum.path, enumValuePath, i)) // 生成枚举值的name = value形式的go源代码 name := ccPrefix + *e.Name g.P(name, \u0026quot; \u0026quot;, ccTypeName, \u0026quot; = \u0026quot;, e.Number) g.file.addExport(enum, constOrVarSymbol{name, \u0026quot;const\u0026quot;, ccTypeName}) } // 枚举值定义完之后取消缩进 g.Out() // 打印最后的结束信息 g.P(\u0026quot;)\u0026quot;) // 生成枚举类型相关的两个map // - 其中一个是枚举值到枚举名的映射； // - 另一个是枚举名到枚举值的映射； g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_name = map[int32]string{\u0026quot;) g.In() // 第一个map generated := make(map[int32]bool) // avoid duplicate values for _, e := range enum.Value { duplicate := \u0026quot;\u0026quot; if _, present := generated[*e.Number]; present { duplicate = \u0026quot;// Duplicate value: \u0026quot; } g.P(duplicate, e.Number, \u0026quot;: \u0026quot;, strconv.Quote(*e.Name), \u0026quot;,\u0026quot;) generated[*e.Number] = true } g.Out() g.P(\u0026quot;}\u0026quot;) // 第二个map g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_value = map[string]int32{\u0026quot;) g.In() for _, e := range enum.Value { g.P(strconv.Quote(*e.Name), \u0026quot;: \u0026quot;, e.Number, \u0026quot;,\u0026quot;) } g.Out() g.P(\u0026quot;}\u0026quot;) // 其他处理动作，也会生成部分源代码，这里可以忽略不计了 // ... }  下面看一下PrintComments如何通过Location path来提取并打印关联的注释信息。\n// 打印.proto文件中对该location path关联的leading comments注释信息 func (g *Generator) PrintComments(path string) bool { if !g.writeOutput { return false } // 在protoc进程解析.proto文件的时候就已经将各个类型、字段的comments信息维 // 护起来了，k就是location的path，通过path就能获取到对应的location，每个 // location中保存了这个位置的源代码的leading comments、trailing comments信 // 息，这里只打印leading comments if loc, ok := g.file.comments[path]; ok { text := strings.TrimSuffix(loc.GetLeadingComments(), \u0026quot;\\n\u0026quot;) for _, line := range strings.Split(text, \u0026quot;\\n\u0026quot;) { g.P(\u0026quot;// \u0026quot;, strings.TrimPrefix(line, \u0026quot; \u0026quot;)) } return true } return false }  看到这里我们对于基本的enum、message类型定义等都基本清楚了，下面我们需要看一下grpc子插件是如何生成service服务的rpc接口源代码的，这样的话，就得再来看一下g.runPlugins(file)是如何实现的。\n// Run all the plugins associated with the file. func (g *Generator) runPlugins(file *FileDescriptor) { // 在上述generator处理的基础上，继续运行generator中注册的插件，依次运行插件 for _, p := range plugins { p.Generate(file) } }  2.4.4. protoc-gen-go grpc子插件实现 # 因为上述2.4.3.4节中runPlugins(\u0026hellip;)的执行过程中，plugins这个slice内只有一个有效的、激活的子插件grpc，因此如果我们想了解service服务对应的rpc接口源代码是如何生成的话，查看一下grpc这个插件的Generate(file)方法就可以了。\n// 生成.proto文件中service定义的rpc接口的go源代码 func (g *grpc) Generate(file *generator.FileDescriptor) { // 如果没有定义service服务直接返回 if len(file.FileDescriptorProto.Service) == 0 { return } // 相关变量定义 g.P(\u0026quot;// Reference imports to suppress errors if they are not otherwise used.\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, contextPkg, \u0026quot;.Context\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P() // 断言，检查版本兼容性 g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the grpc package it is being compiled against.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, grpcPkg, \u0026quot;.SupportPackageIsVersion\u0026quot;, generatedCodeVersion) g.P() // 针对所有的service定义生成相关的service的go源代码 for i, service := range file.FileDescriptorProto.Service { g.generateService(file, service, i) } } // grpc中对generateService的实现，生成service相关的go源代码 // @param .proto解析后的各种DescriptorProto的wrapping类，通过它可以方便地访问.proto中定义的东西 // @param .proto中的某个service解析后对应的ServiceDescriptorProto // @param .proto中可能定义了多个service，当前这个service对应的索引值 func (g *grpc) generateService(file *generator.FileDescriptor, service *pb.ServiceDescriptorProto, index int) { // 构建当前service对应的path! path := fmt.Sprintf(\u0026quot;6,%d\u0026quot;, index) // 6 means service. // 获取service名称 origServName := service.GetName() fullServName := origServName if pkg := file.GetPackage(); pkg != \u0026quot;\u0026quot; { fullServName = pkg + \u0026quot;.\u0026quot; + fullServName } servName := generator.CamelCase(origServName) // 准备生成client相关的go源代码 g.P() g.P(\u0026quot;// Client API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务用户端go源代码生成 // - type 服务名+Client interface g.P(\u0026quot;type \u0026quot;, servName, \u0026quot;Client interface {\u0026quot;) // - 服务用户端定义的各个接口方法 for i, method := range service.Method { // 打印接口的leading comments g.gen.PrintComments(fmt.Sprintf(\u0026quot;%s,2,%d\u0026quot;, path, i)) // 2 means method in a service. // 生成接口的签名 g.P(g.generateClientSignature(servName, method)) } g.P(\u0026quot;}\u0026quot;) g.P() // 服务的用户端struct，其中包括了一个cc *grpc.ClientConn，后面会在该struct // 上实现上述服务接口 g.P(\u0026quot;type \u0026quot;, unexport(servName), \u0026quot;Client struct {\u0026quot;) g.P(\u0026quot;cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() // NewClient工厂 g.P(\u0026quot;func New\u0026quot;, servName, \u0026quot;Client (cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn) \u0026quot;, servName, \u0026quot;Client {\u0026quot;) g.P(\u0026quot;return \u0026amp;\u0026quot;, unexport(servName), \u0026quot;Client{cc}\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() var methodIndex, streamIndex int serviceDescVar := \u0026quot;_\u0026quot; + servName + \u0026quot;_serviceDesc\u0026quot; // 服务用户端的接口方法实现 for _, method := range service.Method { var descExpr string if !method.GetServerStreaming() \u0026amp;\u0026amp; !method.GetClientStreaming() { // Unary RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Methods[%d]\u0026quot;, serviceDescVar, methodIndex) methodIndex++ } else { // Streaming RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Streams[%d]\u0026quot;, serviceDescVar, streamIndex) streamIndex++ } g.generateClientMethod(servName, fullServName, serviceDescVar, method, descExpr) } g.P(\u0026quot;// Server API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务端接口go源代码生成 ... }  到这里为止，已经描述了protoc-gen-go中的generator做了哪些工作，与之协作的grpc又做了什么，一句话概括就是：generator负责生成除service之外的其他go代码，grpc负责生成service相关的go代码。在描述protoc-gen-go实现的过程中我们也描述了哪些信息该从哪里提取，比如定义的message类型、enum类型、service及其注释等信息。相信看到这里，读者应该可以独立开发一个protoc插件了吧。\n3. 总结 # 本文结合protoc源代码、protoc-gen-go源代码，对protoc、protoc插件工作原理进行了较为详细的分析、总结，希望能对想了解这方面内容或者有意向开发protoc插件扩展protoc功能的读者有帮助。\n由于本人水平有限，可能有理解不到位甚至错误的地方，也欢迎大家指出来。\n"}),a.add({id:489,href:"/blog/2017-05-16-protoc%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/",title:"Protoc工作原理分析",description:"团队经常使用protobuf作为消息交换格式，由于protobuf具有很强的自描述性，非常适合对一个服务进行建模。结合配套的编译器protoc，可以轻松理解服务信息，在此基础上可以开发一些脚手架工具（如protoc-gen-go）来完成代码生成、接口自动测试、生成api文档等等工作。本文就来介绍下protoc及其插件的工作原理，读完后读者将具备定制化protoc插件开发的能力。",content:"在进行protoc插件开发之前，首先要了解protoc的工作原理。在protobuf的使用过程中，protoc作为proto文件的编译器，很多开发人员只会用但是不了解其工作原理，更不了解如何扩展其功能。protobuf作为目前常用的数据交换格式在协议开发中被广泛采用，此外，protoc对proto文件的强大解析能力使我们可以开发一些插件，通过插件快速生成特定于proto文件的工具类、配置文件等，从而提高开发效率。\n本文首先会介绍一下protoc的整体工作机制，然后解释一下protoc对proto文件的解析过程，最后给出编写protoc插件扩展protoc功能的一个示例教程。\n1. protoc源代码准备 # 要想了解protoc的工作机制，查看其源代码了解其核心流程是最靠谱的方法。\n获取程序源代码的方式如下：\ngit co https://github.com/google/protobuf  由于我们工程中常用的protoc版本是v2.5.0，所以这里检出对应版本的tag。\ngit ck v2.5.0  考虑到可能会进行测试、修改、注释等学习过程，这里最好创建一个新的分支来操作。\ngit branch ${new-branch-name} git ck ${new-branch-name}  现在源代码准备好了，我比较喜欢使用vim、ctags、cscope来阅读源码，根据个人习惯吧，下面可以阅读protoc的源码梳理以下工作机制。\n2. protoc源码分析 # 上述git检出后的protobuf路径，记为${protobuf}，后面如果出现${protobuf}请知晓其含义。如果在描述源代码时没有提及起始路径${protobuf}，那么起始路径均为${protobuf}。\n2.1. protoc程序入口 # src/google/protobuf/compiler/main.cc中的main函数，为protoc的入口函数。\nfile: src/google/protobuf/compiler/main.cc\n// Author: kenton@google.com (Kenton Varda) // 这个头文件定义了protoc的命令行接口 #include \u0026lt;google/protobuf/compiler/command_line_interface.h\u0026gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include \u0026lt;google/protobuf/compiler/cpp/cpp_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/python/python_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/java/java_generator.h\u0026gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件 // - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头 // - 假定protoc --foo_out，那么实际调用的插件是protoc-foo google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(\u0026quot;protoc-\u0026quot;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator) google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026quot;--cpp_opt\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ header and source.\u0026quot;); // Proto2 Java (指定了--java_out将调用java::Generator) google::protobuf::compiler::java::JavaGenerator java_generator; cli.RegisterGenerator(\u0026quot;--java_out\u0026quot;, \u0026amp;java_generator, \u0026quot;Generate Java source file.\u0026quot;); // Proto2 Python (指定了python_out将调用python::Generator) google::protobuf::compiler::python::Generator py_generator; cli.RegisterGenerator(\u0026quot;--python_out\u0026quot;, \u0026amp;py_generator, \u0026quot;Generate Python source file.\u0026quot;); // 解析proto、生成源代码(借助内置的generator或者plugins)、创建源代码文件 return cli.Run(argc, argv); }  2.2. protoc命令行接口定义 # 下面看一下protoc的命令行接口定义，以了解其对命令行flags、options的解释过程以及对后续程序执行逻辑的影响。\nfile: src/google/protobuf/compiler/command_line_interface.h\n// Author: kenton@google.com (Kenton Varda) // Based on original Protocol Buffers design by // Sanjay Ghemawat, Jeff Dean, and others. // // Implements the Protocol Compiler front-end such that it may be reused by // custom compilers written to support other languages. #ifndef GOOGLE_PROTOBUF_COMPILER_COMMAND_LINE_INTERFACE_H__ #define GOOGLE_PROTOBUF_COMPILER_COMMAND_LINE_INTERFACE_H__ #include \u0026lt;google/protobuf/stubs/common.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;map\u0026gt; #include \u0026lt;set\u0026gt; #include \u0026lt;utility\u0026gt; namespace google { namespace protobuf { //proto文件中定义的数据类型可通过FileDescriptor来遍历、查看 class FileDescriptor; // descriptor.h class DescriptorPool; // descriptor.h class FileDescriptorProto; // descriptor.pb.h template\u0026lt;typename T\u0026gt; class RepeatedPtrField; // repeated_field.h namespace compiler { class CodeGenerator; // code_generator.h class GeneratorContext; // code_generator.h class DiskSourceTree; // importer.h // 这个类实现了protoc的命令行接口，使得protoc很容易扩展。 // 例如我们想让protoc既支持cpp又支持另一种语言foo，那么我们可以定义一个实现了 // CodeGenerator接口的FooGenerator，然后在protoc的main方法中对这两种语言cpp、Foo // 及其对应的CodeGenerator进行注册。 // // int main(int argc, char* argv[]) { // google::protobuf::compiler::CommandLineInterface cli; // // // 支持cpp // google::protobuf::compiler::cpp::CppGenerator cpp_generator; // cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ source and header.\u0026quot;); // // // 支持foo // FooGenerator foo_generator; // cli.RegisterGenerator(\u0026quot;--foo_out\u0026quot;, \u0026amp;foo_generator, \u0026quot;Generate Foo file.\u0026quot;); // // return cli.Run(argc, argv); // } // // The compiler is invoked with syntax like: // protoc --cpp_out=outdir --foo_out=outdir --proto_path=src src/foo.proto // // For a full description of the command-line syntax, invoke it with --help. class LIBPROTOC_EXPORT CommandLineInterface { public: CommandLineInterface(); ~CommandLineInterface(); // 为某种编程语言注册一个对应的代码生成器（其实这里也不一定非得是语言） // // 命令行接口的参数: // @param flag_name 指定输出文件类型的命令，例如--cpp_out，参数名字必须以“-”开头， 如果名字大于两个字符，则必须以“--”开头。 // @param generator 与flag_name对应的CodeGenerator接口实现 // @param help_text 执行protoc --help的时候对这里的flag_name的说明性信息 // // 某些代码生成器可接受额外参数，这些参数在输出路径之前给出，与输出路径之间用“:”分隔。 // protoc --foo_out=enable_bar:outdir // 这里的:outdir之前的enable_bar被作为参数传递给CodeGenerator::Generate()的参数。 void RegisterGenerator(const string\u0026amp; flag_name, CodeGenerator* generator, const string\u0026amp; help_text); // 为某种编程语言注册一个对应的代码生成器 // ... // @param option_flag_name 指定额外的选项 // ... // // 与前面一个函数RegisterGenerator所不同的是，这个重载函数多个参数 // option_flag_name，通过这个函数注册的语言和代码生成器可以接受额外的参数。例 // 如通过command_line_interface.RegisterGenerator(\u0026quot;--foo_out\u0026quot;, \u0026quot;--foo_opt\u0026quot;, ...) // 注册了foo以及对应代码生成器，那么我们可以在执行protoc 的时候指定额外的参数 // --foo_opt：protoc --foo_out=enable_bar:outdir --foo_opt=enable_baz，此时传 // 递给代码生成器的参数将会包括enable_bar和enable_baz。 void RegisterGenerator(const string\u0026amp; flag_name, const string\u0026amp; option_flag_name, CodeGenerator* generator, const string\u0026amp; help_text); // RegisterGenerator方法是在protoc的main方法中进行语言、代码生成器的注册，在 // 生产环境中不可能允许开发人员肆意修改公用程序库，这意味着我们如果要在稳定地 // protoc v2.5.0基础上进行源码的修改这条路是行不通的，那么如何自由地扩展其功 // 能呢？protoc提供了“plugin”机制，我们可以通过自定义插件来实现对其他语言 //（甚至不是语言）的支持。 // 开启protoc对插件的支持，这种模式下，如果一个命令行选项以_out结尾，例如 // --xxx_out，但是在protoc已经注册的语言支持中没有找到匹配的语言及代码生成器， // 这个时候protoc就会去检查是否有匹配的插件支持这种语言，将这个插件来作为代 // 码生成器使用。这里的的protoc插件是一个$PATH中可搜索到的可执行程序，当然 // 这个可执行程序稍微有点特殊。 // 这里插件名称（可执行程序名称）是如何确定的呢？选项--xxx_out中，截取“xxx”， // 然后根据${exe_name_prefix}以及xxx来拼接出一个插件的名字，假如${exe_name_prefix} // 是protoc-，那么插件的名字就是protoc-xxx，protoc将尝试执行这个程序来完成代 // 码生成的工作。 // 假定插件的名字是plugin，protoc是这样调用这个插件的： // plugin [--out=OUTDIR] [--parameter=PARAMETER] PROTO_FILES \u0026lt; DESCRIPTORS // 选项说明： // --out：指明了插件代码生成时的输出目录（跟通过--foo_out传递给protoc的一样）, // 如果省略这个参数，输出目录就是当前目录。 // --parameter：指明了传递给代码生成器的参数。 // PROTO_FILES：指明了protoc调用时传递给protoc的待处理的.proto文件列表。 // DESCRIPTORS: 编码后的FileDescriptorSet（这个在descriptor.proto中定义）， // 这里编码后的数据通过管道重定向到插件的标准输入，这里的FileDescriptorSet包括 // PROTO_FILES中列出的所有proto文件的descriptors，也包括这些PROTO_FILES中 // proto文件import进来的其他proto文件。插件不应该直接读取PROTO_FILES中的 // proto文件，而应该使用这里的DESCRIPTORS。 // // 插件跟protoc main函数中注册的代码生成器一样，它也需要生成所有必须的文件。 // 插件会将所有要生成的文件的名字写到stdout，插件名字是相对于当前输出目录的。如 // 果插件工作过程中发生了错误，需要将错误信息写到stderr，如果发生了严重错误， // 插件应该退出并返回一个非0的返回码。插件写出的数据会被protoc读取并执行后续 // 处理逻辑。 void AllowPlugins(const string\u0026amp; exe_name_prefix); // 根据指定的命令行参数来执行protocol compiler，返回值将由main返回。 // // Run()方法是非线程安全的，因为其中调用了strerror()，不要在多线程环境下使用。 int Run(int argc, const char* const argv[]); // proto路径解析的控制说明，fixme // Call SetInputsAreCwdRelative(true) if the input files given on the command // line should be interpreted relative to the proto import path specified // using --proto_path or -I flags. Otherwise, input file names will be // interpreted relative to the current working directory (or as absolute // paths if they start with '/'), though they must still reside inside // a directory given by --proto_path or the compiler will fail. The latter // mode is generally more intuitive and easier to use, especially e.g. when // defining implicit rules in Makefiles. void SetInputsAreProtoPathRelative(bool enable) { inputs_are_proto_path_relative_ = enable; } // 设置执行protoc --version时打印的版本相关的信息，这行版本信息的下一行也会打印libprotoc的版本。 void SetVersionInfo(const string\u0026amp; text) { version_info_ = text; } private: // ----------------------------------------------------------------- // 这个类的后续部分代码，虽然也比较重要，但是即便在这里先不解释，也不会给我 // 们的理解造成太多干扰，为了简化篇幅并且避免过早地陷入细节而偏离对整体的把 // 握，这里我先把这个类的后续部分代码进行删减……只保留相对比较重要的。 class GeneratorContextImpl; class MemoryOutputStream; // 清楚上次Run()运行时设置的状态 void Clear(); // 映射input_files_中的每个文件，使其变成相对于proto_path_中对应目录的相对路径 // - 当inputs_are_proto_path_relative_为false的时候才会调用这个函数； // - 出错返回false，反之返回true； bool MakeInputsBeProtoPathRelative(DiskSourceTree* source_tree); // ParseArguments() \u0026amp; InterpretArgument()返回的状态 enum ParseArgumentStatus { PARSE_ARGUMENT_DONE_AND_CONTINUE, PARSE_ARGUMENT_DONE_AND_EXIT, PARSE_ARGUMENT_FAIL }; // 解析所有的命令行参数 ParseArgumentStatus ParseArguments(int argc, const char* const argv[]); // 解析某个命令行参数 // - 参数名放name，参数值放value // - 如果argv中的下一个参数应该被当做value则返回true，反之返回false bool ParseArgument(const char* arg, string* name, string* value); // 解析某个命令行参数的状态 ParseArgumentStatus InterpretArgument(const string\u0026amp; name, const string\u0026amp; value); // 从输入的proto文件生成指定的源代码文件 struct OutputDirective; // 对解析成功的每个proto文件，生成对应的源代码文件 // @param parsed_files 解析成功的proto文件vector // @param output_directive 输出指示，包括了文件名、语言、代码生成器、输出目录 // @param generator_context 代码生成器上下文，可记录待输出文件名、文件内容、尺寸等信息 bool GenerateOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const OutputDirective\u0026amp; output_directive, GeneratorContext* generator_context); // 对解析成功的每个proto文件，调用protoc插件生成对应的源代码 // @param parsed_files 解析成功的proto文件vector // @param plugin_name 插件的名称，命名方式一般是protoc-gen-${lang} // @param parameter 传递给protoc插件的参数 // @param generator_context 代码生成器上下文，可记录待输出文件名、文件内容、尺寸等信息 // @param error 错误信息 bool GeneratePluginOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const string\u0026amp; plugin_name, const string\u0026amp; parameter, GeneratorContext* generator_context, string* error); // 编码、解码，实现命令行中的--encode和--decode选项 bool EncodeOrDecode(const DescriptorPool* pool); // 实现命令行中的--descriptor_set_out选项 bool WriteDescriptorSet(const vector\u0026lt;const FileDescriptor*\u0026gt; parsed_files); // 获取指定proto文件依赖的proto文件列表（列表中包括该proto文件本身） // - proto文件通过FileDescriptorProto表示； // - 这些依赖的proto文件列表会被重新排序，被依赖的proto会被排在依它的proto前面, // 这样我们就可以调用DescriptorPool::BuildFile()来建立最终的源代码文件； // - already_seen中已经列出的proto文件不会被重复添加，每一个被添加的proto文件都被加入到already_seen中； // - 如果include_source_code_info为true，则包括源代码信息到FileDescriptorProtos中； static void GetTransitiveDependencies(const FileDescriptor* file, bool include_source_code_info, set\u0026lt;const FileDescriptor*\u0026gt;* already_seen, RepeatedPtrField\u0026lt;FileDescriptorProto\u0026gt;* output); // ----------------------------------------------------------------- // 当前被调用的程序的名称，argv[0] string executable_name_; // 通过SetVersionInfo()设置的版本信息 string version_info_; // 注册的代码生成器 struct GeneratorInfo { string flag_name; // --foo_out string option_flag_name; // --foo_opt CodeGenerator* generator; // 对应的代码生成器 string help_text; // protoc --help时输出的--foo_out的帮助信息 }; typedef map\u0026lt;string, GeneratorInfo\u0026gt; GeneratorMap; // flag_name、代码生成器map GeneratorMap generators_by_flag_name_; // option_name、代码生成器map GeneratorMap generators_by_option_name_; // flag_name、option map // - 如果调用protoc --foo_out=outputdir --foo_opt=enable_bar ...， // map中将包括一个\u0026lt;--foo_out,enable_bar\u0026gt; entry. map\u0026lt;string, string\u0026gt; generator_parameters_; // protoc插件前缀，如果该变量为空，那么不允许使用插件 // @see AllowPlugins() string plugin_prefix_; // 将protoc插件名称映射为具体的插件可执行文件 // - 执行一个插件可执行程序时，首先搜索这个map，如果找到则直接执行； // - 如果这个map中找不到匹配的插件可执行程序，则搜索PATH寻找可执行程序执行； map\u0026lt;string, string\u0026gt; plugins_; // protoc命令行中指定的工作模式 enum Mode { MODE_COMPILE, // Normal mode: parse .proto files and compile them. MODE_ENCODE, // --encode: read text from stdin, write binary to stdout. MODE_DECODE // --decode: read binary from stdin, write text to stdout. }; Mode mode_; vector\u0026lt;pair\u0026lt;string, string\u0026gt; \u0026gt; proto_path_; // Search path for proto files. vector\u0026lt;string\u0026gt; input_files_; // Names of the input proto files. // protoc调用时每个--${lang}_out都对应着一个OutputDirective struct OutputDirective { string name; // flag_name，E.g. \u0026quot;--foo_out\u0026quot; CodeGenerator* generator; // 为NULL则表示使用protoc插件而非内置的代码生成器 string parameter; // 传递给代码生成器或者protoc插件的参数 string output_location; // 源代码文件输出目录 }; // 一次protoc调用可能会同时制定多个--${lang}_out选项 vector\u0026lt;OutputDirective\u0026gt; output_directives_; // 当使用--encode或者--decode的时候，codec_type_指明了encode或者decode的类型 // - 如果codec_type_为空则表示--decode_raw类型; string codec_type_; // 如果指定了--descriptor_set_out选项，FileDescriptorSet将被输出到指定的文件 string descriptor_set_name_; // 如果指定了--include-imports那么所有的依赖proto都要写到DescriptorSet； // 如果未指定，则只把命令行中列出的proto文件写入； bool imports_in_descriptor_set_; // 如果指定--include_source_info为true，则不能从DescriptorSet中删除SourceCodeInfo bool source_info_in_descriptor_set_; // --disallow_services_这个选项有被使用吗？ bool disallow_services_; // See SetInputsAreProtoPathRelative(). bool inputs_are_proto_path_relative_; GOOGLE_DISALLOW_EVIL_CONSTRUCTORS(CommandLineInterface); }; } // namespace compiler } // namespace protobuf } // namespace google #endif // GOOGLE_PROTOBUF_COMPILER_COMMAND_LINE_INTERFACE_H__  2.3. protoc执行流程说明 # protoc执行流程的相关源码，主要包括如下两个部分。\n2.3.1. protoc完成基本的初始化工作后调用cli.Run(argc,argv)开始生成代码 # 这部分内容在前面已经有过较为详细的解释，这里不再详细展开，只给出相应的代码、注释。\nfile: src/google/protobuf/compiler/main.cc\n// Author: kenton@google.com (Kenton Varda) // 这个头文件定义了protoc的命令行接口 #include \u0026lt;google/protobuf/compiler/command_line_interface.h\u0026gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include \u0026lt;google/protobuf/compiler/cpp/cpp_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/python/python_generator.h\u0026gt; #include \u0026lt;google/protobuf/compiler/java/java_generator.h\u0026gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件 // - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头 // - 假定protoc --foo_out，那么实际调用的插件是protoc-foo google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(\u0026quot;protoc-\u0026quot;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator) google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.RegisterGenerator(\u0026quot;--cpp_out\u0026quot;, \u0026quot;--cpp_opt\u0026quot;, \u0026amp;cpp_generator, \u0026quot;Generate C++ header and source.\u0026quot;); // Proto2 Java (指定了--java_out将调用java::Generator) google::protobuf::compiler::java::JavaGenerator java_generator; cli.RegisterGenerator(\u0026quot;--java_out\u0026quot;, \u0026amp;java_generator, \u0026quot;Generate Java source file.\u0026quot;); // Proto2 Python (指定了python_out将调用python::Generator) google::protobuf::compiler::python::Generator py_generator; cli.RegisterGenerator(\u0026quot;--python_out\u0026quot;, \u0026amp;py_generator, \u0026quot;Generate Python source file.\u0026quot;); return cli.Run(argc, argv); }  2.3.2. protoc命令接口cli.Run(argc,argv)详细处理流程 # 这部分代码是protoc对proto文件进行读取、解析、通过注册的代码生成器或者protoc插件生成源代码、保存源代码到源文件的执行流程。\nint CommandLineInterface::Run(int argc, const char* const argv[]) { Clear(); switch (ParseArguments(argc, argv)) { case PARSE_ARGUMENT_DONE_AND_EXIT: return 0; case PARSE_ARGUMENT_FAIL: return 1; case PARSE_ARGUMENT_DONE_AND_CONTINUE: break; } // Set up the source tree. DiskSourceTree source_tree; for (int i = 0; i \u0026lt; proto_path_.size(); i++) { source_tree.MapPath(proto_path_[i].first, proto_path_[i].second); } // Map input files to virtual paths if necessary. if (!inputs_are_proto_path_relative_) { if (!MakeInputsBeProtoPathRelative(\u0026amp;source_tree)) { return 1; } } // Allocate the Importer. ErrorPrinter error_collector(error_format_, \u0026amp;source_tree); Importer importer(\u0026amp;source_tree, \u0026amp;error_collector); vector\u0026lt;const FileDescriptor*\u0026gt; parsed_files; // Parse each file. for (int i = 0; i \u0026lt; input_files_.size(); i++) { // Import the file. const FileDescriptor* parsed_file = importer.Import(input_files_[i]); if (parsed_file == NULL) return 1; parsed_files.push_back(parsed_file); // Enforce --disallow_services. if (disallow_services_ \u0026amp;\u0026amp; parsed_file-\u0026gt;service_count() \u0026gt; 0) { cerr \u0026lt;\u0026lt; parsed_file-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: This file contains services, but \u0026quot; \u0026quot;--disallow_services was used.\u0026quot; \u0026lt;\u0026lt; endl; return 1; } } // We construct a separate GeneratorContext for each output location. Note // that two code generators may output to the same location, in which case // they should share a single GeneratorContext so that OpenForInsert() works. typedef hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; GeneratorContextMap; GeneratorContextMap output_directories; // Generate output. if (mode_ == MODE_COMPILE) { for (int i = 0; i \u0026lt; output_directives_.size(); i++) { string output_location = output_directives_[i].output_location; if (!HasSuffixString(output_location, \u0026quot;.zip\u0026quot;) \u0026amp;\u0026amp; !HasSuffixString(output_location, \u0026quot;.jar\u0026quot;)) { AddTrailingSlash(\u0026amp;output_location); } GeneratorContextImpl** map_slot = \u0026amp;output_directories[output_location]; if (*map_slot == NULL) { // First time we've seen this output location. *map_slot = new GeneratorContextImpl(parsed_files); } if (!GenerateOutput(parsed_files, output_directives_[i], *map_slot)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } // Write all output to disk. for (GeneratorContextMap::iterator iter = output_directories.begin(); iter != output_directories.end(); ++iter) { const string\u0026amp; location = iter-\u0026gt;first; GeneratorContextImpl* directory = iter-\u0026gt;second; if (HasSuffixString(location, \u0026quot;/\u0026quot;)) { if (!directory-\u0026gt;WriteAllToDisk(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } else { if (HasSuffixString(location, \u0026quot;.jar\u0026quot;)) { directory-\u0026gt;AddJarManifest(); } if (!directory-\u0026gt;WriteAllToZip(location)) { STLDeleteValues(\u0026amp;output_directories); return 1; } } } STLDeleteValues(\u0026amp;output_directories); if (!descriptor_set_name_.empty()) { if (!WriteDescriptorSet(parsed_files)) { return 1; } } if (mode_ == MODE_ENCODE || mode_ == MODE_DECODE) { if (codec_type_.empty()) { // HACK: Define an EmptyMessage type to use for decoding. DescriptorPool pool; FileDescriptorProto file; file.set_name(\u0026quot;empty_message.proto\u0026quot;); file.add_message_type()-\u0026gt;set_name(\u0026quot;EmptyMessage\u0026quot;); GOOGLE_CHECK(pool.BuildFile(file) != NULL); codec_type_ = \u0026quot;EmptyMessage\u0026quot;; if (!EncodeOrDecode(\u0026amp;pool)) { return 1; } } else { if (!EncodeOrDecode(importer.pool())) { return 1; } } } return 0; }  2.3.3. protoc执行逻辑总结 # 通过查看上面两部分代码及其他关键代码，可以对protoc的执行流程进行一个简单的总结了：\n  protoc main中初始化命令行参数接口cli;\n  protoc 中开启protoc-前缀的插件作为第三方代码生成器使用cli.AllowPlugins(\u0026ldquo;protoc-\u0026quot;)；\n  protoc main中注册编程语言cpp、java、python及对应的代码生成器，cli.RegisterGenerator(\u0026hellip;)，原生支持cpp、java、python；\n  protoc main中cli.Run(argc, argv)，运行注册的代码生成器或者protoc插件;\n Clear()清空所有的数据备用； ParseArguments(argc,argv)解析参数，对于protoc的某些内置参数的检查，对某些插件相关的\u0026ndash;${lang}_out参数的检查等，将\u0026ndash;${lang}_out作为输出指令保存起来； struct OutputDirective { string name; // E.g. \u0026quot;--foo_out\u0026quot; CodeGenerator* generator; // NULL for plugins string parameter; string output_location; };   参数解析成功之后，继续执行处理，设置源代码树、映射输入文件到虚拟路径、分配importer； 针对每个输入的proto文件进行解析，const FileDescriptor* parsed_file = importer.Import(input_files_[i])，解析成功后的文件会被加入到vector\u0026lt;FileDescriptor*\u0026gt; parsed_files中记录，每一个proto文件解析后都可以用一个FileDescriptor结构体来表示；   备注：\n这里解析proto文件的过程是这样的，首先将proto文件中的内容分割成一个个的token，将内容拆分成一个个词素并检查有效性，也就是词法分析。如果词法分析检查无误则进入后续的语法分析过程，parser对输入token串进行文法相关的分析检查是否可以构成一棵有效的语法分析树，如果可以则表示语法正确。\n // Token定义如下 struct Token { TokenType type; string text; // The exact text of the token as it appeared in // the input. e.g. tokens of TYPE_STRING will still // be escaped and in quotes. // \u0026quot;line\u0026quot; and \u0026quot;column\u0026quot; specify the position of the first character of // the token within the input stream. They are zero-based. int line; int column; int end_column; }; // Token类型定义如下 enum TokenType { TYPE_START, // Next() has not yet been called. TYPE_END, // End of input reached. \u0026quot;text\u0026quot; is empty. TYPE_IDENTIFIER, // A sequence of letters, digits, and underscores, not // starting with a digit. It is an error for a number // to be followed by an identifier with no space in // between. TYPE_INTEGER, // A sequence of digits representing an integer. Normally // the digits are decimal, but a prefix of \u0026quot;0x\u0026quot; indicates // a hex number and a leading zero indicates octal, just // like with C numeric literals. A leading negative sign // is NOT included in the token; it's up to the parser to // interpret the unary minus operator on its own. TYPE_FLOAT, // A floating point literal, with a fractional part and/or // an exponent. Always in decimal. Again, never // negative. TYPE_STRING, // A quoted sequence of escaped characters. Either single // or double quotes can be used, but they must match. // A string literal cannot cross a line break. TYPE_SYMBOL, // Any other printable character, like '!' or '+'. // Symbols are always a single character, so \u0026quot;!+$%\u0026quot; is // four tokens. };  语法分析的过程这里就不解释了，感兴趣的可以看一下protobuf中grammar的定义，无非也就是些规约的事情，只要能够按照grammar将词法分析输出的token串构建出一棵完整的语法分析树proto文件就是合法的，否则就是不合法的，至于语法分析过程中伴随的语义分析过程，语义分析过程中执行哪些语义动作，不说也知道，肯定是生成某些“中间代码”之类的鬼东西。学过编译原理的这些处理过程应该都是比较清楚的，这里就不再展开了。语法分析成功之后就得到了proto对应的FileDescriptor对象，因为可能输入的是多个proto，所以多个FileDescriptor就用vector来存储了。\n 遍历之前记录下来的输出指令OutputDirective output_directives[]，output_directives[i].output_location指明了输出目录，针对输出目录创建GeneratorContextImpl，并记录到hash_map\u0026lt;string, GeneratorContextImpl*\u0026gt; output_directories这个map中，key为flag_out,如\u0026ndash;foo_out，value为GeneratorContextImpl。由于可能多个\u0026ndash;${lang}_out都指向相同的输出目录，所以同一个GeneratorContextImpl也存在复用的情况。每个GeneratorContextImpl记录了一个输出目录、所有该目录下的待创建的源代码文件的信息，待创建的源代码文件信息记录在map\u0026lt;string,string*\u0026gt; files_里面，key为源代码文件名，val为源代码文件的内容，另外还包括了一个vector\u0026lt;FileDescriptor*\u0026gt; parsed_files记录了所有解析成功的proto文件信息。\n遍历output_directives的同时，因为同一个output_directives[i]对应的输出目录下可能有多个源代码文件要输出，并且不管flag_name是什么，要处理的proto文件都是相同的，所以每个output_directives[i]都会对其调用GenerateOutput(parsed_files, output_directives[i], *map_slot)，output_directives[i].plugin指明了语言的代码生成器(为NULL则使用插件)，对所有的解析成功的proto文件parsed_files[i]生成源代码，源代码全部输出到output_directive[i].output_location下，源代码的文件名都记录在parsed_files[i].name()里面，而最终生成的源代码信息都存储在这里的CodeGeneratorImpl **map_slot中，也就相当于存储在了output_directories[]中。 最后遍历output_directories[]，将每个输出目录下要写的所有文件的数据全部写出到磁盘，即output_directories[i]-\u0026gt;WriteAllToDisk()。 done！    了解从proto到源代码生成的关键之处就是这里的GenerateOutput是怎么实现的，接着看。\n2.3.3.1 protoc CommandLineInterface::GenerateOutput(\u0026hellip;)实现 # 下面看下GenerateOutput方法到底执行了哪些操作。\n// 根据输出指示, 为解析成功的proto文件调用代码生成器生成对应的代码并存储到generator_context //@param parsed_files 所有解析成功的proto文件，每个解析成功的proto文件都用一个FileDescriptor来表示 //@param output_directive 输出指示，其指明了目标语言、语言对应的代码生成器、输出目录等 //@param generator_context 代码生成器上下文，可记录生成的代码 bool CommandLineInterface::GenerateOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const OutputDirective\u0026amp; output_directive, GeneratorContext* generator_context) { // Call the generator. string error; // 如果输出指示中没有设置对应的代码生成器，表明没有在protoc main中注册语言对应的代码生成器， // 这种需要protoc通过插件机制，通过调用对应的插件来充当代码生成器的功能。 if (output_directive.generator == NULL) { // This is a plugin. GOOGLE_CHECK(HasPrefixString(output_directive.name, \u0026quot;--\u0026quot;) \u0026amp;\u0026amp; HasSuffixString(output_directive.name, \u0026quot;_out\u0026quot;)) \u0026lt;\u0026lt; \u0026quot;Bad name for plugin generator: \u0026quot; \u0026lt;\u0026lt; output_directive.name; // 实际上protoc搜索插件对应的可执行程序的时候，搜索的名称是“protoc-gen-”+“语言”， // 如果我们调用的是protoc --xxx_out，那么实际搜索的就是protoc-gen-xxx。 string plugin_name = plugin_prefix_ + \u0026quot;gen-\u0026quot; + output_directive.name.substr(2, output_directive.name.size() - 6); // 调用protoc插件来生成代码，这是我们要重点看的，我们就是要实现自己的protoc插件 if (!GeneratePluginOutput(parsed_files, plugin_name, output_directive.parameter, generator_context, \u0026amp;error)) { cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } else { // 这种是protoc main函数中正常注册的语言和代码生成器 // Regular generator. string parameters = output_directive.parameter; if (!generator_parameters_[output_directive.name].empty()) { if (!parameters.empty()) { parameters.append(\u0026quot;,\u0026quot;); } parameters.append(generator_parameters_[output_directive.name]); } // 为每个解析成功的proto文件生成代码 for (int i = 0; i \u0026lt; parsed_files.size(); i++) { if (!output_directive.generator-\u0026gt;Generate(parsed_files[i], parameters, generator_context, \u0026amp;error)) { // Generator returned an error. cerr \u0026lt;\u0026lt; output_directive.name \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; parsed_files[i]-\u0026gt;name() \u0026lt;\u0026lt; \u0026quot;: \u0026quot; \u0026lt;\u0026lt; error \u0026lt;\u0026lt; endl; return false; } } } return true; }  2.3.3.2. protoc调用插件生成代码的执行逻辑 # 下面再来看一下GeneratePluginOutput是如何工作的。\n// 调用protoc插件为解析成功的proto文件生成代码 // //@param parsed_files 解析成功的文件 //@param plugin_name protoc插件名称（这个是拼接出来的protoc-gen-${lang}） //@param parameter 传给插件的参数 //@param generator_context 代码生成器上下文，可记录生成的代码 //@param error 代码生成过程中的错误信息 bool CommandLineInterface::GeneratePluginOutput(const vector\u0026lt;const FileDescriptor*\u0026gt;\u0026amp; parsed_files, const string\u0026amp; plugin_name, const string\u0026amp; parameter, GeneratorContext* generator_context, string* error) { // protoc生成一个代码生成请求，并发送给插件 CodeGeneratorRequest request; // protoc插件根据接收到的代码生成请求生成代码，并发送响应给protoc CodeGeneratorResponse response; // Build the request. if (!parameter.empty()) { request.set_parameter(parameter); } set\u0026lt;const FileDescriptor*\u0026gt; already_seen; for (int i = 0; i \u0026lt; parsed_files.size(); i++) { request.add_file_to_generate(parsed_files[i]-\u0026gt;name()); GetTransitiveDependencies(parsed_files[i], true, // Include source code info. \u0026amp;already_seen, request.mutable_proto_file()); } // fork出一个子进程，子进程来执行插件完成代码生成工作， // 父子进程之间是通过管道通信完成请求、响应过程，如何控制子进程的stdin、stdout， // 这个可以通过dup2或者dup3来控制间fd 0、1分别设置到管道的读端、写端。 // 事实上protobuf的开发人员也是这么来实现的。 // Invoke the plugin. Subprocess subprocess; if (plugins_.count(plugin_name) \u0026gt; 0) { subprocess.Start(plugins_[plugin_name], Subprocess::EXACT_NAME); } else { subprocess.Start(plugin_name, Subprocess::SEARCH_PATH); } string communicate_error; // 请求插件生成代码 if (!subprocess.Communicate(request, \u0026amp;response, \u0026amp;communicate_error)) { *error = strings::Substitute(\u0026quot;$0: $1\u0026quot;, plugin_name, communicate_error); return false; } // Write the files. We do this even if there was a generator error in order // to match the behavior of a compiled-in generator. scoped_ptr\u0026lt;io::ZeroCopyOutputStream\u0026gt; current_output; for (int i = 0; i \u0026lt; response.file_size(); i++) { const CodeGeneratorResponse::File\u0026amp; output_file = response.file(i); if (!output_file.insertion_point().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据已经存在，定位到准确的插入点位置执行写入，然后关闭文件 // - 这里的插入点如何定义，我们在后面再进行说明。具体可参考plugin.proto和plugin.pb.h。 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;OpenForInsert(output_file.name(), output_file.insertion_point())); } else if (!output_file.name().empty()) { // 首先关闭当前正在写入的文件数据（用CodeGeneratorResponse表示） // 打开待写入的文件数据，这个文件数据不存在，不存在插入点信息，从开始处执行写入 current_output.reset(); // OpenForInsert返回一个输出流，以方便后面写入编码后数据 current_output.reset(generator_context-\u0026gt;Open(output_file.name())); } else if (current_output == NULL) { *error = strings::Substitute( \u0026quot;$0: First file chunk returned by plugin did not specify a file name.\u0026quot;, plugin_name); return false; } // 从CodeGeneratorResponse中获取输出流，写出，这里输出流中的数据时存储在GeneratorContextImpl中的， // GenerateOutput调用成功之后后面会遍历每一个GenerateContextImpl完成WriteAllToDisk()的操作。 // Use CodedOutputStream for convenience; otherwise we'd need to provide // our own buffer-copying loop. io::CodedOutputStream writer(current_output.get()); writer.WriteString(output_file.content()); } // Check for errors. if (!response.error().empty()) { // Generator returned an error. *error = response.error(); return false; } return true; }  2.3.3.3. protoc \u0026amp; protoc插件数据交互的执行逻辑 # 整体执行逻辑差不多理清楚了，然后这里我们需要看一下父进程给子进程发送的代码生成请求是什么，收到的代码生成的响应又是什么，以及父子进程通信的细节、子进程对请求的处理过程等。\n先来看下plugin.proto的定义，protoc内置的支持语言里面并不包含go，我们后面需要用go来编写我们自己的插件，所以必须使用protoc的go插件来生成go对应的plugin.go代码，然后我们自己写一些业务类插件（非语言插件）的时候才能用上plugin.go。扯这么多是为了让大家明白这里为什么需要看下plugin.proto，而不是误解为只是在堆砌内容。看了这里的plugin.proto之后才能理解到protoc中的插件机制的边界时什么，我们就可以明白利用protoc的插件机制，我们可以做到什么程度，哪些功能能实现，哪些实现不了，这个是很重要的。\nfile: src/google/protobuf/compiler/plugin.proto\n// protoc (aka the Protocol Compiler) can be extended via plugins. A plugin is // just a program that reads a CodeGeneratorRequest from stdin and writes a // CodeGeneratorResponse to stdout. // // Plugins written using C++ can use google/protobuf/compiler/plugin.h instead // of dealing with the raw protocol defined here. // // A plugin executable needs only to be placed somewhere in the path. The // plugin should be named \u0026quot;protoc-gen-$NAME\u0026quot;, and will then be used when the // flag \u0026quot;--${NAME}_out\u0026quot; is passed to protoc. package google.protobuf.compiler; option java_package = \u0026quot;com.google.protobuf.compiler\u0026quot;; option java_outer_classname = \u0026quot;PluginProtos\u0026quot;; import \u0026quot;google/protobuf/descriptor.proto\u0026quot;; // 发送给插件的代码生成请求 // An encoded CodeGeneratorRequest is written to the plugin's stdin. message CodeGeneratorRequest { // The .proto files that were explicitly listed on the command-line. The // code generator should generate code only for these files. Each file's // descriptor will be included in proto_file, below. //proto文件列表对应的要生成的文件的源代码文件的名字 repeated string file_to_generate = 1; // The generator parameter passed on the command-line. //传递给插件代码生成器的参数 optional string parameter = 2; // FileDescriptorProtos for all files in files_to_generate and everything // they import. The files will appear in topological order, so each file // appears before any file that imports it. // // protoc guarantees that all proto_files will be written after // the fields above, even though this is not technically guaranteed by the // protobuf wire format. This theoretically could allow a plugin to stream // in the FileDescriptorProtos and handle them one by one rather than read // the entire set into memory at once. However, as of this writing, this // is not similarly optimized on protoc's end -- it will store all fields in // memory at once before sending them to the plugin. // 每一个正确解析的proto文件都用一个FileDescriptorProto来表示； // 这里的FileDescriptorProto与FileDescriptor其实是对应的，在请求插件进行代码 // 生成的时候直接就有这样的代码FileDescriptor::CopyTo(FileDescriptorProto\u0026amp;) // 的用法。而在descriptor.h和descriptor.proto中查看二者的描述时，其注释清清 // 楚楚地写着都是描述的一个完整的proto文件。 repeated FileDescriptorProto proto_file = 15; } // 插件返回的代码生成响应 // The plugin writes an encoded CodeGeneratorResponse to stdout. message CodeGeneratorResponse { // Error message. If non-empty, code generation failed. The plugin process // should exit with status code zero even if it reports an error in this way. // // This should be used to indicate errors in .proto files which prevent the // code generator from generating correct code. Errors which indicate a // problem in protoc itself -- such as the input CodeGeneratorRequest being // unparseable -- should be reported by writing a message to stderr and // exiting with a non-zero status code. // 错误信息 optional string error = 1; // Represents a single generated file. // 生成的源代码文件消息类型，注意这里是一个内部类型 message File { // 待生成的源代码文件名（相对于输出目录），文件名中不能包括.或者..，路径是 // 相对输出目录的路径，不能用绝对路径，另分隔符必须用/。 // 如果name没有指定，那么输出的内容将追加到前一个输出的源代码文件中，这种 // 方式使得代码生成器能够将一个大文件的生成分多次写入来完成，不用一次性将很 // 大数据量的数据放在内存中。这里需要指出的是，protoc中并没有针对这种情况 // 进行特殊的优化，它等待读取完整的CodeGeneratorResponse再写出到磁盘。 optional string name = 1; // 如果insertion_point不空的话，name字段也不能为空，并且假定name字段指定的 // 文件已经存在了。这里的内容将被插入到name指定的文件中的特定插入点（注解）的 // 上一行。这有助于扩展代码生成器输出的内容。在一次protoc调用中，可能会同 // 时指定多个protoc插件，前面的插件可能会在输出的内容中指定插入点，后面的 // 插件可能会在这些指定的插入点的位置继续扩展代码内容。 // 例如，前面的一个插件在输出的代码内容中增加了这样一行注解： // @@protoc_insertion_point(NAME) // 这样就定义了一个插入点，插入点前面、后面可以包含任意的文本内容，即使在 // 注释里面也是可以的。这里的插入点定义中的NAME应该可以唯一标识一个插入点 // 才可以，类似于标识符，以供其他的插件使用，插件插入代码的时候将从插入点 // 的上一行开始自行插入。如果包含多个插入点的话，插入点的内容将被插件依次 // 扩展。 // // 一开始创建这个源代码文件的代码生成器或者插件与后面的继续扩展源代码插入 // 点位置内容的代码生成器或者插件，必须在protoc的同一次调用中，代码生成器 // 或者插件按照protoc命令行调用过程中指定的顺序依次调用。 optional string insertion_point = 2; // 待写入到源代码中的内容 optional string content = 15; } // 一次要处理的 proto文件可能有多个，所以插件处理后这里的file是一个list repeated File file = 15; }  下面看一下protoc与protoc插件这对父子进程之间是怎么通信的。\nfile: src/google/protobuf/compiler/subprocess.h\nclass LIBPROTOC_EXPORT Subprocess { public: Subprocess(); ~Subprocess(); enum SearchMode { SEARCH_PATH, // Use PATH environment variable. EXACT_NAME // Program is an exact file name; don't use the PATH. }; // Start the subprocess. Currently we don't provide a way to specify // arguments as protoc plugins don't have any. void Start(const string\u0026amp; program, SearchMode search_mode); // Serialize the input message and pipe it to the subprocess's stdin, then // close the pipe. Meanwhile, read from the subprocess's stdout and parse // the data into *output. All this is done carefully to avoid deadlocks. // Returns true if successful. On any sort of error, returns false and sets // *error to a description of the problem. bool Communicate(const Message\u0026amp; input, Message* output, string* error); // win32 relevant ... neglect private: #ifdef _WIN32 // ... #else // !_WIN32 pid_t child_pid_; // The file descriptors for our end of the child's pipes. We close each and // set it to -1 when no longer needed. int child_stdin_; int child_stdout_; #endif };  下面是Linux平台下的子进程启动处理逻辑。\nfile: src/google/protobuf/compiler/subprocess.cc\nvoid Subprocess::Start(const string\u0026amp; program, SearchMode search_mode) { // Note that we assume that there are no other threads, thus we don't have to // do crazy stuff like using socket pairs or avoiding libc locks. // [0] is read end, [1] is write end. int stdin_pipe[2]; int stdout_pipe[2]; GOOGLE_CHECK(pipe(stdin_pipe) != -1); GOOGLE_CHECK(pipe(stdout_pipe) != -1); char* argv[2] = { strdup(program.c_str()), NULL }; child_pid_ = fork(); if (child_pid_ == -1) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;fork: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } else if (child_pid_ == 0) { // We are the child. // 将子进程的stdin重定向到stdin_pipe的读端 dup2(stdin_pipe[0], STDIN_FILENO); // 将子进程的stdout重定向到stdout_pipe的写端 dup2(stdout_pipe[1], STDOUT_FILENO); // 子进程通过0、1对管道进行操作就够了，释放多余的fd close(stdin_pipe[0]); close(stdin_pipe[1]); close(stdout_pipe[0]); close(stdout_pipe[1]); // 根据程序搜索模式调用exec族函数来调用插件执行，exec族函数通过替换当前进 // 程的代码段、数据段等内存数据信息，然后调整寄存器信息，使得进程转而去执 // 行插件的代码。插件代码执行之前进程就已经将fd 0、1重定向到父进程clone过 // 来的管道了，因此插件程序的输出将直接被输出到父进程创建的管道中。 // 正常情况下，exec一旦执行成功，那么久绝不对执行switch后续的代码了，只有 // 出错才可能会执行到后续的代码。 switch (search_mode) { case SEARCH_PATH: execvp(argv[0], argv); break; case EXACT_NAME: execv(argv[0], argv); break; } // 只有出错才可能会执行到这里的代码。 // Write directly to STDERR_FILENO to avoid stdio code paths that may do // stuff that is unsafe here. int ignored; ignored = write(STDERR_FILENO, argv[0], strlen(argv[0])); const char* message = \u0026quot;: program not found or is not executable\\n\u0026quot;; ignored = write(STDERR_FILENO, message, strlen(message)); (void) ignored; // Must use _exit() rather than exit() to avoid flushing output buffers // that will also be flushed by the parent. _exit(1); } else { free(argv[0]); // 父进程释放无用的fd close(stdin_pipe[0]); close(stdout_pipe[1]); // 子进程的stdin，对父进程来说也就是管道stdin_pipe的写端，CodeGeneratorRequest将通过这个fd写给子进程 child_stdin_ = stdin_pipe[1]; // 子进程的stdout，对父进程来说也就是管道stdout_pipe的读端，CodeGeneratorResponse将通过这个fd从子进程读取 child_stdout_ = stdout_pipe[0]; } }  下面接着看父进程读取子进程返回的CodeGeneratorResponse的执行逻辑。\nbool Subprocess::Communicate(const Message\u0026amp; input, Message* output, string* error) { GOOGLE_CHECK_NE(child_stdin_, -1) \u0026lt;\u0026lt; \u0026quot;Must call Start() first.\u0026quot;; // The \u0026quot;sighandler_t\u0026quot; typedef is GNU-specific, so define our own. typedef void SignalHandler(int); // Make sure SIGPIPE is disabled so that if the child dies it doesn't kill us. SignalHandler* old_pipe_handler = signal(SIGPIPE, SIG_IGN); string input_data = input.SerializeAsString(); string output_data; int input_pos = 0; int max_fd = max(child_stdin_, child_stdout_); // child_stdout==-1的时候表示子进程返回的数据已经读取完毕了，可以gg了 while (child_stdout_ != -1) { fd_set read_fds; fd_set write_fds; FD_ZERO(\u0026amp;read_fds); FD_ZERO(\u0026amp;write_fds); if (child_stdout_ != -1) { FD_SET(child_stdout_, \u0026amp;read_fds); } if (child_stdin_ != -1) { FD_SET(child_stdin_, \u0026amp;write_fds); } // 这种情景下也用select，果然很google！ if (select(max_fd + 1, \u0026amp;read_fds, \u0026amp;write_fds, NULL, NULL) \u0026lt; 0) { if (errno == EINTR) { // Interrupted by signal. Try again. continue; } else { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;select: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // stdout_pipe写事件就绪，写请求CodeGeneratorRequest给子进程 if (child_stdin_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdin_, \u0026amp;write_fds)) { int n = write(child_stdin_, input_data.data() + input_pos, input_data.size() - input_pos); if (n \u0026lt; 0) { // Child closed pipe. Presumably it will report an error later. // Pretend we're done for now. input_pos = input_data.size(); } else { input_pos += n; } // 代码生成请求已经成功写给子进程了，关闭相关的fd if (input_pos == input_data.size()) { // We're done writing. Close. close(child_stdin_); child_stdin_ = -1; } } // stdin_pipe读事件就绪，读取子进程返回的CodeGeneratorResponse if (child_stdout_ != -1 \u0026amp;\u0026amp; FD_ISSET(child_stdout_, \u0026amp;read_fds)) { char buffer[4096]; int n = read(child_stdout_, buffer, sizeof(buffer)); if (n \u0026gt; 0) { output_data.append(buffer, n); } else { // 子进程返回的CodeGeneratorResponse已经读取完毕，关闭相关的fd close(child_stdout_); child_stdout_ = -1; } } } // 子进程还没有读取CodeGeneratorRequest完毕，就关闭了输出，这种情况下也不可 // 能读取到返回的CodeGeneratorResponse了，这种情况很可能是出现了异常。 if (child_stdin_ != -1) { // Child did not finish reading input before it closed the output. // Presumably it exited with an error. close(child_stdin_); child_stdin_ = -1; } // 等待子进程结束，子进程退出之后，需要父进程来清理子进程占用的部分资源。 // 如果当前父进程不waitpid的话，子进程的父进程会变为init或者systemd进程，同样也会被清理的。 int status; while (waitpid(child_pid_, \u0026amp;status, 0) == -1) { if (errno != EINTR) { GOOGLE_LOG(FATAL) \u0026lt;\u0026lt; \u0026quot;waitpid: \u0026quot; \u0026lt;\u0026lt; strerror(errno); } } // 刚才为了阻止SIGPIPE信号到达时导致进程终止，我们修改了SIGPIPE的信号处理函 // 数，这里可以恢复之前的SIGPIPE的信号处理函数。 signal(SIGPIPE, old_pipe_handler); // 根据子进程的退出状态执行后续的处理逻辑 // - 异常处理 if (WIFEXITED(status)) { if (WEXITSTATUS(status) != 0) { int error_code = WEXITSTATUS(status); *error = strings::Substitute( \u0026quot;Plugin failed with status code $0.\u0026quot;, error_code); return false; } } else if (WIFSIGNALED(status)) { int signal = WTERMSIG(status); *error = strings::Substitute( \u0026quot;Plugin killed by signal $0.\u0026quot;, signal); return false; } else { *error = \u0026quot;Neither WEXITSTATUS nor WTERMSIG is true?\u0026quot;; return false; } // 将子进程返回的串行化之后的CodeGeneratorResponse数据进行反串行化，反串行化 // 成Message对象，实际上这里的Message::ParseFromString(const string\u0026amp;)是个虚 // 函数，是被CodeGeneratorResponse这个类重写了的，反串行化过程与具体的类密切 // 相关，也必须在派生类中予以实现。 if (!output-\u0026gt;ParseFromString(output_data)) { *error = \u0026quot;Plugin output is unparseable.\u0026quot;; return false; } return true; }  到这里为止protoc进程的具体执行逻辑我们已经很清楚了，看到这里想必读者也看清楚了吧？下面再看下插件的执行逻辑。\n插件的执行逻辑一定也是非常简单的，插件就只是从stdin读取串行化之后的CodeGeneratorRequest请求，然后执行反串行化得到一个完整的CodeGeneratorRequest对象，然后根据请求进行必要的代码生成逻辑，确定要生成的源代码信息，并将其设置到CodeGeneratorResponse中并串行化后写入到stdout，插件的执行逻辑就这么简单。\n下面我们将进入插件的编写过程了。\n2.4. protoc插件开发 # 2.4.1. protoc中的descriptor定义 # proto文件中的数据类型都是在descriptor.proto中定义好的，为了更好地帮助我们对proto文件中的数据类型进行解析，为了在插件开发过程中更加方便快速地获得与数据类型、变量、rpc等相关的这种内容、那种内容，我们都需要深入地理解descriptor.proto中的相关定义以及从它延伸出来的一些概念、算法等。\n这部分的内容还不少，在不影响理解的大前提下，我还是稍微删减写些代码，避免对大家理解造成不必要的干扰。\nfile: src/google/protobuf/descriptor.proto\n// Author: kenton@google.com (Kenton Varda) // Based on original Protocol Buffers design by // Sanjay Ghemawat, Jeff Dean, and others. // descriptor.proto文件中的messages定义了proto文件中所能见到的所有的定义，一个有效的.proto文件在不提供其他信息（甚至不需要读取它的imports）能够直接被转换成一个FileDescriptorProto对象。 package google.protobuf; option java_package = \u0026quot;com.google.protobuf\u0026quot;; option java_outer_classname = \u0026quot;DescriptorProtos\u0026quot;; // descriptor.proto必须在速度方面优化，因为在启动过程中基于反射的算法不起作用 option optimize_for = SPEED; // protoc可以将解析的proto文件中的descriptor添加到FileDescriptorSet并输出到文件 message FileDescriptorSet { repeated FileDescriptorProto file = 1; } // 下面的message FileDescriptorProto可以用于描述一个完整的proto文件 message FileDescriptorProto { optional string name = 1; // proto文件名，file name，相对于源代码根目录 optional string package = 2; // proto包名，例如 \u0026quot;foo\u0026quot;、\u0026quot;foo.bar\u0026quot; repeated string dependency = 3; // proto文件中import进来的其他proto文件列表 repeated int32 public_dependency = 10; // 上面public import的proto文件在proto文件列表中的索引 // Indexes of the weak imported files in the dependency list. repeated int32 weak_dependency = 11; // 上面weak import的proto文件在proto文件列表中的索引 // 不要使用，只用于google内部的迁移 // proto文件中的所有顶层定义信息 repeated DescriptorProto message_type = 4; // 所有的消息(message)类型定义 repeated EnumDescriptorProto enum_type = 5; // 所有的枚举(enum)类型定义 repeated ServiceDescriptorProto service = 6; // 所有的服务(service)类型定义 repeated FieldDescriptorProto extension = 7; // 所有的扩展字段定义 optional FileOptions options = 8; // 文件选项 // 这个字段包括了源代码的相关信息，这里的信息可以给开发工具使用，也仅应该提供给开发工具使用； // 可以选择将这个字段中的信息删除，在程序运行期间并不会造成破坏。 optional SourceCodeInfo source_code_info = 9; } // 描述消息类型Message message DescriptorProto { optional string name = 1; // Message的类型名称 repeated FieldDescriptorProto field = 2; // Message中包括的字段列表 repeated FieldDescriptorProto extension = 6; // Message中包括的扩展列表 repeated DescriptorProto nested_type = 3; // Message中嵌套的Message类型列表 repeated EnumDescriptorProto enum_type = 4; // Message中嵌套的枚举类型列表 message ExtensionRange { optional int32 start = 1; optional int32 end = 2; } repeated ExtensionRange extension_range = 5; optional MessageOptions options = 7; } // 描述一个字段（字段可以是Message中的，也可以是某些扩展字段） message FieldDescriptorProto { // 字段数据类型 enum Type { // 0 is reserved for errors. // 由于历史方面的原因，这里的枚举值的顺序有点奇怪 TYPE_DOUBLE = 1; TYPE_FLOAT = 2; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT64 if // negative values are likely. TYPE_INT64 = 3; TYPE_UINT64 = 4; // Not ZigZag encoded. Negative numbers take 10 bytes. Use TYPE_SINT32 if // negative values are likely. TYPE_INT32 = 5; TYPE_FIXED64 = 6; TYPE_FIXED32 = 7; TYPE_BOOL = 8; TYPE_STRING = 9; TYPE_GROUP = 10; // Tag-delimited aggregate. TYPE_MESSAGE = 11; // Length-delimited aggregate. // New in version 2. TYPE_BYTES = 12; TYPE_UINT32 = 13; TYPE_ENUM = 14; TYPE_SFIXED32 = 15; TYPE_SFIXED64 = 16; TYPE_SINT32 = 17; // Uses ZigZag encoding. TYPE_SINT64 = 18; // Uses ZigZag encoding. }; // 字段修饰符optional、required、repeated enum Label { // 0 is reserved for errors LABEL_OPTIONAL = 1; LABEL_REQUIRED = 2; LABEL_REPEATED = 3; // TODO(sanjay): Should we add LABEL_MAP? }; optional string name = 1; // 字段名称 optional int32 number = 3; // 字段tag编号 optional Label label = 4; // 字段修饰符 // 如果type_name已设置，这个字段无须设置； // 如果这两个字段都设置了，这里的type字段必须是TYPE_ENUM类型或者TYPE_MESSAGE类型 optional Type type = 5; // 对于TYPE_ENUM或者TYPE_MESSAGE类型，type_name就是type的名字。 // 如果name以“.”开头那么它是完全保留的。对于C++来说，其作用域规则要求首先搜 // 索当前Message类型的嵌套类型，然后才是parent namespace中的类型，一直到root // namespace。 optional string type_name = 6; // 对于扩展，它就是被扩展的类型的名字，对它的解析与对type_name的解析时一样的 optional string extendee = 2; // 对于数值类型，存储了数值的文本表示形式； // 对于布尔类型，存储字符串\u0026quot;true\u0026quot;或\u0026quot;false\u0026quot;； // 对于字符串类型，存储原始的文本内容（未转义的） // 对于字节，存储了c转义后的值（所有\u0026gt;=128的字节都会被转义） // TODO(kenton)，基于base64编码的? optional string default_value = 7; optional FieldOptions options = 8; // 字段选项 } // 描述一个枚举类型enum message EnumDescriptorProto { optional string name = 1; // 枚举类型名称 repeated EnumValueDescriptorProto value = 2; // 枚举类型中包括的枚举值列表 optional EnumOptions options = 3; // 枚举类型选项 } // 描述一个枚举类型中的一个枚举值 message EnumValueDescriptorProto { optional string name = 1; // 枚举值对应的name optional int32 number = 2; // 枚举值对应的number（默认为0，依次递增） optional EnumValueOptions options = 3; // 枚举值选项 } // 描述一个rpc service. message ServiceDescriptorProto { optional string name = 1; // 服务名称 repeated MethodDescriptorProto method = 2; // 服务对应的方法列表 optional ServiceOptions options = 3; // 服务选项 } // 描述一个服务的方法 message MethodDescriptorProto { optional string name = 1; // 方法名称 optional string input_type = 2; // 方法入参类型 optional string output_type = 3; // 方法出参类型 optional MethodOptions options = 4; // 方法选项 } // =================================================================== // Options // 上面的每一个定义基本上都包括了选项option相关的字段，这些选项字段仅仅是一些 // 注解，这些注解会影响代码的生成，使得生成的代码稍有不同，注解也可能包含了操作 // message的代码的一些提示信息、说明信息。 // // clients可能会定义一些自定义的选项来作为*Options message的extensions，这些 // extensions在parsing阶段可能还无法确定下来，所以parser不能存储他们的值，而是 // 将这些自定义的选项先存储到一个*Options message里面，称之为 // uinterpreted_option。这个字段的名字在所有的*Options message里面都必须保证是 // 相同的。之后在我们构建descriptor的时候，这个时候所有的proto文件也都解析完了、 // 所有的extensions也都知道了，这个时候我们再用这里的uinterpreted_option字段去 // 填充那些extensions。 // // 用于自定义选项的extensions编号的选择一般遵循下面的方法： // * 对于只在一个应用程序或者组织内使用的选项，或者用于实验目的的选项，使用字 // 段编号50000~99999范围内的。对于多个选项，用户需要确保不使用相同的编号。 // * 对于可能被多个互不依赖的实体所共同使用的选项，需要给 // protobuf-global-extension-registry@google.com发邮件来申请预留扩展编号。需 // 要提供工程名称、工程站点，没必要解释为什么需要申请预留某个特定的编号。通 // 常只需要一个扩展编号，可以声明多个选项但是只使用这一个相同的扩展编号。如 // 果申请公共的扩展编号是个刚需，google可能会发布一个web service接口来自动分 // 配选项编号。 message FileOptions { // java包名，当前proto文件中生成的java类将位于这个package下 optional string java_package = 1; // 指定一个外部类名称，当前proto文件中生成的所有的类将被封装在这个外部类当中 optional string java_outer_classname = 8; // 如果设置为true，java代码生成器将为每个顶层message、enum、service定义生成 // 单独的java文件，默认为false optional bool java_multiple_files = 10 [default=false]; // 如果设置为true，java代码生成器将未每个message定义生成equals()、hashCode() // 方法，默认为false。本来AbstractMessage基类经包括了一个基于反射的equals()、 // hashCode()方法实现，这里的这个设置项是一个性能方面的优化 optional bool java_generate_equals_and_hash = 20 [default=false]; // 优化类型，生成的类可以进行速度优化、代码尺寸优化 enum OptimizeMode { SPEED = 1; // Generate complete code for parsing, serialization, // etc. CODE_SIZE = 2; // Use ReflectionOps to implement these methods. LITE_RUNTIME = 3; // Generate code using MessageLite and the lite runtime. } optional OptimizeMode optimize_for = 9 [default=SPEED]; // 设置go代码的包名 optional string go_package = 11; // 是否应该针对每一门语言都生成generice services？generic服务并不特定于任何 // 的rpc系统，它是由每个语言的注代码生成器来生成的，不借助于额外的插件。 // generic services是早期protoo2这个版本说支持的唯一一种服务类型。 // // 由于现在推崇使用plugins，plugins可以生成针对特定rpc系统的代码，generic // services现在可以看做是被废弃了。因此，以前proto2总的generice services的默 // 认设置默认为false，早期的依赖于generic services的代码需要显示设置这些选项 // 为true。 optional bool cc_generic_services = 16 [default=false]; optional bool java_generic_services = 17 [default=false]; optional bool py_generic_services = 18 [default=false]; // parser将不识别的选项存储在这里的uinterpreted_option repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message MessageOptions { // 设为true则使用老的proto1 MessageSet wire format……兼容性目的，没必要使用 optional bool message_set_wire_format = 1 [default=false]; // 禁用标准的descriptor()方法的生成，因为如果有个字段名是descriptor的话会生 // 成一个同名的函数，会冲突。这使得从proto1迁移到后续版本更简单，但是新版本 // 中还是应该避免使用字段descriptor。 optional bool no_standard_descriptor_accessor = 2 [default=false]; // parser将不识别的选项存储在这个字段里 repeated UninterpretedOption uninterpreted_option = 999; // 用户可以定义自定义选项来扩展当前Message extensions 1000 to max; } message FieldOptions { // 开启packed选项之后，对于repeated基本数据类型字段的表示会更加高效。不再针 // 对repeated字段中的各个元素执行写tag、类型操作，而是将整个数组作为一个固定 // 长度的blob来存储。 optional bool packed = 2; // 当前字段是否需要lazy parsing？只是建议，lazy为true，protoc不一定lazy parsing optional bool lazy = 5 [default=false]; // 当前字段是否已经被废弃，跟目标平台相关，这个字段可以为生成的accessor方法 // 生成Deprecated注解，如果目标平台不支持就会忽略这个选项。不管目标平台是否 // 支持，proto里面要想废弃一个字段加deprecated选项还是非常正确的做法。 optional bool deprecated = 3 [default=false]; // map字段，目前还未完全实现，应避免使用 optional string experimental_map_key = 9; // google内部迁移使用，因避免使用 optional bool weak = 10 [default=false]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumOptions { // 不允许将多个不同的tag names映射到一个相同的值 // - 意思是说不允许多个字段的编号相同 optional bool allow_alias = 2 [default=true]; // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message EnumValueOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message ServiceOptions { // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } message MethodOptions { // 注意：字段编号1~32被保留给google内部rpc框架使用，google的解释是，在 // protobuf被公开给外部使用之前内部就已经大量使用了，且1~32倍使用的很多，也 // 是不得已的事情，总不能为了开源、推广一个内部组件就把自己的生意砸了吧。 // 用户可以定义自定义选项来扩展当前Message repeated UninterpretedOption uninterpreted_option = 999; // 用户自定义选项来扩展message extensions 1000 to max; } // 描述一个parser不认识的option message // - UninterpretedOption只会出现在compiler::Parser类创建的options protos中； // - 构建Descriptor对象的时候DescriptorPool会解析UninterpretedOptions； // 因此，descriptor对象中的options protos（通过Descriptor::options()返回，或者 // 通过Descriptor::CopyTo()生成）是不会包括UinterpretedOptions的。 message UninterpretedOption { // uinterpreted选项的名字，name中每个元素的name_part字段都表示name中的点分字 // 符串的一段，如果name_part是一个扩展（通过在字符串两端用括号括起来表示）， // is_extension字段为true。 // 例如，{[\u0026quot;foo\u0026quot;, false], [\u0026quot;bar.baz\u0026quot;,true], [\u0026quot;qux\u0026quot;,false]}表示\u0026quot;foo.(bar.baz).qux\u0026quot;。 message NamePart { required string name_part = 1; required bool is_extension = 2; } repeated NamePart name = 2; // uinterpreted选项的值，会设置下面字段中其中一个的值 optional string identifier_value = 3; optional uint64 positive_int_value = 4; optional int64 negative_int_value = 5; optional double double_value = 6; optional bytes string_value = 7; optional string aggregate_value = 8; } // =================================================================== // Optional source code info // FileDescriptorProto是从之前的source file中生成的（source file指的是proto文 // 件），这里的SourceCodeInfo指的是proto中的“源代码”信息。 message SourceCodeInfo { // Location用于识别proto文件中的源代码片段，往往对应着一个特定的定义。这些 // Location信息对于IDE、代码索引工具、文档生成工具等是非常重要的。 // // 下面说明一下Location的概念和作用，以下面这个message为例： // message Foo { // optional string foo = 1; // } // 我们先只看上面这个message中的字段定义： // optional string foo = 1; // ^ ^^ ^^ ^ ^^^ // a bc de f ghi // 我们可以得到下面这几个Location： // span path represents // [a,i) [ 4, 0, 2, 0 ] The whole field definition. // [a,b) [ 4, 0, 2, 0, 4 ] The label (optional). // [c,d) [ 4, 0, 2, 0, 5 ] The type (string). // [e,f) [ 4, 0, 2, 0, 1 ] The name (foo). // [g,h) [ 4, 0, 2, 0, 3 ] The number (1). // // 每个proto文件解析之后用一个FileDescriptorProto来表示，所以Lcoation路径位 // 置从FileDescriptorProto开始。 // - 因为message Foo是一个message，proto中所有顶层message类型定义都在 // FileDescriptorProto中message_type字段存储，这个字段的tag是4，所以Location为[4]； // - 又因为message_type是repeated DescriptorProto类型，因为当前proto示例中 // Foo为第一个message，所以其在message_type列表中的索引值为0，所以Location为[4,0]； // - 因为我们现在看的“源代码”是“optional string foo = 1;”，我们需要定位到 // message中的字段位置，message Foo中的所有字段都在DescriptorProto中的field字 // 段中记录，这个字段的tag=2，所以Location变为[4,0,2]； // - 又因为这个DescriptorProto中的field为repeated FieldDescriptorProto field， // 因为这个message中只有一个字段foo，所以foo在field列表中的索引值为0，Location变为[4,0,2,0]; // 上面解释了定位到完整的“optional string foo = 1”定义这个field的Location变 // 化过程，下面再说一下label、type、name、number的Location如何进一步确定。 // FieldDescriptorProto中label的tag位4，type的tag为5，name的tag为1，number的 // tag为3，Location对应的追加索引4、5、1、3。gg! // // proto文件中的源代码信息就是由一系列的Location来寻址的。 repeated Location location = 1; message Location { // 前面已经描述了Location的确定过程，一个Location如[4,0,2,0]其中的数字要么 // 是字段的tag编号要么是repeated列表中的索引值，这里的数字构成的数组保存在 // path中。 repeated int32 path = 1 [packed=true]; // 该字段span总是包括3个或者4个元素，依次表示startline、startcolumn、endline、endcolumn repeated int32 span = 2 [packed=true]; // 如果这个SourceCodeInfo代表一个完整的声明的话，可能在这个声明的前面或者 // 后面可能有一些attached的注释。 // // 连续的多个行注释看做是一个单独的注释。 // // 这个字段只记录了注释内容，不包括注释内容开头的注释符号//。对于块注释， // 注释前面的空白字符、*这几种符号也会被清理掉。但是会包括换行符。 // // Examples: // // optional int32 foo = 1; // Comment attached to foo. // // Comment attached to bar. // optional int32 bar = 2; // // optional string baz = 3; // // Comment attached to baz. // // Another line attached to baz. // // // Comment attached to qux. // // // // Another line attached to qux. // optional double qux = 4; // // optional string corge = 5; // /* Block comment attached // * to corge. Leading asterisks // * will be removed. */ // /* Block comment attached to // * grault. */ // optional int32 grault = 6; // Location前面的注释信息 optional string leading_comments = 3; // Location后面的注释信息 optional string trailing_comments = 4; } }  2.4.2. 可以提取proto文件中的哪些信息 \u0026amp; 如何提取 # 前一节2.4.1中对descriptor.proto进行了详细地描述，可以说在proto文件中写的每一行内容都可以通过解析FileDescriptorProto来访问到。proto文件只是一种自描述的消息格式，基于这种格式生成面向特定编程语言的源代码文件时，我们想获取的信息不外乎如下几个：\n 待生成的源文件的包名； 待生成的源文件的wrapper class类名； proto文件中定义的各个类型，包括枚举enum、消息message、服务service； 对于枚举enum需要知道枚举类型名、列出的枚举值（包括字段、值、注释信息）、注释信息； 对于消息message需要知道类型名、类成员（包括成员类型、成员名称、定义顺序、默认值、注释信息）、注释信息； 对于服务service需要知道服务名称、服务rpc接口（rpc接口的请求参数、返回值类型、注释信息）、注释信息； proto中可以添加注解吗？注解可以提取出来吗？  如何提取上述信息呢？可以肯定地是，只要能拿到当前proto文件对应的FileDescriptorProto，上述内容几乎都可以获取到。但是如何获取到对应的proto文件对应的这个FileDescriptorProto对象呢？下面我们先来看一个protoc插件的示例代码吧，看完之后，大家也就了解了如何获取proto对应的FileDescriptorProto以及如何从中提取想要的1~7上述信息，生成源代码文件也就简单了。\n2.4.3. protoc go语言插件protoc-gen-go # protoc-gen-go的源代码可以通过通过如下方式获取：\ngit co https://github.com/golang/protobuf git branch -b ${new-branch}  2.4.3.1. protoc-gen-go入口函数分析 # file: protobuf/protoc-gen-go/main.go\npackage main import ( \u0026quot;io/ioutil\u0026quot; \u0026quot;os\u0026quot; \u0026quot;github.com/c4pt0r/proto\u0026quot; \u0026quot;github.com/c4pt0r/protoc-gen-go/generator\u0026quot; ) func main() { // 首先创建一个代码生成器generator，CodeGeneratorRequest、CodeGeneratorResponse // 结构体都被保存在generator中，CodeGenerateResponse中保存着代码生成过程中 // 的错误状态信息，因此我们可以通过这个结构体提取错误状态并进行错误处理 g := generator.New() // 从标准输入中读取CodeGeneratorRequest信息（标准输入已经被重定向到了父进程 // protoc进程创建的管道stdout_pipe的读端，父进程会从管道的写端写入该请求信息） data, err := ioutil.ReadAll(os.Stdin) if err != nil { g.Error(err, \u0026quot;reading input\u0026quot;) } // 读取到的数据时串行化之后的CodeGeneratorRequest，将其反串行化成CodeGeneratorRequest if err := proto.Unmarshal(data, g.Request); err != nil { g.Error(err, \u0026quot;parsing input proto\u0026quot;) } // 检查CodeGeneratorRequest中待生成的源代码文件数量，数量为0则无需生成 if len(g.Request.FileToGenerate) == 0 { g.Fail(\u0026quot;no files to generate\u0026quot;) } // 将CodeGeneratorRequest中传递给代码生成器的参数设置到protoc插件的代码生成器中 g.CommandLineParameters(g.Request.GetParameter()) // 前面的proto.Unmarshal(...)操作将stdin中的请求反串行化成了CodeGeneratorRequest， // 这里的g.WrapTypes()将请求中的一些descriptors进行进一步封装，方便后面引用 g.WrapTypes() g.SetPackageNames() g.BuildTypeNameMap() // 生成所有的源代码文件 g.GenerateAllFiles() // 将CodeGeneratorResponse对象进行串行化处理 data, err = proto.Marshal(g.Response) if err != nil { g.Error(err, \u0026quot;failed to marshal output proto\u0026quot;) } // 将串行化之后的CodeGenerateResponse对象数据写入标准输出（标准输出已经被 // 重定向到了父进程protoc进程创建的管道stdin_pipe的写端，父进程从管道的读 // 端读取这里的响应） _, err = os.Stdout.Write(data) if err != nil { g.Error(err, \u0026quot;failed to write output proto\u0026quot;) } }  2.4.3.2. 回顾一下CodeGeneratorRequest \u0026amp; CodeGeneratorResponse的定义 # 下面看下CodeGeneratorRequest和CodeGeneratorResponse的定义。\nfile: ${protobuf}/src/google/protobuf/compiler/plugin.go\n// 串行化后的CodeGeneratorRequest信息会被写入到插件程序的stdin message CodeGeneratorRequest { // protoc命令执行时，我们在命令行中列出了需要进行处理的.proto文件的名称，代 // 码生成器应该只为这些.proto文件生成源代码文件。每一个.proto文件成功解析之 // 后会生成一个FileDescriptorProto对象，这个对象会被加入到字段proto_file中 repeated string file_to_generate = 1; // protoc命令行程序中传递给插件程序代码生成器的参数信息 optional string parameter = 2; // protoc命令行中列出的所有的.proto文件被添加到了字段file_to_generate中，这 // 些.proto文件中通过import引入进来的文件，这两部分文件解析成功后对应的 // FileDescriptorProto对象都会被加入到这里的proto_file中，添加后的顺序是按照 // 拓扑顺序排序的，怎么讲？就是被import的proto文件会出现在import它们的 proto // 文件前面。 repeated FileDescriptorProto proto_file = 15; } // 串行化后的CodeGeneratorResponse信息会被写入到插件的stdout message CodeGeneratorResponse { // 如果错误信息非空，表示代码生成失败。这种情况下尽管代码生成失败，插件进程 // 仍然应该返回一个状态0。 // // 这个字段用于指示.proto文件错误，.proto文件中的错误将使得代码生成器无法生 // 成正确的代码。指示protoc本身的错误，例如CodeGeneratorRequest数据无法被正 // 确地反串行化，这种情况应该被报告，错误信息应该写到stderr并且插件进程应该 // 返回一个非0状态码 optional string error = 1; // 描述一个待生成的源代码文件 message File { // 待生成的源代码文件相对于输出目录的文件名 optional string name = 1; // 写入到源代码文件中的插入点信息，方便后面的插件在插入点处进行扩展其他内容 optional string insertion_point = 2; // 写入到文件或者文件插入点位置的内容 optional string content = 15; } // 所有的待生成的源代码文件列表 repeated File file = 15; }  2.4.3.3. generator实现分析 # main.go中调用了generator的几个关键方法，我们先来看下这几个方法都做了些什么，然 后再跟进一步看看generator的详细实现过程。\n2.4.3.3.1. generator.New() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// Generator类型的方法能够输出源代码，这些输出的源代码信息存储在Response成员中 type Generator struct { *bytes.Buffer Request *plugin.CodeGeneratorRequest // The input. Response *plugin.CodeGeneratorResponse // The output. Param map[string]string // Command-line parameters. PackageImportPath string // Go import path of the package we're generating code for ImportPrefix string // String to prefix to imported package file names. ImportMap map[string]string // Mapping from .proto file name to import path Pkg map[string]string // The names under which we import support packages packageName string // What we're calling ourselves. allFiles []*FileDescriptor // All files in the tree allFilesByName map[string]*FileDescriptor // All files by filename. genFiles []*FileDescriptor // Those files we will generate output for. file *FileDescriptor // The file we are compiling now. usedPackages map[string]bool // Names of packages used in current file. typeNameToObject map[string]Object // Key is a fully-qualified name in input syntax. init []string // Lines to emit in the init function. indent string writeOutput bool } // 创建一个新的代码生成器，并创建请求、响应对象 func New() *Generator { g := new(Generator) g.Buffer = new(bytes.Buffer) g.Request = new(plugin.CodeGeneratorRequest) g.Response = new(plugin.CodeGeneratorResponse) return g }  2.4.3.3.2. generator.CommandLineParameters(\u0026hellip;) # 这个函数是负责解析protoc传递过来的命令行参数信息的。\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 将都好分隔的key=value列表解析成\u0026lt;key,value\u0026gt; map func (g *Generator) CommandLineParameters(parameter string) { g.Param = make(map[string]string) for _, p := range strings.Split(parameter, \u0026quot;,\u0026quot;) { if i := strings.Index(p, \u0026quot;=\u0026quot;); i \u0026lt; 0 { g.Param[p] = \u0026quot;\u0026quot; } else { g.Param[p[0:i]] = p[i+1:] } } g.ImportMap = make(map[string]string) pluginList := \u0026quot;none\u0026quot; // Default list of plugin names to enable (empty means all). for k, v := range g.Param { switch k { case \u0026quot;import_prefix\u0026quot;: g.ImportPrefix = v case \u0026quot;import_path\u0026quot;: g.PackageImportPath = v // --go_out=plugins=grpc:.，解析这里的参数plugins=grpc case \u0026quot;plugins\u0026quot;: pluginList = v default: if len(k) \u0026gt; 0 \u0026amp;\u0026amp; k[0] == 'M' { g.ImportMap[k[1:]] = v } } } // 在protoc-gen-go的某个地方已经将grpc插件注册到了当前generator（也就是添 // 加到plugins []Plugin中），但是到底是在哪里注册的呢？只有注册并激活（参 // 数中通过--go_out=plugins=grpc:.)grpc子插件，该子插件才能被使用于后续的 // 代码生成过程中（生成rpc相关的go源代码）。 // // 其实这里的grpc子插件注册是利用了link_grpc.go里面的import _操作来隐式地 // 调用了grpc.init()方法，该初始化方法中负责完成向generator的注册操作，即 // generator.RegisterPlugin(new(grpc))，这里的RegisterPlugin其实就是将指定 // 的子插件加入到plugins []Plugin slice中。 // 为了能够在protoc-gen-go中正确地将grpc link进去，在构建protoc-gen-go的时 // 候需要执行命令： // cd protoc-gen-go \u0026amp; go build main.go link_grpc.go // go build的时候如果没有列出link_grpc.go，那么grpc是不会被link进 // protoc-gen-go这个插件的，这样处理.proto文件中的service时插件是不会生成 // service相关的go源代码的。 // 根据--go_out=plugins=?+?+?:.，更新激活的插件列表 if pluginList != \u0026quot;\u0026quot; { // Amend the set of plugins. enabled := make(map[string]bool) for _, name := range strings.Split(pluginList, \u0026quot;+\u0026quot;) { enabled[name] = true } var nplugins []Plugin for _, p := range plugins { if enabled[p.Name()] { nplugins = append(nplugins, p) } } plugins = nplugins } }  2.4.3.3.3. generator.WrapTypes() # file: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// WrapTypes walks the incoming data, wrapping DescriptorProtos, EnumDescriptorProtos // and FileDescriptorProtos into file-referenced objects within the Generator. // It also creates the list of files to generate and so should be called before GenerateAllFiles. func (g *Generator) WrapTypes() { g.allFiles = make([]*FileDescriptor, 0, len(g.Request.ProtoFile)) g.allFilesByName = make(map[string]*FileDescriptor, len(g.allFiles)) for _, f := range g.Request.ProtoFile { // We must wrap the descriptors before we wrap the enums descs := wrapDescriptors(f) g.buildNestedDescriptors(descs) enums := wrapEnumDescriptors(f, descs) g.buildNestedEnums(descs, enums) exts := wrapExtensions(f) fd := \u0026amp;FileDescriptor{ FileDescriptorProto: f, desc: descs, enum: enums, ext: exts, exported: make(map[Object][]symbol), proto3: fileIsProto3(f), } extractComments(fd) g.allFiles = append(g.allFiles, fd) g.allFilesByName[f.GetName()] = fd } for _, fd := range g.allFiles { fd.imp = wrapImported(fd.FileDescriptorProto, g) } g.genFiles = make([]*FileDescriptor, 0, len(g.Request.FileToGenerate)) for _, fileName := range g.Request.FileToGenerate { fd := g.allFilesByName[fileName] if fd == nil { g.Fail(\u0026quot;could not find file named\u0026quot;, fileName) } fd.index = len(g.genFiles) g.genFiles = append(g.genFiles, fd) } }  2.4.3.3.4. generator.GenerateAllFiles() # 调用generator针对所有解析成功的proto文件生成所有的go源代码\nfile: ${golang-protobuf}/protoc-gen-go/generator/generator.go\n// 生成所有.proto文件对应的go源代码，这里只是将源代码内容存储到g.Response中， // 并没有直接创建源代码文件，插件将Response传递给protoc进程后由protoc进程来负 // 责创建源代码文件 func (g *Generator) GenerateAllFiles() { // Initialize the plugins for _, p := range plugins { p.Init(g) } // Generate the output. The generator runs for every file, even the files // that we don't generate output for, so that we can collate the full list // of exported symbols to support public imports. genFileMap := make(map[*FileDescriptor]bool, len(g.genFiles)) for _, file := range g.genFiles { genFileMap[file] = true } for _, file := range g.allFiles { g.Reset() g.writeOutput = genFileMap[file] // 调用generator的generate(...)方法来生成该proto文件的 // FileDescriptorProto描述对应的go源代码 g.generate(file) if !g.writeOutput { continue } g.Response.File = append(g.Response.File, \u0026amp;plugin.CodeGeneratorResponse_File{ Name: proto.String(file.goFileName()), Content: proto.String(g.String()), }) } }  再看下generator.generate(\u0026hellip;)方法是如何实现的。\n// 针对.proto文件（由FileDescriptor表示）生成对应的go源代码 func (g *Generator) generate(file *FileDescriptor) { g.file = g.FileOf(file.FileDescriptorProto) g.usedPackages = make(map[string]bool) // 要生成源代码的首个proto文件对应的go源代码，这部分代码顶部插入版权信息 if g.file.index == 0 { // For one file in the package, assert version compatibility. g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the proto package it is being compiled against.\u0026quot;) g.P(\u0026quot;// A compilation error at this line likely means your copy of the\u0026quot;) g.P(\u0026quot;// proto package needs to be updated.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, g.Pkg[\u0026quot;proto\u0026quot;], \u0026quot;.ProtoPackageIsVersion\u0026quot;, generatedCodeVersion, \u0026quot; // please upgrade the proto package\u0026quot;) g.P() } // 生成import语句 for _, td := range g.file.imp { g.generateImported(td) } // 生成enum类型定义语句 for _, enum := range g.file.enum { g.generateEnum(enum) } // 生成message类型定义语句 for _, desc := range g.file.desc { // Don't generate virtual messages for maps. if desc.GetOptions().GetMapEntry() { continue } g.generateMessage(desc) } // 生成extension类型定义语句 for _, ext := range g.file.ext { g.generateExtension(ext) } // 生成初始化函数语句 g.generateInitFunction() // 前面生成enum、message、extension等的方式都基本类似，后面我们只给出一个 // 生成枚举类型方法的说明，生成message、extension的实现方法可以执行查看 // generator.go中的实现。 // // 需要注意的是，前面的各个生成源代码的方法不能处理service服务定义的rpc接 // 口代码，这部分rpc代码的生成需要借助于grpc子插件来完成，即下面的g.runPlugins(...) g.runPlugins(file) g.generateFileDescriptor(file) // 待输出的源代码需要知道哪些package是需要import的，哪些不需要，因此先运行 // 插件生成go代码中除import之外的其他部分代码，然后知道了哪些package需要 // import，再插入具体的import语句。 // // 最后在go源代码中插入header、import rem := g.Buffer g.Buffer = new(bytes.Buffer) g.generateHeader() g.generateImports() if !g.writeOutput { return } g.Write(rem.Bytes()) // 重新格式化生成的go源代码（gofmt） fset := token.NewFileSet() raw := g.Bytes() ast, err := parser.ParseFile(fset, \u0026quot;\u0026quot;, g, parser.ParseComments) if err != nil { // Print out the bad code with line numbers. // This should never happen in practice, but it can while changing generated code, // so consider this a debugging aid. var src bytes.Buffer s := bufio.NewScanner(bytes.NewReader(raw)) for line := 1; s.Scan(); line++ { fmt.Fprintf(\u0026amp;src, \u0026quot;%5d\\t%s\\n\u0026quot;, line, s.Bytes()) } g.Fail(\u0026quot;bad Go source code was generated:\u0026quot;, err.Error(), \u0026quot;\\n\u0026quot;+src.String()) } g.Reset() err = (\u0026amp;printer.Config{Mode: printer.TabIndent | printer.UseSpaces, Tabwidth: 8}).Fprint(g, fset, ast) if err != nil { g.Fail(\u0026quot;generated Go source code could not be reformatted:\u0026quot;, err.Error()) } }  上面generate.generate(\u0026hellip;)方法中generateEnum()、generateMessage()方法与其他几个方法都是非常类似的，由于大家使用protobuf过程中使用enum、message比较多，并且generateEnum()、generateMessage()方法执行逻辑非常相似，考虑到篇幅方面generateEnum()比generateMessage()简短，这里我们就只以generateEnum()的源代码作为示例进行分析。相信如果看懂了generateEnum的实现思路，generateMessage的实现思路也很容易搞明白，读者也具备了自己实现子插件的能力。\n// 生成指定enum类型的go源代码 func (g *Generator) generateEnum(enum *EnumDescriptor) { // enum类型的完整类型名 typeName := enum.TypeName() // CamelCased之后的完整类型名 ccTypeName := CamelCaseSlice(typeName) ccPrefix := enum.prefix() // 打印enum类型定义之前的leading comments // - 提取源代码信息SourceCodeInfo都是通过Location path来获取的； // - 提取注释信息也不例外，下面我们会介绍PrintComments(path)如何通过 // Location path来生成注释信息； g.PrintComments(enum.path) // 生成枚举类型的定义起始部分：type 枚举类型名 int32 g.P(\u0026quot;type \u0026quot;, ccTypeName, \u0026quot; int32\u0026quot;) g.file.addExport(enum, enumSymbol{ccTypeName, enum.proto3()}) // 枚举类型里面的各个枚举值都作为const int32常量来定义 g.P(\u0026quot;const (\u0026quot;) // 枚举值定义之前缩进一下 g.In() // 针对枚举类型里面的所有枚举值进行源代码生成 for i, e := range enum.Value { // 生成枚举值前面的leading comments g.PrintComments(fmt.Sprintf(\u0026quot;%s,%d,%d\u0026quot;, enum.path, enumValuePath, i)) // 生成枚举值的name = value形式的go源代码 name := ccPrefix + *e.Name g.P(name, \u0026quot; \u0026quot;, ccTypeName, \u0026quot; = \u0026quot;, e.Number) g.file.addExport(enum, constOrVarSymbol{name, \u0026quot;const\u0026quot;, ccTypeName}) } // 枚举值定义完之后取消缩进 g.Out() // 打印最后的结束信息 g.P(\u0026quot;)\u0026quot;) // 生成枚举类型相关的两个map // - 其中一个是枚举值到枚举名的映射； // - 另一个是枚举名到枚举值的映射； g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_name = map[int32]string{\u0026quot;) g.In() // 第一个map generated := make(map[int32]bool) // avoid duplicate values for _, e := range enum.Value { duplicate := \u0026quot;\u0026quot; if _, present := generated[*e.Number]; present { duplicate = \u0026quot;// Duplicate value: \u0026quot; } g.P(duplicate, e.Number, \u0026quot;: \u0026quot;, strconv.Quote(*e.Name), \u0026quot;,\u0026quot;) generated[*e.Number] = true } g.Out() g.P(\u0026quot;}\u0026quot;) // 第二个map g.P(\u0026quot;var \u0026quot;, ccTypeName, \u0026quot;_value = map[string]int32{\u0026quot;) g.In() for _, e := range enum.Value { g.P(strconv.Quote(*e.Name), \u0026quot;: \u0026quot;, e.Number, \u0026quot;,\u0026quot;) } g.Out() g.P(\u0026quot;}\u0026quot;) // 其他处理动作，也会生成部分源代码，这里可以忽略不计了 // ... }  下面看一下PrintComments如何通过Location path来提取并打印关联的注释信息。\n// 打印.proto文件中对该location path关联的leading comments注释信息 func (g *Generator) PrintComments(path string) bool { if !g.writeOutput { return false } // 在protoc进程解析.proto文件的时候就已经将各个类型、字段的comments信息维 // 护起来了，k就是location的path，通过path就能获取到对应的location，每个 // location中保存了这个位置的源代码的leading comments、trailing comments信 // 息，这里只打印leading comments if loc, ok := g.file.comments[path]; ok { text := strings.TrimSuffix(loc.GetLeadingComments(), \u0026quot;\\n\u0026quot;) for _, line := range strings.Split(text, \u0026quot;\\n\u0026quot;) { g.P(\u0026quot;// \u0026quot;, strings.TrimPrefix(line, \u0026quot; \u0026quot;)) } return true } return false }  看到这里我们对于基本的enum、message类型定义等都基本清楚了，下面我们需要看一下grpc子插件是如何生成service服务的rpc接口源代码的，这样的话，就得再来看一下g.runPlugins(file)是如何实现的。\n// Run all the plugins associated with the file. func (g *Generator) runPlugins(file *FileDescriptor) { // 在上述generator处理的基础上，继续运行generator中注册的插件，依次运行插件 for _, p := range plugins { p.Generate(file) } }  因为上述runPlugins(\u0026hellip;)执行过程中，plugins这个slice内只有一个有效的、激活的子插件grpc，因此如果我们想了解service服务对应的rpc接口的实现方式，我们需要就只需要了解grpc这个插件的Generate(file)方法就可以了。\n// 生成.proto文件中service定义的rpc接口的go源代码 func (g *grpc) Generate(file *generator.FileDescriptor) { // 如果没有定义service服务直接返回 if len(file.FileDescriptorProto.Service) == 0 { return } // 相关变量定义 g.P(\u0026quot;// Reference imports to suppress errors if they are not otherwise used.\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, contextPkg, \u0026quot;.Context\u0026quot;) g.P(\u0026quot;var _ \u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P() // 断言，检查版本兼容性 g.P(\u0026quot;// This is a compile-time assertion to ensure that this generated file\u0026quot;) g.P(\u0026quot;// is compatible with the grpc package it is being compiled against.\u0026quot;) g.P(\u0026quot;const _ = \u0026quot;, grpcPkg, \u0026quot;.SupportPackageIsVersion\u0026quot;, generatedCodeVersion) g.P() // 针对所有的service定义生成相关的service的go源代码 for i, service := range file.FileDescriptorProto.Service { g.generateService(file, service, i) } } // grpc中对generateService的实现，生成service相关的go源代码 // @param .proto解析后的各种DescriptorProto的wrapping类，通过它可以方便地访问.proto中定义的东西 // @param .proto中的某个service解析后对应的ServiceDescriptorProto // @param .proto中可能定义了多个service，当前这个service对应的索引值 func (g *grpc) generateService(file *generator.FileDescriptor, service *pb.ServiceDescriptorProto, index int) { // 构建当前service对应的path! path := fmt.Sprintf(\u0026quot;6,%d\u0026quot;, index) // 6 means service. // 获取service名称 origServName := service.GetName() fullServName := origServName if pkg := file.GetPackage(); pkg != \u0026quot;\u0026quot; { fullServName = pkg + \u0026quot;.\u0026quot; + fullServName } servName := generator.CamelCase(origServName) // 准备生成client相关的go源代码 g.P() g.P(\u0026quot;// Client API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务用户端go源代码生成 // - type 服务名+Client interface g.P(\u0026quot;type \u0026quot;, servName, \u0026quot;Client interface {\u0026quot;) // - 服务用户端定义的各个接口方法 for i, method := range service.Method { // 打印接口的leading comments g.gen.PrintComments(fmt.Sprintf(\u0026quot;%s,2,%d\u0026quot;, path, i)) // 2 means method in a service. // 生成接口的签名 g.P(g.generateClientSignature(servName, method)) } g.P(\u0026quot;}\u0026quot;) g.P() // 服务的用户端struct，其中包括了一个cc *grpc.ClientConn，后面会在该struct // 上实现上述服务接口 g.P(\u0026quot;type \u0026quot;, unexport(servName), \u0026quot;Client struct {\u0026quot;) g.P(\u0026quot;cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() // NewClient工厂 g.P(\u0026quot;func New\u0026quot;, servName, \u0026quot;Client (cc *\u0026quot;, grpcPkg, \u0026quot;.ClientConn) \u0026quot;, servName, \u0026quot;Client {\u0026quot;) g.P(\u0026quot;return \u0026amp;\u0026quot;, unexport(servName), \u0026quot;Client{cc}\u0026quot;) g.P(\u0026quot;}\u0026quot;) g.P() var methodIndex, streamIndex int serviceDescVar := \u0026quot;_\u0026quot; + servName + \u0026quot;_serviceDesc\u0026quot; // 服务用户端的接口方法实现 for _, method := range service.Method { var descExpr string if !method.GetServerStreaming() \u0026amp;\u0026amp; !method.GetClientStreaming() { // Unary RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Methods[%d]\u0026quot;, serviceDescVar, methodIndex) methodIndex++ } else { // Streaming RPC method descExpr = fmt.Sprintf(\u0026quot;\u0026amp;%s.Streams[%d]\u0026quot;, serviceDescVar, streamIndex) streamIndex++ } g.generateClientMethod(servName, fullServName, serviceDescVar, method, descExpr) } g.P(\u0026quot;// Server API for \u0026quot;, servName, \u0026quot; service\u0026quot;) g.P() // 服务端接口go源代码生成 ... }  看完之后我们已经清楚了generator做了什么、grpc子插件又做了什么，以及各自的细节是什么样的。下面我们将在此学习、理解的基础上开发一个自己的protoc插件。\n"}),a.add({id:490,href:"/tags/aio/",title:"aio",description:"",content:""}),a.add({id:491,href:"/tags/io-multiplex/",title:"io-multiplex",description:"",content:""}),a.add({id:492,href:"/blog/2017-05-02-linux-common-io-model/",title:"Linux常见IO模型",description:"高性能服务器开发，离不开对网络IO的深刻认识。本文结合Linux平台，详细总结了阻塞IO、非阻塞IO、IO多路复用、实时信号驱动、异步IO的原理、使用、适用场景，加深了对网络IO的认识。",content:"目前Linux下可用的IO模型有5种，分别为阻塞IO、非阻塞IO、IO多路复用、信号驱动IO、异步IO，其中较为成熟且高效、稳定的是IO多路复用模型，因此当前众多网络服务程序几乎都是采用这种IO操作策略。\n当一个应用程序读写（以读为例）某端口数据时，选择不同IO模型的应用程序，其执行流程也将不同。下面将对选择这5种不同IO模型时的程序的执行情形进行分析，以便了解使用IO复用模型的运行情况和性能优势。\n一个完整经典的应用程序的数据读取操作可以看做两步：\n 等待数据准备好； 将数据从内核复制到应用程序进程；  1. 阻塞IO模型 # 最流行的IO模型是阻塞IO（Blocking IO）模型，几乎所有刚开始学习IO操作的人员都是使用这个模型，虽然它存在一定的性能缺陷，但是它的确很简单。\n如下图所示，是利用该模型读取IO端口数据的典型流程。在有些情况下，当系统调用发现用户请求的IO操作不能立刻完成时（比如对IO写操作，缓冲区没有空闲空间或者空闲空间少于待写的数据量；而对于读操作，缓冲区中没有数据可读或者可读数据少于用户请求的数据量），则当前的进程会进入睡眠，也就是进程被IO读写阻塞。但是当数据可以写出或者有数据可供读入时（其他进程或线程从缓冲区中读走了数据后或者向缓冲区写入了数据），系统将会产生中断，唤醒在缓冲区上等待相应事件的进程继续执行。\n 备注：\n有必要在这里进一步解释一下“阻塞IO”的含义。通过阻塞IO系统调用进行IO操作时，以read为例，在内核将数据拷贝到用户程序完成之前，Linux内核会对当前read请求操作的缓冲区（内存中的特殊区域）进行加锁，并且会将调用read的进程的状态设置为 “uninterruptible wait”状态（不可中断等待状态），处于该状态的进程将无法参与进程调度。能够参与进程调度的进程的状态必须是处于running状态的进程或者有信号到达的处于interruptible wait状态（可中断等待状态）的进程。当read操作完成时，内核会将对应的缓冲块解锁，然后发出中断请求，内核中的中断服务程序会将阻塞在该缓冲块上的进程的状态修改为running状态以使其重新具备参与进程调度的能力。\n 2. 非阻塞IO模型 # 在有些时候并不希望进程在IO操作未完成时睡眠，而是希望系统调用能够立刻返回一个错误，以报告这一情况，然后进程可以根据需要在适当的时候再重新执行这个IO操作。这就是所谓的非阻塞IO模型。\n如下图所示，应用程序前几次read系统调用时都没有数据可供返回，此时内核立即返回一个EAGAIN错误代码，程序并不睡眠而是继续调用read，当第四次调用read时数据准备好了，于是执行数据从内核到用户空间的复制操作并成功返回，应用程序接着处理数据。这种对一个非阻塞IO端口反复调用read进行数据读取的动作称为轮询，即应用程序持续轮询内核数据是否准备好。这里的持续轮询操作将导致耗费大量的CPU时间，因此该模型并不推荐使用。\n3. IO多路复用模型 # 前面介绍了非阻塞IO模型的问题在于，尽管应用程序可以在当前IO操作不能完成的时候迫使系统调用立刻返回而不至于睡眠，但是却无法知道什么时候再次请求IO操作可以顺利完成，只能周期性地做很多无谓的轮询，每隔一段时间就要重新请求一次系统调用，这种轮询策略极大浪费了CPU时间。\nIO多路复用模型就是在此之上的改进，它的好处在于使得应用程序可以同时对多个IO端口进行监控以判断其上的操作是否可以顺利（无阻塞地）完成，达到时间复用的目的。进程阻塞在类似于select、poll或epoll这样的系统调用上，而不是阻塞在真正的IO系统调用上，意思也就是说在这些select、poll或者epoll函数内部会代替我们做非阻塞地轮询，那么它的轮询策略是怎样地呢？稍后会进行介绍。\nselect、poll或epoll使得进程可以在多个IO端口上等待IO事件（可读、可写、网络连接请求等）的发生，当有事件发生时再根据发生事件的类型进行适当的IO处理。不过进程在等待IO事件发生时仍然在代码执行序上处于“阻塞”状态，应用程序“阻塞”在这里照样还是无法做其他的工作（尽管可以指定轮询时等待时间的长短）。如果希望进程在没有IO事件要处理时还能做其他的工作，可以考虑分派任务给其他线程、进程，当然也可以在当前线程做，但是不宜过久以免影响处理IO事件。\n下图是IO多路复用模型的示例。\nIO多路复用模型主要有3种实现形式，select、poll、epoll。\n3.1. select # #include \u0026lt;sys/select.h\u0026gt; //返回值：readfds、writefds、exceptfds中事件就绪的fd的数量 int select(int nfds, // 最大文件描述符fd+1 fd_set *restrict readfds, // 等待读取的fds fd_set *restrict writefds, // 等待写入的fds fd_set *restrict exceptfds, // 异常fds struct timeval *restrict timeout); // 超时时间 //返回值：readfds、writefds、exceptfds中事件就绪的fd的数量 int pselect(int nfds, // 最大文件描述符fd+1 fd_set *restrict readfds, // 等待读取的fds fd_set *restrict writefds, // 等待写入的fds fd_set *restrict exceptfds, // 异常fds const struct timespec *restrict timeout, // 超时时间 const sigset_t *restrict sigmask); // 信号掩码   备注：\nIO事件就绪的意思是，执行对应的IO操作时可以无阻塞地完成。例如读事件就绪，表明一定有数据到达，或者已经读取到了数据的结束位置EOF。\n #define __FD_SETSIZE 1024 typedef struct { /* XPG4.2 requires this member name. Otherwise avoid the name from the global namespace. */ #ifdef __USE_XOPEN __fd_mask fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;fds_bits) #else __fd_mask __fds_bits[__FD_SETSIZE / __NFDBITS]; # define __FDS_BITS(set) ((set)-\u0026gt;__fds_bits) #endif } fd_set;  select和pselect基本是相同的，它们主要有3点细微的差别：\n select使用的超时时间struct timeval是微秒级的，而pselect使用的struct timespec可以精确到纳秒级； select会更新timeout的值，将其修改为剩余轮询时间，而pselect不会对timeout做修改； select无法指定轮询时的信号掩码，而pselect允许指定信号掩码，如果pselect第6个参数不为NULL，则用其先替换当前的信号掩码，然后执行与select相同的操作，返回时再还原之前的信号掩码；  fd_set只是一个普通的用于记录待监视的fd的位图，由于__FD_SETSIZE硬编码为1024，所以select最多只能监视1024个fd。\n对fd_set的操作主要通过如下几个函数。\n#include \u0026lt;sys/select.h\u0026gt; void FD_CLR(int fd, fd_set *fdset); // 从fdset中删除fd void FD_ISSET(int fd, fd_set *fdset); // 测试fd是否已添加到fdset中 void FD_SET(int fd, fd_set *fdset); // 向fdset中添加fd void FD_ZERO(fd_set *fdset); // 清空fdset  下面对timeout相关的数据结构进行一下说明：\n 如果timeout中的两个字段均为0，则表示select立即返回； 如果timeout中的任意一个字段不为0，则表示select轮询时经过指定的时间后会返回； 如果timeout为NULL，则表示select会阻塞到有事件就绪才返回；  struct timeval { long tv_sec; long tv_usec; }; struct timespec { long tv_sec; long tv_nsec; };  在循环使用select函数时有三个地方值得注意:\n 第一，虽然在普遍情况下，参数timeout在select函数返回时不会被修改，但是有的Linux版本却会将这个值修改成函数返回时剩余的等待秒数，因此从可移植性上考虑，在每次重新调用select函数前都得再次对参数timeout初始化。 第二，select函数中间的三个参数（即感兴趣的描述符集）在select函数返回时，其保存有指示哪些描述符已经进入就绪状态（此时其对应bit被设置为1，其他未就绪描述符对应bit设置为0），从而程序可以使用宏FD_ISSET来测试描述符集中的就绪描述符。因此，在每次重新调用select函数前都得再次把所有描述符集中关注的fd对应的bit设置为1。 第三，应注意到利用select函数监控的最大描述符收到系统FD_SETSIZE宏的限制，最多能够监视1024个描述符，在高并发情景中，select是难以胜任的。  下面是select的编程模板，可在此基础上进行改进。\n// 可读、可写、异常3种文件描述符集的声明和初始化 fd_set readfds, writefds, exceptfds; FD_ZERO(\u0026amp;readfds); FD_ZERO(\u0026amp;writefds); FD_ZERO(\u0026amp;exceptfds); int max_fd; // socket配置和监听 int sock = socket(...); bind(sock, ...); listen(sock, ...); // 对socket描述符上关心的事件进行注册，select不要求fd非阻塞 FD_SET(sock, \u0026amp;readfds); max_fd = sock; while(1) { int i; fd_set r, w, e; // 为了重复使用readfds、writefds、exceptionfds，将他们复制到临时变量内 memcpy(\u0026amp;r, \u0026amp;readfds, sizeof(fd_set)); memcpy(\u0026amp;w, \u0026amp;writefds, sizeof(fd_set)); memcpy(\u0026amp;e, \u0026amp;exceptfds, sizeof(fd_set)); // 利用临时变量调用select阻塞等待，等待时间为永远等待直到事件发生 select(max_fd+1, \u0026amp;r, \u0026amp;w, \u0026amp;e, NULL); // 测试是否有客户端发起连接请求，如果有则接受并把新建的描述符加入监控 if(FD_ISSET(sock, \u0026amp;r)) { new_sock = accept(sock, ...); FD_SET(new_sock, \u0026amp;readfds); FD_SET(new_sock, \u0026amp;writefds); max_fd = MAX(max_fd, new_sock); } // 对其他描述符上发生的事件进行适当处理 // 描述符依次递增，各系统的最大值可能有所不同，一般可以通过ulimit -n进行设置 for(i=sock+1; i\u0026lt;max_fd+1; ++i) { if(FD_ISSET(i, \u0026amp;r)) { doReadAction(i); } if(FD_ISSET(i, \u0026amp;w)) { doWriteAction(i); } } }   备注： 上述只是一个非常简单的select使用示例，在实际使用过程中需要考虑一些其他的因素，例如对端的tcp连接socket关闭时应该怎样处理，关闭又可以细分为关闭读和写两种情况。\n 代码示例：\n点击这里查看基于select实现的tcp server，[click to see select-based-tcp-server]。\n3.2. poll # #include \u0026lt;poll.h\u0026gt; int poll(struct pollfd *fds, // 待监视的fd构成的struct pollfd数组 nfds_t nfds, // 数组fds[]中元素数量 int timeout); // 轮询时等待的最大超时时间 struct pollfd { int fd; // 待监视的fd short events; // 请求监视的事件 short revents; // 实际收到的事件 };  pollfd中可指定的event类型包括：\n POLLIN，普通数据读取； POLLPRI，紧急数据读取； POLLOUT，普通数据可写； POLLRDHUP，面向流的socket，对端socket关闭连接或者关闭了写半连接； POLLERR，错误； POLLHUP，挂起； POLLNVAL，无效请求，fd没有打开；  当如果通过宏_XOPEN_SOURCE进行条件编译时，还可指定如下event类型：\n POLLRDNORM，与POLLIN等效； POLLRDBAND，优先级带数据可读，在Linux上通常是无用的； POLLWRNORM，与POLLOUT等效； POLLWRBAND，优先级数据可写；  poll系统调用的第三个参数timeout指定了轮询时的等待事件，当timeout\u0026lt;0时永远等待直到监视的fds上有事件发生，当timeout=0时立即返回，单timeout\u0026gt;0时等待到指定的超时时间后返回。poll不要求监视的fd为非阻塞。\npoll与select相比具有如下优势：\n poll系统调用中通过第二个参数nfds来限定要监视的描述符的数量，与select相比，poll去掉了硬编码的FD_SETSIZE宏的监控fd数量上限； 另外poll通过pollfd中的revents来接收fd上到达的事件，events不会被修改，每次调用poll时不用像select一样每次都需要重新设置r、w、e文件描述符集，方便使用也减少数据向内核拷贝的开销。  // 新建并初始化文件描述符集 struct pollfd fds[MAX_NUM_FDS]; int max_fd; // socket配置和监听 sock = socket(...); bind(sock, ...); listen(sock, ...); // 对socket描述符上关心的事件进行注册 fds[0].fd = sock; fds[0].events = POLLIN; max_fd = 1; while(1) { int i; // 调用poll阻塞等待，等待时间为永远等待直到事件发生 poll（fds, max_fd, -1); // 测试是否有客户端发起连接请求，如果有则接受并把新建的描述符加入监控 if(fds[0].revents \u0026amp; POLLIN) { new_sock = accept(sock, ...); fds[max_fd].fd = new_sock; fds[max_fd].events = POLLIN | POLLOUT; ++ max_fd; } // 对其他描述符发生的事件进行适当处理 for(i=1; i\u0026lt;max_fd+1; ++i) { if(fds[i].revents \u0026amp; POLLIN) { doReadAction(i); } if(fds[i].revents \u0026amp; POLLOUT) { doWriteAction(i); } } }   备注：\n上面的代码也是只给出了一个最简单的编程示例，对于对端tcp连接关闭的情况也需要予以考虑，避免服用端占用大量的fd。\n从上面基于select/poll多路复用IO模型可以看出，在大量的并发连接中，如果空闲连接（即无事件发生的连接）较多，select/poll的性能会因为并发数的线性上升而成线型速度下降，实际上性能可能比线型下降更差。当连接数很大时，系统开销会异常大。\n另外select、poll每次返回时都需要从内核向用户空间复制大量的数据，数据复制的开销也会很大，select主要是从内核向用户空间复制readfds、writefds、exceptfds开销大，poll主要是从内核复制pollfd[]开销大。\n使用select/poll实现的多路复用IO模型是最稳定也是使用最为广泛的事件驱动IO模型，但是其固有的一些缺点（如性能低下、伸缩性不强）使得各种更为先进的替代方案出现在各种平台下。\n 代码示例：\n点击这里查看基于poll实现的tcp server，[click to see poll-based-tcp-server]。\n3.3. epoll # epoll作为poll的变体在Linux内核2.5中被引入，相比于select实现的多路复用IO模型，epoll的最大好处在于它不会随着监控描述符数目的增长而使效率急剧下降。在内核中的select实现是采用轮询处理的，轮询的描述符数目越多，自然耗时越多，而且在很多情况下，select最多能同时监听的描述符数目为1024个。\nepoll提供了三种系统调用，如下所示。\n#include \u0026lt;sys/poll.h\u0026gt; // 创建一个epfd，最多监视${size}个文件描述符 int epoll_create(int size); int epoll_ctl(int epfd, // epfd int op, // 操作类型（注册、取消注册） int fd, // 待监视的fd struct epoll_event *event); // 待监视的fd上的io事件 int epoll_wait(int epfd, // epfd struct epoll_event *events, // 最终返回的就绪事件 int maxevents, // 期望的就绪事件数量 int timeout); // 超时时间 int epoll_wait(int epfd, // epfd struct epoll_event *events, // 接收返回的就绪事件 int maxevents, // 期望的就绪事件数量 int timeout, // 超时时间 const sigset_t *sigmask); // 信号掩码 typedef union epoll_data { void *ptr; int fd; __uint32_t u32; __uint64_t u64; } epoll_data_t; struct epoll_event { __uint32_t events; // epoll events epoll_data_t data; // user data variable };  epoll中可以关注的事件主要有：\n EPOLLIN，数据可读事件； EPOLLOUT，数据可写事件； EPOLLRDHUP，流socket对端关闭连接或者关闭了写半连接； EPOLLPRI，紧急数据读取事件； EPOLLERR，错误事件； EPOLLHUP，挂起事件，epoll总是会等待该事件，不需要显示设置； EPOLLET，设置epoll以边缘触发模式工作（不指定该选项则使用级别触发Level Trigger模式）； EPOLLONESHOT，设置epoll针对某个fd上的事件只通知一次，一旦epoll通知了某个事件，该fd上后续到达的事件将不会再发送通知，除非重新通过epoll_ctl EPOLL_CTL_MOD更新其关注的事件。  epoll事件的两种模型：\n LT，Level Triggered，译为水平触发或者级别触发，我更偏向于使用级别触发。级别触发是默认的工作方式，同时支持阻塞和非阻塞socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉进程该描述符有事件发生，之后如果进程一直不对这个就绪状态做出任何操作，则内核会继续通知，直到事件处理完成。以LT方式调用的epoll接口就相当于一个速度比较快的poll模型。 ET，Edge Triggered，译为边缘触发。边缘触发方式是高速工作方式，只支持非阻塞socket。在这种工作方式下，当描述符从未就绪变为就绪时，内核通过epoll告诉进程该描述符有事件发生，之后就算进程一直不对这个就绪状态做出任何操作，内核也不会再发送更多地通知，也就是说内核仅在该描述符事件到达的那个突变边缘对进程做出一次通知。\n根据ET方式的特性，epoll工作在此模式时必须使用非阻塞文件描述符，以避免由于一个文件描述符的阻塞读、阻塞写操作把处理多个文件描述符的任务“饿死”。\n调用ET模式epoll接口的推荐步骤如下：\n1）基于非阻塞文件描述符；\n2）只有当read或write返回EAGAIN（对于面向包/令牌的文件，比如数据报套接口、规范模式的终端）时，或是read/write读到/写出的数据长度小于请求的数据长度（对于面向流的文件，比如pipe、fifo、流套接口）时才需要挂起等待下一个事件。\n总的来说，在大并发的系统中，边缘触发模式比级别触发模式更具有优势，但是对于程序员的要求也更高。如果对于这两种模式想要了解得更加深入，那么建议读者阅读epoll相关的源代码。  下面是epoll多路复用IO模型的一个编程模板，可以在此基础上进行改进。\n// 创建并初始化文件描述符集 struct epoll_event ev; struct epoll_event events[MAX_EVENTS]; // 创建epoll句柄epfd int epfd = epoll_create(MAX_EVENTS); // 监听socket配置 sock = socket(...); bind(sock, ...); listen(sock, ...); // 对socket描述符上关心的事件进行注册 ev.events = EPOLLIN; ev.data.fd = sock; epoll_ctl(epfd, EPOLL_CTL_ADD, sock, \u0026amp;ev); while(1) { int i; // 调用epoll_wait阻塞等待，等待事件未永远等待直到发生事件 int n = epoll_wait(epfd, events, MAX_EVENTS, -1); for(i=0; i\u0026lt;n; ++i) { // 测试是否有客户端发起连接请求，如果有则接受并把新建的描述符加入监控 if(events[i].data.fd == sock) { if(events[i].events \u0026amp; EPOLLIN) { new_sock = accept(sock, ...); ev.events = EPOLLIN | EPOLLOUT; ev.data.fd = new_sock; epoll_ctl(epfd, EPOLL_CTL_ADD, new_sock, \u0026amp;ev); } } else { // 对于其他描述符上发生的事件进行适当处理 if(events[i].events \u0026amp; EPOLLIN) { doReadAction(i); } if(events[i].events \u0026amp; EPOLLOUT) { doWriteAction(i); } } } }   备注： 注意上面的代码也是仅仅给出了一个编程示例，实际应用过程中也需要考虑对端tcp连接关闭时对server端套接字的处理，比如通过epoll_ctl(epfd, EPOLL_CTL_DEL, fd, NULL)取消对fd上事件的轮询，并close(fd)_。服务端如果不注意对分配的套接字fd进行回收，很有可能达到系统允许的fd上限，那时候就会出现服务瘫痪，应注意避免这种情况的发生。\n 备注：\n需要注意级别触发、边缘触发编码方式上的差别，这里首先要铭记一点，级别触发只在事件状态发生改变时通知一次，而边缘触发只要事件处于就绪状态那么就会在处理之前一直发送统治。\n使用边缘触发方式进行编程比使用级别触发编程要稍微复杂一些，需要时刻谨记上述差异，这里说两个直观的情景便于大家理解。\n 当通过epfd监听来自多个客户端的入连接请求时，可能一次会有大量客户端的入连接请求到达，一次epoll_wait，如果工作在边缘触发模式，就只会通知一次epfd可读事件就绪，因此在对epfd上的EPOLLIN进行事件处理时，需要通过一个while循环不停地调用accept来完成所有入连接请求的处理，而不是像上述编程示例（上例为LT触发模式）中一样一次EPOLLIN只调用一次accept，则级别触发模式下上述方式是可行的，但是边缘触发模式下会造成严重的bug。 当通过sock_conn对连接socket上到达的数据进行读取时，对于每一个socket_conn上的数据都要通过一个while循环不停读取知道再次read返回EAGAIN确保所有数据已读取完，因为这个时候不读取，以后就不会收到epoll_wait的再次通知，如果想读取基本上就退化为一个poll了，需要自己轮询或者测试是否可读，影响性能。 对于sock_conn上数据写操作的处理，与sock_conn上数据读的处理是相似的。  与select、poll相比，epoll具有如下优点：\n epoll每次只返回有事件发生的文件描述符信息，这样调用者不用遍历整个文件描述符队列； 使用epoll使得系统不用从内核向用户空间复制数据，因为它是利用mmap使内核和用户空间贡献一块内存； 另外epoll可以设置不同的事件触发方式，包括边缘触发和级别触发两种，为用户使用epoll提供了灵活性。  代码示例：\n点击这里查看基于epoll实现的tcp server，[click to see epoll-based-tcp-server]。注意，这里的代码实现中包括了两个tcp server实现，一个是基于边缘触发模式(ET)，一个是基于级别触发模式(LT)。\n4. 实时信号驱动IO模型 # 实时信号驱动(rtsig)IO模型使得应用程序不需要阻塞在某一个或多个IO端口上，它先利用系统调用sigaction来安装某个端口的事件信号处理函数，该系统调用sigaction执行成功后立即返回，进程继续往下工作而不被阻塞，当某个IO端口上可进行数据操作时，内核就为该进程产生一个SIGIO信号，进程收到该信号后相应地在信号处理函数里进行IO操作，因此，这种机制使得程序能够在一个更合适的时间点被通知到，被通知去执行IO事件处理，之所以说是通知的时间点更好，是因为此时进行IO需要的数据已就绪，IO处理可以保证无阻塞地完成。\n实时信号驱动IO完全不是在select/poll基础上的修改，而是对传统信号驱动IO的完善，因此它是完全不同于前面介绍的几种解决方案的事件驱动IO机制。\n要使用实时信号驱动IO模型相对于处理普通的信号要稍微复杂一点，除了要为SIGIO信号建立信号处理函数（在该处理函数内当然要包含对实际IO操作的系统调用）以外，还需要额外的步骤，如对IO端口做一些设置以便启用信号驱动IO功能。首先要设置描述符的所有者，这可以通过fcntl的F_SETOWN操作来完成，fcntl(fd, F_SETOWN, (int)pid)，接着要启用描述符的信号驱动IO模式，这个步骤一般是通过fcntl的F_SETFL来设置O_ASYNC标识来完成的，fcntl(fd, F_SETFL, O_ASYNC|O_NONBLOCK|O_RDWR)。另外，如果有必要还可以重新设置描述符可读写时要发送的信号值，这可以通过fcntl的F_SETSIG指定，fcntl(fd, F_SETSIG, ev-\u0026gt;signum)。\n 备注：\n要使用F_SETSIG常量值必须在其源文件开头包含宏定义“#define __USE_GNU”或者“#define _GNU_SOURCE”，当然也可以通过GCC -D来指定宏。不过推荐使用宏_GNU_SOURCE而不是__USE_GNU宏。原因是，双划线开头的宏一般是由系统中的头文件对其进行定义、扩展，而不是在普通应用程序中。\n 可以看到所谓的实时信号驱动IO模型就是利用了O_ASYNC来使得当描述符可读、写时发送通知信号（采用非常规可排队的POSIX实时信号）从而使得进程可以异步执行。\n该模型有一些缺点：\n O_ASYNC仅能工作于socket描述符上，而不能工作于管道（pipe）或中断（tty）上； O_ASYNC为边缘触发方式，因此事件处理函数必须完整的完成某个事件处理动作（比如读取数据则必须读取完），否则不能保证进程可靠的再次接收到信号通知；   备注：\nRTSIG的实现与进程怎样分派信号密切相关，对每一个发生的事件就递交一个信号通知将是十分浪费的，因此一般考虑使用sigtimedwait()函数来阻塞等待进程关心的信号，并且结合利用poll()函数实现对描述符事件的水平触发效果。\n 据某些开发人员测试，在一定条件下的实时信号驱动IO模型表现性能比其他基于poll的IO模型都要好，但是这种方案似乎并不可靠，很多开发人员给出的建议就是不要使用这种方式。\n下面给出了一个利用RTSIG IO的编程范例。\n// 屏蔽不关心的信号 sigset_t all; sigfillset(\u0026amp;all); sigdelset(\u0026amp;all, SIGINT); sigprocmask(SIG_SETMASK, \u0026amp;all, NULL); // 新建并初始化关心的信号 sigset_t sigset; siginfo_t siginfo; // sigwaitinfo调用时会阻塞，除非收到wait的信号集中的某个信号 sigemptyset(\u0026amp;sigset); sigaddset(\u0026amp;sigset, SIGRTMIN + 1); // socket配置和监听 sock = socket(...); bind(sock, ...); listen(sock, ...); // 重新设置描述符可读写时要发送的信号值 fcntl(sock, F_SETSIG, SIGRTMIN + 1); // 对socket描述符设置所有者 fcntl(sock, F_SETOWN, getpid()); // 启用描述符的信号驱动IO模式 int flags = fcntl(sock, F_GETFL); fcntl(sock, F_SETFL, flags|O_ASYNC|O_NONBLOCK); while(1) { struct timespec ts; ts.tv_sec = 1; ts.tv_nsec = 0; // 调用sigtimedwait阻塞等待，等待事件1s \u0026amp; sigwaitinfo会一直阻塞 // - 通过这种方式可以达到一种类似级别触发的效果，不再是边缘触发； // - 边缘触发效果，应该通过同一个sighandler进行处理，但是处理起来比较麻烦： // - 假如不同的连接socket使用相同的信号，那么sighandler里无法区分事件就绪的fd； // - 假如不同的连接socket使用不同的信号，实时信号数量有限SIGRTMIN~SIGRTMAX大约才32个！ //sigtimedwait(\u0026amp;sigset, \u0026amp;siginfo, \u0026amp;ts); sigwaitinfo(\u0026amp;sigset, \u0026amp;siginfo); // 测试是否有客户端发起连接请求 if(siginfo.si_fd == sock) { new_sock = accept(sock, ...); fcntl(new_sock, F_SETSIG, SIGRTMIN + 1); fcntl(new_sock, F_SETOWN, getpid() + 1); fcntl(new_sock, F_SETFL, O_ASYNC|O_NONBLOCK|O_RDWR); } // 对其他描述符上发生的读写事件进行处理 else { doReadAction(i); doWriteAction(i); } }  上面的代码看起来似乎挺简单，很多人看了之后可能还很想尝试并在实践中应用，这里要注意的是，rtsig driven io并没有那么简单、有效！且听我细细道来！\n4.1 rtsig在udp中应用 # rtsig driven io在udp server中较为简单，因为udp中只有两种情况会为fd raise一个rtsig：\n fd上有数据到达； fd上io操作有错误；  我的repo里面有一个基于rtsig实现的udp server，实现起来很简单，不需要做什么特殊处理逻辑就可以轻松实现，虽然说rtsig不怎么被看好吧，但是至少有个服务ntp还是使用的rtsig \u0026amp; udp来实现的，可是tcp就不同了，好像还没有一个tcp server是基于rtsig实现的，很多人都反对在tcp中应用rtsig，因为太啰嗦而且很“没用”，每个io事件都raise一个信号也是个累赘，要判断的可能的io状态太多。\n代码示例：\n点击查看基于rtsig实现的udp server示例：[click to see rtsig-udp-server]。\n4.2 rtsig在tcp中应用 # rtsig drive io在tcp server中实现就复杂多了，因为对于一个fd有7种可能的情景会为其raise一个rtsig：\n fd上完成了一个建立连接的请求； fd上发起了一个断开连接的请求； fd上完成了一个断开连接的请求； fd上有数据到达； fd上有数据写出； fd上半连接关闭； fd上有错误发生；  这么多的情景需要作很多额外的判断才能加以区分，所以很多开发人员建议在tcp中只将rtsig应用在监听套接字sock_listen上，对于连接套接字还是基于select、poll、epoll来操作，其实即便这样也是费力不讨好，因为rtsig也存在可能丢失的问题！而且它是边缘触发，对程序员要求也比较高。建议还是用epoll吧！\n这里的tcp server中采用的是通过sigtimedwait/sigwaitinfo \u0026amp; siginfo_t.si_fd来区分收到rtsig的连接套接字、监听套接字的，然后再针对性地进行io处理！在我们的另一个基于rtsig的tcpserver实现中，我们通过同一个sighandler收到SIGIO信号时建立tcp连接并随即选择一个连接进行处理，虽然我们实现了，不过也不是一个特别clean的方法，不建议使用rtsig driven io，还是用IO多路复用来的清爽！\n代码示例：\n点击查看基于rtsig实现的tcp server示例：\n 示例1，基于sigtimedwait/sigwaitinfo \u0026amp; siginfo_t.si_fd来区分连接fd，[click to see rtsig-tcp-server-1]； 示例2，基于sighandler以及一点小技巧实现的对多个连接fd进行处理，[click to see rtsig-tcp-server-2]；  5. 异步IO模型 # 异步IO也是属于POSIX规范的一部分，类似实时信号驱动IO的异步通知机制，这也使得异步IO模型常常与后者相混淆。与后者的区别在于，启用异步IO意味着告知内核启动某个IO操作，并让内核在整个操作（包括将数据从内核复制到用户空间的缓冲区）完成时通知我们。也就是说，实时信号驱动IO是由内核通知我们何时可以启动一个IO操作，而在异步IO模型中，是由内核通知我们IO操作何时完成，即实际的IO操作是异步的。\n5.1. AIO API说明 # 下面的内容摘自Linux man手册，其对POSIX下的AIO接口、实现做了一个基础的介绍。在此基础上，我们将把AIO应用于后台服务中。\nPOSIX AIO接口允许应用程序发起一个或者多个IO操作，这些IO操作是异步执行的，即相比于当前发起IO操作的线程来说这些实际的IO操作是在“后台”运行的。IO操作完成时，可以选择多种方式来通知应用程序完成这一事件，例如：\n 传递一个信号给应用程序通知其IO操作完成； 在应用程序中额外实例化一个线程来对IO完成操作进行后处理； 也可能根本不会通知应用程序；  前面第4节讲过的rtsig driven io也可以算是异步的，从其当时使用的选项O_ASYNC就可以看出来，也可以称其为AIO（Asynchronous IO），但是呢，这里本节所提到的AIO主要指的是POSIX规范里面定义的AIO API。\n5.1.1. POSIX AIO API # POSIX AIO接口包括如下几个函数：\n aio_read(3)：入队一个read请求，它是read的异步操作版本； aio_write(3)：入队一个write请求，它是write的异步操作版本； aio_fsync(3)：入队一个sync请求（针对某个fd上的IO操作），它是fsync和fdatasync的异步版本； aio_error(3)：获取一个已入队的IO请求的错误状态信息； aio_return(3)：获取一个已完成的IO请求的返回状态信息； aio_suspend(3)：挂起IO请求的发起者，直到指定的一个或多个IO事件完成； aio_cancel(3)：尝试取消已经发起的某个特定fd上的未完成的IO请求； lio_listio(3)：使用这一个函数可以一次性入队多个IO请求；  5.1.2. Linux AIO SysCall # 通过上面几个函数后面的“(3)”可以知道，上述几个函数都是普通的libc库函数，而不是系统调用，实际上上述这些纯用户态的库函数是基于5个系统调用来实现的，它们是：\n io_setup(2) - int io_setup(unsigned nr_events, aio_context_t *ctx_idp)\n该函数在内核中为进程创建一个AIO Context，AIO Context是多个数据结构的集合，用于支持内核的AIO操作。每一个进程可以拥有多个AIO Context，每一个AIO Context都有一个唯一的标识符，AIO Context类型aio_context_t变量作为io_setup的第二个参数，内核会设置其对应的值，实际上这个aio_context_t类型仅仅是一个unsigned long类型(typedef unsigned long aio_context_t），io_setup的第一个参数表示aio_context_t变量要支持的同时发起的IO请求的数量。 io_destroy(2) - int io_destroy(aio_context_t ctx_id)\n该函数用于销毁AIO Context变量，销毁之前有两个操作，首先取消基于该aio_context_t发起的未完成的AIO请求，然后对于无法取消的AIO请求就阻塞当前进程等待其执行完成，最后销毁AIO Context。 io_submit(2) - int io_submit(aio_context_t ctx_id, long nr, struct iocb **iocbpp)\n该函数将向aio_context_t ctx_id上提交nr个IO请求，每个IO请求是由一个aio control block来指示的，第三个参数struct iocb **iocbpp是一个aio控制块的指针数组。 io_getevents(2) - int io_getevents(aio_context_t ctx_id, long min_nr, long nr, struct io_event *events, struct timespec *timeout)\n等待aio_context_t ctx_id关联的aio请求已完成队列中返回最少min_nr个事件，最多nr个事件，如果指定了timeout则最多等待该指定的时间，如果timeout为NULL则至少等待min_nr个事件返回。 io_cancel(2) - int io_cancel(aio_context_t ctx_id, struct iocb *iocb, struct io_event *result)\n该函数取消之前提交到aio_context_t ctx_id的一个AIO请求，这个请求由struct iocb *iocb标识，如果这个AIO请求成功取消了，对应的事件将被拷贝到第三个参数struct io_event *result指向的内存中，而不是将其放在已完成队列中。   备注：\n上述几个内核中的函数io_setup、io_destroy、io_submit、io_getevents、io_cancel，libc中并没有提供对应的wrapper函数供我们调用，如果要使用这些函数的话，可以通过syscall(2)来调用，以调用io_setup为例：syscall(__NR_io_setup, hr, ctxp)，这也是一种发起系统调用的常见方式。\n但是呢，libaio库里面提供了对应的wrapper函数，但是其参数类型与这里有点差异，而且返回值的含义也存在一些差异，不是很建议使用。\n 5.2. AIO操作示例 # 5.2.1. Kernel AIO SysCall # 下面是一个基于内核AIO系统调用的一个示例，程序打开一个本地文件，并将一段缓冲区中的数据写入到文件中。\n#define _GNU_SOURCE /* syscall() is not POSIX */ #include \u0026lt;stdio.h\u0026gt; /* for perror() */ #include \u0026lt;unistd.h\u0026gt; /* for syscall() */ #include \u0026lt;sys/syscall.h\u0026gt; /* for __NR_* definitions */ #include \u0026lt;linux/aio_abi.h\u0026gt; /* for AIO types and constants */ #include \u0026lt;fcntl.h\u0026gt; /* O_RDWR */ #include \u0026lt;string.h\u0026gt; /* memset() */ #include \u0026lt;inttypes.h\u0026gt; /* uint64_t */ inline int io_setup(unsigned nr, aio_context_t * ctxp) { return syscall(__NR_io_setup, nr, ctxp); } inline int io_destroy(aio_context_t ctx) { return syscall(__NR_io_destroy, ctx); } inline int io_submit(aio_context_t ctx, long nr, struct iocb **iocbpp) { return syscall(__NR_io_submit, ctx, nr, iocbpp); } inline int io_getevents(aio_context_t ctx, long min_nr, long max_nr, struct io_event *events, struct timespec *timeout) { return syscall(__NR_io_getevents, ctx, min_nr, max_nr, events, timeout); } int main() { int fd = open(\u0026quot;./testfile\u0026quot;, O_RDWR|O_CREAT, S_IRUSR|S_IWUSR); if (fd \u0026lt; 0) { perror(\u0026quot;open error\u0026quot;); return -1; } // init aio context aio_context_t ctx = 0; int ret = io_setup(128, \u0026amp;ctx); if (ret \u0026lt; 0) { perror(\u0026quot;io_setup error\u0026quot;); return -1; } // setup I/O control block struct iocb cb; memset(\u0026amp;cb, 0, sizeof(cb)); cb.aio_fildes = fd; cb.aio_lio_opcode = IOCB_CMD_PWRITE; // command-specific options char data[4096] = \u0026quot;i love you, dad!\\n\u0026quot;; cb.aio_buf = (uint64_t) data; cb.aio_offset = 0; cb.aio_nbytes = strlen(data); struct iocb *cbs[1]; cbs[0] = \u0026amp;cb; ret = io_submit(ctx, 1, cbs); if (ret != 1) { if (ret \u0026lt; 0) perror(\u0026quot;io_submit error\u0026quot;); else fprintf(stderr, \u0026quot;could not sumbit IOs\u0026quot;); return -1; } // get the reply struct io_event events[1]; ret = io_getevents(ctx, 1, 1, events, NULL); printf(\u0026quot;%d io ops completed\\n\u0026quot;, ret); ret = io_destroy(ctx); if (ret \u0026lt; 0) { perror(\u0026quot;io_destroy error\u0026quot;); return -1; } return 0; }  代码示例：\n点击这里查看基于aio的fileio示例1，[click to see aio-based-fileio]。\n5.2.2. POSIX AIO API # POSIX AIO API实现基于上述5个AIO系统调用，下面看一下基于POSIX AIO API的示例。程序读取命令行参数中指定的文件，并读取文件中的内容，程序还会在异步IO过程中检查IO操作的错误信息、状态信息。\n在5.1.1节中列出了POSIX AIO API对应的函数，其中有一个非常重要的参数类型“AIO请求控制块”类型，即struct aiocb，下面是该结构体的定义：\n// 异步io请求控制块 struct aiocb { int aio_fildes; // io操作对应的文件描述符 off_t aio_offset; // 文件读写操作位置的偏移量 volatile void *aio_buf; // 异步io操作对应的数据缓冲区 size_t aio_nbytes; // aio_buf的容量 int aio_reqprio; // aio操作的优先级（一般继承自发起aio操作的线程） struct sigevent aio_sigevent; // aio操作完成时如何通知应用程序 int aio_lio_opcode; // aio操作命令 };  其中aio_sigevent定义如下：\n// Data passed with notification union sigval { int sival_int; // Integer value void *sival_ptr; // Pointer value }; struct sigevent { int sigev_notify; // Notification method // - SIGEV_NONE，不作处理 // - SIGEV_SIGNAL，发送信号 // - SIGEV_THREAD，实例化一个线程 int sigev_signo; // Notification signal union sigval sigev_value; // Data passed with notification // Function used for thread notification (SIGEV_THREAD) void (*sigev_notify_function) (union sigval); // Attributes for notification thread (SIGEV_THREAD) void *sigev_notify_attributes; // ID of thread to signal (SIGEV_THREAD_ID) pid_t sigev_notify_thread_id; };  下面是示例程序的源代码：\n#include \u0026lt;fcntl.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;errno.h\u0026gt; #include \u0026lt;aio.h\u0026gt; #include \u0026lt;signal.h\u0026gt; // Size of buffers for read operations #define BUF_SIZE 20 #define errExit(msg) do { perror(msg); exit(EXIT_FAILURE); } while (0) #define errMsg(msg) do { perror(msg); } while (0) /* Application-defined structure for tracking I/O requests */ struct ioRequest { int reqNum; int status; struct aiocb *aiocbp; }; // On delivery of SIGQUIT, we attempt to cancel all outstanding I/O requests static volatile sig_atomic_t gotSIGQUIT = 0; // Handler for SIGQUIT static void quitHandler(int sig) { gotSIGQUIT = 1; } // Signal used to notify I/O completion #define IO_SIGNAL SIGUSR1 // Handler for I/O completion signal static void aioSigHandler(int sig, siginfo_t *si, void *ucontext) { if (si-\u0026gt;si_code == SI_ASYNCIO) { write(STDOUT_FILENO, \u0026quot;I/O completion signal received\\n\u0026quot;, 31); // The corresponding ioRequest structure would be available as: // struct ioRequest *ioReq = si-\u0026gt;si_value.sival_ptr; // // and the file descriptor would then be available via: // int fd = ioReq-\u0026gt;aiocbp-\u0026gt;aio_fildes; } } int main(int argc, char *argv[]) { if (argc \u0026lt; 2) { fprintf(stderr, \u0026quot;Usage: %s \u0026lt;pathname\u0026gt; \u0026lt;pathname\u0026gt;...\\n\u0026quot;, argv[0]); exit(EXIT_FAILURE); } int numReqs = argc - 1; // Total number of queued I/O requests, i.e, num of files listed on cmdline /* Allocate our arrays */ struct ioRequest *ioList = calloc(numReqs, sizeof(struct ioRequest)); if (ioList == NULL) errExit(\u0026quot;calloc\u0026quot;); struct aiocb *aiocbList = calloc(numReqs, sizeof(struct aiocb)); if (aiocbList == NULL) errExit(\u0026quot;calloc\u0026quot;); // Establish handlers for SIGQUIT and the I/O completion signal // - SIGQUIT struct sigaction sa; sa.sa_flags = SA_RESTART; sigemptyset(\u0026amp;sa.sa_mask); sa.sa_handler = quitHandler; if (sigaction(SIGQUIT, \u0026amp;sa, NULL) == -1) errExit(\u0026quot;sigaction\u0026quot;); // - IO_SIGNAL, actually it's SIGUSR1 sa.sa_flags = SA_RESTART | SA_SIGINFO; sa.sa_sigaction = aioSigHandler; if (sigaction(IO_SIGNAL, \u0026amp;sa, NULL) == -1) errExit(\u0026quot;sigaction\u0026quot;); // Open each file specified on the command line, and queue a read request // on the resulting file descriptor int j; for (j = 0; j \u0026lt; numReqs; j++) { ioList[j].reqNum = j; ioList[j].status = EINPROGRESS; ioList[j].aiocbp = \u0026amp;aiocbList[j]; ioList[j].aiocbp-\u0026gt;aio_fildes = open(argv[j + 1], O_RDONLY); if (ioList[j].aiocbp-\u0026gt;aio_fildes == -1) errExit(\u0026quot;open\u0026quot;); printf(\u0026quot;opened %s on descriptor %d\\n\u0026quot;, argv[j + 1], ioList[j].aiocbp-\u0026gt;aio_fildes); ioList[j].aiocbp-\u0026gt;aio_buf = malloc(BUF_SIZE); if (ioList[j].aiocbp-\u0026gt;aio_buf == NULL) errExit(\u0026quot;malloc\u0026quot;); ioList[j].aiocbp-\u0026gt;aio_nbytes = BUF_SIZE; ioList[j].aiocbp-\u0026gt;aio_reqprio = 0; ioList[j].aiocbp-\u0026gt;aio_offset = 0; ioList[j].aiocbp-\u0026gt;aio_sigevent.sigev_notify = SIGEV_SIGNAL; ioList[j].aiocbp-\u0026gt;aio_sigevent.sigev_signo = IO_SIGNAL; ioList[j].aiocbp-\u0026gt;aio_sigevent.sigev_value.sival_ptr = \u0026amp;ioList[j]; int s = aio_read(ioList[j].aiocbp); if (s == -1) errExit(\u0026quot;aio_read\u0026quot;); } // Number of requests still in progress int openReqs = numReqs; // Loop, monitoring status of I/O requests while (openReqs \u0026gt; 0) { sleep(3); /* Delay between each monitoring step */ if (gotSIGQUIT) { // On receipt of SIGQUIT, attempt to cancel each of the // outstanding I/O requests, and display status returned from the // cancellation requests printf(\u0026quot;got SIGQUIT; canceling I/O requests: \\n\u0026quot;); for (j = 0; j \u0026lt; numReqs; j++) { if (ioList[j].status == EINPROGRESS) { printf(\u0026quot;Request %d on descriptor %d:\u0026quot;, j, ioList[j].aiocbp-\u0026gt;aio_fildes); int s = aio_cancel(ioList[j].aiocbp-\u0026gt;aio_fildes, ioList[j].aiocbp); if (s == AIO_CANCELED) printf(\u0026quot;I/O canceled\\n\u0026quot;); else if (s == AIO_NOTCANCELED) printf(\u0026quot;I/O not canceled\\n\u0026quot;); else if (s == AIO_ALLDONE) printf(\u0026quot;I/O all done\\n\u0026quot;); else errMsg(\u0026quot;aio_cancel\u0026quot;); } } gotSIGQUIT = 0; } // Check the status of each I/O request that is still in progress printf(\u0026quot;aio_error():\\n\u0026quot;); for (j = 0; j \u0026lt; numReqs; j++) { if (ioList[j].status == EINPROGRESS) { printf(\u0026quot;for request %d (descriptor %d): \u0026quot;, j, ioList[j].aiocbp-\u0026gt;aio_fildes); ioList[j].status = aio_error(ioList[j].aiocbp); switch (ioList[j].status) { case 0: printf(\u0026quot;I/O succeeded\\n\u0026quot;); break; case EINPROGRESS: printf(\u0026quot;In progress\\n\u0026quot;); break; case ECANCELED: printf(\u0026quot;Canceled\\n\u0026quot;); break; default: errMsg(\u0026quot;aio_error\u0026quot;); break; } if (ioList[j].status != EINPROGRESS) openReqs--; } } } printf(\u0026quot;All I/O requests completed\\n\u0026quot;); // Check status return of all I/O requests printf(\u0026quot;aio_return():\\n\u0026quot;); for (j = 0; j \u0026lt; numReqs; j++) { ssize_t s = aio_return(ioList[j].aiocbp); printf(\u0026quot;for request %d (descriptor %d): %zd\\n\u0026quot;, j, ioList[j].aiocbp-\u0026gt;aio_fildes, s); } exit(EXIT_SUCCESS); }  代码示例：\n点击这里查看基于aio的fileio示例2，[click to see aio-based-fileio2]。\n下面是程序的执行效果：\n// run: ./a.out f1 f2 // result: I/O completion signal received I/O completion signal received opened f1 on descriptor 3 opened f2 on descriptor 4 aio_error(): for request 0 (descriptor 3): I/O succeeded for request 1 (descriptor 4): I/O succeeded All I/O requests completed aio_return(): for request 0 (descriptor 3): 20 for request 1 (descriptor 4): 20  5.3 AIO在服务端开发中的应用 # Linux下的AIO，Kernel AIO是真正的异步IO，但是glibc中的AIO是在用户态中实现的，利用多开的线程来模拟异步通知，但是这个线程里面的io操作并不是真正的异步。AIO更多的被应用于file io，而不是socket io，stack overflow上曾有人提到，AIO应用到socket上并不会返回明显的错误，只是socket上的io操作仍然是按照默认的“阻塞同步”工作方式执行，并不是异步, 这一点在github上的一篇文章中也被重点提到。\n 摘自github linux-aio\nBlocking during io_submit on ext4, on buffered operations, network access, pipes, etc. Some operations are not well-represented by the AIO interface. With completely unsupported operations like buffered reads, operations on a socket or pipes \u0026hellip;\n Asynchronous IO模型（AIO）比事件驱动的IO模型要晚，而且事件驱动的IO模型已经非常成熟、稳定，因此如果要基于socket开发高性能server，应该首先事件驱动的IO模型，如Linux下的epoll，Mac OS X下的kqueue，Solaris下的/dev/poll。\n那么既然事件驱动的IO模型已经这么成熟了，那么为什么还要设计AIO呢？设计它的目的是什么呢？这里我在stack overflow上找到了两个最具有信服力的回答，整理在此以供大家参考。\n摘自stack overflow, 点击查看原文：\n原文出处：answer-1，译文：\n 网络IO并不是AIO优先考虑的对象，现在几乎所有人编写网络服务器都是基于POSIX事件驱动模型，事件驱动模型已经非常成熟、稳定了。磁盘写一般会被缓冲、磁盘读一般会预取，还有什么不够完美的呢？要说有，那就只有Disk Direct IO这种不带缓冲形式的操作了，这是AIO最适用的地方，而Disk Direct IO仅仅被用于事务数据库或是那些趋向于自己编写线程或者进程来管理disk io的情景。所以，POSIX AIO其实没有什么多大的用途，不要用！\n 原文出处：answer-2，译文：\n 现在借助于kqueue、epoll、/dev/poll等已经可以实现非常高效的socket io操作。异步的文件IO草走是一个出现比较晚的东西（Windows的overlapped io和Solaris早期的POSIX AIO除外）。如果想实现高效的socket io操作，最好是基于上述的事件驱动机制来实现。 AIO的主要目的是为了解决异步的磁盘IO问题，以Mac OS X为例，它提供的AIO就只能作用在普通文件上而不能作用在socket上，因为已经有kqueue可以很好地完成这个工作，没必要重复造轮子。 磁盘写操作通常都会被kernel进行缓冲（将写的数据存在缓冲块中），然后在后面适当的事件将缓冲的写操作全部flush到磁盘（通常由一个额外的进程来完成，linux 0.11中是由pid=2的update进程来负责同步缓冲块数据到磁盘）。后面适当的时刻可以由内核进行选择以获得最优的效率、最少的代价，例如当磁盘的读写头经过某一个磁盘写请求对应的磁盘块时，内核可能就会将这个块对应的缓冲块的数据同步回磁盘。\n但是，对于读操作，如果我们向让内核对多个磁盘读请求根据请求优先级进行排序，AIO是唯一可供选择的方式。下面是为什么让内核来作这个工作比在用户态程序中做这个工作更有优势的原因：\n  内核可以看到所有的磁盘io请求（不止是当前某个程序的磁盘io请求）并且能够排序； 内核知道磁盘读写头的位置，并能根据当前读写头的位置挑选距离当前位置最近的磁盘io请求进行处理，尽量少的移动读写头； 内核能够利用native command queuing技术来进一步优化磁盘的读操作； 可以借助于lio_listio通过一个系统调用发起多个磁盘read操作，比readv方便，特别是如果我们的磁盘read操作不是逻辑上连续的时候还可以节省一点系统的负载； 借助于AIO程序实现可能更见简单些，因为不需要创建额外的一个线程阻塞在read、write系统调用上，完成后还要再通知其他发起io的线程io操作完成； 另外，POSIX AIO设计的接口有点尴尬，举几个例子： 唯一高效的、支持的比较好的事件回调机制就是通过信号，但是这在库里面应用起来不方便，因为这意味着要使用进程的全局信号名字空间。如果操作系统不支持实时信号，还意味着不得不便利所有的请求来判断到底哪一个请求完成了（Mac OS X是这样的，Linux下不是）。此外，在多线程环境中捕获信号也是一项比较有挑战性的工作，还不能直接在信号处理汉书里面对事件作出响应，不得不重新raise一个信号并将它写到管道里面或者使用signalfd（on Linux）然后再由其他线程或进程进行处理，如果在信号处理函数里面响应信号可能耗时较长导致后续信号丢失； lio_suspend跟select存在相同的问题，都具有最大数量限制，伸缩性差！ lio_listio，因为实现的原因也存在提交io操作数量的限制，为了兼容性试图获取这个限制的操作是没有什么意义的，只能通过调用sysconf(_SC_AIO_LISTIO_MAX)来获取，这个系统调用可能会失败，这种情况下可以使用AIO_LISTIO_MAX宏来代替。\n对于Posix AIO的真实应用情况，可以看一下lighttpd，这里面有采用基于AIO来实现server的部分实现，可以参考以下。\n现在大多数POSIX平台都支持POSIX AIO了，例如Linux、BSD、Solaris、AIX等。Windwos通过它的overlapped file io来支持aio。我的理解是只有Solaris、Windows、Linux是真正的支持异步，异步文件io会落到磁盘驱动上，其他的操作系统都是在通过某种机制来模拟异步io，如借助额外的内核线程，这里Linux是个例外，它的glibc中的POSIX AIO实现是借助的一个用户态线程来辅助模拟aio的行为，但是Linux Kernel提供的AIO是真正的异步实现，所有的操作直接落到驱动，只要驱动支持异步那就是真正的异步！\n我相信在不同的操作系统里面，POSIX AIO实现往往只支持普通文件fd类型而不支持socket fd，这种情况是很常见的，也是很正常的！  5.4 关于AIO的结论 # 如果是想基于socket io实现高性能server，还是采用基于事件驱动IO模型吧！别再想信号驱动的IO和AIO了！\n感兴趣的读者可以进一步了解AIO的相关使用和实现细节。\n6 本文总结 # 以上对阻塞IO、非阻塞IO、IO多路复用、实时信号驱动IO、异步IO这5种模型的执行流程、使用方式做了最基本的介绍。如果时间充足，后面会参考Linux内核中的相应实现进一步介绍以上IO模型的实现细节。\n附录A. 错误码定义 # 这里只列出了常见的错误码，Linux中定义的错误码可以通过man errno进行查看。\n   错误码Macro 错误码说明     EAGAIN Resource temporarily unavailable    附录B. 插图信息 # "}),a.add({id:493,href:"/tags/rtsig/",title:"rtsig",description:"",content:""}),a.add({id:494,href:"/tags/coroutine/",title:"coroutine",description:"",content:""}),a.add({id:495,href:"/blog/2017-09-23-%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%8E%86%E5%8F%B2%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/",title:"协程的历史、现在和未来!",description:"进程、线程大家并不陌生，协程呢？近些年协程得到大量运用，如Java字节码增强实现协程的Kilim、Quasar，C++ boost coroutine，微信libco、libtask，当然还有名声在外的Go语言。其实协程思想由来已久，并非近几年才诞生，不妨来了解下这段历史。",content:"计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。\n1.从磁带到协程 # COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 Burroughs 205 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕\n以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 ANTLR 构建的编译器，都遵循这样的设计。\n在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。\n以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。\n2.自顶向下，无需协同 # 虽然协程是伴随着高级语言诞生的，它却没有能像子过程一样成为通用编程语言的基本元素。\n从 1963 年首次提出到上个世纪九十年代，我们在 ALOGL, Pascal, C, FORTRAN 等主流的命令式编程语言中都没有看到原生的协程支持。协程只稀疏地出现在 Simula，Modular-2 (Pascal 升级版) 和 Smalltalk 等相对小众的语言中。协程作为一个比子进程更加通用的概念，在实际编程却没有取代子进程，这一点不得不说是出乎意外的。如果我们结合当时的程序设计思想看，这一点又是意料之中的：协程是不符合那个时代所崇尚的“自顶向下”的程序设计思想的，自然也就不会成为当时主流的命令式编程语言 (imperative programming) 的一部分。\n正如面向对象的语言是围绕面向对象的开发理念设计一样，命令式编程语言是围绕自顶向下(top-down)的开发理念设计的。在自顶向下的理念指导下，程序被切分为一个主程序和大大小小的子模块，每一个子模块又可能调用更多子模块等等。C 家族语言的 main() 函数就是这种自顶而下思想的体现。在这种理念指导下，各模块形成层次调用关系，而程序设计就是制作这些子过程。在“自顶向下”这种层次化的理念下，具有鲜明层次的子过程调用成为软件系统最自然的组织方式，也是理所当然。相较之下，具有执行中让出和恢复功能的协程在这种架构下无用武之地。可以说，自上而下的设计思想从一开始就排除了对协程的需求。其后的结构化编程(Structural Programming) 思想，更是进一步强化了“子过程调用作为唯一控制结构”的基本假设。在这样的指导思想下，协程一直没有成为当时编程语言的一等公民。\n尽管从提出到上世纪 90 年代，协程在编程语言中没有普遍成为一等公民，但作为一种易于理解的控制结构，协程的概念渗入到了软件设计的许多方面。在结构化编程思想一统天下之时， D. Knuth 曾经专门写过一篇 “Structured Programming with GOTO” 来为 GOTO 语句辩护。在他列出的几条 GOTO 可以方便编程且不破坏程序结构的例子中，有一个（例子7b）就是用 GOTO 实现协程控制结构。相比较之下，不用 GOTO 的“结构化”代码反而失去了良好的结构。当然，追求实际结果的工业界对于学界的这场要不要剔除 GOTO 的争论并不感冒。当时许多语言都附带了不建议使用的 GOTO 语句，显得左右逢源。这方面一个最明显的例子就是 Java：其语言本身预留了 goto 关键字，其编译器却没有提供任何的支持，可以说在 goto 这场争论中做足了中间派。\n3.协程的早期应用 # 实践中，协程的思想频繁应用于任务调度和流处理上。比如，UNIX 管道就可以看成是众多命令间的协同操作。当然，管道的现代实现都是以 pipe() 系统调用和进程间的通信为基础，而非简单遵循协程的 yield/resume 语法。\n许多协同式多任务操作系统，也可以看成协程运行系统。说到协同式多任务系统，一个常见的误区是认为协同式调度比抢占式调度“低级”，因为我们所熟悉的桌面操作系统，都是从协同式调度（如 Windows 3.2， Mac OS 9 等）过渡到抢占式多任务系统的。实际上，调度方式并无高下，完全取决于应用场景。抢占式系统允许操作系统剥夺进程执行权限，抢占控制流，因而天然适合服务器和图形操作系统，因为调度器可以优先保证对用户交互和网络事件的快速响应。当年 Windows 95 刚刚推出的时候，抢占式多任务就被作为一大买点大加宣传。协同式调度则等到进程时间片用完或系统调用时转移执行权限，因此适合实时或分时等等对运行时间有保障的系统。\n另外，抢占式系统依赖于 CPU 的硬件支持。 因为调度器需要“剥夺”进程的执行权，就意味着调度器需要运行在比普通进程高的权限上，否则任何“流氓（rogue）”进程都可以去剥夺其他进程了。只有 CPU 支持了执行权限后，抢占式调度才成为可能。x86 系统从 80386 处理器开始引入 Ring 机制支持执行权限，这也是为何 Windows 95 和 Linux 其实只能运行在 80386 之后的 x86 处理器上的原因。而协同式多任务适用于那些没有处理器权限支持的场景，这些场景包含资源受限的嵌入式系统和实时系统。在这些系统中，程序均以协程的方式运行。调度器负责控制流的让出和恢复。通过协程的模型，无需硬件支持，我们就可以在一个“简陋”的处理器上实现一个多任务的系统。我们见到的许多智能设备，如运动手环，基于硬件限制，都是采用协同调度的架构。\n4.协程的复兴和现代形式 # 编程思想能否普及开来，很大程度上在于应用场景。协程没有能在自顶向下的世界里立足，却在动态语言世界里大放光彩，这里最显著的例子莫过于 Python 的迭代器和生成器。\n回想一下在 C 的世界里，循环的标准写法是:\nfor (i = 0; i \u0026lt; n; ++i) { … }  这行代码包含两个独立的逻辑, for 循环控制了 i 的边界条件， ++i 控制了 i 的自增逻辑。这行代码适用于 C 世界里的数组即内存位移的范式，因此适合大多数访问场景。到了 STL 和复杂数据结构的世界，因为许多数据结构只支持顺序访问，循环往往写成:\nfor (i = A.first(); i.hasNext();i = i.next()) { … }  这种设计抽象出了一个独立于数据结构的迭代器，专门负责数据结构上元素访问顺序。迭代器把访问逻辑从数据结构上分离出来, 是一个常用的设计模式 （GoF 23个设计模式之一）.我们在 STL 和 Java Collection 中也常常看到迭代器的身影。\n在适当的时候，我们可以更进一步引入一个语法糖（脚注：这里牵涉到一个外部迭代器和内部迭代器的问题。限于篇幅不在此讨论）将循环写成:\nfor i in A.Iterator() {func(i)}。  事实上，许多现代语言都支持类似的语法。这种语法抛弃了以 i 变量作为迭代指针的功能，要求迭代器自身能够记住当前迭代位置，调用时返回下一个元素。读者不难看到，这种架构就是我们在文章开始提到的语法分析器的架构。正因为如此，我们可以从协程的角度来理解迭代器：当控制流转换到迭代器上时，迭代器负责生成和返回下一个元素。一旦下一个元素准备就绪，迭代器就让出控制流。这种特殊的迭代器实现在 Python 中又被成为生成器。以协程的角度切入的的好处是设计大大精简。实际上，在 Python 中，生成器本身就是一个普通的函数，和普通函数的唯一不同是它的返回语句是协程风格的 yield。这里，yield 一语双关，既是让出控制流，也是生成迭代器的返回值。\n以上我们仅仅讨论了生成器的最基本的特性。实际上，生成器的强大之处在于我们可以像 UNIX 管道一样串联起来，组成所谓的生成器表达式。如果我们有一个可以生成 1，2，3 … 的生成器 N，则 square = (i **2 for i in N) 就是一个生成平方数的生成器表达式。最终的控制流会在这些串联的部分间转换，无需我们写作复杂的嵌套调用。当然，yield 只是冰山的一角，现代的 Python 语言还充分利用了 yield 关键字构建了 yield from 语句，(yield) 语法等等，使得我们无困难的将协程的思想融入到 Python 编程中去。限于篇幅这里不再展开。\n5.协程的实现形式 # 我们前面说过，协程的思想本质上就是控制流的主动让出和恢复机制。在现代语言里，可以实现协程思想的方法很多，这些实现间并无高下之分，所区别的就是是否适合应用场景。理解这一点，我们对于各种协程的分类，如半对称/对称协程，有栈与无栈协程等具体实现就能提纲挈领，无需在实现细节上纠结。\n协程在实践中的实现方式千差万别，一个简单的原因，是协程本身可以通过许多基本元素构建。基本元素的选取方式不一样，构建出来的协程抽象也就有差别。比如, Lua 语言选取了 create, resume 和 yield 作为基本构建元素, 从调度器层面构建出所谓的“非对程”协程系统。而 Julia 语言绕过调度器，通过在协程内调用 yieldto 函数完成了同样的功能，构建出了一个所谓的对称协程系统。尽管这两个语言使用了同样的 setjmp 库，构造出来的原语却不一样。又比如，许多 C 语言的协程库都使用了 ucontext 库实现，这是因为 POSIX 本身提供了 ucontext 库，不少协程实现是以 ucontext 为蓝本实现的。这些实现，都不可避免地带上了 ucontext 系统的一些基本假设，比如协程间是平等的，一般带有调度器来协调协程等等（比如 libtask 实现，以及云风的 coroutine 库）。Go 语言的一个鲜明特色就是通道（channel）作为一级对象。因此，resume 和 yield 等在其他语言里的原语在 go 里都以通道方式构建。我们还可以举出许多同样的例子。这些风格的差异往往和语言的历史，演化路径，和要解决的问题相关，我们不必苛求他们的协程模型一定要如此这般。\n6.总结 # 总的来说，协程为协同任务提供了一种运行时抽象。这种抽象非常适合于协同多任务调度和数据流处理。在现代操作系统和编程语言中，因为用户态线程切换代价比内核态线程小，协程成为了一种轻量级的多任务模型。我们无法预测未来，但是可以看到，协程已经成为许多擅长数据处理的语言的一级对象。随着计算机并行性能的提升，用户态任务调度已经成为一种标准的多任务模型。在这样的大趋势下，协程这个简单且有效的模型就显得更加引人注目。\n参考文献：\n[1] 徐宥，\u0026ldquo;协程的历史，现在和未来\u0026rdquo;, https://blog.youxu.info/\n"}),a.add({id:496,href:"/blog/2017-04-26-coroutine-switching/",title:"Coroutine-Switching",description:"如今协程得到大量应用，大家对此并不陌生。本文对协程上下文切换做了一个简单的实验，以更好地认识协程切换及其开销。",content:"1. 协程Coroutine # 本文提供了一个模拟协程上下文切换过程的测试程序，基本思路是每当希望创建一个coroutine时，就在堆里申请一块内存，然后对内存进行整理，在其中保存预设的硬件上下文等信息（重点设置rbp、rsp、rip（callback）、rdi（callback-arg））。启动协程并进行切换时，通过__SwitchCoroutine__(cur,next)来完成cur向next的切换，切换过程中保存当前上下文信息到cur对应的堆内存中，并提取next对应的堆内存信息还原上下文完成切换。 测试程序中创建了4个coroutine，第1个coroutine只是为了用来启动其他3个，其他3个没有继续调度第一个，原因是第一个coroutine中rip保存的是main.c中__SwitchCoroutine__之后的指令地址，如果让第一个coroutine参与context-switch的话会使得进程结束执行。\n在看下面的程序之前，需要先了解栈帧的构成、栈帧创建之前caller的动作\u0026amp;创建之后callee的动作、函数返回之前callee的动作\u0026amp;函数返回之后caller的动作，之前看过一篇整理的很不错的文章以供参考C Function Call Conventions and the Stack。\nps: 实际上直接使用linux下的ucontext_t实现会更简单，在我的介绍libmill的电子书中有详细介绍。\n1.1. 协程coroutine声明 # file: coroutine.h\n#include \u0026lt;stdint.h\u0026gt; typedef int64_t (*EntryCallback)(void*); //硬件上下文信息 struct stRegister { uint64_t rax; uint64_t rbx; uint64_t rcx; uint64_t rdx; uint64_t rsi; uint64_t rdi; uint64_t r8; uint64_t r9; uint64_t r10; uint64_t r11; uint64_t r12; uint64_t r13; uint64_t r14; uint64_t r15; uint64_t rbp; uint64_t rsp; uint64_t rip; }; //协程上下文 struct stContext { struct stRegister cpu_register; void *arg; uint8_t *stack; }; typedef struct stContext Coroutine; //创建协程 Coroutine* CreateCoroutine(EntryCallback entry, void *arg); //删除协程 void DeleteCoroutine(Coroutine *ptr); //设置协程栈尺寸 void SetStackSize(uint32_t size); //协程切换 void __SwitchCoroutine__(Coroutine *cur, const Coroutine *next);  1.2. 协程Coroutine实现 # file: coroutine.c\n#include \u0026quot;coroutine.h\u0026quot; #include \u0026lt;stdlib.h\u0026gt; #define OFFSET(t, m) (\u0026amp;(((t*)0)-\u0026gt;m)) uint32_t g_stack_size = 100 * 1024; Coroutine* CreateCoroutine(EntryCallback entry, void *arg) { int size = g_stack_size + sizeof(Coroutine); Coroutine *c = (Coroutine *)calloc(size, 1); if (NULL == c) { return NULL; } uint8_t *start = (uint8_t*)c; c-\u0026gt;arg = arg; //函数入口 c-\u0026gt;cpu_register.rip = (uint64_t)entry; //第一个参数 c-\u0026gt;cpu_register.rdi = (uint64_t)arg; //rbp 栈底 c-\u0026gt;cpu_register.rbp = (uint64_t)(start + size); //rsp 当前栈顶 c-\u0026gt;cpu_register.rsp = c-\u0026gt;cpu_register.rbp; return c; } void DeleteCoroutine(Coroutine *ptr) { free(ptr); } void SetStackSize(uint32_t size) { g_stack_size = size; }  2. 协程Coroutine上下文切换 # file: switch.s\n//这里协程库是基于有栈协程的设计来实现，协程硬件上下文信息需通过%rsp来计算访问地址 //__SwitchCoroutine__(current_coroutine, next_coroutine) //- rdi, current_coroutine //- rsi, next_coroutine .globl __SwitchCoroutine__ __SwitchCoroutine__: //save rsp of calling function, here %rsp equals to return address mov %rsp, %rax //set rsp to end of coroutine.stRegister, to push rip, //when rdi coroutine return, it will return the rip to continue exec mov %rdi, %rsp add $136, %rsp push (%rax) //+8 to skip return address to get end address of calling function's %rsp add $8, %rax push %rax //store the current_coroutine's state(stRegister) push %rbp push %r15 push %r14 push %r13 push %r12 push %r11 push %r10 push %r9 push %r8 push %rdi push %rsi push %rdx push %rcx push %rbx push %rax //ready switch to next_coroutine mov %rsi, %rsp //restore the next_coroutine's stRegister to cpu pop %rax pop %rbx pop %rcx pop %rdx pop %rsi pop %rdi pop %r8 pop %r9 pop %r10 pop %r11 pop %r12 pop %r13 pop %r14 pop %r15 pop %rbp //move return address to %rax mov 8(%rsp), %rax pop %rsp //jmp to next_coroutine, ram indirect access to fetch the target address jmp *%rax  3. Coroutine使用 \u0026amp; 测试 # 3.1. 测试程序 # file: main.c\n#include \u0026lt;unistd.h\u0026gt; #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026quot;coroutine.h\u0026quot; Coroutine *coroutines[3]; int64_t callback(void *arg) { while(1) { if(strcmp((char *)arg, \u0026quot;coroutine-a\u0026quot;)==0) { printf(\u0026quot;[%s] ready to switch to coroutine-b\\n\u0026quot;, (char *)arg); __SwitchCoroutine__(coroutines[0], coroutines[1]); } else if(strcmp((char *)arg, \u0026quot;coroutine-b\u0026quot;)==0) { printf(\u0026quot;[%s] ready to switch to coroutine-c\\n\u0026quot;, (char *)arg); __SwitchCoroutine__(coroutines[1], coroutines[2]); } else if(strcmp((char *)arg, \u0026quot;coroutine-c\u0026quot;)==0) { printf(\u0026quot;[%s] ready to switch to coroutine-a\\n\u0026quot;, (char *)arg); __SwitchCoroutine__(coroutines[2], coroutines[0]); } sleep(1); } return 0; } int main() { printf(\u0026quot;initialize coroutine's callback\\n\u0026quot;); EntryCallback cb = callback; printf(\u0026quot;create 3 coroutines\\n\u0026quot;); Coroutine *coo = CreateCoroutine(cb, (void *)\u0026quot;coroutine-o\u0026quot;); Coroutine *coa = CreateCoroutine(cb, (void *)\u0026quot;coroutine-a\u0026quot;); Coroutine *cob = CreateCoroutine(cb, (void *)\u0026quot;coroutine-b\u0026quot;); Coroutine *coc = CreateCoroutine(cb, (void *)\u0026quot;coroutine-c\u0026quot;); coroutines[0] = coa; coroutines[1] = cob; coroutines[2] = coc; printf(\u0026quot;ready to start coroutine switching\\n\u0026quot;); __SwitchCoroutine__(coo, coa); printf(\u0026quot;ready to exit\\n\u0026quot;); return 0; }  3.2. 测试程序build # file: Makefile\nall: *.c *.h *.s @echo \u0026quot;==\u0026gt; build the coroutine test module\u0026quot; gcc -g -o main *.c *.h *.s @echo \u0026quot;==\u0026gt; build successful\u0026quot; test: all @echo \u0026quot;==\u0026gt; run the coroutine test module\u0026quot; ./main clean: @echo \u0026quot;==\u0026gt; delete the build file 'main'\u0026quot; rm main  3.3. 测试结果 # make make test ==\u0026gt; build the coroutine test module gcc -g -o main *.c *.h *.s ==\u0026gt; build successful ==\u0026gt; run the coroutine test module ./main initialize coroutine's callback create 3 coroutines ready to start coroutine switching [coroutine-a] ready to switch to coroutine-b [coroutine-b] ready to switch to coroutine-c [coroutine-c] ready to switch to coroutine-a [coroutine-a] ready to switch to coroutine-b [coroutine-b] ready to switch to coroutine-c [coroutine-c] ready to switch to coroutine-a [coroutine-a] ready to switch to coroutine-b  "}),a.add({id:497,href:"/tags/libtask/",title:"libtask",description:"",content:""}),a.add({id:498,href:"/tags/ucontext/",title:"ucontext",description:"",content:""}),a.add({id:499,href:"/tags/java/",title:"java",description:"",content:""}),a.add({id:500,href:"/blog/2017-04-20-%E5%AD%A6%E4%B9%A0java-nio/",title:"Java NIO Tutorials",description:"Java网络编程中离不开对NIO的熟练运用，本文总结了NIO的实现原理、使用方式，以及并发编程中需要关注的一些核心问题。",content:"1 前言 # Java NIO，意为Java New IO，是一种相对于Java标准IO、网络API的替代方案。从JDK 1.4开始NIO就被引入了进来，它提供了另一种IO处理的方式，这使得Java在IO处理方面向前迈进了一大步。\nNIO Channel \u0026amp; Buffer # 在Java标准IO里面，IO处理的对象是字节流或字符流，在NIO里面我们处理的对象是channel和buffer，数据读总是从channel中读入到buffer，输入写总是从buffer写入到channel。\nNIO Non-Blocking IO # Java NIO使得我们可以通过非阻塞的方式执行IO处理，例如一个线程请求从channel中读取数据到buffer的时候，在channel执行数据读取操作到buffer的过程中，线程仍然可以执行其他的处理工作，当数据被读取到buffer中之后，线程再去对数据进行处理。数据写的过程也是与此类似。\n 备注：\n其实参考glibc中的pthread用户级线程库实现，可以大致想到这种channel、buffer工作模式的一种大致实现，大不了我多开一个用户线程让其执行channel和buffer之间的数据传输工作，处理完之后给原本请求channel读写数据的用户线程发个信号让其进行数据处理。Linux中的AIO就是这么搞的，可以参考《Linux设备驱动开发》。\n大家所描述的没有底层硬件支持的异步，很多都是指的软件代码执行序上的异步，本质上代码还是在以同步的方式执行，只不过在这些同步技术之上结合一些小佐料起到了类似的异步执行的效果。\n NIO Selector # Java NIO中有Selector（选择器）的概念，一个selector可以对多个channel上的事件进行监听，例如对多个channel上的连接打开、数据到达事件进行监听，因此一个selector可以用于对多个channel上的连接打开、关闭以及读写事件进行监听、处理。\n 备注：\nLinux中的selector本质上是基于epoll实现的，因此可以结合epoll来理解selector。\nchannel不过是对网络套接字的封装，buffer不过是对接收缓冲、发送缓冲的封装，selector不过是对epollfd的封装，selector对多个channel的监听，不过是epoll在epollfd上EPOLL_CTL_ADD了多个channel对应的fd，并对其上的事件进行必要的监听。selector轮询事件是否发生，本质上也就是epoll_wait轮询注册的多个fd上是否有事件发生。\n 下面将展开介绍Java NIO是如何工作的。\n2 概要 # Java NIO包括3个核心组件，即channel、buffer、selector。Java NIO里面包括的类不止这几个，但是我个人认为Java NIO API的核心类就这几个，其他的例如Pipe、FileLock子类的都是配合这3个核心组件使用的工具类，所以这里先重点介绍channel、buffer、selector，后面会在独立章节中对其他类进行介绍。\nNIO Channel \u0026amp; Buffer # Java NIO中的所有IO操作几乎都是从一个channel开始的，channel可以看做是对一对套接字的封装，例如一个tcp连接。可以从channel中读取数据到buffer，同样也可以将buffer中的数据写入到channel中，下图展示了channel和buffer的这一关系。\nChannel大致有如下几种实现：\n FileChannel DatagramChannel SocketChannel ServerSocketChannel  其中FileChannel主要用于文件io，DatagramChannel主要用于udp网络通信，SocketChannel用于tcp网络通信，而ServerSocketChannel用于建立tcp连接。\nBuffer大致有如下几种实现：\n ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer  上述多种Buffer的不同之处在于其中存储的数据类型的差异，例如ByteBuffer就是按照直接进行读写，CharBuffer就是按照字符进行读写。\nJava NIO中海油一种Buffer实现MappedByteBuffer，这种Buffer需要与内存映射文件来配合使用，我们这里暂时先不予介绍。\nNIO Selector # 一个selector允许一个单一线程对多个channel上的事件进行处理（Linux平台下的selector实现就是基于epoll），一个单一线程也可以对多个channel进行高效的io处理，例如一个可能会创建很多tcp连接每个tcp连接流量不大的情况下，比如构建一个聊天服务。\n下图是一个单线程借助selector来对3个channel进行io处理的示意图。\n使用selector对多个channel进行事件处理，类似于epoll中首先要将某些fd上的特定事件在epollfd注册一样，这里也需要先将我们关心的channel上的特定事件在selector中注册，然后就像epoll中调用epoll_wait()来等待某个事件发生一样，这里需要调用selector.select(方法来等待事件发生，等某个事件发生后再进入后续的事件处理过程，比如收到tcp入连接请求、数据到达事件等。\n3 NIO Channel # Java NIO与 Channel与标准IO中的stream（流）有某些相似之处，但是也有很大不同。\n 同一个channel既可读又可写，而同一个stream要么只可读要么只可写，从命名XXInputStream上也可以看出这个明显的不同； channel中的读写操作可以是异步的，标准io中的读写操作都是同步的（包括阻塞、非阻塞）； channel中读写操作总是借助于buffer来完成的，而流可以直接读写；  这里首先给出一个简单的FileChannel的示例程序，让大家对channel、buffer的使用有个大致的了解。\n// 打开文件并获取FileChannel RandomAccessFile aFile = new RandomAccessFile(\u0026quot;data/nio-data.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel inChannel = aFile.getChannel(); // 创建一个字节buffer ByteBuffer buf = ByteBuffer.allocate(48); // 读取文件内容到buffer int bytesRead = inChannel.read(buf); while (bytesRead != -1) { System.out.println(\u0026quot;Read \u0026quot; + bytesRead); // 切换buffer读写模式，从写到读 buf.flip(); // 打印buffer中的内容 while(buf.hasRemaining()){ System.out.print((char) buf.get()); } // 清空buffer继续读文件 buf.clear(); bytesRead = inChannel.read(buf); } // 关闭文件 aFile.close();  上面这个示例程序简单介绍了FileChannel \u0026amp; ByteBuffer的使用方式，其他的几个Channel \u0026amp; Buffer实现的使用方式与此有些类似，我们后面再展开。\n这里有个比较关键的点是Buffer的读写模式切换，例子程序中buffer一开始处于写模式，所以我们才能从channel中读取数据存储到buffer中，而后我们想查看buffer中的内容，这个时候首先需要将buffer从写模式切换为读模式，然后才能将其中的内容读取并显示出来。\n读者可能要问为什么buffer要切换读写模式，这里先简单说一下，buffer的底层是借助一个数组来实现的，其通过几个比较关键的位置索引变量来跟踪当前读写位置索引position、最大可读写位置索引limit、最大容量capacity，因为只有一个数组，要想支持读写两种模式的同时不致出现混乱，读写操作之前就需要改变上述pos、max、capacity这3个位置索引变量的语义和值，因此要调用buffer.flip()方法。\n当我们读取了buffer中的数据时，需要调用buffer.clear()来清空所有的buffer中数据，或者调用buffer.compact()来清空已经读取的数据，没有读取的数据则继续留在buffer中，并且数据会被移动到buffer中数组的起始位置，当我们继续向buffer中写数据时数据会追加在未读取数据的后面。\n总结一下buffer的使用过程，主要包括如下4步：\n 写数据到buffer中； 调用buffer.flip()将buffer从写模式切换为读模式； 从buffer中读取出数据； 调用buffer.clear()清空数据或者buffer.compact()清空以读取数据；   备注：\n这里的flip方法是为了能够正确读取写入模式下写入的数据，调用该方法修改position、limit变量后可以保证这一点。我们不调用这个方法也可以读取数据，但是会读取到错误的数据，切记，Java并不会在我们“忘记”调用flip方法时给出警告或者错误，需要程序开发人员自己来掌控。\n对于写操作也是一样的，调用clear或compact方法可以保证有可用空间来存储即将要写入的数据，当“忘记”调用该方法时也可以写入(buffer未满)，但是浪费了buffer存储空间，只能写入少量数据。\nflip、clear、compact，以及后面见要见到的mark、reset方法，都只是修改影响读写位置的position、limit的值而已，没有什么神秘的。\n 这么讲可能仍然有点抽象，后面会结合示意图进行进一步描述。\n4 NIO Buffer # NIO底层是借助一个数组来实现的，使用同一个数组实现了读、写两种不同的操作模式。为了支持读写操作，Buffer实现中提供了3个非常重要的变量position、limit、capacity来跟踪数组的读写指针（实际上是位置索引）。\n在不同的操作模式（读、写模式）下，这里的position、limit、capacity拥有不同的语义，如下图所示。\n 写模式下：  position，代表当前可继续写入的位置索引，[0,position)为已写入数据范围； limit，代表当前可写入的最大位置索引，limit=capacity，[position,limit)为可写数据范围； capacity，代表当前buffer最大容量，；   读模式下：  position，代表当前可继续读取的位置索引； limit，代表当前可读取的最大位置索引，[position,limit)为可读取数据范围； capacity，代表当前buffer最大容量，[limit,capacity)为未写入数据范围；    4.1 capacity # capacity代表了buffer的最大容量，其值为最多可存储的元素数量而非占用的字节数量，这个不难理解，每一种数据类型都使用与之对应的数组来作为存储用的基础设施。\n4.2 position # 写模式下，position初始值为0，然后每写入一个元素到buffer中之后position会+1指向底层数组的下一个存储位置。写模式下position最大值为capacity-1。\n当从写模式切换到读模式的时候，position会被重置为0，limit会被重置为写模式下position的值，这样就意味着只可以读取到写模式下写入到数组中的数据而不会访问越界。当读取数据时先读取position位置处的元素，然后position+1指向底层数组的下一个存储位置。\n4.3 limit # 写模式下，limit表示最多可以写入多少个元素，limit=capacity；而在读模式下，limit表示最多可以读取多少个元素，limit=buffer.flip()前写模式下的position。\n4.4 常用方法 # 下面对Buffer中常用的方法进行一下简要总结。\n4.4.1 创建buffer # allocate方法用于创建一个指定容量的buffer对象，下面分别创建一个48字节容量的ByteBuffer和一个1024字符容量的CharBuffer。\nByteBuffer buf = ByteBuffer.allocate(48); CharBuffer buf = CharBuffer.allocate(1024);  4.4.2 写数据到buffer # 向buffer中写入数据，有两种方法，一种是通过channel.read(buffer)来将channel中的数据写入到buffer中，另一种是通过buffer.put(el)方法及其各种变体来将对应类型的元素el写入到buffer中。\nint bytesRead = inChannel.read(buf); // read from channel into buffer. buf.put(127); // ...  4.4.3 切换buffer为读模式 # buffer.flip()方法将buffer从写模式切换为读模式，调用flip之后将把limit设置为position的值，然后再见position设置为0，使得可以读取[0,limit)范围下的数据，也就是写模式下写入的数据，通过limit的控制避免数组访问越界的可能。\n4.4.4 从buffer中读取数据 # 从buffer中读取数据，也有两种方式，一种是通过channel.write(buffer)将buffer中的数据读取出来写入到channel中，另一种是通过buffer.get()方法及其各种变体来将对应类型的元素读取出来。\nint bytesWritten = inChannel.write(buf); // read from buffer into channel buf.get(); // ...  4.4.5 rewind读取索引 # buffer.rewind()方法会将读索引变量position重设为0，但是limit保持不变，这样可以重新从头开始读取buffer中的数据。\n4.4.6 清空buffer备用 # 当buffer中的数据读取出来之后，需要清空buffer中的数据用于后续的数据写入操作。\n如果确定数据已经读取完毕，这个时候可以调用buffer.clear()方法，这个方法将把position设为0，将limit设置为capacity，这意味着调用了clear方法之后buffer中的所有已存储数据都不在可读，因为已经没有位置变量可以帮助我们读取它们了。\n如果数据没有读取完毕，剩下的数据还是希望继续读，但是现在要先写入某些数据，此时可以执行buffer.compact()方法，该方法将把buffer中未读取的数据拷贝到底层数组的前面，并将position设为0，将limit设置为未读取数据的元素数量。\n4.4.7 mark \u0026amp; reset # buffer.mark()可以标记当前的position位置，后面当position改变之后可以通过buffer.reset()将position重置为调用mark方法时标记的位置。\n这里mark()、reset()在读写模式下都可以使用，mark的实现方式就是通过一个mark变量记录下当前的position位置，reset方法就是将position设置为mark记录的值。\n为了避免读写模式切换时mark()、reset()被乱用，这里buffer.reset()的时候会首先检查当前的mark值是否有效，如果mark值小于0则认为是一个错误，会抛出异常，那么什么情况下mark值会为负值呢？当执行buffer.flip()操作的时候会将mark值重置为-1，这样就避免了读写模式切换后之前的mark可能被错误reset的情况，避免了可能的访问越界问题。\n4.4.8 buffer内容比较 # buffer内容比较主要有两个方法，一个是比较两个buffer是否相等buf1.equals(buf2)，如果两个buf的类型相同，并且两个buf中剩余元素数量相同，并且两个buf中剩余的元素在对应position处都equals都返回true，那么这两个buf1.equals(buf2)才会返回true，否则返回false。\nbuffer内容比较的另一个方法是通过buf1.compareTo(buf2)，当满足以下条件时，认为buf1\u0026lt;buf2，如果两个buf类型相同，并且buf1中的前i-1个元素与buf2中的前i-1个元素对应位置都完全相等，但是buf1中的第i个元素比buf2中的第i个元素小，那么就认为buf1\u0026lt;buf2成立；或者buf1中的所有元素与buf2中对应位置的元素都完全相等，但是buf2还有更多的元素，这个时候也认为buf1\u0026lt;buf2。buf1\u0026gt;buf2的逻辑与之恰好相反，buf1.equals(buf2)的逻辑前面已经提过。\n 备注：\n当buf1\u0026lt;buf2时，buf1.compareTo(buf2)会返回一个负数；\n当buf1==buf2时，buf1.compareTo(buf2)会返回0；\n当buf1\u0026gt;buf2时，buf1.compareTo(buf2)会返回一个正数；\n 5 NIO Scatter \u0026amp; Gather # NIO中支持分散读、聚集写，glibc中也提供了类似的库函数，NIO中的分散读指的是从一个channel中读取数据到多个buffer中，聚集写指的是将多个buffer中的数据写入channel中。\n当我们需要传输的数据可以分开几个固定部分来处理的时候，分散读、聚集写是非常有用的，例如当我们传输协议数据包的时候，希望将协议包头、协议包体分开，这个时候使用分散读、聚集写就是非常有用的，因为包头往往都是固定尺寸的，从channel中先读取固定数量的字节填满包头对应的buffer，再见剩下的数据读到包体对应的buffer中，这是一个很自然的过程。组包时聚集写也是一样的道理。\n5.1 Scatter # 下面是分散读的一个示意图，图中展示了从一个channel中读取数据写入多个buffer的过程。\n对应的示例代码如下所示：\nByteBuffer header = ByteBuffer.allocate(128); ByteBuffer body = ByteBuffer.allocate(1024); ByteBuffer[] bufferArray = { header, body }; channel.read(bufferArray);  首先创建了两个buffer，假定包头是固定128字节，包体最大1024字节，然后又创建了一个ByteBuffer数组，并将其作为参数传递给channel.read()方法，read方法会按照bufferArray中的元素顺序依次进行数据写操作，当填充满第一个buffer后就继续写第二个buffer，以此类推。\n 注意如果包头尺寸不固定，那么分散读就不是很适用了。\n 5.2 Gather # 下面是聚集写的一个示意图，图中展示了从多个buffer中读取数据并写入同一个channel的过程。\n对应的示例代码如下所示：\nByteBuffer header = ByteBuffer.allocate(128); ByteBuffer body = ByteBuffer.allocate(1024); ByteBuffer[] bufferArray = { header, body }; channel.write(bufferArray);  首先也是创建两个buffer，假定包头是固定128字节，包体最大1024字节，然后用这两个buffer创建一个buffer数组，并作为channel.write()的参数，write方法按照bufferArray中buffer出现顺序依次将其内容写入channel，先将第一个buffer的内容写入到channel，再见第二个buffer内容写入到channel，以此类推。\n6 NIO Channel间数据传输 # 在Java NIO中也可以通过一个channel向另一个channel进行数据传输，但是并不是所有的channel实现都支持，这里重点说一下FileChannel，这个类有两个重要方法transferFrom(\u0026hellip;)和transferTo(\u0026hellip;)，前者可以从另一个channel读取数据，后者可以将当前channel中的数据写入到另一个channel。\n下面看一个FileChannel.transferFrom(\u0026hellip;)的应用示例。\nRandomAccessFile fromFile = new RandomAccessFile(\u0026quot;fromFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\u0026quot;toFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); toChannel.transferFrom(fromChannel, position, count);  下面再看一个FileChannel.transferTo(\u0026hellip;)的应用示例。\nRandomAccessFile fromFile = new RandomAccessFile(\u0026quot;fromFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel fromChannel = fromFile.getChannel(); RandomAccessFile toFile = new RandomAccessFile(\u0026quot;toFile.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel toChannel = toFile.getChannel(); long position = 0; long count = fromChannel.size(); fromChannel.transferTo(position, count, toChannel);  FileChannel.transferFrom(\u0026hellip;)方法也可以读取其他类型channel中的数据，FileChannel.transferTo(\u0026hellip;)方法也可以将FileChannel中的数据写入到其他类型的channel中。\n7 NIO Selector # NIO中的selector是一个非常关键的组件，可以用它来监视多个多个channel上的io事件，例如入连接请求、数据可读、数据可写等，这意味着可以用一个线程来处理多个channel，可以获得不错的并发处理性能。\n7.1 为什么使用Selector？ # 使用selector可以只用一个线程来处理多个channel上的io事件，无须创建多个线程来处理多个channel，减少创建线程的数量可以避免操作系统在多个线程之间进行切换所引入的负载。\n既然提到了线程切换所引入的负载，这里就对Java线程调度的内容展开描述一下，介绍一下Java线程、LWP进程、KLT线程之间的关系，也描述一下创建、切换过程中的代价，帮助更好地理解。然后我们再介绍一下面对不同的任务，对于多进程、多线程该如何选择。最后我们再继续介绍这里的selector。\n7.1.1 Java线程、LWP进程、KLT线程，它们之间是什么关系？ # Linux下Hotspot JVM采用的线程模型是基于“用户级线程+KLT线程”实现的，并且是一对一的，即一个Java Thread都会映射到一个Linux内核线程，线程调度利用了Linux的线程调度能力。\n这里有必要提一下Linux内核对线程提供的支持，Linux内核本身是没有什么线程的，其在设计之初就是面向进程的，最开始进程是资源分配的基本单位，也是任务调度的基本单位。但是后面发现进程创建、销毁、切换的开销比较大，如果了解过内核创建进程的实现的话就会明白这里的开销指的都是什么。\n当线程思想开始出现之后，Linux当然也不会汲取精华，为了支持线程机制，Linux内核中引入了轻量级进程(LWP，Light Weight Process)的概念，这里的“轻量级”体现在什么地方呢？如果了解过内核创建进程过程中clone及其某些特殊选项的话，就会明白创建轻量级进程比创建一个普通的进程轻量在什么地方了，简言之就是轻量级进程创建的时候共享父进程所有的资源，只是增加资源对应的引用计数，但是不会重新分配，不同于fork。\n轻量级进程也是进程，那么线程相对于进程有什么区别呢？线程不是资源分配的基本单位，只是任务调度的基本单位，对比一下linux 0.11以及2.0.40中struct task_struct结构体的定义就可以感受到任务调度的基本单位从进程变为线程这一过程。在0.11里面task_struct结构体中的tss（任务状态段，保存硬件上下文信息）为struct tss_struct类型，这一类型是面向进程的，而0.2.40里面tss是struct thread_struct类型，这一类型是面向线程的。而不管是普通进程还是轻量级进程，它们的task_struct定义中都包括一个struct thread_struct tss，用于任务调度过程。\nLinux下的KLT线程其实并不是什么真正的线程，其强调的是一种面向线程的任务切换能力。Java中的线程逻辑上是从属于java进程的，在Linux平台下实现时Java主线程被映射为一个普通的进程，而其他Java线程被映射为系统进程clone出来的轻量级进程LWP，这里clone出来的LWP的tgid（线程组id）与普通进程（父进程）是相同的，因为逻辑上它们从属于同一个线程组。普通进程跟轻量级进程在任务切换时所需要执行的除tss保存、还原之外的附加工作是不一样的，进程的附加工作更重（可能会涉及到虚拟内存等的处理），切换效率更低。\n任务切换过程中涉及到的内容说起来可能就几个关键点，但是如果想把细节讲清楚，需要结合软硬件变迁的历史、各种可能的情景来描述，请原谅我还掌握的还不够，这里就先点到为止。\n讲了这么多，看上去好像是要大肆宣扬使用Java多线程编程，这里不是，只是想到了实现进程、线程所需要付出的代价，多线程确实比多进程更加轻量，但也并非多线程一定比多进程好，要看实际的应用场景。\n7.1.2 面对不同任务，多进程、多线程的选择？ # 我们开发的程序往往可以归为3类：\n 计算密集型（CPU敏感型） IO密集型（计算负载小，网络IO多） 用户交互型（代码逻辑在计算、网络IO之间切换，非固定偏向某一种）  对于计算密集型的任务，即便开多个Java线程也不会得到很好的并发效果，简言之这个Java线程不会让度CPU，为什么这么说呢？以单CPU单核为例，一个时刻只会调度一个Java线程执行，因为这个线程忙于计算，不会因为阻塞让度CPU（阻塞时内核通常会将对应的LWP设为不可中断等待直到IO完成才会将其设为就绪重新参与进程调度），这样其他的Java线程基本得不到调度的机会，除非该线程对应的LWP时间片到切换到执行其他Java线程的LWP才可以。假如所有的线程都是计算密集型，这样的多线程计算效率要远低于多进程计算！多CPU或者多核情况下，虽然可以通过在其他CPU或者核心调度多个Java线程，但也无济于事！\n对于IO密集型的任务，应该开多个Java线程来代替多个进程，IO一般多指网络IO，IO完成需要一定的时间，不可能IO一发起就立即成功结束，所以使用阻塞型IO进程一定会经历阻塞、唤醒的过程。对于阻塞型IO，映射到LWP之后，进入阻塞型系统调用，Linux内核会将LWP状态设置为不可中断等待状态，在IO完成内核重新修改LWP状态为就绪态之前，LWP无法参与进程调度，对应的Java线程也无法执行，这期间CPU就会被让出来供其他LWP选择执行剩余的Java线程，这种情况下多个Java线程可以提高并发效率。\n这里可能有人问为什么一个Java线程阻塞了，对应的Java进程却没有阻塞？JVM中Java线程只是维护了线程应有的某些属性信息，并非真正的线程实体，一个Java进程准确地说是一个JVM实例，也不是一个通俗意义上的进程。一个JVM实例实际上包括一个Java主线程对应的普通进程，同时还包括了很多的调度Java线程用的LWP以及用于执行JVM特殊任务（如GC）的LWP。一个Java线程的阻塞，只是阻塞选择并执行该线程的LWP，对于其他Java线程不会构成影响。这里选择Java多线程模型比多Java进程模型要好多了，后者更消耗资源，任务调度上也获得不了什么优势。\n 备注：\n关于Java线程创建、调度以及多进程、多线程如何选择的内容就先介绍到这里，下面回到本章selector上来。\n 前面我们提到了在不同的任务下对多进程、多线程的选择，对于IO密集型的任务，其实因为计算时间比较短，绝大部分时间是在执行IO处理，如果我们能够采用IO事件驱动的方式来对IO进行处理的话（比如处理连接建立、读写数据），使用单一线程也可以获得不错的系统吞吐量，也能减轻多线程切换的负载。\n下图是一个单线程借助selector对3个channel进行管理的示意图。\n7.2 创建Selector # 通过一个简单的方法调用，就可以创建一个selector对象。\nSelector selector = Selector.open();  7.3 向Selector中注册Channel # 要想通过selector来访问channel，首先要将关心的channel及其事件向selector进行注册，注册的方法如下所示。\n// 通过selector访问channel，channel必须是非阻塞模式 channel.configureBlocking(false); // param1, channel必须是可以设置为non-blocking // param2，关心的事件有4钟，Connect、Accept、Read、Write SelectionKey key = channel.register(selector, SelectionKey.OP_READ);  FileChannel因为无法切换为非阻塞模式，所以无法将其注册到selector，也就无法通过selector对FileChannel进行访问。SocketChannel可以注册到selector，实际上一般多是用selector来处理SocketChannel上的IO事件。\n对于channel.register方法的第二个参数，是要注册的感兴趣的事件类型，主要有4种：\n Connect，表示一个SocketChannel连接到另一个server成功； Accept，表示一个ServerSocketChannel接收一个入连接请求成功； Read，表示channel中有数据到达，可以进行读取； Write，表示channel中有空闲位置，可以写入数据；  当channel中发生了上述事件时，我们称该channel上的对应事件就绪，例如Read事件就绪，或者说是Read Ready。\n7.4 SelectionKey # 当我们调用channel.register()时，该函数返回一个SelectionKey对象，通常这个对象可以获取到注册时的channel、selector、感兴趣的事件集合interestingSet、就绪事件集合readySet，以及一个可选的attach对象。\n7.4.1 感兴趣事件集合interesting set # 下面是一个通过selectionkey来获取注册时提供的interesting set的代码示例。\nint interestSet = selectionKey.interestOps(); boolean isInterestedInAccept = interestSet \u0026amp; SelectionKey.OP_ACCEPT; boolean isInterestedInConnect = interestSet \u0026amp; SelectionKey.OP_CONNECT; boolean isInterestedInRead = interestSet \u0026amp; SelectionKey.OP_READ; boolean isInterestedInWrite = interestSet \u0026amp; SelectionKey.OP_WRITE;  7.4.2 就绪事件集合ready set # 下面是一个通过selectionkey来获取ready set的代码示例。\nint readySet = selectionKey.readyOps();  为了测试到底有哪些事件就绪，是connect、accept？还是read、write？还是没有？可以采用与8.4.1总相同的“AND”操作来对对应的事件bit进行测试，以发现到底有哪些事件就绪。另外selectionkey提供了4个方法可以用于测试某个事件是否就绪，这4个方法是：\nselectionKey.isAcceptable(); selectionKey.isConnectable(); selectionKey.isReadable(); selectionKey.isWritable();  7.4.3 channel + selector # 通过selectionkey获取channel、selector是通过对应的getter方法，如下所示：\nChannel channel = selectionKey.channel(); Selector selector = selectionKey.selector();  7.4.4 attach object # 可以通过selectionkey来设置一个attach对象，这个对象可以用来识别一个channel，也可以用于向channel提供附加信息。比如我们可以将channel对应的buffer作为这里的attach对象。设置attach对象、获取attach对象的方法如下所示。\nselectionKey.attach(theObject); Object attachedObj = selectionKey.attachment();  注册channel到selector时，如果attach对象已存在，也可在注册的时候指定attach对象。\nSelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject);  7.4.5 selector选择事件就绪的Channel # 将channel注册到selector之后，可以通过selector中的select方法来选择出有感兴趣事件就绪的channel，以便对其进行处理。\n这里的select方法有3个不同的变体：\nint select(); // 阻塞在此处直到有感兴趣的channel就绪 int select(long timeout); // 阻塞在此处最多timeout秒 int selectNow(); // 不阻塞在调用处，没有就绪channel立即返回  这几个select方法的返回值表示上一次调用select方法之后又有新事件就绪的channel的数量（类似于epoll的ET_TRIGGER方式）。例如向selector注册了两个channel，第一次调用select时假如有一个channel就绪，那么select返回值为1。假如下次调用select时又有一个channel有时间就绪，那么select返回值为1。假如第一次调用select后的channel就绪事件没有进行处理的话，那么现在就有两个事件就绪的channel等待处理，但是第二次select的时候只返回1而不是2。如果理解epoll的ET_TRIGGER方式的话，这里应该不难理解。\n7.4.6 selectedKeys() # 一旦select返回，并且确实存在事件就绪的channel的话，可以通过selectedKeys()方法来访问这些就绪的channel并执行相应的处理动作。selectedKeys()返回一个集合，集合中的SelectionKey关联的channel均存在就绪事件。下面是方法selectedKeys()的方法声明。\nSet\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys();  由于可能为不同的channel上关联了不同的selectionkey类型（connect、accept、read、write），当我们遍历所有的selectionkey时需要检查对应的selectionkey的类型，以便执行与connect、accept、read、write相对应的处理动作。下面是一个操作示例。\nSet\u0026lt;SelectionKey\u0026gt; selectedKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); // 注意根据不同的事件类型，对key.channel()进行适当的类型转换 if(key.isAcceptable()) { ServerSocketChannel chl = (ServerSocketChannel)key.channel(); ... } else if (key.isConnectable()) { SocketChannel chl = (SocketChannel)key.channel(); ... } else if (key.isReadable()) { SocketChannel chl = (SocketChannel)key.channel(); ... } else if (key.isWritable()) { SocketChannel chl = (SocketChannel)key.channel(); ... } // - 需要从selectedKeys集合中手动移除处理完毕的SelectionKey // - 下次调用selectedKeys()时若事件就绪，会重新将其加入selectedKeys集合中 keyIterator.remove(); }  7.4.7 wakeup # 如果一个线程调用了selector.select()方法并且阻塞在这个方法调用处的话，可以通过在另一个线程将其“唤醒”，唤醒的方式就是在这个不同的线程中调用selector.wakeup()方法。\n假如一个线程调用了wakeup方法，并且当前没有线程因为调用select方法而阻塞在方法调用处的话，那么下次某个线程调用select方法时假如没有事件就绪的channel，这个线程将立即被“唤醒”，即不会阻塞在方法调用处。这与selector的实现细节有关系，这里不过多展开。\n7.4.8 close # 当我们不再需要使用selector对channel进行处理的时候，可以通过selector.close()方法来关闭selector，该selector将同时使注册的所有的selectionKey实例失效，但是呢，这里的close方法并不会关闭注册时的channel对象，如果不需要对channel进行处理了，需要手动处理channel的关闭操作。\n8 FileChannel # FileChannel是连接到文件的channel，可以通过FileChannel对文件进行读写，它是标准IO读写文件的另一种替代方案。\nFileChannel不能设置为non-blocking模式，只能工作在blocking模式下。\n8.1 打开一个FileChannel # 只能通过文件输入输出流或者RandomAccessFile来打开FileChannel，不能直接打开，下面是通过RandomAccessFile打开FileChannel的示例。\nRandomAccessFile aFile = new RandomAccessFile(\u0026quot;data/nio-data.txt\u0026quot;, \u0026quot;rw\u0026quot;); FileChannel inChannel = aFile.getChannel();  8.2 通过FileChannel读取数据 # 通过FileChannel读取数据主要分为两步，首先分配一个buffer，然后将channel中的数据读取到并存储到buffer中，下面是一个读取FileChannel的示例。\nByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buf);  如果read返回-1，表示EOF，End Of File，即到达了文件末尾。\n8.3 向FileChannel写入数据 # 向FileChannel中写数据主要包括下面几步，首先要有一个待写入的数据，然后分配一个buffer并将数据写入buffer中，最后再调用channel.write(buffer)方法将buffer中数据写入channel。下面是一个操作示例。\nString newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); // buffer一开始为write模式，调用channel.write()之前需要flip切换为读模式 buf.flip(); // 不能保证channel.write()方法一次会读取buffer中多少数据，因此要循环处理 while(buf.hasRemaining()) { channel.write(buf); }  8.4 关闭FileChannel # 当FileChannel使用完毕之后，必须关闭，避免句柄泄露的问题。\nchannel.close();  8.5 FileChannel中文件位置 # 类似于fseek类的相关操作，FileChannel也提供了在文件中进行位置定位的能力，主要是通过position这几个方法。\nlong pos = channel.position(); // 获取当前在channel中的位置 channel.position(pos+123); // 在channel中定位到当前位置之后123偏移量处  如果pos+123超过了channel的实际尺寸的话，channel.read(\u0026hellip;)的时候将返回-1。\n8.6 FileChannel Size # 获取FileChannel关联的文件的尺寸，可以通过channel.size()方法。\nlong fileSize = channel.size();  8.7 FileChannel Truncate # 如果将文件截断为指定的尺寸，并丢弃超出部分的内容，可以通过channel.truncate(\u0026hellip;)方法。\nchannel.truncate(1024);  8.8 FileChannel Force # 类似于sync操作，FileChannel也提供了将文件在内存中的数据同步到磁盘的操作，即通过channel.force()方法，另外呢，channel.force(true)还可以将文件的元数据信息同步到磁盘，比如将文件权限信息等同步到磁盘。\n 备注：\n操作系统一般都是将文件内容读取到指定的缓冲块中，文件元数据信息也是会被加载到i节点对应的缓冲块中，当进程对文件本身进行操作时，为了提高性能，操作系统一般不会立即将文件内容、元数据信息的修改同步到磁盘，而是将改写后的数据存储在这里的缓冲块中（缓冲块其实是内核中的一段特殊内存区域），过一段时间之后，内核会自动将这里的数据同步到磁盘（Linux 0.11中是通过update进程来负责完成缓冲块写回磁盘的工作）。\n当时某些情景下，进程希望立即将某些信息写回磁盘，就可以通过这里的force方法来完成。\n 9 NIO SocketChannel # SocketChannel是对Tcp网络套接字的一种抽象，有两种创建SocketChannel的方式，一种是通过连接到远程的某个Tcp Server来创建一个SocketChannel，一种是通过ServerSocketChannel监听到入连接请求时创建一个SocketChannel。\n9.1 创建SocketChannel # 下面是一个通过连接到Tcp Server来创建SocketChannel的示例：\nSocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(\u0026quot;http://jenkov.com\u0026quot;, 80));  9.2 关闭SocketChannel # 关闭socketchannel的方式就是调用close方法。\nsocketChannel.close();   备注：\n资源的释放是非常重要的，我经历过一次因为没有关闭tcp连接导致进程打开的fd达到系统上限，进而导致tcp server拒绝服务的一次事故，直接拖垮了现网\n 9.3 从SocketChannel读取数据 # 从socketchannel读取数据可以通过channel.read()方法及其变体来操作。\nByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = socketChannel.read(buf);  9.4 写数据到SocketChannel # 写数据到socketchannel可以通过channel.write()方法及其变体来操作。\nString newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); buf.flip(); while(buf.hasRemaining()) { channel.write(buf); }  9.5 Non-blocking模式 # 可以将socketchannel设置为非阻塞模式，然后以非阻塞的方式来进行connect、read、write操作，当然也可以通过selector基于事件驱动的方式来对channel进行更好地处理。这里先看下非阻塞方式下的connect、read、write。\n9.5.1 connect # 非阻塞模式下connect调用可能在连接成功建立之前就返回了，为了判断连接是否建立成功，需要通过finishConnect方法来判断连接是否成功建立。\nsocketChannel.configureBlocking(false); socketChannel.connect(new InetSocketAddress(\u0026quot;http://jenkov.com\u0026quot;, 80)); while(! socketChannel.finishConnect() ){ //wait, or do something else... }  9.5.2 read # 在非阻塞模式下read，可能不会返回任何数据，需要对返回值进行判断，如果返回值\u0026gt;=0都是有效的读状态，应该在循环中继续进行read操作。如果返回值为-1（EOF），表示对端Tcp连接关闭，此时应该关闭channel。这里就不给出代码示例了。\n9.5.3 write # 在非阻塞模式下write，可能不会立刻写入任何数据，也需要在循环中进行write操作，直到数据全部写入成功。前面已经给出了类似的write示例代码，这里就不再重复给出代码示例了。\n 备注：\n也可以通过selector注册多个非阻塞的socketchannel，然后通过selector基于事件驱动的方式来对socketchannel上的io事件进行处理，后面会继续对此进行描述。\n 10 NIO ServerSocketChannel # serversocketchannel可以用于监听入tcp连接请求，并返回建立的tcp连接对应的socketchannel。\n下面是一个简单的应用示例。\n// 创建一个serversocketchannel ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); // 绑定监听端口 serverSocketChannel.socket().bind(new InetSocketAddress(9999)); while(true){ // 监听tcp入连接请求 SocketChannel socketChannel = serverSocketChannel.accept(); //do something with socketChannel... } // 关闭serversocketchannel serverSocketChannel.close();  我们也可以使用非阻塞的方式来使用serversocketchannel，如下所示。\nServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); serverSocketChannel.socket().bind(new InetSocketAddress(9999)); // 设置为非阻塞模式 serverSocketChannel.configureBlocking(false); while(true){ SocketChannel socketChannel = serverSocketChannel.accept(); // accept在连接建立之前返回，返回null if(socketChannel != null) { //do something with socketChannel... } } serverSocketChannel.close();  其实我们也可以将serversocketchannel的accept事件注册到selector，然后用selector使用基于事件驱动的方式来对tcp入连接请求进行处理。后面会进一步进行介绍。\n11 NIO Non-blocking Server # 截止到现在，尽管已经对NIO中的selector、channel、buffer进行了介绍，我们也了解了它们的基本使用方法，但是要想设计一个non-blocking io的server还是有较大的难度的。non-blocking io实现的server相比于blocking io实现的server存在一些很有挑战性的地方，这里将针对这些挑战提出一些解决方法。\n从网上找一些关于non-blocking io实现server的方式也是比较困难的，相关的描述也并不是很细致，因此这里的解决方法是根据作者个人的一些工作经验和想法提出的。如果你有好的建议，也可以自己进行实现、测试。\n这里的设计思路是围绕着Java NIO来进行的，其实这里的设计思路同样可以用于其他的编程语言中，只要对应的语言提供了类似selector这样的事件驱动IO处理的API即可，比如可以使用c、c++语言来基于epoll实现。\n11.1 NON-Blocking Server - Github Repo # 这里根据本文提供的非阻塞io server的设计思路，作者对其进行了一个实现，项目的源代码也已经托管在了github上，可以从这里下载到：Non-Blocking IO Server。\n11.2 NON-Blocking IO Pipelines # 非阻塞io流水线模型是通过多个模块构成的职责链来处理非阻塞io，包括非阻塞的read、write操作，下图是一个简化版（只有一个component）的非阻塞io流水线的示意图。\n这里的component通过使用一个selector来检查什么时候可以从channel读取数据，然后读取数据之后执行处理生成某些结果信息，并将结果信息输出到channel。\n一个流水线模型并不总是既读取数据又写数据，某些情况下可能只会读取数据，某些情况下可能只会写入数据。上图中这个简化版的流水线模型示意图只有一个component，通常一个流水线有多长取决于这个流水线要执行什么样的任务处理。一个非阻塞io流水线也可能会同时读取多个channel中的数据，并不一定是只读一个channel，比如可能读取多个SocketChannel中的数据。对于流水线的输出操作也是一样的情况。上图中的控制流也是简化的，数据读取操作是由component发起的，而不是由channel push消息到selector再发送到component……\n11.2 NON-Blocking vs Blocking IO Pipelines # 这里对非阻塞io流水线模型和阻塞io流水线模型进行一下分析、对比。这两种流水线模型的最大区别在于对channel中数据的读取方式，这里的channel无非也就是读写socket或者file。\n如下图所示，io流水线中往往是通过一个Message Reader来读取Stream中的数据，并将数据解析为一个或者多个Message，然后进行再交给其他component进行处理。\n对于阻塞型io，这里的Stream可以通过InputStream等类似接口进行数据read操作，read操作将会被阻塞，直到有数据到达read才返回。阻塞型io场景下MessageReader的实现是比较简单的，因为InputStream的read操作直到读取了指定数据量的数据后才会返回，MessageReader不需要处理没有数据到达或者只有部分数据（read读取的数据小于一个完整的Message）到达的特殊情况。\n类似地，阻塞型io，这里的MessageWriter实现也比较简单，因为write操作总是将指定数据量的数据写入到OutputStream才会返回，不需要处理没有输入写入或者只写了部分数据的特殊情况。\n 备注：\n非阻塞型io需要针对MessageReader可能读取不到数据、读取到部分数据的情况进行处理，也需要对MessageWriter没有写数据或者只写了部分数据的特殊情况进行处理，这涉及到很多细节上的处理，增加了MessageReader、MessageWriter的实现难度。\n 11.3 Blocking IO Pipelines Drawbacks # 虽然前面提到阻塞型io流水线便于简化MessageReader、MessageWriter的实现难度，但是阻塞型io流水线也存在比较明显的劣势，这里就对其存在的问题进行简要描述。\n阻塞型io流水线中，对于一个特定的InputStream的数据读取操作，一般要开一个专门的线程进行数据读取操作，因为如果使用当前线程进行数据读取操作的话将会阻塞当前线程，线程将无法继续执行其他处理。\n如果一个server是基于阻塞型io流水线实现，那么每当一个tcp入连接请求到达，server就建一个对应的tcp连接，对于连接上接收到的数据需要执行read操作，那么需要为每个tcp连接创建一个线程专门用于读取其InputStream上的数据。如果server要处理的并发量只是几十上百的话，那么这种设计方式也不会造成什么危害。但是假如server面对的是成百万上千万的并发量的话，这种设计是难以平行扩展的。在32位系统上，一个Java Thread的线程栈大约占320KB内存，在64位系统上，大约要占用1MB内存，计算一下100w个线程的线程栈总容量，大约为1TB内存！这还只是线程栈的大小，还没有计算线程需要处理请求所需要的堆空间等的内存空间。\n为了减少创建线程的数量，有些解决方案是借助于线程池的方式来避免无限制地创建线程。线程池指定允许创建线程的最小、最大数量。每当有tcp入连接请求到达的时候，主线程创建一个连接，并将这个连接丢到一个阻塞队列中，然后线程池中的线程来从这个阻塞队列中取出要处理的tcp连接，并获取连接对应的InputStream然后进行数据读取操作。这里的设计可以用下面的示意图来表示，图中最左边的多个Stream代表多个tcp连接上的InputStream，将多个Stream组合在一起的方框则代表保存tcp连接的阻塞队列。\n但是这种基于线程池来希望避免无限制创建线程的想法也是站不住脚的，因为假如有太多请求比较耗时，长时间占用线程或者数据read、write阻塞线程，更极端一点，很可能线程池中的所有线程都被阻塞了，那么server为了不出现DoS（Denial of Service）那它可能会执行在线程池继续创建线程的动作以对新的请求进行响应，这一过程将持续到线程池中线程数量达到最大阈值，假如最大值为100w，那么占用内存还是会超过1TB！而如果不继续创建线程，因为线程都阻塞了，也无法继续响应新的请求。\n所以，基于阻塞型io流水线的架构可能实现MessageReader、MessageWriter比较简单，但是真的不利于server的平行扩容，难以有效应对高并发的场景，如果事务处理时间有比较长的话，系统吞吐量将会严重下降，甚至于可能会出现拒绝服务。\n11.4 Basic Non-blocking IO Pipeline Design # 前面提到了阻塞型io流水线的优缺点，为了解决阻塞性io流水线的弊端，可以采用非阻塞型io流水线技术提供另一种读取数据的实现方法。\n非阻塞型io中可以通过一个MessageReader来读取源自多个stream的数据，前提是要将stream对应的channel设置为非阻塞工作模式。非阻塞io流水线下，MessageReader读取数据操作可能返回0或者正数，如果返回0表示没有读取到数据，如果返回正值，则表示成功读取的数据数量。\n某个tcp连接上如果没有数据到达，那么前就不应该分配线程对连接上的数据执行处理。NIO Channel里面对于这些非io事件就绪的连接是不会返回的，只返回我们关心的发生了某些特定事件的channel，然后对channel进行read操作，这样效率还是比较高的。\n这种基于非阻塞io流水线模型的示意图如下。\n11.5 Reading Partial Messages # 当从一个SeletableChannel中读取数据时并不清楚读取到的数据是否是一个完整的消息，这里读取到的数据Data Block可能不足一个完整的Message，可能刚好是一个完整的Message，当然也可能包括了一个完整的Message和另一部分或完整或不完整的Message数据，如下图所示。\n在处理不完整消息数据的时候面临着两个挑战：\n 如何检测在数据块里面是否包括了一个完整的Message； 在完整的Message数据到达之前，对部分到达的数据应该做如何处理；  为了检测消息数据的完整性，需要提供一个Message Reader来检查数据块中是否至少包括一个完整的Message对应的数据。如果这个数据块中包括了一个或者多个完整的Message，这些完整的Message可以发送到流水线中进行后续处理任务。从数据块中检查Message完整性的工作要不停地重复，所以这部分处理要尽可能高效。\n当数据块中出现了一个Message的不完整数据，这个数据可能出现在一个或者多个完整Message数据之后，也可能单独出现，在Message的剩余数据到达之前需要将这部分数据先临时保存起来，以便后续数据到达之后将其拼接为一个完整的Message。\n检测Message数据完整性和存储Message的不完整数据的工作，都是由Message Reader来完成的，为了避免不同的channel上到达的Message数据混淆在一起，我们为每个channel分配一个单独的Message Reader。Message Reader示意图如下所示。\n一旦从selector获取到一个可以进行读操作的channel实例，与之关联的Message Reader就开始工作，从channel中读取数据并将其组装成一个个完整的Message，完整的Message将被丢到流水线执行后续处理工作。\n当然了，Message Reader将读取到的数据如何组装成一个个完整的Message，这个是与定义的应用层协议相关的，Message Reader必须要知道Message的格式。如果要将server实现做成一个支持多种协议的，最好能借助Message Reader插件的形式来完成，可以通常Message Reader工厂模式，通过指定具体的配置参数来获取协议对应的Message Reader。\n11.6 Storing Partial Messages # 前面已经指出了存储不完整的Message数据也是Message Reader的工作，这里我们说明一下如何实现Message Reader存储不完整Message数据。\n在设计实现方案时有这么两个点需要关注：\n 希望能够尽可能少地拷贝消息，拷贝次数、拷贝数据越多，效率越差； 希望能够将属于同一个Message的数据在内存中连续存储，方便解析；  为每个Message Reader分配一个独立的Buffer # 很明显，到达的不完整的Message数据需要被临时存储在某种形式的buffer中，最直接的就是每个Message Reader里面开一个buffer来存储。但是这里的buffer多大合适呢？它需要能够存储下最大尺寸的Message，假如这个最大的Message是1MB的话，假如有100w并发访问，一个tcp连接对应一个channel，一个channel对应一个Message Reader，一个Reader对应一个buffer，假如将buffer开到最大Message的尺寸1MB，这个时候大约需要100w*1MB=1TB的内存，而如果Message尺寸继续增大呢？16MB或者128MB呢？\n这种设计方案存在个巨大的缺陷，现实中的内存很难达到这个容量。\n容量可调整的Buffers # 再想一种方案，我们可以设计一个容量可调整的buffer在Message Reader中使用，这个buffer呢一开始容量比较小，等到有较大的Message到达的时候自动扩展buffer的容量。这样的话每个tcp连接就不会固定占用1MB的buffer了，每个连接仅占用获取下一个完整Message所需要的buffer空间。\n实现容量可调整的buffers的实现方法有多种，各有优劣，这里就介绍几个常用的实现方法。\n通过“拷贝”操作实现Buffer容量调整 # 这里的思路是开始的时候设置buffer为一个较小的容量，例如4KB，当一个正在接收的Message大小超过了这个buffer时，假设Message大小为4.1KB，这个时候就申请一个更大的buffer，例如8KB，然后将已经接收的数据从4KB的buffer拷贝到8KB的buffer。\n这种方式的优点是，可以保证同一个Message的数据在内存中是连续的，这样解析这个Message的时候就会变得很简单（各个协议字段是挨着的，访问各个协议字段时逻辑更简单）。\n这种方式的缺点是，尺寸较大的Message会导致很多的数据拷贝动作。\n为了减少数据拷贝的次数，可以对server请求进行抓包分析，如果大多数的请求Message都小于4KB，那么buffer的起始容量可以设置为4KB。再延伸一下，假如后续抓包分析到有些请求Message尺寸会超过4KB，分析后发现这些都是传输的文件，进一步分析发现这些文件大部分都是小于128KB的，那么这个时候可以考虑将128KB设为buffer的调整后尺寸。再延伸一下，假如后续发现也有些请求Message是超过128KB的，但是这些请求并没有明显的模式表明其最大尺寸，这个时候可以指定一个最大阈值，例如256KB，来作为buffer的最大调整尺寸。\n通过对server中请求Message的分析后，我们得出了3个不同容量的buffer来实现调整buffer容量的目的，一定程度上减少了数据拷贝的次数。\n 对于小于4KB的Message不需要执行拷贝动作，假如Message都小于4KB，100w连接只需要大约4GB的内存，这个容量还是可接受的（2015年数据）； 对于大于4KB小于128KB的Message，之前存储在4KB buffer中的数据需要被拷贝到128KB的buffer中，然后后续到达的数据直接存储到128KB的buffer中即可，因此数据拷贝次数为1； 对于大于128KB的Message，其最初是被存储到4KB buffer中的，后面读取的时候发现数据存不下了，就将其拷贝到128KB的buffer中（拷贝了一次），然后后续读取的时候发现128KB的buffer也不够用了，就需要再将其拷贝到MaxKB buffer中（拷贝了一次），后续再到达的数据直接写入MaxKB buffer中，共执行了两次拷贝动作。  考虑到大于4KB的Message是少量的，因此内存占用应该不是太大的问题，数据拷贝次数也应该是可以接受的。\n当一个Message被构建成功之后，为接收Message数据所分配的大容量的buffer应该予以释放。这样一来，对应的channel上的Message Reader中的buffer又从最小的4KB buffer开始。这种方式保证了各个连接只占用必要容量的内存，使得可以有更多连接同时执行消息处理任务。\n作者曾经实现了一个容量可调整的Array，采用的实现方式与这里的相同，感兴趣的话可以查看一下，链接地址为Resizable Arrays。教程里面给出了github上托管的repo地址。\n通过“追加”操作实现Buffer容量调整 # 另一种调整buffer容量的方式，我们可以创建这样一个buffer，让它包括多个数组（普通buffer都是只包括一个数组），当我们需要调整buffer容量的时候就再额外申请一个数组并将其加入到这个buffer中，向buffer中写更多数据时就可以写入到新加入的数组中。\n这里也可以细分为两种方式。一种是在buffer内部增加一个列表，列表维持一系列数组的引用，当buffer需要扩大容量时，就分配新数组加到这个数组列表里面；另一种是分配一系列的共享同一数组的slices，然后buffer中维持一个列表来记录这些slices。这两种方式类似，但是也确实有点区别，其中第二种方式看上去要更好一点。\n通过追加的方式来扩容buffer，这种方式的缺点是数据不是存储在同一个连续的地址空间中，这使得Message的解析工作更加困难，解析器必须对多个数组内的数据进行检查才能确定Message所包含的所有数据。这种方式比较难处理。\nTLV编码的Message # 一些协议消息Message采用的是TLV格式，TLV即Type、Length、Value。意思是说这样的Message数据首先会存储消息的总长度，这样我们就能立即知道需要分配多少内存空间才能容纳Message的数据。\nTLV编码格式使得内存管理更简单了，很容易就知道需要多少内存空间来容纳Message数据，不会向前面说的resize buffer时存在的内存空间浪费的情况。\nTLV编码格式的缺点是，我们在Message数据完整到达之前就知道了消息的总长度，并且为其一次性分配了内存空间，这其实又浪费了内存的使用效率。如果有很多的慢速tcp连接，并且它们发送的都是比较大的Message，那么可能会导致Message处理之前就大量占据了内存，很可能导致服务没有足够内存来处理其他事务最后拒绝服务。\n解决这个问题可以对Message的消息格式进行一下改进，即让这个Message中的每个字段都编码成TLV格式的，然后一个字段一个字段地来读取，检测长度、分配内存、解析，最后再构建出完整的Message，这样可以避免因为一次性分配全部内存带来的弊端。但是如果字段值确实比较大，仍然会存在类似的内存分配的问题。\n再一种解决思路是给待接收的Message设置一个定时器，例如每个Message的接收时间设置为10~15s。当一个Message数据部分到达，剩余数据没有在定时器设置的时间阈值之内到达，那么则当做超时事件处理，Message Reader可以放弃对这个Message的处理，或者直接关闭这个Message Reader对应的channel，服务就可以腾出资源去处理其他事务。这种方式一定程度上可以避免偶然到达的很多比较大的Message，但是仍然会出现服务无响应的情况。恶意的DoS攻击可能会导致服务器的内存被完全耗尽。\nTLV编码存在多种不同的变体，按照TLV的定义它应该首先指定类型，然后是长度，再然后是数据本身。也有的TLV编码不这样，比如先指定长度，然后再指定类型，最后是数据本身，这种也称为LTV编码，也就是Length、Type、Value，这仍然是LTV的一种变体。LTV比TLV更有优势，以为它将长度放在最前面，更利于程序感知到Message数据的长度。\nTLV编码能让程序尽快感知到Message的长度便于程序为其分配内存，HTTP 1.1之所以采用TLV编码格式也是有这样的考虑。HTTP 2.0里面采用LTV编码格式，完善了HTTP 1.1采用TLV编码所带来的一些问题。作者在设计实现自己的项目VStack.co project的时候也是出于同样的考虑而采用了LTV编码。\n11.7 Writing Partial Messages # 在非阻塞IO流水线中写数据也是一个不小的挑战，当我们调用channel.write(buffer)的时候，如果channel是以非阻塞方式工作的，这种情况下我们没办法保证buffer中的数据是否全部写入到channel了，write方法会返回写入的字节数量，通过这个字节数量来跟踪数据到底有没有写、有没有写完。\n为了对可能的写出部分Message数据的情况进行更好地管理，我们为每个channel都分配一个Message Writers实例，在每个Message Writer实例内部来跟踪当前正在写的Message已经写出了多少字节，从而判断Message的数据是否已经写完。\n某些情况下，可能有多个Message等待被写入到channel中，但是Message Writer不能一次性将所有的Message数据全部写入，因此这里等待被写入到channel中的Message必须“排队”，即我们需要维护一个Message队列，然后将Message Writer按照先进先出的顺序来将队列中的Message写入到channel中。\nMessage Writer的工作示意图如下所示。\nMessage Writer之前可能将部分Message的数据写入到了channel中，这种情况下Message Writer需要被定时或者时不时地多调用几次以将同一个Message的剩余数据写入到channel中。\n如果有很多的tcp连接，也就意味着很多的channel，也就意味着需要分配很多个Message Writer实例。假设我们要支持100w并发连接请求，意味着要分配100w个Message Writer，检查100w个Message Writer是否可以执行写操作（检查channel是否可写、是否有Message等待写入channel）是非常耗时的。首先可能有很多个Message Writer没有需要写入的Message；另一个，并不是所有的channel都处于数据可写的状态。我们不应该浪费过多时间在无用的操作上面，例如尝试向一个不太可能处于可写状态的channel写入数据。\n前面我们提到，可以通过selector来轮询多个channel是否事件就绪，这里当然也可以使用。但是呢，将所有的100w个channel注册到一个selector轮询也是代价比较高的，这样做不仅没必要，也不应该。假如大多数连接都处于空闲状态，现在有100w连接，假设我们将这个100w个channel全部注册到了selector然后使用select()来轮询事件，那么select返回的写操作就绪状态的channel将会非常多（前面已假设了大多数连接处于空闲），这个时候需要逐个检查各个channel上的Message Writer是否有Message等待被写入。\n 备注：\nselect返回很多事件就绪的channel绝对不是一个好事情，是否IO事件就绪的情景没有进行更细粒度地划分？\n 这里对IO情景做一个小的优化，我们肯定是要轮询channel是否写就绪，但是什么时候才需要判断channel的状态呢？只有Message Writer有Message要写入的时候才会判断。所以我们需要轮询Message Writer是否有Message要写入channel，如果有的话，我们再将对应的channel注册到selector，然后通过selector检查channel是否写就绪。一旦Message Writer将一个Messag的数据全部写入到了channel，那么当前一次写操作就完成了，这个时候应该将channel从selector中取消注册，等到有Message要写的时候再注册到selector，这样可以避免selector轮询太多没Message要写入的channel所引发的性能下降问题。\n总结一下，就是可以概括为两步：\n 当一个Message被写入到的Message Writer的Message队列的时候，将Message Writer对应的channel注册到selector（如果还没有注册的话）； 服务空闲的时候通过selector.select()来筛选出写就绪的channel，然后调用对应的Message Writer将当前需要写入的Message数据写入channel。如果Message数据被全部写入，则将channel从selector取消注册。  11.8 Putting it All Together # 一个非阻塞模式的服务可能需要多次检查接收到的数据是否构成了一个完整的请求Message，进而检查是否收到了多个完整的请求Message，只读取一次数据、检查一次数据是不够的。\n类似地，非阻塞模式的服务也需要多次检查同一个Message的全部数据是否全部写出了，同时也需要检查是否还有其他Message要写出。如果检测到有Message数据要写出，那么服务需要检查相关的channel是否写就绪。只在Messge入Message Writer的写队列时检查一次是不够的，因为Message可能会被部分写出，这种情况下需要多次写操作。\n最后稍微概括一下，一个非阻塞模式的服务大致需要3个流水线来协作运行：\n 数据读取流水线，对建立起的tcp连接上的请求数据进行读取； 事务处理流水线，对已经接收到的完整Message进行事务处理； 数据输出流水线，检查是否有Message数据要写出到建立起的连接；  这3个流水线在一个循环体中重复执行，可能有必要对其执行过程进行优化。例如，如果没有Messge等待写出可以选择跳过数据输出流水线的逻辑。或者，如果没有接收到新的完整的Message，也可以跳过事务处理流水线的部分逻辑。\n下图是该教程所阐述的一个非阻塞模式下服务的工作过程示意图。\n如果看了这里的教程之后依然觉得有些困惑或者感觉有点复杂的话，可以查看一下作者的一个nio server的实现，github java-nio-server。阅读这里的代码将有助于加深自己对java nio server的理解。\n这里的java-nio-server的示意图如下所示。\n这里的server实现中主要包括两个线程：\n 线程Accepter Thread用来从ServerSocketChannel中建立连接获取SocketChannel； 线程Processor Thread负责从SocketChannel中读取请求并处理，然后将处理结果输出到SocketChannel完成响应过程。Processor Thread线程是在一个循环中执行3条流水线（前面我们提到过有3条流水线），完成请求读取构建请求Message，并对请求Message进行处理得到响应Message，最后将响应Message返回给请求方；  12 NIO DatagramChannel # DatagramChannel是对Udp网络套接字的一种抽象。因为UDP是无连接协议，不能像读写SocketChannel一样来操作DatagramChannel，在SocketChannel中我们读取的是请求消息的面向数据块的数据，而在DatagramChannel中我们读取的是用户数据报。说的更准确一点是tcp、udp之间的差异。\n12.1 打开一个DatagramChannel # 下面是如何打开一个DatagramChannel的示例代码。\nDatagramChannel channel = DatagramChannel.open(); channel.socket().bind(new InetSocketAddress(9999));  示例中我们创建了一个监听本地9999/udp端口的DatagramChannel。\n12.2 接收数据 # 下面是如何从一个DatagramChannel接收数据的示例代码。\nByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); channel.receive(buf);  DatagramChannel.receive()方法将接收到的用户数据报写入指定的buffer。如果接收到的用户数据报比较大，并且已经超过了接收缓存buffer的大小，那么这里的receive方法会直接丢弃超出的部分，这样buffer中的数据实际上就是不完整的了。\n12.3 发送数据 # 下面是如何向一个DatagramChannel发送数据的示例代码。\nString newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); buf.flip(); int bytesSent = channel.send(buf, new InetSocketAddress(\u0026quot;jenkov.com\u0026quot;, 80));  示例代码中将向站点“jenkov.com”的80/udp端口发送一个字符串，由于目的主机上不存在监听这个端口的服务，所以什么也不会发生。示例代码在发送数据之后也不会收到任何关于用户数据报发送是否成功的通知，因为UDP本身就是不可靠数据传输协议。\n12.4 连接到特定地址 # 我们使用DatagramChannel的时候也可以将本地的socket连接到远程某个主机监听的udp socket上。因为UDP是无连接协议，所以这里的connect操作并不会创建一个类似于TCP中的连接，这里的connect操作只是将DatagramChannel的对端地址设置为待connect到的地址，之后这个DatagramChannel就只能接收这个对端peer发送来的用户数据报，而不能接收其它地址发送过来的用户数据报。\n 备注：\nLinux C编程时也会碰到类似的问题，“udp socket connect作用”甚至被设置成面试题目。\n关于unconnected、connected udp socket之间的差异性，我特地在网上搜索了一篇文章，这篇文章比较详细地介绍了二者之间的差异性以及各自不同的适用场景，例如dns客户端需要connected udp socket的场景（dns客户端只有一个域名解析主机地址），或者server端需要connect的场景（TFTP），或者二者都需要connect的场景。当然也存在不能使用connected udp socket的情景，这里就不展开说了。\n详细内容可以参考这里的总结，链接地址为unconnected/connected-udp-socket diff。\n 好了，下面看一下连接到特定主机地址、端口的示例代码。\nchannel.connect(new InetSocketAddress(\u0026quot;jenkov.com\u0026quot;, 80));  一旦udp socket connect成功之后就可以通过read、write方法来进行数据的读取和写入操作了，此时read、write操作就跟以前在其他channel三的read、write操作很相似了。DatagramChannel不需要保证数据的传输。下面是数据读写的示例代码。\nint bytesRead = channel.read(buf); int bytesWritten = channel.write(buf);  13 NIO Pipe # Java NIO Pipe是一种两个线程之间的单向数据传输的通道，它包括一个source channel和一个sink channel。读取数据时需要从source channel中读取，写入数据时需要向sink channel中写入。\n下图是一个Pipe的工作示意图。\n13.1 创建一个Pipe # 可以通过Pipe.open()方法来打开一个Pipe，也就是创建了一个Pipe。\nPipe pipe = Pipe.open();  13.2 向Pipe中写入数据 # 写数据到Pipe时，需要将数据写入到Pipe的sink channel。\n// 获取Pipe中的sink channel端 Pipe.SinkChannel sinkChannel = pipe.sink(); // 写数据到sink channel String newData = \u0026quot;New String to write to file...\u0026quot; + System.currentTimeMillis(); ByteBuffer buf = ByteBuffer.allocate(48); buf.clear(); buf.put(newData.getBytes()); buf.flip(); while(buf.hasRemaining()) { sinkChannel.write(buf); }  13.3 从Pipe中读取数据 # 从Pipe读取数据时，需要从Pipe的source channel中进行读取。\n// 获取Pipe中的source channel端 Pipe.SourceChannel sourceChannel = pipe.source(); // 从source channel读取数据 ByteBuffer buf = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buf);  14 NIO vs IO # 学习Java NIO和IO相关API时，先要搞明白什么时候应该选择Java NIO什么时候选择Java IO。这里讲描述一下Java NIO和IO的区别、适用场景，以及它们对软件设计、编码带来的影响。\n14.1 NIO和IO之间的主要区别 # 下表中对NIO和IO之间的主要区别进行了总结，本节会详细描述每一个区别。\n   IO NIO     面向流（stream） 面向数据块（buffer）   阻塞IO 非阻塞IO + selector    14.1 Stream Oriented vs Buffer Oriented # NIO和NIO第一个较大不同就是IO是面向流（stream）的，而NIO是面向数据块（buffer）的。什么意思呢？\n面向流的IO，从流中一次只可以读取一个字节，如何对读取到的字节进行处理是由程序决定，这些读取到的字节不会被cache到某个地方。这意味着不能在流中前后移动，如果需要在流中实现前后移动的目的的话，需要将流中的数据先cache起来。\n面向数据块的NIO与IO有些不同。数据首先被读取到数据块buffer中，然后我们对buffer中的数据进行处理。因为数据已经被cache到buffer中了，我们可以达到前后移动读位置的目的，此外也给我们数据处理时更好的灵活性。当然了，这种方式还是要求我们数据处理前检查是否一个完整的Message到达了或者被全部写出了。\n14.2 阻塞IO和非阻塞IO # Java IO的流操作是阻塞的，当一个线程执行read、write操作时，线程会被阻塞，知道read、write操作完成才会被唤醒，在唤醒之前线程无法执行其他任何处理。\nJava NIO的非阻塞模式使得一个线程执行io处理的时候不会阻塞当前线程到io完成，如果io操作没有完成也会立即返回，例如read操作时没有数据可读就返回读取了0个数据，线程可以执行其他处理然后过段事件之后再继续执行io任务。io相关的api不阻塞线程意味着线程可以在某个channel未就绪时去处理其他channel上的io任务，可以提高并发访问性能。\n14.3 Selectors # Java NIO中的选择器selector允许一个线程对多个channel上的io事件就绪状态进行监视，例如监视channel上有数据可读、channel上可以写入数据等等。\n14.3 选择NIO或IO对程序设计的影响 # 不管是选择NIO还是选择IO都会影响到程序设计，主要包括3点：\n 使用NIO或者IO的相关API； 数据出来； 处理数据的线程数量；  14.3.1 API Calls # NIO、IO二者对应的API是不同的，NIO多是结合buffer、channel、selector进行操作的，而IO多是基于stream进行操作的。\n14.3.2 数据处理 # 选择NIO和IO，对数据处理的方式也会造成较大影响。\n以读取数据为例，当选择IO API时我们一般是从InputStream中或者一个Reader中读取数据。假如有现在这样一个文件：\nName: Anna Age: 25 Email: anna@mailserver.com Phone: 1234567890  我们一般会像下面这样来处理上述文件内容：\nInputStream input = ... ; // get the InputStream from the client socket BufferedReader reader = new BufferedReader(new InputStreamReader(input)); String nameLine = reader.readLine(); String ageLine = reader.readLine(); String emailLine = reader.readLine(); String phoneLine = reader.readLine();  通过看程序执行到了哪行代码我们就可以判断当前文件处理的进度。例如，当第一个reader.readLine()方法执行结束后，就意味着程序一定是完整地读取完了“Name: Anne”这行，并且这个调用会在完整读取这行数据之后才会返回，这就是我们可以根据程序执行的位置来推测文件处理进度的根本原因。对后面各行数据的处理方式也是一样的。处理逻辑参考下图。\n一个采用了NIO的程序，其数据处理方式存在一些不同。下面是一个简化版的示例。\nByteBuffer buffer = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buffer);  上面第二行代码是从inChannel中读取数据到buffer，但是当这个inChannel返回时你并不知道这个buffer中到底被写入了多少数据，这使得数据处理变得困难。\n设想一下，假如inChannel.read(buffer)返回时buffer中只被写入了半行的数据，例如只写入了“Name: An”，还有几个字符没有写入，那么这种情况下我们是否要处理这种不完整的数据呢？当然不处理了，我们需要等到至少这一行数据完整到达之后才应该对其进行处理，不然解析一个不完整的、无效的数据也没什么用处。\n那么我们如何知道buffer中恰好包括了完整的一行数据呢？无法得知。我们只能通过重复地检查来发现buffer中是否包括了至少一行完整的数据（可能是半行、一行、不到两行……）。这使得数据处理逻辑变得有些复杂。下面是一个简单的示例。\nByteBuffer buffer = ByteBuffer.allocate(48); int bytesRead = inChannel.read(buffer); // 简化版，认为buffer满为数据处理可以开始的标识 while(! bufferFull(bytesRead) ) { bytesRead = inChannel.read(buffer); } // 处理数据 processData(buffer);  上述简化版示例代码中判断是否满的while(\u0026hellip;)执行逻辑示意图如下所示。\n14.3.3 总结 # NIO使得我们可以借助selector对很多的channel（网络连接或者文件）进行管理，使用的线程数量也少，不足之处在于增加了数据处理的难度，至少比标准IO模式下的数据处理要复杂多了，主要是麻烦在read partial message、write partial message、buffer resize这几个点上。\n如果需要同时处理成千上万的连接，这些连接上只是发送很少量的数据，例如一个聊天服务器，这种情境下使用NIO来实现应该能获得更高的性能，因为连接上收发的数据量都比较小，基于NIO来实现的话可以尽量减少r处理ead partial message、write partial message的代价。这种情况下可以采用一个线程管理多个连接的设计思路，这个线程通过selector监视并处理多个连接上的io事件。如下图所示。\n但是假如服务中有不少连接上的流量比较大，比如可能是在传输文件，这种情况下可能使用Java IO来实现会更好一点，因为如果采用NIO的话，这里的大流量连接上的数据处理就会变得更加复杂，因为服务要不停地处理read partial message、write partial message的情况。这种情况下采用一个线程负责建立入连接请求，然后将建立的连接丢给线程池处理的思路比较靠谱。如下图所示。\n15 NIO Path # Java NIO 2中增加了一种新的接口，java.nio.file.Path，通过它可以来定义一个绝对路径或者相对路径，这里的路径指的是文件在文件系统中的路径信息。\n这部分内容，本人认为并不是特别重要，所以在此不详细展开，只给出简短的示例代码，感兴趣的话可以执行google。\n创建一个Path示例。\nimport java.nio.file.Path; import java.nio.file.Paths; public class PathExample { public static void main(String[] args) { Path path = Paths.get(\u0026quot;/home/jakobjenkov/myfile.txt\u0026quot;); } }  创建一个绝对路径示例。\nPath path = Paths.get(\u0026quot;/home/jakobjenkov/myfile.txt\u0026quot;);  创建一个相对路径示例。\nPath projects = Paths.get(\u0026quot;d:\\\\data\u0026quot;, \u0026quot;projects\u0026quot;); Path file = Paths.get(\u0026quot;d:\\\\data\u0026quot;, \u0026quot;projects\\\\a-project\\\\myfile.txt\u0026quot;);  normalize一个Path，指的是从路径中移除“.”、“..”这样的符号。\nString originalPath = \u0026quot;d:\\\\data\\\\projects\\\\a-project\\\\..\\\\another-project\u0026quot;; Path path1 = Paths.get(originalPath); System.out.println(\u0026quot;path1 = \u0026quot; + path1); Path path2 = path1.normalize(); System.out.println(\u0026quot;path2 = \u0026quot; + path2);  16 NIO Files # Java NIO中引入了一个java.nio.file.Files类，它提供了很多的用于文件操作的方法，这里讲对某些常用方法进行介绍，读者朋友如果发现有些想要的功能或者方法这里没有提到，建议查阅一下JavaDoc确认是否支持。\n这里的Files类一般是配合java.nio.file.Path来使用的，Path前面因介绍过了，这里不再展开。\n16.1 检查文件是否存在 # 通过Files.exist(Path path, new LinkOption[]{\u0026hellip;})来检查指定的path是否存在，path可以是文件在文件系统中的绝对路径或者相对路径，因此可以起到检查文件是否存在的目的。示例代码如下。\nPath path = Paths.get(\u0026quot;data/logging.properties\u0026quot;); boolean pathExists = Files.exists(path, new LinkOption[]{ LinkOption.NOFOLLOW_LINKS});  16.2 创建目录 # 创建目录可以通过Files.createDirectory(Path path)来完成，示例代码如下。\nPath path = Paths.get(\u0026quot;data/subdir\u0026quot;); try { Path newDir = Files.createDirectory(path); } catch(FileAlreadyExistsException e){ // the directory already exists. } catch (IOException e) { //something else went wrong e.printStackTrace(); }  16.3 文件拷贝 # 文件拷贝可以通过Files.copy(Path sourcePath, Path destPath)来完成，示例代码如下。\nPath sourcePath = Paths.get(\u0026quot;data/logging.properties\u0026quot;); Path destinationPath = Paths.get(\u0026quot;data/logging-copy.properties\u0026quot;); try { Files.copy(sourcePath, destinationPath); } catch(FileAlreadyExistsException e) { //destination file already exists } catch (IOException e) { //something else went wrong e.printStackTrace(); }  16.4 覆盖文件 # 通过文件拷贝操作，其实也可以起到覆盖文件的作用，示例代码如下。\n// logging.properties和logging-copy.properties均为已经存在的文件 Path sourcePath = Paths.get(\u0026quot;data/logging.properties\u0026quot;); Path destinationPath = Paths.get(\u0026quot;data/logging-copy.properties\u0026quot;); try { Files.copy(sourcePath, destinationPath, StandardCopyOption.REPLACE_EXISTING); } catch(FileAlreadyExistsException e) { //destination file already exists } catch (IOException e) { //something else went wrong e.printStackTrace(); }  16.5 文件移动 # 文件移动通过Files.move(Path sourcePath, Path destPath)来实现，示例代码如下。\nPath sourcePath = Paths.get(\u0026quot;data/logging-copy.properties\u0026quot;); Path destinationPath = Paths.get(\u0026quot;data/subdir/logging-moved.properties\u0026quot;); try { Files.move(sourcePath, destinationPath, StandardCopyOption.REPLACE_EXISTING); } catch (IOException e) { //moving file failed. e.printStackTrace(); }  16.6 文件删除 # 文件删除可以通过Files.delete(Path path)来实现，示例代码如下。\nPath path = Paths.get(\u0026quot;data/subdir/logging-moved.properties\u0026quot;); try { Files.delete(path); } catch (IOException e) { //deleting file failed e.printStackTrace(); }  16.7 递归遍历目录 # 递归遍历目录可以通过Files.walkFileTree(Path dirPath, FileVisitor vistor)来实现，示例代码如下。\n// FileVistor声明了遍历时的几个关键函数 public interface FileVisitor { public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException; public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException; public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException; public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException; } // 调用walkFileTree时需要传入一个实现了上述接口方法的实例对象，但是有时候没有 // 必要全部自己实现一遍，其实SimpleFileVisitor中已经实现了上述的全部接口，但是 // 在某种情况下可能需要自己实现一个FileVisitor。 // 递归遍历目录 Files.walkFileTree(path, new FileVisitor\u0026lt;Path\u0026gt;() { @Override public FileVisitResult preVisitDirectory(Path dir, BasicFileAttributes attrs) throws IOException { System.out.println(\u0026quot;pre visit dir:\u0026quot; + dir); return FileVisitResult.CONTINUE; } @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { System.out.println(\u0026quot;visit file: \u0026quot; + file); return FileVisitResult.CONTINUE; } @Override public FileVisitResult visitFileFailed(Path file, IOException exc) throws IOException { System.out.println(\u0026quot;visit file failed: \u0026quot; + file); return FileVisitResult.CONTINUE; } @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException { System.out.println(\u0026quot;post visit directory: \u0026quot; + dir); return FileVisitResult.CONTINUE; } });  上述代码不难看懂，这里对FileVisitResult中的枚举变量进行一下说明：\n CONTINUE，继续遍历； TERMINATE，停止遍历； SKIP_SIBLINGS，继续遍历，遍历的时候跳过当前文件的siblings（兄弟）； SKIP__SUBTREE，继续遍历，遍历的时候跳过当前文件的subtree（子树）；  16.8 文件搜索 # 结合Files.walkFileTree()和文件信息比较可以实现文件搜索，示例代码如下。\nPath rootPath = Paths.get(\u0026quot;data\u0026quot;); String fileToFind = File.separator + \u0026quot;README.txt\u0026quot;; try { Files.walkFileTree(rootPath, new SimpleFileVisitor\u0026lt;Path\u0026gt;() { @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { String fileString = file.toAbsolutePath().toString(); //System.out.println(\u0026quot;pathString = \u0026quot; + fileString); if(fileString.endsWith(fileToFind)){ System.out.println(\u0026quot;file found at path: \u0026quot; + file.toAbsolutePath()); return FileVisitResult.TERMINATE; } return FileVisitResult.CONTINUE; } }); } catch(IOException e){ e.printStackTrace(); }  16.9 递归删除目录下文件 # 结合walkFileTree()和delete可以实现递归删除目录下文件，示例代码如下。\nPath rootPath = Paths.get(\u0026quot;data/to-delete\u0026quot;); try { Files.walkFileTree(rootPath, new SimpleFileVisitor\u0026lt;Path\u0026gt;() { @Override public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) throws IOException { System.out.println(\u0026quot;delete file: \u0026quot; + file.toString()); Files.delete(file); return FileVisitResult.CONTINUE; } @Override public FileVisitResult postVisitDirectory(Path dir, IOException exc) throws IOException { Files.delete(dir); System.out.println(\u0026quot;delete dir: \u0026quot; + dir.toString()); return FileVisitResult.CONTINUE; } }); } catch(IOException e){ e.printStackTrace(); }  16.10 其他方法 # java.nio.file.Files中还包括了很多的非常有用的方法，这里无法一一列举出来，感兴趣的读者可以查看JavaDoc进行了解。\n17 NIO AsynchronousFileChannel # Java7中增加了AsynchronousFileChannel，使得我们可以异步地读写文件。\n17.1 创建一个AsynchronousFileChannel # 创建异步filechannel的示例代码如下。\nPath path = Paths.get(\u0026quot;data/test.xml\u0026quot;); AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ);  17.2 通过Future对象来异步读取数据 # 示例代码如下所示。\n// 创建一个异步filechannel AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.READ); ByteBuffer buffer = ByteBuffer.allocate(1024); long position = 0; // 首先通过异步filechannel获取一个Future对象备用 Future\u0026lt;Integer\u0026gt; operation = fileChannel.read(buffer, position); // 等数据读取完成(阻塞在这里的调用点，但是LWP进程不会阻塞) while(!operation.isDone()); buffer.flip(); byte[] data = new byte[buffer.limit()]; buffer.get(data); System.out.println(new String(data)); buffer.clear();  17.3 异步数据读完成后执行CompletionHandler # 示例代码如下所示。\nfileChannel.read(buffer, position, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { // 数据读取完成后会执行这个回调函数 @Override public void completed(Integer result, ByteBuffer attachment) { System.out.println(\u0026quot;result = \u0026quot; + result); attachment.flip(); byte[] data = new byte[attachment.limit()]; attachment.get(data); System.out.println(new String(data)); attachment.clear(); } @Override public void failed(Throwable exc, ByteBuffer attachment) { } });  17.4 通过Future对象来异步写入数据 # 示例代码如下所示。\nPath path = Paths.get(\u0026quot;data/test-write.txt\u0026quot;); // 创建异步filechannel AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.WRITE); ByteBuffer buffer = ByteBuffer.allocate(1024); long position = 0; buffer.put(\u0026quot;test data\u0026quot;.getBytes()); buffer.flip(); // 获得Future对象备用 Future\u0026lt;Integer\u0026gt; operation = fileChannel.write(buffer, position); buffer.clear(); // 阻塞在调用点而非阻塞线程（或LWP进程） while(!operation.isDone()); System.out.println(\u0026quot;Write done\u0026quot;);  17.5 异步写入数据完成后执行CompletionHandler # 示例代码如下所示。\nPath path = Paths.get(\u0026quot;data/test-write.txt\u0026quot;); if(!Files.exists(path)){ Files.createFile(path); } // 创建一个异步filechannel AsynchronousFileChannel fileChannel = AsynchronousFileChannel.open(path, StandardOpenOption.WRITE); ByteBuffer buffer = ByteBuffer.allocate(1024); long position = 0; buffer.put(\u0026quot;test data\u0026quot;.getBytes()); buffer.flip(); fileChannel.write(buffer, position, buffer, new CompletionHandler\u0026lt;Integer, ByteBuffer\u0026gt;() { // 数据写入完成后执行这里的回调函数 @Override public void completed(Integer result, ByteBuffer attachment) { System.out.println(\u0026quot;bytes written: \u0026quot; + result); } // 数据写入失败后执行这里的回调函数 @Override public void failed(Throwable exc, ByteBuffer attachment) { System.out.println(\u0026quot;Write failed\u0026quot;); exc.printStackTrace(); } });  参考内容 # 1 http://tutorials.jenkov.com/java-nio/index.html\n2 https://github.com/jjenkov/java-nio-server\n"}),a.add({id:501,href:"/tags/nio/",title:"nio",description:"",content:""}),a.add({id:502,href:"/tags/ant/",title:"ant",description:"",content:""}),a.add({id:503,href:"/blog/2017-04-01-%E5%AD%A6%E4%B9%A0apache-ant/",title:"学习Apache Ant",description:"Apache Ant是Java工程中比较常用的一个依赖管理、构建工具，本文总结了Ant相关的一些基础知识。",content:"Apache Ant是由Apache开发的基于Java的构建工具，本文对tutorialspoint上面的Apache Ant教程进行简要总结。\n1 为什么需要这样一个构建工具？ # Ant是Another Neat Tool的缩写形式，为什么需要这样一个工具呢？跟它的名字一样，就是希望我们开发人员的工作能够更加neat！\n开发人员有些琐碎的、重复性的工作，包括：编译代码、打包可执行程序、部署程序到测试服务器、测试改变、拷贝代码到不同的地方。Ant可以帮助我们自动化上面列举的这几个步骤，简化我们的工作。\nAnt是tomcat的作者开发出来的，最初适用于构建tomcat的，并且作为tomcat的一部分，之所以开发它是为了弥补当初Apache Make工具（没有在apache项目列表中搜索到该项目）的不足之处，2000年的时候Ant从tomcat项目中独立出来作为一个独立的项目开发。\n至于Apache Ant的优势具体在哪，这个我们最后在给出来，目的是让大家结合自身工作经历，根据Apache Ant的功能自己主动去发现它的优势。\n2 Ant build.xml # Ant的构建脚本默认是build.xml，也可以用其他的文件名。build.xml里面通常包括tag ，这里name指定了工程的名字，default是默认名字，basedir指定了工程的根目录。另外还包括多个tag ，其中name指定了目标动作的名字，例如compile、package、clean等等，它们之间存在某种依赖关系，可以通过depends指定。例如package依赖clean、compile，就可以指定depends=\u0026ldquo;clean,package\u0026rdquo;，注意依赖先后顺序，不要写成depends=\u0026ldquo;package,clean\u0026rdquo;。\n示例1：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;Hello World Project\u0026quot; default=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;target name=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;echo\u0026gt;Hello World - Welcome to Apache Ant!\u0026lt;/echo\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  示例2：\n\u0026lt;target name=\u0026quot;deploy\u0026quot; depends=\u0026quot;package\u0026quot;\u0026gt; .... \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;package\u0026quot; depends=\u0026quot;clean,compile\u0026quot;\u0026gt; .... \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;clean\u0026quot; \u0026gt; .... \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;compile\u0026quot; \u0026gt; .... \u0026lt;/target\u0026gt;  build.xml里面可以使用ant预先定义的一些变量，例如：\n   property desc     ant.file The full location of the build file.   ant.version The version of the Apache Ant installation.   basedir The basedir of the build, as specified in the basedir attribute of the project element.   ant.java.version The version of the JDK that is used by Ant.   ant.project.name The name of the project, as specified in the name atrribute of the project element.   ant.project.default-target The default target of the current project.   ant.project.invoked-targets Comma separated list of the targets that were invoked in the current project.   ant.core.lib The full location of the Ant jar file.   ant.home The home directory of Ant installation.   ant.library.dir The home directory for Ant library files - typically ANT_HOME/lib folder.    示例1：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;Hello World Project\u0026quot; default=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;sitename\u0026quot; value=\u0026quot;www.tutorialspoint.com\u0026quot;/\u0026gt; \u0026lt;target name=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;echo\u0026gt;Apache Ant version is ${ant.version} - You are at ${sitename} \u0026lt;/echo\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  这样ant构建过程中会输出当前ant使用的版本以及站点名称，其中ant.version是ant的预定义变量，sitename是我们自己定义的变量。\n3 Ant build.properties # 像上线这样在build.xml里面创建自定义变量的方式，如果自定义变量少的话还可以，当面对一个大型的工程有很多自定义变量的时候，直接在build.xml里面定义变量就困难了，那怎么办呢？ 我们可以在一个单独的属性配置文件中对需要用到的自定义属性进行配置，然后在build.xml里面进行引用。这个默认的属性配置文件是build.properties。\n示例1：\nbuild.xml：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;Hello World Project\u0026quot; default=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;property file=\u0026quot;build.properties\u0026quot;/\u0026gt; \u0026lt;target name=\u0026quot;info\u0026quot;\u0026gt; \u0026lt;echo\u0026gt;Apache Ant version is ${ant.version} - You are at ${sitename} \u0026lt;/echo\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  这个文件里面引用了一个自定义变量，我们将其定义在build.properties里面。\nbuild.properties：\n# The Site Name sitename=www.tutorialspoint.com buildversion=3.3.2  4 Ant Data Types # 不要将这里的数据类型跟编程语言中的数据类型混为一谈，这里说要描述的Ant提供的数据类型代表了Ant提供的一种service。\nfileset类型代表了一系列文件集合，通过它可以包括某些文件或者排除某些文件，包括、排除文件是通过模式匹配的方式来实现。\n示例1：\n\u0026lt;fileset dir=\u0026quot;${src}\u0026quot; casesensitive=\u0026quot;yes\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.java\u0026quot;/\u0026gt; \u0026lt;exclude name=\u0026quot;**/*Stub*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt;  这个例子中创建了一个fileset，它指向了源代码目录${src}，这里匹配文件模式的时候大小写敏感，并且包括src目录下以及任意子目录下的java文件，并排除Stub文件。\npatternset类型代表了一些列的pattern集合，通过它可以指定一些include用的pattern或者exclude用的pattern。这里我们队实例1进行一下改造，即示例2。\n示例2：\n\u0026lt;patternset id=\u0026quot;java.files.without.stubs\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;src/**/*.java\u0026quot;/\u0026gt; \u0026lt;exclude name=\u0026quot;src/**/*Stub*\u0026quot;/\u0026gt; \u0026lt;/patternset\u0026gt; \u0026lt;fileset dir=\u0026quot;${src}\u0026quot; casesensitive=\u0026quot;yes\u0026quot;\u0026gt; \u0026lt;patternset refid=\u0026quot;java.files.without.stubs\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt;  通过patternset来指定pattern模式的方式有个好处，一个是更加直观，还有一个就是便于被复用。另外这里的pattern中可以使用的匹配符号包括：\n   character desc     ? 可以匹配任意当个字符   * 可以匹配0个或者多个字符   ** 可以匹配当前目录或者任意多级子目录（递归地哦）    filelist类型与fileset有点类似但是又有不同。相同点是都是用于指定一个文件集合，不同点是fileset是通过pattern匹配的方式来完成包括、排除，而filelist是必须通过指定具体的文件名字，不能使用pattern进行匹配。\n示例3：\n\u0026lt;filelist id=\u0026quot;config.files\u0026quot; dir=\u0026quot;${webapp.src.folder}\u0026quot;\u0026gt; \u0026lt;file name=\u0026quot;applicationConfig.xml\u0026quot;/\u0026gt; \u0026lt;file name=\u0026quot;faces-config.xml\u0026quot;/\u0026gt; \u0026lt;file name=\u0026quot;web.xml\u0026quot;/\u0026gt; \u0026lt;file name=\u0026quot;portlet.xml\u0026quot;/\u0026gt; \u0026lt;/filelist\u0026gt;  上面这里定义了一个文件列表，包括了所指定的这些文件。\nfilterset类型往往用于筛选满足指定条件的文件，例如在copy任务中与fileset相结合拷贝指定版本的文件，看下这里的示例吧。\n示例1：\n\u0026lt;copy todir=\u0026quot;${output.dir}\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${releasenotes.dir}\u0026quot; includes=\u0026quot;**/*.txt\u0026quot;/\u0026gt; \u0026lt;filterset\u0026gt; \u0026lt;filter token=\u0026quot;VERSION\u0026quot; value=\u0026quot;${current.version}\u0026quot;/\u0026gt; \u0026lt;/filterset\u0026gt; \u0026lt;/copy\u0026gt;  上面这个动作是要fileset中指定的发行笔记文件拷贝到输出目录${output.dir}中，但是呢，这里拷贝的时候只拷贝特定版本的发行笔记，只有与filter中匹配的版本才会被拷贝。\npath数据类型用于指定classpath，它有个好处就是可以对多个可能的classpath entries通过具体的系统指定的分隔符进行连接，例如在windows下面通过分号进行连接，但是在linux下面通过冒号进行连接。\n示例1：\n\u0026lt;path id=\u0026quot;build.classpath.jar\u0026quot;\u0026gt; \u0026lt;pathelement path=\u0026quot;${env.J2EE_HOME}/${j2ee.jar}\u0026quot;/\u0026gt; \u0026lt;fileset dir=\u0026quot;lib\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/path\u0026gt;  上面这个示例就是将${J2EE_HOME}/${j2ee.jar}中的所有*.jar都看做是一个classpath entry，然后用系统对应的classpath分隔符进行连接，最终构成一个完整的classpath。\n5 Ant的一个简单构建示例 # 下面看一个Ant构建的完整示例，首先要创建一个工程，工程结构如下：\n+---db // 数据库脚本目录 +---src // 源代码目录 . +---faxapp . +---dao . +---entity . +---util . +---web +---war // 资源目录 +---images // - 图片 +---js // - js +---META-INF // - 其他 +---styles // - css文件 +---WEB-INF +---classes // - 编译输出classes文件 +---jsp // - 编写的jsp文件 +---lib // - 应用的jar包  对应的build.xml文件如下：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;fax\u0026quot; basedir=\u0026quot;.\u0026quot; default=\u0026quot;build\u0026quot;\u0026gt; \u0026lt;property name=\u0026quot;src.dir\u0026quot; value=\u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;web.dir\u0026quot; value=\u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;build.dir\u0026quot; value=\u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;name\u0026quot; value=\u0026quot;fax\u0026quot;/\u0026gt; \u0026lt;path id=\u0026quot;master-classpath\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}/WEB-INF/lib\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;pathelement path=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;target name=\u0026quot;build\u0026quot; description=\u0026quot;Compile source tree java files\u0026quot;\u0026gt; \u0026lt;mkdir dir=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;javac destdir=\u0026quot;${build.dir}\u0026quot; source=\u0026quot;1.5\u0026quot; target=\u0026quot;1.5\u0026quot;\u0026gt; \u0026lt;src path=\u0026quot;${src.dir}\u0026quot;/\u0026gt; \u0026lt;classpath refid=\u0026quot;master-classpath\u0026quot;/\u0026gt; \u0026lt;/javac\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;clean\u0026quot; description=\u0026quot;Clean output directories\u0026quot;\u0026gt; \u0026lt;delete\u0026gt; \u0026lt;fileset dir=\u0026quot;${build.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.class\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/delete\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  对于上面build.xml中用到的自定义属性，还需要创建对应的属性文件build.properties：\n\u0026lt;property name=\u0026quot;src.dir\u0026quot; value=\u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;web.dir\u0026quot; value=\u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;build.dir\u0026quot; value=\u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt;  6 Ant构建文档 # Ant可以为工程生成文档，这个是利用javadoc命令行工具来对某些包某些类某些访问类型修饰符对应的成员或者方法根据源代码中添加的javadoc注释来生成项目API文档。下面是一个示例。\n示例1：\n\u0026lt;target name = \u0026quot;generate-javadoc\u0026quot;\u0026gt; \u0026lt;javadoc packagenames=\u0026quot;faxapp.*\u0026quot; sourcepath=\u0026quot;${src.dir}\u0026quot; destdir = \u0026quot;doc\u0026quot; version = \u0026quot;true\u0026quot; windowtitle = \u0026quot;Fax Application\u0026quot;\u0026gt; \u0026lt;doctitle\u0026gt;\u0026lt;![CDATA[= Fax Application =]]\u0026gt;\u0026lt;/doctitle\u0026gt; \u0026lt;bottom\u0026gt; \u0026lt;![CDATA[Copyright © 2011. All Rights Reserved.]]\u0026gt; \u0026lt;/bottom\u0026gt; \u0026lt;group title = \u0026quot;util packages\u0026quot; packages = \u0026quot;faxapp.util.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;web packages\u0026quot; packages = \u0026quot;faxapp.web.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;data packages\u0026quot; packages = \u0026quot;faxapp.entity.*:faxapp.dao.*\u0026quot;/\u0026gt; \u0026lt;/javadoc\u0026gt; \u0026lt;echo message = \u0026quot;java doc has been generated!\u0026quot; /\u0026gt; \u0026lt;/target\u0026gt;  7 Ant构建jar包 # Ant将classes达成jar包示例，例如将faxapp/util下面的除Test.class之外的所有文件达成一个jar包${web.dir}/lib/util.jar。\n示例1：\n\u0026lt;jar destfile = \u0026quot;${web.dir}/lib/util.jar\u0026quot; basedir = \u0026quot;${build.dir}/classes\u0026quot; includes = \u0026quot;faxapp/util/**\u0026quot; excludes = \u0026quot;**/Test.class\u0026quot; /\u0026gt;  如果是希望将util.jar打包成一个可以执行的jar文件的话，需要为其指定main-class，这里可以通过添加manifest来完成。\n示例2：\n\u0026lt;jar destfile = \u0026quot;${web.dir}/lib/util.jar\u0026quot; basedir = \u0026quot;${build.dir}/classes\u0026quot; includes = \u0026quot;faxapp/util/**\u0026quot; excludes = \u0026quot;**/Test.class\u0026quot;\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;attribute name = \u0026quot;Main-Class\u0026quot; value = \u0026quot;com.tutorialspoint.util.FaxUtil\u0026quot;/\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/jar\u0026gt;  最后呢，将上述jar翻到一个target里面：\n\u0026lt;target name=\u0026quot;build-jar\u0026quot;\u0026gt; \u0026lt;jar destfile=\u0026quot;${web.dir}/lib/util.jar\u0026quot; basedir=\u0026quot;${build.dir}/classes\u0026quot; includes=\u0026quot;faxapp/util/**\u0026quot; excludes=\u0026quot;**/Test.class\u0026quot;\u0026gt; \u0026lt;manifest\u0026gt; \u0026lt;attribute name=\u0026quot;Main-Class\u0026quot; value=\u0026quot;com.tutorialspoint.util.FaxUtil\u0026quot;/\u0026gt; \u0026lt;/manifest\u0026gt; \u0026lt;/jar\u0026gt; \u0026lt;/target\u0026gt;  8 Ant构建war包 # 除了上面提到的构建jar包之外，Ant也可以用来构建war包，我们这里只给出一个详细的war包构建配置文件，不再详细展开。\n示例1：\n\u0026lt;target name=\u0026quot;build-war\u0026quot;\u0026gt; \u0026lt;war destfile=\u0026quot;fax.war\u0026quot; webxml=\u0026quot;${web.dir}/web.xml\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}/WebContent\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;lib dir=\u0026quot;thirdpartyjars\u0026quot;\u0026gt; \u0026lt;exclude name=\u0026quot;portlet.jar\u0026quot;/\u0026gt; \u0026lt;/lib\u0026gt; \u0026lt;classes dir=\u0026quot;${build.dir}/web\u0026quot;/\u0026gt; \u0026lt;/war\u0026gt; \u0026lt;/target\u0026gt;  9 Ant的一个完整build.xml配置 # 这里给出了一个综合配置示例，对前面说描述的内容进行了一下综合。\n\u0026lt;?xml version = \u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name = \u0026quot;fax\u0026quot; basedir = \u0026quot;.\u0026quot; default = \u0026quot;usage\u0026quot;\u0026gt; \u0026lt;property file = \u0026quot;build.properties\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;src.dir\u0026quot; value = \u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;web.dir\u0026quot; value = \u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;javadoc.dir\u0026quot; value = \u0026quot;doc\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;build.dir\u0026quot; value = \u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt; \u0026lt;property name = \u0026quot;name\u0026quot; value = \u0026quot;fax\u0026quot;/\u0026gt; \u0026lt;path id = \u0026quot;master-classpath\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;${web.dir}/WEB-INF/lib\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;pathelement path = \u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;target name = \u0026quot;javadoc\u0026quot;\u0026gt; \u0026lt;javadoc packagenames = \u0026quot;faxapp.*\u0026quot; sourcepath = \u0026quot;${src.dir}\u0026quot; destdir = \u0026quot;doc\u0026quot; version = \u0026quot;true\u0026quot; windowtitle = \u0026quot;Fax Application\u0026quot;\u0026gt; \u0026lt;doctitle\u0026gt;\u0026lt;![CDATA[\u0026lt;h1\u0026gt; = Fax Application = \u0026lt;/h1\u0026gt;]]\u0026gt; \u0026lt;/doctitle\u0026gt; \u0026lt;bottom\u0026gt;\u0026lt;![CDATA[Copyright © 2011. All Rights Reserved.]]\u0026gt; \u0026lt;/bottom\u0026gt; \u0026lt;group title = \u0026quot;util packages\u0026quot; packages = \u0026quot;faxapp.util.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;web packages\u0026quot; packages = \u0026quot;faxapp.web.*\u0026quot;/\u0026gt; \u0026lt;group title = \u0026quot;data packages\u0026quot; packages = \u0026quot;faxapp.entity.*:faxapp.dao.*\u0026quot;/\u0026gt; \u0026lt;/javadoc\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;usage\u0026quot;\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;${name} build file\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;-----------------------------------\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;Available targets are:\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;deploy --\u0026gt; Deploy application as directory\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;deploywar --\u0026gt; Deploy application as a WAR file\u0026quot;/\u0026gt; \u0026lt;echo message = \u0026quot;\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;build\u0026quot; description = \u0026quot;Compile main source tree java files\u0026quot;\u0026gt; \u0026lt;mkdir dir = \u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;javac destdir = \u0026quot;${build.dir}\u0026quot; source = \u0026quot;1.5\u0026quot; target = \u0026quot;1.5\u0026quot; debug = \u0026quot;true\u0026quot; deprecation = \u0026quot;false\u0026quot; optimize = \u0026quot;false\u0026quot; failonerror = \u0026quot;true\u0026quot;\u0026gt; \u0026lt;src path = \u0026quot;${src.dir}\u0026quot;/\u0026gt; \u0026lt;classpath refid = \u0026quot;master-classpath\u0026quot;/\u0026gt; \u0026lt;/javac\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;deploy\u0026quot; depends = \u0026quot;build\u0026quot; description = \u0026quot;Deploy application\u0026quot;\u0026gt; \u0026lt;copy todir = \u0026quot;${deploy.path}/${name}\u0026quot; preservelastmodified = \u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;deploywar\u0026quot; depends = \u0026quot;build\u0026quot; description = \u0026quot;Deploy application as a WAR file\u0026quot;\u0026gt; \u0026lt;war destfile = \u0026quot;${name}.war\u0026quot; webxml = \u0026quot;${web.dir}/WEB-INF/web.xml\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/war\u0026gt; \u0026lt;copy todir = \u0026quot;${deploy.path}\u0026quot; preservelastmodified = \u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir = \u0026quot;.\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;*.war\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name = \u0026quot;clean\u0026quot; description = \u0026quot;Clean output directories\u0026quot;\u0026gt; \u0026lt;delete\u0026gt; \u0026lt;fileset dir = \u0026quot;${build.dir}\u0026quot;\u0026gt; \u0026lt;include name = \u0026quot;**/*.class\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/delete\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  10 Ant的一个更完整配置示例 # 这里针对war包与tomcat的结合给出一个配置示例。\nbuild.properties：\n# Ant properties for building the springapp appserver.home=c:\\\\install\\\\apache-tomcat-7.0.19 # for Tomcat 5 use $appserver.home}/server/lib # for Tomcat 6 use $appserver.home}/lib appserver.lib=${appserver.home}/lib deploy.path=${appserver.home}/webapps tomcat.manager.url=http://www.tutorialspoint.com:8080/manager tomcat.manager.username=tutorialspoint tomcat.manager.password=secret  build.xml:\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;fax\u0026quot; basedir=\u0026quot;.\u0026quot; default=\u0026quot;usage\u0026quot;\u0026gt; \u0026lt;property file=\u0026quot;build.properties\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;src.dir\u0026quot; value=\u0026quot;src\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;web.dir\u0026quot; value=\u0026quot;war\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;javadoc.dir\u0026quot; value=\u0026quot;doc\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;build.dir\u0026quot; value=\u0026quot;${web.dir}/WEB-INF/classes\u0026quot;/\u0026gt; \u0026lt;property name=\u0026quot;name\u0026quot; value=\u0026quot;fax\u0026quot;/\u0026gt; \u0026lt;path id=\u0026quot;master-classpath\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}/WEB-INF/lib\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;*.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;pathelement path=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;target name=\u0026quot;javadoc\u0026quot;\u0026gt; \u0026lt;javadoc packagenames=\u0026quot;faxapp.*\u0026quot; sourcepath=\u0026quot;${src.dir}\u0026quot; destdir=\u0026quot;doc\u0026quot; version=\u0026quot;true\u0026quot; windowtitle=\u0026quot;Fax Application\u0026quot;\u0026gt; \u0026lt;doctitle\u0026gt;\u0026lt;![CDATA[\u0026lt;h1\u0026gt;= Fax Application = \u0026lt;/h1\u0026gt;]]\u0026gt;\u0026lt;/doctitle\u0026gt; \u0026lt;bottom\u0026gt;\u0026lt;![CDATA[Copyright © 2011. All Rights Reserved.]]\u0026gt;\u0026lt;/bottom\u0026gt; \u0026lt;group title=\u0026quot;util packages\u0026quot; packages=\u0026quot;faxapp.util.*\u0026quot;/\u0026gt; \u0026lt;group title=\u0026quot;web packages\u0026quot; packages=\u0026quot;faxapp.web.*\u0026quot;/\u0026gt; \u0026lt;group title=\u0026quot;data packages\u0026quot; packages=\u0026quot;faxapp.entity.*:faxapp.dao.*\u0026quot;/\u0026gt; \u0026lt;/javadoc\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;usage\u0026quot;\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;${name} build file\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;-----------------------------------\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;Available targets are:\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;deploy --\u0026gt; Deploy application as directory\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;deploywar --\u0026gt; Deploy application as a WAR file\u0026quot;/\u0026gt; \u0026lt;echo message=\u0026quot;\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;build\u0026quot; description=\u0026quot;Compile main source tree java files\u0026quot;\u0026gt; \u0026lt;mkdir dir=\u0026quot;${build.dir}\u0026quot;/\u0026gt; \u0026lt;javac destdir=\u0026quot;${build.dir}\u0026quot; source=\u0026quot;1.5\u0026quot; target=\u0026quot;1.5\u0026quot; debug=\u0026quot;true\u0026quot; deprecation=\u0026quot;false\u0026quot; optimize=\u0026quot;false\u0026quot; failonerror=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;src path=\u0026quot;${src.dir}\u0026quot;/\u0026gt; \u0026lt;classpath refid=\u0026quot;master-classpath\u0026quot;/\u0026gt; \u0026lt;/javac\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;deploy\u0026quot; depends=\u0026quot;build\u0026quot; description=\u0026quot;Deploy application\u0026quot;\u0026gt; \u0026lt;copy todir=\u0026quot;${deploy.path}/${name}\u0026quot; preservelastmodified=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;deploywar\u0026quot; depends=\u0026quot;build\u0026quot; description=\u0026quot;Deploy application as a WAR file\u0026quot;\u0026gt; \u0026lt;war destfile=\u0026quot;${name}.war\u0026quot; webxml=\u0026quot;${web.dir}/WEB-INF/web.xml\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;${web.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.*\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/war\u0026gt; \u0026lt;copy todir=\u0026quot;${deploy.path}\u0026quot; preservelastmodified=\u0026quot;true\u0026quot;\u0026gt; \u0026lt;fileset dir=\u0026quot;.\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;*.war\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/copy\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;target name=\u0026quot;clean\u0026quot; description=\u0026quot;Clean output directories\u0026quot;\u0026gt; \u0026lt;delete\u0026gt; \u0026lt;fileset dir=\u0026quot;${build.dir}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;**/*.class\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/delete\u0026gt; \u0026lt;/target\u0026gt;  war包相关的定义已经全部给出了，这里还需要给出tomcat相关的部分定义，还是在build.xml里面。\n\u0026lt;!-- ============================================================ --\u0026gt; \u0026lt;!-- Tomcat tasks --\u0026gt; \u0026lt;!-- ============================================================ --\u0026gt; \u0026lt;path id=\u0026quot;catalina-ant-classpath\u0026quot;\u0026gt; \u0026lt;!-- We need the Catalina jars for Tomcat --\u0026gt; \u0026lt;!-- * for other app servers - check the docs --\u0026gt; \u0026lt;fileset dir=\u0026quot;${appserver.lib}\u0026quot;\u0026gt; \u0026lt;include name=\u0026quot;catalina-ant.jar\u0026quot;/\u0026gt; \u0026lt;/fileset\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;taskdef name=\u0026quot;install\u0026quot; classname=\u0026quot;org.apache.catalina.ant.InstallTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;reload\u0026quot; classname=\u0026quot;org.apache.catalina.ant.ReloadTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;list\u0026quot; classname=\u0026quot;org.apache.catalina.ant.ListTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;start\u0026quot; classname=\u0026quot;org.apache.catalina.ant.StartTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;taskdef name=\u0026quot;stop\u0026quot; classname=\u0026quot;org.apache.catalina.ant.StopTask\u0026quot;\u0026gt; \u0026lt;classpath refid=\u0026quot;catalina-ant-classpath\u0026quot;/\u0026gt; \u0026lt;/taskdef\u0026gt; \u0026lt;target name=\u0026quot;reload\u0026quot; description=\u0026quot;Reload application in Tomcat\u0026quot;\u0026gt; \u0026lt;reload url=\u0026quot;${tomcat.manager.url}\u0026quot;username=\u0026quot;${tomcat.manager.username}\u0026quot; password=\u0026quot;${tomcat.manager.password}\u0026quot; path=\u0026quot;/${name}\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  下面对tomcat相关的几个targe他进行一下描述：\n   task desc     InstallTask Installs a web application. Class Name: org.apache.catalina.ant.InstallTask   ReloadTask Reload a web application. Class Name: org.apache.catalina.ant.ReloadTask   ListTask Lists all web applications. Class Name: org.apache.catalina.ant.ListTask   StartTask Starts a web application. Class Name: org.apache.catalina.ant.StartTask   StopTask Stops a web application. Class Name: org.apache.catalina.ant.StopTask   ReloadTask Reloads a web application without stopping. Class Name: org.apache.catalina.ant.ReloadTask    11 Ant执行程序 # 下面给出一个Ant传递参数并执行程序的配置示例。\njava类：\npublic class NotifyAdministrator { public static void main(String[] args) { String email = args[0]; notifyAdministratorviaEmail(email); System.out.println(\u0026quot;Administrator \u0026quot;+email+\u0026quot; has been notified\u0026quot;); } public static void notifyAdministratorviaEmail(String email { //...... } }  build.xml配置文件如下：\n\u0026lt;?xml version=\u0026quot;1.0\u0026quot;?\u0026gt; \u0026lt;project name=\u0026quot;sample\u0026quot; basedir=\u0026quot;.\u0026quot; default=\u0026quot;notify\u0026quot;\u0026gt; \u0026lt;target name=\u0026quot;notify\u0026quot;\u0026gt; \u0026lt;java fork=\u0026quot;true\u0026quot; failonerror=\u0026quot;yes\u0026quot; classname=\u0026quot;NotifyAdministrator\u0026quot;\u0026gt; \u0026lt;arg line=\u0026quot;admin@test.com\u0026quot;/\u0026gt; \u0026lt;/java\u0026gt; \u0026lt;/target\u0026gt; \u0026lt;/project\u0026gt;  12 扩展Ant # Ant中有一些自定义的task，但是我们也可以自己定义task并在target中使用，下面是一个示例。\njava代码：\npackage com.tutorialspoint.ant; import org.apache.tools.ant.Task; import org.apache.tools.ant.Project; import org.apache.tools.ant.BuildException; public class MyTask extends Task { String message; public void execute() throws BuildException { log(\u0026quot;Message: \u0026quot; + message, Project.MSG_INFO); } public void setMessage(String message) { this.message= message; } }  build.xml：\n\u0026lt;target name=\u0026quot;custom\u0026quot;\u0026gt; \u0026lt;taskdef name=\u0026quot;custom\u0026quot; classname=\u0026quot;com.tutorialspoint.ant.MyTask\u0026quot; /\u0026gt; \u0026lt;custom message=\u0026quot;Hello World!\u0026quot;/\u0026gt; \u0026lt;/target\u0026gt;  13 在IDE中使用Ant # 在IDE中使用Ant也是一种不错的选择，目前的主流开发工具Eclipse和Idea都继承了Ant构建插件，开发人员可以根据自己的情况选择使用。\n参考内容：\n[1] TutorialsPoint: Learn Apache Ant\n"}),a.add({id:504,href:"/tags/context/",title:"context",description:"",content:""}),a.add({id:505,href:"/tags/jmp_buf/",title:"jmp_buf",description:"",content:""}),a.add({id:506,href:"/blog/2017-03-27-jmp_bufsetjmplongjmp/",title:"jmp_buf \u0026 setjmp \u0026 longjmp",description:"最近在看spp \u0026 libco源码，他们实现协程上下文切换的过程中，都或多或少借鉴了jmp_buf的设计，用以保存协程执行时的现场。协程切换的时候保存当前协程的现场，然后恢复待调度协程的现场。理解是很容易理解，但是总感觉还是有点浅尝辄止了，于是就抽点时间看了下jmp_buf、setjmp、longjmp相关的代码，大体理了下思路。",content:"最近在看spp \u0026amp; libco源码，他们实现协程上下文切换的过程中，都或多或少借鉴了jmp_buf的设计，用以保存协程执行时的现场。协程切换的时候保存当前协程的现场，然后恢复待调度协程的现场。理解是很容易理解，但是总感觉还是有点浅尝辄止了，于是就抽点时间看了下jmp_buf、setjmp、longjmp相关的代码，大体理了下思路。\n学习整理了一下关于jmp_buf \u0026amp; setjmp \u0026amp; longjmp的内容。\nlinux 4.0内核中jmp_buf这个结构体用于记录硬件上下文信息，可以用于函数内、函数外跳转，goto只能实现函数内跳转。先来看下这个结构体的定义吧，i386架构的处理器与x86_64架构的处理器，对应的jmp_buf结构体定义稍微有些不同，这个很容易理解，寄存器位宽、数量等都有些不同。\ni386架构：\n// 处理器架构：i386 // - Linux/arch/x86/um/shared/sysdep/archsetjmp_32.h struct __jmp_buf { unsigned int __ebx; // 通用数据寄存器之一 unsigned int __esp; // 栈指针寄存器(进程栈空间由高地址向低地址方向增长) unsigned int __ebp; // 基址指针寄存器(记录了当前栈帧的起始地址(进入一个函数后首先执行的便是push %ebp; mov %esp, %ebp)) unsigned int __esi; // 源变址寄存器 unsigned int __edi; // 目的编制寄存器 unsigned int __eip; // 指令指针寄存器(程序计数器PC=CS:IP,二者结合起来确定下一条待执行的机器指令地址) }; typedef struct __jmp_buf jmp_buf[1];  x86_64架构：\n// 处理器架构：x86_64 // - Linux/arch/x86/um/shared/sysdep/archsetjmp_64.h struct __jmp_buf { unsigned long __rbx; // 通用数据寄存器之一 unsigned long __rsp; // 栈指针寄存器 unsigned long __rbp; // 基址指针寄存器 unsigned long __r12; unsigned long __r13; unsigned long __r14; unsigned long __r15; unsigned long __rip; }; typedef struct __jmp_buf jmp_buf[1];  但是呢，glibc里面重新定义了这个类型，这里面还对信号掩码进行了考虑。\nstruct __jmp_buf_tag { /* NOTE: The machine-dependent definitions of `__sigsetjmp' assume that a `jmp_buf' begins with a `__jmp_buf' and that `__mask_was_saved' follows it. Do not move these members or add others before it. */ __jmp_buf __jmpbuf; /* Calling environment. */ int __mask_was_saved; /* Saved the signal mask? */ __sigset_t __saved_mask; /* Saved signal mask. */ }; typedef struct __jmp_buf_tag jmp_buf[1];  这个__jmp_buf_tag主要就是用于记录下当前的进程的硬件上下文信息、信号掩码信息，保存操作是通过setjmp来完成的，而在执行过程中caller1-\u0026gt;\u0026hellip; -\u0026gt;caller${i}-\u0026gt; \u0026hellip; -\u0026gt;callerN中如果希望跳转到在caller${i}中的某个位置时(该位置已经通过__jmp_buf_tag进行了保存)，通过调用longjmp来将指定__jmp_buf_tag变体中保存的硬件上下文信息还原到处理器的各个寄存器中，并将进程信号掩码信息也进行还原，之后机器会回到caller${i}中调用setjmp的下一行代码处开始执行。 glibc在此基础上针对c和c++分别实现了setjmp和longjmp，c下只保存硬件上下文信息，c++中除此之外还保存信号掩码信息，注意是有区别的。\nsetjmp：\n// __BEGIN_NAMESPACE_STD是一个宏，表示namespace std { __BEGIN_NAMESPACE_STD // STD这个命名空间内是既保存硬件上下文信息，也保存信号掩码 typedef struct __jmp_buf_tag jmp_buf[1]; extern int _setjmp(struct __jmp_buf_tag __env[1]) __THROWNL; #define setjmp(env) _setjmp(env) __END_NAMESPACE_STD // __END_NAMESPACE_STD是一个宏，表示} // c下这个保存硬件上下文信息，并且保存__savemask指定的信号掩码 extern int __sigsetjmp (struct __jmp_buf_tag __env[1], int __savemask) __THROWNL; // c下这个只保存硬件上下文信息 extern int _setjmp (struct __jmp_buf_tag __env[1]) __THROWNL; // c下setjmp只保存硬件上下文信息 #define setjmp(env) _setjmp (env)`  longjmp:\ntypedef struct __jmp_buf_tag sigjmp_buf[1]; void __libc_siglongjmp (sigjmp_buf env, int val) { /* Perform any cleanups needed by the frames being unwound. */ _longjmp_unwind (env, val); if (env[0].__mask_was_saved) /* Restore the saved signal mask. */ (void) __sigprocmask (SIG_SETMASK, \u0026amp;env[0].__saved_mask, (sigset_t *) NULL); /* Call the machine-dependent function to restore machine state. */ __longjmp (env[0].__jmpbuf, val ?: 1); } // 如果没有定义这个宏__libc_siglongjmp则执行下面这些别名创建操作 // 什么情况下会定义这个宏呢？先不管，不影响整体的理解！fixme!!! #ifndef __libc_siglongjmp strong_alias (__libc_siglongjmp, __libc_longjmp) libc_hidden_def (__libc_longjmp) weak_alias (__libc_siglongjmp, _longjmp) weak_alias (__libc_siglongjmp, longjmp) weak_alias (__libc_siglongjmp, siglongjmp) #endif  这里对上面几个特殊的宏进行一下说明(以weak_alias为例，其他几个类似的处理方式)：\n// weak_alias(a,b)就是创建一个与a的别名b /* Define ALIASNAME as a weak alias for NAME. If weak aliases are not available, this defines a strong alias.*/ #define weak_alias(name, aliasname) _weak_alias (name, aliasname) #define _weak_alias(name, aliasname) \\ extern __typeof (name) aliasname __attribute__ ((weak, alias (#name)));  现在整体流程已经大体清楚了，现在来看下setjmp以及longjmp的实现：\n setjmp就不需要说了吧，也就是通过gcc扩展的内联汇编取出需要的寄存器的值，甚至是取出当前进程的task_struct中的信号掩码信息，然后保存到jmp_buf中； longjmp就是将参数中指定的jmp_buf取出来并进行还原，还原处理器的硬件上下文信息，还原进程的信号掩码信息，这里我们来说一下;  下面看下几个关键的函数。\n  第一个函数，_longjmp_unwind，这个是在执行实际的jmp之前先对unwind操作所经过的现有栈帧执行一定的处理动作，不过我看默认的/gnu/glibc/setjmp/jmp-unwind.c中没有做任何处理，可能需要用户自己hook一下？为啥要处理这里的栈帧呢，可能有必要可能没必要，只要jmp回去了，从栈低地址回到了高地址之后，之前低地址的栈也就全部作废了，因为栈又要从当前位置开始向低地址增长，之前生成的低地址栈空间会被覆盖。\n  第二个函数，_sigprocmask，这个是执行还原jmp_buf中的信号掩码信息的。\n  static void __set_task_blocked(struct task_struct *tsk, const sigset_t *newset) { if (signal_pending(tsk) \u0026amp;\u0026amp; !thread_group_empty(tsk)) { sigset_t newblocked; /* A set of now blocked but previously unblocked signals. */ sigandnsets(\u0026amp;newblocked, newset, ¤t-\u0026gt;blocked); retarget_shared_pending(tsk, \u0026amp;newblocked); } tsk-\u0026gt;blocked = *newset; recalc_sigpending(); }  文件/gnu/glibc/sysdeps/unix/sysv/linux/x86_64/sigprocmask.c\n这个是glibc中定义的信号掩码处理函数，最终会通过系统调用进入内核来处理，因为毕竟要修改进程pcb中的某些状态字段，只有内核才具备此权限。\n/* Get and/or change the set of blocked signals. */ int __sigprocmask (int how, const sigset_t *set, sigset_t *oset) { /* XXX The size argument hopefully will have to be changed to the real size of the user-level sigset_t. */ return INLINE_SYSCALL (rt_sigprocmask, 4, how, set, oset, _NSIG / 8); } weak_alias (__sigprocmask, sigprocmask)  内核中的信号掩码处理函数，及根据操作类型来决定对进程信号掩码做何种处理，这里毫无疑问应该是set操作。\nint sigprocmask(int how, sigset_t *set, sigset_t *oldset) { struct task_struct *tsk = current; sigset_t newset; /* Lockless, only current can change -\u0026gt;blocked, never from irq */ if (oldset) *oldset = tsk-\u0026gt;blocked; switch (how) { case SIG_BLOCK: sigorsets(\u0026amp;newset, \u0026amp;tsk-\u0026gt;blocked, set); break; case SIG_UNBLOCK: sigandnsets(\u0026amp;newset, \u0026amp;tsk-\u0026gt;blocked, set); break; case SIG_SETMASK: newset = *set; break; default: return -EINVAL; } __set_current_blocked(\u0026amp;newset); return 0; }  获取当前进程的任务结构体，对其中的sighand加锁然后开始信号相关的设置操作，也就是屏蔽newset中指定的信号。\nvoid __set_current_blocked(const sigset_t *newset) { struct task_struct *tsk = current; spin_lock_irq(\u0026amp;tsk-\u0026gt;sighand-\u0026gt;siglock); __set_task_blocked(tsk, newset); spin_unlock_irq(\u0026amp;tsk-\u0026gt;sighand-\u0026gt;siglock); }  更新当前进程任务结构体task_struct中的信号掩码信息，至于更新的过程中做了何种处理，这里先暂时不做详细介绍了，感兴趣的话可以自己查看下源码。\n 第三个函数执行实际的jmp动作，也就是还原硬件上下文信息：  /* Jump to the position specified by ENV, causing the setjmp call there to return VAL, or 1 if VAL is 0. void __longjmp (__jmp_buf env, int val). */ .text ENTRY(__longjmp) /* Restore registers. */ mov (JB_RSP*8)(%rdi),%R8_LP mov (JB_RBP*8)(%rdi),%R9_LP mov (JB_PC*8)(%rdi),%RDX_LP #ifdef PTR_DEMANGLE PTR_DEMANGLE (%R8_LP) PTR_DEMANGLE (%R9_LP) PTR_DEMANGLE (%RDX_LP) #ifdef __ILP32__ /* We ignored the high bits of the %rbp value because only the low bits are mangled. But we cannot presume that %rbp is being used as a pointer and truncate it, so recover the high bits. */ movl (JB_RBP*8 + 4)(%rdi), %eax shlq 2, %rax orq %rax, %r9 # endif #endif LIBC_PROBE (longjmp, 3, LP_SIZE@%RDI_LP, -4@%esi, LP_SIZE@%RDX_LP) /* We add unwind information for the target here. */ cfi_def_cfa(%rdi, 0) cfi_register(%rsp,%r8) cfi_register(%rbp,%r9) cfi_register(%rip,%rdx) cfi_offset(%rbx,JB_RBX*8) cfi_offset(%r12,JB_R12*8) cfi_offset(%r13,JB_R13*8) cfi_offset(%r14,JB_R14*8) cfi_offset(%r15,JB_R15*8) movq (JB_RBX*8)(%rdi),%rbx movq (JB_R12*8)(%rdi),%r12 movq (JB_R13*8)(%rdi),%r13 movq (JB_R14*8)(%rdi),%r14 movq (JB_R15*8)(%rdi),%r15 /* Set return value for setjmp. */ mov %esi, %eax mov %R8_LP,%RSP_LP movq %r9,%rbp LIBC_PROBE (longjmp_target, 3, LP_SIZE@%RDI_LP, -4@%eax, LP_SIZE@%RDX_LP) jmpq *%rdx END (__longjmp)  上面的代码在文件/gnu/glibc/sysdeps/x86_64/__longjmp.S中，通过.text中的汇编代码来执行还原硬件上下文的操作，上面的代码中还用到了两个宏：\n/* Define an entry point visible from C. */ #define ENTRY(name) \\ .globl C_SYMBOL_NAME(name); \\ .type C_SYMBOL_NAME(name),@function; \\ .align ALIGNARG(4); \\ C_LABEL(name) \\ cfi_startproc; \\ CALL_MCOUNT #undef END #define END(name) \\ cfi_endproc; \\ ASM_SIZE_DIRECTIVE(name)  这两个宏就比较巧了，ENTRY其实直接定义了一个在c中具有可见性的函数name，在我们这个情境下就是__longjmp，然后就直接追加上前面还原硬件上下文的汇编代码作为函数体，最后通过END结束函数体。\n注意这里的代码__longjmp其实是个用户态中的函数，并非是内核来处理的。这样这个函数执行完成之后，下面就会自动回到setjmp语句的下一行语句处执行。\nsetjmp、longjmp的大致实现过程就介绍到这里，介可能有些地方描述不到位或者有错误，也请大家能给我指出来。\n"}),a.add({id:507,href:"/tags/longjmp/",title:"longjmp",description:"",content:""}),a.add({id:508,href:"/tags/setjmp/",title:"setjmp",description:"",content:""}),a.add({id:509,href:"/tags/desktop/",title:"desktop",description:"",content:""}),a.add({id:510,href:"/tags/grub/",title:"grub",description:"",content:""}),a.add({id:511,href:"/tags/plymouth/",title:"plymouth",description:"",content:""}),a.add({id:512,href:"/blog/2017-03-13-%E8%81%8A%E8%81%8A%E4%BC%B4%E6%88%91%E5%A4%9A%E5%B9%B4%E7%9A%84%E8%80%81%E5%8F%8Blinux/",title:"聊聊伴我多年的老友，Linux",description:"使用Linux已经快10年了，从大三开始到研究生毕业，Linux作为了我的主力操作系统，Windows几乎没有再怎么使用过（曾经我Windows玩的也很溜的）。这么多年，Linux让我重新认识了桌面环境的效率，也让我认识了定制化的自由，还有它简单却精妙绝伦的设计。也是时间来聊聊这位老友了。",content:"1 邂逅Linux # 初次接触Linux操作系统是在什么时候？想想～～\n高三毕业后买了第一台电脑，一台清华同方的台式机，随机赠送的光盘里面有一张操作系 统光盘“家电下乡Linux适农版”……那是我第一次接触并运行Linux，但那时的我并没有意识 到，放在我面前的是一个即将深深地吸引我并要在多年的职业生涯中去不断锤炼的存在。\n大一、大二这两年，我或多或少地接触到了Linux，但是并没有产生多大兴趣，直到有一 天我激怒了一个同学。当时他正在摆弄Ubuntu，错误地GRUB配置导致系统引导失败，着急 的他在QQ空间发了一条状态，意思就是大神求救之类的。当时我回了一个字“水”。他看后 很生气，系统都启动不了了能不着急吗？于是呢，就言辞激烈地“回敬”了我几句……\n事后我想，Linux有这么复杂吗？于是我开始试图取了解Linux，当然这只是个引子，后面 陆陆续续看到有不少同学都在使用各种Linux的发行版，我才决定认真去了解、学习一下 Linux，没想到这竟是一条不归路……\n LiveCD \u0026amp; RemasterSys \u0026amp; dump \u0026amp; restore GRUB 2 \u0026amp; Customize Boot Menu to bootstrap Multiple OS Plymouth Tweak KDE/GNOME/Unity Appearance (Colors \u0026amp; Themes) Linux Commandline Techs \u0026amp; Administration Unix/Linux Programming Linux Kernel 0.11 Linux Kernel 2.4 Keep going along the roadmap to Linux World!  上面大体上是我初识、折腾、学习、应用、研究Linux的过程，而且这个过程在相当长一 段事时间内还将一直向前延伸下去。与其说对Linux感兴趣，不如说是好奇心驱使，还有 很多疑问没有揭开，这里当然不只是Linux操作系统内核本身。\n我这个博客所要描述的东西可能就比较杂了，这里面我会穿插着记录很多东西～与其说是 博客，不如说是我自己的一个学习笔记了，但是我这个人比较喜欢分享，但有不想那么刻 意，所以我就把它丢在这，谁看见了找到点自己感兴趣的东西，也算是种缘分。\n2 LiveCD \u0026amp; RemasterSys \u0026amp; dump \u0026amp; restore # 2.1 LiveCD # 在学习Linux过程中，会有体验不同Linux发行版这样的需求的，这个时候你有不想频繁地安装系统来解决。LiveCD就是发行版厂商针对用户的这种需求推出的一个玩意，用户可以插入光盘到光驱、BIOS引导从光驱启动来体验。\n可能吧，时间让你明白，Linux最吸引人的地方，并不是有很多的发行版供你换来换去，而是内在的自由。最后，你还是会深度使用某一个发行版并安定下来，而那些各种各样的桌面环境也会有点选择困难。Ubuntu-\u0026gt;Debian-\u0026gt;Fedora-\u0026gt;OpenSuSE-\u0026gt;RHEL-\u0026gt;CentOS-\u0026gt;\u0026hellip;Fedora! Unity-\u0026gt;GNOME3-\u0026gt;GNOME2-\u0026gt;KDE-\u0026gt;\u0026hellip;-\u0026gt;KDE! 我已经坚守在Fedora/CentOS+KDE很多年了，适合自己的就是最好的！\nLiveCD不仅可以帮助我们预先体验Linux发行版，也可以用来安装Linux发行版、修复系统问题。带着一张LiveCD或者Bootable USB Installer，就好像随身携带了一个移动版的操作系统。还是很方便、很酷的一件事情。\nUNetBootin等类似的将USB变身成可引导的Bootable Linux Installer的工具，也是必不可少的工具。\n2.2 RemasterSys # 当你深度使用了一段时间之后，会发现不管是配置文件，还是GUI，还是软件列表\u0026hellip;都已经被自己深度定制化过了，这个时候就很自然会去想系统备份的事情，以免准备多台设备办公时能遍历地迁移备份，或者在设备系统出现问题时能够便捷地还原的问题。\n当你了解了Linux定制化意味着什么的时候，你就应该能体会到定制化背后意味着的工作量、投入的时间，你不会愿意再从安装开始重新定制化了， 没有规划的人才将这种重复性劳动当做是习惯。我为什么不能将现在的完整的系统做成一个初始的可安装的系统呢？\n虽然这要花费的时间、存储可能会大一点，但是适当精简下软件列表、用户文件，完全可以控制在一个合理的范围内，按市面上常见的DVD存储容量来看，完全是hold得住的。而且DVD是真的便宜，存放时间也更长久。\nRemasterSys就是为了满足这样的需求而设计出来的，它就可以把我们当前运行的系统重新做成一个可安装的系统，安装完成后就是现在的样子。但是原作者可能很久没有再更新了吧，在我了解到这款系统工具时，它已经接近失修的边缘了。Sad\n2.3 dump \u0026amp; restore # 慢慢地意识到，所谓的定制都是私人潜意识里面的思想固化，总有不适合他人应用场景的时候，除非你有能力自己给自己定制。最简单的东西，就是最好用的、最靠谱的。一段时间下来，我发现dump \u0026amp; restore就是逼近完美的选择。它专注于转储、恢复操作，非常原始。\ndd最原始直接读写存储设备原始数据，甚至都不理解你的文件系统，但是它缺少一点灵活性。\ndump允许我们在文件系统之上做一些选择，如选择备份哪些目录、文件等等，dump备份的时候会同时备份文件的属性信息，整个打包成一个文件，后续备份恢复的时候你也可以通过restore选择恢复哪些文件到文件系统。\n刚开始的时候，可能觉得全是命令行操作，好复杂？万一出错了怎么办？Linux强大的地方就是命令行操作，习惯了之后就真的爱上了。dump \u0026amp; restore是目前我觉得比较好用的，虽然看上去不像macOS timemachine那样方便，但是它真的算得上最灵活的。\n3 GRUB 2 \u0026amp; Customize Boot Menu to bootstrap Multiple OS # 4 Plymouth # 5 Tweak KDE/GNOME/Unity Appearance (Colors \u0026amp; Themes) # 6 Linux Commandline Techs \u0026amp; Administration # 7 Unix/Linux Programming # 8 Linux Kernel 0.11 # 9 Linux Kernel 2.4 # 10 Keep going along the roadmap to Linux World! # "}),a.add({id:513,href:"/blog/2017-02-09-protobuf%E7%BC%96%E8%A7%A3%E7%A0%81/",title:"Protobuf编解码",description:"开发过程中学习学习的一点protobuf编解码的知识，以及对遇到的一些编解码相关问题的总结。",content:" img { width: 680px; padding-bottom: 1rem; }  开发过程中学习学习的一点protobuf编解码的知识，以及对遇到的一些编解码相关问题的总结。\n1.pb数据类型 # protobuf对message进行编码时，是将message中的各个成员按照key、value组合成一个字节流，这里的key并不是属性的名字，而是varint(tag\u0026laquo;3 | datatype)，其低3位表示字段类型，类型描述见下图。\n当protobuf对一个字节流进行解码的时候，对于那些它不认识的字段会直接跳过，对字节流反串行化操作的代码主要是依赖于各个Message子类的MergePartialFromCodedStream方法实现，常用的ParseFromString或者ParseFromArray方法最终都是调用该方法来完成反串行化任务。MergePartialFromCodedStream方法中包括了对unknown tag的处理，这部分代码都是protoc自动插入的，所以每个Message子类的对未知tag的处理方式也是一样的，下面通过一个简单的proto文件进行说明。\n文件名：T.proto\npackage kn.feeds; enum FeedType { TYPE_RECORD_LIVE = 1; TYPE_RECORD_VIDEO = 2; //TYPE_RECORD_DAYMOMENT = 3; }; message Feed { optional string name = 1; optional int32 time = 2; optional FeedType type = 3; };  使用protobuf --cpp_out=. T.proto进行处理，生成的T.pb.cc中kn::feeds::Feed::MergePartialFromCodedStream方法的源码如下图所示，其中对不相关代码进行了折叠。switch(....GetFieldNumber(tag))获取到了tag的编号并进行分别处理，如果是一个unknown tag则进入default处理分支，一般情况下是执行DO_(\u0026hellip;)将这个unknown tag保存到一个unknown_fields vector中。\n文件名：T.pb.cc，见下图：\n如果新需求中要求改造旧有的pb协议，例如在message中新追加了一些字段，旧代码在进行反串行化的时候并不会读取到新追加的字段，协议改造对旧有服务是不会产生不良影响的。\n另外，大家一般习惯于使用optional对字段进行修饰，这里就optional字段值是否设置对数据传输的影响也进行一下说明：\n 对于message中定义的optional类型的字段field，A给B发消息时，如果A没有显示设置field的值，那么B收到的字节流里面不会包括field字段的信息，B会自动使用proto文件中定义的该字段的默认值。 而当A显示设置字段field的值与默认值相同时，传输给B的字节流里面会包括field字段的信息。设置和不设置optional字段对于串行化数据的编码、传输是不同的。   PS：对于pb2而言，上述描述是正确的。对于pb3的情况，对编码及网络传输数据量又进行了优化，所有的0值都不会在编码时进行编码。如果系统中涉及到pb2、pb3共用，且存在使用pb2的代码中通过判断字段值是否为nil来做特殊逻辑，这里就容易引入问题。而如果全部是pb3协议则不需要考虑这种兼容问题。\n 2.varint \u0026amp; zigzag编解码 # 前面列出了protobuf数据类型编码规则，当tag低3位为0时表示varint类型，对于有符号类型、无符号类型其实差别还是挺大的。\n 对于无符号整数类型我们使用varint编码，如果给一个无符号类型赋一个负值，那么最终得到的值为一个很大的无符号数值； 对于有符号整数类型我们使用zigzag编码。怎么说呢，感觉zigzag也属于varint编码，但是比较特殊而已，仅用来对有符号整数进行编码。  无符号整数varint编解码规则 # - 每个字节的最高有效位（msb）表示是否还有其他字节；\n- 将各个字节从原来的顺序逆序排列一遍；\n- 丢掉各个字节的msb，并将其连接起来；\n- 按照二进制格式解码数据；\n这里其实描述的更像是如何理解一个varint编码，属于解码，但是这样看了之后也会很容易理解varint编码过程是如何进行的。\n有符号整数zigzag编解码规则 # 0被编码为0，-1被编码为1，1被编码为2，-2被编码为3，2被编码为4……以此类推。\n优点：\n这两种编码方式的优点是编解码规则简单，容易实现；占用字节数量少，减少网络传输代价（绝对值小的数字使用更少的字节进行编码，绝对值大的数字可以使用适当多的编码，而并不是限定为定长的16、32、64位）。\n3.non-varint编解码 # tag低3位为1时表示是使用固定的64位来编码一个数字，这里的数字类型仅限于double和fixed64、sfixed64。\n4.string编解码 # string在编码的时候首先是一个varint编码的长度值（字节数量），然后后面跟着的是字符串对应的各个字节。\n下图是一个编码字符串的示例，“testing”被编码成了如下字节流。\n5.嵌入式类型编解码 # 与字符串编解码方式是一致的，一个对象A被嵌到对象B中，也是先写一个varint表示A串行化后的字节流长度，然后再写字节流。\n6.optional \u0026amp; repeated类型编解码 # 对于repeated元素类型，proto2里面是多key存储的，即列表中每一个元素都是使用的相同的key；在proto3里面与此不同，列表中所有的元素共用同一个key。\n其实呢，proto2里面对于repeated类型增加了一个配置选项packed=true也可以达到proto3中的编码效果，proto2中packed属性默认为false；proto3中默认使用packed=true。那么是如何实现这种packed效果的呢？首先写入list中所有元素的直接数量，然后呢逐一对每个元素进行编码，varint中如果msb为0表示当前字节是对应元素的最后一个字节了，下面的字节属于下一个元素。\n7.字段顺序 # 官方文档中的表述是，尽管在proto文件定义的时候可以任意指定字段编号（不能重复编号），但还是建议按顺序对字段编号，这有利于protobuf的parsers采用一些依赖于字段按序编号时的优化方法以增加编解码速度。\n我编写了下面两个proto文件，分别使用protoc进行处理得到输出的头文件、源文件。第一种定义方式不按字段出现顺序进行编号，这么做并非不可，但是这种方式容易引发错误，非常不利于后期的扩展，因为不按顺序对字段编号，当字段数量比较多并且希望增加一个新的字段时可能都不知道该用哪个数字来对其编号了。\nmessage man { optional int32 age = 3; // 字段不按顺序编号 optional int32 sex = 1; optional string name = 2; }; message man { // 字段按顺序编号 optional int32 age = 1; optional int32 sex = 2; optional string name = 3; };  protoc分别对其进行处理后得到的**“头文件”**对比如下，左侧的是“字段不按顺序编号”的，右侧的是“字段”按顺序编号的：\n从上述生成的代码来看，字段值是否已经设置has_${field}方法以及设置有值set_has_${field}的方法，都是使用字段在message中出现的顺序编号对位图进行位与运算的，而不是按照我们手动指定的tag编号去进行位操作的。\n PS: 当时测试的时候应该是protoc v2.5.0，现在protoc已经到了v3.19.1，对比生成的代码发现，这里hasbits的设置与之前又不同了，即不是声明顺序，也不是tag编号，可能是采用了新的规则？这里不确定，简单搜索了下这里hasbits的设置也有些优化手段，可能是因为采用这些优化手段引起的。\nTODO 以后再补充hasbits设置相关的内容。\n 之后又对比了一下生成的**“源文件”**的差异，发现在串行化message信息时使用的字段对应的key还是按照我们指定的tag数值去设置的，如下图所示，左侧是不按序编号情况下对字段age=3进行设置的情况，通过字符串“age\\030\\003”我们知道age对应的key是3；右侧是按序编号情况下对字段age=1进行设置的情况，通过字符串“age\\030\\001”我们知道age对应的key是1（key值对应着pb中指定的field tag编号）。\n当然了反串行化的时候肯定也是按照这样的原则去做的，这样就能保证通信双方的数据视角是完全一致的，至于前面hasbits的逻辑都是通信一方自己的事情，protoc内置实现如何调整对通信双方没有影响，影响的只是自己根据访问对应字段的效率问题。\n总结：尽量按照字段在message中出现顺序进行编号，容易维护、扩展，别没事自讨苦吃，如果字段数量多了又不按序编号，那么新增一个字段的时候都不知道该用哪个编号了。\nx.其他方面 # protobuf的其他内容这里就暂时先不介绍了，有描述不清或者错误的地方还请指正。protobuf这种自描述性超强的消息格式获得了广泛的运用，也被诸多RPC框架用作IDL来指导代码生成，其在编解码效率、数据量方面都有不错的benchmark数据，是当今非常流行的消息格式。\nprotobuf当然也不是唯一一种流行的消息格式，在某些对资源更敏感的游戏场景，flatbuffers也是一种被非常青睐的消息交换格式。还有thrift、xml、json等等诸多格式，它们都有各自的一些适用场景，并非取代与被取代的关系，而是被问题场景选择与被选择的关系。感兴趣的可以更深入了解下。\ny.问题案例 # 最后总结两个初入职场不久遇到的pb问题，这两个问题是我工作中真实遇到的，这里一并记录下，也对其中与pb相关的其他知识点进行一下总结。\n问题1 # 客户端希望协议中新增一种短视频类型，服务端需要读取出短视频类型并进行存储，但是服务端未能成功接收到客户端提交的新的短视频类型。\n问题背景：\n客户端、后台定义好了协议，客户端要求提交一种新的短视频类型“日迹短视频”类型，于是后台在FeedType这个枚举类型里面增加了第3个字段DAY_MOMENT，然后呢，客户端重新编译该pb、后台重新编译该pb、各自开发，后来联调一切正常……\n过了一段时间呢？另一个后台开发同学不知道proto已经被更新了，他只更新了检出的feeds写服务的代码，并没有更新检出的公共目录feeds/proto下的proto文件，自然也就没有将新的日迹短视频类型这个枚举字段编译到代码中去，就这样发布出去了……\n后面客户端同学发现，明明提交的是日迹短视频类型（type=3），后台查询返回的却是普通的短视频类型（type=1），非常不解，检查后台feeds写代码后发现完全是将客户端提交的type直接写到tmem、db的，并没有做任何改动……\n造成这个问题的原因已经是很明白了，就是proto文件没有更新，新增加的枚举字段没有编译进去，但是代码在执行的时候到底发生了什么呢？带着这个问题我扒了一下代码终于理清了这背后的原因。\n首先其他的后台开发人员没有更新检出的proto文件，导致其个人目录下编译出的代码中缺少“日迹短视频字段”，当客户端提交短视频类型FeedType type=3的时候，3被编码为varint(3)；服务端枚举类型只有两个可枚举值1、2没有3，那么服务端收到请求后通过Feed feed; feed.ParseFromString或者feed.ParseFromArray方法反串行化后，读取出来的值feed.type()是多少呢？这里也不卖关子了，feed.type()返回的是1而不是3。下面就说一下为什么这里返回的竟然是1。\n以图1中的T.proto为例，其生成的T.pb.h中包含了如下对FeedType枚举值的检查，当我们执行set_type()方法或者MergeParitalFromCodedStream或者DebugString()的时候，是会对枚举值的有效性进行检查的，检查枚举值有效性的方法就是下图中的FeedType_IsValid()方法。该方法是在enum FeedType中的TYPE_RECORD_DAYMOMENT未被注释掉的情况下生成的，所以switch里面认为case 1、2、3都是有效的；当注释掉TYPE_RECORD_DAYMOMENT生成的switch中就只有case 1、2。无效的枚举值该函数返回false，所以除了case里面出现过的枚举值，其他的都是错误的。\n枚举值有效性检查：\n这里的方法FeedType_IsValid()会在某些断言assert()中被调用，如果程序中没有定义宏NDEBUG，那么一旦调用了该方法的assert()被执行将直接导致程序退出。但是在现网中肯定是不允许程序就因为收到了一个非法的枚举值就“挂掉”的，那么protobuf中对这种非法的枚举值必然会提供一种处理方法，这个方法是什么呢？\n当收到一个pb串行化数据之后，我们希望对其反串行化得到一个自定义的Message对象实例，通常的反串行化方法是调用Message对象实例的ParseFromString或者ParseFromArray方法来完成，这两个方法都调用了一个非常关键的方法：MergePartialFromCodedStream，该方法是基类Message的方法，但是会被Message子类中的方法覆盖，因为如何反串行化数据肯定是由子类中包括的成员来决定的，每个子类都应该提供对应的反串行化实现，这部分代码是protoc自动插入的。以图1中的message Feed为例，protoc处理后生成的T.pb.cc中的MergePartialFromCodedStream方法如下图所示。\nMergePartialFromCodedStream:\n上图是release版本中read tag时读取到tag=3枚举类型FeedType type字段时的相关代码，因为枚举类型也是varint类型，所以会首先检查读取到的tag是否是一个varint类型，如果不是则将其加入unknown_fields vector；如果是则继续检查字段值是否是一个有效的枚举值，如果是则将其强制类型转换成FeedType，并更新调用者Feed对象的成员type；如果不是一个有效的枚举值则将其添加到unknown_fields这个vector中，这个时候调用者Feed对象的成员type并没有被更新，依然是使用的旧值，那么这里的旧值是什么呢？\n在c、c++中枚举类型变量的默认值为0，但是在protobuf中，一个枚举类型变量的默认值为枚举值中的第一个，我们这里的FeedType type枚举变量可枚举的第一个值为1，所以最终FeedType type的值在Feed feed; feed.ParseFromArray(\u0026hellip;rec_pb_data\u0026hellip;)之后不是3而是1。\n……\n上述就是ilive_feeds_write_svr在收到短视频类型为3时写入tmem短视频类型却为1这个问题的原因！\n这里只是加深了对protobuf处理过程的理解，并非造成问题的根源，根源应该从代码管理方面找。\n PS：pb中对枚举值的使用建议，强烈将对应的0值定义为Invalid/Unknown，正常取值从1开始取，用0值表示无意义的枚举值，以解决pb枚举潜在的各种“坑”，这个很重要，我做项目的经历已经清晰地表明了它可能给您的项目带来的风险。\n 问题2 # 问题二：直播场景，用户在房间内发送聊天信息，请求中包含了一个房间id字段roomid，表示用户在哪个房间中发言，但是服务端接收到客户端提交的roomid是错误的。\n问题描述：\n客户端、后台定义好了proto文件，如下所示：\nmessage XXXReq { optional uint32 anyfield = 1; optional uint32 roomid = 2; }; message XXXRsp { optional uint32 roomid = 1; optional ustring json = 2; }; rpc XXX(XXXReq) return (XXXRsp);  但是呢，后来由于协议变动发现XXXReq中的字段anyfield没有用，就删掉吧，于是后台就改成了：\nmessage XXXReq { optional uint32 roomid = 1; };  但是呢，客户端那边只是删掉了第一个字段，改成了：\nmessage XXXReq { optional uint32 roomid = 2; };  后台并不知道客户端是这么改的……一段时间之后，后台同学发现客户端同学提交过来的参数roomid似乎是有问题的，什么问题呢？同一个用户进入now主播房间后发言，每次发言请求提交的roomid都应该是主播自己的roomid，应该是固定的，但是后台同学发现打印出来的请求中的roomid却是变化的，这是什么问题？\n其实这里经过问题1的分析之后也很容易理解了，后台根本就没有读取到客户端设置的tag=2的roomid，后台只是使用了XXXReq req中的默认的roomid值，这个变量又没有进行初始化，roomid中的值是随机值，肯定是会变化的、是错误的。\n"}),a.add({id:514,href:"/tags/varint/",title:"varint",description:"",content:""}),a.add({id:515,href:"/tags/zigzag/",title:"zigzag",description:"",content:""}),a.add({id:516,href:"/blog/2016-05-07-linux%E6%A1%8C%E9%9D%A2%E5%8F%91%E8%A1%8C%E7%89%88%E4%BD%93%E9%AA%8C/",title:"Linux桌面发行版分享",description:"这是我很久之前2016.5.7写的一篇关于linux桌面发行版的文章，但是一直停在我的笔记里。ubuntu 16.04 lts是2016年4月21日发布的，到现在也要6年多了，因为最近在整理之前的一些笔记，发现当初的一些想法还挺好的，拿出来继续分享下。",content:"Linux桌面发行版分享 # 这是一篇写在2016年的文章一直在我的个人笔记里，感觉当时很多想法今天依然成立，所 以拿出来继续分享下。某些信息可能已经有过时，相关的部分我在备注里进行了标注，\n0.体验Linux发行版 # 今天安装了Ubuntu 16.04 LTS，本来准备一直用Fedora的，但是我的笔记本上安装的还是 Fedora 21版本，但是当前最新的已经更新到了Fedora 24,今天刚刚发布了Beta版本。此 前我对Fedora 23 GA以及Fedora 24 Alpha版本进行了简单的测试，实在是不喜欢KDE 5！\n怎么说呢，其实看上去KDE 5挺漂亮的，应该将来也会有不错的发展，但是考虑到KDE 5刚 出来的时间还不够长，其中很多在KDE 4里面方便实用的功能在KDE 5中还没有被开发出来 ，而我又是一个倾向于“工欲善其事，必先利其器”的同学，让我这样把一个未充分完善好 的桌面环境当做自己的主力系统，我实在难以接受！对于GNOME 3，我就不做任何评论了 ，我宁可用Ubuntu Unity也不用GNOME 3！\n可能有人说，没必要一直跟着更新啊，继续实用Fedora 21也可以啊！？此话当然不假， 可是一个失去后续更新支持的版本，我想还是要继续跟进新版本要更好。其实我现在配置 的已经相当棒了，有的软件源里面的程序存在某些小问题，瑕不掩瑜的，我也对其源代码 进行了部分修改，以为自己所用，因为这部分工作还是相当多、相当细的，如果继续跟进 新的发行版，而软件源里面的软件包可能还没有修改过来，或者不符合我的需要，又要进 行重复性的工作，我觉得这个工作量还是蛮大的，至少现在我没有那么充足的时间。\nFedora发行版每6个月更新一次，CentOS 7可以支持10年，我本来也计划使用CentOS的， 但是CentOS对稳定性的追求，也使得很多软件包不能被加入其软件源，有些我很喜欢的工 具，安装、配置起来就会比较麻烦，dpkg、alien、rpmrebuild甚至修改源代码这些可能 都要用到，以配置出一个趁手的系统环境。半年前，我在另一台三星的笔记本安装了 CentOS 7，配置完成之后，堪称完美，那个时候时间多啊，折腾的时间也挺长的；现在时 间没有那么充裕了，我在这台thinkpad上安装了CentOS 7.2，前后也就折腾了一天，不打 算折腾了。\n最后，我选择了Ubuntu 16.04 LTS版本，可以支持5年，而我本身也想重新比较一下 Ubuntu、Fedora这两大发行版，为什么呢？因为对这两款发行版，我都有向当长的使用时 间，现在也积累了很多的经验，前不久我碰巧又看到了一个各大发行版性能对比的文章， 其中Debian系列的性能要明显优于RHEL系列，原因我暂时也不是特别清楚，这也是激发我 重新选择Ubuntu的原因之一。我希望在使用过程中，重新比较一下Ubuntu和Fedora这两大 发行版的差异，例如包管理工具的差异、软件包中的配置文件的差异、系统管理方面的差 异，此外呢，我也希望能够对其性能上的差异进行一下更深的认识。\n1.系统安装过程 # 系统安装过程，应该说是驾轻就熟了，下载一个Ubuntu 16.04 LTS的ISO文件，然后使用 Unetbootin制作一个可以引导系统安装的U盘。U盘要格式化成FAT32格式，且要根据需要 预留一定的存储空间，以供安装过程中释放文件使用，如果预留空间不足，可能导致安装 失败。\n制作完成安装U盘之后，插入电脑，关闭BIOS中的UEFI引导模式，然后从USB HDD启动安装 即可。安装的时候手动分区，最好能够把那些第三方软件包给安装上，这样省的后续安装 ，省心。我是深有体会，之前安装音频、视频播放器的时候，安装解码库浪费了很多时间 。安装过程中有个别地方需要设置一下，例如用户名、密码、语言、地区、时间等等的。\n注意，Ubuntu在安装过程中不会对root用户的密码进行设置，并且默认将新建的用户加入 wheel组中！但是在Fedora安装过程中，会对root密码进行设置，然后再创建一个新用户 ，并允许选择是否将该用户加入wheel组中，还可以指定uid、gid等。这是一个区别，需 要注意一下，安装完成之后，需要通过“passwd root”对密码进行重新设定。\n相对来说，安装过程还是比较顺利的，但是需要注意的是，前面提到过Unetbootin需要预 留一定的空间，例如100m，或者200m，甚至500m，如果设置的比较小的话，可能就会遇到 “磁盘空间不足，安装失败”，这是由于系统安装过程中，有些压缩文件需要释放，释放的 目的地不是在我们要安装到的目标硬盘上，而是在我们的U盘上，剩余空间不足的话，肯 定文件释放就会失败，就不能成功安装到我们的目标硬盘上。例如Ubuntu Kylin设置100m 的话，就会安装失败，设为500m就可以安装成功。用U盘安装与用光盘安装还是有区别的 ，用光盘安装的话，一般释放文件的目的地在目标硬盘上。\n安装完成之后，赶紧试用一下吧。\n2.软件安装配置 # 软件安装完成之后，应该养成一个好习惯，先把软件中的所有配置选项查看一遍，这样的 话就可以对软件整体有个更全面的认识。很多用户在安装了软件之后，就不管不顾了，这 怎么行呢？比如有些人手机上安装了在线视频播放软件，但是从来不关心相关设置，时间 久了，缓存占用空间越来越多，但是却不知道清理这些垃圾；又或者买了IPhone以为手机 有指纹安全了，但是却不知道该在设置里面对Siri进行相关的设置，以阻止未解锁情况下 的绕过安全检查的问题……像这样的类似的问题有很多。\n安装完成一个软件之后尚需如此，安装完成一个操作系统之后，就更需要这样了。对于系 统中的绝大部分配置，例如启动设置、登陆设置、界面设置、环境变量设置、别名设置、 常用软件包设置、安全设置、tricks等等，这些都是一个熟练的计算机用户安装完系统之 后应该考虑的。对于Linux用户，这一点显得尤为重要，一个配置良好的系统，可以让 Linux充分发挥出其优势，成为我们的趁手的兵器！\n3.系统引导设置 # 3.1.设定GRUB引导界面 # 设定GRUB是很重要的，GRUB可以帮助引导多个安装的系统，支持windows、unix、linux等 ，我之前曾经有专门的笔记对GRUB相关的配置进行了详细地说明，这里就不再阐述了，感 兴趣的话，可以参考我之前的说明加以了解。\n这里仅仅对GRUB的工作原理进行一下简单的说明。当我们按下开机按钮的时候，系统BIOS 被启动，并执行加电自检任务，任务完成之后，将引导操作系统启动。BIOS会将系统控制 权交由另一个程序进行处理，这个程序被安装在硬盘的启动扇区中，通常是第一个扇区。 但是一个扇区只有512个字节，不可能装下足够多的代码来完成系统的启动任务。因此在 这个第一扇区中往往存放了一些简单的代码，这段代码接收BIOS转交的系统控制权，去执 行后续的更加复杂的系统启动任务。\n以GRUB2为例，通常将GRUB安装在硬盘的第一扇区中，并且将系统内核映像安装在/boot分 区中，并且/boot/grub2中也保留了其他的大量的GRUB2程序、配置文件等。这样硬盘第一 扇区中的grub引导代码会加载相应的程序，并最终完成内核的装载任务。当内核装载完成 之后，GRUB再将系统控制权交由内核，这时操作系统才算是真正的接管了整个系统。\n3.2.设定Plymouth动画，并开启帧缓冲 # 3.2.1.开启Plymouth # GRUB装载内核、引导内核、内核启动过程中，需要执行很多任务，这个任务耗时可能还比 较长，为了让用户在等待系统启动的过程中，不至于等待地又闷又烦，可以在这段时间里 ，显示一个比较友好的启动界面，例如进度条、启动动画等等。\nplymouth就是这样的一个程序！它通常包括了3个主要部分，一个plymouthd程序，这个相 当于一项服务，在系统启动的时候会决定什么时候开启动画、结束动画，开启和结束动画 是通过另一个程序plymouth来完成的。另一个部分也就是这里的动画了，我们称之为 plymouth主题。\n用户可能在同一个系统中安装多个plymouth主题，这就存在一个“系统显示哪个主题”的选 择问题！在Fedora里面，是通过plymouth-set-default-theme来选择主题，然后通过 dracut重建initramfs实现的。但是在Ubuntu里面采用了一种更加简便的方式，即通过 update-alternatives来实现。在Fedora里面，其实也存在update-alternatives工具，但 是却采用的重新建立initramfs的方式，相比之下，稍微有点繁琐，但是这种方式可能在 系统启动速度方面更胜一筹。因为plymouth主题所需的资源被直接加入到了了 initramfs中，加载后解压缩的速度可能比通过update-alternatives生成的符号链接再次 访问文件系统更加节省时间。各有优缺点！\n3.2.2.开启帧缓冲 # /etc/initramfs-tools/conf.d/splash中增加一行FRAMEBUFFER=y，没有该文件就创建该 文件。开启帧缓冲之后，可以加速plymouth启动，以使得plymouth动画能够尽量铺满系统 启动的整个过程，以使得启动界面更加友好。\n修改完成后，需要重新建立initramfs，执行命令update-initramfs -u命令即可完成。对 于Fedora系统需要通过dracut来完成，其实Ubuntu里面也是通过dracut来完成的， update-initramfs命令只不过是一个shell脚本而已，其只不过是对dracut命令的封装。\n3.3.指定关键内核参数 # 系统中有些参数是在系统启动的过程中指定的，虽然在系统运行期间仍然可以对其进行修 改，但是如果通过配置文件或者其他方式能够指定好相关的参数信息，运行期间就无需再 干预、调整了。\n3.3.1.设定虚拟内存换出比率vm.swappiness # 现在的物理内存越来越大了，在一般使用情况下，交换区是很少会被使用到的。虚拟内存 频繁的换入换出会影响系统的响应速度，就算是现在使用SSD，也比内存慢很多，因此合 理地设置内存页面换入换出率是非常重要的，而且我们要使用的是桌面版操作系统，合理 地设置可以减少图形界面的响应延迟时间。\n/etc/sysctl.conf中增加vm.swappiness=16，通过sysctl vm.swappiness命令可以看出默 认设置是60，我们通过修改配置文件将其设置为16。\n3.3.2.设定udev的网卡命名规则 # 对于系统中的网卡，我们更加熟悉eth0、wlan0这样的命名方式，但是如果我们不加配置 ，系统中很可能显示的是enp0s25、wlp3s0这样的名字，为什么呢？这与udev命名规则有 关系。\n如何看到我们熟悉的名字呢？当然业余udev命名规则有关系，这里可以通过grub传递内核 参数“net.ifnames=0 biosdevname=0”来解决，修改/etc/default/grub之后，需要重新更 新/boot/grub2/grub.cfg，这个可以通过update-grub2来完成。\n但是，我的情况比较特别，我这个笔记本有两个硬盘，分别记为/dev/sda和/dev/sdb。其 中/dev/sdb上安装了Fedora，并且在/dev/sdb上安装了grub；/dev/sda上安装了Ubuntu， 并且在/dev/sda上安装了grub。然后将/dev/sdb作为第一启动设备，为啥这么做？因为 sdb是一个SSD，速度快，而且Fedora是我的主力系统，就是这么个情况。由于引导Ubuntu 启动的grub配置文件是在/dev/sdb上的Fedora中生成的，与Ubuntu上面的grub配置文件没 有关系。\n因此如果要正确改过网卡的名字来，还是需要修改/dev/sdb上的 /boot/grub2/grub.cfg中的相关配置。其实也就是将上述提到的内盒参数加入到 menuentry的linux命令后的选项中而已。\n3.3.3.关闭启动时fsck对文件系统的检查 # /etc/fstab中将每个分区的最后的一列数字全部修改为0，这样可以避免系统启动时对文 件系统进行检查，加快系统启动速度。\n3.3.4.激活所有的系统魔法键vm.sysrq # 修改/etc/sysctl.conf，增加一行vm.sysrq=1，这样就可以激活Linux系统内所有的魔法 键，例如比较常用的Ctrl+Alt+Print+K，表示杀死当前会话，包括当前会话中启动的所有 的进程；Ctrl+Alt+Print+B，表示立即重新启动系统。\n这两个魔法键是我经常使用的，非常有用，特别是希望快速检查配置更改是否有效或者图 形界面失去响应的时候。\n4.系统优化及系统工具 # 4.1.系统配置优化 # 4.1.1.Ubuntu greeter配置 # 要创建、修改的文件主要包括：\n /usr/share/glib-2.0/schemas/com.canonical.unity-greeter.gschema.xml  修改该文件，可以禁用greeter界面的系统已就绪的声音提醒、是否绘制网格、是否要加 载一个图像作为背景，加载图像前的界面颜色等。对于要加载的图片最好能够与用户之前 设定的桌面壁纸一致，这样可以加快系统登陆系统的时间（避免了再次加载图片嘛，减少 了访问文件系统的时间）；另外，加载图片之前的颜色，也应尽量与壁纸、plymouth动画 背景色相一致，这样显得系统启动更加流畅，界面更友好。\n修改该xml文件后，需要执行如下命令使其生效：\n sudo glib-compile-schemas /usr/share/glib-2.0/schemas\n 执行改行命令的目的，是将修改后的xml文件与未修改的xml文件重新编译成一个完整的二 进制文件，gsettings读取这个二进制文件并对图形界面进行相关的设置。\n关于如何在用户设定新的壁纸之后，让系统启动到greeter界面的时候可以自动装载的问 题，我们可以在上述xml里面将待加载的图片设为一个符号链接.background-uri。然后当 用户修改背景图片后，可以通过命令update-background来更新该链接，使其指向新的背 景图片；或者在.bashrc里面写入一些脚本来完成链接的更新。总之目的就是保证用户再 次登陆时，能够加载正确的图片，实现平滑地界面过渡。\n /home/username/.bashrc  关于如何在用户设定新的壁纸之后，让系统启动到greeter界面的时候可以自动装载的问 题，我们可以在上述xml里面将待加载的图片设为一个符号链接.background-uri。然后当 用户修改背景图片后，可以通过命令update-background来更新该链接，使其指向新的背 景图片；或者在.bashrc里面写入一些脚本来完成链接的更新。总之目的就是保证用户再 次登陆时，尅加载正确的图片，实现平滑地界面过渡。\n在我以前使用Ubuntu 12.04 LTS的时候，gconf可以在用户选择新的桌面壁纸后执行一些 操作，比如更新%gconf.xml文件，其中保存了用户选择的壁纸的绝对路径，可以利用它来 更新符号链接.background-uri。但是在Ubuntu 16.04 LTS里面，我发现系统中默认没有 使用生成%gconf.xml文件，但是通过gsettings可以获取到壁纸路径信息，并且格式与 %gconf.xml中是一致的。\n在.bashrc中，增加如下三行脚本就够了：\n BACKGROUND_CONFIG=gsettings get org.gnome.desktop.background picture-uri\nBACKGROUND_CONFIG=echo ${BACKGROUND_CONFIG#*//}\nln -sf $BACKGROUND_CONFIG ~/.background-uri\n  /usr/bin/update-background  当然了，也可以把上述三行脚本写入一个bash脚本中，放入搜索路径/usr/bin中：\n #!/bin/bash\nBACKGROUND_CONFIG=gsettings get org.gnome.desktop.background picture-uri\nBACKGROUND_CONFIG=echo ${BACKGROUND_CONFIG#*//}\nln -sf $BACKGROUND_CONFIG ~/.background-uri\necho \u0026ldquo;update background-uri link \u0026hellip; done\u0026rdquo;\n  /home/username/.background-uri  这只是一个符号链接，通过它指向正确的桌面壁纸。由于不希望在后续使用过程中看到这 个文件，或者对其进行直接修改，所以将其设置为隐藏文件。\n4.1.2.bash配置 #   /etc/passwd\n  /etc/bash.bashrc \u0026amp; /etc/profile\n  .bashrc \u0026amp; .profile\n 环境变量   Java相关\nAnt相关\nMaven相关\n\u0026hellip;\n其他\n  别名   alias bb=\u0026ldquo;byobu\u0026rdquo;\nalias clean=\u0026ldquo;dpkg -l | grep ^rc | awk \u0026lsquo;{print $2}\u0026rsquo; | xargs sudo dpkg -P\u0026rdquo; alias cls=\u0026ldquo;reset\u0026rdquo;\nalias duu=\u0026ldquo;du -h -a -d 1\u0026rdquo; alias ee=\u0026ldquo;exit\u0026rdquo;\nalias g++=\u0026ldquo;g++ \u0026ndash;std=c++0x\u0026rdquo;\nalias gentags=\u0026ldquo;sudo /usr/bin/ctags \u0026ndash;c-kinds=+dfglm \u0026ndash;language-force=C -R .\u0026rdquo;\nalias gg=\u0026ldquo;cd /home/user/Github/Study\u0026rdquo;\nalias grep=\u0026ldquo;grep \u0026ndash;color=auto\u0026rdquo;\nalias gvim=\u0026ldquo;gvim -f\u0026rdquo;\nalias indent=\u0026ldquo;indent -kr\u0026rdquo;\nalias l=\u0026ldquo;ls -CF\u0026rdquo;\nalias la=\u0026ldquo;ls -A\u0026rdquo;\nalias ll=\u0026ldquo;ls -al\u0026rdquo;\nalias ls=\u0026ldquo;ls \u0026ndash;color=auto\u0026rdquo;\nalias lg-ce=\u0026ldquo;sdcv -u\u0026rsquo;朗道汉英字典5.0'\u0026rdquo;\nalias lg-ec=\u0026ldquo;sdcv -u\u0026rsquo;朗道英汉字典5.0'\u0026rdquo;\nalias mirror=\u0026ldquo;wget -r -p -np -k\u0026rdquo;\nalias mmatlab=\u0026ldquo;matlab -nojvm\u0026rdquo;\nalias pp=\u0026quot;/usr/bin/proxychains4\u0026quot;\nalias ss=\u0026ldquo;ssh -qtfnN -D 7070 ZhangJie@192.168.56.254\u0026rdquo;\nalias vvim=\u0026ldquo;vim -u ~/.vvimrc\u0026rdquo;\nalias nvim=\u0026ldquo;vim -u NONE\u0026rdquo;\n  函数   hostlist\n\u0026hellip;\n其他\n   4.1.3.gnome-terminal或Konsole配置 # 4.1.4.Vim配置 #  vim.tiny-\u0026gt;vim-\u0026gt;vim.nox-\u0026gt;vim.athena-\u0026gt;vim.gtk/vim.gnome  vim的不同二进制版本，其中内置的功能特性有所差异，在上述箭头所示顺序中，各版本 包含的特征依次增加。系统中可以安装多个vim版本，然后通过update-alternatives来控 制使用那个版本。\n .viminfo  /etc/vim/vimrc中，保存着vim的全局配置。奇葩的是，在Ubuntu里面默认没有开启 viminfo支持，这个只要对/etc/vim/vimrc文件进行修改，取消相应的配置前面的注释就 可以了。\n .vimrc  vimrc这个是vim的主要配置文件，关于vim这一个编辑器，涉及到很多方面的配置，包括 颜色配置、快捷键配置、颜色配置、命令配置、插件配置等等，建议没事多翻翻vim相关 的论坛，总能学到点东西，加快文本编辑效率。vim不愧是编辑器之神！\n如果实在是对vim的相关配置感兴趣，不妨查看一下我的相关配置说明，可以从如下repo 进行获取：https://github.com/hitzhangjie/Conf.git。\n4.1.5.按键延时、按键速率配置，更快速地输入 # 降低按键延时、提高按键速率，这样可以更加快速地进行输入操作，在Vim中进行移动效 率也会更快。可以根据需要、个人习惯进行适当地调整。\n有些情况下，我们进行输入操作时，如果一边思考一边输入的时候，可能输入操作会比较 慢一些，但是如果思考任务不是很重的情况下，输入的速度就会很快，但是呢，系统的默 认按键设置有一个按键延时和输入速率限制，这个限制在某些情况下会严重干扰输入速度 。对于这一点我是深有体会，何况自己还是一个专业级码农，一个不折不扣的输入快手， 一个命令行、vim重度用户，对于按键输入速度有着较高的要求。\n对于OS X用户，其shell中存在较为严重的按键延时问题，我是在体验OS X的虚拟机的时 候发现这个问题的，之后就在Linux上对相应的设置进行了完善，输入体验有了较大提升 。建议朋友们优化一下相应的配置，相信会有更好的输入体验。\n4.2.系统常用工具 # 系统中包括了大量的工具，包括官方的以及第三方提供的，甚至有些个人提供的工具，能 够从众多的工具中遴选出那些高价值的、实用的工具，对于后续的高效工作是非常有利的 。在多年的Linux使用过程中，我将自己觉得非常好的工具介绍给大家，当然了这里的工 具可能不仅仅是一些软件包，也可能是系统中提供的一些不错的功能、组件等等。\n4.2.1.byobu、tmux、screen # 对于Linux而言，命令行是体现其强大之处的一个窗口。有些刚开始学习Linux的用户，很 难以理解为什么命令行这种极其不方便的操作方式会有比GUI更好的体验、效率。其实这 个问题很容易理解，一个命令通常可以灵活指定几个、多个、很多个选项，在GUI中能够 对其进行有效组织不是一项简单的工作，不是说不能，只是说可能会附带很多的工作量。\n举个简单的例子，以windows资源管理器为例吧。windows资源管理器看似已经非常强大了 ，在里面我们可以将文件以列表、图标等多种视图形式进行展示，并且支持复制、粘贴、 移动、搜索等操作。对于普通桌面用户而言，这个确实已经足够强大了。下面我试着题几 个功能需求，你们看看windows资源管理器是否能够做到。\n 列出最近1分钟内修改过的文件？   Linux下可以通过命令“find -mmin 1”来完成。\n  列出最近10分钟内访问过的文件？   Linux下可以通过命令“find -amin 10\u0026quot;来完成。\n  列出文件内容中包括“xxxx”字样的文件？   Linux下可以通过命令\u0026rsquo;find -iname \u0026ldquo;*\u0026rdquo; | grep \u0026ldquo;xxxx\u0026rdquo; | cut -d':' -f1 | sort | uniq\u0026rsquo;来完成。\n  列出所有的目录文件，或者列出所有的普通文件？   Linux下可以通过shell脚本来完成，如：\n#!/bin/bash\nfor f in find . -iname \u0026quot;*\u0026quot; do\nif [ -d $f ]; then echo $f; fi\ndone\n  显示出指定目录的树形结构，并可以指定深度？   Linux下可以通过命令”tree -L n“来完成。\n   ……\n  其他\n   用户的需求是灵活多样的，是变化的，GUI界面相对比较固定，正所谓众口难调，有的用 户希望功能多点，哪怕界面看上去很复杂，但是有的用户却希望界面尽可能简单，仅仅 保留刚需的功能就可以。\n 对于windows资源管理器而言，无法完成上述任务，实际上Linux中的某些类似的GUI工具 也难以完整地提供上述功能，而Linux命令行却可以通过某种形式的组合，来快速地满足 各种灵活多变的功能需求，GUI工具相比较之下，显得非常不灵活。这还只是谈到一个简 单的资源管理方面的工作，我们的工作实际上比这个要复杂很多很多，Linux中的命令行 可以通过不同程度地组合来满足解决复杂任务，但是要提供一个GUI来胜任所有的灵 活多变的任务，就太不现实了。\n上面提到了命令行的强大之处，相信大家能够对命令产生一点新的认识，对于重度Linux 用户来说，命令行是不可缺少的，一个不能够熟练使用命令行的用户，很难说他是一个水 平较高的用户，哪怕他有再长的使用经历也是白搭，时间并不能保证用户积累了充足的经 验和知识。重度Linux用户可能会开启很多的命令行窗口，并在不同的窗口中执行不同的 任务，但是如果能够通过一个程序对开启的多个命令行窗口进行更加有组织的管理，操作 起来就会更加方便，tmux、screen就是基于这样的目的诞生的。而byobu是建立在tmux或 者screen之上的一个更加界面友好的工具程序，通过它可以更加方便的对打开的多个命令 行窗口进行管理。byobu中的常用操作包括F2切换、F8重命名等等。\n4.2.2.lantern、switchomega+chrome、vpn # 在国内，有堵墙阻碍了我们正常上网，就是GFW嘛，不说你们也知道对不对，但是有些人 确实是不知道的，我刚上大学的时候就不知道。09年高中毕业之后，我买了自己的电脑， 才算是真正地用起了互联网。大一的时候，那个时候比较菜，很多计算机技术方面的问题 ，在百度上搜索一下基本就可以得到解决，但是后来慢慢地发现自己提出的问题，百度基 本上搜索不到正确的结果，而且也对百度的搜索质量越来越不满意。后面是一个同学介绍 我使用Google，也确实让自己受益匪浅。\n用Google，需要翻墙，翻墙的手段也是多种多样，翻墙工具更是五花八门。但是说来说去 ，把那些陈年废弃的老古董搬出来没有多大实用价值，当然了它们非常具有历史意义，对 于那些曾经奋斗在翻墙一线的前辈们我们应表示感谢。现在比较好用的翻墙工具，要么就 是直接用vpn，要么就是用开源的lantern。lantern支持Windows、Linux、OS X多种操作 系统，也支持Android手机，目前不支持iOS。感兴趣的话，可以直接从如下链接进行下载 ：https://github.com/getlantern。\n对于lantern的配置，在windows下面，只要运行lantern，IE浏览器、Chrome浏览器等就 会自动进入代理模式，在不同的Linux发行版中可能要进行不同的设置。Ubuntu 16.04 LTS中可以启动lantern后让浏览器自动进入代理模式；Fedora 21中在启动Lantern之后， Firefox浏览器自动进入代理模式，但是对于Chrome浏览器需要通过SwitchyOmega进行相 应的代理设置，其实就是创建一个代理代理规则，即使用pac.profile来实现自动代理， pac.profile获取url为: http://localhost:16823/proxy_on.pac。造成这种问题的原因 可能是lantern设置页面没有勾选“管理系统代理”，可能也是lantern在不同系统上的”行 为“差异。\nlantern提供了一个http代理端口8787（支持http、https协议），可以通过proxychains 进行设置，对其他http程序进行代理，也可以在其他使用http代理的软件提供代理服务， 例如android studio、eclipse、mendeley desktop等等。\n 写在2022年6月：再见lantern，lantern此时已经退出历史舞台很多年了 :(\n 4.2.3.vim+markdown、cherrytree、wiznote # 不管是在学习Linux的过程中，还是在其他学习过程中，都需要对相关知识进行收藏、整 理、总结，养成一个良好的记笔记的习惯是非常重要的，当然了，拥有一个跟得上思维的 记笔记的工具也是必不可少的，这类工具有很多，也看到很多朋友都选择了了自己的编辑 器。我本人也在长期的学习过程中试用了大量的记笔记工具，但是有的工具提供的功能并 不是我所需要的，或者没有我想要的功能，经过大量尝试之后，我也找到了适合我使用的 记笔记的工具，在这里也简单介绍一下。\n正所谓工具要趁手，趁手的意思也就是说，工具好不好，关键要看是否适合用户自己，因 此不太可能说，我喜欢的工具你也一定喜欢，或者一定能够满足你的需要，请辩证看待。\n vim+markdown  vim作为编辑器之神，已经赢得了很多人的青睐，特别是程序员，我也是程序员，我也喜 欢写东西，比如写总结、写博客、写体会等等吧，但是我讨厌把大量的时间花在排版上。 将vim与markdown结合起来可以说是一个非常好的选择。并且通过配合 vim-instant-markdown插件，可以实现在文字编辑过程中的实时预览。我非常喜欢现在的 这种编辑体验。下图是我现在编辑状态下的一个截图。\n对于集成了markdown语法支持的编辑器，也有很多，但是由于我钟情于vim，即便有编辑 器集成了对vim操作方式的模拟，但是毕竟还是模拟，也不是一个完整的vim，编辑效率仍 然大大受限，所以我没有选择像markdown、atom这样的编辑工具。如果朋友们不喜欢vim，可以试用下atom。\n ps：2022年6月更新，我也是instant-markdown-d的贡献者。\n  cherrytree  cherrytree中可以通过树形结构对多个学习不同的学习内容进行阻止，例如为编程、内核 、算法单独创建一棵树进行管理，简单直观；\n树形结构可以任意扩展，支持多级子树的创建，灵活方便；\n编辑器中支持不同编程语言的语法高亮，而且能方便地调节代码窗口的大小，实用；\ncherrytree是我最常用的记笔记工具了，并且其文件支持加密操作，避免信息泄露，也可 以非常方便地将其加入github中，永不丢失，多好啊！\n ps: 2022.6更新，在我后面工作后逐渐将工作迁移到了mac设备下，主要原因是苹果生 态下设备之间文件同步非常方便，但是cherrytree的作者表示自己没有mac设备，所以 cherrytree短期内兼容mac是不大可能的。有点遗憾，我对mac下的图形化编程一知半解 ，不然还可以帮助贡献下。\n  wiznote  我们都经常上网，不管是用手机还是用电脑，很多时候，看到非常好的帖子，都是希望将 其收藏一下，收单到浏览器收藏夹或者某些app客户端里面，但是我们也常注意到这种情 况，有的帖子经过很长一段时间之后，不能正常访问了，可能是被删除了，也可能是被和 谐了，或者是被重新编辑过了，与之前相比发生了变化……我们当然是希望收藏的内容日后 查看的时候仍然与收藏时内容保持一致，当然更不希望进行收藏的网页日后居然无法访问 了，这岂不是很糟糕。\n为知笔记很好地解决了这一点，当我们收藏一个网页的时候，并不只是简单地保存一下网 页的链接，而是可以在本地中离线一份完整的网页，将内容保存起来。而且为知笔记还做 到了浏览器页面收藏、微信朋友圈文章收藏、公众号文章收藏，还能够将其他地方看到的 网页分享到为知笔记的公众号，只要分享了就自动保存。非常地方便！现在很多人都在使 用为知笔记了！\n现在为知笔记也可以支持markdown语法了，但是，编辑工作我还是希望使用vim来完成， 为知笔记更多时候被我用来收藏网页、朋友圈、公众号中的文章，过一段时间再对其进行 整理，收入cherrytree中。但是对于一般的笔记，我更强相遇使用vim+markdown来完成。\n ps：2022.6更新，为知笔记也是一个很不错的笔记，但是在我后续使用中遇到了同步错 乱的问题，最后放弃使用类似云笔记的东西了，直接用简单靠谱的github来托管数据， 用最好用的编辑器typora等来写文档。\n 4.2.4.gthumb、gimp、shotwell # 查看图片工具，gnome、unity里面最好的我认为要数gthumb了，在kde里面gthumb界面比 较丑，但是其功能绝对是最强大的。gimp是类似于ps的图像处理工具，小巧也很使用。 shotwell是照片管理软件，平心而论软件做的是不错，但是使用的确实不多。\n4.2.5.virtualbox、vmware workstation # 虚拟机管理软件virtualbox在Linux下是非常赞的，vmware workstation也可以，但是 vmware workstation有些bug，我在Fedora 21上进行安装是遇到了问题，当然通过修改源 代码，重新编译也成功进行安装了，但是有的问题还是无法解决。在Linux下面使用 virtualbox要更加省心一些，virtualbox已经做的非常出错了，支持的操作系统类型比 vmware workstation要多，而且性能方面也一点不输vmware workstation，对Linux支持的也比较好。\n在Linux下面，建议使用virtualbox，我现在安装了多个虚拟机，包括windows xp、 openSUSE 13、Mac OS X 10.7是用的非常好，当然其他的系统也都安装后测试过，上面提 到的三个要不同程度地用到。\n以前在windows下面的时候，我确实是用vmware workstation比较多，因为virtualbox在 windows下面跑起来真心慢的要命，vmware workstation要好很多，但是在Linux里面， virtualbox运行速度非常快，而且是自由软件，当然使用virtualbox了。\nvirtualbox提供的几种网络模式，也很简洁明了，nat、host only等模式，可以基本满足 的需要，我倾向于选择virtualbox。\n4.2.6.smplayer、clementine、mixxx、mpg123、openshot # Linux下面的视频播放软件，我认为最方便的应该是smplayer，跟vlc、dragon player、 totem、mpv等等比起来简直是神器，不仅功能多，而且操作也方便，某种程度上归功于其 丰富的快捷键配置操作。\n音频播放器，我觉得clementine比较好，听音乐嘛，也不需要非常复杂的操作，界面简单 清爽就好了，clementine满足了我的需要，我不喜欢rhymbox、banshee等其他流行的音频 播放器。喜欢dj、电子音等劲爆音乐的，可以使用下mixxx。mpg123是命令行下的一个非 常简单的音频播放工具。\nopenshot是一个矢量视频编辑工具，其功能非常多，我经常用它来合成视频、剪辑视频、 视频转码等等，openshot工作过程中，因为计算量较大，cpu使用率较高。\n4.2.7.openssh-server、openssh-client # ssh，secure shell，这个是很有用的代替ftp、telnet的工具，在自己的电脑上搭建一个 sshd服务还是非常有必要的，说不定啥时候就需要从其他电脑链接到自己的电脑，比如 host与guest进行通信的时候，或者在本地搭建git服务器的时候……有很多场景都会用到。 当然了，更多的时候，我们是通过ssh去链接外面的某个主机。\n ps：因为网络的原因访问github不方便，所以我是搞了个二级的git托管，第一级是在 本地电脑上开了个专门的账户git，这个账号home目录下用来托管git数据，但是这个账 号禁止登录。然后白天我在图书馆或者网络不好的地方干活，就会从本地工作空间提交 到这里来，等有网络了我再提交到github，其实有些我也没有提交到github。我主要是 担心误删除rm -rf之类的不小心把仓库给删了，所以才搞个独立账号来充当git服务器 。\n 总之，sshd、ssh是经常用到的工具，可以通过安装openssh-server将本地主机配置成 sshd服务器，安装openssh-client来获取相应的ssh等众多实用客户端工具。\n4.2.8.git、svn # 版本控制工具的两个代表是git和svn，其中svn是集中式的版本控制工具，而git是分布式 的版本控制工具。相比较而言，git比svn要优秀很多，当然其学习成本要高很多。\n建议学习一下《Pro Git》这本书，深入认识下git的工作原理，并在以后的的学习工作中 养成版本控制的意识，并切实将git应用起来。\n4.2.9.gnome-terminal、Konsole # 一个好用的终端模拟软件，绝对是非常重要的，比较好用的两个，kde下面使用konsole， ubuntu unity、gnome下面使用gnome-terminal。\n在里面可以对字体、颜色、输入指示器等等进行较为丰富的设置，一切为了效率。\n4.2.10.Ubuntu Unity、KDE、GNOME # 当前流行的三大桌面环境，是ubuntu unity、kde、gnome，任何一个Linux发行版都可以 对上述桌面环境进行整合，我对目前主流的桌面环境都使用过，上述三个使用的时间比较 长，根据我多年的使用体会，我自己更加倾向于选择kde和ubuntu unity。如果我使用的 是RHEL系列的，我就使用kde，如果我使用的是Ubuntu，那就使用ubuntu unity。gnome3 实在不敢恭维，有很多人比较推崇gnome3，但是我确实不喜欢这种方式，自己感觉操作效 率是上述三个中最差劲的。\n ubuntu unity  从使用ubuntu 12.04 lts开始，就开始使用ubuntu unity了，刚开始的时候确实觉得还不 错，但是永久了，就发现有些东西并不实用，我想回归精简了，仍旧是善变，并不就是人 家unity做的不好。后面你们猜我用上了什么，我用上gnome-shell-fallback，没错，我 觉得gnome2时候的界面真是清爽多了，为此，我后面还使用了相当长时间的rhel 6.5，直 到后面我用上了Fedora并开始使用kde作为主要的桌面环境。\n现在发现ubuntu unity确实做的不错，稳定性、速度等各方面都相当不错，所以我要先给 个赞！可以说之前一直都在折腾GUI方面的东西了，越折腾越心累，现在能够平心静气地 来对待这些问题了，自己也有实力对不合心意的地方进行修改了，改配置文件、改源代码 、替换必要的组件等等，随心所欲不逾矩！这种感觉还是非常爽的！当我看到有某个同学 在使用“丑陋”的Ubuntu时，心里面就有种不一样的感觉，很多新手不会配置却总是抱怨， Linux这么灵活，就是让你去探索的，不喜欢探索、折腾，自认为这是浪费时间的可以去 买个Mac，不过说真的，Mac OS X的GUI就是一个gnome2的级别，操作效率渣的要命！\n ps：2022.6更新，现在mac使用了马上6年了，和我当年使用Linux发行版的时间差不多 久了，说实话mac系统整体而言整合的比较好，但是要想提效，还是有很多东西要配置 的，see 你的mac有哪些趁手的工具  。\n 现在回头来看，我喜欢Ubuntu Unity哪些地方呢，没有特别推崇的地方，就是一种感觉， 优化的确实不错了，比以前强多了，而且操作起来确实也是很方便。\n kde  自从我使用Fedora 21以来，就一直使用kde作为桌面环境，kde4相当成熟、稳定，我很喜 欢，而且灵活性好，可以进行丰富的配置，这一点我非常喜欢，可以让其变得相当简约不 简单，也可以让其变得相当华丽而优雅。\n但是最新的Fedora里面增加了dnf，怎么说呢，我非常依赖yum，但是目前dnf还没有完全 实现某些功能，而且kde5里面很多地方还不完善。今年6月份才会出Fedora 24的GA版本， 我也等不了那么长时间了，于是提前体验了一下Alpha版本，发现kde5并没有达到我希望 的程度，dnf也没有实现我依赖的功能，所以我暂时先放弃了使用Fedora 24的年头，转而 投奔了Ubuntu，也没有继续采用kde桌面环境，而是使用了自带的unity。\n其实kde4是一个非常高效的桌面环境，简约的界面，丰富的快捷键，简直双到爆。\n gnome  gnome2比较简约，实用性比较好，但是对于追求高效操作的用户来讲，未免又显得过于寒 酸了些，值得一提的是，Mac OS X也就是相当于gnome2的级别，虽然苹果重新设计了很多 东西，但是仍然就是这么个水平，操作鸡肋，难以满足我的需要。\ngnome3是比较高级了一点，但是有点哗众取宠，鄙人不喜欢，谁爱谁用，反正我是不用。 其实gnome3很早之前就被无数人喷过了，比如Linus Torvalds。\n ps：2022.6更新，anyway，gnome3目前似乎称为了主流桌面环境，特别是服务器为中心的发行版。\n 4.2.11.workspaces、pager、activity #  虚拟桌面  Ubuntu Unity、GNOME里面使用的是workspaces的概念来表达多个虚拟桌面的意思，在KDE 里面其实也是用的这个概念，但是它提供的工具却叫pager，表达的意思是一样的，都是 表示的虚拟桌面的意思。\n虚拟桌面，其实就是在一个桌面上虚拟出多个桌面，例如一个笔记本就只有一个屏幕，只 能显示一个桌面啊，但是现在我虚拟出4个桌面，可以在其中进行切换。现在主流操作系 统windows、osx、linux中都提供了虚拟桌面支持。而linux中的几乎所有的桌面环境都支 持虚拟桌面。\n ps：2022.6更新，windows是从win10开始支持的吧，叫任务视图。osx下叫桌面1、桌面2……都是类似的东西。\n 虚拟桌面的作用是非常明显的，我们可以在不同的虚拟桌面中做不同的工作，这使得工作 更加井井有条、效率更高。\n 活动  KDE Plasma里面，提供了activity的概念，在同一个用户会话中，可以有多个不同的 activity，比如音乐activity、编程activity等，我们可以在当前会话中的不同activity 中进行切换，使得自己能够在不同的任务之间进行切换。\nactivity看起来也是非常有应用价值的，但是我任务比较明确，并且我认为在不同的任务 之间进行切换，并不需要付出较多的额外的工作，比如在游戏、工作、娱乐之间进行切换 ，我认为是一个很自然的过程，所以我几乎不使用activity。\n ps：2022.6更新，activity其实是在虚拟桌面上的能力升级，它允许你在不同的模式之 间进行快速切换，其实这就是一种通过虚拟环境来实现任务隔离并保持专注的能力。\n现在智能手机中一般也会有类似的功能，比如工作、家庭两个不同的虚拟环境，当然了 我们确实也可以通过多用户切换的方式来达到类似效果，但是activity可能要更优雅些 ，你可以复用这个用户下的应用、数据，只是在不同的高强度任务之间做个隔离，比如 从工作状态一下子切到休闲模式，一键打开需要休闲的程序之类的。\n现在osx里面提出了一种捷径的软件，你可以自定义一些操作，通过捷径来做一些操作 ，但是初衷可能不一样，但可以模拟相同的功能。\n 4.2.12.自定义快捷键shortcuts # Ubuntu Unity、KDE Plasma中都提供了非常丰富的快捷键配置，非常棒！快捷键可以极大地提升操作效率。\n4.2.13.tracking mouse # 这个应该算是一个小小的技巧把，一般在animation effect中进行配置。有的时候，鼠标 颜色难免会难以与其所处的区域进行区分，移动一下鼠标还不容易发现鼠标的位置，怎么 办？开启tracking mouse效果之后，按一下快捷键，就可以发现鼠标的位置了。\n ps：2022.6更新，osx下拼命移动鼠标指针，鼠标指针会变大，也比较容易发现。\n 4.2.14.quick tile windows # 快速地将窗口移动到某一区域（上下左右以及屏幕4个角落）并且使其在该范围内最大化 ，是一个很常用的、有效的操作。很多时候，我们都是同时执行多项任务，并且希望能够 看到多个任务的执行情况，因此，该功能就非常有应用价值了。\nwindows环境中一般有quick tile to left\\right操作，Ubuntu Unity和KDE中一般支持上 下左右以及4个角落的quick tile操作，GNOME3中不清楚，GNOME2中倒是有quick tile to left\\right操作。\n ps：2022.6更新，osx下这点没有linux桌面环境支持的好，基本上要借助工具才能解决 。我目前是使用hammerspoon+lua脚本的方式来对这些功能进行管理。hs的好处是提供 了lua的接口，如果你能看懂文档，懂点变成，就可以写出自己想要的桌面管理软件来 。感兴趣的话可以参考我写的： https://github.com/hitzhangjie/conf/tree/master/macOS-hammerspoon。\n 4.2.15.fcitx+sogou输入法 # 配置一个好用的输入法是至关重要的，特别是在需要中英文混输的情况下，能够快速地在 中英文之间进行切换，并能高效地输入中英文，对于提高输入效率、提高输入体验非常重 要。\n目前在Linux中，最主要的输入法框架主要是给予ibus或者fcitx，其他的都不是很流行。 ibus的话，添加中文输入法之后，可以增加搜狗输入法的词库，但是依然比较鸡肋；最好 的办法就是安装fcitx，然后安装搜狗输入法。\n在Ubuntu 12.04 LTS的时候，由于官方软件源中的fcitx版本较低，不能正常启动搜狗输 入法，因此需要手动添加第三方软件源对fcitx进行更新。现在的Ubuntu 16.04 LTS中 fcitx已经足够新了，直接从搜狗官网上下载deb包进行安装就可以了，比较省事。\n关于搜狗输入法的设置问题，搜狗输入法提供了专门的设置面板，可以修改皮肤、模糊音 等等，提高输入体验。对于输入法切换ctrl+space激活输入法，ctrl+shift在输入法之间 进行切换。\n与windows相比，这里的ctrl+shift在输入法之间进行切换有点差别。在windows中是在所 有的输入法之间进行切换，但是在fcitx中是将所有的输入法分成了两组：Active Group 和Inactive Group，当按下ctrl+shift之后，实际上是在当前group中进行切换，而不是 在所有的输入法之间进行切换。如果要想在所有的输入法之间进行切换，需要进行特别的 设置，如下图所示，勾选上“include inactive input methods when scrolling”。\n ps：2022.6更新，抱歉图片失效了，当初没注意是localhost的链接。\n Ubuntu 16.04 LTS里面有点奇葩，不知道为什么，在.xprofile里面增加export GTK_IM_MODULE=fcitx、export QT_IM_MODULE=fcitx、export XMODIFIERS=\u0026quot;@im=fcitx\u0026quot; 会导致fcitx无法启动。以前在Ubuntu 12.04 LTSu以及Fedora里面都是可以的啊，不晓得 这次是因为什么。wpp（wps里面的演示文稿）需要在启动脚本/usr/bin/wpp中增加上述环 境变量，才能正常输入中文。不然可能运行wpp创建新文件的时候可以输入中文，但是打 开一个已有的ppt文档时就不能够正常输入了。而且更加奇葩的是，wpp里面如果对某一页 演示文稿添加了备注，当切换到这一页的时候，会慢成狗。\n ps：2022.6更新，没想到搜狗被腾讯收购了，变成了一家人，不过现在又要裁员。\n 4.2.16.software-center vs gnome-software # 在ubuntu上面，现在有两款软件安装工具，一个是software-center，ubuntu专属的，另 一个是gnome-software，这个在运行gnome环境的系统上都可以安装，比如在fedora上也可以使用。\n但是gnome-software现在非常不稳定，安装、卸载过程中经常出错，而且对于一些软件组 件（不是一个大型的程序），这种软件包很可能在gnome-software安装列表中就不会出现 。但是ubuntu software-center就可以。怎么说呢，感觉gnome-software不如 software-center实用、健壮，把dpkg数据库搞崩溃了可不是什么好玩的事情。\n ps：使用Linux的一个最大感受就是，free software真香，绝大部分都是免费的，最主 要的还是开放源代码，你可以修改啊，也可以学习。现在用了mac后只能从应用商店买 ，有时候还要找破解版的。鼓励支持正版软件，只是说在Linux下的时候真的感觉很自 由、很放松。从社区中来，到社区中去，从社区中学习，也回馈到社区。给当年自由软 件先驱们个赞！\n 4.2.17.DevHelp # 可以查看glibc的相关手册，极大帮助自己更加深入地学习C语言编程。我下面就要对 glibc中提供的一些特殊的高级数据类型进行学习，例如链表、树、图、map等等。glibc 参考手册如下所示。\n4.2.18.ctags、cscope # 看源代码的，当然了，自己写代码的时候也是用的到的。归根究底，还是要结合vim使用 ，在vim里面可以根据ctags生成的索引进行跳转，例如跳转到函数定义的位置，查看完成 之后再跳转回来。能实现这种功能的原因是ctags生成的索引信息，能够被vim正确解析， vim再执行相应的跳转操作，实现jump to和jump back操作。再将上述跳转操作绑定到其 他快捷键例如[[和]]上将可以极大地提高代码阅读的效率。\n ps：说实话感觉不是很好用。\n 4.2.19.lxr (linux cross reference) # 看源代码，开阔眼界的。lxr也是给予ctags建立索引信息，此外还能够给予swish-e或者 glimpse进行全文检索，因此在阅读代码时检索一个关键词、函数定义、宏定义等方面是 非常方便的。而且lxr支持点击一个函数调用时跳转到相应的函数定义的位置，相当于 jump to的功能，因为lxr是基于浏览器进行访问的，因此可以通过浏览器的历史执行回退 操作，返回到之前的函数调用页面，相当于jump back的操作。\n因为lxr是基于浏览器的、只读的源代码阅读工具，因此在阅读的时候，可以有效避免对 源代码的误修改操作，但是另一方面，我们也不能对源代码添加注释、修改等。\n选择ctags还是lxr关键还是看个人喜好了，我觉得看大型项目的源代码，如果只是本着学 习的目的进行一下阅读的话，那么用lxr好；如果有修改源代码并进行编译、测试等学习 任务的话，最好用ctags。再或者，直接使用某些其他的IDE也是个不错的选择。关键还是 看个人喜好。\n ps：2022.6更新，这个阅读大型项目源码非常赞，不过添加源码比较啰嗦。现在有了比 较好的替代品，sourcegraph。之前学习java jdk的时候用的是在线的grepcode，前几 年倒闭了。现在比较好的就是sourcegraph了。\n 4.2.20.其他 # 肯定还有一些很好的工具，不能一一列举，上面这些事用的比较多的。先分享这些把。\n5.哪里学习Linux # 首先得搞明白要学习linux哪方面？是linux桌面发行版的使用，还是linux系统管理，还 是linux应用开发，还是linux内核开发的知识……幸好，有很多的社区邮件组、讨论组、问 答社区可供我们学习。\nStackExchange \u0026amp; CodeProject \u0026amp; Sourceforge，是极好地学习计算机技术的地方，特别 是这个StackExchange，它真的是包罗万象，而且里面的管理员很有水平，当你的问题描 述不是很准确时，他们还会帮你润色。通常在上面都能得到大佬们的迅速且有效地解答。 我自己是从中受益匪浅。\n学习开发的话，c/c++ primer、glibc学习（常用数据结构等支持很好）、gtk/qt/gnome 开发（图形界面）、make、cmake的使用（项目构建）等等。\n在Linux下面感觉做什么都简单，你想想啊，全世界那么多服务器都是跑在Linux上的，基 于Linux的开发包、经验分享肯定多如牛毛，就是一个字爽。\n"}),a.add({id:517,href:"/tags/documentation/",title:"documentation",description:"",content:""}),a.add({id:518,href:"/blog/2014-10-24-linux%E5%86%85%E6%A0%B8%E6%96%87%E6%A1%A3%E7%B4%A2%E5%BC%95/",title:"Linux内核文档索引",description:"迁移自 hitzhangjie/Study 项目下的内容，本文是看内核源码时对文档的一个阅读、内容总结。\n============================================================================= Fri Sep 18 12:23:06 CST 2014 # Documentation/\n[1] zorro.txt zorro bus ii\\iiioZorro II is the name of the general purpose expansion bus used by the Amiga 2000 computer. The bus is mainly a buffered extension of the Motorola 68000 bus, with support for bus mastering DMA. The expansion slots use a 100-pin connector and the card form factor is the same as the IBM PC. Zorro II cards implement the Autoconfig protocol for automatic address space assignment (designed before, yet similar to, Plug and Play on the PC).",content:"迁移自 hitzhangjie/Study 项目下的内容，本文是看内核源码时对文档的一个阅读、内容总结。\n============================================================================= Fri Sep 18 12:23:06 CST 2014 # Documentation/\n[1] zorro.txt zorro bus ii\\iiioZorro II is the name of the general purpose expansion bus used by the Amiga 2000 computer. The bus is mainly a buffered extension of the Motorola 68000 bus, with support for bus mastering DMA. The expansion slots use a 100-pin connector and the card form factor is the same as the IBM PC. Zorro II cards implement the Autoconfig protocol for automatic address space assignment (designed before, yet similar to, Plug and Play on the PC). Zorro II was succeeded by Zorro III.\n[2] xz.txt XZ is a general purpose data compression format with high compression ratio and relatively fast decompression. The primary compression algorithm (filter) is LZMA2. Additional filters can be used to improve 0010 compression ratio even further. E.g. Branch/Call/Jump (BCJ) filters 0011 improve compression ratio of executable data.\n[3] workqueue.txt There are many cases where an asynchronous process execution context is needed and the workqueue (wq) API is the most commonly used mechanism for such cases. When such an asynchronous execution context is needed, a work item describing which function to execute is put on a queue. An independent thread serves as the asynchronous execution context. The queue is called workqueue and the thread is called worker.\n[4] volatile-considered-harmful.txt C programmers have often taken volatile to mean that the variable could be changed outside of the current thread of execution; as a result, they are sometimes tempted to use it in kernel code when shared data structures are being used. In other words, they have been known to treat volatile types kernel code is almost never correct; this document describes why.\n[5] video-output.txt The output sysfs class driver provides an abstract video output layer that can be used to hook platform specific methods to enable/disable video output device through common sysfs interface.\n[6] vgaarbiter.txt Graphic devices are accessed through ranges in I/O or memory space. While most modern devices allow relocation of such ranges, some \u0026ldquo;Legacy\u0026rdquo; VGA devices implemented on PCI will typically have the same \u0026ldquo;hard-decoded\u0026rdquo; addresses as they did on ISA. For more details see \u0026ldquo;PCI Bus Binding to IEEE Std 1275-1994 Standard for Boot (Initialization Configuration) Firmware Revision 2.1\u0026rdquo; Section 7, Legacy Devices.\n[7] unshare.txt This document describes the new system call, unshare. The document provides an overview of the feature, why it is needed, how it can be used, its interface specification, design, implementation and how it can be tested.\n[8] unicode.txt kernel code has been rewritten to use Unicode to map characters to fonts. By downloading a single Unicode-to-font table, both the eight-bit character sets and UTF-8 mode are changed to use the font as indicated.\n[9] unaligned memory access Linux runs on a wide variety of architectures which have varying behaviour when it comes to memory access. This document presents some details about unaligned accesses, why you need to write code that doesn\u0026rsquo;t cause them, and how to write such code!\n=============================================================================\nFri Sep 19 10:59:56 CST 2014 # [10] sysrq.txt It is a \u0026lsquo;magical\u0026rsquo; key combo you can hit which the kernel will respond to regardless of whatever else it is doing, unless it is completely locked up. Here is the list of possible values in /proc/sys/kernel/sysrq: 0 - disable sysrq completely 1 - enable all functions of sysrq \u0026gt;1 - bitmask of allowed sysrq functions (see below for detailed function description): 2 - enable control of console logging level 4 - enable control of keyboard (SAK, unraw) 8 - enable debugging dumps of processes etc. 16 - enable sync command 32 - enable remount read-only 64 - enable signalling of processes (term, kill, oom-kill) 128 - allow reboot/poweroff 256 - allow nicing of all RT tasks\nYou can set the value in the file by the following command: echo \u0026ldquo;number\u0026rdquo; \u0026gt;/proc/sys/kernel/sysrq\nNote that the value of /proc/sys/kernel/sysrq influences only the invocation via a keyboard. Invocation of any operation via /proc/sysrq-trigger is always allowed (by a user with admin privileges).\nRegarding to how to make invoke the sysrq commands, please refer to the kernel documentation, there\u0026rsquo;s some differences between different architectures including x86, spark and others. some keyboards may generate different keycode sequences, remapping may be required, too.\n[11] sysfs-rules.txt kernel-exported sysfs exports internal kernel implementation details and depends on internal kernel structures and layout. It is agreed upon by the kernel developers that the Linux kernel does not provide a stable internal API. Therefore, there are aspects of the sysfs interface that may not be stable across kernel releases.\nTo minimize the risk of breaking users of sysfs, which are in most cases low-level userspace applications, with a new kernel release, the users of sysfs must follow some rules to use an as-abstract-as-possible way to access this filesystem. The current udev and HAL programs already implement this and users are encouraged to plug, if possible, into the abstractions these programs provide instead of accessing sysfs directly.\nBut if you really do want or need to access sysfs directly, please follow the following rules and then your programs should work with future versions of the sysfs interface.\n[12] svga.txt This small document describes the \u0026ldquo;Video Mode Selection\u0026rdquo; feature which allows the use of various special video modes supported by the video BIOS. Due to usage of the BIOS, the selection is limited to boot time (before the kernel decompression starts) and works only on 80X86 machines.\n[13] stable_kernel_rules.txt Everything you ever wanted to know about Linux -stable releases.\nRules on what kind of patches are accepted, and which ones are not, into the \u0026ldquo;-stable\u0026rdquo; tree:\n It must be obviously correct and tested. It cannot be bigger than 100 lines, with context. It must fix only one thing. It must fix a real bug that bothers people (not a, \u0026ldquo;This could be a problem\u0026hellip;\u0026rdquo; type thing). It must fix a problem that causes a build error (but not for things marked CONFIG_BROKEN), an oops, a hang, data corruption, a real security issue, or some \u0026ldquo;oh, that\u0026rsquo;s not good\u0026rdquo; issue. In short, something critical. Serious issues as reported by a user of a distribution kernel may also be considered if they fix a notable performance or interactivity issue. As these fixes are not as obvious and have a higher risk of a subtle regression they should only be submitted by a distribution kernel maintainer and include an addendum linking to a bugzilla entry if it exists and additional information on the user-visible impact. New device IDs and quirks are also accepted. No \u0026ldquo;theoretical race condition\u0026rdquo; issues, unless an explanation of how the race can be exploited is also provided. It cannot contain any \u0026ldquo;trivial\u0026rdquo; fixes in it (spelling changes, whitespace cleanups, etc). It must follow the Documentation/SubmittingPatches rules. It or an equivalent fix must already exist in Linus' tree (upstream).  Procedure for submitting patches to the -stable tree:\n  Send the patch, after verifying that it follows the above rules, to stable@vger.kernel.org. You must note the upstream commit ID in the changelog of your submission.\n  To have the patch automatically included in the stable tree, add the tag Cc: stable@vger.kernel.org in the sign-off area. Once the patch is merged it will be applied to the stable tree without anything else needing to be done by the author or subsystem maintainer.\n  If the patch requires other patches as prerequisites which can be cherry-picked than this can be specified in the following format in the sign-off area:\nCc: stable@vger.kernel.org # 3.3.x: a1f84a3: sched: Check for idle Cc: stable@vger.kernel.org # 3.3.x: 1b9508f: sched: Rate-limit newidle Cc: stable@vger.kernel.org # 3.3.x: fd21073: sched: Fix affinity logic Cc: stable@vger.kernel.org # 3.3.x Signed-off-by: Ingo Molnar mingo@elte.hu\nThe tag sequence has the meaning of: git cherry-pick a1f84a3 git cherry-pick 1b9508f git cherry-pick fd21073 git cherry-pick   The sender will receive an ACK when the patch has been accepted into the queue, or a NAK if the patch is rejected. This response might take a few days, according to the developer\u0026rsquo;s schedules.\n  If accepted, the patch will be added to the -stable queue, for review by other developers and by the relevant subsystem maintainer.\n  Security patches should not be sent to this alias, but instead to the documented security@kernel.org address.\n  Review cycle:\n When the -stable maintainers decide for a review cycle, the patches will be sent to the review committee, and the maintainer of the affected area of the patch (unless the submitter is the maintainer of the area) and CC: to the linux-kernel mailing list. The review committee has 48 hours in which to ACK or NAK the patch. If the patch is rejected by a member of the committee, or linux-kernel members object to the patch, bringing up issues that the maintainers and members did not realize, the patch will be dropped from the queue. At the end of the review cycle, the ACKed patches will be added to the latest -stable release, and a new -stable release will happen. Security patches will be accepted into the -stable tree directly from the security kernel team, and not go through the normal review cycle. Contact the kernel security team for more details on this procedure.  [14] stable_api_nonsense.txt This is being written to try to explain why Linux does not have a binary kernel interface, nor does it have a stable kernel interface. Please realize that this article describes the in kernel interfaces, not the kernel to userspace interfaces. The kernel to userspace interface is the one that application programs use, the syscall interface. That interface is very stable over time, and will not break. I have old programs that were built on a pre 0.9something kernel that still work just fine on the latest 2.6 kernel release. That interface is the one that users and application programmers can count on being stable.\nthere are two main topics here, binary kernel interfaces and stable kernel source interfaces. They both depend on each other, but we will discuss the binary stuff first to get it out of the way.\nBinary Kernel Interface # Assuming that we had a stable kernel source interface for the kernel, a binary interface would naturally happen too, right? Wrong. Please consider the following facts about the Linux kernel:\n Depending on the version of the C compiler you use, different kernel data structures will contain different alignment of structures, and possibly include different functions in different ways (putting functions inline or not.) The individual function organization isn\u0026rsquo;t that important, but the different data structure padding is very important. Depending on what kernel build options you select, a wide range of different things can be assumed by the kernel:  different structures can contain different fields Some functions may not be implemented at all, (i.e. some locks compile away to nothing for non-SMP builds.) Memory within the kernel can be aligned in different ways, depending on the build options. Linux runs on a wide range of different processor architectures. There is no way that binary drivers from one architecture will run on another architecture properly.    Now a number of these issues can be addressed by simply compiling your module for the exact specific kernel configuration, using the same exact C compiler that the kernel was built with. This is sufficient if you want to provide a module for a specific release version of a specific Linux distribution. But multiply that single build by the number of different Linux distributions and the number of different supported releases of the Linux distribution and you quickly have a nightmare of different build options on different releases. Also realize that each Linux distribution release contains a number of different kernels, all tuned to different hardware types (different processor types and different options), so for even a single release you will need to create multiple versions of your module.\nTrust me, you will go insane over time if you try to support this kind of release, I learned this the hard way a long time ago\u0026hellip;\nStable Kernel Source Interfaces # This is a much more \u0026ldquo;volatile\u0026rdquo; topic if you talk to people who try to keep a Linux kernel driver that is not in the main kernel tree up to date over time.\nLinux kernel development is continuous and at a rapid pace, never stopping to slow down. As such, the kernel developers find bugs in current interfaces, or figure out a better way to do things. If they do that, they then fix the current interfaces to work better. When they do so, function names may change, structures may grow or shrink, and function parameters may be reworked. If this happens, all of the instances of where this interface is used within the kernel are fixed up at the same time, ensuring that everything continues to work properly.\nAs a specific examples of this, the in-kernel USB interfaces have undergone at least three different reworks over the lifetime of this subsystem. These reworks were done to address a number of different issues:\n  A change from a synchronous model of data streams to an asynchronous one. This reduced the complexity of a number of drivers and increased the throughput of all USB drivers such that we are now running almost all USB devices at their maximum speed possible.\n  A change was made in the way data packets were allocated from the USB core by USB drivers so that all drivers now needed to provide more information to the USB core to fix a number of documented deadlocks.\n  This is in stark contrast to a number of closed source operating systems which have had to maintain their older USB interfaces over time. This provides the ability for new developers to accidentally use the old interfaces and do things in improper ways, causing the stability of the operating system to suffer.\nIn both of these instances, all developers agreed that these were important changes that needed to be made, and they were made, with relatively little pain. If Linux had to ensure that it will preserve a stable source interface, a new interface would have been created, and the older, broken one would have had to be maintained over time, leading to extra work for the USB developers. Since all Linux USB developers do their work on their own time, asking programmers to do extra work for no gain, for free, is not a possibility.\nSecurity issues are also very important for Linux. When a security issue is found, it is fixed in a very short amount of time. A number of times this has caused internal kernel interfaces to be reworked to prevent the security problem from occurring. When this happens, all drivers that use the interfaces were also fixed at the same time, ensuring that the security problem was fixed and could not come back at some future time accidentally. If the internal interfaces were not allowed to change, fixing this kind of security problem and insuring that it could not happen again would not be possible.\nKernel interfaces are cleaned up over time. If there is no one using a current interface, it is deleted. This ensures that the kernel remains as small as possible, and that all potential interfaces are tested as well as they can be (unused interfaces are pretty much impossible to test for validity.)\n[15] spinlocks.txt\n自旋锁，这里自旋的意思值得是线程在一个while循环中不停地检查期望的条件是否得到 了满足，如果没有得到满足就等待一段时间，然后继续检查，知道满足之后才会执行后续 的处理。 说白了，自旋就是忙等，我们在以前学习组成原理的时候，了解到cpu与设备的通信方式 主要有3种，分别是程序查询方式（忙等）、中断请求、DMA。其中程序查询方式会中断 cpu的执行，原地踏步，影响cpu的执行效率，可能想到这的时候会认为自旋锁也是这样的 一种锁，这很自然，类比嘛，但是其中有些差别。 我们前面提及的程序查询方式是cpu与硬件设备进行通信的方式，与我们这里操作系统内 部的自旋锁还稍微有些差别，不过，确实是，自旋锁这种排它性锁对系统整体性能可能影 响是比较大的，所以我们在内核中不会用它来长时间阻塞一个线程，而是用它来短暂的阻 塞一个线程，例如将其用于进程调度、线程调度，这个时候，自旋锁在内核中还是非常高 效的。\n另外，实现自旋锁还是比较复杂的，因为要保证能够正确处理可能存在的竟态条件，需要 考虑cpu架构，以及针对这种架构的特殊的汇编指令，例如原子的test、set指令来实现对 自旋锁的加锁、解锁、测试，这在高级语言中是无法做到的。 如果cpu架构中没有原子的这种test、set操作的话，则需要通过某种算法来实现类似的原 子操作。 这样看来，自旋锁是与cpu有关的，好了，现在先不多说了，在看第3个例子的时候，提到 non-irq版本的自旋锁进入临界区后，如果有相同的cpu上有中断到达，并且中断处理函数 中请求相同的自旋锁时，会引发死锁，当讲到这的时候，我们将详细描述自旋锁的实现细 节。\n其实自旋锁效率高不高，还是要看应用的场景，好了下面介绍一下内核中3种常用的自旋 锁。\nLesson 1: Spin locks\nThe most basic primitive for locking is spinlock.\nstatic DEFINE_SPINLOCK(xxx_lock); unsigned long flags; spin_lock_irqsave(\u0026amp;xxx_lock, flags); ... critical section here .. spin_unlock_irqrestore(\u0026amp;xxx_lock, flags); 这里的自旋锁会屏蔽后期到达的中断请求，屏蔽并不是表示忽略，而是将到达的中断 请求暂时保存起来，即irqsave，等临界区代码执行完毕时，再将咱存的中断请求恢 复，即irqrestore。  The above is always safe. It will disable interrupts locally, but the spinlock itself will guarantee the global lock, so it will guarantee that there is only one thread-of-control within the region(s) protected by that lock. This works well even under UP also, so the code does not need to worry about UP vs SMP issues: the spinlocks work correctly under both.\nUP: Uniprocessor，单处理器； SMP: Symmetric Multiprocessor，对称多处理器； spin_lock_irqsave/spin_lock_irqrestore会禁止中断，这种方式使得自旋锁在UP、SMP 两种情况下均适用。\nNOTE! Implications of spin_locks for memory are further described in:\nDocumentation/memory-barriers.txt (5) LOCK operations. (6) UNLOCK operations.  The above is usually pretty simple (you usually need and want only one spinlock for most things - using more than one spinlock can make things a lot more complex and even slower and is usually worth it only for sequences that you know need to be split up: avoid it at all cost if you aren\u0026rsquo;t sure).\nThis is really the only really hard part about spinlocks: once you start using spinlocks they tend to expand to areas you might not have noticed before, because you have to make sure the spinlocks correctly protect the shared data structures everywhere they are used. The spinlocks are most easily added to places that are completely independent of other code (for example, internal driver data structures that nobody else ever touches).\nNOTE! The spin-lock is safe only when you also use the lock itself to do locking across CPU\u0026rsquo;s, which implies that EVERYTHING that touches a shared variable has to agree about the spinlock they want to use.\n Lesson 2: reader-writer spinlocks.\nIf your data accesses have a very natural pattern where you usually tend to mostly read from the shared variables, the reader-writer locks (rw_lock) versions of the spinlocks are sometimes useful. They allow multiple readers to be in the same critical region at once, but if somebody wants to change the variables it has to get an exclusive write lock.\nNOTE! reader-writer locks require more atomic memory operations than simple spinlocks. Unless the reader critical section is long, you are better off just using spinlocks.\n其实这里考虑的还是细粒度加锁，以便提高并行、并发能力。 禁用中断的自旋锁版本是最简单的自旋锁版本，但是它由于是排它性锁，所以对并行性影 响较大； 而自旋锁的另一个版本，读写锁，在读者较多的情况下，能够适当提高并行性，提升系统 性能，但是这种情况下，最好临界区比较长，如果临界区比较短的情况下，并行性能的提 升也不会很明显，这个时候最好使用简单版本的自旋锁。\nThe routines look the same as above:\nrwlock_t xxx_lock = __RW_LOCK_UNLOCKED(xxx_lock); unsigned long flags; read_lock_irqsave(\u0026amp;xxx_lock, flags); .. critical section that only reads the info ... read_unlock_irqrestore(\u0026amp;xxx_lock, flags); write_lock_irqsave(\u0026amp;xxx_lock, flags); .. read and write exclusive access to the info ... write_unlock_irqrestore(\u0026amp;xxx_lock, flags);  The above kind of lock may be useful for complex data structures like linked lists, especially searching for entries without changing the list itself. The read lock allows many concurrent readers. Anything that changes the list will have to get the write lock.\nNOTE! RCU is better for list traversal, but requires careful attention to design detail (see Documentation/RCU/listRCU.txt).\nAlso, you cannot \u0026ldquo;upgrade\u0026rdquo; a read-lock to a write-lock, so if you at any time need to do any changes (even if you don\u0026rsquo;t do it every time), you have to get the write-lock at the very beginning.\nNOTE! We are working hard to remove reader-writer spinlocks in most cases, so please don\u0026rsquo;t add a new one without consensus. (Instead, see Documentation/RCU/rcu.txt for complete information.)\nLesson 3: spinlocks revisited.\nThe single spin-lock primitives above are by no means the only ones. They are the most safe ones, and the ones that work under all circumstances, but partly because they are safe they are also fairly slow. They are slower than they\u0026rsquo;d need to be, because they do have to disable interrupts (which is just a single instruction on a x86, but it\u0026rsquo;s an expensive one - and on other architectures it can be worse).\n这里说的因为前两个版本安全，所以它们慢，这么说的原因，是因为，它们加锁的方式限 制了并行度的提高，以牺牲其他线程的运行来保证安全，这影响了整体的运行效率。\nIf you have a case where you have to protect a data structure across several CPU\u0026rsquo;s and you want to use spinlocks you can potentially use cheaper versions of the spinlocks. IF you know that the spinlocks are never used in interrupt handlers, you can use the non-irq versions:\nnon-irq版本的自旋锁指的是，没有屏蔽中断的自旋锁，当线程进入临界区时，如果这个 时候有中断到达，该中断信号将会被中断处理函数处理，而不是像自旋锁中最简单的那个 版本一样将之irqsave\\irqrestore。\n spin_lock(\u0026amp;lock); ... spin_unlock(\u0026amp;lock);  (and the equivalent read-write versions too, of course). The spinlock will guarantee the same kind of exclusive access, and it will be much faster. This is useful if you know that the data in question is only ever manipulated from a \u0026ldquo;process context\u0026rdquo;, ie no interrupts involved.\nThe reasons you mustn\u0026rsquo;t use these versions if you have interrupts that play with the spinlock is that you can get deadlocks:\n spin_lock(\u0026amp;lock); ... \u0026lt;- interrupt comes in: spin_lock(\u0026amp;lock); 如果在处理器1上加了自旋锁，在进入临界区之后，如果在相同的处理器上有中 断请求，并且处理函数中也请求对相同的自旋锁进行加锁，此时就会发生死锁; 如果该中断是在不同的处理器上的话，则不会引发死锁。 为什么会这样呢，前面讲述各个版本的自旋锁之前，我们提到了自旋锁的实现与 具体的cpu架构以及特殊的汇编指令有关，好的，现在我们讲一下x86架构下，一 个non-irq版本的自旋锁的实现（详细信息参看wiki）： ; Intel syntax locked: ; The lock variable. 1 = locked, 0 = unlocked. dd 0 spin_lock: mov eax, 1 ; Set the EAX register to 1. xchg eax, [locked] ; Atomically swap the EAX register with ; the lock variable. ; This will always store 1 to the lock, leaving ; the previous value in the EAX register. test eax, eax ; Test EAX with itself. Among other things, this will ; set the processor's Zero Flag if EAX is 0. ; If EAX is 0, then the lock was unlocked and ; we just locked it. ; Otherwise, EAX is 1 and we didn't acquire the lock. jnz spin_lock ; Jump back to the MOV instruction if the Zero Flag is ; not set; the lock was previously locked, and so ; we need to spin until it becomes unlocked. ret ; The lock has been acquired, return to the calling ; function. spin_unlock: mov eax, 0 ; Set the EAX register to 0. xchg eax, [locked] ; Atomically swap the EAX register with ; the lock variable. ret ; The lock has been released.  where [an interrupt] tries to lock an already locked variable. This is ok if [the other interrupt] happens on another CPU, but it is not ok if the interrupt happens on the same CPU that already holds the lock, because the lock will obviously never be released (because the interrupt is waiting for the lock, and the lock-holder is interrupted by the interrupt and will not continue until the interrupt has been processed).\n这段话很重要，我翻译翻译！ 在翻译之前，需要指明，文档中有几个地方写的不是很好 ，比如 the other interrupt，其实这个the other interrupt指的就是前面的an interrupt，不指出来理解起来就是误解。\n首先non-irq版本的自旋锁不会屏蔽中断，有中断到达的时候，仍然会对其进行中断处理 ，这一点要明确。\n【当某个中断试图锁定一个已经被锁定的变量时，如果这个中断是在另一个cpu上到达， 那么这种情况下是可行的：\n在当前cpu1上一个线程已经锁定了该变量（non-irq锁），这个时候中断到达到达 cpu2，然后cpu2进入中断的中断处理函数，处理函数中请求对该变量再次加锁，这个 时候，cpu不会允许该加锁，参考上面x86中spinlock的实现，当前[locked]中值为1 ，xchg之后，eax为1，test eax,eax，标志寄存器Z为1，jnz spin_lock继续自旋， 可见此时加锁没有成功，中断会继续自旋直到加锁成功。 如果要加锁成功，就要等到cpu1上的持有锁的线程释放锁，只要它释放了锁，cpu2上 的执行中断处理函数的线程就能够成功对其、进行加锁，二者不会构成死锁。 所以说这种情形下，是可行的！  】\n【当某个中断试图锁定一个已经被锁定的变量时，如果这个中断与当前中断在相同的cpu上 到达，那么这种情况下是不可行的：\n在当前cpu上一个线程已经锁定了该变量（non-irq锁），这个时候中断到达，然后进 入中断的中断处理函数，处理函数中请求对该变量再次加锁，这个时候，cpu不会允 许该加锁，参考上面x86中spinlock的实现，当前[locked]中值为1，xchg之后，eax 为1，test eax,eax，标志寄存器Z为1，jnz spin_lock继续自旋，可见此时加锁没有 成功，中断1会继续自旋直到加锁成功，但是，只有持有该锁的当前线程被中断了， 释放锁的代码不可能被执行，也就是说中断处理函数中会一直阻塞不会返回。中断处 理函数请求加锁，而当前线程作为锁的持有者，又不释放锁，从而造成死锁。 所以说这种情形下，是不可行的！  】\n(This is also the reason why the irq-versions of the spinlocks only need to disable the local interrupts - it\u0026rsquo;s ok to use spinlocks in interrupts on other CPU\u0026rsquo;s, because an interrupt on another CPU doesn\u0026rsquo;t interrupt the CPU that holds the lock, so the lock-holder can continue and eventually releases the lock).\nNote that you can be clever with read-write locks and interrupts. For example, if you know that the interrupt only ever gets a read-lock, then you can use a non-irq version of read locks everywhere - because they don\u0026rsquo;t block on each other (and thus there is no dead-lock wrt interrupts. But when you do the write-lock, you have to use the irq-safe version.\nFor an example of being clever with rw-locks, see the \u0026ldquo;waitqueue_lock\u0026rdquo; handling in kernel/sched.c - nothing ever changes a wait-queue from within an interrupt, they only read the queue in order to know whom to wake up. So read-locks are safe (which is good: they are very common indeed), while write-locks need to protect themselves against interrupts.\n Reference information:\nFor dynamic initialization, use spin_lock_init() or rwlock_init() as appropriate:\nspinlock_t xxx_lock; rwlock_t xxx_rw_lock;\nstatic int __init xxx_init(void) { spin_lock_init(\u0026amp;xxx_lock); rwlock_init(\u0026amp;xxx_rw_lock); \u0026hellip; }\nmodule_init(xxx_init);\nFor static initialization, use DEFINE_SPINLOCK() / DEFINE_RWLOCK() or __SPIN_LOCK_UNLOCKED() / __RW_LOCK_UNLOCKED() as appropriate.\n[16] sparse.txt Using sparse for typechecking\n[17] sgi-viws.txt\nThe SGI Visual Workstations (models 320 and 540) are based around the Cobalt, Lithium, and Arsenic ASICs. The Cobalt ASIC is the main system ASIC which interfaces the 1-4 IA32 cpus, the memory system, and the I/O system in the Lithium ASIC. The Cobalt ASIC also contains the 3D gfx rendering engine which renders to main system memory \u0026ndash; part of which is used as the frame buffer which is DMA\u0026rsquo;ed to a video connector using the Arsenic ASIC. A PIIX4 chip and NS87307 are used to provide legacy device support (IDE, serial, floppy, and parallel).\nThe Visual Workstation chipset largely conforms to the PC architecture with some notable exceptions such as interrupt handling.\n[18] sgi-ioc4.txt\nThe SGI IOC4 PCI device is a bit of a strange beast, so some notes on it are in order.\nFirst, even though the IOC4 performs multiple functions, such as an IDE controller, a serial controller, a PS/2 keyboard/mouse controller, and an external interrupt mechanism, it\u0026rsquo;s not implemented as a multifunction device. The consequence of this from a software standpoint is that all these functions share a single IRQ, and they can\u0026rsquo;t all register to own the same PCI device ID. To make matters a bit worse, some of the register blocks (and even registers themselves) present in IOC4 are mixed-purpose between these several functions, meaning that there\u0026rsquo;s no clear \u0026ldquo;owning\u0026rdquo; device driver.\nThe solution is to organize the IOC4 driver into several independent drivers, \u0026ldquo;ioc4\u0026rdquo;, \u0026ldquo;sgiioc4\u0026rdquo;, and \u0026ldquo;ioc4_serial\u0026rdquo;. Note that there is no PS/2 controller driver as this functionality has never been wired up on a shipping IO card.\n[19] serial-console.txt\nLinux Serial Console\nTo use a serial port as console you need to compile the support into your kernel - by default it is not compiled in. For PC style serial ports it\u0026rsquo;s the config option next to \u0026ldquo;Standard/generic (dumb) serial support\u0026rdquo;. You must compile serial support into the kernel and not as a module.\nIt is possible to specify multiple devices for console output. You can define a new kernel command line option to select which device(s) to use for console output.\nThe format of this option is:\nconsole=device,options\ndevice: tty0 for the foreground virtual console ttyX for any other virtual console ttySx for a serial port lp0 for the first parallel port ttyUSB0 for the first USB serial device\noptions: depend on the driver. For the serial port this defines the baudrate/parity/bits/flow control of the port, in the format BBBBPNF, where BBBB is the speed, P is parity (n/o/e), N is number of bits, and F is flow control (\u0026lsquo;r\u0026rsquo; for RTS). Default is 9600n8. The maximum baudrate is 115200.\nYou can specify multiple console= options on the kernel command line. Output will appear on all of them. The last device will be used when you open /dev/console. So, for example:\nconsole=ttyS1,9600 console=tty0\ndefines that opening /dev/console will get you the current foreground virtual console, and kernel messages will appear on both the VGA console and the 2nd serial port (ttyS1 or COM2) at 9600 baud.\nNote that you can only define one console per device type (serial, video).\nIf no console device is specified, the first device found capable of acting as a system console will be used. At this time, the system first looks for a VGA card and then for a serial port. So if you don\u0026rsquo;t have a VGA card in your system the first serial port will automatically become the console.\nYou will need to create a new device to use /dev/console. The official /dev/console is now character device 5,1.\n(You can also use a network device as a console. See Documentation/networking/netconsole.txt for information on that.)\nHere\u0026rsquo;s an example that will use /dev/ttyS1 (COM2) as the console. Replace the sample values as needed.\n Create /dev/console (real console) and /dev/tty0 (master virtual console):  cd /dev rm -f console tty0 mknod -m 622 console c 5 1 mknod -m 622 tty0 c 4 0\nLILO can also take input from a serial device. This is a very useful option. To tell LILO to use the serial port: In lilo.conf (global section):  serial = 1,9600n8 (ttyS1, 9600 bd, no parity, 8 bits)\nAdjust to kernel flags for the new kernel, again in lilo.conf (kernel section)  append = \u0026ldquo;console=ttyS1,9600\u0026rdquo;\nMake sure a getty runs on the serial port so that you can login to it once the system is done booting. This is done by adding a line like this to /etc/inittab (exact syntax depends on your getty):  S1:23:respawn:/sbin/getty -L ttyS1 9600 vt100\nInit and /etc/ioctl.save  Sysvinit remembers its stty settings in a file in /etc, called `/etc/ioctl.save'. REMOVE THIS FILE before using the serial console for the first time, because otherwise init will probably set the baudrate to 38400 (baudrate of the virtual console).\n/dev/console and X Programs that want to do something with the virtual console usually open /dev/console. If you have created the new /dev/console device, and your console is NOT the virtual console some programs will fail. Those are programs that want to access the VT interface, and use /dev/console instead of /dev/tty0. Some of those programs are:  Xfree86, svgalib, gpm, SVGATextMode\nIt should be fixed in modern versions of these programs though.\nNote that if you boot without a console= option (or with console=/dev/tty0), /dev/console is the same as /dev/tty0. In that case everything will still work.\n[20] rtc.txt\nReal Time Clock (RTC) Drivers for Linux\n[21] rt-mutex.txt\nRT-mutex subsystem with PI support\n这个地方PI指的是Priority Inheritance。\n RT-mutexes with priority inheritance are used to support PI-futexes, which enable pthread_mutex_t priority inheritance attributes (PTHREAD_PRIO_INHERIT). [See Documentation/pi-futex.txt for more details about PI-futexes.]\nThis technology was developed in the -rt tree and streamlined for pthread_mutex support.\nBasic principles: # RT-mutexes extend the semantics of simple mutexes by the priority inheritance protocol. RT-mutexes通过优先级继承协议，扩展了简单mutex的语义。\nA low priority owner of a rt-mutex inherits the priority of a higher priority waiter until the rt-mutex is released. If the temporarily boosted owner blocks on a rt-mutex itself it propagates the priority boosting to the owner of the other rt_mutex it gets blocked on. The priority boosting is immediately removed once the rt_mutex has been unlocked.\nrt-mutex的一个低优先级持有者，可以继承等待该rt-mutex的一个高优先级任务的优先级 ，低优先级持有者获取了高优先级任务的优先级之后，在内核任务调度时会获取更多的机 会，能够尽快执行完任务，更早地释放rt-mutex，从而让高优先级任务不用因为等待低优 先级任务释放锁而浪费太多时间。在低优先级任务释放锁之后，将恢复到以前的低优先级 。\n假如一个获取了rt-mutex（记为m1）的低优先级任务继承了一个等待该锁的高优先级任务 的优先级，此时如果该低优先级任务还希望获取另一个rt-mutex（记为m2），那么该低优 先级会将继承到的高优先级任务的优先级传递给锁m2的持有者。如果m2的持有者因为获取 高优先级提前完成了任务并释放锁，那么m1的持有者也会提前获得锁m2并尽快完成任务， 并释放锁m1、m2，从而使得高优先级任务尽快获得锁m1.这样看来，rt-mutex优先级的继 承，对系统整体性能来说会是一大改进。\nThis approach allows us to shorten the block of high-prio tasks on mutexes which protect shared resources. Priority inheritance is not a magic bullet for poorly designed applications, but it allows well-designed applications to use userspace locks in critical parts of an high priority thread, without losing determinism.\nThe enqueueing of the waiters into the rtmutex waiter list is done in priority order. For same priorities FIFO order is chosen. For each rtmutex, only the top priority waiter is enqueued into the owner\u0026rsquo;s priority waiters list. This list too queues in priority order. Whenever the top priority waiter of a task changes (for example it timed out or got a signal), the priority of the owner task is readjusted. [The priority enqueueing is handled by \u0026ldquo;plists\u0026rdquo;, see\n等待rt-mutex的任务按照优先级顺序进入该rt-mutex的等待队列。如果任务是相同的优先 级，则按照先请求先进入队列的原则。对于每一个rt-mutex，只有优先级最高的处于等待 状态的任务会被选择进入锁持有者的优先级等待者队列中，并且这个队列也是按照优先级 进行排序。不管什么时候，这个任务的优先级等待队列的最高优先级的任务发生改变，这 个任务的优先级都会被进行重新调整。\ninclude/linux/plist.h for more details.]\nRT-mutexes are optimized for fastpath operations and have no internal locking overhead when locking an uncontended mutex or unlocking a mutex without waiters. The optimized fastpath operations require cmpxchg support. [If that is not available then the rt-mutex internal spinlock is used]\nThe state of the rt-mutex is tracked via the owner field of the rt-mutex structure:\nrt_mutex-\u0026gt;owner holds the task_struct pointer of the owner. Bit 0 and 1 are used to keep track of the \u0026ldquo;owner is pending\u0026rdquo; and \u0026ldquo;rtmutex has waiters\u0026rdquo; state.\nowner bit1 bit0 NULL 0 0 mutex is free (fast acquire possible) NULL 0 1 invalid state NULL 1 0 Transitional state* NULL 1 1 invalid state taskpointer 0 0 mutex is held (fast release possible) taskpointer 0 1 task is pending owner taskpointer 1 0 mutex is held and has waiters taskpointer 1 1 task is pending owner and mutex has waiters\nPending-ownership handling is a performance optimization: pending-ownership is assigned to the first (highest priority) waiter of the mutex, when the mutex is released. The thread is woken up and once it starts executing it can acquire the mutex. Until the mutex is taken by it (bit 0 is cleared) a competing higher priority thread can \u0026ldquo;steal\u0026rdquo; the mutex which puts the woken up thread back on the waiters list.\nThe pending-ownership optimization is especially important for the uninterrupted workflow of high-prio tasks which repeatedly takes/releases locks that have lower-prio waiters. Without this optimization the higher-prio thread would ping-pong to the lower-prio task [because at unlock time we always assign a new owner].\n(*) The \u0026ldquo;mutex has waiters\u0026rdquo; bit gets set to take the lock. If the lock doesn\u0026rsquo;t already have an owner, this bit is quickly cleared if there are no waiters. So this is a transitional state to synchronize with looking at the owner field of the mutex and the mutex owner releasing the lock.\n[22] rt-mutex-design.txt\nRT-mutex implementation design # This document tries to describe the design of the rtmutex.c implementation. It doesn\u0026rsquo;t describe the reasons why rtmutex.c exists. For that please see Documentation/rt-mutex.txt. Although this document does explain problems that happen without this code, but that is in the concept to understand what the code actually is doing.\n这个文档解释rtmutex的具体设计，关于为什么要实现rtmutex，请参考前面21这部分。\nThe goal of this document is to help others understand the priority inheritance (PI) algorithm that is used, as well as reasons for the decisions that were made to implement PI in the manner that was done.\n这个文档的目的是为了帮助别人理解使用的优先级继承算法，以及实现该算法过程中采用 的某些相关决策的原因。\nUnbounded Priority Inversion # Priority inversion is when a lower priority process executes while a higher priority process wants to run. This happens for several reasons, and most of the time it can\u0026rsquo;t be helped. Anytime a high priority process wants to use a resource that a lower priority process has (a mutex for example), the high priority process must wait until the lower priority process is done with the resource. This is a priority inversion. What we want to prevent is something called unbounded priority inversion. That is when the high priority process is prevented from running by a lower priority process for an undetermined amount of time.\n理解优先级反转，优先级反转指的是，当一个低优先级进程执行的时候，同时有一个高优 先级进程也希望执行。这在很多情况下都会发生，并且大多数情况下是无法被干预的。某 个时候，如果一个高优先级进车功能希望使用一个低优先级进程拥有的资源，例如一个锁 ，高优先级进程不得不等待到低优先级进程释放这个资源，然后才能获取到该资源，并继 续执行。本来高优先级的进程应该先于低优先级进程执行，但是这里，却因为等待低优先 级进程释放资源而等待，并且等待的时间是无法确定的，这种情况我们称之为优先级反转 。 我们希望能够阻止不受限制的优先级反转，即，当一个高优先级进程被一个低优先级进程 阻塞，并且阻塞时间不缺定，我们需要阻止或者尽量避免这种情况。\nThe classic example of unbounded priority inversion is were you have three processes, let\u0026rsquo;s call them processes A, B, and C, where A is the highest priority process, C is the lowest, and B is in between. A tries to grab a lock that C owns and must wait and lets C run to release the lock. But in the meantime, B executes, and since B is of a higher priority than C, it preempts C, but by doing so, it is in fact preempting A which is a higher priority process. Now there\u0026rsquo;s no way of knowing how long A will be sleeping waiting for C to release the lock, because for all we know, B is a CPU hog and will never give C a chance to release the lock. This is called unbounded priority inversion.\n举个不受限制的优先级反转的例子，假定有3个进程A、B、C，优先级依次降低，现在A希 望获取一个锁，这个锁被C持有，因此A需要等待到C执行到释放锁后才能继续向下执行， 假定在C释放锁之前，B开始执行，由于B优先级比C高，有可能B会抢占CPU而先于C执行， 假定B占用的CPU时间比较长，例如B是一个while(1)循环，它不会给C机会区释放锁，因此 间接地阻止了最高优先级进程A的执行，并且A继续等待的事件会很长甚至是永久，这被称 之为不受限制的优先级反转。\nHere\u0026rsquo;s a little ASCII art to show the problem.\ngrab lock L1 (owned by C) | A ---+ C preempted by B | C +----+ B +--------\u0026gt; B now keeps A from running.  Priority Inheritance (PI) # There are several ways to solve this issue, but other ways are out of scope for this document. Here we only discuss PI.\n有很多方法来解决不受限制的优先级反转问题，但是这里值讨论优先级继承PI这种方法。\nPI is where a process inherits the priority of another process if the other process blocks on a lock owned by the current process. To make this easier to understand, let\u0026rsquo;s use the previous example, with processes A, B, and C again.\nThis time, when A blocks on the lock owned by C, C would inherit the priority of A. So now if B becomes runnable, it would not preempt C, since C now has the high priority of A. As soon as C releases the lock, it loses its inherited priority, and A then can continue with the resource that C had.\n以上个例子为例，引入PI，这次，当A等待C释放锁而阻塞时，C会继承A的优先级。所以如 果B运行的时候，它不会抢占C的CPU，因为C已经继承了A的优先级，A的优先级是最高的。 一旦C释放了锁之后，它就会失去从A继承来的优先级，A然后就会获得C释放的锁并继续执 行。\nTerminology # Here I explain some terminology that is used in this document to help describe the design that is used to implement PI.\nPI chain - The PI chain is an ordered series of locks and processes that cause processes to inherit priorities from a previous process that is blocked on one of its locks. This is described in more detail later in this document.\n 优先级继承链。  mutex - In this document, to differentiate from locks that implement PI and spin locks that are used in the PI code, from now on the PI locks will be called a mutex.\n 在这篇文档中，为了区分实现了优先级继承的锁，和实现该锁的代码中用到 的普通的自旋锁，从现在开始，实现了优先级继承的锁，将被称为mutex。  lock - In this document from now on, I will use the term lock when referring to spin locks that are used to protect parts of the PI algorithm. These locks disable preemption for UP (when CONFIG_PREEMPT is enabled) and on SMP prevents multiple CPUs from entering critical sections simultaneously.\n 在这篇文档中，将使用lock指代自旋锁。  spin lock - Same as lock above.\n 自旋锁，与我们上面提到的lock，在描述PI锁的时候，将表示相同的概念。  waiter - A waiter is a struct that is stored on the stack of a blocked process. Since the scope of the waiter is within the code for a process being blocked on the mutex, it is fine to allocate the waiter on the process\u0026rsquo;s stack (local variable). This structure holds a pointer to the task, as well as the mutex that the task is blocked on. It also has the plist node structures to place the task in the waiter_list of a mutex as well as the pi_list of a mutex owner task (described below).\n waiter is sometimes used in reference to the task that is waiting on a mutex. This is the same as waiter-\u0026gt;task.  waiters - A list of processes that are blocked on a mutex.\ntop waiter - The highest priority process waiting on a specific mutex.\ntop pi waiter - The highest priority process waiting on one of the mutexes that a specific process owns.\nNote: task and process are used interchangeably in this document, mostly to differentiate between two processes that are being described together.\nPI chain # The PI chain is a list of processes and mutexes that may cause priority inheritance to take place. Multiple chains may converge, but a chain would never diverge, since a process can\u0026rsquo;t be blocked on more than one mutex at a time.\nExample:\nProcess: A, B, C, D, E Mutexes: L1, L2, L3, L4\nA owns: L1 B blocked on L1 B owns L2 C blocked on L2 C owns L3 D blocked on L3 D owns L4 E blocked on L4  The chain would be:\nE-\u0026gt;L4-\u0026gt;D-\u0026gt;L3-\u0026gt;C-\u0026gt;L2-\u0026gt;B-\u0026gt;L1-\u0026gt;A\nTo show where two chains merge, we could add another process F and another mutex L5 where B owns L5 and F is blocked on mutex L5.\nThe chain for F would be:\nF-\u0026gt;L5-\u0026gt;B-\u0026gt;L1-\u0026gt;A\nSince a process may own more than one mutex, but never be blocked on more than one, the chains merge.\nHere we show both chains:\nE-\u0026gt;L4-\u0026gt;D-\u0026gt;L3-\u0026gt;C-\u0026gt;L2-+ | +-\u0026gt;B-\u0026gt;L1-\u0026gt;A | F-\u0026gt;L5-+  For PI to work, the processes at the right end of these chains (or we may also call it the Top of the chain) must be equal to or higher in priority than the processes to the left or below in the chain.\nAlso since a mutex may have more than one process blocked on it, we can have multiple chains merge at mutexes. If we add another process G that is blocked on mutex L2:\nG-\u0026gt;L2-\u0026gt;B-\u0026gt;L1-\u0026gt;A\nAnd once again, to show how this can grow I will show the merging chains again.\nE-\u0026gt;L4-\u0026gt;D-\u0026gt;L3-\u0026gt;C-+ +-\u0026gt;L2-+ | | G-+ +-\u0026gt;B-\u0026gt;L1-\u0026gt;A | F-\u0026gt;L5-+  Plist # Before I go further and talk about how the PI chain is stored through lists on both mutexes and processes, I\u0026rsquo;ll explain the plist. This is similar to the struct list_head functionality that is already in the kernel. The implementation of plist is out of scope for this document, but it is very important to understand what it does.\nThere are a few differences between plist and list, the most important one being that plist is a priority sorted linked list. This means that the priorities of the plist are sorted, such that it takes O(1) to retrieve the highest priority item in the list. Obviously this is useful to store processes based on their priorities.\nAnother difference, which is important for implementation, is that, unlike list, the head of the list is a different element than the nodes of a list. So the head of the list is declared as struct plist_head and nodes that will be added to the list are declared as struct plist_node.\nMutex Waiter List # Every mutex keeps track of all the waiters that are blocked on itself. The mutex has a plist to store these waiters by priority. This list is protected by a spin lock that is located in the struct of the mutex. This lock is called wait_lock. Since the modification of the waiter list is never done in interrupt context, the wait_lock can be taken without disabling interrupts.\nTask PI List # To keep track of the PI chains, each process has its own PI list. This is a list of all top waiters of the mutexes that are owned by the process. Note that this list only holds the top waiters and not all waiters that are blocked on mutexes owned by the process.\nThe top of the task\u0026rsquo;s PI list is always the highest priority task that is waiting on a mutex that is owned by the task. So if the task has inherited a priority, it will always be the priority of the task that is at the top of this list.\nThis list is stored in the task structure of a process as a plist called pi_list. This list is protected by a spin lock also in the task structure, called pi_lock. This lock may also be taken in interrupt context, so when locking the pi_lock, interrupts must be disabled.\nDepth of the PI Chain # The maximum depth of the PI chain is not dynamic, and could actually be defined. But is very complex to figure it out, since it depends on all the nesting of mutexes. Let\u0026rsquo;s look at the example where we have 3 mutexes, L1, L2, and L3, and four separate functions func1, func2, func3 and func4. The following shows a locking order of L1-\u0026gt;L2-\u0026gt;L3, but may not actually be directly nested that way.\nvoid func1(void) { mutex_lock(L1);\n/* do anything */ mutex_unlock(L1);  }\nvoid func2(void) { mutex_lock(L1); mutex_lock(L2);\n/* do something */ mutex_unlock(L2); mutex_unlock(L1);  }\nvoid func3(void) { mutex_lock(L2); mutex_lock(L3);\n/* do something else */ mutex_unlock(L3); mutex_unlock(L2);  }\nvoid func4(void) { mutex_lock(L3);\n/* do something again */ mutex_unlock(L3);  }\nNow we add 4 processes that run each of these functions separately. Processes A, B, C, and D which run functions func1, func2, func3 and func4 respectively, and such that D runs first and A last. With D being preempted in func4 in the \u0026ldquo;do something again\u0026rdquo; area, we have a locking that follows:\nD owns L3 C blocked on L3 C owns L2 B blocked on L2 B owns L1 A blocked on L1\nAnd thus we have the chain A-\u0026gt;L1-\u0026gt;B-\u0026gt;L2-\u0026gt;C-\u0026gt;L3-\u0026gt;D.\nThis gives us a PI depth of 4 (four processes), but looking at any of the functions individually, it seems as though they only have at most a locking depth of two. So, although the locking depth is defined at compile time, it still is very difficult to find the possibilities of that depth.\nNow since mutexes can be defined by user-land applications, we don\u0026rsquo;t want a DOS type of application that nests large amounts of mutexes to create a large PI chain, and have the code holding spin locks while looking at a large amount of data. So to prevent this, the implementation not only implements a maximum lock depth, but also only holds at most two different locks at a time, as it walks the PI chain. More about this below.\nMutex owner and flags # The mutex structure contains a pointer to the owner of the mutex. If the mutex is not owned, this owner is set to NULL. Since all architectures have the task structure on at least a four byte alignment (and if this is not true, the rtmutex.c code will be broken!), this allows for the two least significant bits to be used as flags. This part is also described in Documentation/rt-mutex.txt, but will also be briefly described here.\nBit 0 is used as the \u0026ldquo;Pending Owner\u0026rdquo; flag. This is described later. Bit 1 is used as the \u0026ldquo;Has Waiters\u0026rdquo; flags. This is also described later in more detail, but is set whenever there are waiters on a mutex.\ncmpxchg Tricks # Some architectures implement an atomic cmpxchg (Compare and Exchange). This is used (when applicable) to keep the fast path of grabbing and releasing mutexes short.\ncmpxchg is basically the following function performed atomically:\nunsigned long _cmpxchg(unsigned long *A, unsigned long *B, unsigned long *C) { unsigned long T = *A; if (*A == *B) { *A = *C; } return T; } #define cmpxchg(a,b,c) _cmpxchg(\u0026amp;a,\u0026amp;b,\u0026amp;c)\nThis is really nice to have, since it allows you to only update a variable if the variable is what you expect it to be. You know if it succeeded if the return value (the old value of A) is equal to B.\nThe macro rt_mutex_cmpxchg is used to try to lock and unlock mutexes. If the architecture does not support CMPXCHG, then this macro is simply set to fail every time. But if CMPXCHG is supported, then this will help out extremely to keep the fast path short.\nThe use of rt_mutex_cmpxchg with the flags in the owner field help optimize the system for architectures that support it. This will also be explained later in this document.\nPriority adjustments # The implementation of the PI code in rtmutex.c has several places that a process must adjust its priority. With the help of the pi_list of a process this is rather easy to know what needs to be adjusted.\nThe functions implementing the task adjustments are rt_mutex_adjust_prio, __rt_mutex_adjust_prio (same as the former, but expects the task pi_lock to already be taken), rt_mutex_getprio, and rt_mutex_setprio.\nrt_mutex_getprio and rt_mutex_setprio are only used in __rt_mutex_adjust_prio.\nrt_mutex_getprio returns the priority that the task should have. Either the task\u0026rsquo;s own normal priority, or if a process of a higher priority is waiting on a mutex owned by the task, then that higher priority should be returned. Since the pi_list of a task holds an order by priority list of all the top waiters of all the mutexes that the task owns, rt_mutex_getprio simply needs to compare the top pi waiter to its own normal priority, and return the higher priority back.\n(Note: if looking at the code, you will notice that the lower number of prio is returned. This is because the prio field in the task structure is an inverse order of the actual priority. So a \u0026ldquo;prio\u0026rdquo; of 5 is of higher priority than a \u0026ldquo;prio\u0026rdquo; of 10.)\n__rt_mutex_adjust_prio examines the result of rt_mutex_getprio, and if the result does not equal the task\u0026rsquo;s current priority, then rt_mutex_setprio is called to adjust the priority of the task to the new priority. Note that rt_mutex_setprio is defined in kernel/sched.c to implement the actual change in priority.\nIt is interesting to note that __rt_mutex_adjust_prio can either increase or decrease the priority of the task. In the case that a higher priority process has just blocked on a mutex owned by the task, __rt_mutex_adjust_prio would increase/boost the task\u0026rsquo;s priority. But if a higher priority task were for some reason to leave the mutex (timeout or signal), this same function would decrease/unboost the priority of the task. That is because the pi_list always contains the highest priority task that is waiting on a mutex owned by the task, so we only need to compare the priority of that top pi waiter to the normal priority of the given task.\nHigh level overview of the PI chain walk # The PI chain walk is implemented by the function rt_mutex_adjust_prio_chain.\nThe implementation has gone through several iterations, and has ended up with what we believe is the best. It walks the PI chain by only grabbing at most two locks at a time, and is very efficient.\nThe rt_mutex_adjust_prio_chain can be used either to boost or lower process priorities.\nrt_mutex_adjust_prio_chain is called with a task to be checked for PI (de)boosting (the owner of a mutex that a process is blocking on), a flag to check for deadlocking, the mutex that the task owns, and a pointer to a waiter that is the process\u0026rsquo;s waiter struct that is blocked on the mutex (although this parameter may be NULL for deboosting).\nFor this explanation, I will not mention deadlock detection. This explanation will try to stay at a high level.\nWhen this function is called, there are no locks held. That also means that the state of the owner and lock can change when entered into this function.\nBefore this function is called, the task has already had rt_mutex_adjust_prio performed on it. This means that the task is set to the priority that it should be at, but the plist nodes of the task\u0026rsquo;s waiter have not been updated with the new priorities, and that this task may not be in the proper locations in the pi_lists and wait_lists that the task is blocked on. This function solves all that.\nA loop is entered, where task is the owner to be checked for PI changes that was passed by parameter (for the first iteration). The pi_lock of this task is taken to prevent any more changes to the pi_list of the task. This also prevents new tasks from completing the blocking on a mutex that is owned by this task.\nIf the task is not blocked on a mutex then the loop is exited. We are at the top of the PI chain.\nA check is now done to see if the original waiter (the process that is blocked on the current mutex) is the top pi waiter of the task. That is, is this waiter on the top of the task\u0026rsquo;s pi_list. If it is not, it either means that there is another process higher in priority that is blocked on one of the mutexes that the task owns, or that the waiter has just woken up via a signal or timeout and has left the PI chain. In either case, the loop is exited, since we don\u0026rsquo;t need to do any more changes to the priority of the current task, or any task that owns a mutex that this current task is waiting on. A priority chain walk is only needed when a new top pi waiter is made to a task.\nThe next check sees if the task\u0026rsquo;s waiter plist node has the priority equal to the priority the task is set at. If they are equal, then we are done with the loop. Remember that the function started with the priority of the task adjusted, but the plist nodes that hold the task in other processes pi_lists have not been adjusted.\nNext, we look at the mutex that the task is blocked on. The mutex\u0026rsquo;s wait_lock is taken. This is done by a spin_trylock, because the locking order of the pi_lock and wait_lock goes in the opposite direction. If we fail to grab the lock, the pi_lock is released, and we restart the loop.\nNow that we have both the pi_lock of the task as well as the wait_lock of the mutex the task is blocked on, we update the task\u0026rsquo;s waiter\u0026rsquo;s plist node that is located on the mutex\u0026rsquo;s wait_list.\nNow we release the pi_lock of the task.\nNext the owner of the mutex has its pi_lock taken, so we can update the task\u0026rsquo;s entry in the owner\u0026rsquo;s pi_list. If the task is the highest priority process on the mutex\u0026rsquo;s wait_list, then we remove the previous top waiter from the owner\u0026rsquo;s pi_list, and replace it with the task.\nNote: It is possible that the task was the current top waiter on the mutex, in which case the task is not yet on the pi_list of the waiter. This is OK, since plist_del does nothing if the plist node is not on any list.\nIf the task was not the top waiter of the mutex, but it was before we did the priority updates, that means we are deboosting/lowering the task. In this case, the task is removed from the pi_list of the owner, and the new top waiter is added.\nLastly, we unlock both the pi_lock of the task, as well as the mutex\u0026rsquo;s wait_lock, and continue the loop again. On the next iteration of the loop, the previous owner of the mutex will be the task that will be processed.\nNote: One might think that the owner of this mutex might have changed since we just grab the mutex\u0026rsquo;s wait_lock. And one could be right. The important thing to remember is that the owner could not have become the task that is being processed in the PI chain, since we have taken that task\u0026rsquo;s pi_lock at the beginning of the loop. So as long as there is an owner of this mutex that is not the same process as the tasked being worked on, we are OK.\nLooking closely at the code, one might be confused. The check for the end of the PI chain is when the task isn\u0026rsquo;t blocked on anything or the task\u0026rsquo;s waiter structure \u0026ldquo;task\u0026rdquo; element is NULL. This check is protected only by the task\u0026rsquo;s pi_lock. But the code to unlock the mutex sets the task\u0026rsquo;s waiter structure \u0026ldquo;task\u0026rdquo; element to NULL with only the protection of the mutex\u0026rsquo;s wait_lock, which was not taken yet. Isn\u0026rsquo;t this a race condition if the task becomes the new owner?\nThe answer is No! The trick is the spin_trylock of the mutex\u0026rsquo;s wait_lock. If we fail that lock, we release the pi_lock of the task and continue the loop, doing the end of PI chain check again.\nIn the code to release the lock, the wait_lock of the mutex is held the entire time, and it is not let go when we grab the pi_lock of the new owner of the mutex. So if the switch of a new owner were to happen after the check for end of the PI chain and the grabbing of the wait_lock, the unlocking code would spin on the new owner\u0026rsquo;s pi_lock but never give up the wait_lock. So the PI chain loop is guaranteed to fail the spin_trylock on the wait_lock, release the pi_lock, and try again.\nIf you don\u0026rsquo;t quite understand the above, that\u0026rsquo;s OK. You don\u0026rsquo;t have to, unless you really want to make a proof out of it ;)\nPending Owners and Lock stealing # One of the flags in the owner field of the mutex structure is \u0026ldquo;Pending Owner\u0026rdquo;. What this means is that an owner was chosen by the process releasing the mutex, but that owner has yet to wake up and actually take the mutex.\nWhy is this important? Why can\u0026rsquo;t we just give the mutex to another process and be done with it?\nThe PI code is to help with real-time processes, and to let the highest priority process run as long as possible with little latencies and delays. If a high priority process owns a mutex that a lower priority process is blocked on, when the mutex is released it would be given to the lower priority process. What if the higher priority process wants to take that mutex again. The high priority process would fail to take that mutex that it just gave up and it would need to boost the lower priority process to run with full latency of that critical section (since the low priority process just entered it).\nThere\u0026rsquo;s no reason a high priority process that gives up a mutex should be penalized if it tries to take that mutex again. If the new owner of the mutex has not woken up yet, there\u0026rsquo;s no reason that the higher priority process could not take that mutex away.\nTo solve this, we introduced Pending Ownership and Lock Stealing. When a new process is given a mutex that it was blocked on, it is only given pending ownership. This means that it\u0026rsquo;s the new owner, unless a higher priority process comes in and tries to grab that mutex. If a higher priority process does come along and wants that mutex, we let the higher priority process \u0026ldquo;steal\u0026rdquo; the mutex from the pending owner (only if it is still pending) and continue with the mutex.\nTaking of a mutex (The walk through) # OK, now let\u0026rsquo;s take a look at the detailed walk through of what happens when taking a mutex.\nThe first thing that is tried is the fast taking of the mutex. This is done when we have CMPXCHG enabled (otherwise the fast taking automatically fails). Only when the owner field of the mutex is NULL can the lock be taken with the CMPXCHG and nothing else needs to be done.\nIf there is contention on the lock, whether it is owned or pending owner we go about the slow path (rt_mutex_slowlock).\nThe slow path function is where the task\u0026rsquo;s waiter structure is created on the stack. This is because the waiter structure is only needed for the scope of this function. The waiter structure holds the nodes to store the task on the wait_list of the mutex, and if need be, the pi_list of the owner.\nThe wait_lock of the mutex is taken since the slow path of unlocking the mutex also takes this lock.\nWe then call try_to_take_rt_mutex. This is where the architecture that does not implement CMPXCHG would always grab the lock (if there\u0026rsquo;s no contention).\ntry_to_take_rt_mutex is used every time the task tries to grab a mutex in the slow path. The first thing that is done here is an atomic setting of the \u0026ldquo;Has Waiters\u0026rdquo; flag of the mutex\u0026rsquo;s owner field. Yes, this could really be false, because if the mutex has no owner, there are no waiters and the current task also won\u0026rsquo;t have any waiters. But we don\u0026rsquo;t have the lock yet, so we assume we are going to be a waiter. The reason for this is to play nice for those architectures that do have CMPXCHG. By setting this flag now, the owner of the mutex can\u0026rsquo;t release the mutex without going into the slow unlock path, and it would then need to grab the wait_lock, which this code currently holds. So setting the \u0026ldquo;Has Waiters\u0026rdquo; flag forces the owner to synchronize with this code.\nNow that we know that we can\u0026rsquo;t have any races with the owner releasing the mutex, we check to see if we can take the ownership. This is done if the mutex doesn\u0026rsquo;t have a owner, or if we can steal the mutex from a pending owner. Let\u0026rsquo;s look at the situations we have here.\n Has owner that is pending   The mutex has a owner, but it hasn\u0026rsquo;t woken up and the mutex flag \u0026ldquo;Pending Owner\u0026rdquo; is set. The first check is to see if the owner isn\u0026rsquo;t the current task. This is because this function is also used for the pending owner to grab the mutex. When a pending owner wakes up, it checks to see if it can take the mutex, and this is done if the owner is already set to itself. If so, we succeed and leave the function, clearing the \u0026ldquo;Pending Owner\u0026rdquo; bit.\nIf the pending owner is not current, we check to see if the current priority is higher than the pending owner. If not, we fail the function and return.\nThere\u0026rsquo;s also something special about a pending owner. That is a pending owner is never blocked on a mutex. So there is no PI chain to worry about. It also means that if the mutex doesn\u0026rsquo;t have any waiters, there\u0026rsquo;s no accounting needed to update the pending owner\u0026rsquo;s pi_list, since we only worry about processes blocked on the current mutex.\nIf there are waiters on this mutex, and we just stole the ownership, we need to take the top waiter, remove it from the pi_list of the pending owner, and add it to the current pi_list. Note that at this moment, the pending owner is no longer on the list of waiters. This is fine, since the pending owner would add itself back when it realizes that it had the ownership stolen from itself. When the pending owner tries to grab the mutex, it will fail in try_to_take_rt_mutex if the owner field points to another process.\nNo owner   If there is no owner (or we successfully stole the lock), we set the owner of the mutex to current, and set the flag of \u0026ldquo;Has Waiters\u0026rdquo; if the current mutex actually has waiters, or we clear the flag if it doesn\u0026rsquo;t. See, it was OK that we set that flag early, since now it is cleared.\nFailed to grab ownership   The most interesting case is when we fail to take ownership. This means that there exists an owner, or there\u0026rsquo;s a pending owner with equal or higher priority than the current task.\nWe\u0026rsquo;ll continue on the failed case.\nIf the mutex has a timeout, we set up a timer to go off to break us out of this mutex if we failed to get it after a specified amount of time.\nNow we enter a loop that will continue to try to take ownership of the mutex, or fail from a timeout or signal.\nOnce again we try to take the mutex. This will usually fail the first time in the loop, since it had just failed to get the mutex. But the second time in the loop, this would likely succeed, since the task would likely be the pending owner.\nIf the mutex is TASK_INTERRUPTIBLE a check for signals and timeout is done here.\nThe waiter structure has a \u0026ldquo;task\u0026rdquo; field that points to the task that is blocked on the mutex. This field can be NULL the first time it goes through the loop or if the task is a pending owner and had its mutex stolen. If the \u0026ldquo;task\u0026rdquo; field is NULL then we need to set up the accounting for it.\nTask blocks on mutex # The accounting of a mutex and process is done with the waiter structure of the process. The \u0026ldquo;task\u0026rdquo; field is set to the process, and the \u0026ldquo;lock\u0026rdquo; field to the mutex. The plist nodes are initialized to the processes current priority.\nSince the wait_lock was taken at the entry of the slow lock, we can safely add the waiter to the wait_list. If the current process is the highest priority process currently waiting on this mutex, then we remove the previous top waiter process (if it exists) from the pi_list of the owner, and add the current process to that list. Since the pi_list of the owner has changed, we call rt_mutex_adjust_prio on the owner to see if the owner should adjust its priority accordingly.\nIf the owner is also blocked on a lock, and had its pi_list changed (or deadlock checking is on), we unlock the wait_lock of the mutex and go ahead and run rt_mutex_adjust_prio_chain on the owner, as described earlier.\nNow all locks are released, and if the current process is still blocked on a mutex (waiter \u0026ldquo;task\u0026rdquo; field is not NULL), then we go to sleep (call schedule).\nWaking up in the loop # The schedule can then wake up for a few reasons.\n we were given pending ownership of the mutex. we received a signal and was TASK_INTERRUPTIBLE we had a timeout and was TASK_INTERRUPTIBLE  In any of these cases, we continue the loop and once again try to grab the ownership of the mutex. If we succeed, we exit the loop, otherwise we continue and on signal and timeout, will exit the loop, or if we had the mutex stolen we just simply add ourselves back on the lists and go back to sleep.\nNote: For various reasons, because of timeout and signals, the steal mutex algorithm needs to be careful. This is because the current process is still on the wait_list. And because of dynamic changing of priorities, especially on SCHED_OTHER tasks, the current process can be the highest priority task on the wait_list.\nFailed to get mutex on Timeout or Signal # If a timeout or signal occurred, the waiter\u0026rsquo;s \u0026ldquo;task\u0026rdquo; field would not be NULL and the task needs to be taken off the wait_list of the mutex and perhaps pi_list of the owner. If this process was a high priority process, then the rt_mutex_adjust_prio_chain needs to be executed again on the owner, but this time it will be lowering the priorities.\nUnlocking the Mutex # The unlocking of a mutex also has a fast path for those architectures with CMPXCHG. Since the taking of a mutex on contention always sets the \u0026ldquo;Has Waiters\u0026rdquo; flag of the mutex\u0026rsquo;s owner, we use this to know if we need to take the slow path when unlocking the mutex. If the mutex doesn\u0026rsquo;t have any waiters, the owner field of the mutex would equal the current process and the mutex can be unlocked by just replacing the owner field with NULL.\nIf the owner field has the \u0026ldquo;Has Waiters\u0026rdquo; bit set (or CMPXCHG is not available), the slow unlock path is taken.\nThe first thing done in the slow unlock path is to take the wait_lock of the mutex. This synchronizes the locking and unlocking of the mutex.\nA check is made to see if the mutex has waiters or not. On architectures that do not have CMPXCHG, this is the location that the owner of the mutex will determine if a waiter needs to be awoken or not. On architectures that do have CMPXCHG, that check is done in the fast path, but it is still needed in the slow path too. If a waiter of a mutex woke up because of a signal or timeout between the time the owner failed the fast path CMPXCHG check and the grabbing of the wait_lock, the mutex may not have any waiters, thus the owner still needs to make this check. If there are no waiters then the mutex owner field is set to NULL, the wait_lock is released and nothing more is needed.\nIf there are waiters, then we need to wake one up and give that waiter pending ownership.\nOn the wake up code, the pi_lock of the current owner is taken. The top waiter of the lock is found and removed from the wait_list of the mutex as well as the pi_list of the current owner. The task field of the new pending owner\u0026rsquo;s waiter structure is set to NULL, and the owner field of the mutex is set to the new owner with the \u0026ldquo;Pending Owner\u0026rdquo; bit set, as well as the \u0026ldquo;Has Waiters\u0026rdquo; bit if there still are other processes blocked on the mutex.\nThe pi_lock of the previous owner is released, and the new pending owner\u0026rsquo;s pi_lock is taken. Remember that this is the trick to prevent the race condition in rt_mutex_adjust_prio_chain from adding itself as a waiter on the mutex.\nWe now clear the \u0026ldquo;pi_blocked_on\u0026rdquo; field of the new pending owner, and if the mutex still has waiters pending, we add the new top waiter to the pi_list of the pending owner.\nFinally we unlock the pi_lock of the pending owner and wake it up.\n[23] robust-futexes.txt\nBackground # what are robust futexes? To answer that, we first need to understand what futexes are: normal futexes are special types of locks that in the noncontended case can be acquired/released from userspace without having to enter the kernel.\nA futex is in essence a user-space address, e.g. a 32-bit lock variable field. If userspace notices contention (the lock is already owned and someone else wants to grab it too) then the lock is marked with a value that says \u0026ldquo;there\u0026rsquo;s a waiter pending\u0026rdquo;, and the sys_futex(FUTEX_WAIT) syscall is used to wait for the other guy to release it. The kernel creates a \u0026lsquo;futex queue\u0026rsquo; internally, so that it can later on match up the waiter with the waker - without them having to know about each other. When the owner thread releases the futex, it notices (via the variable value) that there were waiter(s) pending, and does the sys_futex(FUTEX_WAKE) syscall to wake them up. Once all waiters have taken and released the lock, the futex is again back to \u0026lsquo;uncontended\u0026rsquo; state, and there\u0026rsquo;s no in-kernel state associated with it. The kernel completely forgets that there ever was a futex at that address. This method makes futexes very lightweight and scalable.\n\u0026ldquo;Robustness\u0026rdquo; is about dealing with crashes while holding a lock: if a process exits prematurely while holding a pthread_mutex_t lock that is also shared with some other process (e.g. yum segfaults while holding a pthread_mutex_t, or yum is kill -9-ed), then waiters for that lock need to be notified that the last owner of the lock exited in some irregular way.\nTo solve such types of problems, \u0026ldquo;robust mutex\u0026rdquo; userspace APIs were created: pthread_mutex_lock() returns an error value if the owner exits prematurely - and the new owner can decide whether the data protected by the lock can be recovered safely.\nThere is a big conceptual problem with futex based mutexes though: it is the kernel that destroys the owner task (e.g. due to a SEGFAULT), but the kernel cannot help with the cleanup: if there is no \u0026lsquo;futex queue\u0026rsquo; (and in most cases there is none, futexes being fast lightweight locks) then the kernel has no information to clean up after the held lock! Userspace has no chance to clean up after the lock either - userspace is the one that crashes, so it has no opportunity to clean up. Catch-22.\nIn practice, when e.g. yum is kill -9-ed (or segfaults), a system reboot is needed to release that futex based lock. This is one of the leading bugreports against yum.\nTo solve this problem, the traditional approach was to extend the vma (virtual memory area descriptor) concept to have a notion of \u0026lsquo;pending robust futexes attached to this area\u0026rsquo;. This approach requires 3 new syscall variants to sys_futex(): FUTEX_REGISTER, FUTEX_DEREGISTER and FUTEX_RECOVER. At do_exit() time, all vmas are searched to see whether they have a robust_head set. This approach has two fundamental problems left:\n  it has quite complex locking and race scenarios. The vma-based approach had been pending for years, but they are still not completely reliable.\n  they have to scan every vma at sys_exit() time, per thread!\n  The second disadvantage is a real killer: pthread_exit() takes around 1 microsecond on Linux, but with thousands (or tens of thousands) of vmas every pthread_exit() takes a millisecond or more, also totally destroying the CPU\u0026rsquo;s L1 and L2 caches!\nThis is very much noticeable even for normal process sys_exit_group() calls: the kernel has to do the vma scanning unconditionally! (this is because the kernel has no knowledge about how many robust futexes there are to be cleaned up, because a robust futex might have been registered in another task, and the futex variable might have been simply mmap()-ed into this process\u0026rsquo;s address space).\nThis huge overhead forced the creation of CONFIG_FUTEX_ROBUST so that normal kernels can turn it off, but worse than that: the overhead makes robust futexes impractical for any type of generic Linux distribution.\nSo something had to be done.\nNew approach to robust futexes # At the heart of this new approach there is a per-thread private list of robust locks that userspace is holding (maintained by glibc) - which userspace list is registered with the kernel via a new syscall [this registration happens at most once per thread lifetime]. At do_exit() time, the kernel checks this user-space list: are there any robust futex locks to be cleaned up?\nIn the common case, at do_exit() time, there is no list registered, so the cost of robust futexes is just a simple current-\u0026gt;robust_list != NULL comparison. If the thread has registered a list, then normally the list is empty. If the thread/process crashed or terminated in some incorrect way then the list might be non-empty: in this case the kernel carefully walks the list [not trusting it], and marks all locks that are owned by this thread with the FUTEX_OWNER_DIED bit, and wakes up one waiter (if any).\nThe list is guaranteed to be private and per-thread at do_exit() time, so it can be accessed by the kernel in a lockless way.\nThere is one race possible though: since adding to and removing from the list is done after the futex is acquired by glibc, there is a few instructions window for the thread (or process) to die there, leaving the futex hung. To protect against this possibility, userspace (glibc) also maintains a simple per-thread \u0026lsquo;list_op_pending\u0026rsquo; field, to allow the kernel to clean up if the thread dies after acquiring the lock, but just before it could have added itself to the list. Glibc sets this list_op_pending field before it tries to acquire the futex, and clears it after the list-add (or list-remove) has finished.\nThat\u0026rsquo;s all that is needed - all the rest of robust-futex cleanup is done in userspace [just like with the previous patches].\nUlrich Drepper has implemented the necessary glibc support for this new mechanism, which fully enables robust mutexes.\nKey differences of this userspace-list based approach, compared to the vma based method:\n  it\u0026rsquo;s much, much faster: at thread exit time, there\u0026rsquo;s no need to loop over every vma (!), which the VM-based method has to do. Only a very simple \u0026lsquo;is the list empty\u0026rsquo; op is done.\n  no VM changes are needed - \u0026lsquo;struct address_space\u0026rsquo; is left alone.\n  no registration of individual locks is needed: robust mutexes dont need any extra per-lock syscalls. Robust mutexes thus become a very lightweight primitive - so they dont force the application designer to do a hard choice between performance and robustness - robust mutexes are just as fast.\n  no per-lock kernel allocation happens.\n  no resource limits are needed.\n  no kernel-space recovery call (FUTEX_RECOVER) is needed.\n  the implementation and the locking is \u0026ldquo;obvious\u0026rdquo;, and there are no interactions with the VM.\n  Performance # I have benchmarked the time needed for the kernel to process a list of 1 million (!) held locks, using the new method [on a 2GHz CPU]:\n with FUTEX_WAIT set [contended mutex]: 130 msecs without FUTEX_WAIT set [uncontended mutex]: 30 msecs  I have also measured an approach where glibc does the lock notification [which it currently does for !pshared robust mutexes], and that took 256 msecs - clearly slower, due to the 1 million FUTEX_WAKE syscalls userspace had to do.\n(1 million held locks are unheard of - we expect at most a handful of locks to be held at a time. Nevertheless it\u0026rsquo;s nice to know that this approach scales nicely.)\nImplementation details # The patch adds two new syscalls: one to register the userspace list, and one to query the registered list pointer:\nasmlinkage long sys_set_robust_list(struct robust_list_head __user *head, size_t len);\nasmlinkage long sys_get_robust_list(int pid, struct robust_list_head __user **head_ptr, size_t __user *len_ptr);\nList registration is very fast: the pointer is simply stored in current-\u0026gt;robust_list. [Note that in the future, if robust futexes become widespread, we could extend sys_clone() to register a robust-list head for new threads, without the need of another syscall.]\nSo there is virtually zero overhead for tasks not using robust futexes, and even for robust futex users, there is only one extra syscall per thread lifetime, and the cleanup operation, if it happens, is fast and straightforward. The kernel doesn\u0026rsquo;t have any internal distinction between robust and normal futexes.\nIf a futex is found to be held at exit time, the kernel sets the following bit of the futex word:\n#define FUTEX_OWNER_DIED 0x40000000\nand wakes up the next futex waiter (if any). User-space does the rest of the cleanup.\nOtherwise, robust futexes are acquired by glibc by putting the TID into the futex field atomically. Waiters set the FUTEX_WAITERS bit:\n#define FUTEX_WAITERS 0x80000000\nand the remaining bits are for the TID.\nTesting, architecture support # i\u0026rsquo;ve tested the new syscalls on x86 and x86_64, and have made sure the parsing of the userspace list is robust [ ;-) ] even if the list is deliberately corrupted.\ni386 and x86_64 syscalls are wired up at the moment, and Ulrich has tested the new glibc code (on x86_64 and i386), and it works for his robust-mutex testcases.\nAll other architectures should build just fine too - but they wont have the new syscalls yet.\nArchitectures need to implement the new futex_atomic_cmpxchg_inatomic() inline function before writing up the syscalls (that function returns -ENOSYS right now).\n[24] robust-futex-ABI.txt\nThe robust futex ABI robust futex # Robust_futexes provide a mechanism that is used in addition to normal futexes, for kernel assist of cleanup of held locks on task exit.\nrobust futex除了提供futex的功能之外，它还提供了一种机制，在任务结束时用于辅助 内核对任务持有的锁进行清理。\nThe interesting data as to what futexes a thread is holding is kept on a linked list in user space, where it can be updated efficiently as locks are taken and dropped, without kernel intervention. The only additional kernel intervention required for robust_futexes above and beyond what is required for futexes is:\n我们关心的数据是线程持有的futexes，这些树需被保存在用户空间的一个链表中，当被 加锁或者锁被释放时，这个链表中的数据可以被高效地更新，这一过程不许要内核的干预 。针对我们上面提到的robust_futexes，内核对它的唯一干预以及它相对于futexes添加 的功能包括：\n a one time call, per thread, to tell the kernel where its list of held robust_futexes begins, and internal kernel code at exit, to handle any listed locks held by the exiting thread.  The existing normal futexes already provide a \u0026ldquo;Fast Userspace Locking\u0026rdquo; mechanism, which handles uncontested locking without needing a system call, and handles contested locking by maintaining a list of waiting threads in the kernel. Options on the sys_futex(2) system call support waiting on a particular futex, and waking up the next waiter on a particular futex.\nFor robust_futexes to work, the user code (typically in a library such as glibc linked with the application) has to manage and place the necessary list elements exactly as the kernel expects them. If it fails to do so, then improperly listed locks will not be cleaned up on exit, probably causing deadlock or other such failure of the other threads waiting on the same locks.\nA thread that anticipates possibly using robust_futexes should first issue the system call:\nasmlinkage long sys_set_robust_list(struct robust_list_head __user *head, size_t len);\nThe pointer \u0026lsquo;head\u0026rsquo; points to a structure in the threads address space consisting of three words. Each word is 32 bits on 32 bit arch\u0026rsquo;s, or 64 bits on 64 bit arch\u0026rsquo;s, and local byte order. Each thread should have its own thread private \u0026lsquo;head\u0026rsquo;.\nIf a thread is running in 32 bit compatibility mode on a 64 native arch kernel, then it can actually have two such structures - one using 32 bit words for 32 bit compatibility mode, and one using 64 bit words for 64 bit native mode. The kernel, if it is a 64 bit kernel supporting 32 bit compatibility mode, will attempt to process both lists on each task exit, if the corresponding sys_set_robust_list() call has been made to setup that list.\nThe first word in the memory structure at \u0026lsquo;head\u0026rsquo; contains a pointer to a single linked list of \u0026lsquo;lock entries\u0026rsquo;, one per lock, as described below. If the list is empty, the pointer will point to itself, \u0026lsquo;head\u0026rsquo;. The last \u0026lsquo;lock entry\u0026rsquo; points back to the \u0026lsquo;head\u0026rsquo;.\nThe second word, called \u0026lsquo;offset\u0026rsquo;, specifies the offset from the address of the associated \u0026lsquo;lock entry\u0026rsquo;, plus or minus, of what will be called the \u0026lsquo;lock word\u0026rsquo;, from that \u0026lsquo;lock entry\u0026rsquo;. The \u0026lsquo;lock word\u0026rsquo; is always a 32 bit word, unlike the other words above. The \u0026lsquo;lock word\u0026rsquo; holds 3 flag bits in the upper 3 bits, and the thread id (TID) of the thread holding the lock in the bottom 29 bits. See further below for a description of the flag bits.\nThe third word, called \u0026lsquo;list_op_pending\u0026rsquo;, contains transient copy of the address of the \u0026lsquo;lock entry\u0026rsquo;, during list insertion and removal, and is needed to correctly resolve races should a thread exit while in the middle of a locking or unlocking operation.\nEach \u0026lsquo;lock entry\u0026rsquo; on the single linked list starting at \u0026lsquo;head\u0026rsquo; consists of just a single word, pointing to the next \u0026lsquo;lock entry\u0026rsquo;, or back to \u0026lsquo;head\u0026rsquo; if there are no more entries. In addition, nearby to each \u0026lsquo;lock entry\u0026rsquo;, at an offset from the \u0026lsquo;lock entry\u0026rsquo; specified by the \u0026lsquo;offset\u0026rsquo; word, is one \u0026lsquo;lock word\u0026rsquo;.\nThe \u0026lsquo;lock word\u0026rsquo; is always 32 bits, and is intended to be the same 32 bit lock variable used by the futex mechanism, in conjunction with robust_futexes. The kernel will only be able to wakeup the next thread waiting for a lock on a threads exit if that next thread used the futex mechanism to register the address of that \u0026lsquo;lock word\u0026rsquo; with the kernel.\nFor each futex lock currently held by a thread, if it wants this robust_futex support for exit cleanup of that lock, it should have one \u0026lsquo;lock entry\u0026rsquo; on this list, with its associated \u0026lsquo;lock word\u0026rsquo; at the specified \u0026lsquo;offset\u0026rsquo;. Should a thread die while holding any such locks, the kernel will walk this list, mark any such locks with a bit indicating their holder died, and wakeup the next thread waiting for that lock using the futex mechanism.\nWhen a thread has invoked the above system call to indicate it anticipates using robust_futexes, the kernel stores the passed in \u0026lsquo;head\u0026rsquo; pointer for that task. The task may retrieve that value later on by using the system call:\nasmlinkage long sys_get_robust_list(int pid, struct robust_list_head __user **head_ptr, size_t __user *len_ptr);\nIt is anticipated that threads will use robust_futexes embedded in larger, user level locking structures, one per lock. The kernel robust_futex mechanism doesn\u0026rsquo;t care what else is in that structure, so long as the \u0026lsquo;offset\u0026rsquo; to the \u0026lsquo;lock word\u0026rsquo; is the same for all robust_futexes used by that thread. The thread should link those locks it currently holds using the \u0026lsquo;lock entry\u0026rsquo; pointers. It may also have other links between the locks, such as the reverse side of a double linked list, but that doesn\u0026rsquo;t matter to the kernel.\nBy keeping its locks linked this way, on a list starting with a \u0026lsquo;head\u0026rsquo; pointer known to the kernel, the kernel can provide to a thread the essential service available for robust_futexes, which is to help clean up locks held at the time of (a perhaps unexpectedly) exit.\nActual locking and unlocking, during normal operations, is handled entirely by user level code in the contending threads, and by the existing futex mechanism to wait for, and wakeup, locks. The kernels only essential involvement in robust_futexes is to remember where the list \u0026lsquo;head\u0026rsquo; is, and to walk the list on thread exit, handling locks still held by the departing thread, as described below.\nThere may exist thousands of futex lock structures in a threads shared memory, on various data structures, at a given point in time. Only those lock structures for locks currently held by that thread should be on that thread\u0026rsquo;s robust_futex linked lock list a given time.\nA given futex lock structure in a user shared memory region may be held at different times by any of the threads with access to that region. The thread currently holding such a lock, if any, is marked with the threads TID in the lower 29 bits of the \u0026lsquo;lock word\u0026rsquo;.\nWhen adding or removing a lock from its list of held locks, in order for the kernel to correctly handle lock cleanup regardless of when the task exits (perhaps it gets an unexpected signal 9 in the middle of manipulating this list), the user code must observe the following protocol on \u0026lsquo;lock entry\u0026rsquo; insertion and removal:\nOn insertion:\n set the \u0026lsquo;list_op_pending\u0026rsquo; word to the address of the \u0026lsquo;lock entry\u0026rsquo; to be inserted, acquire the futex lock, add the lock entry, with its thread id (TID) in the bottom 29 bits of the \u0026lsquo;lock word\u0026rsquo;, to the linked list starting at \u0026lsquo;head\u0026rsquo;, and clear the \u0026lsquo;list_op_pending\u0026rsquo; word.  On removal:\n set the \u0026lsquo;list_op_pending\u0026rsquo; word to the address of the \u0026lsquo;lock entry\u0026rsquo; to be removed, remove the lock entry for this lock from the \u0026lsquo;head\u0026rsquo; list, release the futex lock, and clear the \u0026lsquo;lock_op_pending\u0026rsquo; word.  On exit, the kernel will consider the address stored in \u0026lsquo;list_op_pending\u0026rsquo; and the address of each \u0026lsquo;lock word\u0026rsquo; found by walking the list starting at \u0026lsquo;head\u0026rsquo;. For each such address, if the bottom 29 bits of the \u0026lsquo;lock word\u0026rsquo; at offset \u0026lsquo;offset\u0026rsquo; from that address equals the exiting threads TID, then the kernel will do two things:\n if bit 31 (0x80000000) is set in that word, then attempt a futex wakeup on that address, which will waken the next thread that has used to the futex mechanism to wait on that address, and atomically set bit 30 (0x40000000) in the \u0026lsquo;lock word\u0026rsquo;.  In the above, bit 31 was set by futex waiters on that lock to indicate they were waiting, and bit 30 is set by the kernel to indicate that the lock owner died holding the lock.\nThe kernel exit code will silently stop scanning the list further if at any point:\n the \u0026lsquo;head\u0026rsquo; pointer or an subsequent linked list pointer is not a valid address of a user space word the calculated location of the \u0026lsquo;lock word\u0026rsquo; (address plus \u0026lsquo;offset\u0026rsquo;) is not the valid address of a 32 bit user space word if the list contains more than 1 million (subject to future kernel configuration changes) elements.  When the kernel sees a list entry whose \u0026lsquo;lock word\u0026rsquo; doesn\u0026rsquo;t have the current threads TID in the lower 29 bits, it does nothing with that entry, and goes on to the next entry.\nBit 29 (0x20000000) of the \u0026lsquo;lock word\u0026rsquo; is reserved for future use.\n============================================================================= Sat Sep 20 00:25:48 CST 2014 # [25] rfkill.txt\nrfkill - RF kill switch support\nThe rfkill subsystem provides a generic interface to disabling any radio transmitter in the system. When a transmitter is blocked, it shall not radiate any power.\nThe subsystem also provides the ability to react on button presses and disable all transmitters of a certain type (or all). This is intended for situations where transmitters need to be turned off, for example on aircraft.\nThe rfkill subsystem has a concept of \u0026ldquo;hard\u0026rdquo; and \u0026ldquo;soft\u0026rdquo; block, which differ little in their meaning (block == transmitters off) but rather in whether they can be changed or not:\n hard block: read-only radio block that cannot be overriden by software soft block: writable radio block (need not be readable) that is set by the system software.  [26] rbtree.txt\nWhat are red-black trees, and what are they for? # Red-black trees are a type of self-balancing binary search tree, used for storing sortable key/value data pairs. This differs from radix trees (which are used to efficiently store sparse arrays and thus use long integer indexes to insert/access/delete nodes) and hash tables (which are not kept sorted to be easily traversed in order, and must be tuned for a specific size and hash function where rbtrees scale gracefully storing arbitrary keys).\nRed-black trees are similar to AVL trees, but provide faster real-time bounded worst case performance for insertion and deletion (at most two rotations and three rotations, respectively, to balance the tree), with slightly slower (but still O(log n)) lookup time.\nTo quote Linux Weekly News:\nThere are a number of red-black trees in use in the kernel. The deadline and CFQ I/O schedulers employ rbtrees to track requests; the packet CD/DVD driver does the same. The high-resolution timer code uses an rbtree to organize outstanding timer requests. The ext3 filesystem tracks directory entries in a red-black tree. Virtual memory areas (VMAs) are tracked with red-black trees, as are epoll file descriptors, cryptographic keys, and network packets in the \u0026ldquo;hierarchical token bucket\u0026rdquo; scheduler.\n[27] ramoops.txt\nRamoops is an oops/panic logger that writes its logs to RAM before the system crashes. It works by logging oopses and panics in a circular buffer. Ramoops needs a system with persistent RAM so that the content of that area can survive after a restart.\n[28] prio_tree.txt\n[29] printk-formats.txt\n[30] preempt-locking.txt\n[31] pnp.txt\nPlug and Play provides a means of detecting and setting resources for legacy or otherwise unconfigurable devices. The Linux Plug and Play Layer provides these services to compatible drivers.\n[32] pinctrl.txt\n[33] pi-futex.txt\n类似与rt-mutex的实现。\n[34] parport.txt [35] parport-lowlevel.txt\nThe `parport' code provides parallel-port support under Linux. This includes the ability to share one port between multiple device drivers.\n[36] padata.txt\nPadata is a mechanism by which the kernel can farm work out to be done in parallel on multiple CPUs while retaining the ordering of tasks. It was developed for use with the IPsec code, which needs to be able to perform encryption and decryption on large numbers of packets without reordering those packets. The crypto developers made a point of writing padata in a sufficiently general fashion that it could be put to other uses as well.\n[37] oops-tracing.txt\n[38] 00-INDEX\nThis is a brief list of all the files in ./linux/Documentation and what they contain. If you add a documentation file, please list it here in alphabetical order as well, or risk being hunted down like a rabid dog. Please try and keep the descriptions small enough to fit on one line.\n[39] Changes\nThis document is designed to provide a list of the minimum levels of software necessary to run the 3.0 kernels.\n============================================================================= Sat Sep 20 10:03:48 CST 2014 # [40] CodingStyle.txt\n Linux kernel coding style  This is a short document describing the preferred coding style for the linux kernel. Coding style is very personal, and I won\u0026rsquo;t force my views on anybody, but this is what goes for anything that I have to be able to maintain, and I\u0026rsquo;d prefer it for most other things too. Please at least consider the points made here.\nFirst off, I\u0026rsquo;d suggest printing out a copy of the GNU coding standards, and NOT read it. Burn them, it\u0026rsquo;s a great symbolic gesture.\nAnyway, here goes:\n Chapter 1: Indentation  Tabs are 8 characters, and thus indentations are also 8 characters. There are heretic movements that try to make indentations 4 (or even 2!) characters deep, and that is akin to trying to define the value of PI to be 3.\nRationale: The whole idea behind indentation is to clearly define where a block of control starts and ends. Especially when you\u0026rsquo;ve been looking at your screen for 20 straight hours, you\u0026rsquo;ll find it a lot easier to see how the indentation works if you have large indentations.\nNow, some people will claim that having 8-character indentations makes the code move too far to the right, and makes it hard to read on a 80-character terminal screen. The answer to that is that if you need more than 3 levels of indentation, you\u0026rsquo;re screwed anyway, and should fix your program.\nIn short, 8-char indents make things easier to read, and have the added benefit of warning you when you\u0026rsquo;re nesting your functions too deep. Heed that warning.\nThe preferred way to ease multiple indentation levels in a switch statement is to align the \u0026ldquo;switch\u0026rdquo; and its subordinate \u0026ldquo;case\u0026rdquo; labels in the same column instead of \u0026ldquo;double-indenting\u0026rdquo; the \u0026ldquo;case\u0026rdquo; labels. E.g.:\n switch (suffix) { case 'G': case 'g': mem \u0026lt;\u0026lt;= 30; break; case 'M': case 'm': mem \u0026lt;\u0026lt;= 20; break; case 'K': case 'k': mem \u0026lt;\u0026lt;= 10; /* fall through */ default: break; }  Don\u0026rsquo;t put multiple statements on a single line unless you have something to hide:\n if (condition) do_this; do_something_everytime;  Don\u0026rsquo;t put multiple assignments on a single line either. Kernel coding style is super simple. Avoid tricky expressions.\nOutside of comments, documentation and except in Kconfig, spaces are never used for indentation, and the above example is deliberately broken.\nGet a decent editor and don\u0026rsquo;t leave whitespace at the end of lines.\n Chapter 2: Breaking long lines and strings  Coding style is all about readability and maintainability using commonly available tools.\nThe limit on the length of lines is 80 columns and this is a strongly preferred limit.\nStatements longer than 80 columns will be broken into sensible chunks, unless exceeding 80 columns significantly increases readability and does not hide information. Descendants are always substantially shorter than the parent and are placed substantially to the right. The same applies to function headers with a long argument list. However, never break user-visible strings such as printk messages, because that breaks the ability to grep for them.\n Chapter 3: Placing Braces and Spaces  The other issue that always comes up in C styling is the placement of braces. Unlike the indent size, there are few technical reasons to choose one placement strategy over the other, but the preferred way, as shown to us by the prophets Kernighan and Ritchie, is to put the opening brace last on the line, and put the closing brace first, thusly:\n if (x is true) { we do y }  This applies to all non-function statement blocks (if, switch, for, while, do). E.g.:\n switch (action) { case KOBJ_ADD: return \u0026quot;add\u0026quot;; case KOBJ_REMOVE: return \u0026quot;remove\u0026quot;; case KOBJ_CHANGE: return \u0026quot;change\u0026quot;; default: return NULL; }  However, there is one special case, namely functions: they have the opening brace at the beginning of the next line, thus:\n int function(int x) { body of function }  Heretic people all over the world have claimed that this inconsistency is \u0026hellip; well \u0026hellip; inconsistent, but all right-thinking people know that (a) K\u0026amp;R are right and (b) K\u0026amp;R are right. Besides, functions are special anyway (you can\u0026rsquo;t nest them in C).\nNote that the closing brace is empty on a line of its own, except in the cases where it is followed by a continuation of the same statement, ie a \u0026ldquo;while\u0026rdquo; in a do-statement or an \u0026ldquo;else\u0026rdquo; in an if-statement, like this:\n do { body of do-loop } while (condition);  and\n if (x == y) { .. } else if (x \u0026gt; y) { ... } else { .... }  Rationale: K\u0026amp;R.\nAlso, note that this brace-placement also minimizes the number of empty (or almost empty) lines, without any loss of readability. Thus, as the supply of new-lines on your screen is not a renewable resource (think 25-line terminal screens here), you have more empty lines to put comments on.\nDo not unnecessarily use braces where a single statement will do.\nif (condition) action();\nand\nif (condition) do_this(); else do_that();\nThis does not apply if only one branch of a conditional statement is a single statement; in the latter case use braces in both branches:\nif (condition) { do_this(); do_that(); } else { otherwise(); }\n 3.1: Spaces  Linux kernel style for use of spaces depends (mostly) on function-versus-keyword usage. Use a space after (most) keywords. The notable exceptions are sizeof, typeof, alignof, and attribute, which look somewhat like functions (and are usually used with parentheses in Linux, although they are not required in the language, as in: \u0026ldquo;sizeof info\u0026rdquo; after \u0026ldquo;struct fileinfo info;\u0026rdquo; is declared).\nSo use a space after these keywords: if, switch, case, for, do, while but not with sizeof, typeof, alignof, or attribute. E.g., s = sizeof(struct file);\nDo not add spaces around (inside) parenthesized expressions. This example is bad:\n s = sizeof( struct file );  When declaring pointer data or a function that returns a pointer type, the preferred use of \u0026lsquo;*\u0026rsquo; is adjacent to the data name or function name and not adjacent to the type name. Examples:\n char *linux_banner; unsigned long long memparse(char *ptr, char **retptr); char *match_strdup(substring_t *s);  Use one space around (on each side of) most binary and ternary operators, such as any of these:\n = + - \u0026lt; \u0026gt; * / % | \u0026amp; ^ \u0026lt;= \u0026gt;= == != ? :  but no space after unary operators: \u0026amp; * + - ~ ! sizeof typeof alignof attribute defined\nno space before the postfix increment \u0026amp; decrement unary operators: ++ \u0026ndash;\nno space after the prefix increment \u0026amp; decrement unary operators: ++ \u0026ndash;\nand no space around the \u0026lsquo;.\u0026rsquo; and \u0026ldquo;-\u0026gt;\u0026rdquo; structure member operators.\nDo not leave trailing whitespace at the ends of lines. Some editors with \u0026ldquo;smart\u0026rdquo; indentation will insert whitespace at the beginning of new lines as appropriate, so you can start typing the next line of code right away. However, some such editors do not remove the whitespace if you end up not putting a line of code there, such as if you leave a blank line. As a result, you end up with lines containing trailing whitespace.\nGit will warn you about patches that introduce trailing whitespace, and can optionally strip the trailing whitespace for you; however, if applying a series of patches, this may make later patches in the series fail by changing their context lines.\n Chapter 4: Naming  C is a Spartan language, and so should your naming be. Unlike Modula-2 and Pascal programmers, C programmers do not use cute names like ThisVariableIsATemporaryCounter. A C programmer would call that variable \u0026ldquo;tmp\u0026rdquo;, which is much easier to write, and not the least more difficult to understand.\nHOWEVER, while mixed-case names are frowned upon, descriptive names for global variables are a must. To call a global function \u0026ldquo;foo\u0026rdquo; is a shooting offense.\nGLOBAL variables (to be used only if you really need them) need to have descriptive names, as do global functions. If you have a function that counts the number of active users, you should call that \u0026ldquo;count_active_users()\u0026rdquo; or similar, you should not call it \u0026ldquo;cntusr()\u0026rdquo;.\nEncoding the type of a function into the name (so-called Hungarian notation) is brain damaged - the compiler knows the types anyway and can check those, and it only confuses the programmer. No wonder MicroSoft makes buggy programs.\nLOCAL variable names should be short, and to the point. If you have some random integer loop counter, it should probably be called \u0026ldquo;i\u0026rdquo;. Calling it \u0026ldquo;loop_counter\u0026rdquo; is non-productive, if there is no chance of it being mis-understood. Similarly, \u0026ldquo;tmp\u0026rdquo; can be just about any type of variable that is used to hold a temporary value.\nIf you are afraid to mix up your local variable names, you have another problem, which is called the function-growth-hormone-imbalance syndrome. See chapter 6 (Functions).\n Chapter 5: Typedefs  Please don\u0026rsquo;t use things like \u0026ldquo;vps_t\u0026rdquo;.\nIt\u0026rsquo;s a mistake to use typedef for structures and pointers. When you see a\n vps_t a;  in the source, what does it mean?\nIn contrast, if it says\n struct virtual_container *a;  you can actually tell what \u0026ldquo;a\u0026rdquo; is.\nLots of people think that typedefs \u0026ldquo;help readability\u0026rdquo;. Not so. They are useful only for:\n(a) totally opaque objects (where the typedef is actively used to hide what the object is).\n Example: \u0026quot;pte_t\u0026quot; etc. opaque objects that you can only access using the proper accessor functions. NOTE! Opaqueness and \u0026quot;accessor functions\u0026quot; are not good in themselves. The reason we have them for things like pte_t etc. is that there really is absolutely _zero_ portably accessible information there.  (b) Clear integer types, where the abstraction helps avoid confusion whether it is \u0026ldquo;int\u0026rdquo; or \u0026ldquo;long\u0026rdquo;.\n u8/u16/u32 are perfectly fine typedefs, although they fit into category (d) better than here. NOTE! Again - there needs to be a _reason_ for this. If something is \u0026quot;unsigned long\u0026quot;, then there's no reason to do typedef unsigned long myflags_t; but if there is a clear reason for why it under certain circumstances might be an \u0026quot;unsigned int\u0026quot; and under other configurations might be \u0026quot;unsigned long\u0026quot;, then by all means go ahead and use a typedef.  (c) when you use sparse to literally create a new type for type-checking.\n(d) New types which are identical to standard C99 types, in certain exceptional circumstances.\n Although it would only take a short amount of time for the eyes and brain to become accustomed to the standard types like 'uint32_t', some people object to their use anyway. Therefore, the Linux-specific 'u8/u16/u32/u64' types and their signed equivalents which are identical to standard types are permitted -- although they are not mandatory in new code of your own. When editing existing code which already uses one or the other set of types, you should conform to the existing choices in that code.  (e) Types safe for use in userspace.\n In certain structures which are visible to userspace, we cannot require C99 types and cannot use the 'u32' form above. Thus, we use __u32 and similar types in all structures which are shared with userspace.  Maybe there are other cases too, but the rule should basically be to NEVER EVER use a typedef unless you can clearly match one of those rules.\nIn general, a pointer, or a struct that has elements that can reasonably be directly accessed should never be a typedef.\n Chapter 6: Functions  Functions should be short and sweet, and do just one thing. They should fit on one or two screenfuls of text (the ISO/ANSI screen size is 80x24, as we all know), and do one thing and do that well.\nThe maximum length of a function is inversely proportional to the complexity and indentation level of that function. So, if you have a conceptually simple function that is just one long (but simple) case-statement, where you have to do lots of small things for a lot of different cases, it\u0026rsquo;s OK to have a longer function.\nHowever, if you have a complex function, and you suspect that a less-than-gifted first-year high-school student might not even understand what the function is all about, you should adhere to the maximum limits all the more closely. Use helper functions with descriptive names (you can ask the compiler to in-line them if you think it\u0026rsquo;s performance-critical, and it will probably do a better job of it than you would have done).\nAnother measure of the function is the number of local variables. They shouldn\u0026rsquo;t exceed 5-10, or you\u0026rsquo;re doing something wrong. Re-think the function, and split it into smaller pieces. A human brain can generally easily keep track of about 7 different things, anything more and it gets confused. You know you\u0026rsquo;re brilliant, but maybe you\u0026rsquo;d like to understand what you did 2 weeks from now.\nIn source files, separate functions with one blank line. If the function is exported, the EXPORT* macro for it should follow immediately after the closing function brace line. E.g.:\nint system_is_up(void) { return system_state == SYSTEM_RUNNING; } EXPORT_SYMBOL(system_is_up);\nIn function prototypes, include parameter names with their data types. Although this is not required by the C language, it is preferred in Linux because it is a simple way to add valuable information for the reader.\n Chapter 7: Centralized exiting of functions  Albeit deprecated by some people, the equivalent of the goto statement is used frequently by compilers in form of the unconditional jump instruction.\nThe goto statement comes in handy when a function exits from multiple locations and some common work such as cleanup has to be done.\nThe rationale is:\n unconditional statements are easier to understand and follow nesting is reduced errors by not updating individual exit points when making modifications are prevented saves the compiler work to optimize redundant code away ;)  int fun(int a) { int result = 0; char *buffer = kmalloc(SIZE);\n if (buffer == NULL) return -ENOMEM; if (condition1) { while (loop1) { ... } result = 1; goto out; } ...  out: kfree(buffer); return result; }\n Chapter 8: Commenting  Comments are good, but there is also a danger of over-commenting. NEVER try to explain HOW your code works in a comment: it\u0026rsquo;s much better to write the code so that the working is obvious, and it\u0026rsquo;s a waste of time to explain badly written code.\nGenerally, you want your comments to tell WHAT your code does, not HOW. Also, try to avoid putting comments inside a function body: if the function is so complex that you need to separately comment parts of it, you should probably go back to chapter 6 for a while. You can make small comments to note or warn about something particularly clever (or ugly), but try to avoid excess. Instead, put the comments at the head of the function, telling people what it does, and possibly WHY it does it.\nWhen commenting the kernel API functions, please use the kernel-doc format. See the files Documentation/kernel-doc-nano-HOWTO.txt and scripts/kernel-doc for details.\nLinux style for comments is the C89 \u0026ldquo;/* \u0026hellip; */\u0026rdquo; style. Don\u0026rsquo;t use C99-style \u0026ldquo;// \u0026hellip;\u0026rdquo; comments.\nThe preferred style for long (multi-line) comments is:\n /* * This is the preferred style for multi-line * comments in the Linux kernel source code. * Please use it consistently. * * Description: A column of asterisks on the left side, * with beginning and ending almost-blank lines. */  It\u0026rsquo;s also important to comment data, whether they are basic types or derived types. To this end, use just one data declaration per line (no commas for multiple data declarations). This leaves you room for a small comment on each item, explaining its use.\n Chapter 9: You've made a mess of it  That\u0026rsquo;s OK, we all do. You\u0026rsquo;ve probably been told by your long-time Unix user helper that \u0026ldquo;GNU emacs\u0026rdquo; automatically formats the C sources for you, and you\u0026rsquo;ve noticed that yes, it does do that, but the defaults it uses are less than desirable (in fact, they are worse than random typing - an infinite number of monkeys typing into GNU emacs would never make a good program).\nSo, you can either get rid of GNU emacs, or change it to use saner values. To do the latter, you can stick the following in your .emacs file:\n(defun c-lineup-arglist-tabs-only (ignored) \u0026ldquo;Line up argument lists by tabs, not spaces\u0026rdquo; (let* ((anchor (c-langelem-pos c-syntactic-element)) (column (c-langelem-2nd-pos c-syntactic-element)) (offset (- (1+ column) anchor)) (steps (floor offset c-basic-offset))) (* (max steps 1) c-basic-offset)))\n(add-hook \u0026lsquo;c-mode-common-hook (lambda () ;; Add kernel style (c-add-style \u0026ldquo;linux-tabs-only\u0026rdquo; \u0026lsquo;(\u0026ldquo;linux\u0026rdquo; (c-offsets-alist (arglist-cont-nonempty c-lineup-gcc-asm-reg c-lineup-arglist-tabs-only))))))\n(add-hook \u0026lsquo;c-mode-hook (lambda () (let ((filename (buffer-file-name))) ;; Enable kernel mode for the appropriate files (when (and filename (string-match (expand-file-name \u0026ldquo;~/src/linux-trees\u0026rdquo;) filename)) (setq indent-tabs-mode t) (c-set-style \u0026ldquo;linux-tabs-only\u0026rdquo;)))))\nThis will make emacs go better with the kernel coding style for C files below ~/src/linux-trees.\nBut even if you fail in getting emacs to do sane formatting, not everything is lost: use \u0026ldquo;indent\u0026rdquo;.\nNow, again, GNU indent has the same brain-dead settings that GNU emacs has, which is why you need to give it a few command line options. However, that\u0026rsquo;s not too bad, because even the makers of GNU indent recognize the authority of K\u0026amp;R (the GNU people aren\u0026rsquo;t evil, they are just severely misguided in this matter), so you just give indent the options \u0026ldquo;-kr -i8\u0026rdquo; (stands for \u0026ldquo;K\u0026amp;R, 8 character indents\u0026rdquo;), or use \u0026ldquo;scripts/Lindent\u0026rdquo;, which indents in the latest style.\n\u0026ldquo;indent\u0026rdquo; has a lot of options, and especially when it comes to comment re-formatting you may want to take a look at the man page. But remember: \u0026ldquo;indent\u0026rdquo; is not a fix for bad programming.\n Chapter 10: Kconfig configuration files  For all of the Kconfig* configuration files throughout the source tree, the indentation is somewhat different. Lines under a \u0026ldquo;config\u0026rdquo; definition are indented with one tab, while help text is indented an additional two spaces. Example:\nconfig AUDIT bool \u0026ldquo;Auditing support\u0026rdquo; depends on NET help Enable auditing infrastructure that can be used with another kernel subsystem, such as SELinux (which requires this for logging of avc messages output). Does not do system-call auditing without CONFIG_AUDITSYSCALL.\nFeatures that might still be considered unstable should be defined as dependent on \u0026ldquo;EXPERIMENTAL\u0026rdquo;:\nconfig SLUB depends on EXPERIMENTAL \u0026amp;\u0026amp; !ARCH_USES_SLAB_PAGE_STRUCT bool \u0026ldquo;SLUB (Unqueued Allocator)\u0026rdquo; \u0026hellip;\nwhile seriously dangerous features (such as write support for certain filesystems) should advertise this prominently in their prompt string:\nconfig ADFS_FS_RW bool \u0026ldquo;ADFS write support (DANGEROUS)\u0026rdquo; depends on ADFS_FS \u0026hellip;\nFor full documentation on the configuration files, see the file Documentation/kbuild/kconfig-language.txt.\n Chapter 11: Data structures  Data structures that have visibility outside the single-threaded environment they are created and destroyed in should always have reference counts. In the kernel, garbage collection doesn\u0026rsquo;t exist (and outside the kernel garbage collection is slow and inefficient), which means that you absolutely have to reference count all your uses.\nReference counting means that you can avoid locking, and allows multiple users to have access to the data structure in parallel - and not having to worry about the structure suddenly going away from under them just because they slept or did something else for a while.\nNote that locking is not a replacement for reference counting. Locking is used to keep data structures coherent, while reference counting is a memory management technique. Usually both are needed, and they are not to be confused with each other.\nMany data structures can indeed have two levels of reference counting, when there are users of different \u0026ldquo;classes\u0026rdquo;. The subclass count counts the number of subclass users, and decrements the global count just once when the subclass count goes to zero.\nExamples of this kind of \u0026ldquo;multi-level-reference-counting\u0026rdquo; can be found in memory management (\u0026ldquo;struct mm_struct\u0026rdquo;: mm_users and mm_count), and in filesystem code (\u0026ldquo;struct super_block\u0026rdquo;: s_count and s_active).\nRemember: if another thread can find your data structure, and you don\u0026rsquo;t have a reference count on it, you almost certainly have a bug.\n Chapter 12: Macros, Enums and RTL  Names of macros defining constants and labels in enums are capitalized.\n#define CONSTANT 0x12345\nEnums are preferred when defining several related constants.\nCAPITALIZED macro names are appreciated but macros resembling functions may be named in lower case.\nGenerally, inline functions are preferable to macros resembling functions.\nMacros with multiple statements should be enclosed in a do - while block:\n#define macrofun(a, b, c) do { if (a == 5) do_this(b, c); } while (0)\nThings to avoid when using macros:\n macros that affect control flow:  #define FOO(x) do { if (blah(x) \u0026lt; 0) return -EBUGGERED; } while(0)\nis a very bad idea. It looks like a function call but exits the \u0026ldquo;calling\u0026rdquo; function; don\u0026rsquo;t break the internal parsers of those who will read the code.\nmacros that depend on having a local variable with a magic name:  #define FOO(val) bar(index, val)\nmight look like a good thing, but it\u0026rsquo;s confusing as hell when one reads the code and it\u0026rsquo;s prone to breakage from seemingly innocent changes.\n macros with arguments that are used as l-values: FOO(x) = y; will bite you if somebody e.g. turns FOO into an inline function.\n  forgetting about precedence: macros defining constants using expressions must enclose the expression in parentheses. Beware of similar issues with macros using parameters.\n  #define CONSTANT 0x4000 #define CONSTEXP (CONSTANT | 3)\nThe cpp manual deals with macros exhaustively. The gcc internals manual also covers RTL which is used frequently with assembly language in the kernel.\n Chapter 13: Printing kernel messages  Kernel developers like to be seen as literate. Do mind the spelling of kernel messages to make a good impression. Do not use crippled words like \u0026ldquo;dont\u0026rdquo;; use \u0026ldquo;do not\u0026rdquo; or \u0026ldquo;don\u0026rsquo;t\u0026rdquo; instead. Make the messages concise, clear, and unambiguous.\nKernel messages do not have to be terminated with a period.\nPrinting numbers in parentheses (%d) adds no value and should be avoided.\nThere are a number of driver model diagnostic macros in \u0026lt;linux/device.h\u0026gt; which you should use to make sure messages are matched to the right device and driver, and are tagged with the right level: dev_err(), dev_warn(), dev_info(), and so forth. For messages that aren\u0026rsquo;t associated with a particular device, \u0026lt;linux/printk.h\u0026gt; defines pr_debug() and pr_info().\nComing up with good debugging messages can be quite a challenge; and once you have them, they can be a huge help for remote troubleshooting. Such messages should be compiled out when the DEBUG symbol is not defined (that is, by default they are not included). When you use dev_dbg() or pr_debug(), that\u0026rsquo;s automatic. Many subsystems have Kconfig options to turn on -DDEBUG. A related convention uses VERBOSE_DEBUG to add dev_vdbg() messages to the ones already enabled by DEBUG.\n Chapter 14: Allocating memory  The kernel provides the following general purpose memory allocators: kmalloc(), kzalloc(), kcalloc(), vmalloc(), and vzalloc(). Please refer to the API documentation for further information about them.\nThe preferred form for passing a size of a struct is the following:\n p = kmalloc(sizeof(*p), ...);  The alternative form where struct name is spelled out hurts readability and introduces an opportunity for a bug when the pointer variable type is changed but the corresponding sizeof that is passed to a memory allocator is not.\nCasting the return value which is a void pointer is redundant. The conversion from void pointer to any other pointer type is guaranteed by the C programming language.\n Chapter 15: The inline disease  There appears to be a common misperception that gcc has a magic \u0026ldquo;make me faster\u0026rdquo; speedup option called \u0026ldquo;inline\u0026rdquo;. While the use of inlines can be appropriate (for example as a means of replacing macros, see Chapter 12), it very often is not. Abundant use of the inline keyword leads to a much bigger kernel, which in turn slows the system as a whole down, due to a bigger icache footprint for the CPU and simply because there is less memory available for the pagecache. Just think about it; a pagecache miss causes a disk seek, which easily takes 5 milliseconds. There are a LOT of cpu cycles that can go into these 5 milliseconds.\nA reasonable rule of thumb is to not put inline at functions that have more than 3 lines of code in them. An exception to this rule are the cases where a parameter is known to be a compiletime constant, and as a result of this constantness you know the compiler will be able to optimize most of your function away at compile time. For a good example of this later case, see the kmalloc() inline function.\nOften people argue that adding inline to functions that are static and used only once is always a win since there is no space tradeoff. While this is technically correct, gcc is capable of inlining these automatically without help, and the maintenance issue of removing the inline when a second user appears outweighs the potential value of the hint that tells gcc to do something it would have done anyway.\n Chapter 16: Function return values and names  Functions can return values of many different kinds, and one of the most common is a value indicating whether the function succeeded or failed. Such a value can be represented as an error-code integer (-Exxx = failure, 0 = success) or a \u0026ldquo;succeeded\u0026rdquo; boolean (0 = failure, non-zero = success).\nMixing up these two sorts of representations is a fertile source of difficult-to-find bugs. If the C language included a strong distinction between integers and booleans then the compiler would find these mistakes for us\u0026hellip; but it doesn\u0026rsquo;t. To help prevent such bugs, always follow this convention:\n If the name of a function is an action or an imperative command, the function should return an error-code integer. If the name is a predicate, the function should return a \u0026quot;succeeded\u0026quot; boolean.  For example, \u0026ldquo;add work\u0026rdquo; is a command, and the add_work() function returns 0 for success or -EBUSY for failure. In the same way, \u0026ldquo;PCI device present\u0026rdquo; is a predicate, and the pci_dev_present() function returns 1 if it succeeds in finding a matching device or 0 if it doesn\u0026rsquo;t.\nAll EXPORTed functions must respect this convention, and so should all public functions. Private (static) functions need not, but it is recommended that they do.\nFunctions whose return value is the actual result of a computation, rather than an indication of whether the computation succeeded, are not subject to this rule. Generally they indicate failure by returning some out-of-range result. Typical examples would be functions that return pointers; they use NULL or the ERR_PTR mechanism to report failure.\n Chapter 17: Don't re-invent the kernel macros  The header file include/linux/kernel.h contains a number of macros that you should use, rather than explicitly coding some variant of them yourself. For example, if you need to calculate the length of an array, take advantage of the macro\n#define ARRAY_SIZE(x) (sizeof(x) / sizeof((x)[0]))\nSimilarly, if you need to calculate the size of some structure member, use\n#define FIELD_SIZEOF(t, f) (sizeof(((t*)0)-\u0026gt;f))\nThere are also min() and max() macros that do strict type checking if you need them. Feel free to peruse that header file to see what else is already defined that you shouldn\u0026rsquo;t reproduce in your code.\n Chapter 18: Editor modelines and other cruft  Some editors can interpret configuration information embedded in source files, indicated with special markers. For example, emacs interprets lines marked like this:\n-- mode: c --\nOr like this:\n/* Local Variables: compile-command: \u0026ldquo;gcc -DMAGIC_DEBUG_FLAG foo.c\u0026rdquo; End: */\nVim interprets markers that look like this:\nDo not include any of these in source files. People have their own personal editor configurations, and your source files should not override them. This includes markers for indentation and mode configuration. People may use their own custom mode, or may have some other magic method for making indentation work correctly.\n[41] BUG-HUNTING.txt\n这篇文档讲述了如何定位内核中的bug，常用的方式包括通过git-bisect进行搜索，以及 通过常规的旧有方式进行搜索定位，下面对其进行简要描述。\nFinding using git-bisect # Using the provided tools with git makes finding bugs easy provided the bug is reproducible.\nSteps to do it:\n start using git for the kernel source read the man page for git-bisect have fun  Finding it the old way # [Sat Mar 2 10:32:33 PST 1996 KERNEL_BUG-HOWTO lm@sgi.com (Larry McVoy)]\nThis is how to track down a bug if you know nothing about kernel hacking. It\u0026rsquo;s a brute force approach but it works pretty well.\nYou need:\n . A reproducible bug - it has to happen predictably (sorry) . All the kernel tar files from a revision that worked to the revision that doesn't  You will then do:\n . Rebuild a revision that you believe works, install, and verify that. . Do a binary search over the kernels to figure out which one introduced the bug. I.e., suppose 1.3.28 didn't have the bug, but you know that 1.3.69 does. Pick a kernel in the middle and build that, like 1.3.50. Build \u0026amp; test; if it works, pick the mid point between .50 and .69, else the mid point between .28 and .50. . You'll narrow it down to the kernel that introduced the bug. You can probably do better than this but it gets tricky. . Narrow it down to a subdirectory - Copy kernel that works into \u0026quot;test\u0026quot;. Let's say that 3.62 works, but 3.63 doesn't. So you diff -r those two kernels and come up with a list of directories that changed. For each of those directories: Copy the non-working directory next to the working directory as \u0026quot;dir.63\u0026quot;. One directory at time, try moving the working directory to \u0026quot;dir.62\u0026quot; and mv dir.63 dir\u0026quot;time, try mv dir dir.62 mv dir.63 dir find dir -name '*.[oa]' -print | xargs rm -f And then rebuild and retest. Assuming that all related changes were contained in the sub directory, this should isolate the change to a directory. Problems: changes in header files may have occurred; I've found in my case that they were self explanatory - you may or may not want to give up when that happens. . Narrow it down to a file - You can apply the same technique to each file in the directory, hoping that the changes in that file are self contained. . Narrow it down to a routine - You can take the old file and the new file and manually create a merged file that has #ifdef VER62 routine() { ... } #else routine() { ... } #endif And then walk through that file, one routine at a time and prefix it with #define VER62 /* both routines here */ #undef VER62 Then recompile, retest, move the ifdefs until you find the one that makes the difference.  Finally, you take all the info that you have, kernel revisions, bug description, the extent to which you have narrowed it down, and pass that off to whomever you believe is the maintainer of that section. A post to linux.dev.kernel isn\u0026rsquo;t such a bad idea if you\u0026rsquo;ve done some work to narrow it down.\nIf you get it down to a routine, you\u0026rsquo;ll probably get a fix in 24 hours.\nMy apologies to Linus and the other kernel hackers for describing this brute force approach, it\u0026rsquo;s hardly what a kernel hacker would do. However, it does work and it lets non-hackers help fix bugs. And it is cool because Linux snapshots will let you do this - something that you can\u0026rsquo;t do with vendor supplied releases.\n还讲述了如何修复内核bug的方式。\nFixing the bug # Nobody is going to tell you how to fix bugs. Seriously. You need to work it out. But below are some hints on how to use the tools.\nTo debug a kernel, use objdump and look for the hex offset from the crash output to find the valid line of code/assembler. Without debug symbols, you will see the assembler code for the routine shown, but if your kernel has debug symbols the C code will also be available. (Debug symbols can be enabled in the kernel hacking menu of the menu configuration.) For example:\nobjdump -r -S -l --disassemble net/dccp/ipv4.o  NB.: you need to be at the top level of the kernel tree for this to pick up your C files.\nIf you don\u0026rsquo;t have access to the code you can also debug on some crash dumps e.g. crash dump output as shown by Dave Miller.\n EIP is at ip_queue_xmit+0x14/0x4c0 \u0026hellip; Code: 44 24 04 e8 6f 05 00 00 e9 e8 fe ff ff 8d 76 00 8d bc 27 00 00 00 00 55 57 56 53 81 ec bc 00 00 00 8b ac 24 d0 00 00 00 8b 5d 08 \u0026lt;8b\u0026gt; 83 3c 01 00 00 89 44 24 14 8b 45 28 85 c0 89 44 24 18 0f 85\nPut the bytes into a \u0026ldquo;foo.s\u0026rdquo; file like this:\n .text .globl foo  foo: .byte \u0026hellip;. /* bytes from Code: part of OOPS dump */\nCompile it with \u0026ldquo;gcc -c -o foo.o foo.s\u0026rdquo; then look at the output of \u0026ldquo;objdump \u0026ndash;disassemble foo.o\u0026rdquo;.\nOutput:\nip_queue_xmit: push %ebp push %edi push %esi push %ebx sub $0xbc, %esp mov 0xd0(%esp), %ebp ! %ebp = arg0 (skb) mov 0x8(%ebp), %ebx ! %ebx = skb-\u0026gt;sk mov 0x13c(%ebx), %eax ! %eax = inet_sk(sk)-\u0026gt;opt\n In addition, you can use GDB to figure out the exact file and line number of the OOPS from the vmlinux file. If you have CONFIG_DEBUG_INFO enabled, you can simply copy the EIP value from the OOPS:\nEIP: 0060:[] Not tainted VLI\nAnd use GDB to translate that to human-readable form:\ngdb vmlinux (gdb) l *0xc021e50e\nIf you don\u0026rsquo;t have CONFIG_DEBUG_INFO enabled, you use the function offset from the OOPS:\nEIP is at vt_ioctl+0xda8/0x1482\nAnd recompile the kernel with CONFIG_DEBUG_INFO enabled:\nmake vmlinux gdb vmlinux (gdb) p vt_ioctl (gdb) l *(0x+ 0xda8) or, as one command (gdb) l *(vt_ioctl + 0xda8)\nIf you have a call trace, such as :-\n Call Trace: [] :jbd:log_wait_commit+0xa3/0xf5 [] autoremove_wake_function+0x0/0x2e [] :jbd:journal_stop+0x1be/0x1ee \u0026hellip; this shows the problem in the :jbd: module. You can load that module in gdb and list the relevant code. gdb fs/jbd/jbd.ko (gdb) p log_wait_commit (gdb) l *(0x + 0xa3) or (gdb) l *(log_wait_commit + 0xa3)\n Another very useful option of the Kernel Hacking section in menuconfig is Debug memory allocations. This will help you see whether data has been initialised and not set before use etc. To see the values that get assigned with this look at mm/slab.c and search for POISON_INUSE. When using this an Oops will often show the poisoned data instead of zero which is the default.\nOnce you have worked out a fix please submit it upstream. After all open source is about sharing what you do and don\u0026rsquo;t you want to be recognised for your genius?\nPlease do read Documentation/SubmittingPatches though to help your code get accepted.\n[42] DMA-API-HOWTO.txt\nThis is a guide to device driver writers on how to use the DMA API with example pseudo-code. For a concise description of the API, see DMA-API.txt.\n[43] DMA-API.txt\nThis document describes the DMA API. For a more gentle introduction of the API (and actual examples) see Documentation/DMA-API-HOWTO.txt.\n[44] DMA-ISA-LPC.txt\nThis document describes how to do DMA transfers using the old ISA DMA controller. Even though ISA is more or less dead today the LPC bus uses the same DMA system so it will be around for quite some time.\n[45] DMA-attributes.txt\nThis document describes the semantics of the DMA attributes that are defined in linux/dma-attrs.h.\n[46] HOWTO.txt\nThis is the be-all, end-all document on this topic. It contains instructions on how to become a Linux kernel developer and how to learn to work with the Linux kernel development community. It tries to not contain anything related to the technical aspects of kernel programming, but will help point you in the right direction for that.\n[47] IPMI.txt\nThe Intelligent Platform Management Interface, or IPMI, is a standard for controlling intelligent devices that monitor a system. It provides for dynamic discovery of sensors in the system and the ability to monitor the sensors and be informed when the sensor\u0026rsquo;s values change or go outside certain boundaries. It also has a standardized database for field-replaceable units (FRUs) and a watchdog timer.\nTo use this, you need an interface to an IPMI controller in your system (called a Baseboard Management Controller, or BMC) and management software that can use the IPMI system.\nThis document describes how to use the IPMI driver for Linux. If you are not familiar with IPMI itself, see the web site at: http://www.intel.com/design/servers/ipmi/index.htm.\nIPMI is a big subject and I can\u0026rsquo;t cover it all here!\n[48] IRQ-affinity.txt\nSMP IRQ affinity，指的是\n对称多处理器中的中断请求绑定。\n/proc/irq/IRQ#/smp_affinity and /proc/irq/IRQ#/smp_affinity_list specify which target CPUs are permitted for a given IRQ source. It\u0026rsquo;s a bitmask (smp_affinity) or cpu list (smp_affinity_list) of allowed CPUs. It\u0026rsquo;s not allowed to turn off all CPUs, and if an IRQ controller does not support IRQ affinity then the value will not change from the default of all cpus.\n/proc/irq/IRQ#/smp_affinity和/proc/irq/IRQ#/smp_affinity_list指明了允许接收某 个中断请求IRQ#的多个或某个cpu。它是一个位掩码smp_affinity或者一个cpu列表 smp_affinity_list，其中记录了允许接受该中断请求的cpu。不允许禁止所有cpu接收该 中断请求，如果一个中断控制器不支持中断请求绑定，那么只能采用默认值，即允许所有 cpu接收该中断请求，并且这个值不会被修改。\n/proc/irq/default_smp_affinity specifies default affinity mask that applies to all non-active IRQs. Once IRQ is allocated/activated its affinity bitmask will be set to the default mask. It can then be changed as described above. Default mask is 0xffffffff.\n/proc/irq/default_smp_affinity指明了默认的中断绑定掩码，这个默认值将应用于所有 的非活动的、未激活的中断号。一旦一个中断号被分配、激活，那么它的中断绑定掩码将 被设置为这个默认值。这个默认值可以通过前面提到过的方法进行修改。这个默认掩码的 值为0xffffffff，请注意，该掩码是32位的。\nHere is an example of restricting IRQ44 (eth1) to CPU0-3 then restricting it to CPU4-7 (this is an 8-CPU SMP box):\n网卡向cpu发中断请求44，下面我们对这个中断请求与cpu的绑定关系进行设置，并通过 ping命令进行测试，网卡会将接收到的icmp请求，以中断44的形式发送到绑定的cpu，通 过查看cpu接收到的中断请求数量，我们可以判断，这个44这个中断请求与cpu的绑定关系 。\n[root@moon 44]# cd /proc/irq/44 [root@moon 44]# cat smp_affinity ffffffff 首先，查看到44这个中断请求的默认绑定掩码为0xffffffff，说明，所有的cpu都可以接 收该中断请求。\n[root@moon 44]# echo 0f \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 0000000f\n然后我们设置smp_affinity的值为0x0000000f，即使得编号为0-3的cpu允许接收该44这个 中断请求，其他的cpu都不会接收44这个中断请求。\n[root@moon 44]# ping -f h PING hell (195.4.7.3): 56 data bytes \u0026hellip; \u0026mdash; hell ping statistics \u0026mdash; 6029 packets transmitted, 6027 packets received, 0% packet loss round-trip min/avg/max = 0.1/0.1/0.4 ms\n然后，对主机进行ping测试，这里的-f表示洪泛，h表示主机，实际测试的时候，可以修 改为localhost。这个时候，应用程序ping向主机发送了icmp请求包，网卡设备捕获到之 后，会向cpu发送中断号为44的中断请求。现在该主机上有8个cpu，由于我们设置了编号 为0-3的cpu可以接收该中断，其他的则不可以，那么如果我们查看cpu对中断44的接收情 况时，只有编号为0-3的cpu才能接收到中断请求。\n[root@moon 44]# cat /proc/interrupts | grep \u0026lsquo;CPU|44:\u0026rsquo; CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 44: 1068 1785 1785 1783 0 0 0 0 IO-APIC-level eth1\n通过查看测试结果，我们发现cpu 4-7 确实没有接收到编号为44的中断请求，但是编号 为0-3的cpu接收到了该中断请求。\nAs can be seen from the line above IRQ44 was delivered only to the first four processors (0-3). Now lets restrict that IRQ to CPU(4-7).\n[root@moon 44]# echo f0 \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 000000f0\n进一步进行测试，我们将允许接收编号44的中断请求的cpu设定为编号4-7，即将 smp_affinity的值设定为0x000000f0，下面再次通过ping进行测试。\n[root@moon 44]# ping -f h PING hell (195.4.7.3): 56 data bytes .. \u0026mdash; hell ping statistics \u0026mdash; 2779 packets transmitted, 2777 packets received, 0% packet loss round-trip min/avg/max = 0.1/0.5/585.4 ms [root@moon 44]# cat /proc/interrupts | \u0026lsquo;CPU|44:\u0026rsquo; CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 44: 1068 1785 1785 1783 1784 1069 1070 1069 IO-APIC-level eth1\nThis time around IRQ44 was delivered only to the last four processors. i.e counters for the CPU0-3 did not change.\n将当前cpu接收到的中断请求44的数量，与前面一次ping测试时各个cpu接收到的中断请求 44的数量对比发现，只有编号为4-7的cpu接收到的中断请求44的数量发生了改变，说明我 们成功的设置了中断请求44的中断绑定到cpu 4-7。\nHere is an example of limiting that same irq (44) to cpus 1024 to 1031:\n[root@moon 44]# echo 1024-1031 \u0026gt; smp_affinity [root@moon 44]# cat smp_affinity 1024-1031\n上面的语法可以将中断绑定到编号范围为1024-1031的cpu上。\nNote that to do this with a bitmask would require 32 bitmasks of zero to follow the pertinent one.\n[49] IRQ.txt\nWhat is an IRQ?\nAn IRQ is an interrupt request from a device. Currently they can come in over a pin, or over a packet. Several devices may be connected to the same pin thus sharing an IRQ.\nAn IRQ number is a kernel identifier used to talk about a hardware interrupt source. Typically this is an index into the global irq_desc array, but except for what linux/interrupt.h implements the details are architecture specific.\nAn IRQ number is an enumeration of the possible interrupt sources on a machine. Typically what is enumerated is the number of input pins on all of the interrupt controller in the system. In the case of ISA what is enumerated are the 16 input pins on the two i8259 interrupt controllers.\nArchitectures can assign additional meaning to the IRQ numbers, and are encouraged to in the case where there is any manual configuration of the hardware involved. The ISA IRQs are a classic example of assigning this kind of additional meaning.\n[50] Intel-IOMMU.txt\nLinux IOMMU Support\n[51] ManagementStyle.txt\nLinux kernel management style\n[52] SAK.txt\nSAK, 讲述的其实是系统魔法键sysrq中的一个，还是很有必要的，学习下吧。\nAn operating system\u0026rsquo;s Secure Attention Key is a security tool which is provided as protection against trojan password capturing programs. It is an undefeatable way of killing all programs which could be masquerading as login applications. Users need to be taught to enter this key sequence before they log in to the system.\nFrom the PC keyboard, Linux has two similar but different ways of providing SAK. One is the ALT-SYSRQ-K sequence. You shouldn\u0026rsquo;t use this sequence. It is only available if the kernel was compiled with sysrq support.\nThe proper way of generating a SAK is to define the key sequence using `loadkeys\u0026rsquo;. This will work whether or not sysrq support is compiled into the kernel.\nSAK works correctly when the keyboard is in raw mode. This means that once defined, SAK will kill a running X server. If the system is in run level 5, the X server will restart. This is what you want to happen.\nWhat key sequence should you use? Well, CTRL-ALT-DEL is used to reboot the machine. CTRL-ALT-BACKSPACE is magical to the X server. We\u0026rsquo;ll choose CTRL-ALT-PAUSE.\nIn your rc.sysinit (or rc.local) file, add the command\necho \u0026ldquo;control alt keycode 101 = SAK\u0026rdquo; | /bin/loadkeys\nAnd that\u0026rsquo;s it! Only the superuser may reprogram the SAK key.\nNOTES # 1: Linux SAK is said to be not a \u0026ldquo;true SAK\u0026rdquo; as is required by systems which implement C2 level security. This author does not know why.\n2: On the PC keyboard, SAK kills all applications which have /dev/console opened.\nUnfortunately this includes a number of things which you don\u0026rsquo;t actually want killed. This is because these applications are incorrectly holding /dev/console open. Be sure to complain to your Linux distributor about this!\nYou can identify processes which will be killed by SAK with the command\nls -l /proc/[0-9]/fd/ | grep console\nl-wx\u0026mdash;\u0026mdash; 1 root root 64 Mar 18 00:46 /proc/579/fd/0 -\u0026gt; /dev/console\nThen:\nps aux|grep 579\nroot 579 0.0 0.1 1088 436 ? S 00:43 0:00 gpm -t ps/2\nSo `gpm\u0026rsquo; will be killed by SAK. This is a bug in gpm. It should be closing standard input. You can work around this by finding the initscript which launches gpm and changing it thusly:\nOld:\ndaemon gpm\nNew:\ndaemon gpm \u0026lt; /dev/null\nVixie cron also seems to have this problem, and needs the same treatment.\nAlso, one prominent Linux distribution has the following three lines in its rc.sysinit and rc scripts:\nexec 3\u0026lt;\u0026amp;0 exec 4\u0026gt;\u0026amp;1 exec 5\u0026gt;\u0026amp;2\nThese commands cause all daemons which are launched by the initscripts to have file descriptors 3, 4 and 5 attached to /dev/console. So SAK kills them all. A workaround is to simply delete these lines, but this may cause system management applications to malfunction - test everything well.\n[53] SM501.txt\nThe Silicon Motion SM501 multimedia companion chip is a multifunction device which may provide numerous interfaces including USB host controller USB gadget, asynchronous serial ports, audio functions, and a dual display video interface. The device may be connected by PCI or local bus with varying functions enabled.\n[54] SecurityBugs.txt\nLinux kernel developers take security very seriously. As such, we\u0026rsquo;d like to know when a security bug is found so that it can be fixed and disclosed as quickly as possible. Please report security bugs to the Linux kernel security team.\n Contact  The Linux kernel security team can be contacted by email at security@kernel.org. This is a private list of security officers who will help verify the bug report and develop and release a fix. It is possible that the security team will bring in extra help from area maintainers to understand and fix the security vulnerability.\nAs it is with any bug, the more information provided the easier it will be to diagnose and fix. Please review the procedure outlined in REPORTING-BUGS if you are unclear about what information is helpful. Any exploit code is very helpful and will not be released without consent from the reporter unless it has already been made public.\nDisclosure  The goal of the Linux kernel security team is to work with the bug submitter to bug resolution as well as disclosure. We prefer to fully disclose the bug as soon as possible. It is reasonable to delay disclosure when the bug or the fix is not yet fully understood, the solution is not well-tested or for vendor coordination. However, we expect these delays to be short, measurable in days, not weeks or months. A disclosure date is negotiated by the security team working with the bug submitter as well as vendors. However, the kernel security team holds the final say when setting a disclosure date. The timeframe for disclosure is from immediate (esp. if it\u0026rsquo;s already publicly known) to a few weeks. As a basic default policy, we expect report date to disclosure date to be on the order of 7 days.\nNon-disclosure agreements  The Linux kernel security team is not a formal body and therefore unable to enter any non-disclosure agreements.\n[55] SubmitChecklist.txt\nLinux Kernel patch submission checklist\nHere are some basic things that developers should do if they want to see their kernel patch submissions accepted more quickly.\nThese are all above and beyond the documentation that is provided in Documentation/SubmittingPatches and elsewhere regarding submitting Linux kernel patches.\n1: If you use a facility then #include the file that defines/declares that facility. Don't depend on other header files pulling in ones that you use. 2: Builds cleanly with applicable or modified CONFIG options =y, =m, and =n. No gcc warnings/errors, no linker warnings/errors. 2b: Passes allnoconfig, allmodconfig 2c: Builds successfully when using O=builddir 3: Builds on multiple CPU architectures by using local cross-compile tools or some other build farm. 4: ppc64 is a good architecture for cross-compilation checking because it tends to use `unsigned long' for 64-bit quantities. 5: Check your patch for general style as detailed in Documentation/CodingStyle. Check for trivial violations with the patch style checker prior to submission (scripts/checkpatch.pl). You should be able to justify all violations that remain in your patch. 6: Any new or modified CONFIG options don't muck up the config menu. 7: All new Kconfig options have help text. 8: Has been carefully reviewed with respect to relevant Kconfig combinations. This is very hard to get right with testing -- brainpower pays off here. 9: Check cleanly with sparse. 10: Use 'make checkstack' and 'make namespacecheck' and fix any problems that they find. Note: checkstack does not point out problems explicitly, but any one function that uses more than 512 bytes on the stack is a candidate for change. 11: Include kernel-doc to document global kernel APIs. (Not required for static functions, but OK there also.) Use 'make htmldocs' or 'make mandocs' to check the kernel-doc and fix any issues. 12: Has been tested with CONFIG_PREEMPT, CONFIG_DEBUG_PREEMPT, CONFIG_DEBUG_SLAB, CONFIG_DEBUG_PAGEALLOC, CONFIG_DEBUG_MUTEXES, CONFIG_DEBUG_SPINLOCK, CONFIG_DEBUG_ATOMIC_SLEEP, CONFIG_PROVE_RCU and CONFIG_DEBUG_OBJECTS_RCU_HEAD all simultaneously enabled. 13: Has been build- and runtime tested with and without CONFIG_SMP and CONFIG_PREEMPT. 14: If the patch affects IO/Disk, etc: has been tested with and without CONFIG_LBDAF. 15: All codepaths have been exercised with all lockdep features enabled. 16: All new /proc entries are documented under Documentation/ 17: All new kernel boot parameters are documented in Documentation/kernel-parameters.txt. 18: All new module parameters are documented with MODULE_PARM_DESC() 19: All new userspace interfaces are documented in Documentation/ABI/. See Documentation/ABI/README for more information. Patches that change userspace interfaces should be CCed to linux-api@vger.kernel.org. 20: Check that it all passes `make headers_check'. 21: Has been checked with injection of at least slab and page-allocation failures. See Documentation/fault-injection/. If the new code is substantial, addition of subsystem-specific fault injection might be appropriate. 22: Newly-added code has been compiled with `gcc -W' (use \u0026quot;make EXTRA_CFLAGS=-W\u0026quot;). This will generate lots of noise, but is good for finding bugs like \u0026quot;warning: comparison between signed and unsigned\u0026quot;. 23: Tested after it has been merged into the -mm patchset to make sure that it still works with all of the other queued patches and various changes in the VM, VFS, and other subsystems. 24: All memory barriers {e.g., barrier(), rmb(), wmb()} need a comment in the source code that explains the logic of what they are doing and why. 25: If any ioctl's are added by the patch, then also update Documentation/ioctl/ioctl-number.txt. 26: If your modified source code depends on or uses any of the kernel APIs or features that are related to the following kconfig symbols, then test multiple builds with the related kconfig symbols disabled and/or =m (if that option is available) [not all of these at the same time, just various/random combinations of them]: CONFIG_SMP, CONFIG_SYSFS, CONFIG_PROC_FS, CONFIG_INPUT, CONFIG_PCI, CONFIG_BLOCK, CONFIG_PM, CONFIG_HOTPLUG, CONFIG_MAGIC_SYSRQ, CONFIG_NET, CONFIG_INET=n (but latter with CONFIG_NET=y)  [56] SubmittingPatches.txt\nHow to Get Your Change Into the Linux Kernel or Care And Operation Of Your Linus Torvalds\nFor a person or company who wishes to submit a change to the Linux kernel, the process can sometimes be daunting if you\u0026rsquo;re not familiar with \u0026ldquo;the system.\u0026rdquo; This text is a collection of suggestions which can greatly increase the chances of your change being accepted.\nRead Documentation/SubmitChecklist for a list of items to check before submitting code. If you are submitting a driver, also read Documentation/SubmittingDrivers.\n SECTION 1 - CREATING AND SENDING YOUR CHANGE #  \u0026ldquo;diff -up\u0026rdquo;   Use \u0026ldquo;diff -up\u0026rdquo; or \u0026ldquo;diff -uprN\u0026rdquo; to create patches.\nAll changes to the Linux kernel occur in the form of patches, as generated by diff(1). When creating your patch, make sure to create it in \u0026ldquo;unified diff\u0026rdquo; format, as supplied by the \u0026lsquo;-u\u0026rsquo; argument to diff(1). Also, please use the \u0026lsquo;-p\u0026rsquo; argument which shows which C function each change is in - that makes the resultant diff a lot easier to read. Patches should be based in the root kernel source directory, not in any lower subdirectory.\nTo create a patch for a single file, it is often sufficient to do:\nSRCTREE= linux-2.6 MYFILE= drivers/net/mydriver.c cd $SRCTREE cp $MYFILE $MYFILE.orig vi $MYFILE # make your change cd .. diff -up $SRCTREE/$MYFILE{.orig,} \u0026gt; /tmp/patch  To create a patch for multiple files, you should unpack a \u0026ldquo;vanilla\u0026rdquo;, or unmodified kernel source tree, and generate a diff against your own source tree. For example:\nMYSRC= /devel/linux-2.6 tar xvfz linux-2.6.12.tar.gz mv linux-2.6.12 linux-2.6.12-vanilla diff -uprN -X linux-2.6.12-vanilla/Documentation/dontdiff \\ linux-2.6.12-vanilla $MYSRC \u0026gt; /tmp/patch  \u0026ldquo;dontdiff\u0026rdquo; is a list of files which are generated by the kernel during the build process, and should be ignored in any diff(1)-generated patch. The \u0026ldquo;dontdiff\u0026rdquo; file is included in the kernel tree in 2.6.12 and later. For earlier kernel versions, you can get it from http://www.xenotime.net/linux/doc/dontdiff.\nMake sure your patch does not include any extra files which do not belong in a patch submission. Make sure to review your patch -after- generated it with diff(1), to ensure accuracy.\nIf your changes produce a lot of deltas, you may want to look into splitting them into individual patches which modify things in logical stages. This will facilitate easier reviewing by other kernel developers, very important if you want your patch accepted. There are a number of scripts which can aid in this: Quilt: http://savannah.nongnu.org/projects/quilt\nAndrew Morton\u0026rsquo;s patch scripts: http://userweb.kernel.org/~akpm/stuff/patch-scripts.tar.gz Instead of these scripts, quilt is the recommended patch management tool (see above).\nDescribe your changes.  Describe the technical detail of the change(s) your patch includes.\nBe as specific as possible. The WORST descriptions possible include things like \u0026ldquo;update driver X\u0026rdquo;, \u0026ldquo;bug fix for driver X\u0026rdquo;, or \u0026ldquo;this patch includes updates for subsystem X. Please apply.\u0026rdquo;\nThe maintainer will thank you if you write your patch description in a form which can be easily pulled into Linux\u0026rsquo;s source code management system, git, as a \u0026ldquo;commit log\u0026rdquo;. See #15, below.\nIf your description starts to get long, that\u0026rsquo;s a sign that you probably need to split up your patch. See #3, next.\nWhen you submit or resubmit a patch or patch series, include the complete patch description and justification for it. Don\u0026rsquo;t just say that this is version N of the patch (series). Don\u0026rsquo;t expect the patch merger to refer back to earlier patch versions or referenced URLs to find the patch description and put that into the patch. I.e., the patch (series) and its description should be self-contained. This benefits both the patch merger(s) and reviewers. Some reviewers probably didn\u0026rsquo;t even receive earlier versions of the patch.\nIf the patch fixes a logged bug entry, refer to that bug entry by number and URL.\nSeparate your changes.  Separate logical changes into a single patch file.\nFor example, if your changes include both bug fixes and performance enhancements for a single driver, separate those changes into two or more patches. If your changes include an API update, and a new driver which uses that new API, separate those into two patches.\nOn the other hand, if you make a single change to numerous files, group those changes into a single patch. Thus a single logical change is contained within a single patch.\nIf one patch depends on another patch in order for a change to be complete, that is OK. Simply note \u0026ldquo;this patch depends on patch X\u0026rdquo; in your patch description.\nIf you cannot condense your patch set into a smaller set of patches, then only post say 15 or so at a time and wait for review and integration.\nStyle check your changes.  Check your patch for basic style violations, details of which can be found in Documentation/CodingStyle. Failure to do so simply wastes the reviewers time and will get your patch rejected, probably without even being read.\nAt a minimum you should check your patches with the patch style checker prior to submission (scripts/checkpatch.pl). You should be able to justify all violations that remain in your patch.\nSelect e-mail destination.  Look through the MAINTAINERS file and the source code, and determine if your change applies to a specific subsystem of the kernel, with an assigned maintainer. If so, e-mail that person.\nIf no maintainer is listed, or the maintainer does not respond, send your patch to the primary Linux kernel developer\u0026rsquo;s mailing list, linux-kernel@vger.kernel.org. Most kernel developers monitor this e-mail list, and can comment on your changes.\nDo not send more than 15 patches at once to the vger mailing lists!!!\nLinus Torvalds is the final arbiter of all changes accepted into the Linux kernel. His e-mail address is torvalds@linux-foundation.org. He gets a lot of e-mail, so typically you should do your best to -avoid- sending him e-mail.\nPatches which are bug fixes, are \u0026ldquo;obvious\u0026rdquo; changes, or similarly require little discussion should be sent or CC\u0026rsquo;d to Linus. Patches which require discussion or do not have a clear advantage should usually be sent first to linux-kernel. Only after the patch is discussed should the patch then be submitted to Linus.\nSelect your CC (e-mail carbon copy) list.  Unless you have a reason NOT to do so, CC linux-kernel@vger.kernel.org.\nOther kernel developers besides Linus need to be aware of your change, so that they may comment on it and offer code review and suggestions. linux-kernel is the primary Linux kernel developer mailing list. Other mailing lists are available for specific subsystems, such as USB, framebuffer devices, the VFS, the SCSI subsystem, etc. See the MAINTAINERS file for a mailing list that relates specifically to your change.\nMajordomo lists of VGER.KERNEL.ORG at: http://vger.kernel.org/vger-lists.html\nIf changes affect userland-kernel interfaces, please send the MAN-PAGES maintainer (as listed in the MAINTAINERS file) a man-pages patch, or at least a notification of the change, so that some information makes its way into the manual pages.\nEven if the maintainer did not respond in step #5, make sure to ALWAYS copy the maintainer when you change their code.\nFor small patches you may want to CC the Trivial Patch Monkey trivial@kernel.org which collects \u0026ldquo;trivial\u0026rdquo; patches. Have a look into the MAINTAINERS file for its current manager. Trivial patches must qualify for one of the following rules: Spelling fixes in documentation Spelling fixes which could break grep(1) Warning fixes (cluttering with useless warnings is bad) Compilation fixes (only if they are actually correct) Runtime fixes (only if they actually fix things) Removing use of deprecated functions/macros (eg. check_region) Contact detail and documentation fixes Non-portable code replaced by portable code (even in arch-specific, since people copy, as long as it\u0026rsquo;s trivial) Any fix by the author/maintainer of the file (ie. patch monkey in re-transmission mode)\nNo MIME, no links, no compression, no attachments. Just plain text.  Linus and other kernel developers need to be able to read and comment on the changes you are submitting. It is important for a kernel developer to be able to \u0026ldquo;quote\u0026rdquo; your changes, using standard e-mail tools, so that they may comment on specific portions of your code.\nFor this reason, all patches should be submitting e-mail \u0026ldquo;inline\u0026rdquo;. WARNING: Be wary of your editor\u0026rsquo;s word-wrap corrupting your patch, if you choose to cut-n-paste your patch.\nDo not attach the patch as a MIME attachment, compressed or not. Many popular e-mail applications will not always transmit a MIME attachment as plain text, making it impossible to comment on your code. A MIME attachment also takes Linus a bit more time to process, decreasing the likelihood of your MIME-attached change being accepted.\nException: If your mailer is mangling patches then someone may ask you to re-send them using MIME.\nSee Documentation/email-clients.txt for hints about configuring your e-mail client so that it sends your patches untouched.\nE-mail size.  When sending patches to Linus, always follow step #7.\nLarge changes are not appropriate for mailing lists, and some maintainers. If your patch, uncompressed, exceeds 300 kB in size, it is preferred that you store your patch on an Internet-accessible server, and provide instead a URL (link) pointing to your patch.\nName your kernel version.  It is important to note, either in the subject line or in the patch description, the kernel version to which this patch applies.\nIf the patch does not apply cleanly to the latest kernel version, Linus will not apply it.\nDon\u0026rsquo;t get discouraged. Re-submit.  After you have submitted your change, be patient and wait. If Linus likes your change and applies it, it will appear in the next version of the kernel that he releases.\nHowever, if your change doesn\u0026rsquo;t appear in the next version of the kernel, there could be any number of reasons. It\u0026rsquo;s YOUR job to narrow down those reasons, correct what was wrong, and submit your updated change.\nIt is quite common for Linus to \u0026ldquo;drop\u0026rdquo; your patch without comment. That\u0026rsquo;s the nature of the system. If he drops your patch, it could be due to * Your patch did not apply cleanly to the latest kernel version. * Your patch was not sufficiently discussed on linux-kernel. * A style issue (see section 2). * An e-mail formatting issue (re-read this section). * A technical problem with your change. * He gets tons of e-mail, and yours got lost in the shuffle. * You are being annoying.\nWhen in doubt, solicit comments on linux-kernel mailing list.\nInclude PATCH in the subject  Due to high e-mail traffic to Linus, and to linux-kernel, it is common convention to prefix your subject line with [PATCH]. This lets Linus and other kernel developers more easily distinguish patches from other e-mail discussions.\nSign your work  To improve tracking of who did what, especially with patches that can percolate to their final resting place in the kernel through several layers of maintainers, we\u0026rsquo;ve introduced a \u0026ldquo;sign-off\u0026rdquo; procedure on patches that are being emailed around.\nThe sign-off is a simple line at the end of the explanation for the patch, which certifies that you wrote it or otherwise have the right to pass it on as an open-source patch. The rules are pretty simple: if you can certify the below:\n Developer's Certificate of Origin 1.1 By making a contribution to this project, I certify that: (a) The contribution was created in whole or in part by me and I have the right to submit it under the open source license indicated in the file; or (b) The contribution is based upon previous work that, to the best of my knowledge, is covered under an appropriate open source license and I have the right under that license to submit that work with modifications, whether created in whole or in part by me, under the same open source license (unless I am permitted to submit under a different license), as indicated in the file; or (c) The contribution was provided directly to me by some other person who certified (a), (b) or (c) and I have not modified it. (d) I understand and agree that this project and the contribution are public and that a record of the contribution (including all personal information I submit with it, including my sign-off) is maintained indefinitely and may be redistributed consistent with this project or the open source license(s) involved. then you just add a line saying Signed-off-by: Random J Developer \u0026lt;random@developer.example.org\u0026gt;  using your real name (sorry, no pseudonyms or anonymous contributions.)\nSome people also put extra tags at the end. They\u0026rsquo;ll just be ignored for now, but you can do this to mark internal company procedures or just point out some special detail about the sign-off.\nIf you are a subsystem or branch maintainer, sometimes you need to slightly modify patches you receive in order to merge them, because the code is not exactly the same in your tree and the submitters\u0026rsquo;. If you stick strictly to rule (c), you should ask the submitter to rediff, but this is a totally counter-productive waste of time and energy. Rule (b) allows you to adjust the code, but then it is very impolite to change one submitter\u0026rsquo;s code and make him endorse your bugs. To solve this problem, it is recommended that you add a line between the last Signed-off-by header and yours, indicating the nature of your changes. While there is nothing mandatory about this, it seems like prepending the description with your mail and/or name, all enclosed in square brackets, is noticeable enough to make it obvious that you are responsible for last-minute changes. Example :\n Signed-off-by: Random J Developer \u0026lt;random@developer.example.org\u0026gt; [lucky@maintainer.example.org: struct foo moved from foo.c to foo.h] Signed-off-by: Lucky K Maintainer \u0026lt;lucky@maintainer.example.org\u0026gt;  This practise is particularly helpful if you maintain a stable branch and want at the same time to credit the author, track changes, merge the fix, and protect the submitter from complaints. Note that under no circumstances can you change the author\u0026rsquo;s identity (the From header), as it is the one which appears in the changelog.\nSpecial note to back-porters: It seems to be a common and useful practise to insert an indication of the origin of a patch at the top of the commit message (just after the subject line) to facilitate tracking. For instance, here\u0026rsquo;s what we see in 2.6-stable :\nDate: Tue May 13 19:10:30 +0000 SCSI: libiscsi regression in 2.6.25: fix nop timer handling commit 4cf1043593db6a337f10e006c23c69e5fc93e722 upstream  And here\u0026rsquo;s what appears in 2.4 :\nDate: Tue May 13 22:12:27 +0200 wireless, airo: waitbusy() won't delay [backport of 2.6 commit b7acbdfbd1f277c1eb23f344f899cfa4cd0bf36a]  Whatever the format, this information provides a valuable help to people tracking your trees, and to people trying to trouble-shoot bugs in your tree. 13) When to use Acked-by: and Cc:\nThe Signed-off-by: tag indicates that the signer was involved in the development of the patch, or that he/she was in the patch\u0026rsquo;s delivery path.\nIf a person was not directly involved in the preparation or handling of a patch but wishes to signify and record their approval of it then they can arrange to have an Acked-by: line added to the patch\u0026rsquo;s changelog.\nAcked-by: is often used by the maintainer of the affected code when that maintainer neither contributed to nor forwarded the patch.\nAcked-by: is not as formal as Signed-off-by:. It is a record that the acker has at least reviewed the patch and has indicated acceptance. Hence patch mergers will sometimes manually convert an acker\u0026rsquo;s \u0026ldquo;yep, looks good to me\u0026rdquo; into an Acked-by:.\nAcked-by: does not necessarily indicate acknowledgement of the entire patch. For example, if a patch affects multiple subsystems and has an Acked-by: from one subsystem maintainer then this usually indicates acknowledgement of just the part which affects that maintainer\u0026rsquo;s code. Judgement should be used here. When in doubt people should refer to the original discussion in the mailing list archives.\nIf a person has had the opportunity to comment on a patch, but has not provided such comments, you may optionally add a \u0026ldquo;Cc:\u0026rdquo; tag to the patch. This is the only tag which might be added without an explicit action by the person it names. This tag documents that potentially interested parties have been included in the discussion\nUsing Reported-by:, Tested-by: and Reviewed-by:  If this patch fixes a problem reported by somebody else, consider adding a Reported-by: tag to credit the reporter for their contribution. Please note that this tag should not be added without the reporter\u0026rsquo;s permission, especially if the problem was not reported in a public forum. That said, if we diligently credit our bug reporters, they will, hopefully, be inspired to help us again in the future.\nA Tested-by: tag indicates that the patch has been successfully tested (in some environment) by the person named. This tag informs maintainers that some testing has been performed, provides a means to locate testers for future patches, and ensures credit for the testers.\nReviewed-by:, instead, indicates that the patch has been reviewed and found acceptable according to the Reviewer\u0026rsquo;s Statement:\n Reviewer's statement of oversight By offering my Reviewed-by: tag, I state that: (a) I have carried out a technical review of this patch to evaluate its appropriateness and readiness for inclusion into the mainline kernel. (b) Any problems, concerns, or questions relating to the patch have been communicated back to the submitter. I am satisfied with the submitter's response to my comments. (c) While there may be things that could be improved with this submission, I believe that it is, at this time, (1) a worthwhile modification to the kernel, and (2) free of known issues which would argue against its inclusion. (d) While I have reviewed the patch and believe it to be sound, I do not (unless explicitly stated elsewhere) make any warranties or guarantees that it will achieve its stated purpose or function properly in any given situation.  A Reviewed-by tag is a statement of opinion that the patch is an appropriate modification of the kernel without any remaining serious technical issues. Any interested reviewer (who has done the work) can offer a Reviewed-by tag for a patch. This tag serves to give credit to reviewers and to inform maintainers of the degree of review which has been done on the patch. Reviewed-by: tags, when supplied by reviewers known to understand the subject area and to perform thorough reviews, will normally increase the likelihood of your patch getting into the kernel.\nThe canonical patch format  The canonical patch subject line is:\nSubject: [PATCH 001/123] subsystem: summary phrase  The canonical patch message body contains the following:\n  A \u0026ldquo;from\u0026rdquo; line specifying the patch author.\n  An empty line.\n  The body of the explanation, which will be copied to the permanent changelog to describe this patch.\n  The \u0026ldquo;Signed-off-by:\u0026rdquo; lines, described above, which will also go in the changelog.\n  A marker line containing simply \u0026ldquo;\u0026mdash;\u0026rdquo;.\n  Any additional comments not suitable for the changelog.\n  The actual patch (diff output).\n  The Subject line format makes it very easy to sort the emails alphabetically by subject line - pretty much any email reader will support that - since because the sequence number is zero-padded, the numerical and alphabetic sort is the same.\nThe \u0026ldquo;subsystem\u0026rdquo; in the email\u0026rsquo;s Subject should identify which area or subsystem of the kernel is being patched.\nThe \u0026ldquo;summary phrase\u0026rdquo; in the email\u0026rsquo;s Subject should concisely describe the patch which that email contains. The \u0026ldquo;summary phrase\u0026rdquo; should not be a filename. Do not use the same \u0026ldquo;summary phrase\u0026rdquo; for every patch in a whole patch series (where a \u0026ldquo;patch series\u0026rdquo; is an ordered sequence of multiple, related patches).\nBear in mind that the \u0026ldquo;summary phrase\u0026rdquo; of your email becomes a globally-unique identifier for that patch. It propagates all the way into the git changelog. The \u0026ldquo;summary phrase\u0026rdquo; may later be used in developer discussions which refer to the patch. People will want to google for the \u0026ldquo;summary phrase\u0026rdquo; to read discussion regarding that patch. It will also be the only thing that people may quickly see when, two or three months later, they are going through perhaps thousands of patches using tools such as \u0026ldquo;gitk\u0026rdquo; or \u0026ldquo;git log \u0026ndash;oneline\u0026rdquo;.\nFor these reasons, the \u0026ldquo;summary\u0026rdquo; must be no more than 70-75 characters, and it must describe both what the patch changes, as well as why the patch might be necessary. It is challenging to be both succinct and descriptive, but that is what a well-written summary should do.\nThe \u0026ldquo;summary phrase\u0026rdquo; may be prefixed by tags enclosed in square brackets: \u0026ldquo;Subject: [PATCH tag] \u0026rdquo;. The tags are not considered part of the summary phrase, but describe how the patch should be treated. Common tags might include a version descriptor if the multiple versions of the patch have been sent out in response to comments (i.e., \u0026ldquo;v1, v2, v3\u0026rdquo;), or \u0026ldquo;RFC\u0026rdquo; to indicate a request for comments. If there are four patches in a patch series the individual patches may be numbered like this: 1/4, 2/4, 3/4, 4/4. This assures that developers understand the order in which the patches should be applied and that they have reviewed or applied all of the patches in the patch series.\nA couple of example Subjects:\nSubject: [patch 2/5] ext2: improve scalability of bitmap searching Subject: [PATCHv2 001/207] x86: fix eflags tracking  The \u0026ldquo;from\u0026rdquo; line must be the very first line in the message body, and has the form:\n From: Original Author \u0026lt;author@example.com\u0026gt;  The \u0026ldquo;from\u0026rdquo; line specifies who will be credited as the author of the patch in the permanent changelog. If the \u0026ldquo;from\u0026rdquo; line is missing, then the \u0026ldquo;From:\u0026rdquo; line from the email header will be used to determine the patch author in the changelog.\nThe explanation body will be committed to the permanent source changelog, so should make sense to a competent reader who has long since forgotten the immediate details of the discussion that might have led to this patch. Including symptoms of the failure which the patch addresses (kernel log messages, oops messages, etc.) is especially useful for people who might be searching the commit logs looking for the applicable patch. If a patch fixes a compile failure, it may not be necessary to include all of the compile failures; just enough that it is likely that someone searching for the patch can find it. As in the \u0026ldquo;summary phrase\u0026rdquo;, it is important to be both succinct as well as descriptive.\nThe \u0026ldquo;\u0026mdash;\u0026rdquo; marker line serves the essential purpose of marking for patch handling tools where the changelog message ends.\nOne good use for the additional comments after the \u0026ldquo;\u0026mdash;\u0026rdquo; marker is for a diffstat, to show what files have changed, and the number of inserted and deleted lines per file. A diffstat is especially useful on bigger patches. Other comments relevant only to the moment or the maintainer, not suitable for the permanent changelog, should also go here. A good example of such comments might be \u0026ldquo;patch changelogs\u0026rdquo; which describe what has changed between the v1 and v2 version of the patch.\nIf you are going to include a diffstat after the \u0026ldquo;\u0026mdash;\u0026rdquo; marker, please use diffstat options \u0026ldquo;-p 1 -w 70\u0026rdquo; so that filenames are listed from the top of the kernel source tree and don\u0026rsquo;t use too much horizontal space (easily fit in 80 columns, maybe with some indentation).\nSee more details on the proper patch format in the following references.\nSending \u0026ldquo;git pull\u0026rdquo; requests (from Linus emails)  Please write the git repo address and branch name alone on the same line so that I can\u0026rsquo;t even by mistake pull from the wrong branch, and so that a triple-click just selects the whole thing.\nSo the proper format is something along the lines of:\n \u0026quot;Please pull from git://jdelvare.pck.nerim.net/jdelvare-2.6 i2c-for-linus to get these changes:\u0026quot;  so that I don\u0026rsquo;t have to hunt-and-peck for the address and inevitably get it wrong (actually, I\u0026rsquo;ve only gotten it wrong a few times, and checking against the diffstat tells me when I get it wrong, but I\u0026rsquo;m just a lot more comfortable when I don\u0026rsquo;t have to \u0026ldquo;look for\u0026rdquo; the right thing to pull, and double-check that I have the right branch-name).\nPlease use \u0026ldquo;git diff -M \u0026ndash;stat \u0026ndash;summary\u0026rdquo; to generate the diffstat: the -M enables rename detection, and the summary enables a summary of new/deleted or renamed files.\nWith rename detection, the statistics are rather different [\u0026hellip;] because git will notice that a fair number of the changes are renames.\n SECTION 2 - HINTS, TIPS, AND TRICKS # This section lists many of the common \u0026ldquo;rules\u0026rdquo; associated with code submitted to the kernel. There are always exceptions\u0026hellip; but you must have a really good reason for doing so. You could probably call this section Linus Computer Science 101.\n Read Documentation/CodingStyle  Nuff said. If your code deviates too much from this, it is likely to be rejected without further review, and without comment.\nOne significant exception is when moving code from one file to another \u0026ndash; in this case you should not modify the moved code at all in the same patch which moves it. This clearly delineates the act of moving the code and your changes. This greatly aids review of the actual differences and allows tools to better track the history of the code itself.\nCheck your patches with the patch style checker prior to submission (scripts/checkpatch.pl). The style checker should be viewed as a guide not as the final word. If your code looks better with a violation then its probably best left alone.\nThe checker reports at three levels:\n ERROR: things that are very likely to be wrong WARNING: things requiring careful review CHECK: things requiring thought  You should be able to justify all violations that remain in your patch.\n#ifdefs are ugly  Code cluttered with ifdefs is difficult to read and maintain. Don\u0026rsquo;t do it. Instead, put your ifdefs in a header, and conditionally define \u0026lsquo;static inline\u0026rsquo; functions, or macros, which are used in the code. Let the compiler optimize away the \u0026ldquo;no-op\u0026rdquo; case.\nSimple example, of poor code:\n dev = alloc_etherdev (sizeof(struct funky_private)); if (!dev) return -ENODEV; #ifdef CONFIG_NET_FUNKINESS init_funky_net(dev); #endif  Cleaned-up example:\n(in header) #ifndef CONFIG_NET_FUNKINESS static inline void init_funky_net (struct net_device *d) {} #endif\n(in the code itself) dev = alloc_etherdev (sizeof(struct funky_private)); if (!dev) return -ENODEV; init_funky_net(dev);\n\u0026lsquo;static inline\u0026rsquo; is better than a macro  Static inline functions are greatly preferred over macros. They provide type safety, have no length limitations, no formatting limitations, and under gcc they are as cheap as macros.\nMacros should only be used for cases where a static inline is clearly suboptimal [there are a few, isolated cases of this in fast paths], or where it is impossible to use a static inline function [such as string-izing].\n\u0026lsquo;static inline\u0026rsquo; is preferred over \u0026lsquo;static inline\u0026rsquo;, \u0026lsquo;extern inline\u0026rsquo;, and \u0026lsquo;extern inline\u0026rsquo;.\nDon\u0026rsquo;t over-design.  Don\u0026rsquo;t try to anticipate nebulous future cases which may or may not be useful: \u0026ldquo;Make it as simple as you can, and no simpler.\u0026rdquo;\n[57] SubmittingPatches.txt\nSubmitting Drivers For The Linux Kernel # This document is intended to explain how to submit device drivers to the various kernel trees. Note that if you are interested in video card drivers you should probably talk to XFree86 (http://www.xfree86.org/) and/or X.Org (http://x.org/) instead.\nAlso read the Documentation/SubmittingPatches document.\nAllocating Device Numbers # Major and minor numbers for block and character devices are allocated by the Linux assigned name and number authority (currently this is Torben Mathiasen). The site is http://www.lanana.org/. This also deals with allocating numbers for devices that are not going to be submitted to the mainstream kernel. See Documentation/devices.txt for more information on this.\nIf you don\u0026rsquo;t use assigned numbers then when your device is submitted it will be given an assigned number even if that is different from values you may have shipped to customers before.\nWho To Submit Drivers To # Linux 2.0: No new drivers are accepted for this kernel tree.\nLinux 2.2: No new drivers are accepted for this kernel tree.\nLinux 2.4: If the code area has a general maintainer then please submit it to the maintainer listed in MAINTAINERS in the kernel file. If the maintainer does not respond or you cannot find the appropriate maintainer then please contact Willy Tarreau w@1wt.eu.\nLinux 2.6: The same rules apply as 2.4 except that you should follow linux-kernel to track changes in API\u0026rsquo;s. The final contact point for Linux 2.6 submissions is Andrew Morton.\nWhat Criteria Determine Acceptance # Licensing: The code must be released to us under the GNU General Public License. We don\u0026rsquo;t insist on any kind of exclusive GPL licensing, and if you wish the driver to be useful to other communities such as BSD you may well wish to release under multiple licenses. See accepted licenses at include/linux/module.h\nCopyright: The copyright owner must agree to use of GPL. It\u0026rsquo;s best if the submitter and copyright owner are the same person/entity. If not, the name of the person/entity authorizing use of GPL should be listed in case it\u0026rsquo;s necessary to verify the will of the copyright owner.\nInterfaces: If your driver uses existing interfaces and behaves like other drivers in the same class it will be much more likely to be accepted than if it invents gratuitous new ones. If you need to implement a common API over Linux and NT drivers do it in userspace.\nCode: Please use the Linux style of code formatting as documented in Documentation/CodingStyle. If you have sections of code that need to be in other formats, for example because they are shared with a windows driver kit and you want to maintain them just once separate them out nicely and note this fact.\nPortability:Pointers are not always 32bits, not all computers are little endian, people do not all have floating point and you shouldn\u0026rsquo;t use inline x86 assembler in your driver without careful thought. Pure x86 drivers generally are not popular. If you only have x86 hardware it is hard to test portability but it is easy to make sure the code can easily be made portable.\nClarity: It helps if anyone can see how to fix the driver. It helps you because you get patches not bug reports. If you submit a driver that intentionally obfuscates how the hardware works it will go in the bitbucket.\nPM support: Since Linux is used on many portable and desktop systems, your driver is likely to be used on such a system and therefore it should support basic power management by implementing, if necessary, the .suspend and .resume methods used during the system-wide suspend and resume transitions. You should verify that your driver correctly handles the suspend and resume, but if you are unable to ensure that, please at least define the .suspend method returning the -ENOSYS (\u0026ldquo;Function not implemented\u0026rdquo;) error. You should also try to make sure that your driver uses as little power as possible when it\u0026rsquo;s not doing anything. For the driver testing instructions see Documentation/power/drivers-testing.txt and for a relatively complete overview of the power management issues related to drivers see Documentation/power/devices.txt .\nControl: In general if there is active maintenance of a driver by the author then patches will be redirected to them unless they are totally obvious and without need of checking. If you want to be the contact and update point for the driver it is a good idea to state this in the comments, and include an entry in MAINTAINERS for your driver.\nWhat Criteria Do Not Determine Acceptance # Vendor: Being the hardware vendor and maintaining the driver is often a good thing. If there is a stable working driver from other people already in the tree don\u0026rsquo;t expect \u0026lsquo;we are the vendor\u0026rsquo; to get your driver chosen. Ideally work with the existing driver author to build a single perfect driver.\nAuthor: It doesn\u0026rsquo;t matter if a large Linux company wrote the driver, or kernel tree. Anyone who tells you otherwise isn\u0026rsquo;t telling the whole story.\n[58] VGA-softcursor.txt\nLinux now has some ability to manipulate cursor appearance. Normally, you can set the size of hardware cursor (and also work around some ugly bugs in those miserable Trident cards\u0026ndash;see #define TRIDENT_GLITCH in drivers/video/vgacon.c). You can now play a few new tricks: you can make your cursor look like a non-blinking red block, make it inverse background of the character it\u0026rsquo;s over or to highlight that character and still choose whether the original hardware cursor should remain visible or not. There may be other things I have never thought of.\n[59] applying-patches.txt\nA frequently asked question on the Linux Kernel Mailing List is how to apply a patch to the kernel or, more specifically, what base kernel a patch for one of the many trees/branches should be applied to. Hopefully this document will explain this to you.\n[60] atomic_opts.txt\nThis document is intended to serve as a guide to Linux port maintainers on how to implement atomic counter, bitops, and spinlock interfaces properly.\nport这里是移植的意思。\n[61] bad_memory.txt\nHow to deal with bad memory e.g. reported by memtest86+ ?\n如何处理内存诊断工具memtest86+报告的坏内存。 #########################################################\nThere are three possibilities I know of:\n Reinsert/swap the memory modules  重新插入内存条、将内存条拔下来插入其他内存槽。\nBuy new modules (best!) or try to exchange the memory if you have spare-parts  购买新的内存条（这是最好的）或者试着换用其他备用的内存，如果你有的话。\nUse BadRAM or memmap  继续使用坏内存，但是要对其中的某些坏区域进行屏蔽。\nThis Howto is about number 3) .\nBadRAM\n# BadRAM is the actively developed and available as kernel-patch here: http://rick.vanrein.org/linux/badram/\nFor more details see the BadRAM documentation.\nmemmap\n# memmap is already in the kernel and usable as kernel-parameter at boot-time. Its syntax is slightly strange and you may need to calculate the values by yourself!\nSyntax to exclude a memory area (see kernel-parameters.txt for details): memmap=$\nmemmap=容量:起始地址。 注意，这里容量的表示有两种方式，一种是通过十进制+容量单位，一种是通过16进制， 采用16进制的时候，默认表示容量单位为字节。 可以参照下面的示例。\nExample: memtest86+ reported here errors at address 0x18691458, 0x1869and some others. All had 0x1869xxxx in common, so I chose a pattern of 0x18690000,0xffff0000.\nWith the numbers of the example above: memmap=64K$0x18690000 or memmap=0x10000$0x18690000\n[62] basic_profiling.txt\n[63] binfmt_misc.txt\nThis Kernel feature allows you to invoke almost (for restrictions see below) every program by simply typing its name in the shell. This includes for example compiled Java(TM), Python or Emacs programs.\n只要你在shell里面输入程序的名字，linux内核几乎允许你执行所有的程序，例如运行 java程序、python程序或者emacs程序等。\nTo achieve this you must tell binfmt_misc which interpreter has to be invoked with which binary. Binfmt_misc recognises the binary-type by matching some bytes at the beginning of the file with a magic byte sequence (masking out specified bits) you have supplied. Binfmt_misc can also recognise a filename extension aka \u0026lsquo;.com\u0026rsquo; or \u0026lsquo;.exe\u0026rsquo;.\nA few examples (assumed you are in /proc/sys/fs/binfmt_misc):\n  enable support for em86 (like binfmt_em86, for Alpha AXP only): echo \u0026lsquo;:i386:M::\\x7fELF\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02 \\x00\\x03:\\xff\\xff\\xff\\xff\\xff\\xfe\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff \\xff\\xfb\\xff\\xff:/bin/em86:\u0026rsquo; \u0026gt; register echo \u0026lsquo;:i486:M::\\x7fELF\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02 \\x00\\x06:\\xff\\xff\\xff\\xff\\xff\\xfe\\xfe\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff \\xff\\xfb\\xff\\xff:/bin/em86:\u0026rsquo; \u0026gt; register\n  enable support for packed DOS applications (pre-configured dosemu hdimages): echo \u0026lsquo;:DEXE:M::\\x0eDEX::/usr/bin/dosexec:\u0026rsquo; \u0026gt; register\n  enable support for Windows executables using wine: echo \u0026lsquo;:DOSWin:M::MZ::/usr/local/bin/wine:\u0026rsquo; \u0026gt; register\n  For java support see Documentation/java.txt\n[64] braille-console.txt\nTo get early boot messages on a braille device (before userspace screen readers can start), you first need to compile the support for the usual serial console (see serial-console.txt), and for braille device (in Device Drivers - Accessibility).\n[65] bt8xxgpio.txt\n[66] btmrvl.txt\nAll commands are used via debugfs interface.\n[67] bus-virt-phys-mapping.txt\n[ NOTE: The virt_to_bus() and bus_to_virt() functions have been superseded by the functionality provided by the PCI DMA interface (see Documentation/DMA-API-HOWTO.txt). They continue to be documented below for historical purposes, but new code must not use them. \u0026ndash;davidm 00/12/12 ]\n[ This is a mail message in response to a query on IO mapping, thus the strange format for a \u0026ldquo;document\u0026rdquo; ]\nThe AHA-is a bus-master device, and your patch makes the driver give the controller the physical address of the buffers, which is correct on x86 (because all bus master devices see the physical memory mappings directly).\nHowever, on many setups, there are actually three different ways of looking at memory addresses, and in this case we actually want the third, the so-called \u0026ldquo;bus address\u0026rdquo;.\nEssentially, the three ways of addressing memory are (this is \u0026ldquo;real memory\u0026rdquo;, that is, normal RAM\u0026ndash;see later about other details):\n - CPU untranslated. This is the \u0026quot;physical\u0026quot; address. Physical address 0 is what the CPU sees when it drives zeroes on the memory bus. - CPU translated address. This is the \u0026quot;virtual\u0026quot; address, and is completely internal to the CPU itself with the CPU doing the appropriate translations into \u0026quot;CPU untranslated\u0026quot;. - bus address. This is the address of memory as seen by OTHER devices, not the CPU. Now, in theory there could be many different bus addresses, with each device seeing memory in some device-specific way, but happily most hardware designers aren't actually actively trying to make things any more complex than necessary, so you can assume that all external hardware sees the memory the same way.  Now, on normal PCs the bus address is exactly the same as the physical address, and things are very simple indeed. However, they are that simple because the memory and the devices share the same address space, and that is not generally necessarily true on other PCI/ISA setups.\nNow, just as an example, on the PReP (PowerPC Reference Platform), the CPU sees a memory map something like this (this is from memory):\n0-2 GB \u0026quot;real memory\u0026quot; 2 GB-3 GB \u0026quot;system IO\u0026quot; (inb/out and similar accesses on x86) 3 GB-4 GB \u0026quot;IO memory\u0026quot; (shared memory over the IO bus)  Now, that looks simple enough. However, when you look at the same thing from the viewpoint of the devices, you have the reverse, and the physical memory address 0 actually shows up as address 2 GB for any IO master.\nSo when the CPU wants any bus master to write to physical memory 0, it has to give the master address 0x8000as the memory address.\nSo, for example, depending on how the kernel is actually mapped on the PPC, you can end up with a setup like this:\n physical address: 0 virtual address: 0xC0000000 bus address: 0x80000000  where all the addresses actually point to the same thing. It\u0026rsquo;s just seen through different translations..\n[68] cachetlb.txt\nCache and TLB Flushing Under Linux\n转译后备缓冲器，在中国大陆也被翻译为页表缓存、转址旁路缓存，为CPU的一种缓存， 由存储器管理单元用于改进虚拟地址到物理地址的转译速度。目前所有的桌面型及服务器 型处理器皆使用TLB。TLB具有固定数目的空间槽，用于存放将虚拟地址映射至物理地址的 标签页表条目。为典型的内容可寻址存储器。其搜索关键字为虚拟内存地址，其搜索结果 为物理地址。如果请求的虚拟地址在TLB中存在，CAM 将给出一个非常快速的匹配结果， 之后就可以使用得到的物理地址访问存储器。如果请求的虚拟地址不在TLB 中，就会使用 标签页表进行虚实地址转换，而标签页表的访问速度比TLB慢很多。\n[69] circular-buffers.txt\nLinux provides a number of features that can be used to implement circular buffering. There are two sets of such features:\nlinux提供了一些特征用于实现环形缓冲，这些特征主要可以分为两组：\n(1) Convenience functions for determining information about power-of-2 sized buffers.\n 一些方便使用的函数，用于获取、设置2^x的容量的环形缓冲区中的信息。  (2) Memory barriers for when the producer and the consumer of objects in the buffer don\u0026rsquo;t want to share a lock.\n 内存访问限制，用于保证环形缓冲区中数据对象的生产者和消费者不能共享锁。  To use these facilities, as discussed below, there needs to be just one producer and just one consumer. It is possible to handle multiple producers by serialising them, and to handle multiple consumers by serialising them.\n[70] coccinelle.txt\n[71] cpu-hotplug.txt\nCPU hotplug Support in Linux(tm) Kernel\n[72] cpu-load.txt\nLinux exports various bits of information via /proc/stat' and /proc/uptime' that userland tools, such as top(1), use to calculate the average time system spent in a particular state\n[73] cputopology.txt\nExport CPU topology info via sysfs. Items (attributes) are similar to /proc/cpuinfo.\n[74] dcdbas.txt\nThe Dell Systems Management Base Driver provides a sysfs interface for systems management software such as Dell OpenManage to perform system management interrupts and host control actions (system power cycle or power off after OS shutdown) on certain Dell systems.\n[75] debugging-modules.txt\nDebugging Modules after 2.6.3\n[76] debugging-via-ohci1394.txt\nUsing physical DMA provided by OHCI-FireWire controllers for debugging\n[77] dell_rbu.txt\nPurpose: Demonstrate the usage of the new open sourced rbu (Remote BIOS Update) driver for updating BIOS images on Dell servers and desktops.\n[78] devices.txt\nThis list is the Linux Device List, the official registry of allocated device numbers and /dev directory nodes for the Linux operating system.\n[79] dmaengine.txt\nBelow is a guide to device driver writers on how to use the Slave-DMA API of the DMA Engine. This is applicable only for slave DMA usage only\n[80] dontdiff.txt\n[81] dynamic-debug-howto.txt\nThis document describes how to use the dynamic debug (ddebug) feature.\nDynamic debug is designed to allow you to dynamically enable/disable kernel code to obtain additional kernel information. Currently, if CONFIG_DYNAMIC_DEBUG is set, then all pr_debug()/dev_dbg() calls can be dynamically enabled per-callsite.\nDynamic debug has even more useful features:\n  Simple query language allows turning on and off debugging statements by matching any combination of:\n source filename function name line number (including ranges of line numbers) module name format string    Provides a debugfs control file: /dynamic_debug/control which can\n  be read to display the complete list of known debug statements, to help guide you\n  [82] edac.txt\nEDAC, error detection and correction.\nThe \u0026lsquo;edac\u0026rsquo; kernel module goal is to detect and report errors that occur within the computer system running under linux.\n[83] eisa.txt\nEISA bus support.\n[84] email-clients.txt\nEmail clients info for Linux. 介绍了在通过email提交linux内核补丁信息时的一些与email客户端相关的注意事项，例 如使用Alphine、Evolution、Kmail、Lotus Notes、Mutt、Pine、Sylpheed、 Thunderbird、TkRat、Gmail Web等。\n[85] feature-removal-schedule.txt\nThe following is a list of files and features that are going to be removed in the kernel source tree. Every entry should contain what exactly is going away, why it is happening, and who is going to be doing the work. When the feature is removed from the kernel, it should also be removed from this file.\nMon Sep 29 012:03:32 CST 2014\n[86] flexible-arrays.txt\nLarge contiguous memory allocations can be unreliable in the Linux kernel. Kernel programmers will sometimes respond to this problem by allocating pages with vmalloc(). This solution not ideal, though. On 32-bit systems, memory from vmalloc() must be mapped into a relatively small address space; it\u0026rsquo;s easy to run out. On SMP systems, the page table changes required by vmalloc() allocations can require expensive cross-processor interrupts on all CPUs. And, on all systems, use of space in the vmalloc() range increases pressure on the translation lookaside buffer (TLB), reducing the erformance of the system\n[87] futex-requeue-pi.txt\nFutex Requeue PI # Requeueing of tasks from a non-PI futex to a PI futex requires special handling in order to ensure the underlying rt_mutex is never left without an owner if it has waiters; doing so would break the PI boosting logic [see rt-mutex-desgin.txt] For the purposes of brevity, this action will be referred to as \u0026ldquo;requeue_pi\u0026rdquo; throughout this document. Priority inheritance is abbreviated throughout as \u0026ldquo;PI\u0026rdquo;.\n[88] gcov.txt\nUsing gcov with the Linux kernel\n[89] gpio.txt\nA \u0026ldquo;General Purpose Input/Output\u0026rdquo; (GPIO) is a flexible software-controlled digital signal. They are provided from many kinds of chip, and are familiar to Linux developers working with embedded and custom hardware.\n[90] highuid.txt\nNotes on the change from 16-bit UIDs to 32-bit UIDs:\n  kernel code MUST take into account __kernel_uid_t and __kernel_uid32_t when communicating between user and kernel space in an ioctl or data structure.\n  kernel code should use uid_t and gid_t in kernel-private structures and code.\n  [91] hw_random.txt\nIntroduction:\nThe hw_random framework is software that makes use of a special hardware feature on your CPU or motherboard, a Random Number Generator (RNG). The software has two parts: core providing the /dev/hw_random character device and its sysfs support, plus a hardware-specific driver that plugs into that core.\nTo make the most effective use of these mechanisms, you should download the support software as well. Download the latest version of the \u0026ldquo;rng-tools\u0026rdquo; package from the hw_random driver\u0026rsquo;s official Web site:\n http://sourceforge.net/projects/gkernel/  Those tools use /dev/hw_random to fill the kernel entropy pool, which is used internally and exported by the /dev/urandom and /dev/random special files.\n[92] hwspinlock.txt\nHardware Spinlock Framework\n[93] init.txt\nExplaining the dreaded \u0026ldquo;No init found.\u0026rdquo; boot hang message\n[94] initrd.txt\nUsing the initial RAM disk (initrd)\ninitrd provides the capability to load a RAM disk by the boot loader. This RAM disk can then be mounted as the root file system and programs can be run from it. Afterwards, a new root file system can be mounted from a different device. The previous root (from initrd) is then moved to a directory and can be subsequently unmounted.\ninitrd is mainly designed to allow system startup to occur in two phases, where the kernel comes up with a minimum set of compiled-in drivers, and where additional modules are loaded from initrd.\nThis document gives a brief overview of the use of initrd. A more detailed discussion of the boot process can be found in [1].\nOperation\nWhen using initrd, the system typically boots as follows:\n  the boot loader loads the kernel and the initial RAM disk\n  the kernel converts initrd into a \u0026ldquo;normal\u0026rdquo; RAM disk and frees the memory used by initrd\n  if the root device is not /dev/ram0, the old (deprecated) change_root procedure is followed. see the \u0026ldquo;Obsolete root change mechanism\u0026rdquo; section below.\n  root device is mounted. if it is /dev/ram0, the initrd image is then mounted as root\n  /sbin/init is executed (this can be any valid executable, including shell scripts; it is run with uid 0 and can do basically everything init can do).\n  init mounts the \u0026ldquo;real\u0026rdquo; root file system\n  init places the root file system at the root directory using the pivot_root system call\n  init execs the /sbin/init on the new root filesystem, performing the usual boot sequence\n  the initrd file system is removed\n  Note that changing the root directory does not involve unmounting it. It is therefore possible to leave processes running on initrd during that procedure. Also note that file systems mounted under initrd continue to be accessible.  [95] intel_txt.txt\nIntel(R) TXT Overview:\nIntel\u0026rsquo;s technology for safer computing, Intel(R) Trusted Execution Technology (Intel(R) TXT), defines platform-level enhancements that provide the building blocks for creating trusted platforms.\nIntel TXT was formerly known by the code name LaGrande Technology (LT).\nIntel TXT in Brief: o Provides dynamic root of trust for measurement (DRTM) o Data protection in case of improper shutdown o Measurement and verification of launched environment\nIntel TXT is part of the vPro(TM) brand and is also available some non-vPro systems. It is currently available on desktop systems based on the Q35, X38, Q45, and Q43 Express chipsets (e.g. Dell Optiplex 755, HP dc7800, etc.) and mobile systems based on the GM45, PM45, and GS45 Express chipsets.\n[96] io-mapping.txt\nThe io_mapping functions in linux/io-mapping.h provide an abstraction for efficiently mapping small regions of an I/O device to the CPU. The initial usage is to support the large graphics aperture on 32-bit processors where ioremap_wc cannot be used to statically map the entire aperture to the CPU as it would consume too much of the kernel address space.\n[97] io_ordering.txt\nOn some platforms, so-called memory-mapped I/O is weakly ordered. On such platforms, driver writers are responsible for ensuring that I/O writes to memory-mapped addresses on their device arrive in the order intended. This is typically done by reading a \u0026lsquo;safe\u0026rsquo; device or bridge register, causing the I/O chipset to flush pending writes to the device before any reads are posted. A driver would usually use this technique immediately prior to the exit of a critical section of code protected by spinlocks. This would ensure that subsequent writes to I/O space arrived only after all prior writes (much like a memory barrier op, mb(), only with respect to I/O).\n[98] iostats.txt\nI/O statistics fields\nSince 2.4.20 (and some versions before, with patches), and 2.5.45, more extensive disk statistics have been introduced to help measure disk activity. Tools such as sar and iostat typically interpret these and do the work for you, but in case you are interested in creating your own tools, the fields are explained here.\n[99] irqflags-tracing.txt\nIRQ-flags state tracing\nthe \u0026ldquo;irq-flags tracing\u0026rdquo; feature \u0026ldquo;traces\u0026rdquo; hardirq and softirq state, in that it gives interested subsystems an opportunity to be notified of every hardirqs-off/hardirqs-on, softirqs-off/softirqs-on event that happens in the kernel.\n[100] isapnp.txt\nISA Plug \u0026amp; Play support\n[101] java.txt\nJava(tm) Binary Kernel Support for Linv1.03\nLinux beats them ALL! While all other OS\u0026rsquo;s are TALKING about direct of Java Binaries in the OS, Linux is doing it!\n[101] kernel-doc-nano-HOWTO.txt\n[102] kernel-docs.txt\n这篇文档列出了很多文档的索引以及参考书目，要经常看这些书目。\nIndex of Documentation for People Interested in Writing and/or Understanding the Linux Kernel. Juan-Mariano de Goyeneche jmseyas@dit.upm.es\nThe need for a document like this one became apparent in the linux-kernel mailing list as the same questions, asking for pointers to information, appeared again and again.\nFortunately, as more and more people get to GNU/Linux, more and more get interested in the Kernel. But reading the sources is not always enough. It is easy to understand the code, but miss the concepts, the philosophy and design decisions behind this code.\nUnfortunately, not many documents are available for beginners to start. And, even if they exist, there was no \u0026ldquo;well-known\u0026rdquo; place which kept track of them. These lines try to cover this lack. All documents available on line known by the author are listed, while some reference books are also mentioned.\nPLEASE, if you know any paper not listed here or write a new document, send me an e-mail, and I\u0026rsquo;ll include a reference to it here. Any corrections, ideas or comments are also welcomed.\nThe papers that follow are listed in no particular order. All are cataloged with the following fields: the document\u0026rsquo;s \u0026ldquo;Title\u0026rdquo;, the \u0026ldquo;Author\u0026rdquo;/s, the \u0026ldquo;URL\u0026rdquo; where they can be found, some \u0026ldquo;Keywords\u0026rdquo; helpful when searching for specific topics, and a brief \u0026ldquo;Description\u0026rdquo; of the Document.\nEnjoy!\nON-LINE DOCS:\n  Title: \u0026ldquo;Linux Device Drivers, Third Edition\u0026rdquo; Author: Jonathan Corbet, Alessandro Rubini, Greg Kroah-Hartman URL: http://lwn.net/Kernel/LDD3/ Description: A 600-page book covering the (2.6.10) driver programming API and kernel hacking in general. Available under the Creative Commons Attribution-ShareAlike 2.0 license.\n  Title: \u0026ldquo;The Linux Kernel\u0026rdquo; Author: David A. Rusling. URL: http://www.tldp.org/LDP/tlk/tlk.html Keywords: everything!, book. Description: On line, 200 pages book describing most aspects of the Linux Kernel. Probably, the first reference for beginners. Lots of illustrations explaining data structures use and relationships in the purest Richard W. Stevens' style. Contents: \u0026ldquo;1.-Hardware Basics, 2.-Software Basics, 3.-Memory Management, 4.-Processes, 5.-Interprocess Communication Mechanisms, 6.-PCI, 7.-Interrupts and Interrupt Handling, 8.-Device Drivers, 9.-The File system, 10.-Networks, 11.-Kernel Mechanisms, 12.-Modules, 13.-The Linux Kernel Sources, A.-Linux Data Structures, B.-The Alpha AXP Processor, C.-Useful Web and FTP Sites, D.-The GNU General Public License, Glossary\u0026rdquo;. In short: a must have.\n  Title: \u0026ldquo;Linux Device Drivers, 2nd Edition\u0026rdquo; Author: Alessandro Rubini and Jonathan Corbet. URL: http://www.xml.com/ldd/chapter/book/index.html Keywords: device drivers, modules, debugging, memory, hardware, interrupt handling, char drivers, block drivers, kmod, mmap, DMA, buses. Description: O\u0026rsquo;Reilly\u0026rsquo;s popular book, now also on-line under the GNU Free Documentation License. Notes: You can also buy it in paper-form from O\u0026rsquo;Reilly. See below under BOOKS (Not on-line).\n  Title: \u0026ldquo;Conceptual Architecture of the Linux Kernel\u0026rdquo; Author: Ivan T. Bowman. URL: http://plg.uwaterloo.ca/ Keywords: conceptual software architecture, extracted design, reverse engineering, system structure. Description: Conceptual software architecture of the Linux kernel, automatically extracted from the source code. Very detailed. Good figures. Gives good overall kernel understanding.\n  Title: \u0026ldquo;Concrete Architecture of the Linux Kernel\u0026rdquo; Author: Ivan T. Bowman, Saheem Siddiqi, and Meyer C. Tanuan. URL: http://plg.uwaterloo.ca/ Keywords: concrete architecture, extracted design, reverse engineering, system structure, dependencies. Description: Concrete architecture of the Linux kernel, automatically extracted from the source code. Very detailed. Good figures. Gives good overall kernel understanding. This papers focus on lower details than its predecessor (files, variables\u0026hellip;).\n  Title: \u0026ldquo;Linux as a Case Study: Its Extracted Software Architecture\u0026rdquo; Author: Ivan T. Bowman, Richard C. Holt and Neil V. Brewster. URL: http://plg.uwaterloo.ca/ Keywords: software architecture, architecture recovery, redocumentation. Description: Paper appeared at ICSE'99, Los Angeles, May 16-22,\n  A mixture of the previous two documents from the same author.    Title: \u0026ldquo;Overview of the Virtual File System\u0026rdquo; Author: Richard Gooch. URL: http://www.mjmwired.net/kernel/Documentation/filesystems/vfs.txt Keywords: VFS, File System, mounting filesystems, opening files, dentries, dcache. Description: Brief introduction to the Linux Virtual File System. What is it, how it works, operations taken when opening a file or mounting a file system and description of important data structures explaining the purpose of each of their entries.\n  Title: \u0026ldquo;The Linux RAID-1, 4, 5 Code\u0026rdquo; Author: Ingo Molnar, Gadi Oxman and Miguel de Icaza. URL: http://www.linuxjournal.com/article.php?sid=2391 Keywords: RAID, MD driver. Description: Linux Journal Kernel Korner article. Here is its abstract: \u0026ldquo;A description of the implementation of the RAID-1, RAID-4 and RAID-5 personalities of the MD device driver in the Linux kernel, providing users with high performance and reliable, secondary-storage capability using software\u0026rdquo;.\n  Title: \u0026ldquo;Dynamic Kernels: Modularized Device Drivers\u0026rdquo; Author: Alessandro Rubini. URL: http://www.linuxjournal.com/article.php?sid=1219 Keywords: device driver, module, loading/unloading modules, allocating resources. Description: Linux Journal Kernel Korner article. Here is its abstract: \u0026ldquo;This is the first of a series of four articles co-authored by Alessandro Rubini and Georg Zezchwitz which present a practical approach to writing Linux device drivers as kernel loadable modules. This installment presents an introduction to the topic, preparing the reader to understand next month\u0026rsquo;s installment\u0026rdquo;.\n  Title: \u0026ldquo;Dynamic Kernels: Discovery\u0026rdquo; Author: Alessandro Rubini. URL: http://www.linuxjournal.com/article.php?sid=1220 Keywords: character driver, init_module, clean_up module, autodetection, mayor number, minor number, file operations, open(), close(). Description: Linux Journal Kernel Korner article. Here is its abstract: \u0026ldquo;This article, the second of four, introduces part of the actual code to create custom module implementing a character device driver. It describes the code for module initialization and cleanup, as well as the open() and close() system calls\u0026rdquo;.\n  Title: \u0026ldquo;The Devil\u0026rsquo;s in the Details\u0026rdquo; Author: Georg v. Zezschwitz and Alessandro Rubini. URL: http://www.linuxjournal.com/article.php?sid=1221 Keywords: read(), write(), select(), ioctl(), blocking/non blocking mode, interrupt handler. Description: Linux Journal Kernel Korner article. Here is its abstract: \u0026ldquo;This article, the third of four on writing character device drivers, introduces concepts of reading, writing, and using ioctl-calls\u0026rdquo;.\n  Title: \u0026ldquo;Dissecting Interrupts and Browsing DMA\u0026rdquo; Author: Alessandro Rubini and Georg v. Zezschwitz. URL: http://www.linuxjournal.com/article.php?sid=1222 Keywords: interrupts, irqs, DMA, bottom halves, task queues. Description: Linux Journal Kernel Korner article. Here is its abstract: \u0026ldquo;This is the fourth in a series of articles about writing character device drivers as loadable kernel modules. This month, we further investigate the field of interrupt handling. Though it is conceptually simple, practical limitations and constraints make this an ``interesting'' part of device driver writing, and several different facilities have been provided for different situations. We also investigate the complex topic of DMA\u0026rdquo;.\n  Title: \u0026ldquo;Device Drivers Concluded\u0026rdquo; Author: Georg v. Zezschwitz. URL: http://www.linuxjournal.com/article.php?sid=1287 Keywords: address spaces, pages, pagination, page management, demand loading, swapping, memory protection, memory mapping, mmap, virtual memory areas (VMAs), vremap, PCI. Description: Finally, the above turned out into a five articles series. This latest one\u0026rsquo;s introduction reads: \u0026ldquo;This is the last of five articles about character device drivers. In this final section, Georg deals with memory mapping devices, beginning with an overall description of the Linux memory management concepts\u0026rdquo;.\n  Title: \u0026ldquo;Network Buffers And Memory Management\u0026rdquo; Author: Alan Cox. URL: http://www.linuxjournal.com/article.php?sid=1312 Keywords: sk_buffs, network devices, protocol/link layer variables, network devices flags, transmit, receive, configuration, multicast. Description: Linux Journal Kernel Korner. Here is the abstract: \u0026ldquo;Writing a network device driver for Linux is fundamentally simple\u0026mdash;most of the complexity (other than talking to the hardware) involves managing network packets in memory\u0026rdquo;.\n  Title: \u0026ldquo;Writing Linux Device Drivers\u0026rdquo; Author: Michael K. Johnson. URL: http://users.evitech.fi/~tk/rtos/writing_linux_device_d.html Keywords: files, VFS, file operations, kernel interface, character vs block devices, I/O access, hardware interrupts, DMA, access to user memory, memory allocation, timers. Description: Introductory 50-minutes (sic) tutorial on writing device drivers. 12 pages written by the same author of the \u0026ldquo;Kernel Hackers' Guide\u0026rdquo; which give a very good overview of the topic.\n  Title: \u0026ldquo;The Venus kernel interface\u0026rdquo; Author: Peter J. Braam. URL: http://www.coda.cs.cmu.edu/doc/html/kernel-venus-protocol.html Keywords: coda, filesystem, venus, cache manager. Description: \u0026ldquo;This document describes the communication between Venus and kernel level file system code needed for the operation of the Coda filesystem. This version document is meant to describe the current interface (version 1.0) as well as improvements we envisage\u0026rdquo;.\n  Title: \u0026ldquo;Programming PCI-Devices under Linux\u0026rdquo; Author: Claus Schroeter. URL: ftp://ftp.llp.fu-berlin.de/pub/linux/LINUX-LAB/whitepapers/pcip.ps.gz Keywords: PCI, device, busmastering. Description: 6 pages tutorial on PCI programming under Linux. Gives the basic concepts on the architecture of the PCI subsystem, as long as basic functions and macros to read/write the devices and perform busmastering.\n  Title: \u0026ldquo;Writing Character Device Driver for Linux\u0026rdquo; Author: R. Baruch and C. Schroeter. URL: ftp://ftp.llp.fu-berlin.de/pub/linux/LINUX-LAB/whitepapers/drivers.ps.gz Keywords: character device drivers, I/O, signals, DMA, accessing ports in user space, kernel environment. Description: 68 pages paper on writing character drivers. A little bit old (1.993, 1.994) although still useful.\n  Title: \u0026ldquo;Design and Implementation of the Second Extended Filesystem\u0026rdquo; Author: Rémy Card, Theodore Ts\u0026rsquo;o, Stephen Tweedie. URL: http://web.mit.edu/tytso/www/linux/ext2intro.html Keywords: ext2, linux fs history, inode, directory, link, devices, VFS, physical structure, performance, benchmarks, ext2fs library, ext2fs tools, e2fsck. Description: Paper written by three of the top ext2 hackers. Covers Linux filesystems history, ext2 motivation, ext2 features, design, physical structure on disk, performance, benchmarks, e2fsck\u0026rsquo;s passes description\u0026hellip; A must read! Notes: This paper was first published in the Proceedings of the First Dutch International Symposium on Linux, ISBN 90-367-0385-9.\n  Title: \u0026ldquo;Analysis of the Ext2fs structure\u0026rdquo; Author: Louis-Dominique Dubeau. URL: http://www.nondot.org/sabre/os/files/FileSystems/ext2fs/ Keywords: ext2, filesystem, ext2fs. Description: Description of ext2\u0026rsquo;s blocks, directories, inodes, bitmaps, invariants\u0026hellip;\n  Title: \u0026ldquo;Journaling the Linux ext2fs Filesystem\u0026rdquo; Author: Stephen C. Tweedie. URL: ftp://ftp.uk.linux.org/pub/linux/sct/fs/jfs/journal-design.ps.gz Keywords: ext3, journaling. Description: Excellent 8-pages paper explaining the journaling capabilities added to ext2 by the author, showing different problems faced and the alternatives chosen.\n  Title: \u0026ldquo;Kernel API changes from 2.0 to 2.2\u0026rdquo; Author: Richard Gooch. URL: http://www.linuxhq.com/guides/LKMPG/node28.html Keywords: 2.2, changes. Description: Kernel functions/structures/variables which changed from 2.0.x to 2.2.x.\n  Title: \u0026ldquo;Kernel API changes from 2.2 to 2.4\u0026rdquo; Author: Richard Gooch. Keywords: 2.4, changes. Description: Kernel functions/structures/variables which changed from 2.2.x to 2.4.x.\n  Title: \u0026ldquo;Linux Kernel Module Programming Guide\u0026rdquo; Author: Ori Pomerantz. URL: http://tldp.org/LDP/lkmpg/2.6/html/index.html Keywords: modules, GPL book, /proc, ioctls, system calls, interrupt handlers . Description: Very nice 92 pages GPL book on the topic of modules programming. Lots of examples.\n  Title: \u0026ldquo;I/O Event Handling Under Linux\u0026rdquo; Author: Richard Gooch. Keywords: IO, I/O, select(2), poll(2), FDs, aio_read(2), readiness event queues. Description: From the Introduction: \u0026ldquo;I/O Event handling is about how your Operating System allows you to manage a large number of open files (file descriptors in UNIX/POSIX, or FDs) in your application. You want the OS to notify you when FDs become active (have data ready to be read or are ready for writing). Ideally you want a mechanism that is scalable. This means a large number of inactive FDs cost very little in memory and CPU time to manage\u0026rdquo;.\n  Title: \u0026ldquo;The Kernel Hacking HOWTO\u0026rdquo; Author: Various Talented People, and Rusty. Location: in kernel tree, Documentation/DocBook/kernel-hacking.tmpl (must be built as \u0026ldquo;make {htmldocs | psdocs | pdfdocs}) Keywords: HOWTO, kernel contexts, deadlock, locking, modules, symbols, return conventions. Description: From the Introduction: \u0026ldquo;Please understand that I never wanted to write this document, being grossly underqualified, but I always wanted to read it, and this was the only way. I simply explain some best practices, and give reading entry-points into the kernel sources. I avoid implementation details: that\u0026rsquo;s what the code is for, and I ignore whole tracts of useful routines. This document assumes familiarity with C, and an understanding of what the kernel is, and how it is used. It was originally written for the 2.3 kernels, but nearly all of it applies to 2.2 too; 2.0 is slightly different\u0026rdquo;.\n  Title: \u0026ldquo;Writing an ALSA Driver\u0026rdquo; Author: Takashi Iwai tiwai@suse.de URL: http://www.alsa-project.org/~iwai/writing-an-alsa-driver/index.html Keywords: ALSA, sound, soundcard, driver, lowlevel, hardware. Description: Advanced Linux Sound Architecture for developers, both at kernel and user-level sides. ALSA is the Linux kernel sound architecture in the 2.6 kernel version.\n  Title: \u0026ldquo;Programming Guide for Linux USB Device Drivers\u0026rdquo; Author: Detlef Fliegl. URL: http://usb.in.tum.de/usbdoc/ Keywords: USB, universal serial bus. Description: A must-read. From the Preface: \u0026ldquo;This document should give detailed information about the current state of the USB subsystem and its API for USB device drivers. The first section will deal with the basics of USB devices. You will learn about different types of devices and their properties. Going into detail you will see how USB devices communicate on the bus. The second section gives an overview of the Linux USB subsystem [2] and the device driver framework. Then the API and its data structures will be explained step by step. The last section of this document contains a reference of all API calls and their return codes\u0026rdquo;. Notes: Beware: the main page states: \u0026ldquo;This document may not be published, printed or used in excerpts without explicit permission of the author\u0026rdquo;. Fortunately, it may still be read\u0026hellip;\n  Title: \u0026ldquo;Linux Kernel Mailing List Glossary\u0026rdquo; Author: various URL: http://kernelnewbies.org/glossary/ Keywords: glossary, terms, linux-kernel. Description: From the introduction: \u0026ldquo;This glossary is intended as a brief description of some of the acronyms and terms you may hear during discussion of the Linux kernel\u0026rdquo;.\n  Title: \u0026ldquo;Linux Kernel Locking HOWTO\u0026rdquo; Author: Various Talented People, and Rusty. Location: in kernel tree, Documentation/DocBook/kernel-locking.tmpl (must be built as \u0026ldquo;make {htmldocs | psdocs | pdfdocs}) Keywords: locks, locking, spinlock, semaphore, atomic, race condition, bottom halves, tasklets, softirqs. Description: The title says it all: document describing the locking system in the Linux Kernel either in uniprocessor or SMP systems. Notes: \u0026ldquo;It was originally written for the later (\u0026gt;2.3.47) 2.3 kernels, but most of it applies to 2.2 too; 2.0 is slightly different\u0026rdquo;. Freely redistributable under the conditions of the GNU General Public License.\n  Title: \u0026ldquo;Global spinlock list and usage\u0026rdquo; Author: Rick Lindsley. URL: http://lse.sourceforge.net/lockhier/global-spin-lock Keywords: spinlock. Description: This is an attempt to document both the existence and usage of the spinlocks in the Linux 2.4.5 kernel. Comprehensive list of spinlocks showing when they are used, which functions access them, how each lock is acquired, under what conditions it is held, whether interrupts can occur or not while it is held\u0026hellip;\n  Title: \u0026ldquo;Porting Linux 2.0 Drivers To Linux 2.2: Changes and New Features \u0026quot; Author: Alan Cox. URL: http://www.linux-mag.com/1999-05/gear_01.html Keywords: ports, porting. Description: Article from Linux Magazine on porting from 2.0 to 2.2 kernels.\n  Title: \u0026ldquo;Porting Device Drivers To Linux 2.2: part II\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/238 Keywords: ports, porting. Description: Second part on porting from 2.0 to 2.2 kernels.\n  Title: \u0026ldquo;How To Make Sure Your Driver Will Work On The Power Macintosh\u0026rdquo; Author: Paul Mackerras. URL: http://www.linux-mag.com/id/261 Keywords: Mac, Power Macintosh, porting, drivers, compatibility. Description: The title says it all.\n  Title: \u0026ldquo;An Introduction to SCSI Drivers\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/284 Keywords: SCSI, device, driver. Description: The title says it all.\n  Title: \u0026ldquo;Advanced SCSI Drivers And Other Tales\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/307 Keywords: SCSI, device, driver, advanced. Description: The title says it all.\n  Title: \u0026ldquo;Writing Linux Mouse Drivers\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/330 Keywords: mouse, driver, gpm. Description: The title says it all.\n  Title: \u0026ldquo;More on Mouse Drivers\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/356 Keywords: mouse, driver, gpm, races, asynchronous I/O. Description: The title still says it all.\n  Title: \u0026ldquo;Writing Video4linux Radio Driver\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/381 Keywords: video4linux, driver, radio, radio devices. Description: The title says it all.\n  Title: \u0026ldquo;Video4linux Drivers, Part 1: Video-Capture Device\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/406 Keywords: video4linux, driver, video capture, capture devices, camera driver. Description: The title says it all.\n  Title: \u0026ldquo;Video4linux Drivers, Part 2: Video-capture Devices\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/429 Keywords: video4linux, driver, video capture, capture devices, camera driver, control, query capabilities, capability, facility. Description: The title says it all.\n  Title: \u0026ldquo;PCI Management in Linux 2.2\u0026rdquo; Author: Alan Cox. URL: http://www.linux-mag.com/id/452 Keywords: PCI, bus, bus-mastering. Description: The title says it all.\n  Title: \u0026ldquo;Linux 2.4 Kernel Internals\u0026rdquo; Author: Tigran Aivazian and Christoph Hellwig. URL: http://www.moses.uklinux.net/patches/lki.html Keywords: Linux, kernel, booting, SMB boot, VFS, page cache. Description: A little book used for a short training course. Covers building the kernel image, booting (including SMP bootup), process management, VFS and more.\n  Title: \u0026ldquo;Linux IP Networking. A Guide to the Implementation and Modification of the Linux Protocol Stack.\u0026rdquo; Author: Glenn Herrin. URL: http://www.cs.unh.edu/cnrg/gherrin Keywords: network, networking, protocol, IP, UDP, TCP, connection, socket, receiving, transmitting, forwarding, routing, packets, modules, /proc, sk_buff, FIB, tags. Description: Excellent paper devoted to the Linux IP Networking, explaining anything from the kernel\u0026rsquo;s to the user space configuration tools' code. Very good to get a general overview of the kernel networking implementation and understand all steps packets follow from the time they are received at the network device till they are delivered to applications. The studied kernel code is from 2.2.14 version. Provides code for a working packet dropper example.\n  Title: \u0026ldquo;Get those boards talking under Linux.\u0026rdquo; Author: Alex Ivchenko. URL: http://www.edn.com/article/CA46968.html Keywords: data-acquisition boards, drivers, modules, interrupts, memory allocation. Description: Article written for people wishing to make their data acquisition boards work on their GNU/Linux machines. Gives a basic overview on writing drivers, from the naming of functions to interrupt handling. Notes: Two-parts article. Part II is at URL: http://www.edn.com/article/CA46998.html\n  Title: \u0026ldquo;Linux PCMCIA Programmer\u0026rsquo;s Guide\u0026rdquo; Author: David Hinds. URL: http://pcmcia-cs.sourceforge.net/ftp/doc/PCMCIA-PROG.html Keywords: PCMCIA. Description: \u0026ldquo;This document describes how to write kernel device drivers for the Linux PCMCIA Card Services interface. It also describes how to write user-mode utilities for communicating with Card Services.\n  Title: \u0026ldquo;The Linux Kernel NFSD Implementation\u0026rdquo; Author: Neil Brown. URL: http://www.cse.unsw.edu.au/~neilb/oss/linux-commentary/nfsd.html Keywords: knfsd, nfsd, NFS, RPC, lockd, mountd, statd. Description: The title says it all. Notes: Covers knfsd\u0026rsquo;s version 1.4.7 (patch against 2.2.7 kernel).\n  Title: \u0026ldquo;A Linux vm README\u0026rdquo; Author: Kanoj Sarcar. URL: http://kos.enix.org/pub/linux-vmm.html Keywords: virtual memory, mm, pgd, vma, page, page flags, page cache, swap cache, kswapd. Description: Telegraphic, short descriptions and definitions relating the Linux virtual memory implementation.\n  Title: \u0026ldquo;(nearly) Complete Linux Loadable Kernel Modules. The definitive guide for hackers, virus coders and system administrators.\u0026rdquo; Author: pragmatic/THC. URL: http://packetstormsecurity.org/docs/hack/LKM_HACKING.html Keywords: syscalls, intercept, hide, abuse, symbol table. Description: Interesting paper on how to abuse the Linux kernel in order to intercept and modify syscalls, make files/directories/processes invisible, become root, hijack ttys, write kernel modules based virus\u0026hellip; and solutions for admins to avoid all those abuses. Notes: For 2.0.x kernels. Gives guidances to port it to 2.2.x kernels.\n  BOOKS: (Not on-line)\n  Title: \u0026ldquo;Linux Device Drivers\u0026rdquo; Author: Alessandro Rubini. Publisher: O\u0026rsquo;Reilly \u0026amp; Associates. Date: 1998. Pages: 439. ISBN: 1-56592-292-1\n  Title: \u0026ldquo;Linux Device Drivers, 2nd Edition\u0026rdquo; Author: Alessandro Rubini and Jonathan Corbet. Publisher: O\u0026rsquo;Reilly \u0026amp; Associates. Date: 2001. Pages: 586. ISBN: 0-59600-008-1 Notes: Further information in http://www.oreilly.com/catalog/linuxdrive2/\n  Title: \u0026ldquo;Linux Device Drivers, 3rd Edition\u0026rdquo; Authors: Jonathan Corbet, Alessandro Rubini, and Greg Kroah-Hartman Publisher: O\u0026rsquo;Reilly \u0026amp; Associates. Date: 2005. Pages: 636. ISBN: 0-596-00590-3 Notes: Further information in http://www.oreilly.com/catalog/linuxdrive3/ PDF format, URL: http://lwn.net/Kernel/LDD3/\n  Title: \u0026ldquo;Linux Kernel Internals\u0026rdquo; Author: Michael Beck. Publisher: Addison-Wesley. Date: 1997. ISBN: 0-201-33143-8 (second edition)\n  Title: \u0026ldquo;The Design of the UNIX Operating System\u0026rdquo; Author: Maurice J. Bach. Publisher: Prentice Hall. Date: 1986. Pages: 471. ISBN: 0-13-201757-1\n  Title: \u0026ldquo;The Design and Implementation of the 4.3 BSD UNIX Operating System\u0026rdquo; Author: Samuel J. Leffler, Marshall Kirk McKusick, Michael J. Karels, John S. Quarterman. Publisher: Addison-Wesley. Date: 1989 (reprinted with corrections on October, 1990). ISBN: 0-201-06196-1\n  Title: \u0026ldquo;The Design and Implementation of the 4.4 BSD UNIX Operating System\u0026rdquo; Author: Marshall Kirk McKusick, Keith Bostic, Michael J. Karels, John S. Quarterman. Publisher: Addison-Wesley. Date: 1996. ISBN: 0-201-54979-4\n  Title: \u0026ldquo;Programmation Linux 2.0 API systeme et fonctionnement du noyau\u0026rdquo; Author: Remy Card, Eric Dumas, Franck Mevel. Publisher: Eyrolles. Date: 1997. Pages: 520. ISBN: 2-212-08932-5 Notes: French.\n  Title: \u0026ldquo;Unix internals \u0026ndash; the new frontiers\u0026rdquo; Author: Uresh Vahalia. Publisher: Prentice Hall. Date: 1996. Pages: 600. ISBN: 0-13-101908-2\n  Title: \u0026ldquo;Programming for the real world - POSIX.4\u0026rdquo; Author: Bill O. Gallmeister. Publisher: O\u0026rsquo;Reilly \u0026amp; Associates, Inc.. Date: 1995. Pages: ???. ISBN: I-56592-074-0 Notes: Though not being directly about Linux, Linux aims to be POSIX. Good reference.\n  Title: \u0026ldquo;UNIX Systems for Modern Architectures: Symmetric Multiprocessing and Caching for Kernel Programmers\u0026rdquo; Author: Curt Schimmel. Publisher: Addison Wesley. Date: June, 1994. Pages: 432. ISBN: 0-201-63338-8\n  MISCELLANEOUS:\n  Name: linux/Documentation Author: Many. URL: Just look inside your kernel sources. Keywords: anything, DocBook. Description: Documentation that comes with the kernel sources, inside the Documentation directory. Some pages from this document (including this document itself) have been moved there, and might be more up to date than the web version.\n  Name: \u0026ldquo;Linux Kernel Source Reference\u0026rdquo; Author: Thomas Graichen. URL: http://marc.info/?l=linux-kernel\u0026amp;m=96446640102205\u0026amp;w=4 Keywords: CVS, web, cvsweb, browsing source code. Description: Web interface to a CVS server with the kernel sources. \u0026ldquo;Here you can have a look at any file of the Linux kernel sources of any version starting from 1.0 up to the (daily updated) current version available. Also you can check the differences between two versions of a file\u0026rdquo;.\n  Name: \u0026ldquo;Cross-Referencing Linux\u0026rdquo; URL: http://lxr.linux.no/source/ Keywords: Browsing source code. Description: Another web-based Linux kernel source code browser. Lots of cross references to variables and functions. You can see where they are defined and where they are used.\n  Name: \u0026ldquo;Linux Weekly News\u0026rdquo; URL: http://lwn.net Keywords: latest kernel news. Description: The title says it all. There\u0026rsquo;s a fixed kernel section summarizing developers' work, bug fixes, new features and versions produced during the week. Published every Thursday.\n  Name: \u0026ldquo;Kernel Traffic\u0026rdquo; URL: http://kt.earth.li/kernel-traffic/index.html Keywords: linux-kernel mailing list, weekly kernel news. Description: Weekly newsletter covering the most relevant discussions of the linux-kernel mailing list.\n  Name: \u0026ldquo;CuTTiNG.eDGe.LiNuX\u0026rdquo; URL: http://edge.kernelnotes.org Keywords: changelist. Description: Site which provides the changelist for every kernel release. What\u0026rsquo;s new, what\u0026rsquo;s better, what\u0026rsquo;s changed. Myrdraal reads the patches and describes them. Pointers to the patches are there, too.\n  Name: \u0026ldquo;New linux-kernel Mailing List FAQ\u0026rdquo; URL: http://www.tux.org/lkml/ Keywords: linux-kernel mailing list FAQ. Description: linux-kernel is a mailing list for developers to communicate. This FAQ builds on the previous linux-kernel mailing list FAQ maintained by Frohwalt Egerer, who no longer maintains it. Read it to see how to join the mailing list. Dozens of interesting questions regarding the list, Linux, developers (who is \u0026hellip;?), terms (what is\u0026hellip;?) are answered here too. Just read it.\n  Name: \u0026ldquo;Linux Virtual File System\u0026rdquo; Author: Peter J. Braam. URL: http://www.coda.cs.cmu.edu/doc/talks/linuxvfs/ Keywords: slides, VFS, inode, superblock, dentry, dcache. Description: Set of slides, presumably from a presentation on the Linux VFS layer. Covers version 2.1.x, with dentries and the dcache.\n  Name: \u0026ldquo;Gary\u0026rsquo;s Encyclopedia - The Linux Kernel\u0026rdquo; Author: Gary (I suppose\u0026hellip;). URL: http://slencyclopedia.berlios.de/index.html Keywords: linux, community, everything! Description: Gary\u0026rsquo;s Encyclopedia exists to allow the rapid finding of documentation and other information of interest to GNU/Linux users. It has about 4000 links to external pages in 150 major categories. This link is for kernel-specific links, documents, sites\u0026hellip; This list is now hosted by developer.Berlios.de, but seems not to have been updated since sometime in 1999.\n  Name: \u0026ldquo;The home page of Linux-MM\u0026rdquo; Author: The Linux-MM team. URL: http://linux-mm.org/ Keywords: memory management, Linux-MM, mm patches, TODO, docs, mailing list. Description: Site devoted to Linux Memory Management development. Memory related patches, HOWTOs, links, mm developers\u0026hellip; Don\u0026rsquo;t miss it if you are interested in memory management development!\n  Name: \u0026ldquo;Kernel Newbies IRC Channel\u0026rdquo; URL: http://www.kernelnewbies.org Keywords: IRC, newbies, channel, asking doubts. Description: #kernelnewbies on irc.openprojects.net. From the web page: \u0026ldquo;#kernelnewbies is an IRC network dedicated to the \u0026lsquo;newbie\u0026rsquo; kernel hacker. The audience mostly consists of people who are learning about the kernel, working on kernel projects or professional kernel hackers that want to help less seasoned kernel people. [\u0026hellip;] #kernelnewbies is on the Open Projects IRC Network, try irc.openprojects.net or irc..openprojects.net as your server and then /join #kernelnewbies\u0026rdquo;. It also hosts articles, documents, FAQs\u0026hellip;\n  Name: \u0026ldquo;linux-kernel mailing list archives and search engines\u0026rdquo; URL: http://vger.kernel.org/vger-lists.html URL: http://www.uwsg.indiana.edu/hypermail/linux/kernel/index.html URL: http://marc.theaimsgroup.com/?l=linux-kernel URL: http://groups.google.com/group/mlist.linux.kernel URL: http://www.cs.helsinki.fi/linux/linux-kernel/ URL: http://www.lib.uaa.alaska.edu/linux-kernel/ Keywords: linux-kernel, archives, search. Description: Some of the linux-kernel mailing list archivers. If you have a better/another one, please let me know.\n  [103] kernel-parameters.txt\nparameters may be changed at runtime by the command \u0026ldquo;echo -n ${value} \u0026gt; /sys/module/${modulename}/parameters/${parm}\u0026rdquo;.\n内核参数可以通过上述命令进行调整，也可以在系统引导时通过grub传递内核参数。\nThe parameters listed in this document are only valid if certain kernel build options were enabled and if respective hardware is present.\n内核参数太多了，这里不予列出，请查看kernel-parameters.txt。\n============================================================================= Mon Sep 29 10:17:39 CST 2014 # [104] kmemcheck.txt\nkmemcheck用于内核的未初始化内存的动态检测，它工作在内核态，与工作在用户态的 memcheck实现机制不同。虽然kmemcheck不如memcheck精确，但是已经足够使用的了。此外，kmemcheck会使用更多的内存，增加系统负载，仅适合用于内核的调试。\nkmemcheck is a debugging feature for the Linux Kernel. More specifically, it is a dynamic checker that detects and warns about some uses of uninitialized memory.\nUserspace programmers might be familiar with Valgrind\u0026rsquo;s memcheck. The main difference between memcheck and kmemcheck is that memcheck works for userspace programs only, and kmemcheck works for the kernel only. The implementations are of course vastly different. Because of this, kmemcheck is not as accurate as memcheck, but it turns out to be good enough in practice to discover real programmer errors that the compiler is not able to find through static analysis.\nEnabling kmemcheck on a kernel will probably slow it down to the extent that the machine will not be usable for normal workloads such as e.g. an interactive desktop. kmemcheck will also cause the kernel to use about twice as much memory as normal. For this reason, kmemcheck is strictly a debugging feature.\n[105] kmemleak.txt\nkmemleak是一个工作在内核态，用于检测内核中内存泄漏的工具，与工作态的内存泄漏检 测工具memcheck加参数\u0026ndash;leak-check工作时效果类似。 为了加深对内存管理的理解，应该查看下这两个工具的源代码。\nKernel Memory Leak Detector\nKmemleak provides a way of detecting possible kernel memory leaks in a way similar to a tracing garbage collector\n(http://en.wikipedia.org/wiki/ Garbage_collection_%28computer_science%29#Tracing_garbage_collectors), with the difference that the orphan objects are not freed but only reported via /sys/kernel/debug/kmemleak. A similar method is used by the Valgrind tool (memcheck \u0026ndash;leak-check) to detect the memory leaks in user-space applications.\n[106] kobject.txt\nEverything you never wanted to know about kobjects, ksets, and ktypes\n过去你不曾了解的关于kobjects\\ksets\\ktypes的一切。\nPart of the difficulty in understanding the driver model - and the kobject abstraction upon which it is built - is that there is no obvious starting place. Dealing with kobjects requires understanding a few different types, all of which make reference to each other. In an attempt to make things easier, we\u0026rsquo;ll take a multi-pass approach, starting with vague terms and adding detail as we go. To that end, here are some quick definitions of some terms we will be working with.\n理解驱动模型以及在其上抽象出来的kobject的部分难点在于，没有明显的起始点。要想 理解kobjects，需要理解多种不同的类型，而这些类型都是相互不同的。为了尽可能使其 理解起来简单，我们将从头到尾讲解多遍，先讲述一些含糊的术语，然后再往其中添加相 应的细节。下面，是我们经常提到的一些常用术语的定义。\n  A kobject is an object of type struct kobject. Kobjects have a name and a reference count. A kobject also has a parent pointer (allowing objects to be arranged into hierarchies), a specific type, and, usually, a representation in the sysfs virtual filesystem.\n一个kobject是一个kobject结构体类型。每一个kobject都有一个名字一个引用计数， 此外还具有一个指向parent指针（通过parent指针可以将多个kobject组织成不同的层 次）、特定的类型，通常，还包括一个在虚拟文件系统sysfs(/proc/sys)中的代表。\nKobjects are generally not interesting on their own; instead, they are usually embedded within some other structure which contains the stuff the code is really interested in.\nkobjects本身是没有什么特别意义的，它们通常被嵌入在其他的结构体中，这些嵌入 了kobjects的结构体，再包含其他操作相关的数据结构，就变得有意义了。\nNo structure should EVER have more than one kobject embedded within it. If it does, the reference counting for the object is sure to be messed up and incorrect, and your code will be buggy. So do not do this.\n任意一个结构体最多嵌套1个kobject，如果不这样的话，这个对象的引用计数就会出 错，代码就会出现bug，所以切忌嵌套超过1个kobject。\n  A ktype is the type of object that embeds a kobject. Every structure that embeds a kobject needs a corresponding ktype. The ktype controls what happens to the kobject when it is created and destroyed.\n1个ktype是一个嵌套了kobject结构体的类型，每一个嵌套了kobject结构体的结构体 类型都需要一个相应的ktype。这个ktype在创建或销毁其嵌入的kobject时，可以对其 进行适当的操作。\n  A kset is a group of kobjects. These kobjects can be of the same ktype or belong to different ktypes. The kset is the basic container type for collections of kobjects. Ksets contain their own kobjects, but you can safely ignore that implementation detail as the kset core code handles this kobject automatically.\n1个kset是一组kobjects。这些kobjects可以是相同的ktype类型，也可以分属不同的 ktype类型。这个kset是用于kobjects集合的一个基本的容器类型。ksets包含了它们 自己的kobjects，但是你可以简单地忽略这些细节，这是安全的，因为kset的核心代 码会自动处理kobject。\nWhen you see a sysfs directory full of other directories, generally each of those directories corresponds to a kobject in the same kset.\n当你看到一个包含了其他目录的sysfs目录(一般为/proc/sys)的时候，通常这些目录 中的每一个都对应着相同kset中的一个kobject.\n  We\u0026rsquo;ll look at how to create and manipulate all of these types. A bottom-up approach will be taken, so we\u0026rsquo;ll go back to kobjects.\n下面，我们将看一看如何创建和操作所有的这些类型，我们将自底向上地对其进行描述， 所以我们现回到kobjects。\nEmbedding kobjects\nIt is rare for kernel code to create a standalone kobject, with one major exception explained below. Instead, kobjects are used to control access to a larger, domain-specific object. To this end, kobjects will be found embedded in other structures. If you are used to thinking of things in object-oriented terms, kobjects can be seen as a top-level, abstract class from which other classes are derived. A kobject implements a set of capabilities which are not particularly useful by themselves, but which are nice to have in other objects. The C language does not allow for the direct expression of inheritance, so other techniques - such as structure embedding - must be used.\n在内核代码中创建一个独立的kobject是很少见的，下面会介绍一种例外情况。一般地， kobjects对象被用于控制对一个大对象、特定领域的对象。kobjects经长出现在其他结构 体中。如果你了解面向对象的相关术语、思想，kobjects可以被看作一个顶层的抽象类， 嵌套了该kobject的类则相当于kobject类的派生类。一个kobject实现了某些功能，这些 功能不是本身kobject需要的，但是如果将kobject嵌入到其他对象中之后，这些对 kobject本身来说不是特别关键的功能就变得非常有意义了。由于c语言不支持面向对象、 对象继承，因此必须通过其他手段来实现类似的继承机制，这里使用的是结构体嵌套。\n(As an aside, for those familiar with the kernel linked list implementation, this is analogous as to how \u0026ldquo;list_head\u0026rdquo; structs are rarely useful on their own, but are invariably found embedded in the larger objects of interest.)\nSo, for example, the UIO code in drivers/uio/uio.c has a structure that defines the memory region associated with a uio device:\nstruct uio_map { struct kobject kobj; struct uio_mem *mem; };  If you have a struct uio_map structure, finding its embedded kobject is just a matter of using the kobj member. Code that works with kobjects will often have the opposite problem, however: given a struct kobject pointer, what is the pointer to the containing structure? You must avoid tricks (such as assuming that the kobject is at the beginning of the structure) and, instead, use the container_of() macro, found in \u0026lt;linux/kernel.h\u0026gt;:\ncontainer_of(pointer, type, member)  where:\n \u0026ldquo;pointer\u0026rdquo; is the pointer to the embedded kobject, \u0026ldquo;type\u0026rdquo; is the type of the containing structure, and \u0026ldquo;member\u0026rdquo; is the name of the structure field to which \u0026ldquo;pointer\u0026rdquo; points.  The return value from container_of() is a pointer to the corresponding container type. So, for example, a pointer \u0026ldquo;kp\u0026rdquo; to a struct kobject embedded within a struct uio_map could be converted to a pointer to the containing uio_map structure with:\nstruct uio_map *u_map = container_of(kp, struct uio_map, kobj);  For convenience, programmers often define a simple macro for \u0026ldquo;back-casting\u0026rdquo; kobject pointers to the containing type. Exactly this happens in the earlier drivers/uio/uio.c, as you can see here:\nstruct uio_map { struct kobject kobj; struct uio_mem *mem; }; #define to_map(map) container_of(map, struct uio_map, kobj)  where the macro argument \u0026ldquo;map\u0026rdquo; is a pointer to the struct kobject in question. That macro is subsequently invoked with:\nstruct uio_map *map = to_map(kobj);  Initialization of kobjects\nCode which creates a kobject must, of course, initialize that object. Some of the internal fields are setup with a (mandatory) call to kobject_init():\nvoid kobject_init(struct kobject *kobj, struct kobj_type *ktype);  The ktype is required for a kobject to be created properly, as every kobject must have an associated kobj_type. After calling kobject_init(), to register the kobject with sysfs, the function kobject_add() must be called:\nint kobject_add(struct kobject *kobj, struct kobject *parent, const char *fmt, ...);  This sets up the parent of the kobject and the name for the kobject properly. If the kobject is to be associated with a specific kset, kobj-\u0026gt;kset must be assigned before calling kobject_add(). If a kset is associated with a kobject, then the parent for the kobject can be set to NULL in the call to kobject_add() and then the kobject\u0026rsquo;s parent will be the kset itself.\nAs the name of the kobject is set when it is added to the kernel, the name of the kobject should never be manipulated directly. If you must change the name of the kobject, call kobject_rename():\nint kobject_rename(struct kobject *kobj, const char *new_name);  kobject_rename does not perform any locking or have a solid notion of what names are valid so the caller must provide their own sanity checking and serialization.\nThere is a function called kobject_set_name() but that is legacy cruft and is being removed. If your code needs to call this function, it is incorrect and needs to be fixed.\nTo properly access the name of the kobject, use the function kobject_name():\nconst char *kobject_name(const struct kobject * kobj);  There is a helper function to both initialize and add the kobject to the kernel at the same time, called surprisingly enough kobject_init_and_add():\nint kobject_init_and_add(struct kobject *kobj, struct kobj_type *ktype, struct kobject *parent, const char *fmt, ...);  The arguments are the same as the individual kobject_init() and kobject_add() functions described above.\nUevents\nAfter a kobject has been registered with the kobject core, you need to announce to the world that it has been created. This can be done with a call to kobject_uevent():\nint kobject_uevent(struct kobject *kobj, enum kobject_action action);  Use the KOBJ_ADD action for when the kobject is first added to the kernel. This should be done only after any attributes or children of the kobject have been initialized properly, as userspace will instantly start to look for them when this call happens.\nWhen the kobject is removed from the kernel (details on how to do that is below), the uevent for KOBJ_REMOVE will be automatically created by the kobject core, so the caller does not have to worry about doing that by hand.\nReference counts\nOne of the key functions of a kobject is to serve as a reference counter for the object in which it is embedded. As long as references to the object exist, the object (and the code which supports it) must continue to exist. The low-level functions for manipulating a kobject\u0026rsquo;s reference counts are:\nkobject对象的一个关键作用就是充当嵌入它的对象的引用计数器，只要这个对象的引用 存在，这个对象就会一直存在。操作kobject引用计数的低级操作包括如下两个函数。\nstruct kobject *kobject_get(struct kobject *kobj); void kobject_put(struct kobject *kobj);  A successful call to kobject_get() will increment the kobject\u0026rsquo;s reference counter and return the pointer to the kobject.\n成功调用kobject_get将会增加kobject的引用技术，并返回指向kobject的指针。\nWhen a reference is released, the call to kobject_put() will decrement the reference count and, possibly, free the object. Note that kobject_init() sets the reference count to one, so the code which sets up the kobject will need to do a kobject_put() eventually to release that reference.\n当一个引用被创建，kobject_put的一次成功调用将会使kobject的引用计数减1，如果减 为0，则会释放这个kobject。注意kobject_init将kobject引用计数设置为1，所以创建 kobject的相关代码最后应该调用一次kobject_put来释放这个kobject对象。\nBecause kobjects are dynamic, they must not be declared statically or on the stack, but instead, always allocated dynamically. Future versions of the kernel will contain a run-time check for kobjects that are created statically and will warn the developer of this improper usage.\n由于kobjects是根据需要动态创建的，不应该将其声明为静态的，或者在栈上创建，必须 动态分配创建在堆上。后续版本的内核将包含对kobjects的运行时检查，对于哪些静态创 建的kobjects，内核将给予警告。\nIf all that you want to use a kobject for is to provide a reference counter for your structure, please use the struct kref instead; a kobject would be overkill. For more information on how to use struct kref, please see the file Documentation/kref.txt in the Linux kernel source tree.\n如果使用kobject的目的仅仅是为某个结构体提供一个引用计数，请使用kref结构体代替 。使用kobject有点杀鸡用牛刀的味道，没有必要。关于如何使用kref，请参考linux内核 源代码树中的文档Documentation/kref.txt。\nCreating \u0026ldquo;simple\u0026rdquo; kobjects\nSometimes all that a developer wants is a way to create a simple directory in the sysfs hierarchy, and not have to mess with the whole complication of ksets, show and store functions, and other details. This is the one exception where a single kobject should be created. To create such an entry, use the function:\n有时，开发人员指向在sysfs目录中创建一个简单的目录，不需要ksets、显示和保存函数 等其他细节。这种情况下，就是我们前面提到的在内核代码中单独使用kobject的例外情 况。在sysfs中创建这样一个简单入口，使用如下函数:\nstruct kobject *kobject_create_and_add(char *name, struct kobject *parent);  This function will create a kobject and place it in sysfs in the location underneath the specified parent kobject. To create simple attributes associated with this kobject, use:\n这个函数创建一个kobject，并将其放置在sysfs目录中指定的parent kobject目录下面， 创建一个与该kobject相关联的简单属性，使用如下函数：\nint sysfs_create_file(struct kobject *kobj, struct attribute *attr); or int sysfs_create_group(struct kobject *kobj, struct attribute_group *grp);  Both types of attributes used here, with a kobject that has been created with the kobject_create_and_add(), can be of type kobj_attribute, so no special custom attribute is needed to be created.\nSee the example module, samples/kobject/kobject-example.c for an implementation of a simple kobject and attributes.\nktypes and release methods\nOne important thing still missing from the discussion is what happens to a kobject when its reference count reaches zero. The code which created the kobject generally does not know when that will happen; if it did, there would be little point in using a kobject in the first place. Even predictable object lifecycles become more complicated when sysfs is brought in as other portions of the kernel can get a reference on any kobject that is registered in the system.\n还有一个非常重要的问题没有讨论，就是当kobject引用计数减为0时，该如何操作。创建 kobject的代码并不知道何时该kobject的引用计数会减为0.\nThe end result is that a structure protected by a kobject cannot be freed before its reference count goes to zero. The reference count is not under the direct control of the code which created the kobject. So that code must be notified asynchronously whenever the last reference to one of its kobjects goes away.\n受kobject保护的结构体，只要kobject引用计数不为0，那么包含它的结构体就不应该被 释放。这个引用计数并不受创建kobject的代码的直接控制。所以当kobject引用计数被减 为0时，必须异步通知创建它的那段代码，才能让创建它的代码获知kobject引用计数为0。\nOnce you registered your kobject via kobject_add(), you must never use kfree() to free it directly. The only safe way is to use kobject_put(). It is good practice to always use kobject_put() after kobject_init() to avoid errors creeping in.\n一旦通过kobject_add注册了kobject，就不能再使用kfree直接释放包含了kobject的对象 。唯一安全的方式是调用kobject_put。为了避免忘记在创建kobject代码的最后部分调用 kobject_put（kobject_init初始引用计数为1），从而造成无法成功释放的后果，在实际 编程时，在kobject_init之后调用一次kobject_put是一个不错的方法\n注： 如果init之后立即调用put不就导致引用计数为0了吗？ 举个例子: typedef struct T { struct kobject kobj; \u0026hellip;. }TT; TT * tt = (TT *)malloc(sizeof(TT)); // kobj引用计数为0\nkobject *kp = kobject_init(tt-\u0026gt;kobj); // init中初始化后kobj引用计数1 // init返回指向kobj的指针，引用计数为2 kobject_put(tt-\u0026gt;kobj); // kobj引用计数--后，为1 如果是这样的话，那就不存在问题了。  This notification is done through a kobject\u0026rsquo;s release() method. Usually such a method has a form like:\nvoid my_object_release(struct kobject *kobj) { struct my_object *mine = container_of(kobj, struct my_object, kobj); /* Perform any additional cleanup on this object, then... */ kfree(mine); }  这里的异步通知，是通过kobject提供的一个release方法实现，这里的通知好像通知的是 kobject自身，而不是包含它的结构体。kobject必须提供一个release方法，如上面的代 码所示，当kobject的引用计数为0时，就会调用kobject提供的release方法，在这个方法 体里面，通过前面提过的container_of方法获取嵌入该object对象的结构体的指针，然后 再调用kfree释放该结构体。\nOne important point cannot be overstated: every kobject must have a release() method, and the kobject must persist (in a consistent state) until that method is called. If these constraints are not met, the code is flawed. Note that the kernel will warn you if you forget to provide a release() method. Do not try to get rid of this warning by providing an \u0026ldquo;empty\u0026rdquo; release function; you will be mocked mercilessly by the kobject maintainer if you attempt this.\n一个在强调都不为过的重点：每一个kobject都必须拥有一个release方法。如果不提供该 方法，内核会发出警告，编程人员不应该提供一个空的release方法来避免该警告，必须 提供切实可行的代码。\nNote, the name of the kobject is available in the release function, but it must NOT be changed within this callback. Otherwise there will be a memory leak in the kobject core, which makes people unhappy.\n注意，在release函数中可以获取到kobject的名字，但是不应该在这个回调函数里面改变 它的名字，否则会造成内存泄漏。\nInterestingly, the release() method is not stored in the kobject itself; instead, it is associated with the ktype. So let us introduce struct kobj_type:\nrelease方法并不属于结构体kobject自身，而是与一个ktype关联起来的，现面是 kobj_type的结构体定义：\nstruct kobj_type { void (*release)(struct kobject *); const struct sysfs_ops *sysfs_ops; struct attribute **default_attrs; }; 从这个结构体定义中，我们看到它包括一个成员release，这是一个函数指针，即我 们前面提到的为每个kobject提供的release函数。 前面提及必须为每个kobject指定release函数，而release方法包含在ktype结构体里 面，这样我们就可以理解前面提及的“每个kobject都必须指定一个ktype”这个知识点 了。  This structure is used to describe a particular type of kobject (or, more correctly, of containing object). Every kobject needs to have an associated kobj_type structure; a pointer to that structure must be specified when you call kobject_init() or kobject_init_and_add().\nThe release field in struct kobj_type is, of course, a pointer to the release() method for this type of kobject. The other two fields (sysfs_ops and default_attrs) control how objects of this type are represented in sysfs; they are beyond the scope of this document.\nThe default_attrs pointer is a list of default attributes that will be automatically created for any kobject that is registered with this ktype.\nksets\nA kset is merely a collection of kobjects that want to be associated with each other. There is no restriction that they be of the same ktype, but be very careful if they are not.\nkset仅仅是一系列希望相互间产生某种关联的kobjects的集合，kset并不限制其包含的 kobjects的种类是否相同。如果包含的kobjects类型如果不同的话，就要多加注意了。\nA kset serves these functions:\nkset提供了如下功能：\n  It serves as a bag containing a group of objects. A kset can be used by the kernel to track \u0026ldquo;all block devices\u0026rdquo; or \u0026ldquo;all PCI device drivers.\u0026rdquo;\nkset可以充当一个包含了一组objects的包，可以让内核追踪所有的块设备或者所有的 pci设备。\n  A kset is also a subdirectory in sysfs, where the associated kobjects with the kset can show up. Every kset contains a kobject which can be set up to be the parent of other kobjects; the top-level directories of the sysfs hierarchy are constructed in this way.\nkset也是sysfs中的一个子目录，在这个子目录中，与当前kset对应的kobjects会被显 示出来。每个kset包含了一个比较特殊的kobject，这个kobject可以被设置成当前 kset下其他kobjects的parent。\n  Ksets can support the \u0026ldquo;hotplugging\u0026rdquo; of kobjects and influence how uevent events are reported to user space.\nksets支持kobjects的热插拔，并且能够影响如何将uevent事件报道到用户空间。\n  In object-oriented terms, \u0026ldquo;kset\u0026rdquo; is the top-level container class; ksets contain their own kobject, but that kobject is managed by the kset code and should not be manipulated by any other user.\nA kset keeps its children in a standard kernel linked list. Kobjects point back to their containing kset via their kset field. In almost all cases, the kobjects belonging to a kset have that kset (or, strictly, its embedded kobject) in their parent.\nAs a kset contains a kobject within it, it should always be dynamically created and never declared statically or on the stack. To create a new kset use:\n前面我们提到过kobject必须被动态创建，由于kset也包含一个kobject，所以kset 也 必须被动态创建。\nstruct kset *kset_create_and_add(const char *name, struct kset_uevent_ops *u, struct kobject *parent);\nWhen you are finished with the kset, call: void kset_unregister(struct kset *kset); to destroy it.\nAn example of using a kset can be seen in the samples/kobject/kset-example.c file in the kernel tree.\nIf a kset wishes to control the uevent operations of the kobjects associated with it, it can use the struct kset_uevent_ops to handle it:\nstruct kset_uevent_ops { int (*filter)(struct kset *kset, struct kobject *kobj); const char *(*name)(struct kset *kset, struct kobject *kobj); int (*uevent)(struct kset *kset, struct kobject *kobj, struct kobj_uevent_env *env); };\nThe filter function allows a kset to prevent a uevent from being emitted to userspace for a specific kobject. If the function returns 0, the uevent will not be emitted.\nThe name function will be called to override the default name of the kset that the uevent sends to userspace. By default, the name will be the same as the kset itself, but this function, if present, can override that name.\nThe uevent function will be called when the uevent is about to be sent to userspace to allow more environment variables to be added to the uevent.\nOne might ask how, exactly, a kobject is added to a kset, given that no functions which perform that function have been presented. The answer is that this task is handled by kobject_add(). When a kobject is passed to kobject_add(), its kset member should point to the kset to which the kobject will belong. kobject_add() will handle the rest.\nIf the kobject belonging to a kset has no parent kobject set, it will be added to the kset\u0026rsquo;s directory. Not all members of a kset do necessarily live in the kset directory. If an explicit parent kobject is assigned before the kobject is added, the kobject is registered with the kset, but added below the parent kobject.\nKobject removal\nAfter a kobject has been registered with the kobject core successfully, it must be cleaned up when the code is finished with it. To do that, call kobject_put(). By doing this, the kobject core will automatically clean up all of the memory allocated by this kobject. If a KOBJ_ADD uevent has been sent for the object, a corresponding KOBJ_REMOVE uevent will be sent, and any other sysfs housekeeping will be handled for the caller properly.\nIf you need to do a two-stage delete of the kobject (say you are not allowed to sleep when you need to destroy the object), then call kobject_del() which will unregister the kobject from sysfs. This makes the kobject \u0026ldquo;invisible\u0026rdquo;, but it is not cleaned up, and the reference count of the object is still the same. At a later time call kobject_put() to finish the cleanup of the memory associated with the kobject.\nkobject_del() can be used to drop the reference to the parent object, if circular references are constructed. It is valid in some cases, that a parent objects references a child. Circular references must be broken with an explicit call to kobject_del(), so that a release functions will be called, and the objects in the former circle release each other.\nExample code to copy from\nFor a more complete example of using ksets and kobjects properly, see the example programs samples/kobject/{kobject-example.c,kset-example.c}, which will be built as loadable modules if you select CONFIG_SAMPLE_KOBJECT.\n[107] kprobes.txt\n该文档中解释了内核调试中经常使用的三种探针kprobe\\jprobe\\rprobe，并解释了这几种 探针的工作原理，好好看一看。\nTitle : Kernel Probes (Kprobes) Authors : Jim Keniston jkenisto@us.ibm.com : Prasanna S Panchamukhi prasanna.panchamukhi@gmail.com : Masami Hiramatsu mhiramat@redhat.com\nCONTENTS\n  Concepts: Kprobes, Jprobes, Return Probes\n  Architectures Supported\n  Configuring Kprobes\n  API Reference\n  Kprobes Features and Limitations\n  Probe Overhead\n  TODO\n  Kprobes Example\n  Jprobes Example\n  Kretprobes Example Appendix A: The kprobes debugfs interface Appendix B: The kprobes sysctl interface\n  Concepts: Kprobes, Jprobes, Return Probes\n  Kprobes enables you to dynamically break into any kernel routine and collect debugging and performance information non-disruptively. You can trap at almost any kernel code address, specifying a handler routine to be invoked when the breakpoint is hit.\nThere are currently three types of probes: kprobes, jprobes, and kretprobes (also called return probes). A kprobe can be inserted on virtually any instruction in the kernel. A jprobe is inserted at the entry to a kernel function, and provides convenient access to the function\u0026rsquo;s arguments. A return probe fires when a specified function returns.\nIn the typical case, Kprobes-based instrumentation is packaged as a kernel module. The module\u0026rsquo;s init function installs (\u0026ldquo;registers\u0026rdquo;) one or more probes, and the exit function unregisters them. A registration function such as register_kprobe() specifies where the probe is to be inserted and what handler is to be called when the probe is hit.\nThere are also register_/unregister_*probes() functions for batch registration/unregistration of a group of *probes. These functions can speed up unregistration process when you have to unregister a lot of probes at once.\nThe next four subsections explain how the different types of probes work and how jump optimization works. They explain certain things that you\u0026rsquo;ll need to know in order to make the best use of Kprobes \u0026ndash; e.g., the difference between a pre_handler and a post_handler, and how to use the maxactive and nmissed fields of a kretprobe. But if you\u0026rsquo;re in a hurry to start using Kprobes, you can skip ahead to section 2.\n1.1 How Does a Kprobe Work?\nWhen a kprobe is registered, Kprobes makes a copy of the probed instruction and replaces the first byte(s) of the probed instruction with a breakpoint instruction (e.g., int3 on i386 and x86_64).\nWhen a CPU hits the breakpoint instruction, a trap occurs, the CPU\u0026rsquo;s registers are saved, and control passes to Kprobes via the notifier_call_chain mechanism. Kprobes executes the \u0026ldquo;pre_handler\u0026rdquo; associated with the kprobe, passing the handler the addresses of the kprobe struct and the saved registers.\nNext, Kprobes single-steps its copy of the probed instruction. (It would be simpler to single-step the actual instruction in place, but then Kprobes would have to temporarily remove the breakpoint instruction. This would open a small time window when another CPU could sail right past the probepoint.)\nAfter the instruction is single-stepped, Kprobes executes the \u0026ldquo;post_handler,\u0026rdquo; if any, that is associated with the kprobe. Execution then continues with the instruction following the probepoint.\n1.2 How Does a Jprobe Work?\nA jprobe is implemented using a kprobe that is placed on a function\u0026rsquo;s entry point. It employs a simple mirroring principle to allow seamless access to the probed function\u0026rsquo;s arguments. The jprobe handler routine should have the same signature (arg list and return type) as the function being probed, and must always end by calling the Kprobes function jprobe_return().\nHere\u0026rsquo;s how it works. When the probe is hit, Kprobes makes a copy of the saved registers and a generous portion of the stack (see below). Kprobes then points the saved instruction pointer at the jprobe\u0026rsquo;s handler routine, and returns from the trap. As a result, control passes to the handler, which is presented with the same register and stack contents as the probed function. When it is done, the handler calls jprobe_return(), which traps again to restore the original stack contents and processor state and switch to the probed function.\nBy convention, the callee owns its arguments, so gcc may produce code that unexpectedly modifies that portion of the stack. This is why Kprobes saves a copy of the stack and restores it after the jprobe handler has run. Up to MAX_STACK_SIZE bytes are copied \u0026ndash; e.g., 64 bytes on i386.\nNote that the probed function\u0026rsquo;s args may be passed on the stack or in registers. The jprobe will work in either case, so long as the handler\u0026rsquo;s prototype matches that of the probed function.\n1.3 Return Probes\n1.3.1 How Does a Return Probe Work?\nWhen you call register_kretprobe(), Kprobes establishes a kprobe at the entry to the function. When the probed function is called and this probe is hit, Kprobes saves a copy of the return address, and replaces the return address with the address of a \u0026ldquo;trampoline.\u0026rdquo; The trampoline is an arbitrary piece of code \u0026ndash; typically just a nop instruction. At boot time, Kprobes registers a kprobe at the trampoline.\nWhen the probed function executes its return instruction, control passes to the trampoline and that probe is hit. Kprobes' trampoline handler calls the user-specified return handler associated with the kretprobe, then sets the saved instruction pointer to the saved return address, and that\u0026rsquo;s where execution resumes upon return from the trap.\nWhile the probed function is executing, its return address is stored in an object of type kretprobe_instance. Before calling register_kretprobe(), the user sets the maxactive field of the kretprobe struct to specify how many instances of the specified function can be probed simultaneously. register_kretprobe() pre-allocates the indicated number of kretprobe_instance objects.\nFor example, if the function is non-recursive and is called with a spinlock held, maxactive = 1 should be enough. If the function is non-recursive and can never relinquish the CPU (e.g., via a semaphore or preemption), NR_CPUS should be enough. If maxactive \u0026lt;= 0, it is set to a default value. If CONFIG_PREEMPT is enabled, the default is max(10, 2*NR_CPUS). Otherwise, the default is NR_CPUS.\nIt\u0026rsquo;s not a disaster if you set maxactive too low; you\u0026rsquo;ll just miss some probes. In the kretprobe struct, the nmissed field is set to zero when the return probe is registered, and is incremented every time the probed function is entered but there is no kretprobe_instance object available for establishing the return probe.\n1.3.2 Kretprobe entry-handler\nKretprobes also provides an optional user-specified handler which runs on function entry. This handler is specified by setting the entry_handler field of the kretprobe struct. Whenever the kprobe placed by kretprobe at the function entry is hit, the user-defined entry_handler, if any, is invoked. If the entry_handler returns 0 (success) then a corresponding return handler is guaranteed to be called upon function return. If the entry_handler returns a non-zero error then Kprobes leaves the return address as is, and the kretprobe has no further effect for that particular function instance.\nMultiple entry and return handler invocations are matched using the unique kretprobe_instance object associated with them. Additionally, a user may also specify per return-instance private data to be part of each kretprobe_instance object. This is especially useful when sharing private data between corresponding user entry and return handlers. The size of each private data object can be specified at kretprobe registration time by setting the data_size field of the kretprobe struct. This data can be accessed through the data field of each kretprobe_instance object.\nIn case probed function is entered but there is no kretprobe_instance object available, then in addition to incrementing the nmissed count, the user entry_handler invocation is also skipped.\n1.4 How Does Jump Optimization Work?\nIf your kernel is built with CONFIG_OPTPROBES=y (currently this flag is automatically set \u0026lsquo;y\u0026rsquo; on x86/x86-64, non-preemptive kernel) and the \u0026ldquo;debug.kprobes_optimization\u0026rdquo; kernel parameter is set to 1 (see sysctl(8)), Kprobes tries to reduce probe-hit overhead by using a jump instruction instead of a breakpoint instruction at each probepoint.\n1.4.1 Init a Kprobe\nWhen a probe is registered, before attempting this optimization, Kprobes inserts an ordinary, breakpoint-based kprobe at the specified address. So, even if it\u0026rsquo;s not possible to optimize this particular probepoint, there\u0026rsquo;ll be a probe there.\n1.4.2 Safety Check\nBefore optimizing a probe, Kprobes performs the following safety checks:\n  Kprobes verifies that the region that will be replaced by the jump instruction (the \u0026ldquo;optimized region\u0026rdquo;) lies entirely within one function. (A jump instruction is multiple bytes, and so may overlay multiple instructions.)\n  Kprobes analyzes the entire function and verifies that there is no jump into the optimized region. Specifically:\n the function contains no indirect jump; the function contains no instruction that causes an exception (since the fixup code triggered by the exception could jump back into the optimized region \u0026ndash; Kprobes checks the exception tables to verify this); and there is no near jump to the optimized region (other than to the first byte).    For each instruction in the optimized region, Kprobes verifies that the instruction can be executed out of line.\n  1.4.3 Preparing Detour Buffer\nNext, Kprobes prepares a \u0026ldquo;detour\u0026rdquo; buffer, which contains the following instruction sequence:\n code to push the CPU\u0026rsquo;s registers (emulating a breakpoint trap) a call to the trampoline code which calls user\u0026rsquo;s probe handlers. code to restore registers the instructions from the optimized region a jump back to the original execution path.  1.4.4 Pre-optimization\nAfter preparing the detour buffer, Kprobes verifies that none of the following situations exist:\n The probe has either a break_handler (i.e., it\u0026rsquo;s a jprobe) or a post_handler. Other instructions in the optimized region are probed. The probe is disabled. In any of the above cases, Kprobes won\u0026rsquo;t start optimizing the probe. Since these are temporary situations, Kprobes tries to start optimizing it again if the situation is changed.  If the kprobe can be optimized, Kprobes enqueues the kprobe to an optimizing list, and kicks the kprobe-optimizer workqueue to optimize it. If the to-be-optimized probepoint is hit before being optimized, Kprobes returns control to the original instruction path by setting the CPU\u0026rsquo;s instruction pointer to the copied code in the detour buffer \u0026ndash; thus at least avoiding the single-step.\n1.4.5 Optimization\nThe Kprobe-optimizer doesn\u0026rsquo;t insert the jump instruction immediately; rather, it calls synchronize_sched() for safety first, because it\u0026rsquo;s possible for a CPU to be interrupted in the middle of executing the optimized region(*). As you know, synchronize_sched() can ensure that all interruptions that were active when synchronize_sched() was called are done, but only if CONFIG_PREEMPT=n. So, this version of kprobe optimization supports only kernels with CONFIG_PREEMPT=n.(**)\nAfter that, the Kprobe-optimizer calls stop_machine() to replace the optimized region with a jump instruction to the detour buffer, using text_poke_smp().\n1.4.6 Unoptimization\nWhen an optimized kprobe is unregistered, disabled, or blocked by another kprobe, it will be unoptimized. If this happens before the optimization is complete, the kprobe is just dequeued from the optimized list. If the optimization has been done, the jump is replaced with the original code (except for an int3 breakpoint in the first byte) by using text_poke_smp().\n(*)Please imagine that the 2nd instruction is interrupted and then the optimizer replaces the 2nd instruction with the jump address while the interrupt handler is running. When the interrupt returns to original address, there is no valid instruction, and it causes an unexpected result.\n(**)This optimization-safety checking may be replaced with the stop-machine method that ksplice uses for supporting a CONFIG_PREEMPT=y kernel.\nNOTE for geeks: The jump optimization changes the kprobe\u0026rsquo;s pre_handler behavior. Without optimization, the pre_handler can change the kernel\u0026rsquo;s execution path by changing regs-\u0026gt;ip and returning 1. However, when the probe is optimized, that modification is ignored. Thus, if you want to tweak the kernel\u0026rsquo;s execution path, you need to suppress optimization, using one of the following techniques:\n Specify an empty function for the kprobe\u0026rsquo;s post_handler or break_handler. or Execute \u0026lsquo;sysctl -w debug.kprobes_optimization=n\u0026rsquo;  Architectures Supported  Kprobes, jprobes, and return probes are implemented on the following architectures:\n i386 (Supports jump optimization) x86_64 (AMD-64, EM64T) (Supports jump optimization) ppc64 ia64 (Does not support probes on instruction slot1.) sparc64 (Return probes not yet implemented.) arm ppc mips  Configuring Kprobes  When configuring the kernel using make menuconfig/xconfig/oldconfig, ensure that CONFIG_KPROBES is set to \u0026ldquo;y\u0026rdquo;. Under \u0026ldquo;Instrumentation Support\u0026rdquo;, look for \u0026ldquo;Kprobes\u0026rdquo;.\nSo that you can load and unload Kprobes-based instrumentation modules, make sure \u0026ldquo;Loadable module support\u0026rdquo; (CONFIG_MODULES) and \u0026ldquo;Module unloading\u0026rdquo; (CONFIG_MODULE_UNLOAD) are set to \u0026ldquo;y\u0026rdquo;.\nAlso make sure that CONFIG_KALLSYMS and perhaps even CONFIG_KALLSYMS_ALL are set to \u0026ldquo;y\u0026rdquo;, since kallsyms_lookup_name() is used by the in-kernel kprobe address resolution code.\nIf you need to insert a probe in the middle of a function, you may find it useful to \u0026ldquo;Compile the kernel with debug info\u0026rdquo; (CONFIG_DEBUG_INFO), so you can use \u0026ldquo;objdump -d -l vmlinux\u0026rdquo; to see the source-to-object code mapping.\nAPI Reference  The Kprobes API includes a \u0026ldquo;register\u0026rdquo; function and an \u0026ldquo;unregister\u0026rdquo; function for each type of probe. The API also includes \u0026ldquo;register_*probes\u0026rdquo; and \u0026ldquo;unregister_*probes\u0026rdquo; functions for (un)registering arrays of probes. Here are terse, mini-man-page specifications for these functions and the associated probe handlers that you\u0026rsquo;ll write. See the files in the samples/kprobes/ sub-directory for examples.\n4.1 register_kprobe\n#include \u0026lt;linux/kprobes.h\u0026gt; int register_kprobe(struct kprobe *kp);\nSets a breakpoint at the address kp-\u0026gt;addr. When the breakpoint is hit, Kprobes calls kp-\u0026gt;pre_handler. After the probed instruction is single-stepped, Kprobe calls kp-\u0026gt;post_handler. If a fault occurs during execution of kp-\u0026gt;pre_handler or kp-\u0026gt;post_handler, or during single-stepping of the probed instruction, Kprobes calls kp-\u0026gt;fault_handler. Any or all handlers can be NULL. If kp-\u0026gt;flags is set KPROBE_FLAG_DISABLED, that kp will be registered but disabled, so, its handlers aren\u0026rsquo;t hit until calling enable_kprobe(kp).\nNOTE:\n  With the introduction of the \u0026ldquo;symbol_name\u0026rdquo; field to struct kprobe, the probepoint address resolution will now be taken care of by the kernel. The following will now work:\n kp.symbol_name = \u0026quot;symbol_name\u0026quot;;    (64-bit powerpc intricacies such as function descriptors are handled transparently)\n Use the \u0026ldquo;offset\u0026rdquo; field of struct kprobe if the offset into the symbol to install a probepoint is known. This field is used to calculate the probepoint.\n  Specify either the kprobe \u0026ldquo;symbol_name\u0026rdquo; OR the \u0026ldquo;addr\u0026rdquo;. If both are specified, kprobe registration will fail with -EINVAL.\n  With CISC architectures (such as i386 and x86_64), the kprobes code does not validate if the kprobe.addr is at an instruction boundary. Use \u0026ldquo;offset\u0026rdquo; with caution.\n  register_kprobe() returns 0 on success, or a negative errno otherwise.\nUser\u0026rsquo;s pre-handler (kp-\u0026gt;pre_handler): #include \u0026lt;linux/kprobes.h\u0026gt; #include \u0026lt;linux/ptrace.h\u0026gt; int pre_handler(struct kprobe *p, struct pt_regs *regs);\nCalled with p pointing to the kprobe associated with the breakpoint, and regs pointing to the struct containing the registers saved when the breakpoint was hit. Return 0 here unless you\u0026rsquo;re a Kprobes geek.\nUser\u0026rsquo;s post-handler (kp-\u0026gt;post_handler): #include \u0026lt;linux/kprobes.h\u0026gt; #include \u0026lt;linux/ptrace.h\u0026gt; void post_handler(struct kprobe *p, struct pt_regs *regs, unsigned long flags);\np and regs are as described for the pre_handler. flags always seems to be zero.\nUser\u0026rsquo;s fault-handler (kp-\u0026gt;fault_handler): #include \u0026lt;linux/kprobes.h\u0026gt; #include \u0026lt;linux/ptrace.h\u0026gt; int fault_handler(struct kprobe *p, struct pt_regs *regs, int trapnr);\np and regs are as described for the pre_handler. trapnr is the architecture-specific trap number associated with the fault (e.g., on i386, 13 for a general protection fault or 14 for a page fault). Returns 1 if it successfully handled the exception.\n4.2 register_jprobe\n#include \u0026lt;linux/kprobes.h\u0026gt; int register_jprobe(struct jprobe *jp)\nSets a breakpoint at the address jp-\u0026gt;kp.addr, which must be the address of the first instruction of a function. When the breakpoint is hit, Kprobes runs the handler whose address is jp-\u0026gt;entry.\nThe handler should have the same arg list and return type as the probed function; and just before it returns, it must call jprobe_return(). (The handler never actually returns, since jprobe_return() returns control to Kprobes.) If the probed function is declared asmlinkage or anything else that affects how args are passed, the handler\u0026rsquo;s declaration must match.\nregister_jprobe() returns 0 on success, or a negative errno otherwise.\n4.3 register_kretprobe\n#include \u0026lt;linux/kprobes.h\u0026gt; int register_kretprobe(struct kretprobe *rp);\nEstablishes a return probe for the function whose address is rp-\u0026gt;kp.addr. When that function returns, Kprobes calls rp-\u0026gt;handler. You must set rp-\u0026gt;maxactive appropriately before you call register_kretprobe(); see \u0026ldquo;How Does a Return Probe Work?\u0026rdquo; for details.\nregister_kretprobe() returns 0 on success, or a negative errno otherwise.\nUser\u0026rsquo;s return-probe handler (rp-\u0026gt;handler): #include \u0026lt;linux/kprobes.h\u0026gt; #include \u0026lt;linux/ptrace.h\u0026gt; int kretprobe_handler(struct kretprobe_instance *ri, struct pt_regs *regs);\nregs is as described for kprobe.pre_handler. ri points to the kretprobe_instance object, of which the following fields may be of interest:\n ret_addr: the return address rp: points to the corresponding kretprobe object task: points to the corresponding task struct data: points to per return-instance private data; see \u0026ldquo;Kretprobe entry-handler\u0026rdquo; for details.  The regs_return_value(regs) macro provides a simple abstraction to extract the return value from the appropriate register as defined by the architecture\u0026rsquo;s ABI.\nThe handler\u0026rsquo;s return value is currently ignored.\n4.4 unregister_*probe\n#include \u0026lt;linux/kprobes.h\u0026gt; void unregister_kprobe(struct kprobe *kp); void unregister_jprobe(struct jprobe *jp); void unregister_kretprobe(struct kretprobe *rp);\nRemoves the specified probe. The unregister function can be called at any time after the probe has been registered.\nNOTE: If the functions find an incorrect probe (ex. an unregistered probe), they clear the addr field of the probe.\n4.5 register_*probes\n#include \u0026lt;linux/kprobes.h\u0026gt; int register_kprobes(struct kprobe **kps, int num); int register_kretprobes(struct kretprobe **rps, int num); int register_jprobes(struct jprobe **jps, int num);\nRegisters each of the num probes in the specified array. If any error occurs during registration, all probes in the array, up to the bad probe, are safely unregistered before the register_*probes function returns.\n kps/rps/jps: an array of pointers to *probe data structures num: the number of the array entries.  NOTE: You have to allocate(or define) an array of pointers and set all of the array entries before using these functions.\n4.6 unregister_*probes\n#include \u0026lt;linux/kprobes.h\u0026gt; void unregister_kprobes(struct kprobe **kps, int num); void unregister_kretprobes(struct kretprobe **rps, int num); void unregister_jprobes(struct jprobe **jps, int num);\nRemoves each of the num probes in the specified array at once.\nNOTE: If the functions find some incorrect probes (ex. unregistered probes) in the specified array, they clear the addr field of those incorrect probes. However, other probes in the array are unregistered correctly.\n4.7 disable_*probe\n#include \u0026lt;linux/kprobes.h\u0026gt; int disable_kprobe(struct kprobe *kp); int disable_kretprobe(struct kretprobe *rp); int disable_jprobe(struct jprobe *jp);\nTemporarily disables the specified *probe. You can enable it again by using enable_*probe(). You must specify the probe which has been registered.\n4.8 enable_*probe\n#include \u0026lt;linux/kprobes.h\u0026gt; int enable_kprobe(struct kprobe *kp); int enable_kretprobe(struct kretprobe *rp); int enable_jprobe(struct jprobe *jp);\nEnables *probe which has been disabled by disable_*probe(). You must specify the probe which has been registered.\nKprobes Features and Limitations  Kprobes allows multiple probes at the same address. Currently, however, there cannot be multiple jprobes on the same function at the same time. Also, a probepoint for which there is a jprobe or a post_handler cannot be optimized. So if you install a jprobe, or a kprobe with a post_handler, at an optimized probepoint, the probepoint will be unoptimized automatically.\nIn general, you can install a probe anywhere in the kernel. In particular, you can probe interrupt handlers. Known exceptions are discussed in this section.\nThe register_probe functions will return -EINVAL if you attempt to install a probe in the code that implements Kprobes (mostly kernel/kprobes.c and arch//kernel/kprobes.c, but also functions such as do_page_fault and notifier_call_chain).\nIf you install a probe in an inline-able function, Kprobes makes no attempt to chase down all inline instances of the function and install probes there. gcc may inline a function without being asked, so keep this in mind if you\u0026rsquo;re not seeing the probe hits you expect.\nA probe handler can modify the environment of the probed function \u0026ndash; e.g., by modifying kernel data structures, or by modifying the contents of the pt_regs struct (which are restored to the registers upon return from the breakpoint). So Kprobes can be used, for example, to install a bug fix or to inject faults for testing. Kprobes, of course, has no way to distinguish the deliberately injected faults from the accidental ones. Don\u0026rsquo;t drink and probe.\nKprobes makes no attempt to prevent probe handlers from stepping on each other \u0026ndash; e.g., probing printk() and then calling printk() from a probe handler. If a probe handler hits a probe, that second probe\u0026rsquo;s handlers won\u0026rsquo;t be run in that instance, and the kprobe.nmissed member of the second probe will be incremented.\nAs of Linux v2.6.15-rc1, multiple handlers (or multiple instances of the same handler) may run concurrently on different CPUs.\nKprobes does not use mutexes or allocate memory except during registration and unregistration.\nProbe handlers are run with preemption disabled. Depending on the architecture and optimization state, handlers may also run with interrupts disabled (e.g., kretprobe handlers and optimized kprobe handlers run without interrupt disabled on x86/x86-64). In any case, your handler should not yield the CPU (e.g., by attempting to acquire a semaphore).\nSince a return probe is implemented by replacing the return address with the trampoline\u0026rsquo;s address, stack backtraces and calls to __builtin_return_address() will typically yield the trampoline\u0026rsquo;s address instead of the real return address for kretprobed functions. (As far as we can tell, __builtin_return_address() is used only for instrumentation and error reporting.)\nIf the number of times a function is called does not match the number of times it returns, registering a return probe on that function may produce undesirable results. In such a case, a line: kretprobe BUG!: Processing kretprobe d000000000041aa8 @ c00000000004f48c gets printed. With this information, one will be able to correlate the exact instance of the kretprobe that caused the problem. We have the do_exit() case covered. do_execve() and do_fork() are not an issue. We\u0026rsquo;re unaware of other specific cases where this could be a problem.\nIf, upon entry to or exit from a function, the CPU is running on a stack other than that of the current task, registering a return probe on that function may produce undesirable results. For this reason, Kprobes doesn\u0026rsquo;t support return probes (or kprobes or jprobes) on the x86_64 version of __switch_to(); the registration functions return -EINVAL.\nOn x86/x86-64, since the Jump Optimization of Kprobes modifies instructions widely, there are some limitations to optimization. To explain it, we introduce some terminology. Imagine a 3-instruction sequence consisting of a two 2-byte instructions and one 3-byte instruction.\n IA |  [-2][-1][0][1][2][3][4][5][6][7] [ins1][ins2][ ins3 ] [\u0026lt;- DCR -\u0026gt;] [\u0026lt;- JTPR -\u0026gt;]\nins1: 1st Instruction ins2: 2nd Instruction ins3: 3rd Instruction IA: Insertion Address JTPR: Jump Target Prohibition Region DCR: Detoured Code Region\nThe instructions in DCR are copied to the out-of-line buffer of the kprobe, because the bytes in DCR are replaced by a 5-byte jump instruction. So there are several limitations.\na) The instructions in DCR must be relocatable. b) The instructions in DCR must not include a call instruction. c) JTPR must not be targeted by any jump or call instruction. d) DCR must not straddle the border between functions.\nAnyway, these limitations are checked by the in-kernel instruction decoder, so you don\u0026rsquo;t need to worry about that.\nProbe Overhead  On a typical CPU in use in 2005, a kprobe hit takes 0.5 to 1.0 microseconds to process. Specifically, a benchmark that hits the same probepoint repeatedly, firing a simple handler each time, reports 1-2 million hits per second, depending on the architecture. A jprobe or return-probe hit typically takes 50-75% longer than a kprobe hit. When you have a return probe set on a function, adding a kprobe at the entry to that function adds essentially no overhead.\nHere are sample overhead figures (in usec) for different architectures. k = kprobe; j = jprobe; r = return probe; kr = kprobe + return probe on same function; jr = jprobe + return probe on same function\ni386: Intel Pentium M, 1495 MHz, 2957.31 bogomips k = 0.57 usec; j = 1.00; r = 0.92; kr = 0.99; jr = 1.40\nx86_64: AMD Opteron 246, 1994 MHz, 3971.48 bogomips k = 0.49 usec; j = 0.76; r = 0.80; kr = 0.82; jr = 1.07\nppc64: POWER5 (gr), 1656 MHz (SMT disabled, 1 virtual CPU per physical CPU) k = 0.77 usec; j = 1.31; r = 1.26; kr = 1.45; jr = 1.99\n6.1 Optimized Probe Overhead\nTypically, an optimized kprobe hit takes 0.07 to 0.1 microseconds to process. Here are sample overhead figures (in usec) for x86 architectures. k = unoptimized kprobe, b = boosted (single-step skipped), o = optimized kprobe, r = unoptimized kretprobe, rb = boosted kretprobe, ro = optimized kretprobe.\ni386: Intel(R) Xeon(R) E5410, 2.33GHz, 4656.90 bogomips k = 0.80 usec; b = 0.33; o = 0.05; r = 1.10; rb = 0.61; ro = 0.33\nx86-64: Intel(R) Xeon(R) E5410, 2.33GHz, 4656.90 bogomips k = 0.99 usec; b = 0.43; o = 0.06; r = 1.24; rb = 0.68; ro = 0.30\nTODO  a. SystemTap (http://sourceware.org/systemtap): Provides a simplified programming interface for probe-based instrumentation. Try it out. b. Kernel return probes for sparc64. c. Support for other architectures. d. User-space probes. e. Watchpoint probes (which fire on data references).\nKprobes Example  See samples/kprobes/kprobe_example.c\nJprobes Example  See samples/kprobes/jprobe_example.c\nKretprobes Example  See samples/kprobes/kretprobe_example.c\nFor additional information on Kprobes, refer to the following URLs: http://www-106.ibm.com/developerworks/library/l-kprobes.html?ca=dgr-lnxw42Kprobe http://www.redhat.com/magazine/005mar05/features/kprobes/ http://www-users.cs.umn.edu/~boutcher/kprobes/ http://www.linuxsymposium.org/2006/linuxsymposium_procv2.pdf (pages 101-115)\nAppendix A: The kprobes debugfs interface\nWith recent kernels (\u0026gt; 2.6.20) the list of registered kprobes is visible under the /sys/kernel/debug/kprobes/ directory (assuming debugfs is mounted at //sys/kernel/debug).\n/sys/kernel/debug/kprobes/list: Lists all registered probes on the system\nc015d71a k vfs_read+0x0 c011a316 j do_fork+0x0 c03dedc5 r tcp_v4_rcv+0x0\nThe first column provides the kernel address where the probe is inserted. The second column identifies the type of probe (k - kprobe, r - kretprobe and j - jprobe), while the third column specifies the symbol+offset of the probe. If the probed function belongs to a module, the module name is also specified. Following columns show probe status. If the probe is on a virtual address that is no longer valid (module init sections, module virtual addresses that correspond to modules that\u0026rsquo;ve been unloaded), such probes are marked with [GONE]. If the probe is temporarily disabled, such probes are marked with [DISABLED]. If the probe is optimized, it is marked with [OPTIMIZED].\n/sys/kernel/debug/kprobes/enabled: Turn kprobes ON/OFF forcibly.\nProvides a knob to globally and forcibly turn registered kprobes ON or OFF. By default, all kprobes are enabled. By echoing \u0026ldquo;0\u0026rdquo; to this file, all registered probes will be disarmed, till such time a \u0026ldquo;1\u0026rdquo; is echoed to this file. Note that this knob just disarms and arms all kprobes and doesn\u0026rsquo;t change each probe\u0026rsquo;s disabling state. This means that disabled kprobes (marked [DISABLED]) will be not enabled if you turn ON all kprobes by this knob.\nAppendix B: The kprobes sysctl interface\n/proc/sys/debug/kprobes-optimization: Turn kprobes optimization ON/OFF.\nWhen CONFIG_OPTPROBES=y, this sysctl interface appears and it provides a knob to globally and forcibly turn jump optimization (see section 1.4) ON or OFF. By default, jump optimization is allowed (ON). If you echo \u0026ldquo;0\u0026rdquo; to this file or set \u0026ldquo;debug.kprobes_optimization\u0026rdquo; to 0 via sysctl, all optimized probes will be unoptimized, and any new probes registered after that will not be optimized. Note that this knob changes the optimized state. This means that optimized probes (marked [OPTIMIZED]) will be unoptimized ([OPTIMIZED] tag will be removed). If the knob is turned on, they will be optimized again.\n[108] kref.txt\nkref可以为你自定义的结构体提供一个引用计数器，前面[106]中提到的kobject也可以实 现该功能，但是kobject比较复杂，如果只是提供一个简单的引用计数器的话，应该使用 kref而不是kobject。\nkrefs allow you to add reference counters to your objects. If you have objects that are used in multiple places and passed around, and you don\u0026rsquo;t have refcounts, your code is almost certainly broken. If you want refcounts, krefs are the way to go.\nTo use a kref, add one to your data structures like:\nstruct my_data { . . struct kref refcount; . . };\nThe kref can occur anywhere within the data structure.\nYou must initialize the kref after you allocate it. To do this, call kref_init as so:\n struct my_data *data; data = kmalloc(sizeof(*data), GFP_KERNEL); if (!data) return -ENOMEM; kref_init(\u0026amp;data-\u0026gt;refcount);  This sets the refcount in the kref to 1.\nOnce you have an initialized kref, you must follow the following rules:\n  If you make a non-temporary copy of a pointer, especially if it can be passed to another thread of execution, you must increment the refcount with kref_get() before passing it off: kref_get(\u0026amp;data-\u0026gt;refcount); If you already have a valid pointer to a kref-ed structure (the refcount cannot go to zero) you may do this without a lock.\n  When you are done with a pointer, you must call kref_put(): kref_put(\u0026amp;data-\u0026gt;refcount, data_release); If this is the last reference to the pointer, the release routine will be called. If the code never tries to get a valid pointer to a kref-ed structure without already holding a valid pointer, it is safe to do this without a lock.\n  If the code attempts to gain a reference to a kref-ed structure without already holding a valid pointer, it must serialize access where a kref_put() cannot occur during the kref_get(), and the structure must remain valid during the kref_get().\n  For example, if you allocate some data and then pass it to another thread to process:\nvoid data_release(struct kref *ref) { struct my_data *data = container_of(ref, struct my_data, refcount); kfree(data); }\nvoid more_data_handling(void *cb_data) { struct my_data *data = cb_data; . . do stuff with data here . kref_put(\u0026amp;data-\u0026gt;refcount, data_release); }\nint my_data_handler(void) { int rv = 0; struct my_data *data; struct task_struct *task; data = kmalloc(sizeof(*data), GFP_KERNEL); if (!data) return -ENOMEM; kref_init(\u0026amp;data-\u0026gt;refcount);\n kref_get(\u0026amp;data-\u0026gt;refcount); task = kthread_run(more_data_handling, data, \u0026quot;more_data_handling\u0026quot;); if (task == ERR_PTR(-ENOMEM)) { rv = -ENOMEM; goto out; } . . do stuff with data here .  out: kref_put(\u0026amp;data-\u0026gt;refcount, data_release); return rv; }\nThis way, it doesn\u0026rsquo;t matter what order the two threads handle the data, the kref_put() handles knowing when the data is not referenced any more and releasing it. The kref_get() does not require a lock, since we already have a valid pointer that we own a refcount for. The put needs no lock because nothing tries to get the data without already holding a pointer.\nNote that the \u0026ldquo;before\u0026rdquo; in rule 1 is very important. You should never do something like:\n task = kthread_run(more_data_handling, data, \u0026quot;more_data_handling\u0026quot;); if (task == ERR_PTR(-ENOMEM)) { rv = -ENOMEM; goto out; } else /* BAD BAD BAD - get is after the handoff */ kref_get(\u0026amp;data-\u0026gt;refcount);  Don\u0026rsquo;t assume you know what you are doing and use the above construct. First of all, you may not know what you are doing. Second, you may know what you are doing (there are some situations where locking is involved where the above may be legal) but someone else who doesn\u0026rsquo;t know what they are doing may change the code or copy the code. It\u0026rsquo;s bad style. Don\u0026rsquo;t do it.\nThere are some situations where you can optimize the gets and puts. For instance, if you are done with an object and enqueuing it for something else or passing it off to something else, there is no reason to do a get then a put:\n /* Silly extra get and put */ kref_get(\u0026amp;obj-\u0026gt;ref); enqueue(obj); kref_put(\u0026amp;obj-\u0026gt;ref, obj_cleanup);  Just do the enqueue. A comment about this is always welcome:\n enqueue(obj); /* We are done with obj, so we pass our refcount off to the queue. DON'T TOUCH obj AFTER HERE! */  The last rule (rule 3) is the nastiest one to handle. Say, for instance, you have a list of items that are each kref-ed, and you wish to get the first one. You can\u0026rsquo;t just pull the first item off the list and kref_get() it. That violates rule 3 because you are not already holding a valid pointer. You must add a mutex (or some other lock). For instance:\nstatic DEFINE_MUTEX(mutex); static LIST_HEAD(q); struct my_data { struct kref refcount; struct list_head link; };\nstatic struct my_data *get_entry() { struct my_data *entry = NULL; mutex_lock(\u0026amp;mutex); if (!list_empty(\u0026amp;q)) { entry = container_of(q.next, struct my_data, link); kref_get(\u0026amp;entry-\u0026gt;refcount); } mutex_unlock(\u0026amp;mutex); return entry; }\nstatic void release_entry(struct kref *ref) { struct my_data *entry = container_of(ref, struct my_data, refcount);\n list_del(\u0026amp;entry-\u0026gt;link); kfree(entry);  }\nstatic void put_entry(struct my_data *entry) { mutex_lock(\u0026amp;mutex); kref_put(\u0026amp;entry-\u0026gt;refcount, release_entry); mutex_unlock(\u0026amp;mutex); }\nThe kref_put() return value is useful if you do not want to hold the lock during the whole release operation. Say you didn\u0026rsquo;t want to call kfree() with the lock held in the example above (since it is kind of pointless to do so). You could use kref_put() as follows:\nstatic void release_entry(struct kref ref) { / All work is done after the return from kref_put(). */ }\nstatic void put_entry(struct my_data *entry) { mutex_lock(\u0026amp;mutex); if (kref_put(\u0026amp;entry-\u0026gt;refcount, release_entry)) { list_del(\u0026amp;entry-\u0026gt;link); mutex_unlock(\u0026amp;mutex); kfree(entry); } else mutex_unlock(\u0026amp;mutex); }\nThis is really more useful if you have to call other routines as part of the free operations that could take a long time or might claim the same lock. Note that doing everything in the release routine is still preferred as it is a little neater.\nCorey Minyard minyard@acm.org\nA lot of this was lifted from Greg Kroah-Hartman\u0026rsquo;s 2004 OLS paper and presentation on krefs, which can be found at: http://www.kroah.com/linux/talks/ols_2004_kref_paper/Reprint-Kroah-Hartman-OLS2004.pdf and: http://www.kroah.com/linux/talks/ols_2004_kref_talk/\n[109] ldm.txt\nLDM - Logical Disk Manager (Dynamic Disks) # Originally Written by FlatCap - Richard Russon ldm@flatcap.org. Last Updated by Anton Altaparmakov on 30 March 2007 for Windows Vista.\nOverview # Windows 2000, XP, and Vista use a new partitioning scheme. It is a complete replacement for the MSDOS style partitions. It stores its information in a 1MiB journalled database at the end of the physical disk. The size of partitions is limited only by disk space. The maximum number of partitions is nearly 2000.\nAny partitions created under the LDM are called \u0026ldquo;Dynamic Disks\u0026rdquo;. There are no longer any primary or extended partitions. Normal MSDOS style partitions are now known as Basic Disks.\nIf you wish to use Spanned, Striped, Mirrored or RAID 5 Volumes, you must use Dynamic Disks. The journalling allows Windows to make changes to these partitions and filesystems without the need to reboot.\nOnce the LDM driver has divided up the disk, you can use the MD driver to assemble any multi-partition volumes, e.g. Stripes, RAID5.\nTo prevent legacy applications from repartitioning the disk, the LDM creates a dummy MSDOS partition containing one disk-sized partition. This is what is supported with the Linux LDM driver.\nA newer approach that has been implemented with Vista is to put LDM on top of a GPT label disk. This is not supported by the Linux LDM driver yet.\nExample # Below we have a 50MiB disk, divided into seven partitions. N.B. The missing 1MiB at the end of the disk is where the LDM database is stored.\nDevice | Offset Bytes Sectors MiB | Size Bytes Sectors MiB \u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; hda | 0 0 0 | 52428800 102400 50 hda1 | 51380224 100352 49 | 1048576 2048 1 hda2 | 16384 32 0 | 6979584 13632 6 hda3 | 6995968 13664 6 | 10485760 20480 10 hda4 | 17481728 34144 16 | 4194304 8192 4 hda5 | 21676032 42336 20 | 5242880 10240 5 hda6 | 26918912 52576 25 | 10485760 20480 10 hda7 | 37404672 73056 35 | 13959168 27264 13\nThe LDM Database may not store the partitions in the order that they appear on disk, but the driver will sort them.\nWhen Linux boots, you will see something like:\nhda: 102400 sectors w/32KiB Cache, CHS=50/64/32 hda: [LDM] hda1 hda2 hda3 hda4 hda5 hda6 hda7\nCompiling LDM Support # To enable LDM, choose the following two options:\n\u0026ldquo;Advanced partition selection\u0026rdquo; CONFIG_PARTITION_ADVANCED \u0026ldquo;Windows Logical Disk Manager (Dynamic Disk) support\u0026rdquo; CONFIG_LDM_PARTITION\nIf you believe the driver isn\u0026rsquo;t working as it should, you can enable the extra debugging code. This will produce a LOT of output. The option is:\n\u0026ldquo;Windows LDM extra logging\u0026rdquo; CONFIG_LDM_DEBUG\nN.B. The partition code cannot be compiled as a module.\nAs with all the partition code, if the driver doesn\u0026rsquo;t see signs of its type of partition, it will pass control to another driver, so there is no harm in enabling it.\nIf you have Dynamic Disks but don\u0026rsquo;t enable the driver, then all you will see is a dummy MSDOS partition filling the whole disk. You won\u0026rsquo;t be able to mount any of the volumes on the disk.\nBooting # If you enable LDM support, then lilo is capable of booting from any of the discovered partitions. However, grub does not understand the LDM partitioning and cannot boot from a Dynamic Disk.\nMore Documentation # There is an Overview of the LDM together with complete Technical Documentation. It is available for download.\nhttp://www.linux-ntfs.org/\nIf you have any LDM questions that aren\u0026rsquo;t answered in the documentation, email me.\nCheers, FlatCap - Richard Russon ldm@flatcap.org\n[110] local_ops.txt\n前面了解了x86上non-irq自旋锁的实现，理解起来没有问题！ 但是现在问的是，多核cpu如何实现同步？？？可能要cpu提供支持或者内存控制器进行支 持。 有人提问过，可以参考下。 http://stackoverflow.com/questions/8188649/ in-multi-core-multi-processor-architecture-what-part-of-the-system-synchronize http://stackoverflow.com/questions/20858260/ how-can-synchronize-data-between-differernt-cores-on-xeon-linux-how-to-use-memo\n"}),a.add({id:519,href:"/tags/unix/",title:"unix",description:"",content:""}),a.add({id:520,href:"/blog/2014-10-01-linux%E5%86%85%E8%81%94%E6%B1%87%E7%BC%96%E5%9F%BA%E7%A1%80/",title:"Linux内联汇编基础",description:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是阅读内核源码《Linux内核源码情景分析》时对内联汇编的一些总结。\n1.full template __asm__(assembler template :output operands	/* optional */ :input operands	/* optional */ :list of clobbered registers	/* optional */ ); 2.x86 registers eax,ebx,ecx,edx edi,esi ebp,esp eip eflags 3.linux代码中很多地方都使用了这种形式的汇编语言，嵌入汇编程序的格式如下： __asm__ __volatile__ ( asm statements : outputs : inputs : registers-modified ); asm statements是一组AT\u0026amp;T格式的汇编语言语句，每个语句一行，由\\n分隔各行。所有的语句都被包裹在一对双引号内。其中使用的寄存器前面要加两个%%做前缀(%n表示参数,n:数字)；转移指令多是局部转移，因此多使用数字标号。 inputs指明程序的输入参数，每个输入参数都括在一对圆括号内，各参数用逗号分开。每个参数前加一个用双引号括起来的标志，告诉编译器把该参数装入到何处。 可用的标志有： “g”：让编译器决定如何装入它； “a”：装入到ax/eax； “b”：装入到bx/ebx； “c”：装入到cx/ecx； “d”：装入到dx/edx； “D”：装入到di/edi； “S”：装入到si/esi； “q”：a、b、c、d寄存器等； “r”：任一通用寄存器； “i”：整立即数； “I”：0-31 之间的立即数（用于32位移位指令）； “J”：0-63 之间的立即数（用于64 位移位指令）； “N”：0-255 ，之间的立即数（用于out 指令）； “n”：立即数，有些系统不支持除字以外的立即数，这些系统应该使用“n”而不是“i”； “p”：有效内存地址； “m”：内存变量； “o”：操作数为内存变量，但是其寻址方式是偏移量类型，也即是基址寻址，或者是基址加变址寻址； “V”：操作数为内存变量，但寻址方式不是偏移量类型； “,”：操作数为内存变量，但寻址方式为自动增量； “X”：操作数可以是任何类型； “f”：浮点数； “t”：第一个浮点寄存器； “u”：第二个浮点寄存器； “G”：标准的80387； % ：浮点常数,该操作数可以和下一个操作数交换位置； “=”：输出； “+”：既是输入又是输出； “\u0026amp;”：改变其值之前写,分配一个独立的寄存器,使得函数返回值和该变量不因为重复使用同一个寄存器,出现数据覆盖； “%”：与下一个操作数之间可互换； “#”：忽略其后的字符，直到逗号； “*”：当优先选择寄存器时，忽略下面的字符； “0”~“9”：指定一个操作数，它既做输入又做输出。通常用“g”； outputs指明程序的输出位置，通常是变量。每个输出变量都括在一对圆括号内，各个输出变量间用逗号隔开。每个输出变量前加一个标志，告诉编译器从何处输出。 可用的标志与输入参数用的标志相同，只是前面加“=”。如“=g”。输出操作数必须是左值，而且必须是只写的。如果一个操作数即做输出又做输 入，那么必须将它们分开：一个只写操作数，一个输入操作数。输入操作数前加一个数字限制（0~9），指出输出操作数的序号，告诉编译器它们必须在同一个物 理位置。两个操作数可以是同一个表达式，也可以是不同的表达式。 registers-modified告诉编译器程序中将要修改的寄存器。每个寄存器都用双引号括起来，并用逗号隔开。如“ax”。如果汇编程 序中引用了某个特定的硬件寄存器，就应该在此处列出这些寄存器，以告诉编译器这些寄存器的值被改变了。如果汇编程序中用某种不可预测的方式修改了内存，应 该在此处加上“memory”。这样以来，在整个汇编程序中，编译器就不会把它的值缓存在寄存器中了。 如: “cc”：你使用的指令会改变CPU的条件寄存器cc； “memory”：你使用的指令会修改内存； __volatile__是可选的，它防止编译器修改该段汇编语句（重排序、重组、删除等）。 输入参数和输出变量按顺序编号，先输出后输入，编号从0开始。程序中用编号代表输入参数和输出变量（加%做前缀）。 输入、输出、寄存器部分都可有可无。如有，顺序不能变；如无，应保留“：”，除非不引起二意性。 看一个在C语言中使用at\u0026amp;t的嵌入汇编程序的例子，c语言中的3个int变量，一般会是三个内存地址。每个操作数的长度则要根据操作系统和编译器来决定，一般32位操作系统为32位，则每个操作数占用4个字节： int i=0, j=1, k=0; __asm__ __volatile__(\u0026quot; pushl %%eax\\n //asm statement movl %1, %%eax\\n //asm statement addl %2, %%eax\\n //asm statement movl %%eax, %0\\n //.",content:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是阅读内核源码《Linux内核源码情景分析》时对内联汇编的一些总结。\n1.full template __asm__(assembler template :output operands	/* optional */ :input operands	/* optional */ :list of clobbered registers	/* optional */ ); 2.x86 registers eax,ebx,ecx,edx edi,esi ebp,esp eip eflags 3.linux代码中很多地方都使用了这种形式的汇编语言，嵌入汇编程序的格式如下： __asm__ __volatile__ ( asm statements : outputs : inputs : registers-modified ); asm statements是一组AT\u0026amp;T格式的汇编语言语句，每个语句一行，由\\n分隔各行。所有的语句都被包裹在一对双引号内。其中使用的寄存器前面要加两个%%做前缀(%n表示参数,n:数字)；转移指令多是局部转移，因此多使用数字标号。 inputs指明程序的输入参数，每个输入参数都括在一对圆括号内，各参数用逗号分开。每个参数前加一个用双引号括起来的标志，告诉编译器把该参数装入到何处。 可用的标志有： “g”：让编译器决定如何装入它； “a”：装入到ax/eax； “b”：装入到bx/ebx； “c”：装入到cx/ecx； “d”：装入到dx/edx； “D”：装入到di/edi； “S”：装入到si/esi； “q”：a、b、c、d寄存器等； “r”：任一通用寄存器； “i”：整立即数； “I”：0-31 之间的立即数（用于32位移位指令）； “J”：0-63 之间的立即数（用于64 位移位指令）； “N”：0-255 ，之间的立即数（用于out 指令）； “n”：立即数，有些系统不支持除字以外的立即数，这些系统应该使用“n”而不是“i”； “p”：有效内存地址； “m”：内存变量； “o”：操作数为内存变量，但是其寻址方式是偏移量类型，也即是基址寻址，或者是基址加变址寻址； “V”：操作数为内存变量，但寻址方式不是偏移量类型； “,”：操作数为内存变量，但寻址方式为自动增量； “X”：操作数可以是任何类型； “f”：浮点数； “t”：第一个浮点寄存器； “u”：第二个浮点寄存器； “G”：标准的80387； % ：浮点常数,该操作数可以和下一个操作数交换位置； “=”：输出； “+”：既是输入又是输出； “\u0026amp;”：改变其值之前写,分配一个独立的寄存器,使得函数返回值和该变量不因为重复使用同一个寄存器,出现数据覆盖； “%”：与下一个操作数之间可互换； “#”：忽略其后的字符，直到逗号； “*”：当优先选择寄存器时，忽略下面的字符； “0”~“9”：指定一个操作数，它既做输入又做输出。通常用“g”； outputs指明程序的输出位置，通常是变量。每个输出变量都括在一对圆括号内，各个输出变量间用逗号隔开。每个输出变量前加一个标志，告诉编译器从何处输出。 可用的标志与输入参数用的标志相同，只是前面加“=”。如“=g”。输出操作数必须是左值，而且必须是只写的。如果一个操作数即做输出又做输 入，那么必须将它们分开：一个只写操作数，一个输入操作数。输入操作数前加一个数字限制（0~9），指出输出操作数的序号，告诉编译器它们必须在同一个物 理位置。两个操作数可以是同一个表达式，也可以是不同的表达式。 registers-modified告诉编译器程序中将要修改的寄存器。每个寄存器都用双引号括起来，并用逗号隔开。如“ax”。如果汇编程 序中引用了某个特定的硬件寄存器，就应该在此处列出这些寄存器，以告诉编译器这些寄存器的值被改变了。如果汇编程序中用某种不可预测的方式修改了内存，应 该在此处加上“memory”。这样以来，在整个汇编程序中，编译器就不会把它的值缓存在寄存器中了。 如: “cc”：你使用的指令会改变CPU的条件寄存器cc； “memory”：你使用的指令会修改内存； __volatile__是可选的，它防止编译器修改该段汇编语句（重排序、重组、删除等）。 输入参数和输出变量按顺序编号，先输出后输入，编号从0开始。程序中用编号代表输入参数和输出变量（加%做前缀）。 输入、输出、寄存器部分都可有可无。如有，顺序不能变；如无，应保留“：”，除非不引起二意性。 看一个在C语言中使用at\u0026amp;t的嵌入汇编程序的例子，c语言中的3个int变量，一般会是三个内存地址。每个操作数的长度则要根据操作系统和编译器来决定，一般32位操作系统为32位，则每个操作数占用4个字节： int i=0, j=1, k=0; __asm__ __volatile__(\u0026quot; pushl %%eax\\n //asm statement movl %1, %%eax\\n //asm statement addl %2, %%eax\\n //asm statement movl %%eax, %0\\n //... popl %%eax\u0026quot; //... : \u0026quot;=g\u0026quot; (k) //outputs : \u0026quot;g\u0026quot; (i), \u0026quot;g\u0026quot; (j) //inputs : \u0026quot;ax\u0026quot;, \u0026quot;memory\u0026quot; //registers modified ); 按照参数编号原则输出参数参数k为%0,输入参数i和j依次为%1和%2。值得注意的是输出和输入标志都使用了\u0026quot;g\u0026quot;,所以我们不必关心这些参数究竟是使用了寄存器还是内存操作数，编译器自己会决定。 4.linux/windows汇编指令的区别 Note: 汇编指令的执行需要汇编程序将其翻译成机器代码，由于汇编程序是系统程序的一部分，而linux跟windows本身设计上存在很多不同，汇编程序当然不例外，所以，他们支持的汇编指令的格式也存在很多不同。 DOS/Windows 下的汇编语言代码都是 Intel 风格的。但在 Unix 和 Linux 系统中，更多采用的还是 AT\u0026amp;T 格式，两者在语法格式上有着很大的不同： 在 AT\u0026amp;T 汇编格式中，寄存器名要加上 '%' 作为前缀；而在 Intel 汇编格式中，寄存器名不需要加前缀。例如： AT\u0026amp;T 格式 pushl %eax Intel 格式 push eax 在 AT\u0026amp;T 汇编格式中，用 '\\$' 前缀表示一个立即操作数；而在 Intel 汇编格式中，立即数的表示不用带任何前缀。例如： AT\u0026amp;T 格式 pushl $1 Intel 格式 push 1 AT\u0026amp;T 和 Intel 格式中的源操作数和目标操作数的位置正好相反。在 Intel 汇编格式中，目标操作数在源操作数的左边；而在 AT\u0026amp;T 汇编格式中，目标操作数在源操作数的右边。例如： AT\u0026amp;T 格式 addl $1, %eax Intel 格式 add eax, 1 在 AT\u0026amp;T 汇编格式中，操作数的字长由操作符的最后一个字母决定，后缀'b'、'w'、'l'分别表示操作数为字节（byte，8 比特）、字（word，16 比特）和长字（long，32比特）；而在 Intel 汇编格式中，操作数的字长是用 \u0026quot;byte ptr\u0026quot; 和 \u0026quot;word ptr\u0026quot; 等前缀来表示的。例如： AT\u0026amp;T 格式 movb val, %al Intel 格式 mov al, byte ptr val 在 AT\u0026amp;T 汇编格式中，绝对转移和调用指令（jump/call）的操作数前要加上'*'作为前缀，而在 Intel 格式中则不需要。 远程转移指令和远程子调用指令的操作码，在 AT\u0026amp;T 汇编格式中为 \u0026quot;ljump\u0026quot; 和 \u0026quot;lcall\u0026quot;，而在 Intel 汇编格式中则为 \u0026quot;jmp far\u0026quot; 和 \u0026quot;call far\u0026quot;，即： AT\u0026amp;T 格式 ljump $section, $offset lcall $section, $offset Intel 格式 jmp far section:offset call far section:offset 与之相应的远程返回指令则为： AT\u0026amp;T 格式 lret $stack_adjust Intel 格式 ret far stack_adjust 在 AT\u0026amp;T 汇编格式中，内存操作数的寻址方式是 section:disp(base, index, scale) 而在 Intel 汇编格式中，内存操作数的寻址方式为： section:[base + index*scale + disp]  "}),a.add({id:521,href:"/blog/2014-09-13-cplusplus%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/",title:"C++核心知识点总结",description:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是C++编程里的一些知识要点。\n============================================================================= Sun Sep 7 16:50:05 CST 2014 ============================================================================= 为了开启c++11的某些特性，需要在g++编译时添加参数：-std=c++0x。 c++语言里面，除了char类型被明确规定为占1个字节之外，其他的数据类型都没有指定其 具体的尺寸，这样做的原因是，在不同的编译器实现中，编译器会根据运行平台的特点， 自动为各个类型指定所占用的字节数，以使得编译后的程序能够尽可能适应运行平台。这 样做的好处是，使得编写的c++程序，不仅能够适应现在的机器结构，也能适应将来的机 器结构，实在是高明！ c++11标准中变量的初始化方式有3种，这3中初始化方式是等价的： type varname = varvalue; type varname (varvalue); type varname {varvalue}; auto varname = varvalue; 变量auto会根据初始化时初值varvalue的类新，自动指定varname的类型； decltype(varname)可以获取变量varname的类型，例如可以这样使用： newvar； 这样变量newvar与新变量oldvar是相同的类型，decltype主要是用于模板中根据模板参数 的类型创建其他相同变量。 c++中有专门的字符串类string，需要包含头文件string。 cout输出时追加endl的作用不仅仅是输出换行符，考虑一下缓冲机制就明白了，在终端中 ，缓冲一般是采用行缓冲，因此在cout中追加endl不仅输出了换行符，还进行了行缓冲， 从而确保信息被输出到cout上。 如果在通过cout输出某些信息时不在末尾追加endl，如果输出信息中没有换行符做结尾， 那么信息就不会输出到终端上，因为终端采用行缓冲，不碰到换行符或者待输出信息没有 超过缓冲区的长度，信息不会被输出到终端上。 std::cout，std是一个命名空间，c++标准库中的所有东西都包含在std这个命名空间中， cout指定了设备是输出设备，c++中常用的cin\\cout\\cerr就等效于c中的 stdin\\stdout\\stderr。 常量类型 整型常量，常用的包括十进制、八进制、十六进制，分别如123,0234,0xffff；整型常量 可以在末尾追加合适的字符表示该常量应该用什么类型进行存储： u/U表示unsigned； l/L表示long； ll/LL表示long long； 浮点常量，常用的包括float、double、long double，浮点常量的形式包括3.1415、 3.14e23，其中e表示10的多少次方，浮点常量默认是用一个double类型进行存储，也可以 在浮点常量的末尾追加字符表示使用什么类型进行存储，例如： f/F表示float类型； l/L表示long double类型； 什么都不加，即采用默认的double类型； 在c++ shell中的测试结果显示，double表示8字节，long double表示16字节，这个跟编 译器有关。 字符常量、字符串常量'x',\u0026quot;xxxxx\u0026quot;，注意一些特殊的转义字符，例如： \\n newline \\r carriage return \\t tab \\v vertical tab \\b backspace \\f form feed (page feed) \\a alert (beep) \\' single quote (') \\\u0026quot; double quote (\u0026quot;) \\?",content:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是C++编程里的一些知识要点。\n============================================================================= Sun Sep 7 16:50:05 CST 2014 ============================================================================= 为了开启c++11的某些特性，需要在g++编译时添加参数：-std=c++0x。 c++语言里面，除了char类型被明确规定为占1个字节之外，其他的数据类型都没有指定其 具体的尺寸，这样做的原因是，在不同的编译器实现中，编译器会根据运行平台的特点， 自动为各个类型指定所占用的字节数，以使得编译后的程序能够尽可能适应运行平台。这 样做的好处是，使得编写的c++程序，不仅能够适应现在的机器结构，也能适应将来的机 器结构，实在是高明！ c++11标准中变量的初始化方式有3种，这3中初始化方式是等价的： type varname = varvalue; type varname (varvalue); type varname {varvalue}; auto varname = varvalue; 变量auto会根据初始化时初值varvalue的类新，自动指定varname的类型； decltype(varname)可以获取变量varname的类型，例如可以这样使用： newvar； 这样变量newvar与新变量oldvar是相同的类型，decltype主要是用于模板中根据模板参数 的类型创建其他相同变量。 c++中有专门的字符串类string，需要包含头文件string。 cout输出时追加endl的作用不仅仅是输出换行符，考虑一下缓冲机制就明白了，在终端中 ，缓冲一般是采用行缓冲，因此在cout中追加endl不仅输出了换行符，还进行了行缓冲， 从而确保信息被输出到cout上。 如果在通过cout输出某些信息时不在末尾追加endl，如果输出信息中没有换行符做结尾， 那么信息就不会输出到终端上，因为终端采用行缓冲，不碰到换行符或者待输出信息没有 超过缓冲区的长度，信息不会被输出到终端上。 std::cout，std是一个命名空间，c++标准库中的所有东西都包含在std这个命名空间中， cout指定了设备是输出设备，c++中常用的cin\\cout\\cerr就等效于c中的 stdin\\stdout\\stderr。 常量类型 整型常量，常用的包括十进制、八进制、十六进制，分别如123,0234,0xffff；整型常量 可以在末尾追加合适的字符表示该常量应该用什么类型进行存储： u/U表示unsigned； l/L表示long； ll/LL表示long long； 浮点常量，常用的包括float、double、long double，浮点常量的形式包括3.1415、 3.14e23，其中e表示10的多少次方，浮点常量默认是用一个double类型进行存储，也可以 在浮点常量的末尾追加字符表示使用什么类型进行存储，例如： f/F表示float类型； l/L表示long double类型； 什么都不加，即采用默认的double类型； 在c++ shell中的测试结果显示，double表示8字节，long double表示16字节，这个跟编 译器有关。 字符常量、字符串常量'x',\u0026quot;xxxxx\u0026quot;，注意一些特殊的转义字符，例如： \\n newline \\r carriage return \\t tab \\v vertical tab \\b backspace \\f form feed (page feed) \\a alert (beep) \\' single quote (') \\\u0026quot; double quote (\u0026quot;) \\? question mark (?) \\\\ backslash (\\) 转义字符的输出还可以通过\\后加八进制数字或者十六进制数字的形式进行，八进制数字 直接加在\\后面，十六进制数字需要在\\后面加个x，然后再加上对应的十六进制数字，如 下： \\77 \\xff 常量字符也可以在后面追加字母表示类型，例如： u表示char16_t， U表示char32_t， L表示wchar_t， 什么都不加表示char。 此外常量字符串前面还可以追加前缀，例如： u8,u8\u0026quot;hello world\u0026quot;，u8表示后面的字符串采用utf8编码，解码的时候怎么指定编码？； R,R\u0026quot;hello'''\\xxx\u0026quot;，R表示后面的字符串是原始字符串，没看懂什么意思； 其他常量类型：true、false、nullptr。 通过const指定常量，通过预处理指令#define、#undef定义、取消定义常量。 cin\\cout\\cerr\\clog，其中clog是日志流，其他3个跟c中的类似。 \u0026lt;sstream\u0026gt;中的stringstream允许将一个string对象当作一个流，然后从这样的流中读取 、插入指定类型的数据，这就类似于c语言里面的sscanf、sprintf。 string a = \u0026quot;1111\u0026quot;; int b; stringstream(a)\u0026gt;\u0026gt;b; cin类似于scanf，cout、cerr、clog类似于printf(stdin/stderr, \u0026quot;xxx\u0026quot;, xxx)。 ============================================================================= Mon Sep 8 01:48:59 CST 2014 ============================================================================= 内联函数只是告诉编译器建议采用内联的形式，但是只是建议，具体是不是内敛要看编译 器的具体实现。 函数原型声明中只需要包含函数名称以及参数类型即可，不必指明参数名称以及具体的函 数实现。 通过模板参数来定义类和函数，可以适用于多种类型，增强适应性。模板参数的声明形式 为： template \u0026lt;class T1, class T2, ..., class T3\u0026gt; { return (T3)xxx; } 上面只是举了一个简单的例子，注意模板参数中的class可以用typename代替。 命名空间的使用实例。 1）定义一个命名空间： namespace my { int a,b; } 2）使用一个命名空间：方式1是通过{using namespace my; cout\u0026lt;\u0026lt;a\u0026lt;\u0026lt;b;}，方式2是通过 cout\u0026lt;\u0026lt;my::a\u0026lt;\u0026lt;my::b； 3）命名空间可以创建别名，例如namespace aliasname == oldname; 数组c++提供了一个library array, array\u0026lt;int,3\u0026gt; a {1,2,3}。 char * str = \u0026quot;helloworld\u0026quot;; str[0] = 'A'; 因为helloworld是存放在常量存储区中的，str只是指向了这个常量存储区中的地址，其 中的内容是不允许被修改的，因此str[0]被赋值的时候，会报段错误； char str[20] = \u0026quot;helloworld\u0026quot;; str[0] = 'A'; 因为helloworld是存放在str[20]中的，str这个数组是在栈中被创建的，因此是可以被修 改的，后面的str[0]被赋值是合法操作； c风格的字符串与c++中string字符串类是可以相互转换的，例如将c风格的转换成string： char * str = \u0026quot;helloworld\u0026quot;; string s = str; 将string字符串对象转换成c风格字符串： string s = \u0026quot;helloworld\u0026quot;; const char * str = s.c_str(); ============================================================================= Tue Sep 9 00:37:56 CST 2014 ============================================================================= 关于const修饰的是指针还是值的问题，请参见如下形式： int x; int * p1 = \u0026amp;x; // non-const pointer to non-const int const int * p2 = \u0026amp;x; // non-const pointer to const int int * const p3 = \u0026amp;x; // const pointer to non-const int const int * const p4 = \u0026amp;x; // const pointer to const int 可见const仅仅紧跟在其后的类型进行修饰。 void类型表示没有类型或者没有指定类型，void*类型就可以指向任何数据类型，但是在 对数据进行类型转换时，必须明确地知道数据的类型，然后进行强制类型转换。 type (*funcPtr)(type,type,type...)，定义了一个函数指针funcPtr，例如： { return a+b; } { = add; int result = myadd(1,2); } pointer = new type pointer = new type [number] delete pointer delete [] pointer c++中通过new来申请内存的时候，内存如果申请失败该如何处理呢？c++语言提供了几种 处理方式，如果内存申请失败，会抛出bad_alloc异常，如果这个异常没有被捕获，则程 序会被强制终止；如果该异常通过try-catch捕获，则不会终止程序，而是从catch开始执 行；通过在new语句中加入（nothrow）来阻止抛出异常，而将new返回的结果设为nullptr ，这样程序也会继续向后执行。 关于异常、nothrow两种方式对内存分配失败的处理，nothrow效率要低一些，因为这种机 制对内存分配进行显示地检查，不管成功还是失败，而异常机制则只是在申请内存失败的 时候才会触发，因此捕获异常这种机制的效率要更高些，但是nothrow相对来说要简洁些 。 需要特别强调的是，c++虽然支持c中的malloc、calloc、realloc、free方法，但是 malloc等申请得到的内存块与new返回的内存块并不兼容，因此不应混用，例如malloc出 来的内存块必须用free释放，而不能用delete释放。 c++中定义类型可以通过struct、typedef、using，其中struct允许嵌套，typedef举例： typedef char C; typedef unsigned int WORD; typedef char * pChar; typedef char field [50]; // field == char[50] using new_type_name = existing_type;举例： using C = char; using WORD = unsigned int; using pChar = char *; using field = char [50]; struct\\union enum\\enum class\\enum struct c++中类访问修饰符： private：可以被当前类、friend类访问； protected：可以被当前类、friend类、派生类访问； public：可以被当前类、friend类、派生类、非派生类访问； 定义类的时候，可以把类的成员函数的实现在类体中定义，也可以在类体外面定义，两种 方式的区别是，在类体内部定义的成员函数会被自动当成inline函数,而在类体外定义的 则不被当作inline函数，这对编译器对代码进行优化时有影响。 关于如何调用构造函数： new func(x,y,z); // 传统函数式 new func = x; // 如果构造函数只包含一个参数 new func {x,y,z}; // c++11中引入的统一式 对成员进行初始化可以在构造函数中进行，也可以在成员初始化器中进行。两者有所区别 ，在对基本数据类型进行初始化的时候，通过构造函数和成员初始化器这两种方式并没有 多大区别，但是当类定义中有一个类对象作为成员时，假如不在成员初始化器中对其进行 初始化，就会调用它的默认构造函数完成初始化，因此成员对象如果需要特别的初始化操 作一般要放在成员初始化器中进行。 c++中也可以用struct定义类似类的结构，其中也可以定义各种成员函数，但是struct中 所有的成员默认都是public。 至于union的话，自己搜索下吧。 ============================================================================= Wed Sep 10 17:49:15 CST 2014 ============================================================================= 传参数、返回返回值，实际上都是创建了值的一份拷贝，不管是不是传引用、指针，即便 是引用、指针，也是引用、指针值的一份拷贝， 一般返回值都是放在eax寄存器里，但是有的时候eax寄存器装不下了，就得往其他地方放， 对于大结构体、对象的返回值我确实没有研究过，不过我想返回的时候可能是在栈上创建 了一个临时变量，然后将变量的值搬到另一个接收返回值的变量中。如果没有变量接收返 回值呢，这样想的话，一定有某个中间的临时位置用于存储这个返回值。需要研究下。 经过测试，不管是什么类型，只要返回值足够eax寄存器装下，那么就会将返回值存在eax 寄存器中，如果返回值超出了eax寄存器的位宽呢？ 编译器是这么做的，假定有如下代码： struct num { long long a; long long b; }; typedef num NUM; { NUM res; res.a = a.a+b.a; res.b = a.b +b.b; return res; } { NUM a,b; a.a=100; a.b=100; b.a=200; b.b=300; NUM c = add(a,b); } 看这段简单的代码，首先编译器知道了返回值要往c这个地方存储，并且也知道了NUM类型 的返回值超过了寄存器的位宽，不可能保存在eax寄存器中。 这个时候，编译器会在栈中为c分配好空间，然后将变量c的内存单元地址存储到rdi这个 基地变址寄存器中，然后开始调用add。 add进入函数体后，将调用者传递过来的rdi寄存器的值，存储到当前函数所在栈帧中的某 个位置，然后开始根据调用者传递过来的参数进行运算，并将运算结果存储到当前栈帧中 的NUM res中。当return语句被执行时，从存储了rdi寄存器值的那个内存区域取回其中的 值，这个值就是返回值所要存储到的位置，然后根据该值及一系列的mov指令将运算结果 写入目标返回位置。此时执行完成时，对应的c=add(a,b)这条语句的赋值也就完成了。 如果只是调用add(a,b)则在add调用开始之前，也需要调用者通过rdi寄存器通知add将结 果存储到哪个位置，此时这个存储位置是调用者在其所在栈上创建的一个位置。 ok! 现在把函数返回值的存储问题解决了！ 上面的问题解决了之后，又学到了新的知识，哈哈，幸亏我想不通了就会google！ 之前我学习linux编程基本上是在笔记本thinkpad x61t上进行的，当时我在做反汇编的时 候发现所有的寄存器类型不外乎al,ah,ax,eax（现在明白了因为当时的cpu是L7500，应该 是32位运算能力），当时我了解ax包括了ah、al，但是我不清楚eax跟它们的区别，由于 看汇编计算字节偏移量时我只考虑了变量在内存中的开始位置，没有考虑结束位置，因此 当时寄存器位宽这个问题，没有影响到我做实验，但是今天发现了汇编代码中出现了rax 寄存器，而且发现每次移动struct结构体中的成员时，偏移量是8字节，我才想起这个问 题，会不会是cpu寄存器位宽、数据总线宽度的问题，google了下，寄存器AT\u0026amp;T汇编中代 码及其对应的位宽如下： |63..32|31..16|15-8|7-0| |AH. |AL.| |AX......| |EAX............| |RAX...................| 看完这些就明白其中的原因了！ ============================================================================= Thu Sep 11 17:13:53 CST 2014 ============================================================================= c++中定义的类本质上是在c++中定义了一种新的数据类型。 c++中规定了一些允许重载的运算符，汇总如下： + - * / = \u0026lt; \u0026gt; += -= *= /= \u0026lt;\u0026lt; \u0026gt;\u0026gt; \u0026lt;\u0026lt;= \u0026gt;\u0026gt;= == != \u0026lt;= \u0026gt;= ++ -- % \u0026amp; ^ ! | , -\u0026gt;* -\u0026gt; new delete new[] delete[] 运算符重载的格式为： type operator sign (params); 例如: { .... return (Obj)objx; } 当重载完成之后，可以隐式地调用+这个函数，也可以显示的调用+这个函数，其形式分别 为： c = a+b; c = a.operator+(b); 上述两种方法是等效的。 注意二元运算符重载的时候，默认第一操作数（左侧的操作数）为当前运算符函数的调用 者，例如a.operator+(b)中+的第一操作数即为a。 二元运算符在重载的时候参数列表中只允许有一个参数，此时如果想用两个参数，可以使 之成为友元函数；另外如果二元运算符两侧的操作数类型不一样，需要特别注意，调用的 时候应该注意调用顺序。 不同的运算符重载的时候的格式，汇总如下： Expression Operator Member function Non-member function operator@(A) operator@(A,int) operator@(A,B) - - - - c++类模板，形式大致如下： template \u0026lt;class T\u0026gt; class Obj { T ... T ... T func(T t1, T t2, ...); } 指定类模板参数时除了可以使用class T，也可以使用typename T来代替。 如果已经有了个类被声明为类模板，在此基础上我们可以实现自己的一个模板特例，例如： template \u0026lt;class T\u0026gt; class mycontainer { ... }; template \u0026lt;\u0026gt; class mycontainer \u0026lt;char\u0026gt; { ... }; 我们定义了一个模板类mycontainer，如果有需要，在此基础上，我们可以实现一个模板 特例，即template \u0026lt;\u0026gt; class mycontainer \u0026lt;char\u0026gt; {...}; c++类中特殊的成员函数，有6个，整理成5条，我们将移动构造、赋值函数放在5）中进行 描述，好的，下面以类Ex为例: 1）默认构造函数 Ex::Ex() 如果没有显示地为类定义一个构造函数，那么c++编译器会默认为其创建一个不带任何参 数的构造函数，这个构造函数就称为默认构造函数； 当显示地为该类指定了一个构造函数时，那么c++编译器便不再为该类隐式地创建默认构 造函数； 2）析构函数 Ex::~Ex() 在析构函数里面执行一些与构造函数功能相反的任务，例如在构造函数中申请了内存，在 类对象声明周期结束的时候，析构函数被自动调用，析构函数里面可以实现资源的回收及 释放等清理工作； 3）拷贝构造函数 Ex::Ex(const Ex\u0026amp;)/Ex::operator= (const Ex\u0026amp;) 注意原型中参数Ex\u0026amp;表示的是某个对象的引用！参数类型需要与当前对象类型一致！ 假如有如下代码: Ex d; Ex e(d); 如果没有显示地创建一个拷贝构造函数，那么c++编译器会提供一个默认的拷贝构造函数 ，这个默认的拷贝构造函数的实现只是简单的拷贝对象d中的成员的值到e中，而且拷贝是 浅拷贝，所谓浅拷贝指的是，没有考虑指针指向的内存区域，例如d中有一个指针ptr指向 一段内存区域，执行完默认的拷贝构造函数（浅拷贝）之后，d、e中的ptr的值是相同的 ，假如ptr指向的内存是动态分配的，并且d这个对象生命周期结束的时候释放了这段内存 ，那么e中ptr这个指针就变成了无效指针，它指向了一段无效的内存区域，继续访问这段 内存区域的话将引起难以预料的后果。 如果涉及到动态内存分配，并且对象里面包含了这样的指针的话，应该考虑提供自己定义 的拷贝构造函数，实现深拷贝，从而避免上述情况。实现方法也很简单，比如在自定义的 拷贝构造函数内部，首先申请一段新的内存区域，然后再将这段内存区域的地址赋值给成 员ptr，这样就实现了深拷贝，不会出现之前提到的浅拷贝引发的内存访问问题。 4）拷贝赋值函数 Ex\u0026amp; Ex::operator= (const Ex\u0026amp;) 参数类型需要与当前对象类型一致！ c++中对象的拷贝动作不仅仅是在构造的时候才会发生，当对象已经构造完成，在之后的 有效声明周期过程中，也可以通过拷贝赋值函数完成拷贝对象的动作，注意c++11中引入 的调用构造函数的3中方式： T t; T t(...); T{...}; 上述3中方式都是调用构造函数的方式，但是拷贝构造函数只有如下两种原型形式： T t1; T t2 = t1; 调用拷贝构造函数 T t3(t1); 调用拷贝构造函数 t2 = t1; 调用拷贝赋值函数 需要注意上述几种形式的发生时间以及原型的区别。 || 移动赋值函数 Ex\u0026amp; Ex::operator= (Ex\u0026amp;\u0026amp;) 注意，移动构造函数、移动赋值函数中，其参数类型与当前对象类型一致！ 移动的意思主要是针对动态分配的内存区域，将参数对象中指向动态分配的内存的指针赋 值给目的对象，并将原对象中的指针设置为nullptr。在考虑尽量节省资源的需求下，可 以考虑使用。 那么c++为什么要提供这种移动构造函数呢？算是另一种形式的垃圾回收吧！？！ 在c++的世界里，所有的动态分配的内存都需要程序员自行管理，不像java里面那样有gc 可以自动帮你把没有被引用的内存区域进行释放完成内存回收，举例来看，在java中假如 有这样一段代码： ArrayList a = new ArrayList(); a = new ArrayList(); 上述代码中，在执行第二行代码a = new ArrayList()时，a指向了新的内存区域，但是第 一次申请的内存此时没有变量引用它，因此它的引用计数为0，当gc进行垃圾回收时会回 收这样的内存，因此不需要程序员自己管理垃圾的释放、内存的回收，减轻了程序员的压 力。但是gc也占用资源，而且回收不及时，对系统性能影响也比较大。 我们来看看c++中是如何对内存进行更有效的管理的，通常程序员在堆上申请了内存之后 ，例如new了之后，必须通过delete显示地加以释放该内存区域，否则该内存不会被回收 ，程序员不得不认真考虑内存的占用问题，一定程度上，受此影响，程序员也对资源、性 能、垃圾回收的概念比较清晰、谨慎。 此外，需要注意的是，有的时候，在c++中，某些在堆上创建的匿名对象我们是无法去显 示的释放的，例如有一段代码： new Ex(); 上面这行代码创建了一个对象，但是没有变量指向这个对象，我们是无法显示地通过 delete释放其所占用的堆内存的，在c++中应该尽力避免这样的情况，但是有的时候无法 避免这种情况。 上面说了这么多，还没有说到移动构造函数、移动赋值函数诞生的原因，这两个特殊的函 数参数都必须是匿名对象，我们看个例子。 class Ex { string * ptr; { ptr = new string(param); } { this.ptr = t.ptr; t.ptr = nullptr; } { this.ptr = t.ptr; t.ptr = nullptr; } } Ex a(Ex(\u0026quot;xxx\u0026quot;)); 代码中首先首先创建了一个对象Ex(\u0026quot;xxx\u0026quot;)不过它是匿名对象，虽然创建的这个匿名对象 是一个局部变量 在参数列表中创建的），但是这个变量内部包含了一个指向堆内存的指 针，并且这段内存没有被在析构时释 ，这样这段内存会被泄漏，现在我通过移动构造函 数，将这段ptr指向的差点泄漏的内存为新变量Ex a所使用，即通过移动构造函数将匿名 对象中的ptr的值移动到对象a中，这样不仅没有造成内存泄漏，还巧妙的进行了对象a的 初始化操作。参见Ex::Ex(Ex\u0026amp;\u0026amp; t)定义。 移动构造函数与之类似，只不过是在对象构建之后继续操作，例如调用如下代码： Ex a(\u0026quot;hello\u0026quot;); a = Ex(\u0026quot;hello world\u0026quot;); 第二行就是执行的移动赋值函数，参见Ex::operator=函数定义。 但是经过测试，我发现移动赋值函数成功执行了，但是移动构造函数没有执行,可能是编 译器的原因。因为“移动”的支持是c++11中才引入的。 这里顺便讲一下运算符\u0026amp;和\u0026amp;\u0026amp;的区别： \u0026amp;：引用运算符，比如这样使用： int a = 100; int \u0026amp;b = a;我们定义了一个a的引用b， 或者说b是a的引用。因为\u0026amp;b = a，a是a=100这条语句的左值，所以说\u0026amp;运算符称为左值引 用或者简称为引用。 \u0026amp;\u0026amp;: 右值引用运算符，比如这样使用: class Ex {...}; Ex a;	// default constructor Ex \u0026amp;b = a;	// 创建了一个a对象的引用b Ex \u0026amp;\u0026amp;c = a;	// invalid, 因为a是一个左值，第一条语句相当于Ex a = Ex(); Ex \u0026amp;\u0026amp; p = Ex();	// valid， \u0026amp;\u0026amp;引用的是右值，右边的Ex()没有被任何左值变量所记录 说明了什么呢？\u0026amp;\u0026amp;做右值引用的时候，赋值运算符右边创建按的临时对象，不能被任何变 量所引用，也就是说匿名对象，而移动构造函数、移动赋值函数，也正是为了解决匿名对 象的清理才引入的。 简单总结一下： c++中类的6种特殊的默认成员函数： 成员函数名称 成员函数原型 Default constructor C::C(); Destructor C::~C(); Copy constructor C::C (const C\u0026amp;); Copy assignment C\u0026amp; operator= (const C\u0026amp;); Move constructor C::C (C\u0026amp;\u0026amp;); Move assignment C\u0026amp; operator= (C\u0026amp;\u0026amp;); 上面提到的这6个成员函数都是由c++隐式定义的，下面说一下这些隐式定义会执行哪些操 作： 隐式成员函数名称 条件 操作 Default constructor if no other constructors does nothing Destructor if no destructor does nothing Copy constructor if no move constructor and no move assignment copies all members Copy assignment if no move constructor and no move assignment copies all members Move constructor if no destructor, no copy constructor and no copy nor move assignment moves all members Move assignment if no destructor, no copy constructor and no copy nor move assignment moves all members 这6个隐式的成员函数，默认都是被开启的，我们可以选择开启或者禁用其中的某个或者 全部，显示开启或关闭的方法，很简单，只要按照如下格式在类声明中注明就可以了： function_declaration = default; function_declaration = delete; 举个例子: class C { // 表明该原型将使用c++提供的默认构造函数 = default; // 表明该原型（拷贝构造函数）被禁用，即不使用拷贝构造函数（默认的拷贝构造 // 函数也一并被禁用了） = delete; } ============================================================================= Sat Sep 13 00:13:16 CST 2014 ============================================================================= c++中，在类A中通过friend修饰的函数或者类不是A的成员，他可以直接访问A的private 修饰的数据。 类继承： class A : public B { }; A继承自B，B前面有访问修饰符，继承时的访问修饰符规定： B中的成员的访问修饰符级别如果比继承时的访问修饰符更加严格，那么A继承B之后，对A 来讲，B中的成员的访问级别保持不变； 如果B中的成员的访问级别比继承时的访问级别要更加宽松或者相等，那么A继承B之后， 对A来讲，B中对应的成员的访问级别由继承时的访问修饰符来修饰。 继承时的访问修饰符的目的，其实还是为了对成员的访问进行限制，继承时的访问修饰符 不会使被继承成员的访问更加宽松，而是使其访问级别变得更加严格或者保持不变。例如 ，如果继承时的修饰符是private，那么对A来讲，B中所有成员的访问修饰符将被限定为 private，从A中将无法访问B中的任何成员。 Access public protected private members of the same class yes yes yes members of derived class yes yes no not members yes no no 类继承的时候，派生类会继承基类的成员，但是不包括下面这些成员： its constructors and its destructor its assignment operator members (operator=) its friends its private members 多重继承，class A : public B, protected C, ... {}; 声明引用MyClass \u0026amp;obj2 = obj; 这样声明了一个引用obj2，它引用了obj这个对象， MyClass *ptr = \u0026amp;obj;则是创建了一个指向对象obj的指针，注意引用、指针声明方式的 区别。 c++中多态实现方式，简单地说是：指针+虚函数+类继承。 首先，要实现多态，必须有个基类，然后定义几个派生类。然后需要创建几个基类指针， 让基类指针指向派生类对象。然后通过基类指针去调用期望的成员函数，实现多态。这里 要想让其表现出多态的特征，必须在基类中用virtual定义虚函数（虚函数可以由派生类 重新定义），然后派生类重新定义虚函数。这样通过指向派生类对象的基类指针去调用这 些虚函数时，就会根据指针指向的对象类型，自动调用目标对象中的这些成员函数。这样 就实现了多态。 注意，基类指针，可以访问到的成员函数，与其指向的对象类型无关，只与基类自身有关 ，基类中定义了什么，它就可以访问到什么，基类中如果没有定义，就算是派生类中定义 了，它也是访问不到的，就相当于已经将派生类对象进行了强制类型转换，向上转换成了 基类而将自己添加的部分丢弃了一样。 虚函数可以有函数定义，没有函数定义的函数就变成了纯虚函数，其语法是type = 0;即将函数定义部分用“=0;\u0026quot;替换。 包含纯虚函数的类就是抽象类（在java中，抽象类要通过abstract关键字指明），抽象类 不能用来实例化对象，只适合用来做基类，然后创建它的派生类对象。但是抽象类也不是 完全没有用的，作为基类是一个不错的选择，另外，它也可以用于创建指向派生类对象的 基类指针，然后使用c++中多态的一切特征。 类型转换： 1）基本数据类型的类型转换： 基本类型的隐式类型转换，例如从short a=2000; int b=a;这里就b=a就发生了short向 int的饮食类型转换。对于c++中的基本数据类型，从精度较低的转换为精度较高的类型时 ，由于不会发生数据丢失，所以一般会自动地进行类型转换，不需要编码中显示指明，因 此称之为隐式类型转换。 但是当基本数据类型从精度较高的转换为精度较低的类型时，由于有可能发生数据丢失， 一般情况下，编译器会报warning而不是错误，一般在编码时需要显示指明类型转换，我 们称之为强制类型转换。 2）类的类型转换： 类之间也可以发生类型转换，但是试想一下，类有不是简单的数据类型，它还包括成员函 数，怎么能实现类型的转换呢？更不用说也是类型转换了！对，那么它一定是通过某种诡 辩术实现了这一类型转换，总结一下，类之间的饮食类型转换，主要通过3个成员函数进 行： [single-argument constructor]：允许用一个特定的类型来初始化另一个类型，例如有 两个类A、B，B中定义一个构造函数来完成利用对象A a对B对象的初始化： class B { {...}; }; A a; B b(a); 注意这里的构造函数只是一个普通的构造函数，我们之前提到的拷贝构造函数、拷贝赋值 函数、移动构造函数、移动赋值函数这几个特殊的成员函数，其参数类型与当前类类型都 是一致的。 [assignment operator]：通过这个赋值运算符，完成类型的转换。这里需要重载运算符= ，例如还是两个类A、B，B希望能够实现在赋值时将对象A隐式转换成对象B，可以这样实 现： class B { {....} }; A a; B b; b=a; 注意这里重载了赋值运算符， [type-cast operator]：通过类型转换运算符，完成类型的转换。这里需要重载运算符() ，例如还是两个类A、B，B希望能够被强制类型转换成类A对象，这可以这样实现： class B { {return A()} }; A a; B b; a = b; a=b;这行代码表示B类对象b需要被隐式转换成A类对象，因此会调用b.A()方法转换成A类 对象。 关于运算符重载，请仔细查看c++中运算符重载规则，有的运算符重载时有返回值，有的 则没有返回值，需要注意。另外，运算符重载的时候，应保持其实现与其语义相一致。 c++中在函数调用的时候，会检查传递给函数的参数类型，如果类型不匹配，例如传递的 实参的类型为A，并且期望的参数类型B中提供了一个合适的隐式类型转换函数，能够将A 转换成B，那么就会发生隐式类型转换。如果我们不希望这种隐式类型转换的发生，可以 在B中的对应类型转换函数之前加上关键字explicit，这样就会阻止饮食类型转换的发生 。例如： class A{}; class B{ {..} }; {...} { A a; fn(a); } 其中fn(a)这一行会报错，因为在B的类定义中已经通过explicit关键字禁用了从A向B的隐 式类型转换。 这种情况下，可以通过强制类型转换来解决，fn((b)a);其执行过程是，编译器检查到fn 形参类型为B，但是实参类型为A，于是希望能够进行隐式类型转换，于是去检查B的定义 中有没有合适的隐式类型转换函数，结果找到了B(A\u0026amp; a);这个合适的函数，但是它被 explicit修饰，禁用了自动隐式类型转换，于是开始检查传递形参到fn时是否指明了强制 类型转换，检查到传递的形参是(B)a，即指明了要从A向B进行强制类型转换，满足了 explicit的要求，然后类型转换开始，将a转换为B类对象后作为实参传递给fn，fn执行。 另外，多提一句，在c++中，对象的初始化的3中形式其实调用的是相同的构造函数。例如 ： A a; B b=a; // 形式1 B b(a); // 形式2 B b{a}; // 形式3 这3种形式都是调用的构造函数B(A \u0026amp;)。 类的显示类型转换，也是通过强制类型转换运算符实现()。c++中类型转换考虑的比较周 全，首先提供了两个比较通用的强制类型转换形式： expression; // c-style notation new_type (expression); // functional notation 此外还提供了4中类型转换运算符，在说明这4中类型转换运算符之前，先说明下其原因。 由于通过强制类型转换，尤其是指针类型的转换，我们通过强制类型转换，可以将一个指 针指向任何类对象，当我们通过这样的指针调用某些成员函数的时候，就会出现runtime 错误，虽然在编译时没有任何问题，但是在运行时会出错。为了安全起见，c++提供了4中 类型转换运算符用于对类对象的强制类型转换进行控制。 它们分别是： dynamic_cast \u0026lt;new_type\u0026gt; (expression); reinterpret_cast \u0026lt;new_type\u0026gt; (expression); static_cast \u0026lt;new_type\u0026gt; (expression); const_cast \u0026lt;new_type\u0026gt; (expression); 每一种类型转换都有自己独特的特征。 dynamic_cast \u0026lt;new_type\u0026gt; (expression)： dynamic_cast可以实现upcast和downcast，dynamic_cast仅应被用于指类对象的指针或者 引用的类型转换（包括void*），它的目的是确保转换后的指针或者引用可以指向一个有 效的、完整的对象。如果转换成功，返回对应的指针或引用；如果转换指针失败，返回 null，null就是0，内存0地址，如果转换引用失败，则抛出bad_cast异常，表示转换引用 失败。 看下面这个简单的例子： {} }; class Derived: public Base { int a; }; { try { Base * pba = new Derived; Base * pbb = new Base; Derived * pd; pd = dynamic_cast\u0026lt;Derived*\u0026gt;(pba); cout \u0026lt;\u0026lt; \u0026quot;Null pointer on first type-cast.\\n\u0026quot;; pd = dynamic_cast\u0026lt;Derived*\u0026gt;(pbb); cout \u0026lt;\u0026lt; \u0026quot;Null pointer on second type-cast.\\n\u0026quot;; {cout \u0026lt;\u0026lt; \u0026quot;Exception: \u0026quot; \u0026lt;\u0026lt; e.what();} return 0; } 上面的代码中，第一次类型转换是成功的，因为pba指向了一个完整的派生类对象，虽然 pba是一个基类指针，通过dynamic_cast可以被downcast成派生类指针；第二次类型转换 是失败的，因为pbb指向的是一个基类对象，这个基类对象不是一个有效的、完整的派生 类对象，所以将该基类指针downcast成派生类指针会失败。 dynamic_cast需要RTTI（Runtime Type Information）的支持，需要编译器在编译的时候 打开相应的feature在编译后的代码中假如相应的信息，以便在运行时追踪dynamic类型信 息，以便完成这样的动态类型转换。 static_cast \u0026lt;new_type\u0026gt; (expression): static_cast可以实现upcast和downcast，应该说static_cast是dynamic_cast的经济实用 版，为什么这么说呢？首先，它会在编译时完成指针和引用的upcast和downcast ，这个 与dynamic_cast相同，但是它不会像dynamic_cast那样，在运行时检查转换后的指针或引 用是否指向了一个有效的、完整的对象，运行时安全可能无法保证，类型转换后的安全由 程序员自己决定，因此，static_cast较之于dynamic_cast，损失了运行时安全检查，但 是也正是由于此，也减少了因为类型安全检查所引起的开销。 reinterpret_cast \u0026lt;new_type\u0026gt; (expression): dynamic_cast、static_cast基本上都是在基类和派生类指针、引用之间进行转换，与它 们相比，reinterpret_cast可以实现任何指针类型向任何指针类型的转换，它的做法就是 将指针的值拷贝过去。基于这样的实现，它甚至可以将整型转换为指针类型，只要指针变 量的内存单元可以容纳这个整型值，这也是其提供的唯一的安全性检查。 const_cast \u0026lt;new_type\u0026gt; (expression): const_cast主要是用于对指针set、remove const标志，即设置const标志或者移除const 标志，根据当前类型与目标类型是否有const标志自动进行设置。 在讲下面的例子之前，有几个基本常识需要了解，在c、c++中字符串常量都是存放在常量 存储区中的，是不允许修改的，例如char *str=\u0026quot;helloworld\u0026quot;,这里的helloworld就是存 储在常量存储区中的，虽然char *str前面没有const修饰，也不能通过str[i]去改变 helloworld中某个字符的值。如果是这样赋值，char str[] = \u0026quot;helloworld\u0026quot;,则 helloworld不是存储在常量存储区中的，而是存储在栈上的，str这个数组在栈上创建， hellowrold就存储在对应的内存单元中。 其实为什么会有这些差别，说白了都是编译器实现的原因。应该了解下编译器对内存分配 的管理，例如将内存分成堆区、栈区、程序文本区，刚才我习惯性说的常量存储区也就是 程序文本区，反汇编的时候就是.text段，总之是不允许修改的。 好了看下面一个简单的例子，理解下const_cast的使用： void print (char * str) { cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; '\\n'; str[0] = 'A'; cout \u0026lt;\u0026lt; str \u0026lt;\u0026lt; '\\n'; } { char str[] = \u0026quot;hello world\u0026quot;; const char * c = str; ); return 0; } 这里主要看函数print，它的参数类型是char *而不是const char *，而参数c是const char *类型，我们在调用print时，使用了const_cast对c进行类型转换，转换的类型与c 相同，只不过是需要const_cast根据需要为我们选择是设置const标志还是移除const标志 ，这里const_cast为我们移除了const标志，使我们在print中可以改变字符串中的值。 通过typeid获取对象的类型信息，看一个简单的例子： { int * a,b; a=0; b=0; != typeid(b)) { cout \u0026lt;\u0026lt; \u0026quot;a and b are of different types:\\n\u0026quot;; \u0026lt;\u0026lt; '\\n'; \u0026lt;\u0026lt; '\\n'; } return 0; } 输出： a is: int * b is: int typeid可以通过参数的类型构建出一个对象，这个对象的name方法可以获取到这个类型的 描述性字符串，这些类型信息在头文件\u0026lt;typeinfo\u0026gt;中定义。 下面在看一个typeid获取类对象类型信息的简单例子： class Base { virtual void f(){} }; class Derived : public Base {}; { try { Base* a = new Base; Base* b = new Derived; \u0026lt;\u0026lt; '\\n'; \u0026lt;\u0026lt; '\\n'; \u0026lt;\u0026lt; '\\n'; \u0026lt;\u0026lt; '\\n'; \u0026lt;\u0026lt; '\\n'; } return 0; } 输出： a is: class Base * b is: class Base * *a is: class Base *b is: class Derived 注意typeid这两个应用实例，应用起来就没有问题了。 另外需要注意，如果typeid(*ptr)中ptr为null的话，会抛出bad_typeid异常。 c++中异常处理： try-catch，try中包含可能抛出异常的代码，抛出的异常可以是基本数据类型，也可以是 类对象，例如: throw 20; throw new B(); 捕获基本数据类型时需要注意，catch(int e)或者catch(int \u0026amp;e),其中必须精确指明异常 类型为int，如果将其指明为short或者long则不会被捕获，如果需要一个能够捕获所有异 常类型的处理句柄，可以使用catch(...)来作为默认异常捕获句柄。 捕获类对象异常类型时，与捕获基本数据类型的异常稍微有所区别，例如假如有两个类A 、B，并且B是A的派生类，如果我们throw new B()，如果希望捕获类B，要么直接在catch 中捕获B类型异常对象，通过catch(B e)或者catch(B \u0026amp;e)进行直接捕获，要么通过 catch(...)捕获。 此外，还可以利用类的继承关系，来通过基类A来捕获派生类B，但是需要注意的是，基类 A必须是c++中标准异常类std::exception的派生类才可以，如果满足了这个条件，catch 的时候就可以通过catch(A \u0026amp;e)或者catch(A e)来捕获派生类B的对象。 一般，异常类，应该继承自std::exception，这样我们可以通过类的继承链关系来对抛出 的异常进行捕获，并且这样的话，也可以通过std::exception来统一对抛出的异常类对象 进行捕获。 与c++做个对比，java中捕获异常的时候，如果希望达到通过基类捕获派生类对象的目的 ，例如通过A捕获B，那么要求类A必须是java.lang.Throwable的派生类，在java中通过基 类异常对象Exception捕获所有的异常对象。 此外，java中要catch的对象必须是java.lang.Throwable的派生类，也就是普通的基本数 据类型、非其派生类对象是不能够被当作异常抛出的。 在try-catch的过程中，可能会出现层层嵌套的情况，这个时候，如果希望将所有的异常 在外层进行统一处理，内层仅用来捕获异常的话，那么内层捕获异常之后可以选择将异常 重新抛出 ，即通过不带任何参数的语句throw就可以将异常重新抛出。 捕获异常的时候，为了提高效率，尽量传引用，而不是传值，这样可以一定程度上提高效 率。 try { try { throw xxx; } { throw; } } { ... } 捕获异常之后，为了能够将捕获到的对象的异常信息显示出来，可以重写std::exception 中的成员函数what()。 c++标准库中抛出的所有异常类都继承自std:exception这个类，这些异常类包括: bad_alloc thrown by new on allocation failure bad_cast thrown by dynamic_cast when it fails in a dynamic cast bad_exception thrown by certain dynamic exception specifiers bad_typeid thrown by typeid bad_function_call thrown by empty function objects bad_weak_ptr thrown by shared_ptr when passed a bad weak_ptr ============================================================================= Sat Sep 13 12:05:00 CST 2014 ============================================================================= c++中的预处理指令，下面只介绍这些预处理指令中的一些常用的方法，具体地高级应用 暂不涉及。 宏定义#define,#undef: 预处理指令创建的宏在#undef之前一直有效，与语句块无关。宏定义在编译之前由预处理 器读取并进行相应的处理，宏定义的话，预处理器不会检查其数据类型，而仅仅是进行简 单的文本替换。 #define NUM 100 a\u0026gt;b?a:b #x x ## y 宏定义中的#表示将参数x两侧加上双引号,##表示将两个参数x，y连接在一起，连接的时 候只是将x、y的值连接，##前后的空格不用于连接。 条件包含指令： #ifdef,#ifndef,#if,#endif,#else,#elif 条件包含指令在内核代码中大量出现，可以用于条件编译。 行控制： #line linenumber \u0026quot;filename\u0026quot;，我们在编译源代码的时候，如果编译出错的时候，会报 出在那个源文件的哪一行出现了错误，我们可以通过#line指令控制显示的文件的名称， 即filename部分，另外，错误出现的行号可以被设置成基于某个初始行号的，例如我们设 置linenumber为100，显示的出错行号，就是在100+实际的出错行号。 错误指令： #error something， 预处理器遇到这个宏，就表示遇到了错误，后续的编译过程就不会 被执行了。 源文件包含或者头文件包含： #include，注意有两种形式#include \u0026lt;header\u0026gt;会在标准库中寻找对应的头文件实现， #include \u0026quot;header\u0026quot;会首先在当前目录中寻找其实现，如果找不到再到标准库中寻找其实 现。有些时候允许我们设置include这个参数，让编译器自动到对应的目录中按照顺序检 索头文件，如果这么做的话，那么不管是不是c++标准库的实现还是用户自己的实现还是 其他第三方提供的库，使用#include \u0026quot;hedaer\u0026quot;或者#include \u0026lt;header\u0026gt;都是可以的。 pragma指令: #pragam,该指令用于向编译器传递多种多样的控制选项，通常这些选项是与使用的平台和 编译器相关的，需要我们自己查看使用的平台、编译器手册以便确定可以传递的参数。 预定义宏： __LINE__：当前代码行的行编号； __FILE__：当前代码行所在源文件的名称； __DATE__：当前系统日期； __TIME__：当前系统时间； __cplusplus：当前编译器支持的c++版本； 还有其他的一些编译器里面可选实现的宏定义选项，这里就布列出了。 c++里面的输入输出，这些没有什么特别之处，用到的时候，可以查看相关手册。 ============================================================================= /* vim: set ft=text: */  "}),a.add({id:522,href:"/tags/programming/",title:"programming",description:"",content:""}),a.add({id:523,href:"/blog/2014-06-01-unix%E7%8E%AF%E5%A2%83%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B/",title:"Unix环境高级编程",description:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是Unix环境高级编程里的一些知识要点。\n# Advanced Programming in Unix Environment ############################################################################ Mon Jun 9 09:22:41 CST 2014 ############################################################################ M1 Unix基础知识 1. man man 1)user commands 2)system calls 3)c library functions 4)devices and special files 5)file formats and conventions 6)games 7)miscellanea 8)system admistration tools and daemons 2. c return values 1)return 0, 正常结束 2)return 1-255，表示错误代码 3. 工作目录 char *getcwd(char *buf, size_t size); int chdir(char *path); 4. libc与glibc的关系 libc是泛指c库，glibc是gnu组织对libc的一种实现，是unix、linux的根基，微软也有自 己对libc的实现，叫msvcrt。 5. read system call return 0, 表示到达了文件的结尾。 6.",content:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是Unix环境高级编程里的一些知识要点。\n# Advanced Programming in Unix Environment ############################################################################ Mon Jun 9 09:22:41 CST 2014 ############################################################################ M1 Unix基础知识 1. man man 1)user commands 2)system calls 3)c library functions 4)devices and special files 5)file formats and conventions 6)games 7)miscellanea 8)system admistration tools and daemons 2. c return values 1)return 0, 正常结束 2)return 1-255，表示错误代码 3. 工作目录 char *getcwd(char *buf, size_t size); int chdir(char *path); 4. libc与glibc的关系 libc是泛指c库，glibc是gnu组织对libc的一种实现，是unix、linux的根基，微软也有自 己对libc的实现，叫msvcrt。 5. read system call return 0, 表示到达了文件的结尾。 6. Ctrl+D，默认的文件结束字符 ctrl+c，中断键 ctrl+\\，退出键 7. fork，执行一次，返回两次，对父进程返回子进程的进程id，对子进程返回0 8. 出错处理和出错恢复 errno 当unix函数出错时，常常返回一个负值，同时将整形变量errno设置为含有附加信息的一 个值，例如open调用失败返回-1，对应的有大约15中不同的errno值。 errno.h中定义了errno以及可以赋予它的各种常量，这些常量都以字母E开头。 举个例子： E2BIG：参数列表太长 EAGAIN：资源临时不可获取 EACCESS：权限不够，访问被拒绝 EBADF：无效文件描述符 EBUSY：设备忙或资源忙 ECANCELED：操作被取消 ECHILD：没有子进程 EEXIST：文件已经存在 EFAULT：无效地址 EFBIG：文件尺寸过大 EINTR：中断函数调用 EIO：IO错误 ... char *strerror(int errno); void perror(char *msg); 对于资源相关的非致命性错误，一般恢复动作是延迟一些时间，然后再试 9. 支持线程的环境中，需要使用局部errno，避免线程间的相互干扰 10. 为什么要将用户名、组名映射为id呢？ 1）如果使用全场ascii登录名和组名，则需要更多的磁盘空间进行存储； 2）在查验权限期间，比较字符串较之比较整形更消耗时间 11. 度量一个进程的执行时间： 时钟时间、用户cpu时间、系统cpu时间，time命令 12. 系统调用和库函数 1)从实现者的角度来看，两者的实现有着重大的不同，通常库函数是在系统调用之上建立起 来的； 2)从用户的角度来看，两者并没有明显的区别； 通常，我们可以替换库函数，但是不能或者很难替换系统调用； ############################################################################ M2 Unix标准化 1. 1)ISO C, (ANSI在ISO中代表美国的利益），按照改标准定义的头文件，将iso c库分成24 个区 2)IEEE POSIX，添加来pthreads（POSIX线程）、更多的实时接口、事件跟踪方面的扩展 3)Single Unix Specification(SUS)，是POSIX的超集，在POSIX基础上，定义来一些附加 的接口，相应的系统接口全集被称为X/Open系统接口(X/Open System Interface, XSI) ISO-\u0026gt;POSIX-\u0026gt;XSI 只有遵循XSI的实现，才能称为是Unix系统 2. 限制 Unix定义了很多幻数和常量，不同的实现定义的值可能不一样，为了增加可移植性，需要 解决这些问题，为此提供了如下三种限制： 1)编译时限制（头文件） 编译时需要确定的幻数和常量的值，可以在头文件中定义； 2)不与文件或目录相关联的运行时限制，可以通过sysconf函数获取； 3)与文件或目录相关链的运行时限制，可以通过pathconf或者fpathconf函数获取； 1）iso c定义的限制都是编译时限制，例如头文件limits.h中定义的常量； 2）posix和xsi定义的限制既有编译时限制，也有运行时限制； ############################################################################ M3 文件I/O 1. 不带缓冲的IO，指的是每个read、write操作都对应内核中的一次系统调用 2.将标准输入、输出、错误输出分别用文件描述符1、2、3来引用，是shell的惯例，与内 核没有关系。 一个进程可以打开的文件描述符的范围是0～OPEN_MAX。 3. lseek，返回文件当前的偏移量，可以是负值，所以再测试lseek是否失败的时候，不 能判断是否小于0，而应判断是否等于-1；lseek定位时指定的偏移量可以大于文件长度， 这时会在文件中产生空洞; 产生的空洞读为\\0，可以在程序中进行处理，将\\0去掉，即将空洞从文件中删除。 4. IO效率，建议缓冲区长度采用4096字节，此时消耗的系统cpu时间最小，用户cpu时间 、时钟时间也比较小4. 5. 内核用于所有IO的数据结构 1)进程表项中存储着打开的文件描述符列表，每个文件描述符表项包含文件描述符以及指 向文件表项的指针； 2)文件表，在文件表中，内核为所有打开的文件增加一个表项。其实进程每调用一次open ，就会在文件表中增加一个文件表项；dup、dup2只是复制文件描述符，内核不会创建新 的文件表项； 每个文件表项，包含文件状态标志、当前文件的偏移量以及指向v节点表项的v节点指针 3)v节点表，每个打开的文件，内核都在v节点表中创建一个v节点表项，v节点表项包含了 i节点信息（索引节点信息）以及当前文件长度； 每个打开的磁盘上的文件，只对应一个v节点表项 6. 因为对文件的io操作，通常是采用的建议性锁机制，多个进程读写同一个文件时，可 能在读写时产生冲突， pread、pwrite可以将定位和读写封装为一个原子性操作，可以解 决这个问题；当然如果对文件操作施加强制性锁，不用pread、pwrite也是可以的 7. sync，fsync，fdatasync 平时我们说的不带缓冲的io，指的是每次read、write都是一个系统调用，然后进入内核 进行操作。这里需要注意的是，并不是说内核在处理io相关的操作的时候，就没有缓冲。 为了减少磁盘读写次数，内核总是使用了缓冲机制的，只不过用户通过不带缓冲的io进行 访问时，会进入内核进行操作而已。 例如通过write写一个文件，写入的数据内核不会立即将其更新到磁盘上，而是将其放入 一个缓冲区中，等待缓冲区满时，在将其排入输出队列更新到磁盘上，这样做的优点是减 少了写磁盘的次数，提高了效率；这样做的缺点是，延长了磁盘文件的更新时间，如果发 生某种意外，可能会造成更新数据的丢失； 为了使得内核缓冲区中的数据与磁盘上的数据保持一致，提供了三个函数 sync,fsync,fdatasync，对于普通用户来讲，fsync应该是用的比较多的吧。 8. fcntl函数，可以更改已打开文件的性质。 9. 打开文件描述符/dev/fd/N等效于复制文件描述符N ############################################################################ M4 文件和目录 1. stat结构体中的st_mode成员，对其进行测试，判断文件类型，判断的时候使用如下宏： S_ISREG(st_mode)：普通文件 S_ISDIR(st_mode)：目录文件 S_ISCHR(st_mode)：字符设备文件 S_ISBLK(st_mode)：块设备文件 S_ISFIFO(st_mode)：fifo，用于进程间通信，有时也称其为有名管道（mkfifo创建有名 管道，pipe创建无名管道） S_ISLNK(st_mode)：符号链接文件（非符号链接文件的硬链接数至少为1） S_ISSOCK(st_mode)：socket文件，用于网络间的进程间通信 2. shell命令过长，通过符号“\\”来段行 3. stat,fstat,lstat stat函数不会观察到符号链接，观察符号链接，应该使用lstat函数 4. 与一个进程相关联的ID有6个或者更多 1)实际用户ID/实际组ID：（标识进程实际上是谁创建的） 2)有效用户ID/有效组ID/附加组ID：（用于进程的文件访问权限检查） 3)保存的设置用户ID/保存的设置组ID：（exec从有效用户ID复制得到的） 使用宏S_ISUID和S_ISGID对st_mode进行测试，判断有没有对设置用户ID位/设置组ID位进 行设置, 例如S_ISUID \u0026amp; st.st_mode。 ```c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int main(int argc, char *argv[]) { printf(\u0026quot;euid is: %d\\n\u0026quot;, (int)geteuid()); printf(\u0026quot;uid is: %d\\n\u0026quot;, (int)getuid()); return 0; }  测试uid，euid\nkn创建sid程序，以kn执行：euid:500,uid:500 加sudo执行：euid:0,uid:0 sudo chown root:root sid kn执行sid：euid:0,uid:0 sudo chmod u+s sid kn执行sid：euid:0,uid:500\n最后一次kn执行sid，shell执行过程： shell接收到./sid命令； shell fork创建子shell进程； 子shell进程检测sid的文件访问权限，通过测试宏S_ISUID，发现文件sid设置了设置用户 ID位，该文件的属主为root，exec函数将设置进程的有效用户ID为0，并复制有效用户ID 到保存的设置用户ID，然后执行sid程序，这样sid执行时输出的有效用户ID为0，实际用 户 ID为500。\n保存的设置用户ID用于在exec执行结束之后恢复原来的有效用户ID。\n对，就这么理解！！！！ passwd的权限就是rwsr-xr-x，也是通过设置用户ID来让普通用户完成对/etc/passwd和 /etc/shadow访问的\ngetuid,geteuid只能获取当前实际用户ID和有效用户ID，不能获取保存的设置用户ID。\n其实这些ID里面最重要的就是：实际用户id（getuid）和有效用户id（geteuid）。当程 序文件本身通过chmod被设置了设置用户ID位的时候，在通过shell执行的时候， shell fork后通过exec执行该程序，exec不会创建新的进程，只是将程序的代码、栈、堆等替换 当前进程的内容，在执行前，也将当前进程的有效用户ID设置为程序文件属主的ID ，并 将旧的有效用户ID复制到保存的设置用户ID。\n umask 创建文件模式屏蔽子 mode \u0026amp; ~mask，为创建文件的实际模式\n  文件系统 1)一个磁盘可以划分为多个分区 2)每个分区可以单独设置文件文件系统类型 3)文件系统一般包括：自举块、超级块、很多柱面组（柱面组0，柱面组1, \u0026hellip;，柱面组n） 4)每一个柱面组包括：超级块副本、配置信息、i节点图、块位图、很多i节点、很多数据块 5)i节点和数据块是非常重要的，数据块根据存储内容的不同，可以细分为数据块和目录 块，其中数据块中存放的是文件的内容，目录块中存放的是目录下面文件的名字以及该文 件对应的i节点编号； 目录块中，每个文件占有一个目录项，通过目录项中的i节点编号，就可以访问对应的i节 点，从i节点中就可以读取文件系统中指向存放文件内容的数据块的指针的值，通过这些 指向数据块的指针的值，就可以访问文件系统上的数据块，读取文件的内容。\n  1)当创建一个硬链接文件时，只是在所处的目录下面创建一个目录项，目录项中存储的只是 硬链接文件的名称以及i节点编号。由于每个文件系统对文件系统内的i节点单独进行编号 ，所以硬链接不能够跨越文件系统创建。 2)i节点中都存储着文件的硬链接计数信息，当硬链接计数减为0时，文件才可以被删除，这 就是为什么删除文件的函数是unlink而不是delete的原因。 3)当在同一个文件系统下面进行mv操作时，文件对应的数据块并没有做任何改变，文件对应 的i节点也没有任何改变，系统所做的工作，只是在目标目录所对应的目录块下面创建一 个新的目录项，将目录项中的i节点编号设置为源文件所对应的i节点的编号。\n 符号链接、硬链接都可能造成循环，例如在一个目录a下面创建一个指向a的链接b，当 我们递归便利目录a的时候，就永远无法结束，因为会发生这样的过程a-\u0026gt;b-\u0026gt;a，造成循环 ，递归永远结束。 1)假如b是一个符号链接，这中循环容易消除，因为unlink不跟随符号链接，所以很容易把b给删除； 2)假如b是一个硬链接，那么就不容易删除，因为b指向一个目录，由于硬链接的实现方面 的原因，b的链接计数\u0026gt;1，无法删除，无法消除循环，所以不允许创建指向目录的硬链接 ，即便是root用户也不行。\n  symlin函数创建符号链接，由于open函数跟随符号链接，所以想要打开符号链接本身 的话，就不能使用open函数，可以使用readlink函数来实现。\n  文件的时间 stat结构体中： 1)st_atime：文件数据的最后访问时间（访问数据块） 2)st_mtime：文件数据的最后修改时间（修改数据块） 3)st_ctime：i节点状态的最后更改时间（修改i节点）\n  utime函数可以对1）2）进行修改，不能修改3）的内容，3）的值由内核负责更新。\n mkdir, rmdir\n  read dir DIR *opendir(const char *pathname); struct dirent *readdir(DIR *dp);\n  struct dirent { ino_t d_ino;	// i-node number char d_name[NAME_MAX+1];	// null-terminated string, dir entry name };\n主设备号标识设备驱动程序；次设备号标识特定的子设备。 stat结构体中的st_dev 和st_rdev两个值表示设备号相关的信息，通过宏 major(st.st_dev)、minor(st.st_dev) 来获取设备的主次设备号； st_rdev只有字符特殊设备或者块特殊设备才有，也是通过 major和minor宏来获取其主次设备号。  ############################################################################## M5 标准IO\n  请勿将标准IO流的概念与System V的STREAMS IO系统相混淆。\n  标准IO流可以处理单字节、多字节字符集，但是要设置正确的“流的定向”，因为流的 定向决定了所读、写的字符是单字节的还是多字节的。\n  如果打开文件、创建流后，没有设置流定向： 调用了多字节的函数，则流被定向成多字节的； 调用来单子节的函数，则流被定向成单字节的；\n获取、设置流定向： fwide函数 清除流的定向： freopen\n STDIN_FILENO\\STDOUT_FILENO\\STDERR_FILENO，这是文件的描述符(int)； stdin\\stdout\\stderr是文件指针(FILE *);\n  标准IO流提供的缓冲方式：全缓冲、行缓冲、不带缓冲，很多系统默认采用下列类型 的缓冲： 1)标准出错是不带缓冲的，这样就可以使得错误信息尽快输出 2)如果涉及终端设备的其他流，则是行缓冲的；其他的，为全缓冲的\n  setbuf，setvbuf： 通过上述两个函数可以指定标准IO缓冲的类型。\n格式化输入的时候，scanf(\u0026quot;%d\u0026quot;,\u0026amp;num);希望读一个int数赋值给num，这个时候号会 匹配int数前面的字符，但是不会将其存入num变量中。  ############################################################################\nM6 系统数据文件和信息\n1)口令文件/etc/passwd 2)影子文件/etc/shadow，其中用户的登录密码是单向加密的，不能够从/etc/shadow中猜 解出用户的密码; 3)组文件 4)附加组ID 5)登录账户记录，utmp文件记录当前登录进系统的用户；wtmp文件跟踪各个登录和注销事 件。 6)系统标识\n##########################################################################\nM7 进程环境\n1)c程序启动、退出示意图，P180 内核执行c程序前，首先执行一个特殊的启动例程，，该启动例程可以获取环境表等信息 ，然后启动例程调用exec，执行c程序，这是内核执行c程序的唯一方法。c程序执行过程 中，c程序终止的方法有这么几种： 正常终止的情况： a.从main返回（执行结束），返回到启动例程后，启动例程立即调用exit方 法，例如exit(main); b.从main中调用其他exit、_exit、_Exit退出（调用return等效于调用exit） c.从main中调用其他函数，其他函数中调用exit、_exit、_Exit退出 d.c程序最后一个线程从其启动例程返回 e.c程序最后一个线程调用pthread_exit 异常终止的情况： a.调用abort b.接收到一个信号并终止 c.最后一个线程对取消请求作出响应（pthread_cancel)\n调用exit会先调用atexit注册的函数（执行退出处理程序的顺序与注册的顺序相反，因为 这些函数指针是存放在栈中的），然后关闭所有打开的流，然后进入内核； 调用_exit或_Exit直接进入内核；\n2)echo $?打印上一条命令的返回状态\n3)jmp_buf类型、setjmp、longjmp实现非局部goto，goto只能够实现函数内跳转，而非局 部goto可以在函数之间进行跳转，跳转时越过的函数栈帧将直接被丢弃。\n关于跳转之后的变量的值是否回滚，针对总结如下： a.全局变量、静态变量在longjmp的时候值保持不变，即不会回滚；不受编译优化的影响； b.自动变量、寄存器变量、易失(volatile)变量，如果未进行编译器的优化，则其值不回 滚，如果进行全部优化，则回滚；\n############################################################################\nM8 进程控制\n1)PID为0的进程通常是调度进程swapper，是内核的一部分，并不执行任何磁盘上的程序 ，因此也被称为系统进程；PID为1的进程是init，它不是内核进程，是一个普通的用户进 程，只不过以root权限运行；PID为2的是页守护进程(pagedaemon)。\n2)fork执行一次，返回两次，子进程复制父进程的数据空间、堆、栈的副本，父子进程共 享程序正文段； 在子进程中创建父进程的副本的时候，遵循写时复制。\n文件共享，父进程打开的文件描述符也被复制到子进程中，例如无名管道pipe的创建就是 利用了这个道理。\nfork失败的原因： a.系统中已经有了太多的进程； b.该实际用户ID的进程总数超过了系统限制；\n3)wait/waitpid a.如果子进程已经终止，但是父进程还没有终止，并且父进程没有对子进程调用wait或者 waitpid，那么子进程就会变成僵死进程，通过ps aux命令可以查看到其状态为 Z+; b.如果子进程的父进程已经终止，那么子进程将由init进程领养，init进程对每个终止的 子进程调用waitpid，因此可以保证不会使领养进程变成僵死进程； c.书上说的通过两次fork避免产生僵死进程（P183）有点牵强，不过也是利用来init进程 领养这个原理而已。\n4)竞争条件的解决 a.通过信号实现进程间通信 b.通过各种其他进程间通信机制\n5)exec函数的执行会用新程序的正文段、堆、栈替换当前进程中的对应部分，但是并没有 创建新的进程，因此进程的ID不会发生改变 6个exec函数的转换关系P191\n6)更改用户ID和组ID\n时刻铭记，有效用户ID、有效组ID、附加ID，用于文件访问权限检查！！！\n有两种方式达到这个目的：a.通过chmod u+s,chmod g+s设置程序文件本身的设置用户ID 位、设置组ID位；b.在程序代码中通过setuid、setgid函数设置设置用户ID位、设置组ID 位；\n注意两种方式的要点： a. exec函数不能修改实际用户ID，可能修改有效用户ID，每次都会修改保存的设置用户ID； exec函数根据程序文件本身有没有通过chmod添加设置用户ID位、设置组ID位，决定是 否将程序文件的属主ID设置为调用进程的有效用户ID。如果程序文件被设置了设置用户ID 位，exec将程序文件的属主ID设置为进程的有效用户ID，然后将该有效用户ID复制到保存 的设置用户ID，然后执行该程序；如果程序文件本身没有设置设置用户ID 位，那么有效 用户ID位就是实际用户ID位，那么exec 函数只是将有效用户ID复制到保存的设置用户ID ；\n保存的设置用户ID用于exec返回前，恢复进程的有效用户ID； b.setuid类似于在程序的运行过程中调用chmod一样，修改进程的有效用户ID； 如果进程具有root权限，调用setuid(uid)时会将实际用户id、有效用户id、保存的设置 用户id全部设置为uid；但是这样调用setuid之后，root权限一旦丢失，无法再通过 setuid(0)将权限恢复成root权限，可以用seteuid代替setuid。 如果进程没有root权限，是普通用户权限，仅当setuid(uid)中的uid等于实际用户id时或 者等于保存的设置用户id时，才能够将有效用户id设置成uid，但是实际用户id和保存的 设置用户id不变。\n详情请参见P239\n  setuid(uid): set the effective user id of calling process seteuid(uid): set the effective user id of calling process 这两个函数的功能不容易区分，都是设置有效用户id，区别何在呢? 1)如果非root权限运行的进程调用这两个函数，那么没有什么区别，当uid等于实际用户 id或者保存的设置用户id时才可以修改有效用户id为uid，但是实际用户id和保存的设置 用户id不会改变 2)如果是以root权限运行的进程调用这两个函数，就有区别了。如果进程调用 setuid(uid)放弃了root权限，当希望再次恢复root权限运行时，setuid(0)不会调用成功 ，无法恢复root权限；但是如果是通过调用seteuid(uid)放弃root权限，以后希望恢复 root权限运行时，就可以通过seteuid(0)来恢复root权限；\n可以参看例子P194 man的工作原理，也顺便了解保存的设置用户ID用来恢复有效用户ID的 原理。所有的东西都是围绕有效用户ID转的。\n进程会计  ############################################################################\nM9 进程关系\n1)进程组 进程组，是一个或者多个进程的集合。通常，进程组中的进程与同一作业相关联。 进程组存在组长进程，组长进程的进程id与进程组的id相同，组长进程可以创建一个进程 组; setpgid(pid_t pid, pid_t pgid)既可以改变进程的进程组id，也可以创建一个新的进程 组，另外setsid函数也可以创建一个新的进程组；\n2)会话 会话，是一个或者多个进程组的集合。 通常管道线可以用来将前后的几个进程编入一个进程组中，例如proc1 | proc2 \u0026amp;将创建 一个包含进程proc1和proc2的进程组，并且是后台进程组； 进程组中的非组长进程可以通过调用pid_t setsid(void)创建一个新的会话；创建新的会 话之后，调用进程成为会话首进程，并且成为新进程组的组长；调用进程将失去对控制终 端的控制，但是会话首进程仍然可以通过open调用打开控制终端，只有会话非首进程才可 以彻底失去对控制终端的控制。 鉴于此，可以通过创建会话非首进程，用它来作为daemon进程。\n会话，通常包含前台进程组和后台进程组，终端产生的终端、退出信号将传递给前台进程 组中的所有进程，调制解调器的挂断信号，则会发送给会话的控制进程，就是会话的首进 程。\n3)作业控制 一个作业，只是几个进程的集合，通常是用管道线连接起来的几个进程，也就是说，一个 作业基本上是对应着一个进程组。\n作业既可以在前台运行，也可以在后台运行。在后台作业时，shell赋予它一个作业标识。\n4)shell执行程序的方式 ps | cat1 | cat2 请参见P227，注意管道线连接的多个进程中的最后一个进程才是子shell要通过exec执行 的程序。 大体上执行流程如下： shell执行fork，创建子进程，我们称为子shell； 子shell中创建两个管道，第一个是pipe_ps_cat1，第二个是pipe_cat1_cat2； 子shellfork两次，分别称为子子shell1，子子shell2； 子子shell1中将标准输出重定向至pipe_ps_cat1的写端，子子shell2将标准输入重定向至管道的读段； 子子shell2将标准输出重定向至管道pipe_cat1_cat2的写端； 子shell将标准输入重定向至管道pipe_cat1_cat2的读段，并调用exec执行ps；\n############################################################################\nM10 信号 1)信号是软件中断，信号提供了一种处理异步事件的方法 2)头文件signal.h中定义了信号，信号是正整数 3)不存在编号为0的信号，kill函数对信号编号0有特殊的应用 4)信号是随机出现的，程序必须告诉内核，在信号到达时，执行下列3种操作中的一种： 忽略、采用默认动作、用户自定义的信号捕捉函数 5)signal函数 学习signal函数的时候，学习sigaction函数，这样对信号的理解和学习更好。\n在最早的signal实现中，程序接收到信号之后，准备调用信号处理函数之前，就把对信号 的处理方式恢复为 SIG_DFL，并且在调用信号处理函数的过程中并不屏蔽这个信号。但是 如果想继续以当前处理方式对信号进行处理时，不得不在进入信号处理函数时，立即调用 signal函数重新对信号注册当前信号函数，但是由于没有屏蔽该信号，加入在成功调用 signal之前信号到达了，那么就会执行了默认的处理动作，例如SIGINT的默认动作是退出 ，之前的信号处理函数还没有执行，程序就已经退出了。 综合这两点，1)执行信号处理程序时，信号没有被屏蔽2)signal将信号处理方式重置为默 认，就使得这个信号处理不可靠。\n6)解决不可靠信号的方法就是，通过signaction函数，由于可以通过信号屏蔽字屏蔽信号 ，并且不会自动将对信号的处理方式重置为默认，因此可以实现可靠的信号处理。\n现在的signal函数，一般都是在sigaction函数的基础上实现的，因此可以保证对信号的 可靠处理。对于简单的信号处理，signal完全已经够用了，如果需要更复杂的信号处理， 那就还是要通过sigaction来实现。\n############################################################################ /* vim: set ft=text: */\n "}),a.add({id:524,href:"/tags/network/",title:"network",description:"",content:""}),a.add({id:525,href:"/tags/security/",title:"security",description:"",content:""}),a.add({id:526,href:"/blog/2013-09-30-%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8tcpipnetworksecurity/",title:"TCP/IP网络安全篇",description:"《TCP/IP 网络安全篇》，作者是日本的寺田真敏 萱岛 信。\n感谢作者理论与实践结合的教学方式，简单地介绍了网络安全的方方面面，让 我学起来也是很有兴趣，真诚地向寺田真敏先生道一声谢谢。\n下面是我对本书学习过程中的一个总结，难免有理解偏差之处，还需在以后的 学习实践过程中，进一步体会、纠正。\n 1 TCP/IP的基础知识 # 1.1 TCP/IP与因特网 # OSI 7-layer model\nHost layers:	applications	Message presentation session -------------------------- transport	Message segment -------------------------- media layer:	network	packet/datagram -------------------------- data link	frame -------------------------- physical	bit  用于分组交换的设备，IMP（Interface Message Processor）接口报文处理机 的第一号机被设计制成。\nTCP/IP协议，是以tcp协议和ip协议为中心，构成的协议族的总称。 TCP/IP协议，从最底层开始，是由网络接口层、网络层、传输层、应用层构成。 像这样的构成层次，可以使开发工作形成模块式开发。\n1.2 IP # IP地址与网络分类 # IP数据包的数据最大长度为65535字节。\nIP地址由网络号与主机号组成。可以类对网络进行划分，根据网络的规模，从 A类到C类，也存在用于多播通信的D类，其他用于实验的地址还有E类。\n但是在目前，为了有效利用已经濒临枯竭的IPv4地址，采用了不依赖于类的IP 地址分配方法——CIDR（Classless Inter Domain Routing，无类域间路由）。 而且为了解决IPv4地址的资源枯竭问题，也开发了具有128位长度的IPv6。\n无类域间路由CIDR # 无类域间路由中关键的就是子网掩码。子网掩码，是为了改变网络号与主机号的分界位置而采用的方法，如192.168.0.0/24，表示网络号24位，主机号8位，这个子网掩码设置就比之前分类的方式要灵活多了。\n特殊的IP地址: 1)本地环路地址:linux下常见的回环接口lo，地址127.0.0.1，其ip地址可以 根据需要任意设定，也称为localhost。常被用于同一计算机上的通信。 2)广播地址:主机号字段全部为1。 3)多播地址:224.0.0.0～239.255.255.255,常被用于特定工作组中的通信。 4)私有IP地址:限定于内部网络使用而分配的地址，rfc1597中，建议使用以下 的地址段: A类中，10.",content:"《TCP/IP 网络安全篇》，作者是日本的寺田真敏 萱岛 信。\n感谢作者理论与实践结合的教学方式，简单地介绍了网络安全的方方面面，让 我学起来也是很有兴趣，真诚地向寺田真敏先生道一声谢谢。\n下面是我对本书学习过程中的一个总结，难免有理解偏差之处，还需在以后的 学习实践过程中，进一步体会、纠正。\n 1 TCP/IP的基础知识 # 1.1 TCP/IP与因特网 # OSI 7-layer model\nHost layers:	applications	Message presentation session -------------------------- transport	Message segment -------------------------- media layer:	network	packet/datagram -------------------------- data link	frame -------------------------- physical	bit  用于分组交换的设备，IMP（Interface Message Processor）接口报文处理机 的第一号机被设计制成。\nTCP/IP协议，是以tcp协议和ip协议为中心，构成的协议族的总称。 TCP/IP协议，从最底层开始，是由网络接口层、网络层、传输层、应用层构成。 像这样的构成层次，可以使开发工作形成模块式开发。\n1.2 IP # IP地址与网络分类 # IP数据包的数据最大长度为65535字节。\nIP地址由网络号与主机号组成。可以类对网络进行划分，根据网络的规模，从 A类到C类，也存在用于多播通信的D类，其他用于实验的地址还有E类。\n但是在目前，为了有效利用已经濒临枯竭的IPv4地址，采用了不依赖于类的IP 地址分配方法——CIDR（Classless Inter Domain Routing，无类域间路由）。 而且为了解决IPv4地址的资源枯竭问题，也开发了具有128位长度的IPv6。\n无类域间路由CIDR # 无类域间路由中关键的就是子网掩码。子网掩码，是为了改变网络号与主机号的分界位置而采用的方法，如192.168.0.0/24，表示网络号24位，主机号8位，这个子网掩码设置就比之前分类的方式要灵活多了。\n特殊的IP地址: 1)本地环路地址:linux下常见的回环接口lo，地址127.0.0.1，其ip地址可以 根据需要任意设定，也称为localhost。常被用于同一计算机上的通信。 2)广播地址:主机号字段全部为1。 3)多播地址:224.0.0.0～239.255.255.255,常被用于特定工作组中的通信。 4)私有IP地址:限定于内部网络使用而分配的地址，rfc1597中，建议使用以下 的地址段: A类中，10.0.0.0～10.255.255.255 B类中，172.16.0.0～172.31.255.255 C类中，192.168.0.0～192.168.255.255 与私有IP地址相对，对于那些只使用于因特网上的IP地址，我们称为全局IP地址。\n注意IP数据包的Header，其中与分片有关的标识、标志、片偏移，其中的片偏移 的值若为N，表示其承载数据的初始字节在原始未分片的数据包中的偏移量为64*N位。 同时，在本科学习的时候，老师几乎对选项字段没有介绍，其实，选项字段还是 非常重要的，比如选项9可以用来源路由，选项7可以记录路由路径等。\n路由控制: IP数据包的传输，有两种方式。如果发送端与接收端位于同一网络上时，则可以 直接将IP数据包传送到作为接收端的主机上，这种传输方式称为直接传输；另一 种方式，如果接收端处于通过路由器等中继装置连接的其他网络上，需要通过中 继装置传输数据，这种传输方式称为间接传输。\n间接传输方式下，在经过怎样的路径将数据包传送到目的网络及主机方面， 有两种方式:一是通过指定路径来传送数据包（源路由）；另一种是在路由器中 预先配置路由表。\nQ:关于路由时Metric与Hop的计算？ 值得注意的是，跳数越少，不一定应答性能就好。\n静态路由:手工配置路由表。 动态路由:通过在路由器上运行某些选路协议，动态配置更新路由表\n路由协议:路由协议包括在网络与网关管理上群组化的AS中使用的IGPs（Interior Gateway Protocols，内部网关协议）与EGPs（Exterior Gateway Protocols）。\n IGPs:有RIP和OSPF，主要是这两种。 EGPs:主要有BGP。  IP源路由，包括两种，一个是从源到目的地指定了部分路由路径的松散源路由， 一个是指定了完全的路由路径的严格源路由。 松散源路由中指定的路由，可以是不连续的，比如说从源到端如果通过路径a-\u0026gt;b -\u0026gt;c-\u0026gt;d-\u0026gt;e可达的话，可以只选择b,d作为源路由中的路由。书上没有提，不过我 觉得松散源路由的话，应该是这样的。\nIP的错误处理，离不开ICMP。\nIP与数据链路 为了IP数据包通过网络接口层，在相邻层之间进行数据传输，必须考虑到数据链 路层级的地址体系以及最大传输单元MTU。 链路层，或者说网络接口层，通过MAC（介质访问控制）地址进行数据帧的转发， 查MAC地址需要用到ARP协议。ARP查询在链路层被触发，ARP查询是通过子网内广 播的方式进行查询，理论上只能为同一子网内的主机提供ARP查询服务，但是其 实不然，如果在两个处于不是同一网段的主机A，B上，在A，B中通过添加路由， 使A，B间可以直接相互转发IP数据包，比如A的IP地址为192.168.0.1/24，而B的 IP地址位:10.0.0.1/24。\n在A中添加路由: route add -host 10.0.0.1/24 gw 192.168.0.1 metric 1 dev eth0 在B中添加路由: route add -host 192.168.0.1/24 gw 10.0.0.1 metric 1 dev eth0\n然后用一根双绞线将A，B各自的eth0适配器连接起来，那么这样的话，如果A要 给B发IP数据包的话，A首先检查路由表发现有一条路由表项，该表项指示应该将 数据包从eth0接口转发出去，那么理所当然地，到达链路层的时候，ARP请求会 通过设备eth0发出去，当B收到ARP请求之后，发现询问的正是自己的MAC地址， 然后它就把自己的MAC地址发给了A，A然后将IP数据包封装形成的数据帧发送给B， B收到后拆掉链路层Header，提交给网络层。 在源路由的过程中，通过路由表查找下一跳路由器，找到之后，通过对应的接口 发送出ARP请求，也是相同的工作方式。\nIP数据包的分割，发生在网络层，是由于链路层的MTU决定的。而链路层帧的有 效载荷的限制，不只是限制最大尺寸MTU，其实，对于最小尺寸也有限制，为什 么要限制最小尺寸呢？这在研究生计算机网络课程上提到过，有线以太网上的话 ，运行CSMA/CD协议，为了能够使发送方成功检测出碰撞，通过一系列计算得出 了这个最小值。\nQ:在网络核心的话，这个限制存在吗？ 在用gns模拟器进行模拟的时候发现，路由器与局域网互联的时候是通过4E模块， 表示4个 以太网接口；而在路由器之间进行互联的时候，用的模块是4T，表示4 个串口。完全不一样 的接口模块，我觉得4E的口连接的链路上是有最小帧长度 限制的，而4T的口连接的链路上不会有这种限制。而且，路由器之间不处于以太 网中，不会运行CSMA/CD,加上最小帧长度限制也没有什么意义。\nIP数据包分片的组装，在目的接收方进行组装，这个目的接收方可以使目的主机， 也可以是路由器，比如源路由的时候，源路由路径比较长，就可能会引起数据包 的分片，但是为了能够正确地找出下一跳的路由地址，必须对分片后的数据包进 行重组。\nIP地址与主机名 DNS记录的缓存,在ubuntu 12.04 lts中是通过dnsmasq来实现的,并且dnsmasq被内 置进了network-manager中,并且随着network-manager的启动而启动,默认地, dnsmasq的缓存机制被禁用了,从/var/log/syslog中可以找到相应的证据.\nDNS查询,可以通过dig或者nslookup来实现.\n dig hostname [option list]  +short +nocomments	+comments +noauthority	+authority +noaddtional	+additional +nostats	+stats +noanswer	+answer +noquestion	+question +noall\n\u0026ldquo;dig hostname +nocomments +noauthority +noaddtional +nostats +noquestion\u0026rdquo; is equivalent to \u0026ldquo;dig hostname +noall +answer\u0026rdquo;.\n-t soa -t a -t ns -t mx -t any -t cname ??? acutally, non-existent\n-x ptr, reverse lookup for PTR record how does reverse lookup works ???\n@dnsserver to use a specified dns server for lookup example: dig @202.12.27.33 redhat.com -t ns +noall +answer 202.12.27.33 is one of the 13 root domain name servers\n-f to use data file to query several hostnames example: dig -f filename -t ns +noall +answer\nyou can also query several hostnames in one command line: dig hostname1 -t type1 [op-list] hostname2 -t type2 [op-list] example: dig redhat.com -t ns +noall +answer centos.org -t a +answer\n~/.digrc add options within this file to set the default query options.\nexample: append text \u0026lsquo;+noall +answer\u0026rsquo; within file .digrc, then next time when you start dig, options \u0026lsquo;+noall\u0026rsquo; and \u0026lsquo;+answer\u0026rsquo; will be auto -matically appended to the cmd option list, but these options won\u0026rsquo;t be displayed.\nnslookup, using interactive mode to lookup is very convenient.  common interactive cmds: server: specify a domain name server host : spefify a hostname that you want to lookup, usually host cmd can be neglected, i.e, you can directly type in the hostname. set q=type: set the query type, ns/a/cname/mx/ptr/soa. set q=ns, then type \u0026lsquo;.\u0026rsquo; to display all 13 root domain name servers. exit : exit programme\nDNS records\n for CNAME record:  usually we think the format of CNAME record is : || Alias Hostname | CNAME | Canonical Hostname || but actually, it may be not set as you supposed, for example, right field \u0026lsquo;Canonial Hostname\u0026rsquo; may not a canonical name but another alias hostname, this leads to so-called \u0026lsquo;alias chain\u0026rsquo; or \u0026lsquo;alias cycle\u0026rsquo;. so, you may not be able to use one single lookup through all CNAME records to find out the canonical hostname. but, among all presented alias chains, we can pick out the right side hostnames and put them together, all of them must appear in the alias chains in some order, so we can find out which of them is the canonical hostname by comparison.\nif \u0026lsquo;alias cycle\u0026rsquo; among CNAME records occurs, CNAME type query should respond an error message.\nfor PTR record:  the best option is to resolve the IP address to the Canonical Hostname.\nrfc doesn\u0026rsquo;t point out dns must implement the reverse query, it is opti -onal. if the dns receives an unsupported query request, it should res -ponded an error message.\nrfc doesn\u0026rsquo;t require we must set only one PTR record for the same one IP address. so, some people may set multiple PTR records on the same on IP address. it is not reccommended ! why ? first, if we set multiple PTR records for the same one IP address. among the multiple PTR records, several alias hostname and canonical hostname are contained. when an PTR type request comes, dns works in round-robin for load-sharing, and the PTR records matched are resorted in round-robin and then responded to your client programme. usally, the programme select the first PTR record and resolve the IP address to the hostname. if the resolved hostname is an alias hostname, when we access it, something wrong may happen if some other hosts has an same alias hostname. it leads to a problem, Hosts : IP = n : 1, it is unacceptable. so, as mentioned above, one IP should always be resolved to the canonical Hostname.\nso, dig -x, usally can resolve the IP address to the Canonical Hostname. while, nslookup -cname, can process ordinary \u0026ldquo;alias | cname | canonical\u0026rdquo; format CNAME record, \u0026lsquo;alias chain\u0026rsquo; and \u0026lsquo;alias cycle\u0026rsquo; format CNAME records to find out the Canonical Hostname.\ndig can\u0026rsquo;t directly lookup the Canonical Hostname with the Alias Hostname through CNAME type records. you have to lookup the A type record to find out the IP address, then lookup the PTR type record to find it.\nnote: one IP address should have only one PTR record. but one domain, such as 10.in_addr.arpa, can have several PTR records, because one domain, i.e, one network, can have multiple gateways.\n######################################################################\n2 网络安全的基础知识 # 2.1 因特网上的安全 # 2.1.1 网络层 # 伪造IP地址 伪造ARP 伪造路径控制信息 恶意使用源路由 利用IP/ICMP数据包的DoS攻击\n2.1.2 传输层 # 预测TCP初始序号 利用TCP/UDP数据包的DoS攻击\n2.1.3 应用层 # 搜索/扫描 DNS欺骗 窃听 攻击程序缺陷 代理服务器的非法使用 利用电子邮件进行DoS攻击 病毒 蠕虫 木马\n2.1.4 用户层 # 社交工程攻击:利用人的心理，诱使人作出某种行为，实现攻击者的目标\n2.2 安全技术概要 # 2.2.1 加密技术 # 两大密钥系统，共享密钥系统和公开密钥系统。 区别: 1)共享密钥系统，加密和解密使用同一个密钥。 2)公开密钥系统，由信息的接收方，生成一对密钥，分别称为公钥和私钥。 这一对密钥，由两种使用方式。 一种是希望他人在发送给自己数据之前对数据进行加密处理,然后只有自己可以 解密，此时，密钥对的制作者，可以将公钥发布出去，对方用公钥对发送数据 进行加密然后发送给自己，然后自己通过私钥进行解密。由于私钥只有制作者 拥有，并且通过公钥无法推测 出私钥，所以即使截获了公钥，也无法解密别人 发送来的数据。 另一种是，密钥对的制作者，希望对自己发送出去的数据进行一种签名，向信息 的接收方表明，发布此信息的人确实是自己。此时，密钥对的制作者通过私钥对 信息进行签名，然后将签名和原始数据发送给对方，对方接收后利用公钥对签名 进行处理，如果还原出的数据与收到的原始数据相同，表示发送此信息的人确实 是密钥对制作者本人，这样就提供了一种身份的识别功能。 由于签名时是利用私钥进行处理，而只有密钥对制作者本人拥有私钥，所以其他 任何人无法伪造该签名，同时制作者一旦对数据进行签名，也不可以不承认这确 实是自己的签名。\n3)共享密钥系统，加密解密，处理速度快，但是不够安全。 4)公开密钥系统，加密解密，处理速度慢，但是比共享密钥系统更安全。\n混合密钥系统: 综合共享密钥系统和公开密钥系统的优缺点，人们在网络通信过程中，通常使用 混合密钥系统。 对于通信数据的加密解密采用共享密钥系统，因为它处理速度快。而将公开密钥 系统应用于对共享密钥的加密解密，为共享密钥的安全性提供保护。 这样既利用了公开密钥系统安全性好的优势，又利用了共享密钥系统速度快的优 势。\nDES，3DES，IDEA，RC5等，这些都是共享密钥系统。 RSA等，这些是公开密钥系统。\n分组密码和流式密码: 流式密码是对数据中的每一位逐位进行加密，分组密码是根据一定的分组长度对 数据先进行分组，然后逐组进行加密。\n分组密码，逐组进行加密，也会分为两种。 一种是ECB（Electric Code Book）电子密码本方式，在用密钥对分组进行加密 之前，分组中的数据不再参加某些变化，因此，相同的明文分组加密后总是被加 密成相同的密文分组。 另一种是，CBC（Cipher Block Chaining）分组密码连接，后一个明文分组在进 行加密之前，需要与前一个明文分组加密后的密文分组进行异或运算，然后再用 密钥对其进行加密处理，这样，即使相同的明文分组，也会被加密成不同的密文 分组。\n2.2.2 访问管理技术 # 为保护电子化信息，需要一定的访问管理技术，即，不能让没有正当权限的用户， 访问计算机以及计算机中的文件，这样的技术称为访问管理技术。\n识别: 用户名或者ID 认证: 密码 授权: 对特定文件的读写执行权限\n密码认证的危险因素 1）预防在登录时泄漏密码 例如，启动了伪造的登录程序 2）穷举尝试登录 连续登录数次失败后，禁止登录； 验证码打断穷举攻击；\n利用密钥文件的认证 /etc/passwd: loginname:password:uid:gid:username:homefolder:shell password field is set to x. /etc/shadow: loginname:encryptedpassword:lastchange:\u0026hellip;\u0026hellip;.\n一次性口令: 1)挑战/回答方式 通过询问/回答的每一次改变，可以预防重放攻击。 2)时间戳方式 服务器端生成随机数，在规定的时间内要求客户端输入正确的随机数。\n采用加密技术的认证: 1）利用共享密钥的认证\n\u0026mdash;\u0026mdash;\u0026ndash; | R-b | \u0026mdash;\u0026mdash;\u0026mdash; | | \u0026lt;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; | | | | | R-a | *R-b | | | | User | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026gt; | User | | | | *R-a | | | | A | \u0026lt;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; | B | | | | |\n 这种认证方式，是挑战回答方式的一种，它利用了挑战的随机数。作为对挑战的 回答，使用双方,利用共享的密钥加密随机数，来认证能够正确解密的对方。\n首先B发起认证，发送明文随机数R-b，用户A用共享密钥进行加密，得到R-b， 同时生成随机数R-a，一并发给B，B收到后，利用共享密钥对R-b进行解密，将 解密后的明文与R-b比较，若相同，则B可以获知，A确实可以正确地加密，B认证 A的工作结束，但是A还要认证B，所以B继续用共享密钥加密R-a，得到R-a，发 给A，A收到后，用共享密钥解密，与R-a比较，若相同，则A可以获知，B确实可 以对R-b进行正确的解密，并能对R-a进行正确的加密，A认证B的工作也结束。 双方认证完成。\n2）利用公开密钥的认证\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | R-b | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash; | | \u0026lt;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | | | | | R-a | *R-b | Public-key-A | | | | User A | \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; | User B | | | | *R-a | Public-key-B | | | | Private-key-A | \u0026lt;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; | Private-key-B | | | | | | | | |\n 这种方式，也是挑战回答方式之一，它也利用了挑战的随机数。回答是利用发送 端的私有密钥加密的随机数，而将利用发送端的公开密钥进行正确解密的一方确 认为用户本人。\n首先B发送明文随机数R-b给A，A收到后，用A的私钥对R-b进行加密，连同生成的 随机数以及A的公钥发给B，B收到后，用A的公钥对*R-b进行解密，将解密后的明 文与R-b比较，若相同，B可以获知，自己确实可以正确地解密A发送的数据，然 后B用自己的私钥对R-a加密，发送给A，A用B的公钥进行解密，并与R-a比较，若 相同，表示A自己确实可以正确地解密B发送的数据。\n如果不存在第三者干扰的话，那么这里的公开密钥认证过程，B可以确认A就是A 本人，A也可以确认B就是B本人。 但是问题在哪呢？问题是B先发起向A的认证请求，这个请求有可能被第三方截获， 也就是说与B通信的对方可能并不是A。例如用户C截获了B发给A的R-b，兵通过C 自己的私钥进行加密发给B，B就无法知道C其实并非目的接收方A。 如果解决这个问题呢？公开密钥证书。通过一个认证机构来证明该公开密钥确实 是为某个人所有。比如可以通过公开密钥证书获知，C的公钥是属于C的而不是属 于A，那么B就会知道自己发送给A的数据被第三方截获了。\nCA: Certificate Authority in cryptography, a certificate authority or certification authority (CA), is an entity that issues digital certificates.The digital certificate certifies the ownership of a public key by the named subject of the certificate. This allows others (relying parties) to rely upon signatures or assertions made by the private key that corresponds to the public key that is certified. In this model of trust relationships, a CA is a trusted third party that is trusted by both the subject (owner) of the certificate and the party relying upon the certificate. CAs are characteristic of many public key infrastructure schemes.\ncommercial CAs charge to issue certificates that will automatically be trusted by most web browsers (Mozilla maintains a list of at least 57 trusted root CAs, though multiple commercial CAs or their resellers may share the same trusted root). The number of web browsers and other devices and applications that trust a particular certificate authority is referred to as ubiquity.\naside from commercial CAs, some providers issue digital certificates to the public at no cost. Large institutions or government entities may have their own CAs.\n授权 对文件的读写执行权限的授权，可执行位setuid，setgid，以及粘贴位。\n数字签名技术\n2.3 计算机反应机关 最长听到的就是CERT了。\n######################################################################\n3 非法访问技术 # 3.1 扫描与搜索 # 网络扫描，扫描网络中那些主机处于启动状态，比如使用ping命令，ping某台主 机，如果收到了响应，则表示该主机处于运行状态。\n端口扫描，对某台运行中的主机扫描其打开的端口，通过编制程序对某台主机上 从MinPortNum到MaxPortNum范围内的端口进行连接，例如connect函数，并通过 getservbyport（）函数获取指定端口号处运行的服务名称，因为某些周知端口 运行什么服务都是已经规定了的。这样就可以获知目的主机上开启了哪些服务， 然后针对这些特定的服务的漏洞展开攻击。\nping getservbyport telnet (Attack)\n3.2 窃听WireTapping # 窃听，数据包嗅探，通过对截获的数据包的分析获取某些敏感的信息。 可以使用Wireshark或者tcpdump来进行抓包.\ntcpdump: dump packets on interface\n-i :interface -X :it\u0026rsquo;s very handy -A :display data in ascii\n-w :store captured packets into file -r :read packets data from file\ntcpdump filter options: dst host src host host port tcp udp \u0026hellip;\nhow to extract the username and password or other something ? when we submit something, for example, a username, the server side will respond to the client side with status code. around the status code, there may be something which you will be intersted in.\nconvert from ascii to hex:\nhexdump -x od -x  convert from hex to ascii:\necho -e \u0026quot;\\xHH\\xHH\\xHH\\xHH\u0026quot;  convert hex to decimal:\necho $((0xaa))  3.3 数据篡改 # A checksum or hash sum is a small-size datum computed from an arbitrary block of digital data for the purpose of detecting errors that may have been introduced during its transmission or storage. The actual procedure that yields the checksum, given a data input, is called a checksum function or checksum algorithm.\nchecksum can be used to check the data\u0026rsquo;s integrity, but it can\u0026rsquo;t be used to check data\u0026rsquo;s authentication. we should use hash function to check whether data has been changed.\nif data is changed, maybe the checksum stays the same, but the hash value is largely sure to change.\n利用检验和，检测数据错误 如果检验和出错，数据一定是错的； 如果检验和正确，数据有可能是正确的，但是也有可能是错的，因为数据可以被 人为的修改，并且保证检验和不变，要想检测数据是否经过篡改，需要散列函数。 checksum tools: cksum\n利用散列函数，检测数据篡改 hash tools: \u0026lsquo;md5sum\u0026rsquo; is equivalent to \u0026lsquo;openssl dgst -md5\u0026rsquo;\n3.4 伪装Masquerade # 密码跟踪\n伪装IP地址，通过强加路由或者源路由 on samsung pc: add route info: ifconfig eth0 up ifconfig eth0 10.0.0.1/24 route add -net 192.168.1.0/24 gw 10.0.0.1 metric 1 dev eth0\non thinkpad x61: ifconfig eth0 up ifconfig eth0 192.168.1.1/24 route add -net 10.0.0.1/24 gw 192.168.1.1 metric 1 dev eth0\nThen, from either pc, you can ping the other one and get the response.\nArp, itself, works within the same subnet boundary. but it still works out of the same subnet with the help of route table. How does it works? For example, ping from samsung to thinkpad. Within the network layer, when routing, it finds a route table item: 192.168.1.0 255.255.255.0 gw 10.0.0.1 metric 1 eth0 it knows the packet should be sent out through the device \u0026lsquo;eth0\u0026rsquo;. But before sending, the target MAC must be available, so it sends out ARP request through device \u0026lsquo;eth0\u0026rsquo;, then the target responds with the ARP request.\nlinux下设置录由的方法: route -n route add -net/netmask | -host(default) \u0026hellip;/.. | .. gw \u0026hellip; metric .. device route del -net/netmask | -host(default) \u0026hellip;/.. | ..\n非法路由控制\nIP源路由 源路由的实现: 在IP Header中通过设置源路由选项9,可以在数据字段中存储要经过的指定的路 由器IP,同时会在头部字段中设置一个指针字段pointer,单位字节,用来指示当前 使用的转发代理(Forward Agent,FA,即当前源路由节点向下一个源路由节点转发 数据时,下一个源路由节点的地址)的IP数据在数据字段中的偏移量,如果当前字 段pointer字段没有超出数据字段的最大长度,则pointer=pointer+4,表示当下一 个源路由节点收到该报文时,可以根据pointer的值确定应该使用的FA. 注意松散源路由的时候,除了源路由节点之外,还有其他的路由节点,而且,源路由 节点之间也可能有其他路由节点.IP Header中pointer字段的值,只有事先指定的 源路由节点才可以对其进行修改.\n当pointer的值大于等于数据的最大长度时,\nHost-A ------------\u0026gt;-------------- Host-B |	| \\/	/\\	|	| |--- Host-C ------------ Host-A: 192.168.1.1/24 Host-B: 10.0.0.1/24 Host-C: 192.168.1.2/24  Target: To ping from Host-A to Host-B, and specify Host-C as the next hop of loosen source route.\nConfigure: in Host-A: sudo route add -net 10.0.0.0/24 gw 192.168.1.1 metric 1 dev wlan0 in Host-B: sudo route add -net 192.168.1.0/24 gw 10.0.0.1 metric 1 dev wlan0 in Host-C: sudo route add -net 10.0.0.0/24 gw 192.168.1.2 metric 1 dev wlan0\nin Host-C: enable IP source route function\ncheck the following configruation files: /proc/sys/net/ipv4/conf/wlan0/accept_source_route	default 1 /proc/sys/net/ipv4/conf/wlan0/forwarding	default 0 /proc/sys/net/ipv4/conf/all/accept_source_route	default 0 /proc/sys/net/ipv4/conf/all/forwarding	default 0 set all of them to 1 temporarily.  Test: windows: ping [-j loosenSourceRouter-list] [-k strictSourceRoute-list] Addr ping -j 192.168.1.2 10.0.0.1\nwindows下,ping -j, Loose Source Route; ping -k, Strict Source Route. linux下,ping好像不可以实现源路由. linux下: ping : send ICMP echo_request to network hosts and wait for the echo_reply. -c :count -f :flood ping -i :interval -D :time -s :packet size why 8 bytes added to the specified size ? because size of ICMP header data is 8 bytes. -b :allows ping a broadcast address\nICMP header format ???  -t :time to live,\u0026gt;=1\n关于ping的时候,ping -T tsonly IP. ping -T tsonly localhost时,是有响应的,但是将IP换成是远程IP地址时,就没 有响应了,针对这个问题,展开了一些思考. 我好像找到原因了，http://www.rikfarrow.com/Network/net0700.html，这里 的ping部分，说了，ping是发送icmp echo request包，然后目的主机或路由器 给予响应。除了echo请求响应，icmp还有子类型，称为code，比如提过的 timestamp。当我们ping的时候，发送echo请求的同时，可以设置对应的选项， 就是code，比如-T tsonly。目的主机或路由器端可以配置是否响应这种请求， http://www.rapid7.com/db/vulnerabilities/generic-icmp-timestamp。\n3.5 非授权使用 # 缓存溢出 关于这一点，请参看QQ空间中关于C Function Stack的说明，以及C Modify Return Address的说明，对缓存溢出的理解会更深入. 缓存溢出,不仅可能导致程序崩溃,精心策划的缓存溢出,例如将恶意代码的二进 制数据覆盖源程序的输入缓存,如一个数组,假定这段数据足够长,以致于把远程 序的代码也覆盖了,而且该数据的最后还有精心设计好的一个地址,用这个地址覆 盖原函数的返回地址,这样一来,就可以使函数返回时,跳转到恶意代码开始处执 行.\n64-bit computing In computer architecture, 64-bit computing is the use of processors that have datapath widths, integer size, and memory addresss widths of 64 bits. Also, 64-bit CPU and ALU architetures are those that based on registers, address buses, or data buses of that size. From the software perspective, 64-bit computing means the use of code with 64-bit virtual memory address.\ncomputer artechture : function computer composition : logical implementation computer implementation: physical implementation\nuname -m: machine hardware name uname -p: processor type uname -i: hardware platform ( supported hardware platform by current operating system, implicitly indicating the current operating system type )\nMachine hardware name (family) means the cpu family, \u0026lsquo;cat /proc/cpuinfo\u0026rsquo;, if the \u0026lsquo;cpu family\u0026rsquo; is 6, it is i686, similar for 3, 4, 5. Processor type means the same as the machine hardware name.\n######################################################################\n4 远程终端访问所面临的危险以及防范对策 # 危险的发现与对策的方案: 危险的发现与对策的立案,是指在明确需要保护的信息资产的同时,发现可能发生 的危险,并且在此基础上,研讨针对各种危险所要采取的对策. 安全对策方针的制定: 针对各种危险,需要采取具体的对策.对于具体对策的制定,可以从以下四点进行 研讨,即:用于阻止非法行为以及危险发生的\u0026quot;抑制\u0026quot;,用于保护防范威信的\u0026quot;预防\u0026quot;, 用来检查伴随危险所发生的问题及影响的\u0026quot;发现\u0026quot;,以及伴随危险所发生的相应问 题及影响的\u0026quot;恢复\u0026quot;.\n对策:数据机密通信技术 SSL: Secure Socket Layer SSH: Secure Shell IPSec: 对原始IP Header以及数据进行加密处理,只有目的接收方才可以进行解 密.通过对比telnet,ssh远程登陆的实验可以验证,ssh是对数据进行加密处理的.\nssh端口转发: 利用ssh加密通信的功能,可以将不采用加密通信的程序通过ssh的端口转发功能 来进行更安全的通信,如telnet本身没有对数据进行加密的功能,通过端口的转发 功能,可以通过ssh的端口转发功能,可以对telnet通信进行加密,从而进行更安全 的通信.\n local port redirect, aims to access remote host through local port  ssh -L localPort:remoteHost:remoteHostPort remoteHost telnet localhost localPort\nnote: ssh -p: port that will be used by the ssh server on remote host. ssh -D: port that will be used by the ssh client on local host.\nProviding ssh server on remote host uses PORT-R, ssh client on local host uses PORT-L, then ssh local port redirect works as following: \u0026ndash; ssh creates a connection between PORT-L and PORT-R to communicate with ssh protocol.\n ssh on the local host redirects input from \u0026lsquo;localPort\u0026rsquo; to \u0026lsquo;PORT-L\u0026rsquo;, and encrypted the message, then send it to PORT-R on the remote host. ssh on the remote host receives message from PORT-R, unencrypted it, then redirects it to remoteHostPort.  remote port redirect, aims to access local host through remote host  ssh -R remoteHostPort:localhost:localPort remoteHost on remote host: telnet localhost remoteHostPort\n######################################################################\n5 电子邮件所面临的威胁及其安全对策 # 1 电子邮件的概要\n电子邮件地址格式: username@domain\n电子邮件系统的消息是以接力的方式发送的: 从发送端user@hitachi.co.jp发送往user@ohmasha.co.jp的电子邮件,它首先从 客户端被发送到邮件服务器X,然后从邮件服务器X到服务器Y,最后邮件被转发到 服务器Z上. 此时,邮件服务器Z成为拥有邮件地址user@ohmasha.co.jp的用户的邮件服务器, 当阅读邮件时,该邮件酒会 从邮件服务器Z上下载到用户的接收设备上. 在电子邮件的传送过程中,电子邮件是从邮件服务器X到Y,再到Z上,但是各个邮件 服务器是一边查询电子邮件的传送路径信息,一边接力传送邮件的.\n telnet, send emails  telnet smtp.163.com 25 helo hhhh auth login base64-username base64-passwd mail from:username1@163.com	: can\u0026rsquo;t masquerade rcpt to:username2@domain	: one recipient, one \u0026lsquo;rcpt to:\u0026lt;\u0026hellip;\u0026gt;\u0026rsquo; data from:	: masquerade from, to and subject for inexperienced computer users to: subject: hhhhhhhhhhhhhhhhhhh .	: end input quit\nnote: 1)for experienced computer users, they may check the source content, where they can check the \u0026lsquo;Sender\u0026rsquo; to identify whom this mail comes from on earth.\n2)echo -n username | base64, add option -n to delete the trailing newline character.  telnet, receive emails  telnet pop3.163.com 110 user username pass password stat	: check mail status list	: list emails top emailNum lines	: display email\u0026rsquo;s header retr emailNum	: display email\u0026rsquo;s content dele emailNum	: delete email quit\n电子邮件所面临的威胁: 对服务器的威胁: 恶意利用sendmail、popd等程序漏洞进行攻击，夺取服务器控制权限，从而 进行入侵；或者，通过向服务器发送大量超过其处理能力的电子邮件或大量 的电子邮件，以影响服务器正常运行或导致其瘫痪。 通信过程中所面临的威胁: 主要是在连接邮件服务器的pop3时，对所传输的用户名以及密码等用户认证 信息的窃听。 客户端所面临的威胁: 利用得到的帐号及密码，伪装用户进行非法活动，此外，还包括合法用户可 能辉收到从未谋面的第三者发送的大量的广告邮件、垃圾邮件甚至附带病毒 的邮件等。 用户所面临的危险: 用户所面临的危险，指的是，利用人的心理以诱使其进行某种有目的的活动， 这称为社交工程攻击。\n数字签名技术 适用于电子邮件的签名技术有PGP和S/MIME。\n######################################################################\n6 Web所面临的威胁机器对策 # CGI程序，我认为指的就是一些可以处理HTTP请求的一些脚本，比如JSP、PHP等。\nWeb所面临的威胁有: 对服务器的威胁: 恶意利用httpd、CGI等程序的弱点，进行夺取服务器控制权限的非法侵入； 通过对服务器进行超过服务器处理能力的、大量的访问，使服务器的正常运 行收到干扰甚至瘫痪。 通信信道中的威胁: 当访问Web服务器提供的、有一定限制的网页时，使用的帐号名、密码等用户 认证信息以及网上购物所涉及的信用卡号等，都存在被窃听的危险。 客户端所面临的威胁: 如果在Web服务器提供的信息中混入了病毒等非法程序，那么通过这些信息就 可能使客户端蒙受灾难。 用户所面临的威胁: 用户可能会收到伪装的Web服务器的诱骗，或者被花言巧语所蒙骗，将密码、 信用卡等信息送至服务器，而使自己遭受损失。\n对策:防火墙 在因特网与组织内部网络的节点上，防火墙在事先所确定的基准下，通过对“允 许某些数据通信，拒绝某些数据通信”的访问控制，可以控制数据的流入流出路 径。这样就可以组织外部的非法入侵，预防内部机密信息的无意流出，进行流入 流出信息的管理，限制风险发生的范围，同时有重点地实施安全对策（监察、认 证、监控等）。\n防火墙分类 1）根据保护对象进行分类 网络型和主机型。网络型防火墙设置在内部网络与外部网络之间，主机型防火墙 是安装在主机上。 2）根据采用的方式进行分类 包过滤: 包过滤是在网络层进行控制的方法，它利用路由器等具有路径控制功能的装 置，在传送到路由器的数据包中，让满足条件的数据包通过，而丢弃不满足 条件的数据包。IP数据包中的源IP地址、目的IP地址、源端口号、目的端口 号、标志常作为包过滤的访问控制条件。 传输网关: 传输网关是在OSI模型中的传输层进行访问控制的方式，也称为电路网关。 源IP地址或源主机名、目的IP地址或目的主机名、目的端口号常作为访问控 制的条件。 应用网关: 应用网关是在OSI模型中应用层进行访问控制的方式，应用网关需要准备可 以解析所使用的协议的中继程序。应用网关必须对每一个应用准备中继程 序，而且会有损网络的透明性。 在应用网关的访问控制中，可以对每个应用协议设定条件。除了源端及目的 端的IP地址、源端及目的端的主机名以及目的端口号以外，应用网关的访问 控制可以了解具体的应用协议，可以实施用户认证、选择可用的命令以及应 用所具有的访问控制。因此，能够获得非常细致的访问控制以及利用状况等 的记录。\n 先总结道这里……\n"}),a.add({id:527,href:"/tags/bash/",title:"bash",description:"",content:""}),a.add({id:528,href:"/blog/2012-06-21-linux%E7%B3%BB%E7%BB%9F%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5-%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%8A%80%E6%9C%AF/",title:"Linux系统最佳实践 - 命令行技术",description:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是《Linux系统最佳实践工具-命令行技术》里的一些知识要点。\n# 《Linux系统最佳实践》学习笔记 \u0026gt; 参考书目： 《Linux 系统最佳实践工具 —— 命令行技术 》 \u0026gt; 本文撰写： 张 杰 \u0026gt; 截至日期： 2012-6-21 \u0026gt; 总结	： \u0026gt; 这是我在学习linux过程中，对本书重点内容的一点总结。谈不上心得，只是一点总结，便于以后查阅。在理解/实践的基础上，回头看这些总结的内容会轻松许多。 \u0026gt; 如果你想从本文中获取到丁点帮助，恐怕你必须付出实践，必须肯花时间。 \u0026gt; 有句话叫做“纸上得来终觉浅，绝知此事要躬行”。如果想进步，想获得实质性的进步，必须付出实践。 \u0026gt; linux系统的强大之处不在于它的桌面环境，可能linux现在众多的发行版本中没有任何一款可以与微软抗衡。也许你觉得linux很酷，是的，它的确很酷。 \u0026gt; 它给予了你无穷尽的自由，从内核到桌面，每一个使用linux的人都从中尝到了甜头。但是说真的，linux的“酷”不是靠桌面打下的口碑，这是我们都深知的。 \u0026gt; 当你学习过linux的命令行之后，也许，你才会大彻大悟，linux真是非一般的强悍。而这是windows望尘莫及的。 \u0026gt; 如果你渴望自由，如果你渴望高效，如果…… \u0026gt; 欢迎你加入linux大家庭中来！ # 第一章 Linux简介 ## 1.查看内核版本 uname -r，主版本号/次版本号/修订次数/编译次数 # 第二章 Linux文件系统及其相关处理命令 ## 1.file system - /:文件系统根目录 - /bin:最小系统所需要的命令，其中的文件都是可执行的 - /boot:包含一些启动文件 - /dev:接口设备文件目录 - /etc:系统配置文件所在目录,Editable Text Configuration - /home:用户的主目录 - /lib:库文件目录，例如在执行/bin，/sbin目录下的二进制命令文件时可能会调用的库文件 - /mnt:各项装置的文件系统挂载点，如/mnt/cdrom是光驱的挂载点 - /opt:可以在这里安装自定义软件包（较大的且固定的） - /proc:系统运行时，进程信息以及内核信息（cpu/disk/memory等）都存放在这里。它是一个伪文件系统，存在于内存中，而非硬盘中，通过这个虚拟的文件系统可以在系统运行时调整内核参数，改变内核行为。不用重新启动查看cmos，即可查看系统信息。 - /root:管理员的主目录 - /sbin:目录sbin下的程序都是root权限才可以执行的 - /tmp:存放暂存盘的目录 - /usr:这是系统存放程序的目录，比如命令/配置文件等。当我们安装一个linux发行版提供提供的软件包时，大多安装在这里。这个目录下包含字体文件目录/usr/share/fonts,帮助目录/usr/share/man,/usr/share/doc，普通用户可执行目录/usr/bin,/usr/local/bin,/usr/X11R6/bin,超级用户可执行命令目录/usr/sbin,usr/X11R6/sbin,/usr/local/sbin等。还包含程序的头文件目录/usr/include。 ## 2.",content:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是《Linux系统最佳实践工具-命令行技术》里的一些知识要点。\n# 《Linux系统最佳实践》学习笔记 \u0026gt; 参考书目： 《Linux 系统最佳实践工具 —— 命令行技术 》 \u0026gt; 本文撰写： 张 杰 \u0026gt; 截至日期： 2012-6-21 \u0026gt; 总结	： \u0026gt; 这是我在学习linux过程中，对本书重点内容的一点总结。谈不上心得，只是一点总结，便于以后查阅。在理解/实践的基础上，回头看这些总结的内容会轻松许多。 \u0026gt; 如果你想从本文中获取到丁点帮助，恐怕你必须付出实践，必须肯花时间。 \u0026gt; 有句话叫做“纸上得来终觉浅，绝知此事要躬行”。如果想进步，想获得实质性的进步，必须付出实践。 \u0026gt; linux系统的强大之处不在于它的桌面环境，可能linux现在众多的发行版本中没有任何一款可以与微软抗衡。也许你觉得linux很酷，是的，它的确很酷。 \u0026gt; 它给予了你无穷尽的自由，从内核到桌面，每一个使用linux的人都从中尝到了甜头。但是说真的，linux的“酷”不是靠桌面打下的口碑，这是我们都深知的。 \u0026gt; 当你学习过linux的命令行之后，也许，你才会大彻大悟，linux真是非一般的强悍。而这是windows望尘莫及的。 \u0026gt; 如果你渴望自由，如果你渴望高效，如果…… \u0026gt; 欢迎你加入linux大家庭中来！ # 第一章 Linux简介 ## 1.查看内核版本 uname -r，主版本号/次版本号/修订次数/编译次数 # 第二章 Linux文件系统及其相关处理命令 ## 1.file system - /:文件系统根目录 - /bin:最小系统所需要的命令，其中的文件都是可执行的 - /boot:包含一些启动文件 - /dev:接口设备文件目录 - /etc:系统配置文件所在目录,Editable Text Configuration - /home:用户的主目录 - /lib:库文件目录，例如在执行/bin，/sbin目录下的二进制命令文件时可能会调用的库文件 - /mnt:各项装置的文件系统挂载点，如/mnt/cdrom是光驱的挂载点 - /opt:可以在这里安装自定义软件包（较大的且固定的） - /proc:系统运行时，进程信息以及内核信息（cpu/disk/memory等）都存放在这里。它是一个伪文件系统，存在于内存中，而非硬盘中，通过这个虚拟的文件系统可以在系统运行时调整内核参数，改变内核行为。不用重新启动查看cmos，即可查看系统信息。 - /root:管理员的主目录 - /sbin:目录sbin下的程序都是root权限才可以执行的 - /tmp:存放暂存盘的目录 - /usr:这是系统存放程序的目录，比如命令/配置文件等。当我们安装一个linux发行版提供提供的软件包时，大多安装在这里。这个目录下包含字体文件目录/usr/share/fonts,帮助目录/usr/share/man,/usr/share/doc，普通用户可执行目录/usr/bin,/usr/local/bin,/usr/X11R6/bin,超级用户可执行命令目录/usr/sbin,usr/X11R6/sbin,/usr/local/sbin等。还包含程序的头文件目录/usr/include。 ## 2.比较重要的子目录的功能 - /etc/init.d，存放系统或服务器以System V模式启动的脚本，这在以System V模式启动或初始化的系统中 常见。如Fedora/Redhat。 - /etc/xinit.d，如果服务器是通过xinitd模式启动运行的，它的脚本要放在这个目录下，有些系统没有这个 目录，比如Slackware，有些老版本也没有。在Redhat/Fedora中比较新的版本中存在。 - /etc/rc.d，这是Slackware发行版下的一个目录，是BSD方式启动脚本的存放地。比如定义网卡，服务器 开启脚本等。 - /etc/X11，这是X-Windows相关的配置文件存放地。 - /usr/bin，这个目录是可执行程序的目录，普通用户就有权限执行。当我们通过系统自带的软件包安装 工具安装软件时，软件对应的可执行文件大多都存放在这个目录下。与此类似的文件是/usr /local/bin，有时/usr/bin目录下的文件是指向/usr/local/bin下文件的符号链接文件。 - /usr/sbin，这个目录是可执行程序的目录，但是大多数情况下存放涉及系统管理的命令。只有root权限 才能运行。相似的目录是/usr/local/sbin,/sbin,/usr/X11R6/sbin。 - /usr/local，这个目录通常用来存放用户自编译安装软件。一般是通过源码包安装的软件，如果没有特别 指明安装目录，则一般安装这个目录下。这个目录下面可以建立用于存放安装程序的子目录 ，便于管理安装程序。 - /usr/lib，和/lib目录相似，是库文件的存储目录。 - /usr/share，本系统中所有用户共用文件或者程序的存放地点。比如/usr/share/fonts是所有用户共用的 字体文件存放地，/usr/share/doc是文档存放地，/usr/share/man是命令文档存放地。 - /usr/src，这个是内核源码包的所在目录，有的系统中安装源码程序时，也会安装到此目录下的相应子 目录中。 - /var/adm，存放软件包安装信息/日志/管理信息等，在Slackware操作系统中有这个目录，但是在Fedora系统中没有，其他的自行查看。 - /var/log，系统日志所在的目录，分析日志要查看这个目录的东西。 - /var/spool，打印机/邮件/代理服务器等假脱机目录。 ## 3./proc vfs 此目录中的主要文件： - apm，高级电源管理 - cmdline，内核命令行 - cpuinfo，中央处理器信息 - dma，显示当前使用的dma通道 - filesystems， 核心配置的文件系统 - ioports，当前使用的io端口 - interrupts，显示使用的中断 - core，系统物理内存映像 - msg，核心输出的消息，被送到syslog文件 - syms，核心符号表 - loadavg，系统平均负载均衡 - meminfo，存储器使用信息，包括物理内存和交换内存swap - modules，当前加载了哪些核心模块 - net，网络协议状态信息 - partitions，系统识别的分区表 - pci，pci设备信息 - scsi，scsi设备信息 elf，指向查看/proc进程目录的符号链接	- stat，全面统计状态表 - swaps，交换分区情况 - uptime，系统启动的时间长度 - version，核心版本号 ## 4.file type - 普通文件：ascii码文件，二进制文件。 - 目录文件：linux中通过指针进行管理。 - 链接文件：硬链接/软链接。 - 设备文件：linux系统把每一个io设备都看成是一个文件，操作设备与操作文件采取的方法一样，屏蔽了io设备的细节，这样可以是文件操作和设备操作尽可能统 一。值得一提的特殊设备文件有FIFO，/dev/null。向fifo中写入数据，它就增长，读取数据，它就缩减。向/dev/null中写入的任何数据都会被忽略。 - 管道文件：管道是通过通常的io接口存取的字节流。管道文件是一种很特殊的文件，主要用于不同进程之间的信息传递，在进程通信中扮演着重要的角色。 ## 5.文件系统主流格式 ext：第一个专门开发的linux文件系统类型，叫做扩展文件系统。 ext2：是为解决ext文件系统的缺陷而设计的可扩展的/高性能的文件系统，它又被称为二级扩展的文件系统。 ext3：日志式文件系统，由数据库中因操作失败触发回滚操作从而恢复数据的思想演变而来，每进行操作之前，会向日志中写入一个条目，如果出错，则会按照日志中的记录回滚，恢复到操作之前的状态。 还有很多其他的文件系统，ubuntu中主要使用的是上述三种类型。 ## 6.man手册 查看一个命令的选项时，最好用man而非info，虽然info也可以，但是info中包含很多不需要的信息，阅读起来浪费时间。 ## 7.隐藏文件 linux中，以'.'开头的文件名对应的文件表示隐藏文件。隐藏文件多数是配置文件。 ## 8.常用文件操作命令 ls	：显示当前目录下的文件或者目录信息，也可以显示指定文件或者目录的信息。 cat	：将文件或者标准输入组合输出到标准输出。但是也可以通过重定向将标准输入写	入文件中去。 rm	：删除文件。 less	：分屏显示文件，类似与more。 cp	：复制文件。 mv	：更改文件名，通过更改路径，可以实现移动/重命名操作。 grep	：查找字符串。grep 'pattern' filename，从指定文件中查找匹配模式pattern的 字符串。也可以将其用作管道操作符的右侧操作命令，将其他命令的输出结果作 为grep命令的输入，比如检索当前目录下有没有file文件，ls | grep 'file'。 head	：显示文件内容的前多少行，head -n 10 filename,显示文件的前10行 tail	：显示文件末尾的后多商行，tail -n 10 filename,显示文件的后10行。 sort	：对文件中的内容进行排序并将排序后的结果输出。 sort filename，正序排序；sort -r filename，逆序排序。 uniq	：忽略文件中的重复行。 diff	：找出两个文件的不同点。 diffstat：读取diff的输出结果，然后统计各文件的插入/删除/修改等差异计量。 file	：file filename，可以探测filename对应文件的类型。 echo ：显示文本。 date	：先似乎日期/时间。 script	：记录终端中输入的命令信息以及命令执行后的输出信息。记录的信息是从script启动开始到script记录结束之间的活动信息。script命令启动，默认在当前路径下创建script文件，然后在里面记录输入输出信息，直到exit退出script为止。也可以手动指定记录活动信息的文件名，如'script /usr/test.txt'。 apropos ：根据提供的关键词，搜寻相关的命令，例如'apropos search'，将给出与搜索相关联的指令，其实apropos完全可以用'man -k'来代替。 locate	: 搜索文件。 rmdir	: 删除目录。 basename: 删除文件或者目录的基本名。 chattr	: 改变文件的属性。 cksum	: 文件的CRC校验。 cmp	: 比较文件差异。 split	: 分割文件，这个比较实用。split -b 1m srcfile prefix,这条命令表示将文件srcfile以1m为约定尺寸，将其进行分割，分割后的文件将以prefix加上自动追加的编号命名。split -l，将按照行数进行分割；split -c，与-b类似，按照字节数进行分割，但是分割的时候尽量保持行的完整性。 dirname	: 显示除文件名之外的路径信息。 find	: 查找目录或者文件。find \u0026lt;path\u0026gt; \u0026lt;option\u0026gt;在路径path下按照选项option查找符号expression的文件。 ln	: 链接文件或目录，-s符号链接，不加-s，硬链接。 lsattr : 显示文件属性。 od : 读取文件内容并以8进制形式输出。 paste	: 合并文件的列。 stat	: 显示索引节点inode的内容。 tee	: 读取标准输入到标准输出并可保存为文件。例如：tee \u0026gt;\u0026gt; hello.txt。 tmpwatch: 删除临时文件。 touch	: 更新文件或者目录时间，也可以用来创建文件。 tree : 以树状图显示目录的内容。 chmod	: 设置文件或者目录的权限。 chgrp : 改变文件或者目录所属的组。 chown	: 改变文件的拥有者或者群组。 # 第三章 Linux磁盘文件管理及其相关命令 1.linux里面最多可以有16个分区，其中主分区（或者扩展分区）最多4个，逻辑分区占12个。其中主分区（或扩展分区）占hda1，hda2,hda3,hda4，而逻辑分区占hda5~hda16。 2.安装linux系统必须建立的分区有：swap分区，/boot分区，/分区。 3.常用命令 df	： 磁盘信息。 du	： 显示文件或者目录所占用的空间。 dd	： 主要是从文件或者设备读取信息，然后输出到设备或者文件。功能相当强大， 可以用来拷贝文件/备份磁盘数据/备份恢复mbr等等。 fdisk	： 磁盘分区。 mount	： 加载文件系统。 unmount ： 卸载文件系统。 mkfs	： 建立文件系统。 mkbootdisk： 建立启动盘。 fsck	： 检查文件系统。 hdparm	： 设置磁盘参数。 mkswap	： 建立交换分区。 dump	： 备份文件系统。 restore	： 还原文件。 sync	： 写入磁盘。 badblock： 检查磁盘。 quota	： 显示磁盘已使用的空间与限制。 quotacheck： 检查磁盘的使用空间与限制。 quotaoff： 关闭磁盘空间限制。 quotaon ： 开启磁盘空间限制。 quotastats： 显示磁盘空间的限制。 mdadm	： raid工具。 parted	： 磁盘分区工具。 # 第四章 Linux进程及其管理命令 1.Linux进程中最有名的属性就是它的进程号PID和它的父进程号PPID。PID，PPID都是非零的正整数。 2.所有的进程追踪其祖先，最终都会洛到进程号为1的进程身上，这个进程叫做init进程。它是内核自举后第一个启动的进程。 3.通过pstree命令可以查看进程树中进程与进程之间的继承关系。 4.进程在内存里有3部分数据，数据段/代码段/堆栈段，一个程序可以对应多个进程，因此这多个进程共用同一代码段，只是各自的数据段/堆栈段不同。 5.创建进程可以理解为创建PCB的过程，PCB，进程控制块。 6.启动进程的方式有两种：前台启动和后台启动。对于前台启动的程序，在终端中，可以利用组合见ctrl+c来终止；但是如果是后台运行的程序，就不能用ctrl+c来终止，必须提供pid，然后用‘kill pid’来终止。 7.通过命令runlevel可以查看当前系统的运行级别，系统常见的运行级别有0～6，不同的发行版可能不一样，大体上差不多，这里姑且认为是一致的： (0)-halt(do not set initdefault to this) (1)-single user mode (2)-multiuser,without nfs(the same as 3,if you don't use networking) (3)-full multiuser mode (4)-unused (5)-X11 (6)-reboot(do not set initdefault to this) 8.在rcX.d目录下的进程，如果以S开头，表示启动该程序，以K打头，表示终止该程序。 9.进程与线程的比较，了解将进程再细分为线程的原因，以及何时需要使用线程。 10.理解linux守护进程 进程一般分为交互进程/批处理进程/守护进程3种，其中守护进程总是活跃的，一般在后台运行。它一般是在开机的时候通过脚本启动或开机之后由root用户手动启动。 有的时候，习惯上也将守护进程称为服务。 11.linux下的守护进程很多，单单是常见的就有100多项，这里就不记下了，用的时候再查。 12.Linux进程管理命令详解 linux管理进程的最好方法就是使用命令行下的系统命令。linux下面涉及进程的命令有at/bg/fg/kill/crontab/jobs/ps/pstree/top/nice/renice/sleep/nohup。 at：在指定时刻执行指定的命令序列。 at 23:52 06/05/2012 at\u0026gt;wall \u0026quot;hello,zhangjie\u0026quot; ctrl+d bg：使一个被挂起的进程在后台运行。 fg：使一个被挂起的进程在前台运行。 jobs：显示后台程序。 kill：终止一个进程。 crontab：用于安装/删除或者列出用于驱动cron后台进程的任务表。 ps：查看系统中进程的状态。 pstree：列出当前进程的树状结构。 top：显示当前的进程状况。 nice：改变程序执行的优先权等级。 renice：允许用户修改一个正在运行的进程的优先权。 sleep：使进程暂停一段时间，然后继续执行。 nohup：用户退出系统之后继续工作。 pgrep：查找当前进程并列出匹配给定条件的进程pid。 chkconfig：检查/设置系统的各种服务。 # 第五章 Linux网络体系及其相关命令 1.专用ip地址有三块： 10.0.0.0 172.16.0.0~172.31.0.0 192.168.0.0~192.168.255.0 2.linux下的tcp/ip网络配置 以redhat为例，系统中大部分的配置文件都存放在/etc目录下面。配置文件如下所示： /etc/gated.conf: gated的配置，只能被gated守护进程使用。 /etc/gated.version: gated守护进程的版本号 /etc/gateway: 由routed守护进程可选择地使用 /etc/networks： 列举及其所连接的网络中可以访问的网络名和网络地址。通过路由命令使用，允许使用网络名称 /etc/protocols： 列举当前可用的协议，请参阅网络管理员指南和联机帮助页 /etc/rsolv.conf: 在程序请求解析一个ip地址时，告诉内核应该查询哪个dns服务器 /etc/rpc： 包含rpc指令规则,这些指令/规则可以在nfs调用/远程文件系统安装等中使用 /etc/exports： 要导出的网络文件系统（nfs）和对它的权限 /etc/services： 将网络服务器名转换为端口号/协议，由inet.d/telnet/tcpdump和一些其他程序读取，有一些c访问例程 /etc/xinetd.conf: xinetd的配置文件，请参阅xinetd联机帮助页，包含每个网络服务的条目，inetd必须为这些网络服务控制守护进程或者其他服务，注意，服务将会运行，但是在/etc/services中将它们注释掉了，这样即时这些服务在运行也将不可用 /etc/hostname： 该文件包含了系统的主机名称，包括完全的域名 /etc/host.cnf： 该文件指定如何解析主机名，linux通过解析器来获得主机名对应的ip地址 /etc/sysconfig/network： 指出networking=yes或者no，由rc.sysinit读取 /etc/sysconfig/network-scripts/if*： redhat网络配置脚本 /etc/host： 机器启动时，在查询dns以前，机器需要查询一些主机名与ip地址的配置信息，这些配置信息存放在/etc/hosts文件中。在没有域名服务器的情况下，系统上的所有网络程序都是通过查询该文件来解析对应某个主机名的ip地址 这些配置信息存放在/etc/hosts文件中。在没有域名服务器的情况下，系统上的所有网络程序都是通过查询该文件来解析对应某个主机名的ip地址 3 linux网络管理命令详解 arp命令：arp协议，工作在数据链路层，将ip地址转换为mac地址。arp命令可以列出/添加/删除ip地址与mac地址的记录 arpwatch：用来监听网络上的arp记录 adsl命令：adsl调制解调器命令用来配置宽带调制解调器工作 ifconfig：用来设置网络设备的状态，或显示目前的设置。功能比较多，而且涉及很多常用的操作，建议仔细查看一下man文档 iwconfig:设置无线网卡 hostname：显示主机名 ifup：激活网络设备 ifdown：禁用网络设备 mii-tool:调整网卡模式 route：设置路由表 netstat：查看网络连接 ping：检查网卡接口 minicom：设置调制解调器，主要用来设置28～56K调制解调器 pppd：该命令用来在56K调制解调器和ppp服务器之间建立连接并维持链接，传输数据。Peer to Peer Protocol。 pppstats：显示ppp连接状态 chat：拨号命令 traceroute：显示数据包到达主机之间的路径 rcp：远程复制文件或者目录 finger：查找并显示用户信息 tcpdump：网络数据分析器 ip：网络集成命令工具 yum：软件包管理工具 apt:管理套件的工具 # 第六章 Linux用户管理及其相关命令 1.linux多用户多任务概念的理解 2.用户的角色区分，通过UID来区分。root用户/虚拟用户/普通真实用户。root用户权限最高，可以操作所有的文件/命令等，普通真实用户与root用户做对比，只能操作自己的目录下的文件和普通用户允许执行的命令，root用户和普通真实用户都可以登录系统。虚拟用户是系统所有的，这类用户不具有登录系统的能力。 3.理解用户，用户组。用户组下的用户具有相同的操作权限，用户和用户组之间的对应关系可以是一对一/一对多/多对一/多对多。 4.linux安装过程中，创建的系统标准用户与/etc/passwd文件对应，创建的标准用户组用/etc/group对应。 5.定制环境变量echo $varname,env,export,set,unset $varname。 6.useradd，userdel，usermod，passwd，chage，groupadd，groupdel，groupmod，vipw,vigr,newgrp,groups,gpasswd,whoami,who,id,su,pwck,grpck,chsh,chfn. # 第七章 Linux的备份和压缩及其相关命令 1.首先学会普通的压缩文件的解压和创建，其他高级的功能慢慢再学，因此这一章，先行跳过。 # 第八章 Linux系统管理 1.linux基本启动过程： 1).bios由两部分组成，post代码，运行时服务。post即加电自检阶段，这一阶段结束后，post代码会从内存中清理出来，但是运行时服务仍然保留在内存中，供系统使用。 2).提取mbr信息 dd if=/dev/sda of=mbr.bin bs=512 count=1 od -xa mbr.bin 3).引导加载程序boot loader会读取引导介质的前512个字节，即主引导记录mbr。在一个单一的mbr中只能存储一个os的引导程序，因此如果有多个os时，引导的时候就会出现问题，因此需要更加灵活的引导方式。比如grub。 4).加载内核，当内核影像文件被加载到内存，内核就开始工作了。 5).执行init进程，进程号为1，是所有进程的父进程。 6).根据运行级别，执行相应的脚本文件。这里不同的linux发行版可能有所差异。 2.运行级别 0	：关闭系统 1	：单一用户模式，一般用于管理目的 2	：多用户模式，不允许使用网络 3	：多用户模式，允许使用网络 4	：没有用到的优先级 5	：多用户模式，允许使用网络，x-windows方式 6	：重新启动 运行级别的定义以及相关执行脚本在/etc/inittab中定义。 3.Linux 系统管理命令详解 arch	：显示主机的体系结构 alias	：设置命令的别名 chkconfig：设置服务 cal	：显示日历 chroot	：改变根目录 date	：显示或设置系统时间 dmesg	：显示开机信息 depmod	：分析模块的相依性，供modprobe在安装模块时使用 exec	：执行完命令后，交出命令控制权 eject	：弹出介质 enable	：开启或关闭shell内建命令 fgconsole：显示当前虚拟终端的数目 free	：显示内存信息 halt	：关闭系统 history	：显示使用的命令历史列表 hwclock	：显示与设定硬件时钟 init	：进程处理初始化 init 0 ；转入运行级别0，即关闭系统 init 6 ；转入运行级别6，即重启系统 last	：显示登录用户信息 locale	：显示本地支持的语言系统 logname	：显示登录的用户信息 logout	：退出登录shell lsmod	：显示linux内核的模块信息 modinfo	：显示内核信息 modprobe：自动处理可载入模块 ntsysv	：设置系统的各种服务（ubuntu没有此命令） pmap	：显示程序的内存信息 procinfo：显示系统状态 pwd	：显示当前工作目录 reboot	：重启系统 rlogin	：远程登录 rmmod	：删除模块 rmmod -a ；删除当前所有不使用的模块 rmmod 模块名称 ；删除指定模块 shutdown：系统关机命令 sleep	：延迟指定数量的时间 suspend	：暂停执行shell 用kill恢复执行，但是必须事先获知被挂起shell的pid，然后在另一个shell中执行命令kill -18 pid tload	：显示系统负载 uname	：显示系统信息 authconfig：配置系统的认证信息 declare	：显示或设定shell变量 enable	：可用的shell内置命令 export	：设置或者显示环境变量 hostid	：打印出当前主机的标识 insmod	：插入模块 常用的：insmod -o 模块名称 runlevel：显示运行等级 set	：shezhishell setconsole：设置系统终端 setenv	：查询或显示环境变量 startx	：启动x window unalias	：删除别名 unset	：删除变量或函数 创建环境变量var,export var=\u0026quot;value\u0026quot;;查看环境变量是否存在，env | grep var,set | grep var;显示环境变量,echo $var;删除环境变量,unset var uptime	：告知系统运行了多长时间 lspci	：显示主板所有硬件插槽信息 whereis	：在特定的目录中查找符合条件的文件（二进制文件，手册页文件，源代码文件） 4.linux系统性能监控 1）linux服务器整体性能监控包括几大部分：cpu监控/进程监控/内存监控/网络监控/io监控/磁盘监控 2）监控系统的性能可以通过现有工具，也可以通过内核模块，也可以通过/proc虚拟文件系统，常用的是利用/proc虚拟文件系统 3）proc虚拟文件系统实现了如下五大功能：进程信息/系统信息/cpu信息/负载信息/系统内存信息 4）进程信息：对于系统中的任何一个进程来说，在proc子目录里都有一个同名的进程ID。你还可以找到如下的信息：cmdline，meminfo等等。 系统信息：可以从/proc/stat中获得系统的整体信息，包括cpu占用/磁盘空间/内存页/内存对换/全部中断/接触开关以及上次系统自举时间 cpu信息 ：利用/proc/cpuinfo文件，可以获得当前中央处理器的详细信息 负载信息：/proc/loadavg文件包含了系统负载信息 系统内存信息：meminfo文件包含了系统内存的详细信息 5)这部分涉及到的命令和工具就不详细介绍了，一般情况下在个人计算机上用之甚少 # 第九章	Linux服务器命令 1）linux服务器管理，主要涉及以下几个大方向： apache服务器应用命令 dns服务器管理命令 nfs服务器管理命令 samba服务器管理命令 ssh服务器管理命令 squid服务器管理命令 dhcp服务器管理命令 ftp服务器管理命令 e-mail服务器管理命令 linux防火墙管理工具 xinetd和linux服务器工作方式的关系 2）这部分内容在自己的实际应用过程中，可以有侧重点/有针对性地学习，比如学习php开发需要搭建自己的web服务器，就可以学习apache服务器管理命令。 # 第十章 Linux打印系统及其相关命令 这部分内容与打印机相关，在实际购买并连接打印机之后，可以有针对性地学习。 略。 # 第十一章 Linux库应用及其相关命令 在学习编程的过程中，可以慢慢学习。 略。 # 第十二章 Linux开发常用命令gcc和make 在学习编程的过程中，可以慢慢学习。 略。 # 第十三章 Linux编辑器VI和EMACS 我喜欢vim,喜欢哪个编辑器，无所谓，能达到自己期望的效率就好了。 略。 # 第十四章 使用SHELL linux系统的shell作为操作系统的外壳，为用户提供使用操作系统的接口。它是命令语言/命令解释程序以及程序设计语言的统称。 2）可以理解为shell就是围绕在linux操作系统内核周围的一个外壳，一个接口，当用户通过这个接口执行命令或者应用程序时，这些命令或程序将被分解为系统调用，然后 将这些调用信息传入内核，内核会对此作出相应的反映。 3）简单介绍shell在执行命令时的步骤： step1：用户输入命令后，shell首先检查输入的命令是否是内部命令，如果是的话，就执行。 step2：如果不是内部命令，shell将检查输入是否是一个应用程序，如果是应用程序，shell就会在搜索路径里搜索这些应用程序（搜索路径是由用户设定的一个路径列 表)。 step3：如果应用程序被搜索到了，shell的内部命令或应用程序将被转化为系统调用，然后传递给linux内核。 step4：如果输入的命令或应用程序在搜索路径中没有找到，shell将会显示一条错误提示信息。 4）linux系统提供多种不同shell以供选择，常用的有Bourne Shell(sh)/C-Shell(csh)/Korn Shell(ksh)/Bourne Againe Shell(bash)。还有其他shell。 5）linux系统shell中比较重要的几个知识点是： 通配符/重定向/管道/别名/命令行补全/命令替换/命令历史 6）元字符，最好系统地学习下正则表达式。 7）shell变量和shell环境 变量是一个可以保存值的内存位置。 变量可以分为用户变量和预定义变量，其中用户变量是指在第一次使用时被创建的变量，预定义变量用来保存关于环境的配置。 预定义变量又可以分为两类：shell变量和环境变量。 shell变量用来定制shell，环境变量用来定制用户环境。  "}),a.add({id:529,href:"/tags/shell/",title:"shell",description:"",content:""}),a.add({id:530,href:"/blog/2013-07-01-linux%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E6%9D%82%E8%B0%88-%E7%BB%8F%E9%AA%8C%E6%8A%80%E5%B7%A7/",title:"Linux系统使用杂谈 - 经验技巧",description:"这是一个笔记大杂烩，记录了Linux发行版日常使用过程中遇到的大大小小的问题及解决办法",content:"迁移自 hitzhangjie/Study 项目下的内容，本文主要总结的是日常使用Linux发行版过程中遇到的问题及解决办法。\n/* vim: set ft=text: */ ############################################################################## config codeblocks for wxwidgets if you want to compile and link wxwidgets project,do as following: compiler and debugger--\u0026gt;compiler settings--\u0026gt;other options: add `wx-config --cflags` compiler and debugger--\u0026gt;linker settings--\u0026gt;other options: add	`wx-config --libs` note: if you want to build normal c/c++ project rather than wxwidgets projects, you must remove `wx-config --cflags` and `wx-config --libs`. a better choice is to set the target project's properties including compiler and linker options where you can set `wx-config --cflags` and `wx-config --libs`. ############################################################################## add desktop icon for apps. create and edit appName.desktop file in /usr/share/applications. please note,Icon=.../fg,fg is a picture without expanded name. ############################################################################## install stardict to search words in terminal 1)	install 'sdcv' which is the core of programme. sudo apt-get install sdcv 2)	download the dictionaries from site: http://abloz.com/huzheng/stardict-dic/ 3)	extract the downloaded files and extract them into the path '/usr/share/stardict/dic' to use it conveniently,set some alias cmds,which was written in .bashrc,to use different dictionaries. ############################################################################## security of GRUB lock grub interaction lock start item lock both grub interaction and start item ############################################################################## start a program when os started 1)	we can create a symbolic link of actual programme or put that programme in the folder /etc/init.d/. 2)	then we should execute command 'update-rc.d' to install links into /etc/rcNumber.d,for example: sudo update-rc.d name start priorityNum runlevel . stop priorityNum2 runlevel. ############################################################################## mpg123 : use shell to play music now i want to say,it is nice ! ############################################################################## to extract specific column content from result of 'ls -l' or other cmds cut -d'delimiter' -fFiledNO example: cat filename | cut -d',' -f2 -d means delimiter,-f means fields. awk '{print $number}' can be an alternate method. ############################################################################## in text mode: adjust brightness: echo number \u0026gt; /sys/class/back_light/intel_backlight/brightness adjust volume: run 'alasmixer' in text mode,when zhcon running,alsamixer interface will be messed up! ############################################################################## purge all configruation files of the deinstalled packages dpkg -l |grep ^rc|awk '{print $2}' |sudo xargs dpkg -P ############################################################################## how to boot through \u0026quot;GRUB\u0026quot; here are the three methods to start linux from grub cli: 1)	ls linux (hd0,msdos10)/vmlinuz root=/dev/sda10 [...other options] initrd (hd0,msdos10)/initrd.img boot ls linux (hd0,msdos10)/boot/vmlinuz-3.2.0-23-26-generic root=/dev/sda10 [...other options] initrd (hd0,msdos10)/boot/initrd.img-3.2.0-26-generic boot actully, /vmlinuz,/initrd are symbolic links to /boot/.. configfile (hd0,msdos1)/boot/grub/grub.cfg boot	for windows os here are the only method to start windows from grub cli: - for grub1: rootnoverify (hd0,msdos1)	:this option prevents grub trying to mount :partition hd0/msdos1 chainloader +1	:this option +1 let grub try to load the :proper boot-loader for windows from the 1st :fan sector of (hd0,msdos1) - for grub2: there's no command rootnoverify. set root=(hd0,msdos1) chainloader +1 boot this is useful when you reinstall windows os,windows bootloader will override mbr and other os boot items will be missing. then you can use a linux live cd to boot into grub command line interface,use method above to boot into linux,then reinstall grub. ############################################################################## download website wget -r -p -np -k url -r :recursively -p :download picture -np:don't ascend to the parental directory -k :modify the relavant link ############################################################################## linux core version major.minor.release-revise 主版本号.次版本号.释出版本-修改版本 主版本号.次版本号为偶数，稳定版本，为奇数，表示开发中版本 linux核心版本号 与 某linux发行版本号，是不同的概念 ############################################################################## acpi call module sudo apt-get install git git clone http://github.com/mkottman/acpi_call.git cd acpi_call/ make sudo insmod ./acpi_call.ko uname -r sudo cp acpi_call.ko /lib/modules/\u0026lt;UNAME -R VALUE\u0026gt;/kernel/drivers/acpi/ sudo depmod *** note: 'sudo depmod',this step is of vital importance because 'depmod' generates file 'modules.dep' which can be used by other modules. if we didn't execute 'depmod' before restart,pc will spend more start-up time because the dependencies haven't been worked out. vim /etc/modules,add line 'acpi_call' run ./test-sh Trying \\_SB.PCI0.P0P1.VGA._OFF: failed Trying \\_SB.PCI0.P0P2.VGA._OFF: failed Trying \\_SB_.PCI0.OVGA.ATPX: failed Trying \\_SB_.PCI0.OVGA.XTPX: failed Trying \\_SB.PCI0.P0P3.PEGP._OFF: failed Trying \\_SB.PCI0.P0P2.PEGP._OFF: failed Trying \\_SB.PCI0.P0P1.PEGP._OFF: failed Trying \\_SB.PCI0.MXR0.MXM0._OFF: failed Trying \\_SB.PCI0.PEG1.GFX0._OFF: failed Trying \\_SB.PCI0.PEG0.GFX0.DOFF: failed Trying \\_SB.PCI0.PEG1.GFX0.DOFF: failed Trying \\_SB.PCI0.PEG0.PEGP._OFF: works! add 'echo \u0026quot;\\SB.PCI0.PEG0.PEGp._OFF\u0026quot; \u0026gt; /proc/acpi/call' into your script file /etc/rc.local. note: after 'sudo depmod' is run,add 'acpi_call' into file /etc/modules is ok, too. for my pc,the last cmd works! use 'cat rate /proc/acpi/battery/BAT1/state' to check current power! ############################################################################## use mentohust to instead of ruijie(xrgsu) ############################################################################## use Chinese characters in LaTeX support chinese	:	sudo apt-get install latex-cjk-all pay attention to the document format: \\documentclass{article} \\usepackage{CJK} \\begin{document} \\begin{CJK}{UTF8}{gbsn}	%gbsn/gkai are supported while GB not supported ... \\end{CJK} \\end{document} generally,the supported fonts' directory is : /usr/share/texmf/tex/latex/CJK/ note: in current dir,dirName is the encoding name,fonts in it are all supported. ############################################################################## disable or renable the download bar of chrome how to disable chrome://flags--\u0026gt;disable 'new download gui' how to get it back just delete the config info of current user,'sudo rm -r /home/$USERNAME/.config/chrome/Profile 1' ############################################################################## customize the background image of grub2 and login shell note: after seting up the splash image of grub2,the menu color can't be set. if we don't use splash image of grub2,we can use the following way to set the menu color on grub2. edit /lib/plymouth/themes/default.grub: set menu_color_normal=color1/color2 set menu_color_highlight=color1/color2 1.change background color of Grub cd /lib/plymouth/themes/ modify default.grub,substitute the current color r,g,b to your favorite one. change background image of Grub cp imagePath /boot/grub/ update-grub 2.change the background color which appears before login interface. cd /lib/plymouth/themes/ubuntu-logo modify '*.scrpit','vim *.script', change the major color and minor color set by function 'SetBackground...(r,g,b)'. note that value of 'r' is 'r/255',values of 'g' and 'b' are calculated as the same method. 3.change the picture or color shown before the login interface appear cd /usr/share/glib-2.0/schemas/ record the file name,'grep *greeter* *',then modify its contents. and background-color(color),if your like,change the 'draw desktop background' and 'startup sound'. glib-compile-schemas ./ suggestion: set the schema 'background' as a image rather than color can accerlarate the loading speed. ############################################################################## mount windows file system in /etc/rc.local or in /etc/fstab. in /etc/rc.local: # mount /dev/disk/by-label/Document /media/document # mount /dev/disk/by-label/Multi-media /media/multi-media in /etc/fstab: UUID=..... /media/... ntfs rw 0 0 note: if we want to use 'Trash' mechanism in linux desktop distribution such as Ubuntu,'user,gid=1000,uid=1000' must be added to the mount option in fstab in the following manner: UUID=... /mount-point fs-type defaults,user,gid=1000,uid=1000 0 0 use command 'blkid' to check the UUID and LABEL for all partitions and command 'id' to check the user's group identifier and user identifier. only files owned by current user(or you are super user),files can be deleted to the trash and restored from there. UUID means 'Univerally Unique Identifier'. ############################################################################## fix desktop environment at times,some essential packages to desktop environment components may be removed when we uninstall some gnome based programmes. on this occasion,maybe the reason is some unity or gnome components are uncarefully removed. do as the following to fix this problem: 1)	install package 'unity-greeter',then we can login into desktop environment. 2)	install package 'unity,unity-2d,unity-2d-shell' to add the 'unity,unity-2d' display solution besides 'gnome,gnome classic,gnome classic(no effect). 3)install package 'gnome-icon-themes,gnome-icon-themes-full,gnome-mono' to install our needed common icons for desktop environment. 4)install package 'gnome-tweak-tool' to slightly adjust the desktop environment components to make it much more beautiful. note: before uninstalling a package,you'd better use 'apt-cache rdepends' to check whether there're other packages requiring it. ############################################################################## change the order of buttons 'minimize,maximize,close' and the positon of these buttons on windows. start app 'gconf' and search branch '/apps/metacity/general' and find the item 'button_layout',change its value. for example,if the value is ':minimize,maximize,close',then the three buttons are on the right side of windows in the order 'minimize,maximize,close'; note that this colon ':' control the position of buttons on windows. then if we want to set the three buttons on the left side on windows in order 'close,minimize,maximize',then we can set item 'button_layout' to value 'close,minimize,maximize:' ############################################################################## optimize the initramfs vim /etc/initramfs-tools/initramfs.conf change item \u0026quot;MODULES=most\u0026quot; to \u0026quot;MODULES=dep\u0026quot;. then \u0026quot;sudo update-initramfs -u\u0026quot; ############################################################################## activate 'brightness and lock' if we want to activate the feature 'dim screen' and 'lock screen' in system settings 'brightness and lock',services 'acpi-daemon' and 'acpid' must be enabled. ACPI means 'Advanced Configuration and Power management Interface'. ############################################################################## solve the encoding mistakes in vim edit ~/.vimrc and add the following lines: set the character encoding in buffer set encoding=utf-8 set the character encoding when written to files set fileencodings=utf-8,gb2312,gbk,gb18030 set the character endoding when output to terminal set termencoding=utf-8 gedit can't handle Chinese encoding,too, install 'Kate' instead of it. ############################################################################## ERROR 1045 (28000): Access denied for user 'root'@'localhost'. this fault is similar to the previous one. so, how to fix it? stop process 'mysqld' sudo service mysqld stop start process mysqld_safe with special options to fix it sudo mysqld_safe --skip-grant-tables --skip-networking \u0026amp; launch mysql client to connect to database mysql mysql -h localhost mysql check whether there's something wrong in the user table select host,user,password from user; it it not allowed to exist user whose name is empty, so first delete those users, then change your root password with following cmd. where user='root'; kill process mysqld_safe sudo pkill mysqld_safe restart mysql service sudo service mysql start user mysql client to connect the mysql server again mysql -h localhost -u root -p all done ! ############################################################################## can not create user ??? do it similarly as mentioned above to check whether the user has right privileges. ############################################################################## enable 'charset auto detect' in chrome browser tools-\u0026gt;encoding-\u0026gt;auto detect ############################################################################## remove marks '\r' at the end of lines press ctrl+V then ctrl+M to generate mark '\r',then we can use :%s/\r//g to delete them. ############################################################################## detect and convert file encodings 'chardet' : detect file encoding 'iconv'	: convert file encoding from one to another script:{ step 1: detect charset of specified files #!/bin/bash for file in 'ls | grep php' do chardet $file \u0026gt;\u0026gt; ~/Desktop/tmp/encoding done step 2: convert charset of specified files from one to another #!/bin/bash for line in `cat encoding | grep GB2312 | awk '{print $1}'` do lenght=${#line} line=`echo ${line:0:length-1}` echo $line /usr/bin/iconv -f GB2312 -t UTF-8 /path/php/$line \u0026gt;\u0026gt; ./$line done echo \u0026quot;convertion finished !\u0026quot; } ############################################################################## add a new font into system copy relavent font files that end with *.ttf to /usr/share/fonts/customized_dir/. enter customized_dir,'cd customized_dir_path' 'sudo mkfontscale' 'sudo mkfontdir' 5)'sudo fc-cache -fv' 6)'restart os' but note,if you want to display the Chinese characters well,you had better install the software 'Language Support' from the Software Center. ############################################################################## after wine has been installed,windows notepad will be the default text editor,but when wine has been uninstalled,option in context menu 'open with notepad' is still there,while notepad has been uninstalled,too. we can edit file '~/.local/usr/applications/mimeinfo.cache' for current user or '/usr/share/applications/mimeinfo.cache' for all users on this computer. change 'text/plain=...' to 'text/plain=kde4-kate',then kate will be default text editor. if install program systemwide, then you may check /usr/share/*mime*, too. ############################################################################## use 'gnome classic' theme instead of 'gnome' or 'unity' themes when login in Ubuntu. several techniques: 1)	'gnome-panel --replace' to restart panel on desktop 2)	'win+alt' + 'right click' to open menus to remove unnecessary icons on bars. 3)	to remove 'notification area',put the cursor on the left side of this area,press 'win+alt' and 'right click' to remove the 'notification area'. 4)	use	'indicator applet complete' to replace 'notification area' to the left of windows list on the bottom panel to customize the preferences. ############################################################################## source file source .bashrc in bash source .vimrc in vim you can't source .vimrc file in bash. ############################################################################## remove style 'unity' and 'unity 2d',just use 'gnome','gnome classic','gnome classic(no effect)'. apt-get purge unity unity-2d unity-2d-places unity-2d-panel unity-2d-spread apt-get purge unity-asset-pool unity-services unity-lens-* unity-scope-* apt-get purge liboverlay-scrollbar* apt-get purge appmenu-gtk appmenu-gtk3 appmenu-qt apt-get purge firefox-globalmenu thunderbird-globalmenu apt-get purge unity-2d-common unity-common apt-get purge libunity-misc4 libunity-core-5* you'd better use 'apt-cache rdepends' to check whether there're other packages depending on the package to be uninstalled. #######################################/////////// enable 'localhost/phpmyadmin' to access phpmyadmin sudo ln -s /usr/share/phpmyadmin /var/www/phpmyadmin ############################################################################## customize notification fade time and position Open a terminal window and enter these commands one by one: sudo add-apt-repository ppa:leolik/leolik sudo apt-get update sudo apt-get upgrade sudo apt-get install libnotify-bin pkill notify-osd This installs a patched version of the notify-osd package. Then you will need to install the GUI configuration tool, to do this enter these commands one by one into a terminal window: sudo add-apt-repository ppa:nilarimogard/webupd8 sudo apt-get update sudo apt-get install notifyosdconfig To use the congfiguration tool type \u0026quot;notify\u0026quot; into the dash and launch the NotifyOSD Configuration application. ############################################################################## restore scripts in /etc/grub.d purge all grub* package,then reinstall grub2. ############################################################################## change volume icon at the top panel. cd /usr/share/icons/ find -name audio-volume-* put the audio-volume-* icons that you like into the target icon theme directory to replace the target icons. ############################################################################## about the background wallpaper i want to put a picture into /boot/grub in order to load background image on grub interface, but i also want to use another picture as the desktop wallpaper,also,i don't want the grub background wallpaper appear again before the desktop wallpaper is loaded,how to i realize it? 1)firstly,in .bashrc,we use shell commands to access the .gconf configuration file which consist the desktop wallpaper information,do it as following: TEMP1=`cat ~/.gconf/desktop/gnome/background/%gconf.xml` TEMP2=`echo ${TEMP1#*//}` WALLPAPER=`echo ${TEMP2%\u0026lt;/stringvalue\u0026gt;*}` ln -sf $WALLPAPER /home/$USERNAME/.background.jpg TEMP1=\u0026quot;\u0026quot; TEMP2=\u0026quot;\u0026quot; 2)secondly,edit /usr/share/glib-compile-schemas/*greet*:	set the schema 'background' to '/home/$USERNAME/.background.jpg' now it can automatically load the desktop wallpaper now,we needn't edit '*greet*' after we changed desktop wallpaper from now on. we can also put the shell cmds mentioned above into a script file,i copy the cmds into /usr/bin/update-background. #### in 16.04 lts, there's no %gconf.xml found, but we can get the background via gsettings by exec command: 'gsettings get org.gnome.desktop.background picture-uri'. then we can recreate the soft link. # update background when login BACKGROUND_CONFIG=`gsettings get org.gnome.desktop.background picture-uri` BACKGROUND_CONFIG=`echo ${BACKGROUND_CONFIG#*//}` ln -sf $BACKGROUND_CONFIG /home/$USERNAME/.background-uri ############################################################################## modify ubuntu_logo or progress_dot_on.png if you want to change the color,image-\u0026gt;mode must be changed from 'index' to 'rgb' ############################################################################## install oracle java instead of openjdk or icedea version 1)	First you need to remove openjdk for this run the following command from your terminal sudo apt-get purge openjdk* If you installed java 7 from any other PPA and you are having problem with java then you have to do following steps before installing the PPA menctioned here sudo rm /var/lib/dpkg/info/oracle-java7-installer* sudo apt-get purge oracle-java7-installer* sudo rm /etc/apt/sources.list.d/*java* sudo apt-get update 3)	Install oracle java 7 in ubuntu 12.04 sudo add-apt-repository ppa:webupd8team/java sudo apt-get update sudo apt-get install oracle-java7-installer You can check the java version by searching java in dashboard ############################################################################## install oracle jdk i found a new method, you can leaving openjdk* there, and just download the oracle jdk from oracle offical site, then unpack it to /usr/local/share/jdkxxxx, then you change work directory to that directory, and execute: 'for item in 'ls .'; do update-alternatives --install /usr/bin/$item $item /usr/local/share/jdkxxx/bin/$item 10000; done' over!	note: a better method is to install java as the master link, and install other jdk relevant tools as slave link. ############################################################################## eclipse can't load swt relevant libraries ln -s /usr/lib/jni/libswt-* ~/.swt/linux/x86_64/ ############################################################################## zhcon --utf8 if error occurs,check the permission of file /usr/bin/zhcon, 'chmod 4755 /usr/bin/zhcon', to enable all users to execute this program with root permission. ############################################################################## change the hostname cmd 'hostname': display current hostname: 'hostname' change hostname temporarily: 'hostname newname' change hostname forever,edit file /etc/hostname,the modification won't take effect until next boot. ############################################################################## ftp/ssh/telnet to login in remote server ftp: need ftp/ftpd to be installed, and its' configuration is within /etc/inetd.conf and is controlled by /etc/init.d/openbsd-inetd. ssh: need sshd running,install openssh-server to make it. login remote server: ssh username@ip-server to configure ssh client/server, edit the conf file within /etc/ssh/ssh_config and /etc/ssh/sshd_config. telnet: need telnetd running,install openbsd-inetd login remote server: telnet username@ip-server copy file between remote server and local machine,use cmd 'scp' scp usrname@ip-src:/path/file1 username@ip-des:/path/file2 ############################################################################## on my thinkpad x61t,tomcat7 doesn't allow to access the symlinks,but it indeed worked on my samsung pc. i really don't know why. i have to move all the jsp source files to the /var/lib/tomcat7/webapps/ROOT/,and create a symlink named ~/Documents/jsp pointing to /var/lib/tomcat7/webapps/ROOT/. i have found a resolution,that is create a descriptive file within /etc/tomcat7/Catalina/localhost/. ############################################################################## place window on the proper position,such as 'smart','center','maximized' and so on. use compiz to customize it. ############################################################################## install 'mysql workbench' instead of 'emma' ############################################################################## wireshark by default,only user in group sudo can capture packets,how to enable non-sudo user capture the packets. 'sudo dpkg-reconfigure wireshark-common' choose option 'yes' and press enter to install 'dumpcap' then 'sudo chmod +x /usr/bin/dumpcap' ############################################################################## in single-user mode,remount fs '/' in order to edit files mount -o rw,remount / -o: options rw: read and write remount: umount first,then remount /: the root filesystem ############################################################################## single-mode reset root passwd select 'recovery mode' and press 'e' to change the kernel parameters,i.e, change 'ro' to 'rw' to enable write operation on filesystems,and change 'recovery' to 'single' to enable single-mode that give you the root privilege,and ... don't forget to add 'init=/bin/bash' to the parameter list in order to start bash for emergent recovery operation. then you'll get the root privileges and do whatever you want. ############################################################################## ps -lax ps -aux -l : long format -a : all processes -x : processes that don't have control terminal -u : output format is user-oriented ############################################################################## strace use cmd 'strace' to trace programmes' system calls and signals ############################################################################## redirect for input: to the right file of operator '\u0026lt;'. for output: to the right file of operator '\u0026gt;'. to the right file of operator '\u0026amp;\u0026gt;'. to the right file of operator '2\u0026gt;'. to the right file of operator '1\u0026gt;'. ############################################################################## fuser/lsof fuser: identifying processes that are using specific file lsof: list open files by specific process df : report disk usage of filesystem du : report disk usage of file fuser 8080/tcp, can list ther processes that listening on 8080 port. ############################################################################## remove dir,cmd 'rm' or 'rmdir' remove file,cmd 'rm' or 'unlink' ############################################################################## useradd,userdel,usermod add a user: sudo useradd username	// generate an item in /etc/passwd and /etc/shadow // in /etc/shadow,item 'username:*:...',field '*' // points out user 'username' can't login because // lack of passwd. sudo passwd username	// then set a initial passwd for user 'username' sudo mkdir /home/username	// by default,/home/username is the home // folder for user 'username'. sudo chown username:username /home/username -R	// give user 'username' // proper authority to // access its home folder. we can use cmd 'adduser' instead to finish all operations mentioned above. delete a user: sudo userdel username	// home folder is left that need to be deleted sudo rm -rf /home/username ############################################################################## Exception in thread \u0026quot;AWT-EventQueue-0\u0026quot; java.awt.HeadlessException: No config0ost(). config0X11 DISPLAY variable was set, but this program performed an operation wxwidgets0Post(). config0ost0hich requires it. config0cp#onPopupPost(). solution: export DISPLAY=hostname:0.0 ############################################################################## byobu bugs when edit files in vim within byobu,the speed is too slowly,especially when pressing 'tab' key. we'd better close byobu to edit in vim,then all the speed of 'acp','snippet' and other plugins will be guaranteed ############################################################################## command line to operate network connection first,stop network-manager,'sudo service network-manager stop'. // for open or WEP encrypted access point sudo ifconfig wlan0 up	// start wlan0 sudo iwlist wlan0 scan	// scan nearby wireless networks // choose wireless network and configure sudo iwconfig wlan0 mode ... essid ... key [open | num | s:passphrase] sudo dhclient -v wlan0	// to get a dynamic ip note: iwconfig only supports the wifi networks that are \u0026quot;open\u0026quot; unencrypted or \u0026quot;WEP\u0026quot; enabled. iwconfig doesn't support wifi networks that using \u0026quot;WPA/WPA2\u0026quot;. // for WPA/WPA2 encrypted access point sudo ifconfig wlan0 up sudo iwconfig wlan0 mode managed wpa_passphrase ESSID PASSWORD \u0026gt; wpa.conf sudo wpa_supplicant -B -D wext -i wlan0 -c wpa.conf \u0026amp;\u0026gt; /dev/null sudo dhclient wlan0 -v // on ubuntu distro because the up-start service 'network-manager' take charge of all network interface,if we do manually as mentioned above for other distros,some exceptions may occur even though the service 'network-manager' has been stopped. we'd better use network-manager cmdline tools 'nmcli' to finish this task. nmcli con list	// list all avaiable network-connections,including // wired and wireless conns nmcli con up id ...	// id value,actually,is the conn's name ############################################################################## environment variable DISPLAY set default display for current machine,take my thinkpad x61t as an example. i should add lines into /etc/profile,wait next reboot or source it. DISPLAY=\u0026quot;localhost:0.0\u0026quot; export DISPLAY if i want to run X-appliation that reqire connection with X-server if i want to run x-application on remote machine,i should set DISPLAY to 'remoteHostname:0.0'. example: ssh $USERNAME@10.42.0.1 cd ~/Videos/MV DISPLAY=fm:0.0 export DISPLAY totem MvFileName , actually, set DISPLAY to 'hostname:0.0',but when the given hostname is current machine's hostname,the hostname will be set to 'localhost'. hostname can be set to IP. ############################################################################## desktop environment: gnome gnome classic gnome classic ( no effect ) run cmd 'apt-get install gnome-shell' if you want to install gnome classic only,just install 'gnome-session-fallback' ############################################################################## *.jar file mv *.jar *.zip unzip *.zip or: jar xvf *.jar then,we can get the *.class file,and use 'javap' we can check the className and function from *.class file. ############################################################################## disable the notification bubbles the best method i found out is : kill process 'notification-daemon' sudo apt-get purge notification-daemon this method let me remove the package notification-daemon but reserve package gnome-fallback-session. ############################################################################## cmd_1 \u0026amp;\u0026amp; cmd_2	: only cmd_1 is successfully executed,can cmd_2 be executed. cmd_1 || cmd_2 : only cmd_1 fails,can cmd_2 be executed. ############################################################################## / : slash \\ : backslash ############################################################################## sort -t'delimiter' -kFieldNO -f -r ############################################################################## tee copy pipe data stream,one portion will be output to stream 'stdout',the other portion will be output to specified file. example: ls | tee ls_result ############################################################################## execute shell script ./filename bash filename source filename ############################################################################## find findPath -name pattern specify findPath before find,you don't have to change work-directory to the root '/' ############################################################################## a=1 b=2 c=$a+$b---\u0026gt;c=1+2---\u0026gt;treat $a+$b as the string operation c=$(($a+$b))---\u0026gt;c=3---\u0026gt;treat $a+$b as number operation if you want number operation,put the expression within $((...)) ############################################################################## array in shell script example: array=(aa 'bb cc' dd) ---\u0026gt; aa equals ${#array[@]}, its value is 3, the length of array. ${#array[0]),its value is 2,the length of first element 'aa' in 'array' note: for ele in \u0026quot;array\u0026quot;---\u0026gt;on this case,\u0026quot;array\u0026quot; will reserve the former structure of \u0026quot;array\u0026quot;,(aa 'bb cc' dd). for ele in array---\u0026gt;on this case,array's former structure is broken,(aa bb cc dd). ############################################################################## update-rc.d serviceName { start | stop } priorityNum runlevels example: update-rc.d cups start 80 2 3 4 5 . stop 80 1 6 ############################################################################## /etc/sudoers example: Cmnd_Alias LDAP = /usr/bin/ldapadd, /usr/bin/ldapdelete, /usr/bin/ldapmodify Host_Alias = ip address ip/netmask User_Alias = bob, tom, lucy Runas_Alias = it is similar to User_Alias format: Cmd1,Cmd2,...,Cmdn note: we must set a passwd for account 'root',then modify user privileges within file '/etc/sudoers': ALL then we can use 'visudo -cf /etc/sudoers' to parse this configuration file to check whether it is syntax right. 'su' is allowed now. ############################################################################## ls --hide=pattern ls --ignore=pattern (or ls -Ipattern for short) doesn't list the file entries that match the pattern ############################################################################## umask is used by open and mkdir ############################################################################## harddisk volume \u0026lt; 2TB : install Windows MBR partition table tools: cfdisk or fdisk harddisk volume \u0026gt; 2TB : install GPT partition table tools: parted ############################################################################## format Udisk sudo fdisk /dev/sdb 'd' to delete specified partition 'n' to add new partiton 'w' to write partition table 'q' to quit ############################################################################## dump: bakup files or filesystems for ext2/3/4 restore: restore files or filesystems backuped with dump ############################################################################## ipcalc: calculate the network and host example: ipcalc 192.168.1.1 255.255.0.0 or ipcalc 192.168.1.1/16 output: Address: 192.168.1.1 11000000.10101000. 00000001.00000001 Netmask: 255.255.0.0 = 16 11111111.11111111. 00000000.00000000 Wildcard: 0.0.255.255 00000000.00000000. 11111111.11111111 =\u0026gt; Network: 192.168.0.0/16 11000000.10101000. 00000000.00000000 HostMin: 192.168.0.1 11000000.10101000. 00000000.00000001 HostMax: 192.168.255.254 11000000.10101000. 11111111.11111110 Broadcast: 192.168.255.255 11000000.10101000. 11111111.11111111 Hosts/Net: 65534 Class C, Private Internet ############################################################################## for ssh issue 'refused to connect' solution: remove /home/USERNAME/.ssh/known_hosts,then retry again ############################################################################## LVM means what? no volume groups found? ############################################################################## thindpad x61t: press \u0026quot;F1\u0026quot; to enter BIOS configuration when startup use \u0026quot;USB-HDD\u0026quot; to boot up the machine when using Udisk ############################################################################## how to identify the dependencies and reverse dependencies use 'apt-cache' apt-cache depends packagname apt-cache rdepends packagename ############################################################################## set cursor blink frequency: cursor_blink_time	: gconf-editor,set its value to 300 miliseconds ############################################################################## set text-mode terminal font: sudo dpkg-reconfigure console-setup	: choose font 'VGA' ############################################################################## reinstall package: sudo apt-get --reinstall install packagename ############################################################################## libpeerconnection	: modify /opt/google/chrome/google-chrome # create libpeerconnection within directory /tmp cd /tmp exec -a \u0026quot;$0\u0026quot; \u0026quot;$HERE/chrome\u0026quot; \u0026quot;$@\u0026quot; ############################################################################## update-alternatives sudo update-alternatives --config \u0026quot;masterLinkName\u0026quot; sudo update-alternatives --install \u0026quot;link\u0026quot; \u0026quot;masterLinkName\u0026quot; \u0026quot;path\u0026quot; priority maybe,to change the environment variable PATH in .bashrc is a better way. ############################################################################## install java plugins for chrome: bad way: ln -s /usr/lib/jvm/jdk-1.7.0_25-oracle/jre/lib/i386/libnpjp2.so ~/.mozilla/plugins good way: cd /opt/google/chrome mkdir plugins cd plugins sudo ln -s /usr/lib/jvm/jdk-1.7.0_25-oracle/jre/lib/i386/libnpjp2.so ./plugins/ best way add-apt-repository to install oracle java. this method will modify the default jre which other packages may depend on from openjdk to oracle java. this way may come more up to our want. ############################################################################## LaTex /leiteks/ it is a document markup language,not refer to an application #######################################///////// qBittorrent : in fact,this software uses search engine btdigg.org ############################################################################## ctags generate tags for c/c++/qt4 ctags --c++-kinds=+p --fields=+iaS --extra=+q --language-force=C++ for c glibc/kernel: ctags --C-kinds=+dfgm --language-force=C -R . for user c files: ctags --C-kinds=+dfglm --language-force=C -R . note: please don't use ctags Ctrl+] to refer to header files. it doesn't work well, but we can use TTlistToggle to browse the headers and open it, then we can use Ctrl+\\ to jump back. ############################################################################## format codes tool: indent indent -kr -i4 filename.c ############################################################################## gdb common cmds: start run quit finish	-- continue running until current function finishes backtrace(bt)	-- list function calls as stack frame bt cmd is usually used to fix segmentation fault frame(f)	-- select stack frame locals	-- list local vars and their values list(l)	-- list following 10 lines list lineNO. list funcName next(n)	-- next step(s)	-- step(into) continue(c)	-- continue running until a breakpoint is encountered print(p)	-- print value of var for this time display	-- print value for the following every time undisplay x/7b	-- one byte one group,print 7 groups x cmd print memory info watch	-- display old and new value when var's value changes this kind of vars are called watchpoints info watchpoints break(b) break if(b if) info breakpoints	delete breakpoints disable breakpoints enable breakpoints set Var	-- change value of var ############################################################################## objdump -dS ObjFile note: this ObjFile must be compiled with -g option,-g option need the source code existing. -S option implies that -d option is specified,and this -S option need the source code existing,too. display assembling language and c language in mixed mode. this is a good way to learn assembling language ***************** gcc -S filename.c this method also lets you view the matched assembling language code. ############################################################################## nm, list symbols of object files #######################################////////// 1)check linux kernel version: uname 2)check linux distribution version: lsb_release or you have to check file content:	/etc/*-release or /etc/issue ############################################################################## manual bootparam is an introduction to all boot parameters; manual X is an introduction to X Window System. ############################################################################## centos,add parameter vga=0x34C to change vga resolution to 1366x768 when bootup ############################################################################## c programming,macro definition # and ## #value --\u0026gt; \u0026quot;value\u0026quot; a ## b --\u0026gt; ab length-variable parameter list ...	: length-variable paramter list,used in function macro definition. __VA_ARGS	: reference to length-variable parameter list,used in function macro definition body. 3)not all macros must be defined in *.c file using 'gcc -D' to define a macro ############################################################################## centos,install 'ncurses-devel',because 'make menuconfig' requires this package using 'make menuconfig' to generate '.config' file, using 'make' to compile needed modules into kernel, besides, it generates configuration info which is stored in autoconf.h,'autoconf.h' will be included in 'config.h'. ubuntu,install 'libncurses5-dev' instead of 'ncurses-devel'. note: when on different distros, some required packages' names may be different. ############################################################################## gcc -E	:	stop after preprocess,generate *.i from *.c gcc -S	:	stop after compile,generate *.s from *.i gcc -c	:	stop after assemble,generate *.o from *.s gcc	:	stop after link,generate executable file from *.o ############################################################################## gcc -MM automatically generates the dependencies for all object files how to build Makefile ? gcc -MM *.c \u0026gt; Makefile	: this method only generate the dependencies for \u0026quot;headers\u0026quot; gcc -M *.c \u0026gt; Makefile	: this method will generate the dependencies for \u0026lt;headers\u0026gt; and \u0026quot;headers\u0026quot; recommend to adding lines: |	all: main |	main: obj1.o obj2.o obj3.o |	gcc $^ -o $@ or |	main: *.o |	gcc *.o -o main ############################################################################## make make all make install make clean |---| |- we'd better declare 'clean' as a phony target, why need we do |- this ? because target 'clean' has no prerequires, and, if a |- file named 'clean' exists, cmds following 'clean:' will not be |- executed. add '.PHONY clean' to declare 'clean' as a phony |- target. .PHONY clean make distclean make -n : list cmds that will be executed but not execute them make -C : entering directory and execute the Makefile within it ############################################################################## linux assemble language,there're two types: AT\u0026amp;T,used by gcc. intel,used by official intel documentation and Microsoft. differencies between AT\u0026amp;T and Intel formats: AT\u0026amp;T,should add prefix % before registers. AT\u0026amp;T,should add prefix $ before immediate operand. AT\u0026amp;T,should put source operand on the left,while destination operand on the right. ... linux assemble language compiler: NASM,using intel format nasm -f elf filename.asm ld -s -o filename filename.o ./filename ############################################################################## system call 'open(pathname,flags,mode)' to create file,actually the created file's privilege is 'mode \u0026amp; (~mask)'. touch --\u0026gt; value of mode is 0666. gcc --\u0026gt; value of mode is 0777. how to prove ? umask 0. ############################################################################## evince, a programme to view pdf, enable 'evince' to display Chinese characters install package 'poppler-data' ############################################################################## od dump files in octal or other formats example: od -t x1c filename ############################################################################## in-band and out-of-band transmission in-band: data flow and control flow are transmitted through the same connection. out-of-band: data flow and control flow are transmitted througn respective connections. ############################################################################## one network-adaptor can bind several IP address. several network-adaptors can be bond to one IP address. ############################################################################## install 2.6.32.61 kernel download linux-2.6.32.61.tar.xz tar xvfJ linux-2.6.32.61.tar.xz cd linux-2.6.32.61 make menuconfig make :this step generates the 'vmlinuz' make modules :this step build up modules and its dependencies make modules_install :install kernel modules make install :install kernel and generate initrd.img and update grub.cfg done! ############################################################################## dmesg use dmesg to view the info stored in kernel ring buffer. ############################################################################## uptime tell you how long the system has been running from startup ############################################################################## split: 分割文件，这个比较实用。 split -b 1m srcfile prefix,这条命令表示将文件srcfile以1m为约定尺寸， 将 其进行分割，分割后的文件将以prefix加上自动追加的编号命名。 split -l，将按照行数进行分割。 split -c，与-b类似，按照字节数进行分割，但 是分割的时候尽量保持行的完整性。 ############################################################################## dd： 主要是从文件或者设备读取信息，然后输出到设备或者文件。功能相当强大， 可以用来拷贝文件/备份磁盘数据/备份恢复mbr等等。 ############################################################################## ps aux | grep zhcon pgrep zhcon note: pgrep can get the pid of specified process ############################################################################## add hotkeys to run a new shell in vim add line in ~/.vimrc: map \u0026lt;Leader\u0026gt;r :sh\u0026lt;CR\u0026gt; note: \u0026lt;Leader\u0026gt;r, this manner, after you type in \u0026lt;Leader\u0026gt;r, vim will keep waiting for some more typed 'keys', so you can obviously feel there' a delay before 'sh' is executed. why ? because in vim default configuration, some combinations of \u0026lt;Leader\u0026gt;r and other keys have been defined, so vim has to wait to avoid neglecting some hotkeys. how to solve this problem ?	--| | map \u0026lt;Leader\u0026gt;rr :sh\u0026lt;CR\u0026gt;	\u0026lt;---------| if you don't want to display the cmd, add \u0026lt;silent\u0026gt; as following: map \u0026lt;silent\u0026gt; \u0026lt;Leader\u0026gt;rr :sh\u0026lt;CR\u0026gt; done! ############################################################################## route -n .../.. | .. gw ... metric .. device .../.. | .. #################################################### /etc/passwd: loginname:password:uid:gid:username:homefolder:shell password field is set to x. /etc/shadow: loginname:encryptedpassword:lastchange:....... ############################################################################## ping : send ICMP echo_request to network hosts and wait for the echo_reply. -c :count -f :flood ping -i :interval -D :time -s :packet size why 8 bytes added to the specified size ? because size of ICMP header data is 8 bytes. ICMP header format ??? -t :time to live,\u0026gt;=1 -b :allows ping a broadcast address ############################################################################## tcpdump : dump packets on interface -D -d -e -i :interface -K -l -q -S -X :it's very handy -A :display data in ascii -w :store captured packets into file -r :read packets data from file filter options: dst host src host host port tcp udp ... how to extract the username and password or other something ? when we submit something, for example, a username, the server side will respond to the client side with status code. around the status code, there may be something which you will be intersted in. ############################################################################## convert from ascii to hex: hexdump -x od -x convert from hex to ascii: echo -e \u0026quot;\\xHH\\xHH\\xHH\\xHH\u0026quot; convert hex to decimal: echo $((0xaa)) ############################################################################## cache dns records in ubuntu 12.04, dnsmasq is built into network-manager and it'll be started when network-manager is started. but dnsmasq defaultly is set to disable the dns-cache function, you can find the evidence from /var/log/syslog. ############################################################################## w3m hotkeys H:	display help messages U:	go to url B:	back to previous buffer s:	pop up buffer selection window v:	show html source code Esc-s:	save current html source file into file S:	save buffer into file, the buffer refers to the terminal C-l:	redraw screen ############################################################################## dig: to lookup dns record dig hostname [option list] +short +nocomments	+comments +noauthority	+authority +noaddtional	+additional +nostats	+stats +noanswer	+answer +noquestion	+question +noall \u0026quot;dig hostname +nocomments +noauthority +noaddtional +nostats +noquestion\u0026quot; is equivalent to \u0026quot;dig hostname +noall +answer\u0026quot;. -t soa -t a -t ns -t mx -t any -t cname ??? acutally, non-existent -x ptr, reverse lookup for PTR record how does reverse lookup works ??? what does AAAA record mean ??? a record resolves hostname to a IPv6 address in DNS @dnsserver to use a specified dns server for lookup example: dig @202.12.27.33 redhat.com -t ns +noall +answer 202.12.27.33 is one of the 13 root domain name servers, and it's deployed in Japan. -f to use data file to query several websites example: dig -f filename -t ns +noall +answer you can also query several websites in one command line, do it as following: dig hostname1 -t type1 [option list] hostname2 -t type2 [option list] example: dig redhat.com -t ns +noall +answer centos.org -t a +answer ~/.digrc add options within this file to set the default query options. example: append text '+noall +answer', then next time when you start dig, options '+noall' and '+answer' will be automatically appended to the cmd option list, but these options won't be displayed. ############################################################################## nslookup, using interactive mode to lookup is very convenient. common interactive cmds: server: specify a domain name server host : spefify a hostname that you want to lookup, usually host cmd can be neglected, i.e, you can directly type in the hostname. set q=type: set the query type, ns/a/cname/mx/ptr/soa. set q=ns, then type '.' to display all 13 root domain name servers. exit : exit programme ############################################################################## for CNAME record: usually we think the format of CNAME record is : || Alias Hostname | CNAME | Canonical Hostname || but actually, it may be not set as you supposed, for example, the right-hand field 'Canonial Hostname' may not a canonical name but another alias hostname, this leads to so-called 'alias chain' or 'alias cycle'. so, you may not be able to use one single lookup through all CNAME records to find out the canonical hostname. but, among all presented alias chains, we can pick out the right side hostnames and put them together, all of them must appear in the alias chains in some order, so we can find out which of them is the canonical hostname by comparison. if 'alias cycle' among CNAME records occurs, CNAME type query should respond an error message. ############################################################################## for PTR record: the best option is to resolve the IP address to the Canonical Hostname. rfc doesn't point out dns must implement the reverse query, it is optional. if the dns receives an unsupported query request, it should respond an error message. rfc doesn't require we must set only one PTR record for the same one IP address. so, some people may set multiple PTR records on the same on IP address. it is not reccommended ! why ? first, if we set multiple PTR records for the same one IP address. amony of the multiple PTR records, several alias hostname and canonical hostname are contained. when an PTR type request comes, dns works in round-robin for load-sharing, and the PTR records matched are resorted in round-robin and then responded to your client programme. usally, the programme select the first PTR record and resolve the IP address to the hostname. if the resolved hostname is an alias hostname, when we access it, something wrong may happen if some other hosts has an same alias hostname. it leads to a problem, Hosts : IP = n : 1, it is unacceptable. so, as mentioned above, one IP should always be resolved to the canonical Hostname. so, dig -x, usally can resolve the IP address to the Canonical Hostname. while, nslookup -cname, can process ordinary \u0026quot;alias | cname | canonical\u0026quot; format CNAME record, 'alias chain' and 'alias cycle' format CNAME records to find out the Canonical Hostname. dig can't directly lookup the Canonical Hostname with the Alias Hostname through CNAME type records. you have to lookup the A type record to find out the IP address, then lookup the PTR type record to find it. note: one IP address should have only one PTR record. but one domain, such as 10.in_addr.arpa, can have several PTR records, because one domain, i.e, one network, can have multiple gateways. ############################################################################## A checksum or hash sum is a small-size datum computed from an arbitrary block of digital data for the purpose of detecting errors that may have been introduced during its transmission or storage. The actual procedure that yields the checksum, given a data input, is called a checksum function or checksum algorithm. checksum can be used to check the data's integrity, but it can't be used to check data's authentication. we should use hash function to check whether data has been changed. if data is changed, maybe the checksum stays the same, but the hash value is largely sure to change. checksum tools: cksum hash tools: 'md5sum' is equivalent to 'openssl dgst -md5' ############################################################################## shell script num=1 num=$((${num}+1)) ############################################################################## match in vim: .	match only one character .*	match characters more than one ############################################################################## nm: list symbols from object files. gdb: disas /m objdump -S ############################################################################## 64-bit computing in computer architecture, 64-bit computing is the use of processors that have datapath widths, integer size, and memory addresss widths of 64 bits. also, 64-bit CPU and ALU architetures are those that based on registers, address buses, or data buses of that size. from the software perspective, 64-bit computing means the use of code with 64-bit virtual memory address. computer artechture : function computer composition : logical implementation computer implementation: physical implementation uname -m: machine hardware name uname -p: processor type uname -i: hardware platform ( supported hardware platform by current operating system, implicitly indicating the current operating system type ) means the cpu family, 'cat /proc/cpuinfo', if the 'cpu family' is 6, it is i686, similar for 3, 4, 5. process type means the same as the machine hardware name. ############################################################################## tcp_wrapper,what's this?tcpd?	* it's a facility for access control of internet services inet,what's inetd? there's no /etc/inetd.conf file. after you install iputils-inetd, you can use 'update-inetd' to configure /etc/inetd.conf to control the Internet Services. ############################################################################## how to configure /etc/hosts.allow and /etc/hosts.deny?	daemon-list : client-list [ : shell command list ] ############################################################################## shell redirect 1\u0026gt;\u0026amp;2 2\u0026gt;\u0026amp;1 \u0026amp;\u0026gt;/dev/null ############################################################################## ssh-keygen generate rsa public and private keys ############################################################################## ssh redirect local port redirect, aims to access remote host through local port ssh -L localPort:remoteHost:remoteHostPort remoteHost telnet localhost localPort note: ssh -p specifies the port that will be used by the ssh server on remote host. ssh -D specifies the port that will be used by the ssh client on local host. providing ssh server on remote host uses port PORT-R, and ssh client on localhost uses PORT-L, then ssh local port redirect works as following: ssh creates a connection between PORT-L and PORT-R to communicate with ssh protocol. ssh on the local host redirects input from stdin to 'PORT-L', and encrypted the message, then send the message to PORT-R on the remote host, ssh on the remote host receives the message from PORT-R, and unencrypted the message, then redirects the message to remoteHostPort. remote port redirect, aims to access local host through remote host ssh -R remoteHostPort:localhost:localPort remoteHost on remote host: telnet localhost remoteHostPort ############################################################################## lo, loopback interface loopback is used to test local host' IP stack to check whether it is normally initialized. ############################################################################## cmd: echo zzjie_scu | base64 enpqaWVfc2N1Cg== echo justdoit9497 | base64 anVzdGRvaXQ5NDk3Cg== when i telnet the smtp.163.com and request the authentication, i always failed. why? i used the online base64 app to code the string zzjie_scu and the result was enpqaWVfc2N1. by comparison, i found 'Cg==' was appended when i executed 'echo zzjie_scu | base64'. then i wanted to see what did 'Cg==' mean. i executed 'echo Cg== | base64 -d', then i found out it means a newline character. so i realized i should add option '-n' to delete the trailing newline character when using echo. the right cmd is 'echo -n zzjie_scu | base64'. ############################################################################## telnet, send emails telnet smtp.163.com 25 helo hhhh auth login base64-username base64-passwd mail from:\u0026lt;username1@163.com\u0026gt;	: can't masquerade rcpt to:\u0026lt;username2@domain\u0026gt;	: one recipient, one 'rcpt to:\u0026lt;...\u0026gt;' data from:	: masquerade from, to and subject for : inexperienced computer users to: subject: hhhhhhhhhhhhhhhhhhh .	: end input quit note: for experienced computer users, they may check the source content, where they can check the 'Sender' to identify whom this mail comes from on earth. telnet, receive emails telnet pop3.163.com 110 user username pass password stat	: check mail status list	: list emails top emailNum lines	: display email's header retr emailNum	: display email's content dele emailNum	: delete email quit ##############################################################################/ uninstall specified package and ignore the dependencies. using dpkg, add option '--ignore-depends=packageNameIgnored' example: gnome-tweak-tool depends on gnome-shell, if i want to uninstall gnome-shell and reserve gnome-tweak-tool, do as following: sudo dpkg -P --ignore-depends=gnome-tweak-tool gnome-shell ##############################################################################/ lightdm and kdm	sometimes, lightdm can't login, then you can try kdm, then change the /etc/X11/default-display-manager to let the lightdm serve as the default one. ##############################################################################/ get the pid of specified process cat /var/run/processName.pid ##############################################################################/ ddrescue with the help of 'ddrescue/gddrescue', i rescued the video data in dvd ##############################################################################/ in codeblocks environment configuration: gnome-terminal -t $TITLE -x instead of xterm -T $TITLE -e ##############################################################################/ check tty configurations stty -a ##############################################################################/ for static archive: ar c: create r: insert into archive with replacement v: verbose q: quick append ar crv lib-name *.o note: the archive name must be prefixed by 'lib', or the lib won't be found example: main.c add.c minus.c headers.h gcc -c add.c gcc -c minus.c gcc -c main.c ar crv libfunc.a add.o minus.o gcc -o main main.o -L. -lfunc	(when linking) gcc -o main main.o libfunc.a	(when linking) gcc -o main main.c -L. -lfunc	(when compiling) gcc -o main main.c libfunc.a	(when compiling) 4)./main for dynamic archive: ldd: to check the shared libraries that needed by specified programme gcc -shared to generate the *.so example: main.c add.c minus.c headers.h gcc -c add.c gcc -c minus.c gcc -c main.c gcc -shared -o libfunc.so add.o minus.o gcc -o main main.o -L. -lfunc	(when linking) gcc -o main main.o libfunc.so	(when linking) gcc -o main main.c -L. -lfunc	(when compiling) gcc -o main main.c libfunc.so	(when compiling) before running, set the environment variable LD_LIBRARY_PATH you'd better set it up within .bashrc gcc: -L: the lib directory that to be searched -l: link the lib-name ##############################################################################/ notify-send	\u0026quot;msg\u0026quot; ##############################################################################/ ns2: Network Simulator 2 nam: Network AniMator ############################################################################## disable event sound edit *sound*xml	in /usr/share/glib-2.0/schemas. ############################################################################## disable animation on panel-bar by default, the animation is displayed. for example, i put a chrome icon on the panel-bar in order to launch it more conveniently, but when i launch it, it will display an animation which sometimes makes me sick. how to disables it ? edit file /usr/share/glib-2.0/schemas/org.gnome.desktop.interface.gschema.xml, to disable 'enable-animation', don't forget to exec 'glib-compile-schemas .'. ############################################################################## install and configure LXR	LXR is short for 'Linux Cross Referencer', it is a nice tool to read source code, it worths trying. install: download the lxr-\u0026lt;x.x.x\u0026gt;.tar.gz. unpack the tar.gz file. read the 'INSTALL' file within directory lxr-\u0026lt;x.x.x.\u0026gt;/doc, and do as it says. ok, i will simply summarize the points that you have to pay attenttion. install perl interpreter (\u0026gt;=5.10), then exec 'perl -v' to check whether you have installed it correctly. intall exuberant	ctags (\u0026gt;=5.0), then exec 'ctags-exuberant --version' to check whether you have installed it correctly. install a relational database, such as mysql, so you should try to install several packages, including mysql-client, mysql-server, ... after installed, try to check whether you can connect to mysql server normally, and the privileges of user root. install a web server, such as apache2. after installed, fire your browser at http://localhost to check whether it works normally. install apache mod_perl, sudo apt-get install mod_perl. install swish-e for freetext searching, you can download the package from offical site and install it manually, or you can use apt package manager to finish that, you just need exec 'sudo apt-get install swish-e'. then exec 'swish-e -V' to check whether it runs normally. or: download and manually install it, pay attention to its dependencies. can be installed instead of swish-e. remark: if you just want to browse source code, you needn't installing swish-e or glimpse, but if you want to search some keyword or references, swish-e or glimpse should be installed to help building the index. and relevant drivers (database driver, DBD). you can download it from the offical site and install it manually. or, you can use apt package manager to install them. just exec 'sudo apt-get install libdbi-perl' and 'sudo apt-get install libdbd-odbc-perl'. i used the first way, if you fail, try the other one. or: sudo yum install 'perl-DBI.x86_64' sudo yum install 'perl-DBD-MySQL.x86_64' sudo yum install 'libdbi-mysql.x86_64' install perl file mmagic module, download it from official site, or use CPAN, or use apt to exec 'sudo apt-get install libfile-mmagic-perl'. download the lxr-\u0026lt;x.x.x\u0026gt;.tar.gz from the offitial site. unpack it to /usr/local, and rename it from lxr-\u0026lt;x.x.x\u0026gt; to lxr. cd /path/lxr, and exec './genxref --checkonly' to check whether the nessessary components have been installed and detected. configure LXR and the database. after installation, this step is also frequently used, so you must pay attention to master it. exec './scripts/configure-lxr.pl', it is an interactive script, so you can configure it conveniently, sometimes, you may be confused, don't be upset, try it again and again until you make it. after configuration, some configuration files will be generated according to the template files within /path/lxr/templates, these configuration files will be put into /path/lxr/custom.d, and .htaccess will put into /path/lxr. as i have checked, file .htaccess doesn't need to be modified, but file 'apache-lxrserver.conf' and 'lxr.conf' need modifying. maybe it is a bug of /path/lxr/genxref, why do i say so? when it prompt for the hostname, you type '//localhost' or '//127.0.0.1', but the configuration is \u0026quot;hostname==\u0026gt;http://l\u0026quot; or \u0026quot;http://1\u0026quot; both in the two files listed above. check it and correct it. after modification, put /path/custom.d/lxr.conf to /path/lxr, and put /path/custom.d/apache-lxrserver.conf to /etc/apache/conf.d. also, you must change the line 'NameVirtualHost *' to 'NameVirtualHost localhost', and the line '\u0026lt;VirtualHost *\u0026gt;' to '\u0026lt;VirtualHost localhost\u0026gt;', and the line 'ServerName l' or 'ServerName 1' to 'ServerName localhost' or 'ServerName 127.0.0.1'. or you can adopt other more intelligent techniques, reference 'Apache Configuration' in my QZone. ok, all modification is done, then issue './custom.d/initdb.sh', it will create the database user $dbuser with root, then create the tables with $dbuser. generate the index. fire the following command, this process of building index may takes a long time, so sit down and play something else. './genxref --url=http://$hostname/$sectionname --treename=$treename', you can add other options, such as '--version=$version', actually, '$version' is the name of subdirectory of your source directory. '--reindexall' may be another useful option. after the process of building index finished, fire your browser at 'http://$hostname/$sectionname/source' to check your source tree. you can browse the code now. pay attention, accessing 'http://$hostname/$sectionname' will throws an error of 'do not have permission to access $sectionname on this server'. please and be sure to use 'http://$hostname/$sectionname/source' instead. Enjoy ! ############################################################################## /etc/motd, motd, is short for 'Message of The Day'. login message /etc/motd is regenerated based on file /etc/motd.tail. by default, this file doesn't exist on system, so create /etc/motd.tail manually. ############################################################################## change the preprompt message before login, edit /etc/issue and /etc/issue.net. ############################################################################## time 'program' to check 'realtime, userspace-time, kernelspace-time' ############################################################################## vim: 1. verbose set fo list last configuration for option 'formatoptions' 2. ~/.vim/after/[ftplugin]/filetype.vim will be executed by vim. a text file without specifying modeline or extension name, then it will be treaded as 'conf' filetype, so /usr/share/vim/vim72/ftplugin/conf.vim will be executed. a better method is, we specify modeline at the top or end of file to specify the filetype, then we put a new configure file into ~/.vim/ftplugin/filetype.vim, in filetype.vim, we can do some settings. if we specify // vim: ft=text in file, then vim will search and then execute: /usr/share/vim/vim72/ftplugin.vim, then: /usr/share/vim/vim72/ftplugin/text.vim, then: ~/.vim/after/ftplugin/text.vim. pay attention, it is ~/.vim/after/ftplugin rather than ~/.vim/after/plugin. 3. modeline has 2 forms: such as: // vim: ft=text /* vim: set ft=text: */ ############################################################################# RHEL Configuration: 1. install acpi_call module tar acpi_call-master.zip cd acpi_call-master make cp acpi_call.ko /lib/modules/.../acpi sudo depmod sudo vim /etc/sysconfig/modules/acpi_call.modules content: #!/bin/sh if [ ! -c /sys/module/acpi_call ] ; then exec /sbin/modprobe acpi_call \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 fi sudo chmod a+x /etc/sysconfig/modules/acpi_call.modules 2. replace rhel repo with centos repo sudo rpm -qa | grep yum | xargs rpm -e --nodeps sudo rpm -e python-iniparse download python-iniparse, yum-metaparser, yum-3.xxx, and yum-plugin-fastestmirror.xxx. sudo rpm -i python-iniparse sudo rpm -i yum-metaparser sudo rpm -i yum-3.xxx yum-plugin-fastestmirror... sudo rpm -i Packagekit-... troubleshooting 'subscription manager': sudo rpm -qa | grep subscription | xargs rpm -e --nodeps copy CentOS repos, rpmforge repos, ... into /etc/yum/yum.repos.d/. yum makecache troubleshooting 'YumRepo Error: All mirror URLs are not using ftp, http[s] or file': edit /etc/yum/yum.repos.d/*, change $basearch to x86_64, change $releasever to 6. then yum makecache, ok. download and import the gpg public key, yum will use it after downloading and installing packages. 3. add thirdparty repos rpmforge epel rmi 4. win+e, open places 'home' edit-\u0026gt;preferences-\u0026gt;behavior-\u0026gt;check on 'always open in browser window'. ############################################################################## RHEL: dracut Ubuntu: update-initramfs dracut, update-initramfs will replace of mkinitrd to generate initramfs-\u0026lt;version\u0026gt;.img, but the kernel dump file is still the form initrd-...-kdump.img. ############################################################################## RHEL httpd: 1. run hostname: it displays localhost.localdomain, but in /etc/hosts, it wrote: 127.0.0.1 localhost localhost.localdomain, localhost.localdomain should be the alias of canonical hostname, but why 'hostname' cmd displays the latter one. actually, /etc/sysconfig/network, in this file, there's one configuration options, HOSTNAME=localhost.localdomain, so i think, priority of this file is larger than /etc/hosts. so edit /etc/sysconfig/network, change from localhost.localdomain to localhost. 2. when making httpd autostart when system bootup, it says 'temporary failure in name resolution www.dev.com', i don't know why? i have add it into /etc/hosts, like: 127.0.0.2 www.dev.com, but why? this failure occurs when i add 'Listen www.dev.com:80' in httpd.conf, so i changed it to 'Listen 127.0.0.2:80', but the failure is still there. there're several 'Listen' cmds in /etc/httpd/conf/httpd.conf, so i changed it to 'Listen 80', after this modification, httpd start normally. oh, i nearly forget, 'ServerName' must be unique. ############################################################################## 6. vim modeline ############################################################################## RHEL install openshot 1. Download the *latest* nux-dextop-release rpm from http://li.nux.ro/download/nux/dextop/el6/ 2. Install nux-dextop-release rpm: rpm -Uvh nux-dextop-release*rpm 3. Install openshot rpm package: yum install openshot 4. update your ffmpeg sudo yum install ffmpeg, ffmpeg will be updated because of the dependencies to nux-dextop. what a pity! openshot can't start successfully, ah, forget it! ############################################################################## RHEL loglevel when rhel boots, it will generates an warning or error message on the console, just like 'pnp,...cannot evaluate crs 8', it is relevant to the acpi. i can't figure it out how to fix it, so i just disable the message output, how do realize it? append loglevel=N to the kernel boot parameters to control which kind of messages can be logged. i set it to loglevel=3, then loglevel 3,4,5,6 will be logged. what is intereting is that rhel loglevel is contrary to the log4j. in rhel, higher priority loglevel has a lower number, for example, 3\u0026lt;4, loglevel 3 has a higher priority than loglevel4. when you set loglevel=3, messages of loglevel4 will also be logged. while in log4j, FATAL has a higher priority than INFO, when you set log level FATAL, messages of INFO will be ignored. ############################################################################## RHEL generate splashimage *.xpm.gz there's a cmd tool called 'convert', it can convert an image to xpm format, for example: convert palm.JPG -resize 640x480 -colors 14 -depth 16 -normalize -verbose palm.xpm then compress it: gzip palm.xpm put 'palm.xpm.gz' to /boot/grub, and change the splash option in grub.conf. reboot to see the effect! ############################################################################## RHEL snmpconf using cmd tool snmpconf to configure snmp.conf\\snmpd.conf\\snmptrapd.conf, it is very convenient! ############################################################################## when exec 'git commit', 'Error detected while processing /home/$USERNAME/.vimrc', unknown options .... git config --global core.editor vim ############################################################################## exec vim, type ':help', it reports an error, 'no help for help.txt'. reinstall all vim relevant packages, then it will be solved. i think, maybe, this error is caused by bleachbit cleaning. ############################################################################## gnuplot using gnuplot to draw, such as drawing following functions: log2(x), x^0.5, x, x^2, x^3, 2^x, x! exec gnuplot, enter interactive mode: \u0026gt; set xrange [1:25] \u0026gt; set yrange [1:10000] \u0026gt; \u0026gt; log2(x)=log(x)/log(2) \u0026gt; set sample 1000 title 'log(n)' \u0026gt; replot x**0.5 title 'n^0.5' \u0026gt; replot x ttle 'n' \u0026gt; replot x**2 title 'n^2' \u0026gt; replot x**3 title 'n^3' \u0026gt; replot 2**x title '2^n' \u0026gt; set sample 25 \u0026gt; replot floor(x)! title 'n!' \u0026gt; \u0026gt; set yrange [1:500] \u0026gt; replot ############################################################################## /etc/yum.repos.d/xxx, enabled=1 is default value. ############################################################################## file cmd, can be used to determine file type. ############################################################################## install Gnu binutils to operate binary files, such as we can use 'readelf' cmd to read and display elf part of Binary Object Files. ############################################################################## install gtk+-2.24.23. recently, i found a very good programme named gtkqq on github, i want to study it and the webqq protocol. so i clone it, but when i build it, i found there's no apropriate gtk+ installed. it requires at least gtk+-2.24.23, rhel 6.5 has gtk+-2.20.1 installed, and there's no proper rpm package to install, i have to manually installed from the source. from the INSTALL file of gtkqq, we know it needs following prerequisites: 1)glib 2.28.0	: manually install 2)pango 1.20	: rhel repo 3)atk 1.29.2	: manually install 4)gdkpixelbuf 2.21.0	: manually install 5)cairo 1.6.0	: rhel repo 6)gobject-introspection 1.6.0	: rhel repo please install the prerequisites as the listed order mentioned above, when installing, maybe some other packages you should install. has been installed, configure your .bashrc to export environment variable: PKG_CONFIG_PATH=/opt/gtk/lib/pkgconfig:$PKG_CONFIG_PATH LD_LIBRARY_PATH=/opt/gtk/lib:$LD_LIBRARY_PATH export PKG_CONFIG_PATH export LD_LIBRARY_PATH then configure\\make\\make install gtk+-2.24.23. ok, gtk is installed successfully, and gtkqq is compiled successfully, but it can't run successfully. ############################################################################## configure ANT_HOME env var. my rhel has installed eclipse IDE from repo, and ant is installed with eclipse. version of ant is 1.7.1, but i want to install a higer version of ant, so i download 1.9.4 from apache offical site, then i unpack it to /opt/apache/ant, and add /opt/apache/ant/bin to PATH env var. i am sure /opt/apache/ant/bin appears before the /usr/bin, so i am sure /opt/apache/ant/bin will be run when i type ant in terminal. but when i type 'ant -version', it still output 1.7.1, but i can see /opt/apache/ant/bin/ant has been run with the help of cmd 'hash', so i use strace to trace the open files, i find it open /etc/ant.conf to read ANT_HOME var's value, i realized maybe i have to configure ANT_HOME env var in ~/.bashrc, after i did that, it works. ############################################################################## vim, change from lowercase to uppercase: 1)enter visual mode and select text 2)U/u vim, jump to the matched brace: % ############################################################################## 搜索字符串用的是正规表达式(Regular expression)，其中许多字符都有特殊含义： \\ 取消后面所跟字符的特殊含义。比如 \\[vim\\] 匹配字符串“[vim]” [] 匹配其中之一。比如 [vim] 匹配字母“v”、“i”或者“m”，[a-zA-Z] 匹配任意字母 [^] 匹配非其中之一。比如 [^vim] 匹配除字母“v”、“i”和“m”之外的所有字符 . 匹配任意字符 * 匹配前一字符大于等于零遍。比如 vi*m 匹配“vm”、“vim”、“viim”…… \\+ 匹配前一字符大于等于一遍。比如 vi\\+m 匹配“vim”、“viim”、“viiim”…… \\? 匹配前一字符零遍或者一遍。比如 vi\\?m 匹配“vm”或者“vim” ^ 匹配行首。例如 /^hello 查找出现在行首的单词 hello $ 匹配行末。例如 /hello$ 查找出现在行末的单词 hello 括住某段正规表达式 \\数字 重复匹配前面某段括住的表达式。例如 \\(hello\\).*\\1 匹配一个开始和末尾都 是“hello”，中间是任意字符串的字符串 对于替换字符串，可以用“\u0026amp;”代表整个搜索字符串，或者用“\\数字”代表搜索字符串中的某 段括住的表达式。 举一个复杂的例子，把文中的所有字符串“abc……xyz”替换为“xyz……abc”可以有下列写法： :%s/abc\\(.*\\)xyz/xyz\\1abc/g :%s/\\(abc\\)\\(.*\\)\\(xyz\\)/\\3\\2\\1/g 其它关于正规表达式搜索替换的更详细准确的说明请看 :help pattern 例如：在文本中搜索所有包含amount大于0的以[ ] 括住的字符串的行，如 “amount[123] “, ”amount[200]“ 等： 首先按 ：进入命令 模式，然后输入下面的串再回车开始查找： /amount\\[[1-9]\\([0-9]*\\)\\+\\] 解释如下： / 表示进行串搜索, 其它字符为 正则表达式的内容 amount 表示匹配串包含amount \\[ 转义字符，表示匹配左中括号 [ [1-9] 表示匹配一位1到9之间任何数字 转义的左右括号，表示括住某段正则表达式， 表 示 任意个0-9之间的数字 \\] 转义字符 ] 分组匹配: s/\\(.*\\)=\\(.*\\);/\\2=\\1;/g。 其中s/ / /g为搜索并替换的语法。\\2,\\1是引用用正则表达匹配到的分组。\\( \\)括起来 的是正则表达式分组匹配项，我这里将“=”之前的内容设为\\1，将“=”号好“;\u0026quot;之间的内容 设为\\2。 ############################################################################## 想安装linux内核函数手册页，一般安装的时候，软件仓库中是不会提供这个包的，可以 下载linux内核源代码然后手动建立该manual。 1. 准备工作 1)下载内核源代码,或者直接yumdownload --source kernel下载rpm包,然后从中提取出 linux-4.1.xz; 2)安装xmlto,这个工具可以用来生成man格式的文档; 2. 开始建立手册 cd $linux-source-path make mandocs make installmandocs 这里也可以生成其他格式的手册,例如pdf格式的或者html格式的,分别执行命令make pdfdocs或者make htmldocs即可. 手册会被安装到/usr/local/man/man9中去,然后就可以通过man 9来查看内核提供的函数 的帮助文件了。 3. 如何卸载呢? 如果不需要该内核man手册文档了,如何卸载呢?man格式的会被安装到 /usr/local/man/man9目录下,直接删除该目录就可以了. ############################################################################## bakup/restore linux system 自从上了大学，买了电脑一共5个，其中一个台式机，4台笔记本，哈哈哈，当然了，4台 笔记本中有3台是二手，买来不是玩的，当然是为了学习。由于偏好ilnux操作系统，于是 乎在各个系统上安装配置linux就成了一件乐趣，但是慢慢地觉得配置系统是一件记为麻 烦的事情，于是我想了些办法，为的就是能够避免这种重复性的安装配置操作。 最初的时候我通过将配置文件进行备份，来解决复杂的配置问题，例如将vim、bash等的 配置文件上传到github上进行备份，以后每当重新安装系统之后就可以及时的将配置文件 恢复，这也算是一种巧妙的办法。 但是，后面发现即便是这样，重新配置系统也是非常低效的，于是，我希望能够将我现有 的系统做成iso文件，然后将其做成可以引导的启动盘，例如刻录到u盘里面，或者更大容 量的移动硬盘里面，这样每次换电脑时，或者希望在不同的硬盘间进行系统的安装配置时 ，就可以通过安装直接完成。这样做的优势是，将常用的应用软件、配置文件都集成在一 起了，装上之后就是自己期望的操作系统，有点类似与windows下的gho文件，但是比较起 来，安装的速度仍然是稍微慢些，不过也可以接受。主要是同股remastersys进行，但是 这个程序也有些bug，对不同的发行版支持的程度不一样，备份出来的iso文件可能有错。 一段时间之后,发现系统的备份还原依旧是个问题，尤其是时间比较紧急，希望快速的完 成系统的备份、恢复时。也是为情势所迫，逼着我学习了下linux系统的备份、恢复，实 践证明效果是非常好的，赞一个！ 具体的就是通过linux系统下提供的dump、restore这两个工具。 我当前学习的比较浅显，只是学习了文件系统的备份、还原，构造一个情景阐述下如何进 行操作，假如现在有两个硬盘，分别为A、B，现在A里面已经有一个linux操作系统了，但 是B里面没有，假定B里面现在有一个windows操作系统，我们现在希望将A里面的linux操 作系统拷贝到B中，我们可以按照如下步骤进行操作： 1）首先，我们需要将A中的linux操作系统备份，这里我们可以选择“文件系统备份”，这 样我们通过这个备份文件还原到B中的时候，原有的文件系统中的文件属性信息都会被保 留，这正是我们所希望的。假定A中的linux系统在/dev/sda3中，我们通过如下命令进行 文件系统级别的备份: 首先通过这条命令检查下生成的备份文件的尺寸，以便于我们决定将这个备份文件存 储到哪个位置: sudo dump -0S /dev/sda3	然后开始备份： sudo dump -0u -f path/os.dump /dev/sda3 备份完成之后，我们就要准备进行还原了，必须保证硬盘B上有足够的空间，我们先从 B上分出两个分区，一个用来挂载/分区，一个用来做swap交换区。 这个可以通过安装盘完成，或者在其他的linux操作系统里面完成。 然后假定这个即将挂在/分区的分区为/dev/sdb4,我们就可以这样对其进行还原操作： sudo mount /dev/sdb4 /mnt cd /mnt restore -r -f path/os.dump 如果希望排除某些文件，不对其进行备份，可以通过-E选项指定要排除的文件对应的 inode，inode可以通过ls -i进行查看。 这样备份的文件系统就会恢复到/dev/sdb4中去了，时间可能会长一些。 在恢复的过程中，用户可能区查看恢复的情况，这个时候看到的文件的属主基本上都 是root的，包括/home/anyuser下的文件也都是root的，这个不要怕，当你恢复成功 后，引导进入/dev/sdb4中的操作系统时，文件属性就是正确的了。 恢复成功之后，就要准备进行重新引导了，但是这个时候，grub没有安装，是无法引 导B中的双系统的，所以需要在当前linux系统中先将grub装上，通过命令： pwd is /mnt. grub-install --boot-directory=/mnt/boot/grub/ /dev/sdb 这个时候已经将grub安装到sdb上了，但是由于grub之前认分区的时候可能是通过 uuid的，这样换了硬盘之后，uuid不同了，所以grub在引导的时候会出错，不能够自 动引导，我们需要手动修改grub引导配置，或者通过命令手动引导。也就是说我们在 grub引导界面通过configfile引导的时候会出错，因为uuid变了，找不到对应的分区 了，我们可以在grub引导界面上，通过ls查看对应的分区信息，并通过linux装载内 核配置root，通过initrd装载初始ram盘，然后boot启动就可以了。 这样系统就可以启动了。 然后，我们不能一直这样修改吧，我们必须修改配置文件，包括/etc/fstab中的uuid ，uuid可以通过blkid进行查看，还有必须更新grub，让grub更新配置文件中的引导参数 ，这样就可以引导windows、linux双系统了。 windows有个100mb的系统保留分区，里面可能包含了某些引导性的代码，因为之前B中已 经有4个主分区了，为了建linux分区，我把它删掉了，然后才可以建扩展分区，然后将 linux分区、swap建立在扩展分区中。 这样，如果不安装grub的话，把windows7自带的系统保留分区删掉，windows7就没法启动 了，所以我猜测里面包含了引导性的代码，经过验证发现，这100mb的分区里面果然是安 装了启动的代码。如果安装win7的时候就手动删除了这个保留分区，那么启动代码 bootmgr以及启动配置Bot/BCD等均会安装在c盘下，而如果是保留分区没有删除，则安装 在该保留分区中。如果安装了win7之后再删除保留分区，由于之前启动相关文件在保留分 区里面，这样安装了grub之后，进入系统之后再执行下grub-update也是找不到win7所在 分区的，这个时候就是要用系统盘进行修复。 ############################################################################## 使用opengl进行渲染，不要使用xrender进行渲染 ############################################################################## 添加内核参数video.brightness_switch_enabled=0到grub ，不要添加 acpi_backlight=vendor，在某些笔记本电脑上，必须添加参数acpi_backlight=vendor才 可以让系统通过快捷键调节亮度，比如在我的samsung q460 js02这台笔记本上就是。但 是在thinkpad品牌的电脑上，就不需要添加这个参数，添加、不添加这个参数，亮度都可 以通过快捷键进行调节，但是如果添加了该参数，快捷键调节亮度的时候，对应的指示器 没有显示出来，去掉这个参数的话，就可以正常显示了。 ############################################################################## 备份、备份，还是备份！ dump\\restore是备份还原的利器！ ############################################################################## 安装搜狗词库到ibus-pinyin，也就是替换词库android.db，但是要删除 ibus-pinyin-db-openphrase ############################################################################## 安装搜狗输入法，真是太爽了，详细参考sogou官网，里面有详细的说明 ############################################################################## using synergy to control several pc. when i set 'ctrl+alt+k' as the hotkey, i saw the error log, it says 'cannot register hotkey ctrl+alt+k', i realized maybe there has one hotkey 'ctrl+alt+k' existing in the kde desktop environment. i checked the keyboard and shortcuts settings from system settings, indeed it's been registered to switch keyboard layout, i found it and unregistered it, then restart synergy, every thing goes ok! ############################################################################## in VirtualBox, don't use left ctrl key as the host key, if you do that, ctrl+c,ctrl+\\,ctrl+d signal will not be generated and sent to the guest terminal. you can try left win as the host key instead of right ctrl. ############################################################################## To register Nessus, fire your browser at the following url: http://www.tenable.com/products/nessus/ nessus-plugins/obtain-an-activation-code Nessus website doesn't block the access from China. Regarding to blocking China access, it's nonsense. if you uninstall and reinstall nessus, you have to get a new activation code. the same email can be used to register more than once. /opt/nessus/sbin/nessus-update-plugins all-2.0.tar.gz，在nessus一分钟内处理完 成之后，这个压缩包就不需要了，但是还是放在某个位置备份一下比较好。注意，这一分 钟之内，不要重启nessus，也不要移动all-2.0.tar.gz，否则可能处理失败，而又不给出 错误提示，最后使用nessus的时候，就会出现奇怪的问题。 ############################################################################## /etc/xdg/autostart/fcitx-autostart.desktop to enable fcitx autostart. ############################################################################## squid3 搭建http代理服务器 ############################################################################## apt-get update to find the checksum is mismatched. why and how to fix ? Wait a few hours. This is caused by the download site being behind a CDN, and the caches for Release and Packages.gz being mismatched. It'll clear itself up within a few hours. After ~12 hours it has not fixed itself, but a new error arose: W: A error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://download.mono-project.com wheezy Release: The following signatures were invalid: BADSIG A6A19B38D3D831EF Xamarin Public Jenkins (auto-signing) \u0026lt;releng@xamarin.com\u0026gt; W: Failed to fetch http://download.mono-project.com/repo/debian/dists/wheezy/Release W: Some index files failed to download. They have been ignored, or old ones used instead. After 14 hours the repository was parsed successfully and the problem has been resolved. ############################################################################## The following signatures couldn't be verified because the public key is not available: NO_PUBKEY 16126D3A3E5C1192. sudo apt-key adv --recv-keys --keyserver keyserver.ubuntu.com 16126D3A3E5C1192 apt-key, cmd 'adv' can pass advanced options to gpg, for example, adv with option --recv-keys can be used to download public key from keyserver specified by --keyserver. ############################################################################## install 'xrdp' to make your pc works as a rdp server. ############################################################################## install 'kde-config-touchpad' to switch off touchpad when in keyboard activity. ############################################################################## eclipse 'install new software', add 'viPlugin/http://viPlugin.com', after pending select 'viplugin' to install, create file viPlugin2.lic, and write 'q1MHdGlxh7nCyn_FpHaVazxTdn1tajjeIABlcgJBc20' into it, then put it under /opt/eclipse, restart. ############################################################################## grub-install --boot-directory /dev/sda here, --boot-directory should point to the /path/boot directory rather than /path/boot/grub directory, or when you restart, grub will not find relevant mods. and in manual, it is described clearly as following: --boot-directory=DIR: ... points to DIR/grub ... ############################################################################## /etc/X11/X when kdm failed to start, i swithed to text mode, then i check the /var/log/kdm.log, it says there's no /etc/X11/X, then i create a symlink /etc/X11/X which points to /usr/bin/Xorg. then restart kdm, ok. maybe linux distros and communities are so ... free. ############################################################################## i remove the bug report packages, apport* ############################################################################## install several display managers, conflict! after i install several display managers, some conflicts occur. i installed kdm, lightdm, gdm in order, then only gdm can start normally, kdm and lightdm will stuck when start them. so i delete logs in /var/log, then i restart kdm, and deep into /var/log/kdm.log, it says no X in /etc/X11/, then i recreate a symlink points to /usr/bin/Xorg, now kdm can start normally now. then i tried lightdm, in /var/log/lightdm/lightdm.log, it says failed to start greeter, then i check /var/log/lightdm/x-1-greeter.log, it says no authority to access /var/lib/lightdm/.Xauthority. then i check the mode of file .Xauthority, then i saw its owner user and group is 'gdm'. what a suck! it clearly belongs to 'lightdm', why you set it to 'gdm'. what a suck! what a bug! then i checked /etc/passwd, kdm\\lightdm\\gdm entries exist. then i know display managers run as the kdm\\lightdm\\gdm rather than root. when i installed them, they changed the modes of some files which are belonged to by kdm\\lightdm\\gdm, so only the last installed one works normally. the previous can't be sure. even though you uninstall the last installed one, the previous installed must be reinstalled to enable it normally. i changed the owner:group of /var/lib/lightdm/* to lightdm, it works! restart! ok! ############################################################################## Unknown media type in type 'all/all' Unknown media type in type 'all/allfiles' Unknown media type in type 'uri/mms' Unknown media type in type 'uri/mmst' Unknown media type in type 'uri/mmsu' Unknown media type in type 'uri/pnm' Unknown media type in type 'uri/rtspt' Unknown media type in type 'uri/rtspu' cd /usr/share/mimeinfo, mv kde.xml kde.xml.bakup, sudo update-mime-datebase over! ############################################################################## 12.04 latest kernel 3.13.0-40 is not compatible with latest virtualbox and relevant components in main repo. remove it and reinstall 'virtualbox virtualbox-dkms', must add '--reinstall' parameter. then ok. guest screen resolution can't be changed, install 'virtualbox virtualbox-dkms virtualbox-guest-additions virtualbox-guest-dkms virtualbox-guest-utils', must add '--reinstall' parameter. sudo service virtualbox restart, then test still not works. ############################################################################# 删除符号链接的时候，最好使用unlink，删除符号连接的时候，也会删除所指向的文件 ############################################################################# apt-get update, checksum mismatch 原因： Wait a few hours. This is caused by the download site being behind a CDN, and the caches for Release and Packages.gz being mismatched. It'll clear itself up within a few hours. After ~12 hours it has not fixed itself, but a new error arose: W: A error occurred during the signature verification. The repository is not updated and the previous index files will be used. GPG error: http://download.mono-project.com wheezy Release: The following signatures were invalid: BADSIG A6A19B38D3D831EF Xamarin Public Jenkins (auto-signing) \u0026lt;releng@xamarin.com\u0026gt; W: Failed to fetch http://download.mono-project.com/repo/debian/dists/wheezy/Release W: Some index files failed to download. They have been ignored, or old ones used instead. After 14 hours the repository was parsed successfully and the problem has been resolved. ############################################################################# ubuntu里面没有plymouth-set-default-theme，使用如下命令代替： update-alternatives --list/config default.plymouth来代替 ############################################################################# 原来带有PAE标识的32位系统是支持扩展内存，最大支持64GB内存或者在32位系统上安装 pae内核模块 ############################################################################# vim treaks: shortcut: zz, put the current line under cursor to the center of screen. command: %Tohtml, convert current document to html. ############################################################################# ssh-keygen 生成的公钥必须要放置在被管理服务器的root账户中才可以，才可以实现无 密码登录. I don't know why? ############################################################################# byobu\\tmux升级之后，解决某些annoying problems: 1)byobu配置问题，每次f2新建窗口之后，下方tab上显示的title特别长，开的窗口数量 多了之后，切换起来眼花撩换，搞得整个人心情都不好了，这就是一个坑爹的配置方案 。解决办法如下： 修改/usr/share/byobu/profile/tmux中的配置信息，进行如下修改： set -g default-terminal screen --\u0026gt; set -g default-terminal xterm-256color 2)tmux升级之后的问题，启动tmux的时候有一个起始目录，再f2新建窗口之后，这个新 增窗口的shell提示符显示，pwd显示其位置为按f2时，shell所在的目录的位置，看上去 这个功能很方便，其实不然。窗口多了之后，容易引发混乱，还是统一为起始目录位置 要更好些。个人看法，个人使用体验决定的。解决办法如下： 修改/usr/share/byobu/keybindings/f-keys.tmux，进行如下修改： 对下行内容进行修改： bind-key -n F2 new-window -c \u0026quot;#{pane_current_path}\u0026quot; \\; rename-window \u0026quot;-\u0026quot; 修改为： bind-key -n F2 new-windows -c $PWD \\; rename-window \u0026quot;-\u0026quot; 当然了，再次升级之后，上述配置信息会被覆盖，一种更好的办法是，将上述配置信息 写入到~/.byobu中的相关配置文件中。这样就不用每次升级之后，重新对其进行配置. ############################################################################# fedora 21, enable fan control: create conf file /etc/modprobe.d/thinkpad_acpi.conf, and add the following lines in it: options thinkpad_acpi fan_control=1 reboot. now you can use echo xxx \u0026gt; /proc/acpi/ibm/fan to control the fan speed, pay attention not to damage your hardware. ############################################################################# install input method: sogoupinyin, sogoupinyin-skins [myrepo] name=Sensor baseurl=https://gitcafe.com/sensor/myrepo/raw/master/fedora/$releasever/$basearch/ skip_if_unavailable=True gpgcheck=0 enabled=1 add aboved repo into /etc/yum.repos.d, yum install sogoupinyin sogoupinyin-skins. before doing this, you'd better remove all fcitx* to remove plugins that may conflict with sogoupinyin. and before yum install, remove ~/.config/fcitx to remove configuration files that may conflict with sogoupinyin. after yum install, you may find that sogou skins can't be set. copy all skins from /usr/share/sogou-qimpanel/recommendSkin/skin/ to ~/.config/sogou-qimpanel/skin/, this will solve the problem. ############################################################################# vim编写doc-like的文件: 简化版: filename.txt modeline, \u0026lt;Leader\u0026gt;h1, \u0026lt;Leader\u0026gt;h2 *tagname* |tagname| helptags `pwd`, \u0026lt;Leader\u0026gt;hh [[\\]] to jump 详细版： 最关键的只有2步，一个是将待编辑的文件的文件类型在模式行modeline中设置为help类 型；一个是通过*tagname*定制标签，然后在文档中的其他地方或者其他文档中引用的时 候，通过|tagname|来引用实现跳转（这部分实际是参考的add-local-help）。 上述2步是在编辑过程中比较重要的部分，另外一个，最最重要但是重要的不用提你也不 会忘记的就是，打开文件之后，记得运行helptags `pwd`为文件生成tags。也不要忘记开 启语法高亮等。说道这里的helptags `pwd`不得不提vim的运行方式，即vim只为扩展名为 txt的文件生成tags文件，所以记得将文件的扩展名修改为txt; 为了简化上述工作流程，我在vimrc里面定义了几个inoremap映射，分别是\u0026lt;Leader\u0026gt;h1和 \u0026lt;Leader\u0026gt;h2，h1表示help-begin，h2表示help-end。 之后在编辑文档的时候，按照前面锁提的2个关键点进行编辑就可以了。 为了更新tags文件，我自定了一个命令\u0026lt;Leader\u0026gt;hh用来更新tags文件，执行的实际上是命 令helptags `pwd`。 一般情况下，我们不希望使用vim的help命令之后的响应方式，那种方式的时候文件是只 读的、不可修改的，而且是以文档的方式半vim屏幕打开，看起来不方便，这种方式是通 过set helpfile=xxx来设置的，默认不设置的！ ############################################################################## caj转换为pdf cnki下载下来的论文大部分都是caj格式的，linux上使用wine运行cajviewer进行查看， 查看效果不佳，而且我现在都是使用mendeley对pdf格式论文统一进行管理，也便于查看 、注释等操作。 网上提供了一种方式，虚拟打印机，我在linux上面通过配置cups、cups-pdf来进行虚拟 pdf打印机管理，可以结合cajviewer中的打印功能，将caj格式的论文打印成pdf格式的， 然后导入到mendeley中，很方便！ cups管理web界面http://localhost:631。 ############################################################################## cnki网站使用asp.net进行开发，有的代码需要在用户端浏览器中进行运行（类似于java applet），需要java支持，但是linux版的chrome浏览器在38之后的，就已经移除了对旧 的java api接口的支持。所以打开某些asp页面的时候并没有打开页面，而是下载了页面 。 例如下载论文的链接，在chrome中点击了之后，是下载了asp页面文件，而不是对应的论 文。 解决办法：使用其他浏览器代替，例如使用firefox！ ############################################################################## chmod u+s/g+s，设置可执行位； chmod o+t/o-t，设置粘贴位，粘贴位主要是用来限制其他用户删除的，所以用o! 如果是对目录设置s、t，则ll显示权限的时候是小写的s、t，如果是目录的话，显示的是 S、T. 需要注意的是，由于s、S是设置的可执行位，因此目标文件应该由可执行权限才可以，否 则ll显示的时候，终端里面有红色背景色提示设置错误；粘贴位，再给目录设置了粘贴位 之后，其内部的所有文件的删除都只能由当前用户删除，其他无权限的用户不能删除、重 命名（当然root啥都可以）。 ############################################################################## vim配置相关： centos7中the-nerd-commenter的nerdtree不能够显示出来，提示说，NERDTreeToggle不 是一个vim的编辑命令。相同的配置在fedora21中是正常的。 后来在centos7下面的vim中又安装了一个新的插件，叫做The-NERD-tree的插件，安装好 之后，就可以显示了。 Something Strange! ############################################################################## ibus背景色问题： ibus输入框中的背景色，这个是在kde的相关颜色主题设置中进行的，具体地就是在系统 设置面板中的color部分进行设置的，修改某个颜色schema的selection background属性 对应的背景色即可。 ############################################################################## 安装nvidia官方驱动程序: 我的笔记本中是双显卡，通过optimus技术进行控制，图像渲染负载小的时候，直接使用 集成显卡（集成在intel处理器芯片内部的）进行渲染，但负载重的时候，使用独立显卡 进行渲染，并将计算后的数据送往集成显卡，集成显卡负责显示。 目前在双显卡的笔记本中安装nvidia驱动程序，当前有两个办法，比较好用。 1）只想使用集成显卡，那么可以通过安装acpi call禁用独立显卡。 2）如果只想使用独立显卡，那么可以通过bios禁用集成显卡，安装nvidia官方驱动强制 使用独立显卡；或者安装bumblebee，按需使用独立显卡。 当前看来，2）是一个不错的选择，但是使用2）的话，基本上平时都是使用的集成显卡， 如果要开启独立显卡，需要手动通过optirun yourprogram来运行，目前bumblebee还不能 够通过计算渲染负载来自动启动独立显卡。 针对此，我写了一篇博文,请在ChinaUnix下搜索《linux推广1:双显卡切换》。 ############################################################################## 在fedora21里面，不知道怎么回事，估计是plymouth自身的问题，我执行 plymouth-set-default-theme \u0026lt;theme-name\u0026gt; -R之后，并没有正确生成initramfs，为此 我自己手动生成。安装了一个hotdog主题之后，说什么也修改不了了，估计还是 plymouth-scripts自身的问题。 在/sbin目录下面添加了一些常用的脚本，例如update-grub2、update-initramfs。 ############################################################################## 安装pavccontrol对音量进行控制，非常好用的工具，可以调节每个程序的音量、虚拟机 的音量等等。 ############################################################################### pmap, 显示进程使用的内存映射！ ############################################################################## cherrytree中文汉化文件有误，我自己修改了一下： 下载cherrytree源代码，由于我之前已经向作者反应过存在的问题并提交了修改后的汉化 文件，作者也予以了合并但是现在还是没有被打包到官方源里面，官方软件源中仍然存在 错误。 我重新安装了系统，再次安装了cherrytree，发现还是存在相似的问题，于是将修改方法 重新记录了一下。 git clone https://github.com/hitzhangjie/CherryTree.git cherrytree cd cherrytree/locale ./i18n_pot_to_mo.py zh_CN.po 然后会生成很多的mo文件，并分别按照语言区域进行了划分，比如zh_CN\\en\\es等。 cd zh_CN/LC_MESSAGES sudo cp -f cherrytree.mo /usr/share/locale/zh_CN/LC_MESSAGES/cherrytree.mo 重新启动cherrytree即可！直接修改程序安装时的mo文件，cherrytree启动会失败，可能 是检查了某些校验和相关的信息吧！ ############################################################################## 当希望从系统中删除某个文件，而又不能确定该文件是否是某些软件残留的垃圾文件时， 可以通过yum provides $(file-path/file-name)来查看一下，如果检索结果不能显示该 文件所属的软件包，那么该文件就是垃圾文件无疑，可以直接删除，如果能检索到对应的 软件包的话，就需要慎重考虑一下了，有可能配置文件的删除会影响该软件包中软件的正 常运行。 ############################################################################## ImageMagic contains some tools to manipulate images. example: convert pdf to images /usr/bin/convert 100pages.pdf -append 1page.jpg ############################################################################## 关于安装了simsun字体之后，某些网站默认的字体族显示宋体为默认字体，konsole中也 是，其他某些应用程序中也是，这些字体在网页、konsole中看起来特别糟糕。但是在wps 或者某些其他中文程序又想通过明确指定simsun的方式来使用该字体，只是不希望默认使 用宋体作为显示。为此通过查阅man fonts-conf手册，对系统默认设置进行了修改，主要 包括如下几个地方： /usr/share/fontconfig/conf.avail/40-nonlatin.conf /usr/share/fontconfig/conf.avail/65-nonlatin.conf 将其中的跟simsun、nsimsun相关的字体描述注释掉，这样当某些希望请求中文字体的程 序请求serif、sans-serif、monospace时，就不会默认使用宋体来作为默认字体显示了， 因为找不到该字体的描述信息了，但是在某些特定的应用，例如wps中，我们明确指定使 用simsun字体作为字体的时候，不是通过serif、sans-serif、monospace来向系统请求获 取一个最佳匹配字体。 这种情况下，就满足了两种情况，即，明确指明使用simsun字体的程序依然可以使用 simsun字体，通过serif、sans-serif、monospace来请求一个最佳匹配的中文字体的时候 ，不能使用宋体。 ############################################################################## 之前搜索、批量删除文件的时候，一直使用的是find、xargs配合使用，前者完成搜索， 输出每一个匹配的文件，后者呢，则针对前者的每一行输出执行命令。但是刚才发现，这 样是有风险的，并且确实也已经对我造成了损失。我希望删除mendeley相关的内容，所以 使用find ~ -iname \u0026quot;*mendeley*\u0026quot; 进行搜索，然后将其通过管道输入给xargs rm -rf。 结果我发现命令执行之后，把我的Desktop文件夹给删除了，卧槽。原因是为什么呢？原 因就是前面的find命令再执行之后，匹配到了一个文件名Mendeley Desktop，因为文件名 中包含空格，xargs对其执行rm -rf指令的时候，实际上是执行的rm -rf Mendeley Desktop，而我刚好在～目录下，所以将Desktop文件夹删除了，坑爹吧！！！！！ 对啊，就是这么坑！以后希望批量删除的时候，先确认下有没有空格分割的文件名，免得 造成损失。后者，更靠谱的，利用find的-print0参数，文件名结束之后输出null结尾的 符号，同时xargs使用-0参数，以null作为分隔符进行处理，即： find ~ -iname \u0026quot;*mendeley*\u0026quot; -print0 | xargs -0 rm -rf 吃一堑长一智。 ############################################################################## linux相关的一些权威论坛： cpan.org:权威的perl模块库 freshmeat.net:linux/unix的软件的海量索引库 kernel.org:linux内核的官方网站 linux.com:linux论坛,适合新用户 linux.org:linux一般信息交换地 linux.slashdot.org:技术新闻巨头slashdot针对linux的网站 linuxhq.com:有关内河的信息和补丁的汇编 lwn.net:linux和开放源代码方面的通讯社 securityfocus.com:计算机安全方面的一般信息 serverfault.com:针对系统管理问题而分工协作编辑的数据库 serverfiles.com:网络管理软件和硬件的目录 slashdot.org:各类技术新闻 ugu.com:unix guru universe(unix高手大世界)--所有内容都好系统管理有关 ############################################################################## \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD apt \u0026amp; yum，类似的操作，总结： 1. Simple conversions: * apt-get install ~= yum install * apt-get upgrade ~= yum upgrade * apt-get remove ~= yum remove * apt-get --reinstall install ~= yum reinstall * apt-get install foo=1.0 ~= yum downgrade foo-1.0 * apt-get clean ~= yum clean * apt-get build-dep ~= yum-builddep * dpkg -l ~= yum list installed * apt-cache search ~= yum search * apt-cache search --names-only ~= yum list ~= repoquery * dpkg -L ~= rpm -ql * apt-file list ~= repoquery -l 2. Not so Simple conversions: * apt-cache show ~= yum info ~= repoquery -i * apt-get purge ~= yum remove * apt-get dist-upgrade ~= yum upgrade ~= yum distro-sync * apt-get source ~= yumdownloader --source * dpkg --get-selections ~= yum-debug-dump * dpkg --set-selections ~= yum-debug-restore * dpkg -S ~= repoquery --installed -f ~= rpm -qf * apt-file search ~= repoquery -f ~= yum provides * apt-get --simulate upgrade ~= yum check-update ~= yum --assumeno upgrade * apt-get --simulate install ~= yum --assumeno install * sbuild ~= mock ############################################################################## use alien to convert a *.deb package to *.rpm package. for example, I download a xmind.deb, then I want to convert it to rpm, why? Because official site does not package the software to rpm. How to? 1 install alien、rpmrebuild 2 alien -r --scripts xmind.deb, the xmind.rpm will be generated 3 after step 2, I tried to install it, but it said: file /usr/bin/, /usr/lib/ conflicts with the files in package filesystem.rpm, we can fix it by rpmrebuild. 4 rpmrebuild -pe xmind.rpm, then it will use vim to edit configuration, I commented out the line 'attr .... /usr/bin' and line 'attr .... /usr/lib', save and exit, and continue rebuild. 5 after step 4, new rpm package will be generated under ~/rpmbuild directory. Try to install it and enjoy yourself. ############################################################################## apt-get没有提供类似于yum history的命令选项，那么我们如何查看历史信息呢？可以通 过/var/log/apt/history进行查看，然后通过一些方法对其历史信息进行处理，比如批量 删除已经安装的软件等等。 ############################################################################## mbuntun可以将基于unity的ubuntu进行深度定制，将界面打造成osx一样的风格，其中 synapse可以配合xdotool来提供快捷键支持。 ############################################################################## kwin cool effect avoid one frame blinking 1. fedora21: replace isfadeWindow with following definition: { return !window.deleted \u0026amp;\u0026amp; !window.desktopWindow \u0026amp;\u0026amp; window.onCurrentDesktop \u0026amp;\u0026amp; window.visible \u0026amp;\u0026amp; !window.skipSwitcher \u0026amp;\u0026amp; !window.utility \u0026amp;\u0026amp; !effect.isGrabbed(window, Effect.WindowAddedGrabRole) \u0026amp;\u0026amp; !effect.isGrabbed(window, Effect.WindowClosedGrabRole) \u0026amp;\u0026amp; !CoolEffect.isLoginWindow(window); } 2. CentOS7: ... ############################################################################## mount Mac OSX hfsplus filesystem on Linux mount -t hfsplus -o force,rw /dev/osx-partition /mount-point ############################################################################## 当遇到wifi/bluetooth rfkill的问题的时候，直接关闭wifi的硬件开关，然后重新启动 电脑，重新启动并进入系统之后，再打开硬件开关，如果此时执行rfkill list all显示 设备仍然被soft block，则执行rfkill unblock all即可，如果已经显示没有软锁，那么 就ok了。 linux内核在启动的时候，好像是期望hard block/soft block为true！ rfkill list all rfkill unblock all 备注：奇葩！在火车上通过笔记本给手机充电的时候，笔记本开着为了减少电量消耗，关 闭了wifi硬件开关，之后笔记本没电休眠了，后来重新接上电源之后，不管是windows下 还是linux下，都打不开无线网卡。后来，把外接电源拔掉，笔记本电池也拆掉，再安装 上电池，重新启动，蓝牙、wifi就可以打开了。 这是联想的问题吗？联想，联想个蛋蛋！ ############################################################################## dolphin里面搜索文件，如果文件名中包含空格的话，就搜索不出来，这个问题的原因可 能是由于Desktop Search功能导致的，直接通过系统设置里面，禁用Desktop Search功能 就可以解决这个问题。 不确定具体的原因是什么，现在也无法对其进行补丁修复了，后续版本的fedora或者kde 中可能修复这个问题。 补充：后来我发现Desktop Search里面可以通过配置哪些位置禁用Desktop Search来实现 ，这样Dolphin也可以正确进行搜索。 ############################################################################## 移除kde桌面右上角的desktop toolbox，这个玩意没有什么用，因为在右键菜单里面、面 板上都可以调出类似的工具箱来。留着它，一不小心点到了就挺啰嗦，还需要再点一下才 能取消对应的操作。 如何移除呢？将/usr/share/kde4/services/plasma-toolbox-desktoptoolbox.desktop重 命名一下就可以了。我习惯性地将其重命名为${previous-name}.bak。 ############################################################################## 2016-03-11 01:41:49 AM 今天笔记本thinkpad t420s出了个怪事，就是我一用力按c壳右下角，无线网卡、蓝牙就 被关掉，松开一会就又重新被打开。我猜可能是线路接触不良，于是拆开之后重新接了下 线，问题解决！ ############################################################################## 2016-03-12 02:23:31 PM kdemenuedit对菜单进行配置，有时更换菜单图标之后，如果图标完整路径+图标名称与之 前旧的图标相同的话，菜单的图标还是以前旧的图标，而不是最新的图标，这个问题是由 于kde使用kbuildsycoca4对系统中的图标等资源进行增量配置，一个最好最简单的办法就 是直接进入/var/tmp/kdecache-${username}目录下，直接删除icon-cache.kcache，然后 logout、login即可解决图标缓存的问题。 这个也从侧面说明了bleachbit等清理工具的不靠谱! ############################################################################## 2016-03-12 11:40:58 PM mendeley desktop中对文档进行批注之后，如果不小心改变了文档所在的文件夹的名称， 就是路径变动之后，mendeley就会找不到原来文件的情形，点击也打不开文档，这个时候 只要重新点击details-\u0026gt;添加文档就可以了，千万不要点击移除文档，然后再添加，因为 一点击移除文档，mendeley就会删除对应的批注信息！！！！！ ############################################################################## 字体配置的时候,有几个地方需要特别注意，konsole中显示中文不正常，这个问题是因为 缺乏必须的字体导致的，从windows下面复制必要的中文字体粘贴到当前用户的.fonts目 录下，或者点击直接安装，然后到/usr/share/fontconfig/conf.avail/目录下将simsun 字体屏蔽即可！ 其实有一个更好的办法，可以在终端中使用WenQuanYi Micro Hei字体来显示中文，具体 设置方法就是修改/usr/share/fontconfig/conf.avail/65-nonlatin.conf，在所有的 simsun、nsimsun前面添加\u0026lt;family\u0026gt;WenQuanYi Micro Hei\u0026lt;/family\u0026gt;，这样就可以在使用各个字体族的时候，中文都默认使用WenQuanYi Micro Hei来显示了。 其实关于字形、字体、字体族的概念，还是很容易混淆的，还有就是系统对字体的搜索、 替换过程，可能更让人摸不着头脑，不管怎么样，这都是小事，自己改成自己需要的配置 就可以了。 ############################################################################## 2016-03-17 01:03:39 PM 关于vim的详细配置过程，请参考当前的vimrc配置说明进行一下总结，最好能够整理成文 档的形式，整理好之后，会在此处进行一下说明，并把其中的关键插件进行一下描述！ ############################################################################## 2016-03-17 03:51:10 PM cherrytree的工具栏不显示的问题，图形界面中没有找到可以从哪里进行设置，直接修改 .config/cherrytree将其中的toolbar 是否visible修改为True即可。 ############################################################################## rpmdb altered outside ... 这个问题可以直接通过yum clean all解决。 这个问题的原因是由于有的程序直接使用了rpm或者用户直接使用了rpm进行操作，没有通 过yum提供的操作接口。为什么要加这个提醒呢，这是因为如果直接通过rpm进行修改， yum中是看不到修改记录的，yum history sync之后也是看不到的，为了防止电脑被黑后 rpmdb被篡改植入恶意软件，为了让用户能够尽快看到这个rpmdb被修改的情况，所以yum 中加入了这个检查！当然你可以关掉这个，在/etc/yum.conf中添加history_record=0， 但是这样之后，yum history相关的所有的命令就都不能使用了。 ############################################################################## 2016-03-18 04:06:59 PM 安装了maya2016之后，启动的时候无法启动，一个是要安装libXp这个库，然后提示缺少 libtiff.so.3，通过yum list libtiff，检查了一下，只有4.0.3的包了，没有3.x的包， 所以直接创建了一个符号链接ln -s libtiff.so.5.0.2 libtiff.so.3，然后maya就可以 成功启动了。 ############################################################################## 2016-04-13 02:01:22 AM kde菜单中的程序启动的时候，是不会加载.bash_profile或者.bashrc中的变量的，因为 前者是给登陆shell用的，后者是给非登陆shell用的（当然对于登陆shell，先source前 者再source后者），而kde中的gui程序启动的时候，如果直接从菜单中启动而非从shell 中启动，那么是不会获得在上述两个脚本中的环境变量的。 kde中的这部分环境变量应该在~/.kde/env/xxx.sh中进行设置，在里面直接协商export xxxx=xxx将变量导出即可. ############################################################################## 2016-04-17 02:15:11 AM in vim, ':scriptnames' can list the sourced scripts in order, which will help us judge where problem occurs. ':help initialization' can also help us realize the detailed initialization process when starting vim. ############################################################################## 2016-04-17 02:39:03 AM vim misunderstand *.md files as modula2 filetype? edit /usr/share/vim/vim74/ftplugin.vim: change from 'README.md' to '*.md' for markdown; delete '*.md' from filetype modula2! ############################################################################## 2016-04-18 01:45:19 PM delete duplicate 'places' in dolphine save file dialog \u0026quot;.kde/share/apps/kfileplaces/bookmarks.xml\u0026quot; delete this file or manually remove dupliate 'places' entries, remove bookmarks.tbcache. then you should restart 'display manager', then login again. remember, just logout/login may not work! ############################################################################## 2016-04-24 12:01:41 AM 增加VBox中虚拟机的磁盘容量： 1. 创建新的数据盘，这种容易操作，可以直接在VirtualBox图形用户界面中完成； 备注： 这种方式重新创建新的数据盘是可以的，但是假如我们把系统等所有的东西安装一个分区 中，系统要升级，就得占用一定的新的空间，例如Mac OS X升级，实际上我也是在这个时 候碰到这个问题的，这个时候创建新的数据盘是没有用的。 而且很多时候，我们只是希望扩展现有的磁盘空间的容量，而不是重新增加新的数据盘， 那么怎么修改呢？VBox v4.0以上的版本可以灵活地对其进行修改。 VBoxManage modifyhd \u0026quot;filename.vdi\u0026quot; --resize ${nnnn}，其中${nnnn}的单位是MB。 重新启动VirtualBox就可以看到虚拟机对应的最大磁盘容量的大小发生了变化。 ############################################################################## 2016-04-24 02:48:59 PM /usr/src/Kernels下的源代码，在安装文件kernel-devel-$(uname -r).rpm中，而不是在 kernel-$(uname -r).src.rpm中。 另外关于kernel-headers-$(uname -r).rpm，官方库中没有的时候，虽然系统运行不怎么 受影响，因为已经编译好了嘛，但是新的需要重新构建内核模块的程序，仍然希望 kernel-headers与当前运行内核版本一致，所以应该通过搜索某些repo或者直接搜索rpm 包来安装匹配的版本。 ############################################################################## 2016-04-24 05:28:40 PM 谷歌浏览器有一个配置文件叫做Local State，里面有个protocol_handler定义好了处理 特定协议的方式，例如\u0026quot;thunder\u0026quot;，当希望重新设置对其处理方式时，可以将浏览器关闭 ，然后删除该配置文件中的相应条目，重启浏览器再点击一下这种类型的链接就可以了。 ############################################################################## 2016-05-07 12:56:18 PM vim *rawhide* :zz it outputs: one more file to edit? :next or :prev to move between differenet files being edited. ############################################################################## 2016-05-08 04:58:16 PM fedora 21中将桌面背景设置为marble，结果一直报错；但是新建一个用户，在这个新用 户下进行这种操作，就没有问题。这是一个好办法，在解决桌面环境相关问题时，通过新 建一个用户，在干净的环境里面进行配置容易发现问题。最后我将现在用户中的 .kde/share/config/plasma-desktop-appletsrc直接删除，然后重新登陆，问题解决。 ############################################################################## 2016-05-08 05:02:20 PM kde中的activity，好像是专门为设置不同的电源管理模式而准备的，因为我在看kde的相 关帮助手册的时候仅发现了activity与电源管理设置相关。activity相关的设置仅仅出现 在系统设置的电源管理部分。 之前，我还以为activity有什么大的作用呢？原来是为了设置不同的电源管理模式。 补充：不对啊，还是之前理解的对，activity确实是虚拟桌面的一个超集，activity就是 相当于一个活动，你可以在里面设置希望用到的程序等等。不过我不喜欢这种东西，太过 复杂了也不好，我觉得虚拟桌面已经差不多够用了，而且，我们很难把工作分的那么清楚 ，例如一边听歌一边工作。特别的工作可能需要另当别论，比如协作或者编程。根据自己 情况选择吧。针对不同的activity，可以指定不同的电源管理模式。 ############################################################################## 2016-05-10 01:02:32 PM HIBERNATE MODE Vs SLEEP MODE While sleep puts your work and settings in memory and draws a small amount of power, hibernation puts your open documents and programs on your hard disk, and then turns off your computer. Of all the power-saving states in Windows, hibernation uses the least amount of power. 也就是说睡眠模式，是将当前系统状态驻留到内存中，仍然会耗费一定的电力；休眠模式 会将当前系统状态保存到磁盘，并关机，当按了开机按键之后，系统读取磁盘上保留的系 统状态，并恢复到内存中。 ############################################################################## 2016-05-14 06:07:19 PM 使用vim-instant-markdown的时候，如果文件中引用了图片，浏览器也存在缓存的问题， 如果要替换一个图片文件的话，最好是通过修改文件名，这样立即就可以生效，你不可能 说是让浏览器禁用缓存功能吧，那以后访问网页就太慢了。另外如果确实还是希望使用跟 以前相同的文件名，清理一下浏览器图片缓存就可以了。 ############################################################################## 2016-06-13 05:30:27 PM update-grub2 generates wrong UUID for 'linux16 ... root=UUID=xxxxx'. why? when modify disk partitions, new uuid will be generated! but where is it stored, some people say uuids will be stored into superblock of partitions. after that, blkid can inspect it, and update-grub2 also can inspect it. but why in grub.cfg, 'search xxxxx uuid=xxxx' is right, but 'linux16 ... root=UUID=xxxx' is wrong. I am still confused. it is more likely that grub2-mkconfig contains a bug. how to resolve it? mannually edit the file 'grub.cfg', and boot system, then re-install grub to /dev/sdx, then reboot into another system and exec update-grub2 again. ############################################################################## 2016-06-17 08:24:06 PM 安装cscope之后，当通过vim查看源代码并根据tag进行跳转的时候，cscope插件会将定义 这个tag的所有文件以列表的形式显示出来，让用户选择然后再跳转；ctags是直接跳转到 第一个中去。很明显cscope这种方式更加友好。 ############################################################################## 2016-07-14 07:33:55 AM markdown中预览的时候经常该发现vim编写的文件中不同的字符之间如果存在一个断行操 作则在markdown中进行预览操作的时候，常常会在newline前后的字符之间出现一个空格 ，经过测试，这个问题出现在“汉字-newline-汉字”这种情形之下，英文的时候不会出现 问题。应该与vimrc中的换行操作无关。 根本原因是，vim中会将newline当做一个空格来进行处理，这对于英文单词之间的 newline来说当做换行进行处理是完全没有问题的，而且是相当好的处理方式，但是对于 中文来说就不是这样了，因为我们中文习惯中，中文的每个字符之间都是没有空格进行分 隔的。 总结一下，这个问题是vim对中文字符处理的问题，以及vim对markdown支持的问题，不是 什么大问题，在写文档的时候依然可以继续使用这种编辑方式，希望以后vim能够改进这 一功能。 备注： 另外，对于markdown文件，可以安装discount命令行工具，利用命令discount-mkd2html 将markdown文件转换为html文件。 ############################################################################## 2016-08-10 12:14:47 AM CentOS common repos: official: CentOS-Base.repo CentOS-Debuginfo.repo CentOS-fasttrack.repo CentOS-Sources.repo CentOS-Vault.repo CentOS-fasttrack.repo CentOS-CR.repo epel.repo epel-testing.repo 3rd: nux-desktop.repo elrepo.repo bad: rpmfusion-free-updates.repo rpmfusion-free-update-testing.repo rpmfusion-nonfree-updates.repo rpmfusion-nonfree-update-testing.repo ############################################################################## 2016-08-10 08:25:36 AM install java master and slave links. #!/bin/bash update-alternatives --install /usr/bin/java java /usr/java/jdk1.7.0_71/bin/java 1000 \\ --slave /usr/bin/appletviewer appletviewer /usr/java/jdk1.7.0_71/bin/appletviewer \\ --slave /usr/bin/apt apt /usr/java/jdk1.7.0_71/bin/apt \\ --slave /usr/bin/ControlPanel ControlPanel /usr/java/jdk1.7.0_71/bin/jcontrol \\ --slave /usr/bin/extcheck extcheck /usr/java/jdk1.7.0_71/bin/extcheck \\ --slave /usr/bin/idlj idlj /usr/java/jdk1.7.0_71/bin/idlj \\ --slave /usr/bin/jar jar /usr/java/jdk1.7.0_71/bin/jar \\ --slave /usr/bin/jarsigner jarsigner /usr/java/jdk1.7.0_71/bin/jarsigner \\ --slave /usr/bin/javac javac /usr/java/jdk1.7.0_71/bin/javac \\ --slave /usr/bin/javadoc javadoc /usr/java/jdk1.7.0_71/bin/javadoc \\ --slave /usr/bin/javafxpackager javafxpackager /usr/java/jdk1.7.0_71/bin/javafxpackager \\ --slave /usr/bin/javah javah /usr/java/jdk1.7.0_71/bin/javah \\ --slave /usr/bin/javap javap /usr/java/jdk1.7.0_71/bin/javap \\ --slave /usr/bin/java-rmi.cgi java-rmi.cgi /usr/java/jdk1.7.0_71/bin/java-rmi.cgi \\ --slave /usr/bin/javaws javaws /usr/java/jdk1.7.0_71/bin/javaws \\ --slave /usr/bin/jcmd jcmd /usr/java/jdk1.7.0_71/bin/jcmd \\ --slave /usr/bin/jconsole jconsole /usr/java/jdk1.7.0_71/bin/jconsole \\ --slave /usr/bin/jcontrol jcontrol /usr/java/jdk1.7.0_71/bin/jcontrol \\ --slave /usr/bin/jdb jdb /usr/java/jdk1.7.0_71/bin/jdb \\ --slave /usr/bin/jhat jhat /usr/java/jdk1.7.0_71/bin/jhat \\ --slave /usr/bin/jinfo jinfo /usr/java/jdk1.7.0_71/bin/jinfo \\ --slave /usr/bin/jmap jmap /usr/java/jdk1.7.0_71/bin/jmap \\ --slave /usr/bin/jmc jmc /usr/java/jdk1.7.0_71/bin/jmc \\ --slave /usr/bin/jmc.ini jmc.ini /usr/java/jdk1.7.0_71/bin/jmc.ini \\ --slave /usr/bin/jps jps /usr/java/jdk1.7.0_71/bin/jps \\ --slave /usr/bin/jrunscript jrunscript /usr/java/jdk1.7.0_71/bin/jrunscript \\ --slave /usr/bin/jsadebugd jsadebugd /usr/java/jdk1.7.0_71/bin/jsadebugd \\ --slave /usr/bin/jstack jstack /usr/java/jdk1.7.0_71/bin/jstack \\ --slave /usr/bin/jstat jstat /usr/java/jdk1.7.0_71/bin/jstat \\ --slave /usr/bin/jstatd jstatd /usr/java/jdk1.7.0_71/bin/jstatd \\ --slave /usr/bin/jvisualvm jvisualvm /usr/java/jdk1.7.0_71/bin/jvisualvm \\ --slave /usr/bin/keytool keytool /usr/java/jdk1.7.0_71/bin/keytool \\ --slave /usr/bin/native2ascii native2ascii /usr/java/jdk1.7.0_71/bin/native2ascii \\ --slave /usr/bin/orbd orbd /usr/java/jdk1.7.0_71/bin/orbd \\ --slave /usr/bin/pack200 pack200 /usr/java/jdk1.7.0_71/bin/pack200 \\ --slave /usr/bin/policytool policytool /usr/java/jdk1.7.0_71/bin/policytool \\ --slave /usr/bin/rmic rmic /usr/java/jdk1.7.0_71/bin/rmic \\ --slave /usr/bin/rmid rmid /usr/java/jdk1.7.0_71/bin/rmid \\ --slave /usr/bin/rmiregistry rmiregistry /usr/java/jdk1.7.0_71/bin/rmiregistry \\ --slave /usr/bin/schemagen schemagen /usr/java/jdk1.7.0_71/bin/schemagen \\ --slave /usr/bin/serialver serialver /usr/java/jdk1.7.0_71/bin/serialver \\ --slave /usr/bin/servertool servertool /usr/java/jdk1.7.0_71/bin/servertool \\ --slave /usr/bin/tnameserv tnameserv /usr/java/jdk1.7.0_71/bin/tnameserv \\ --slave /usr/bin/unpack200 unpack200 /usr/java/jdk1.7.0_71/bin/unpack200 \\ --slave /usr/bin/wsgen wsgen /usr/java/jdk1.7.0_71/bin/wsgen \\ --slave /usr/bin/wsimport wsimport /usr/java/jdk1.7.0_71/bin/wsimport \\ --slave /usr/bin/xjc xjc /usr/java/jdk1.7.0_71/bin/xjc ############################################################################## 2016-08-24 14:05:34 in OSX, how to speed up your input? defautls write NSGlobalDomain KeyRepeat -int 1	: repeat rate defaults write NSGlobalDomain InitialKeyRepeat -int 8	: repeat delay then logout/login again! ############################################################################## 2016-10-08 00:53:29 osx下面没有提供像linux中update-alternatives的软件多版本控制软件，但是homebrew 提供了一个可以管理多个jdk版本的工具jenv，jdk的安装还是要自己安装，只是通过jenv add来注册当前系统中可用的jdk版本，然后必要的时候可以通过jenv local ${ver}或者 jenv global ${ver}来设置当前shell或者系统全局使用的jdk版本。 为什么要安装多个版本呢？必要性自不必提。我需要安装多个版本，为啥？jdk1.8是趋势 ，但是很多框架尤其是依赖于字节码底层操作的框架对jdk版本依赖性很强，比如kilim， 主要是其依赖asm这个字节码框架。kilim必须使用jdk1.7进行编译、测试，1.8会抛异常。 ############################################################################## 2017-04-02 22:32:50 +0800 之前安装的vim的markdown预览插件，不能很好地对特殊字符\u0026amp;和\u0026lt;进行处理，通过修改文 件/usr/local/lib/node_modules/instant-markdown-d来修复这个问题。 { var body = ''; { body += data; { throw new Error('The request body is too long.'); } }); { // 自动转换markdown中的特殊字符\u0026amp;和\u0026lt;，Enjoy it！ body = body.replace(/\u0026amp;/g, '\u0026amp;amp;'); // 转换\u0026amp; body = body.replace(/\u0026lt;/g, '\u0026amp;lt;'); // 转换\u0026lt; output.emit('newContent', md.render(body)); }); }  "}),a.add({id:531,href:"/blog/2021-04-19-go-sync.mutex%E8%AE%BE%E8%AE%A1%E5%AE%9E%E7%8E%B0/",title:"",description:"终于来到了go语言相关的设计实现，go中sync.Mutex的设计有很多设计方面的考虑。\n我们看下对应的加锁解锁部分，对应的源码 see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L72\n首先，了解下锁的定义，我们看到里面有个state字段，这个字段表示的是锁的状态，为0表示锁是解锁状态，其他状态可以参考下源码中的定义。\n// A Mutex is a mutual exclusion lcok. // The zero value for a Mutex is an unlocked mutex. // // A Mutex must not be copied after first use. type Mutext struct { state	int32 sema	uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota )  下面看下加解锁实现，多注意下state相关的逻辑，比较容易好理解。\nmutex.Lock() # fastpath # 首先，会执行fastpath，会尝试CAS加锁一次，如果没有很多锁竞争，且锁处于未加锁状态（state=0），大概率会加锁成功（state=1）成功返回。\n如果fastpath加锁失败了，比如尝试加锁前state != 0：",content:"终于来到了go语言相关的设计实现，go中sync.Mutex的设计有很多设计方面的考虑。\n我们看下对应的加锁解锁部分，对应的源码 see https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L72\n首先，了解下锁的定义，我们看到里面有个state字段，这个字段表示的是锁的状态，为0表示锁是解锁状态，其他状态可以参考下源码中的定义。\n// A Mutex is a mutual exclusion lcok. // The zero value for a Mutex is an unlocked mutex. // // A Mutex must not be copied after first use. type Mutext struct { state	int32 sema	uint32 } const ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota )  下面看下加解锁实现，多注意下state相关的逻辑，比较容易好理解。\nmutex.Lock() # fastpath # 首先，会执行fastpath，会尝试CAS加锁一次，如果没有很多锁竞争，且锁处于未加锁状态（state=0），大概率会加锁成功（state=1）成功返回。\n如果fastpath加锁失败了，比如尝试加锁前state != 0：\n  state可能为1\n此时，表示锁已经被锁定，新goroutine尝试加锁请求失败，这种很好理解；\n  state != 0，但也不是1（mutexLocked）\n这种情况就比较特殊了，涉及到go的一些锁优化，拿个例子来说一下。比如state有可能为4（mutexStarving），即它确实处于解锁状态(state\u0026amp;mutexLocked=0)，但却处于starvation模式下，这说明之前有尝试加锁的goroutine很久没有拿到锁了，所以将当前锁的模式从normal修改为了starvation。\n为了避免调度延迟过大，go会优先受理部分goroutine的加锁请求，所以，这种情况新加入抢锁的goroutine也是不能拿到锁的。\n  OK，有了这个大致的了解之后，我们继续看加锁失败后的处理路径，继续执行slowpath。\n// Lock locks m. // If the lock is already in use, the calling goroutine // blocks until the mutex is available. func (m *Mutex) Lock() { // Fast path: grab unlocked mutex. if atomic.CompareAndSwapInt32(\u0026amp;m.state, 0, mutexLocked) { if race.Enabled { race.Acquire(unsafe.Pointer(m)) } return } // Slow path (outlined so that the fast path can be inlined) m.lockSlow() }  slowpath # 这部分就有很多优化措施了，感兴趣的可以阅读这里的源码，我们先尝试总结下。\nsee https://sourcegraph.com/github.com/golang/go/-/blob/src/sync/mutex.go#L84\nfunc (m *Mutex) lockSlow() { ... old := m.state for { // Don't spin in starvation mode, ownership is handed off to waiters // so we won't be able to acquire the mutex anyway. if old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { // Active spinning makes sense. // Try to set mutexWoken flag to inform Unlock // to not wake other blocked goroutines. if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state continue } ... } ... }  加锁失败后，失败原因有多种，要么是锁已经被锁定了，要么是处于饥饿模式。对应的处理方式也不一样，所以开头先判断下。\n如果old\u0026amp;(mutexLocked|mutexStarvig) == mutexLocked为true，则表示之前加锁的失败原因是，锁已经被锁定了。那怎么办呢？难道要让goroutine立即去睡觉觉？goroutine睡着后再被唤醒参与调度这个开销和线程比是小，但是还是有的嘛，能不能再尝试几次，避免过早睡眠？当然可以。\n那就让当前goroutine自旋+重新加锁几次试试，就是这里的runtime_canSpin(iter)来控制能否自旋了。\n// Active spinning for sync.Mutex. //go:linkname sync_runtime_canSpin sync.runtime_canSpin //go:nosplit func sync_runtime_canSpin(i int) bool { // sync.Mutex is cooperative, so we are conservative with spinning. // Spin only few times and only if running on a multicore machine and // GOMAXPROCS\u0026gt;1 and there is at least one other running P and local runq is empty. // As opposed to runtime mutex we don't do passive spinning here, // because there can be work on global runq or on other Ps. if i \u0026gt;= active_spin || ncpu \u0026lt;= 1 || gomaxprocs \u0026lt;= int32(sched.npidle+sched.nmspinning)+1 { return false } if p := getg().m.p.ptr(); !runqempty(p) { return false } return true }  最多自旋4次，当然还有其他要求，就是必须运行在多核机器上，并且GOMAXPROCS\u0026gt;1，并且至少有另外一个正在运行的P且其runq为空。大家可以想一下为什么？如果不这么限制，那谁来释放锁呢，当前goroutine大概率自旋无效，也优化不了什么。\n这些条件满足时，检查当前g运行的P上runq是否为空，如果为空才允许自旋，为什么？会影响到runq中的goroutine的调度执行吧。\n最后再看lockSlow中的代码逻辑：\nfunc (m *Mutex) lockSlow() { ... old := m.state for { if old\u0026amp;(mutexLocked|mutexStarving) == mutexLocked \u0026amp;\u0026amp; runtime_canSpin(iter) { // Active spinning makes sense. // Try to set mutexWoken flag to inform Unlock // to not wake other blocked goroutines. if !awoke \u0026amp;\u0026amp; old\u0026amp;mutexWoken == 0 \u0026amp;\u0026amp; old\u0026gt;\u0026gt;mutexWaiterShift != 0 \u0026amp;\u0026amp; atomic.CompareAndSwapInt32(\u0026amp;m.state, old, old|mutexWoken) { awoke = true } runtime_doSpin() iter++ old = m.state continue } ... } ... }  大家看刚开加锁失败后awoke=false, 并且假定old=mutexLocked，old\u0026raquo;mutexWaiterShift这个写法，让人猜测m.state中还存储了waiter相关的信息，然后尝试将m.state设置上mutexWoken，awoke=true，没看出这是在干啥。\n然后runtime_doSpin开始空转CPU，可以理解成一个for循环从30减到0，结束。这么做无非就是想等其他goroutine把锁释放掉。\nconst ( active_spin_cnt = 30 ) //go:linkname sync_runtime_doSpin sync.runtime_doSpin //go:nosplit func sync_runtime_doSpin() { procyield(active_spin_cnt) } func procyield(cycles uint32) TEXT runtime·procyield(SB),NOSPLIT,$0-0 MOVL	cycles+0(FP), AX again: PAUSE SUBL	$1, AX JNZ	again RET  然后iter++，表示自旋次数+1（最多4次），更新锁状态，注意此时mutexWoken设置了，现在可以猜测下mutexWoken表示啥了，它表示的是mutex有没有唤醒协程来抢锁。\n自旋之后continue，进入循环体的下一次循环，继续检查锁的状态：\n 如果锁依旧被锁定，且当前可以继续自旋，则继续自旋； 如果锁依旧被锁定，且当前超过了自旋次数，则执行下面的逻辑； 如果锁被解锁了，则也执行下面的逻辑；  下面的new表示当前代码执行完后锁的状态，有这么几种情况：\n 锁还没被释放，锁必然处于锁定状态，new\u0026amp;mutexLocked==1； 锁已经被释放，锁如果处于normal模式，当前goroutine必抢锁成功，所以new|=mutexLocked也很好理解； 锁已经被释放，锁如果处于starvation模式，当前goroutine抢锁失败，入队等待，但是这个锁将直接递交给等待队列中的第一个waiter，不用这个waiter被唤醒后抢锁，所以其new|=mutexLocked没什么疑问了；  继续看waiter标志位相关的设置：检查old状态，如果仍是锁定或者饿死状态，则直接将new中设置mutexWaiter标记。干嘛用的，表示有waiter在等待锁释放啊。\n继续看starvation标志位相关的设置：如果发现锁之前的状态就是饥饿模式了，并且没有被锁定，那么锁的最新状态还是饥饿模式（new|=mutexStarving岂不是多余？）\nfunc (m *Mutex) lockSlow() { ... old := m.state for { new := old // Don't try to acquire starving mutex, new arriving goroutines must queue. if old\u0026amp;mutexStarving == 0 { new |= mutexLocked } if old\u0026amp;(mutexLocked|mutexStarving) != 0 { new += 1 \u0026lt;\u0026lt; mutexWaiterShift } // The current goroutine switches mutex to starvation mode. // But if the mutex is currently unlocked, don't do the switch. // Unlock expects that starving mutex has waiters, which will not // be true in this case. if starving \u0026amp;\u0026amp; old\u0026amp;mutexLocked != 0 { new |= mutexStarving } ... } .... }  继续看，如果当前mutex已经有被唤醒的goroutine尝试抢锁，那么new里面mutexWoken应该为1，如果为0是一种不一致状态，报错。然后从new中清除这一标记位，也需mutexwoken代表的就是当前goroutine吧，一次唤醒一个嘛。\nfunc (m *Mutex) lockSlow() { ... old := m.state for { new := old ... if awoke { // The goroutine has been woken from sleep, // so we need to reset the flag in either case. if new\u0026amp;mutexWoken == 0 { throw(\u0026quot;sync: inconsistent mutex state\u0026quot;) } new \u0026amp;^= mutexWoken } ... } ... }  继续看，CAS更新下锁状态m.state，注意此时new里面设置了locked（starvation可能有也可能没有）。\n继续检查，如果之前锁状态不是锁定状态、不是饥饿状态，那么现在肯定就是锁定成功了，退出循环结束加锁过程。\n如果发现waitStartTime不为0，说明之前已经有几轮循环来尝试过获得锁了，现在要算一下当前这次加锁操作总共等待了多久了。\nfunc (m *Mutex) lockSlow() { var waitStartTime int64 ... old := m.state for { new := old ... if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { if old\u0026amp;(mutexLocked|mutexStarving) == 0 { break // locked the mutex with CAS } // If we were already waiting before, queue at the front of the queue. queueLifo := waitStartTime != 0 if waitStartTime == 0 { waitStartTime = runtime_nanotime() } ... } ... } ... }  现在来算一下当前goroutine加锁等待了多久了，这个时间很好算，直接拿当前时间减去第第一次开始的时间就算出来了，runtime_nanotime()-waitStartTime()，并且发现，如果这个时间超过阈值1ms，就会将starving设为true，意味着mutex将被设置为饥饿模式，当然如果以前就是饥饿模式，现在肯定也是饥饿模式了。\n另外注意queueLifo的值，如果是新抢锁的goroutine，那么为false，调用runtime_Semacquire时会将该goroutine假如到队列的末尾排队，如果是之前唤醒过的goroutine，则会将其添加到队列的对首，如果锁变成了饥饿模式且被释放了，则直接交给对首的goroutine执行。\n这个函数runtime_semacquiremutex，还挺关键的：\n信号量semaroot好理解，它是地址addr处对应的信号量，本身内部维护了一个等待信号量的sudog（等待执行的g）列表，对mutex而言就是等待抢锁的goroutines/waiters列表。\nmutex里面为什么要加一个字段sema，其实就是为了间接具备这样一种能力，维护一个\u0026amp;sema的信号量，维护一个因为抢锁而阻塞的goroutine列表，以方便在锁被释放的时候，再把它们唤醒。\n看下这个函数是怎么实现的吧，它调用了semacquire1这个函数，这个函数内部就是获得\u0026amp;addr处对应的信号量，然后尝试对semaroot.lock加锁，这个锁是一个runtime.mutex，\n我擦，我发现这个函数里面调用了semacquire1(\u0026hellip;)，这个函数里面调用了lockWithRank，lockWithRank调用了lock2()，lock2内部使用了Linux系统调用futex这个能够把线程挂起的重量级锁！\n打脸，前面总结说sync.Mutex没有使用futex，哇擦！\nm.sema这个变量表示的是一个信号量，但是这个信号量是用来通知啥的呢？这个信号量对应的有一个等待队列的，如果lifo为true，则表示将当前的goroutine对应的后续sudog放入队列的头部，这样方便饿死模式下直接将mutex的拥有权交给这个对首的waiter，避免其等锁等太久。\n 如果拿到了这个信号量就立即返回了； 如果拿不到这个信号量就要做后面的处理了；  可能有多个并发的goroutine来抢锁的情况，可能之前已经有没抢到阻塞的goroutine了，这里先找一个阻塞的goroutine，获得信号量地址对应的一个数据结构，记为semaroot，这个维护了mutex上因为抢锁失败而等待的goroutine（waiters）队列。\n对这个semaroot.lock的加锁操作，用了自旋、CAS、futex，为啥用futex呢？这不相当于sync.Mutex间接用了futex嘛！那如果加锁失败不是直接阻塞线程了吗！\n 这种情况下好的情况是几个线程自旋一下抢到sync.Mutex.sema，大概率会成功，但是锁竞争严重的时候还是会失败，怎么办总不能一直自旋不干活啊，注意了，这里调用了  func (m *Mutex) lockSlow() { ... old := m.state for { new := old ... if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { ... queueLifo := waitStartTime != 0 ... runtime_SemacquireMutex(\u0026amp;m.sema, queueLifo, 1) starving = starving || runtime_nanotime()-waitStartTime \u0026gt; starvationThresholdNs old = m.state if old\u0026amp;mutexStarving != 0 { // If this goroutine was woken and mutex is in starvation mode, // ownership was handed off to us but mutex is in somewhat // inconsistent state: mutexLocked is not set and we are still // accounted as waiter. Fix that. if old\u0026amp;(mutexLocked|mutexWoken) != 0 || old\u0026gt;\u0026gt;mutexWaiterShift == 0 { throw(\u0026quot;sync: inconsistent mutex state\u0026quot;) } delta := int32(mutexLocked - 1\u0026lt;\u0026lt;mutexWaiterShift) if !starving || old\u0026gt;\u0026gt;mutexWaiterShift == 1 { // Exit starvation mode. // Critical to do it here and consider wait time. // Starvation mode is so inefficient, that two goroutines // can go lock-step infinitely once they switch mutex // to starvation mode. delta -= mutexStarving } atomic.AddInt32(\u0026amp;m.state, delta) break } awoke = true iter = 0 } else { old = m.state } } ... }  sync.Mutex里面的锁实现，不使用futex，即当Lock失败时，不会导致调用的进程线程被阻塞，而只是将当前goroutine阻塞，go runtime scheduler仍然可以在当前线程上调度执行其他的goroutine，等锁被Unlock时，就有机会再唤醒之前Lock失败的goroutine执行。\n另外，go sync.Mutex做了很多优化，大致总结一下。sync.Mutex有两种工作模式：normal mode 和 starvation mode，两种模式对执行Lock、Unlock的goroutine会产生不同的影响。\n  normal mode\n该模式下，waiters（goroutines）会按照加锁申请进入一个FIFO的队列，一个被唤醒的waiter不一定能够立即持有锁，它要和所有新的发起加锁请求的goroutines竞争。新到达的goroutines通常有一个优势——它们已经在CPU上运行了，并且有很多，所以一个刚被唤醒的waiter大概率会竞争锁失败。\n这种情况下，这个失败的waiter会被加入到这个FIFO队列的对首，如果一个waiter竞争锁超过1ms还没有成功，就会将mutex从normal mode切换为startvation mode。\n  starvation mode\n该模式下，当一个goroutine释放锁时，锁的拥有者立即从该goroutine转交给对首的waiter。新到达的goroutines不会尝试获得锁，尽管它能观察到锁好像被释放掉了。这种模式下，新到达的goroutines会追加到FIFO的队列的末尾。\n  当一个waiter收到一个mutex的拥有者权限时，它会检查，如果：1）它是这个锁竞争等待队列中的最后一个waiter；或者 2）它的加锁等待时间小于1ms，此时将把mutex从starvation mode切换为normal mode。\nmutex.Unlock() # fastpath # 先尝试CAS去掉加锁标志位，其实返回的是锁的新状态，如果之前状态是locked，现在unlocked去掉了这个标志位，如果新状态state==0，表示没什么其他要处理的了，直接返回就可以了，反之，则说明锁可能被设置了其他的状态，如前面提到的锁的normal、starvation mode，还需要进入slowpath进一步处理。\n// Unlock unlocks m. // It is a run-time error if m is not locked on entry to Unlock. // // A locked Mutex is not associated with a particular goroutine. // It is allowed for one goroutine to lock a Mutex and then // arrange for another goroutine to unlock it. func (m *Mutex) Unlock() { if race.Enabled { _ = m.state race.Release(unsafe.Pointer(m)) } // Fast path: drop lock bit. new := atomic.AddInt32(\u0026amp;m.state, -mutexLocked) if new != 0 { // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) } }  slowpath # 锁的状态不只是有持有、未持有这几种，那看来这里是要处理其他几种锁状态的情况了。\nconst ( mutexLocked = 1 \u0026lt;\u0026lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota )  继续看源码，首先做个检查，当前goroutine调用Unlock之前是否有持有这把锁，很好比较，只要检查 (new+mutexLocked) \u0026amp; mutexLocked 下便知道。\nQA：如果当前goroutine没有持有过锁，前面fastpath中却去掉了锁标志位，走到这里检查发现之前没有持有锁，这是很严重的问题，直接throw了，也没什么善后的，直接退出啦，程序员自己抓紧改bug吧，继续跑也会造成bug！\n然后这里面主要是这个函数runtime_Semrelease：\n 如果是正常模式，这个函数从对头取出一个sudog（等待锁的goroutine），然后将其丢入runq等待被调度； 如果是饥饿模式，这个函数从头取出一个sudog（等待锁的goroutine），然后将其丢入runq，并立即让出CPU，相当于让这个sudog尽可能快地被执行到。  func (m *Mutex) unlockSlow(new int32) { if (new+mutexLocked)\u0026amp;mutexLocked == 0 { throw(\u0026quot;sync: unlock of unlocked mutex\u0026quot;) } if new\u0026amp;mutexStarving == 0 { old := new for { // If there are no waiters or a goroutine has already // been woken or grabbed the lock, no need to wake anyone. // In starvation mode ownership is directly handed off from unlocking // goroutine to the next waiter. We are not part of this chain, // since we did not observe mutexStarving when we unlocked the mutex above. // So get off the way. if old\u0026gt;\u0026gt;mutexWaiterShift == 0 || old\u0026amp;(mutexLocked|mutexWoken|mutexStarving) != 0 { return } // Grab the right to wake someone. new = (old - 1\u0026lt;\u0026lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(\u0026amp;m.state, old, new) { runtime_Semrelease(\u0026amp;m.sema, false, 1) return } old = m.state } } else { // Starving mode: handoff mutex ownership to the next waiter, and yield // our time slice so that the next waiter can start to run immediately. // Note: mutexLocked is not set, the waiter will set it after wakeup. // But mutex is still considered locked if mutexStarving is set, // so new coming goroutines won't acquire it. runtime_Semrelease(\u0026amp;m.sema, true, 1) } }  # "}),a.add({id:532,href:"/blog/08%E9%87%8D%E8%A6%81%E7%9A%84%E9%9B%86%E7%BE%A4%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE%E4%B8%8B/",title:"08重要的集群参数配置",description:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101763",content:"略，感兴趣可以参考：https://time.geekbang.org/column/article/101763\n"}),a.add({id:533,href:"/blog/09%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E6%81%AF%E5%88%86%E5%8C%BA%E5%8E%9F%E7%90%86%E5%89%96%E6%9E%90/",title:"09生产者消息分区原理剖析",description:"kafka中数据组织 #  主题 topic 分区 partition（一个topic下可有多个partitions，每个partition都有副本replicas） 消息 message（同一个partition内的消息是有序的）  ",content:"kafka中数据组织 #  主题 topic 分区 partition（一个topic下可有多个partitions，每个partition都有副本replicas） 消息 message（同一个partition内的消息是有序的）  "}),a.add({id:534,href:"/tags/bytedance/sonic/",title:"bytedance/sonic",description:"",content:""}),a.add({id:535,href:"/tags/c/cpp/",title:"c/cpp",description:"",content:""}),a.add({id:536,href:"/tags/encoding/json/",title:"encoding/json",description:"",content:""}),a.add({id:537,href:"/tags/go/ast/",title:"go/ast",description:"",content:""}),a.add({id:538,href:"/tags/goccy/go-json/",title:"goccy/go-json",description:"",content:""}),a.add({id:539,href:"/landscape/",title:"Landscape",description:"my interests landscape.",content:" iframe { width: 100%; height: 100%; } .iframe-container { position: relative; height: 100vh; overflow: hidden; } .iframe-container iframe { position: absolute; top: -170px; left: -40px; border: none; width: 100%; height: 98%; }   "}),a.add({id:540,href:"/tags/segmentio/encoding/",title:"segmentio/encoding",description:"",content:""}),a.add({id:541,href:"/tags/tcp/ip/",title:"tcp/ip",description:"",content:""}),search.addEventListener('input',b,!0);function b(){var b,e;const d=5;b=this.value,e=a.search(b,{limit:d,enrich:!0});const c=new Map;for(const a of e.flatMap(a=>a.result)){if(c.has(a.doc.href))continue;c.set(a.doc.href,a.doc)}if(suggestions.innerHTML="",suggestions.classList.remove('d-none'),c.size===0&&b){const a=document.createElement('div');a.innerHTML=`No results for "<strong>${b}</strong>"`,a.classList.add("suggestion__no-results"),suggestions.appendChild(a);return}for(const[h,a]of c){const f=document.createElement('div');suggestions.appendChild(f);const b=document.createElement('a');b.href=h,f.appendChild(b);const g=document.createElement('span');g.textContent=a.title,g.classList.add("suggestion__title"),b.appendChild(g);const e=document.createElement('span');if(a.description.length>128?e.textContent=a.description.substring(0,128)+"...read more":e.textContent=a.description,e.classList.add("suggestion__description"),b.appendChild(e),suggestions.appendChild(f),suggestions.childElementCount==d)break}}})()