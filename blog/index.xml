<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Blog on</title><link>/blog/</link><description>Recent content in Blog on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Tue, 06 Oct 2020 08:49:55 +0000</lastBuildDate><atom:link href="/blog/index.xml" rel="self" type="application/rss+xml"/><item><title>GoTalk - Go Execution Tracer</title><link>/blog/go_execution_tracer/</link><pubDate>Sat, 08 Nov 2025 08:00:00 +0800</pubDate><guid>/blog/go_execution_tracer/</guid><description> .iframe-container { position: relative; height: 100vh; overflow: hidden; } .iframe-container iframe { width: 100%; height: 90%; border: none; position: absolute; top: -200px; left: -0px; }</description></item><item><title>GoTalk - Go内存管理</title><link>/blog/go_memory_management/</link><pubDate>Sat, 08 Nov 2025 08:00:00 +0800</pubDate><guid>/blog/go_memory_management/</guid><description> .iframe-container { position: relative; height: 100vh; overflow: hidden; } .iframe-container iframe { width: 100%; height: 90%; border: none; position: absolute; top: -200px; left: -0px; }</description></item><item><title>git鬼故事 - How `git cherrypick` Works</title><link>/blog/how_git_cherrypick_works/</link><pubDate>Thu, 06 Nov 2025 08:00:00 +0800</pubDate><guid>/blog/how_git_cherrypick_works/</guid><description>git鬼故事 - How git cherrypick Works # 1. 问题背景 # 项目组内部同事想合并一个线上版本分支的一系列bugfix到下个待发布分支，于是执行了分支merge操作：git merge &amp;lt;branch&amp;gt;。由于存在多分支同时修改的情况，所以预料之中会出现一些合并冲突问题（merge conflicts），git设计上希望能减少认为干预，尽可能启发式地、自动化地去解决一些冲突，尽管如此我们已经有心理准备。
OK，这里我们暂时不去讨论git分支策略上的一些最佳实践或者不良实践，这里我们想讨论一个让人头疼的问题，“git merge”“git cherrypick”究竟靠谱、不靠谱？
之所以提出这个问题，是因为出现了一个出乎我们所有人意料的情况，git merge &amp;lt;branch&amp;gt;后：
有一个源文件中同样的处理逻辑（注意两次的代码稍有不同）竟然被追加了两次。 这两个分支独立修改(插入)后的内容在行号范围上是有重叠的，git没有报冲突。 git merge &amp;lt;branch&amp;gt;, git cherrypick &amp;lt;commit&amp;gt;都会导致相同的问题。 如果说合并一个差异很大的分支不是一个常规操作，cherrypick相比较之下则是使用更加频繁的一个操作，不管是从master cherrypick提交到其他分支，还是线上分支的bugfix backport到master分支，经常用到。巧的是，我们执行 git cherrypick &amp;lt;commit&amp;gt;也会导致上述问题。ps：这里的 &amp;lt;commit&amp;gt;就是涉及到重复的处理逻辑的提交号。
wtf，这直接挑战了很多10年git使用经验的开发者们，发生了什么，连gitd都不住了么？禁不住会问，git是如何设计的，merge、cherrypick乃至rebase、apply是如何工作的。接下来我会用几篇文章解释清楚。
2. 测试准备 # 尽管项目组的代码也没什么特别的分享价值，但是写分享还是要注意脱敏，所以我构造了一个可以复现这个问题的极简git仓库。 您可以通过以下脚本来重建这个测试用的git仓库 (git cp, cc, ck分别是git cherry-pick，git commit, git checkout的alias）：
#!/bin/bash -e mkdir git_mistake &amp;amp;&amp;amp; cd git_mistake git init # master branch touch f echo &amp;quot;apple from master&amp;quot; &amp;gt; f echo &amp;quot;banana from master&amp;quot; &amp;gt;&amp;gt; f git add f &amp;amp;&amp;amp; git cc -m 'add f from master' # feat branch (insert after line 2, [3,4] inserted ) git ck -b feat echo &amp;quot;aaa from feat&amp;quot; &amp;gt;&amp;gt; f echo &amp;quot;bbb from feat&amp;quot; &amp;gt;&amp;gt;f git add .</description></item><item><title>git鬼故事 - How `git merge` Works</title><link>/blog/how_git_merge_works/</link><pubDate>Thu, 06 Nov 2025 08:00:00 +0800</pubDate><guid>/blog/how_git_merge_works/</guid><description> .iframe-container { position: relative; height: 100vh; overflow: hidden; } .iframe-container iframe { width: 1200px; height: 90%; border: none; position: absolute; top: -170px; left: -386px; }</description></item><item><title>git鬼故事 - How `git rebase` Works</title><link>/blog/how_git_rebase_works/</link><pubDate>Thu, 06 Nov 2025 08:00:00 +0800</pubDate><guid>/blog/how_git_rebase_works/</guid><description> .iframe-container { position: relative; height: 100vh; overflow: hidden; } .iframe-container iframe { width: 1200px; height: 90%; border: none; position: absolute; top: -170px; left: -386px; }</description></item><item><title>Linux任务调度(8): 任务越多调度就越频繁吗</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A68/</link><pubDate>Tue, 22 Apr 2025 12:36:00 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A68/</guid><description>Linux任务调度(8): 任务越多调度就越频繁吗 # 本文将讲述一个曾经困扰在我们项目组心头的关于go进程混部时的担忧，以及由此引出的多进程混部时的隔离性问题。比如，个别程序不健壮创建大量进程，是否会推高上下文切换次数导致无谓的CPU开销的问题。我们将结合工具perf、bpftrace来深入观察并分析，以加深了对真实负载场景下任务调度的深层理解。
Go运行时引发的思考 # 一个线上问题 # 对CFS的深入思考，一个直接原因是因为go程序中GOMAXPROCS设置不合理，母机上有128个CPU核心，但是虚拟化技术下容器里分配的只有2个cpus。
此时go进程检测到GOMAXPROCS=128（go不会自动感知到实际上只分配了2个cpus），此时runtime会误认为最多可以创建128个P（GMP中的P，Processor），后果就是进程中最多会创建128个P。比如随着goroutines增多如果当前P处理不过来，就会激活更多的空闲P，对应的创建更多的线程M并轮询绑定的P上的的localrunq、全局的globalrunq以及定时器事件、网络IO事件就绪的goroutines并调度。这里的轮询操作就会导致较高的CPU开销，容易导致CPU throttling（节流）从而导致程序性能下降。
GMP调度是如何初始化的 # go运行时是这样创建GMP的
进程启动的时候会根据GOMAXPROCS先创建出对应数量的P，详见 schedinit()-&amp;gt;procresize()，但是还是没有创建M个这么多线程的； 上述创建出来的一堆P，除了当前g.m.p是在用状态，其他都是idle状态；M也不会预先创建出来，而是根据设计负载情况动态去创建、去激活P去执行的； 具体来说就是当创建一堆goroutines后，这些goroutine会先往 p.runq放，放不下了就会考虑 injectglist(...)，这个其实就是放到全局队列 sched.runq，放的时候： 如果当前M有关联一个P，就先放 npidle个G到 sched.runq，并且启动 npdile个M去激活 npdile个P，去尝试从goroutine抢G然后执行。然后剩下的放到 p.runq； 如果当前M没有关联一个P，这种情况下怎么会发生呢（有多种情况可能会发生，比如GC、系统调用阻塞、初始化阶段等）？这种情况下会全部放到 sched.runq，然后启动最多npidle个（即 min(goroutineQSize, npdile)）个M去激活P并执行； 简单总结就是：“如果短时间内创建大量goroutines，当前p.runq full（或者M解绑了P）就会往sched.runq放。然后会启动最多npidle个M去抢P激活，然后workstealing的方式从sched.runq抢goroutines执行。”
如果这种情况一旦出现了，这些大量创建出来的M，后续无goroutines执行时，也会不断地执行一些轮询 p.runq、sched.runq、netpoller、stealing、timer事件，这个无谓的轮询过程中就容易推高CPU占用。而实际的 --cpus 配额很少，就更容易达到CPU配额限制，进而被虚拟化管理软件给节流（CPU throttling），进而导致程序性能出现整体性的下降 (程序正常逻辑还没怎么执行，全被这些多出来的M轮询消耗掉了)。
一时负载高创建的M能退出吗 # 那有没有办法，让这些创建出来的大量M退出呢？创建出来的M退出只有一种办法，runtime.LockOSThread()，这种情况下，goroutine会和M绑定，goroutine执行完毕退出时，M也会被销毁。但是正常情况下是不会调用这个函数的（调试器tracer会调用该函数），所以多创建出来的M不会退出，进而就导致了这里的问题。
实际上，go程序中解决这个问题，很简单，读取下cgroups的cpu配额即可。可以直接 import _ &amp;quot;github.com/uber-go/automaxprocs&amp;quot; 来解决。
更多任务会导致更频繁上下文切换吗 # 上面go运行时错误设置GOMAXPROCS导致过多P、M创建出来导致了轮询的CPU开销，这个点我们已经明确了，并且了解到了对应的解决方案。
我们还有一个顾虑：
1）同一个机器上，有多个进程，其中一个go进程因为上述原因创建了大量的线程，CFS调度器任务切换频率会不会也被推高？我们都知道上下文切换有开销。 2）同一个机器上，如果有多个进程，如果我想避免某个进程对其他进程的影响，或者某个用户下的所有进程对其他用户下的进程的影响？该如何做。
这几个问题，其实就是我深入研究CFS调度器的根本原因，因为我像搞明白混部的影响及问题边界，这对保证服务乃至系统的可用性至关重要。当然你可以不混部来绕过这些弯弯绕绕的细节。
让我来尝试会大下上面两个问题，其中2）我们已经知道了，CFS可以通过组调度来解决这类问题，但是不会自动构建不同用户的任务组，一个进程包括多个线程也不会作为一个任务组进行限制，可以理解成系统默认有更多线程有更多处理能力，除非你们的系统管理员显示设置。
OK, 那现在，我们只需要搞清楚1），如果任务数增多会导致上下文切换更频率吗？
假设CFS的设计实现果真如此，那这就是个巨大的风险点。现代Linux系统可以创建非常多的任务出来。现代Linux系统不是早些年的时候由CS 13bits索引范围限制了GDT/LDT表长度了，2^13/2=4096个进程（每个进程占GDT表的2项），早期版本最多支持这么多个任务。但是后面Linux版本对此做了修改，解除了这里的限制。每个处理器核心只在GDT中记录它当前运行的任务的表项信息，而任务队列则交给每个处理器核心的cfs_rq，可以创建的任务数量不再受CS 13bits索引、GDT/LDT表长度限制了。Linux系统可以支持的任务数只受限于pid_max、内核配置项、系统资源了。
而如果随着任务数增多，上下文切换频率就变高，这样大量的CPU资源会被浪费在上下文切换上。所以调度器是绝对不会这样实现的，这种设计太蠢了。如果任务数很多，我们可以接受不饿死的前提下、允许一定的调度延时、允许降低一定的交互性，但是不能降低系统调度的吞吐量、不能导致CPU资源巨大浪费、完全不可用。
所以我们的判断应该是，No！更多任务不会导致更频繁的上下文切换！这里的更多任务是指的非常多任务，而不是说从1到2，从2到4，从4到8，从8到16，从16到32这种程度，我们讨论的是从128到256，从1024到2048，从2048到4096这种程度。
谨慎评估下上下文切换频率 # 根据前面的介绍，任务切换 __schedule(preempt)的时机有3个，任务阻塞主动让出CPU、任务抢占、任务唤醒被重新加入run-queue。结合我们下面的测试用例，任务阻塞到被唤醒，我们创建的线程不会主动阻塞，只会被抢占，所以我们只需要分析任务抢占这个路径即可，scheduler_tick()-&amp;gt;task_tick()-&amp;gt;check_preempt_tick()，这里面会检查当前任务是否应该被抢占，发生抢占才会发生上下文切换。</description></item><item><title>Linux任务调度(7): CFS调度器源码分析1</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A67v2/</link><pubDate>Thu, 27 Jun 2024 12:36:00 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A67v2/</guid><description>Linux任务调度(7): CFS调度器源码分析 # 前面几篇文章介绍了Linux下调度器的演进过程，也对CFS调度器的大致工作原理进行了介绍，本文在CFS源码层面进行深入分析，帮助大家更深刻地理解CFS调度器的实现细节。Linux从开始引入CFS调度器到现在，已经发展了近20年的时间。在这一段时间里，CFS调度器经历了多次演进，我们选择相对比较新的版本 v5.12 版本内核为例进行说明。现在主流云厂商提供的Linux发行版内核都还有这个版本，我们的分析仍然具有一定的时效性方面的价值。OK，我们开始。
核心概念及源码分析 # 对“公平”的理解 # CFS的目标是为所有任务提供公平的CPU时间分配，这里要先好好理解下 “公平” 的含义：
1）如果多个任务具有相同的优先级，那么它们理应获得相同的调度机会； 2）如果多个任务优先级有高低之分，那么它们在调度上要有对应的体现，优先级高的要获得更多的调度机会； 3）要防止高优先级任务始终霸占CPU，导致低优先级任务饿死（starvation）； 4）对于响应式任务、非响应式任务，要有必要的奖励和惩罚机制，以改善用户体验； 5）要有能力在用户层级、任务组层级、具体任务层级，建立这种“公平性”； 6）这种公平性在多CPU核心上，除了100%保证单CPU核心上的公平，也需要考虑负载均衡和任务迁移，尽力去做到多CPU核心上的整体调度的相对公平；
这是我对CFS中“公平性”的理解，接下来我们将结合CFS的源码来分析是如何做到的，让大家知其然知其所以然。
核心数据结构 # 被调度的具体任务，或者用户组、任务组，它们都用可调度实体来抽象表示，即 sched_entity； struct sched_entity { /* For load-balancing: */ struct load_weight load; struct rb_node run_node; struct list_head group_node; unsigned int on_rq; u64 exec_start; u64 sum_exec_runtime; u64 vruntime; u64 prev_sum_exec_runtime; u64 nr_migrations; struct sched_statistics exec_statistics; #ifdef CONFIG_FAIR_GROUP_SCHED int depth; struct sched_entity *parent; /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; /* rq &amp;quot;owned&amp;quot; by this entity/group: */ struct cfs_rq *my_q; /* cached value of my_q-&amp;gt;h_nr_running */ unsigned long runnable_weight; #endif #ifdef CONFIG_SMP /* * Per entity load average tracking.</description></item><item><title>vscode-常规配置以及同步说明</title><link>/blog/2024-04-14-%E5%B8%B8%E8%A7%84%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%90%8C%E6%AD%A5%E8%AF%B4%E6%98%8E/</link><pubDate>Sun, 14 Apr 2024 23:00:00 +0800</pubDate><guid>/blog/2024-04-14-%E5%B8%B8%E8%A7%84%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%90%8C%E6%AD%A5%E8%AF%B4%E6%98%8E/</guid><description>前言 # 我经常在项目开发过程中针对不同项目，甚至是相同项目的不同模块阶段，频繁调整配置以满足当时的需要，我觉得能够快速调整vscode配置满足开发人员需要，是一项必备技能。
这里就简单总结下vscode配置调整过程中，一些比较有价值的信息。
搜索配置项 # 搜索修改过的配置项，可以按照 &amp;ldquo;@modified&amp;quot;进行过滤， 搜索指定插件的话，可以按照&amp;rdquo;@ext:&amp;ldquo;进行过滤 设置优先级 # 配置项可以在不同的设置范围内进行覆盖。在下面的列表中，后面的范围会覆盖前面的范围：
默认设置 - 这个范围代表未配置的默认设置值。 用户设置 - 对所有的 VS Code 实例全局适用。 远程设置 - 适用于用户打开的远程机器。 工作区设置 - 适用于打开的文件夹或工作区。 工作区文件夹设置 - 适用于多根工作区的特定文件夹。 特定语言的默认设置 - 这些是由扩展提供的特定语言的默认值。 特定语言的用户设置 - 与用户设置相同，但特定于某种语言。 特定语言的远程设置 - 与远程设置相同，但特定于某种语言。 特定语言的工作区设置 - 与工作区设置相同，但特定于某种语言。 特定语言的工作区文件夹设置 - 与工作区文件夹设置相同，但特定于某种语言。 策略设置 - 由系统管理员设置，这些值始终会覆盖其他设置值。 跨设备同步 # Settings Sync功能，之前使用IDEA系列产品时，一来一个Settings Repository及插件来做这个事情，VSCode就方便多了，直接支持用户维度下的多份的同步，比如分别为macOS、Linux、Windows分别自定义一份配置。
同步的内容也很丰富：
常规设置项 view tasks snippets shortcuts 甚至是UI状态都可以 而且可以精确控制每一个配置项是否参与同步，这个就很有用，比如要读本地机器的文件，但是文件路径在参与同步的设备上不同，那么该配置项就可以“取消设置同步”。
重置配置 # 当该乱某个配置项时，可以选择齿轮按钮，点击弹出菜单然后选择“reset this setting”，或者从settings.</description></item><item><title>vscode-调整配置以保持专注</title><link>/blog/2024-04-14-%E8%B0%83%E6%95%B4%E9%85%8D%E7%BD%AE%E4%BB%A5%E4%BF%9D%E6%8C%81%E4%B8%93%E6%B3%A8/</link><pubDate>Sun, 14 Apr 2024 10:00:00 +0800</pubDate><guid>/blog/2024-04-14-%E8%B0%83%E6%95%B4%E9%85%8D%E7%BD%AE%E4%BB%A5%E4%BF%9D%E6%8C%81%E4%B8%93%E6%B3%A8/</guid><description>前言 # 保持专注、减少外界干扰，首要的是培养内在的专注力，而不是依赖工具。回想起我前几年的一些经历：
我的 MacBook Pro Touch Bar 经常闪烁，几乎刺痛了我的双眼。最终发现是硬件故障，我曾看到一个网友的解决方法，简直让我笑掉大牙。他直接用黑色胶带把 Touch Bar 给封住了。 后来我购买了一款防眩光、防窥的屏幕膜，但它稍微有些厚度，导致关闭屏幕时无法完全贴合。我开始寻找更轻薄、更便携的替代品，直到一个“老手”给了我建议：“简单点，直接将屏幕膜撕下来放在配套袋子里。” 为何提及这两个例子呢？其实是想说，现阶段虽然有很多创新产品，但未必完美。与其花大量时间寻找“完美”，不如早日认识到自己深处发展历程中的某个时刻、转而采用更经济更有效的解决方案。
但是，尽管产品成品不完美，但我们依然可以尽己所能让它接近我们期望的那样。就比如使用vscode进行开发时，我希望它能在不同规模的项目中能够帮助开发者保持专注。
问题背景 # 项目采用的微服务架构+monorepo进行代代码组织，每个微服务一个子目录，当然也有很多scripts、tools、ci/cd配置、配置文件管理、外部依赖等等。业务开发的时候，其实你很想只关心某些范围，而忽略掉不相关的范围，以让自己保持专注的同时提升检索、开发的效率。
为了保持专注，不同产品中有不同的设计，比如KDE中的activity，IDEA中的projectscope，Typora中有打字机模式……就不扯远了，我们只看看vscode中能做到什么程度，来让开发者保持更好的专注度。
配置方式 # 忽略掉不关心的文件: files.exclude # vscode中支持在explorer、代码搜索操作中忽略某些文件夹、文件，这个是通过配置一些忽略规则来实现的。
规则配置说明，详见：see: https://code.visualstudio.com/docs/editor/glob-patterns
如果代码库是monorepo管理的，使用git进行版本控制（没有针对大仓的权限控制、拉取等进行特殊优化），那拉取下来后文件数量会很多，但是在我们对全局进行了了解之后，以后大部分功能开发过程中，你很可能希望能聚焦于其中某些部分，而非全部。不管是explorer中查看，还是代码搜索时检索，还是提交日志检查，你都希望能尽可能聚焦。所以是有必要隐藏某些不紧密相干的内容的。
忽略gitignore中文件: explorer.excludeGitIgnore # gitignore中通常会忽略一些文件，大多数时候这些文件也是一些不需要在explorer中显示的，所以vscode也增加了这样一个配置项，允许忽略.gitignore中忽略的文件。
严格来说，是vscode会读取gitignore中的配置，但是对其中某些规则的解析上并不完全等同于git。
举个例子，下述配置项通常用来忽略linux上的编译构建生成的二进制程序，但是如果vscode读取后就会忽略所有内容，并不完全等价于git忽略的内容。
* !*.* !*/ 不要watch不关心的目录：files.watcherExclude # vscode会通过filesystem watch特性来监视某些文件内容的修改情况，以便及时reload最新内容，但是这也是由性能开销的，如果某些路径下的变更不是自己关心的，可以考虑忽略。至少在显示打开、强制reload window时还是会加载最新内容的。
通过 project scope # IDEA系列的IDE产品中，有一个非常有用的特性，project scope。
前面提到的两种方式，控制的事工程全局层面，哪些文件可显示、隐藏出来。而project scope则是概念上对工程的划分。
比如用户登录流程、用户匹配流程、对局结束流程、DS管理流程，这些不同关键链路上的服务列表，它们有重叠的，也有各自特有的。用project scope进行管理就非常方便了。
你可以创建不同的project scopes，然后每个scope控制好要显示、隐藏的文件，当希望从某个关键业务流程切换到另一个关键业务流程的开发时，只需要切换project scope就可以了。
很遗憾的是，vscode原生不支持project scope，但是有些作者通过vscode extension的方式来实现了project scope，实现方式就是在进行scope切换时，自动帮用户设置好files.exclude。
通过 workspace # vscode支持workspace，以及multi-root workspace，意思是你可以将多个独立的工程组织在一个workspace中，在一个workspace中也可以控制显示、隐藏的文件。
workspace是不同于project scope的另一种特性，可以针对同一个project配置多个workspace分别设置好隐藏、显示规则，可以近似实现project scope的功能。 multi-root workspace还可以将多个不相干的projects组合在一个workspace里面，比如我有些个人兴趣驱动的电子书，调试器相关的、RPC框架相关的、Go语言设计实现相关的，我就可以将这几个独立的工程编排为一个workspace。</description></item><item><title>解决c10k c100k c10m问题</title><link>/blog/2024-01-06-%E8%A7%A3%E5%86%B3c10kc100kc10m%E9%97%AE%E9%A2%98/</link><pubDate>Sat, 06 Jan 2024 20:30:24 +0800</pubDate><guid>/blog/2024-01-06-%E8%A7%A3%E5%86%B3c10kc100kc10m%E9%97%AE%E9%A2%98/</guid><description>问题背景 # c10k, c100k甚至c10m，这些问题大家已经不再陌生，聊起来可能显得有点枯燥？新技术层出不穷，至少我自己对这些问题有了些新的认识，需要更新沉淀下我的“小宇宙”。
c10k问题, 1999, 1Gbps Ethernet # The C10k problem is the problem of optimizing network sockets to handle a large number of clients at the same time.[1] The name C10k is a numeronym for concurrently handling ten thousand connections.[2] Handling many concurrent connections is a different problem from handling many requests per second: the latter requires high throughput (processing them quickly), while the former does not have to be fast, but requires efficient scheduling of connections.</description></item></channel></rss>