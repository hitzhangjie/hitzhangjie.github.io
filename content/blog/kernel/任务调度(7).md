---
layout: post
title: "Linux任务调度(7): CFS调度器源码分析1"
description: "前面几篇文章介绍了Linux下调度器的演进过程，也对CFS调度器的大致工作原理进行了介绍，但是还是只停留在思想层面，本文在CFS源码层面进行深入分析，帮助大家更深刻地理解CFS调度器的实现细节。本文最后继续探讨几个比较实际的问题，当线程数多了之后，线程切换频率会上升吗？会导致CPU占用率上升吗？调度器又如何平衡多cpu多核上的负载。"
date: 2024-06-27 12:36:00 +0800
tags: ["scheduler","cfs","fair","vruntime","gmp"]
categories: ["linux内核"]
toc: true
reward: true
---
## Linux任务调度(7): CFS调度器源码分析

Linux从开始引入CFS调度器到现在，已经发展了近20年的时间。在这一段时间里，CFS调度器经历了多次演进，我们选择相对比较新的版本 v5.12 版本内核为例进行说明。现在主流云厂商提供的Linux发行版内核都还有这个版本，我们的分析仍然具有一定的时效性方面的价值。OK，我们开始。

### 核心概念及源码分析

#### 对“公平”的理解

CFS的目标是为所有任务提供公平的CPU时间分配，这里要先好好理解下 “**公平**” 的含义：

1）如果多个任务具有相同的优先级，那么它们理应获得相同的调度机会；
2）如果多个任务优先级有高低之分，那么它们在调度上要有对应的体现，优先级高的要获得更多的调度机会；
3）要防止高优先级任务始终霸占CPU，导致低优先级任务饿死（starvation）；
4）对于响应式任务、非响应式任务，要有必要的奖励和惩罚机制，以改善用户体验；
5）要有能力在用户层级、任务组层级、具体任务层级，建立这种“公平性”；
6）这种公平性在多CPU核心上，除了100%保证单CPU核心上的公平，也需要考虑负载均衡和任务迁移，尽力去做到多CPU核心上的整体调度的相对公平；

这是我对CFS中“公平性”的理解，接下来我们将结合CFS的源码来分析是如何做到的，让大家知其然知其所以然。

#### 核心数据结构

1) 被调度的具体任务，或者用户组、任务组，它们都用可调度实体来抽象表示，即 `sched_entity`；
   ```c
   struct sched_entity {
       /* For load-balancing: */
       struct load_weight        load;
       struct rb_node            run_node;
       struct list_head		      group_node;
       unsigned int              on_rq;

       u64                       exec_start;
       u64                       sum_exec_runtime;
       u64                       vruntime;
       u64                       prev_sum_exec_runtime;

       u64                       nr_migrations;

       struct sched_statistics exec_statistics;

       #ifdef CONFIG_FAIR_GROUP_SCHED
           int                     depth;
           struct sched_entity     *parent;
           /* rq on which this entity is (to be) queued: */
           struct cfs_rq           *cfs_rq;
           /* rq "owned" by this entity/group: */
           struct cfs_rq           *my_q;
           /* cached value of my_q->h_nr_running */
           unsigned long           runnable_weight;
       #endif

       #ifdef CONFIG_SMP
           /*
            * Per entity load average tracking.
            *
            * Put into separate cache line so it does not
            * collide with read-mostly values above.
            */
          struct sched_avg        avg;
      #endif
   }
   ```

2）每个处理器独立维护一个任务队列cfs_rq，避免1个全局队列的方式导致竞争问题：

```c
   /* CFS-related fields in a runqueue */
    struct cfs_rq {
        struct load_weight    load;
        unsigned int          nr_running;
        unsigned int          h_nr_running;      /* SCHED_{NORMAL,BATCH,IDLE} */
        unsigned int          idle_h_nr_running; /* SCHED_IDLE */
  
        u64                   exec_clock;
        u64                   min_vruntime;
        ...
  
        struct rb_root_cached    tasks_timeline; /* 维护任务的vruntime的rbtree */
  
        /*
         * 'curr' points to currently running entity on this cfs_rq.
         * It is set to NULL otherwise (i.e when none are currently running).
         */
        struct sched_entity    *curr;
        struct sched_entity    *next;
        struct sched_entity    *last;
        struct sched_entity    *skip;
        ...
  
        /*
         * CFS load tracking
         */
        struct sched_avg    avg;
        ...
  
    // 组调度相关的内容，暂时忽略
    #ifdef CONFIG_FAIR_GROUP_SCHED
      ...
    #endif /* CONFIG_FAIR_GROUP_SCHED */
    };
```

   内核为每个处理器维护一个任务队列cfs_rq, cfs_rq中通过指针成员next,last建立了一个双向链表，方便调度器遍历任务列表。

3) 调度器为了能够快速找到任务队列cfs_rq中下一个vruntime最小的可运行任务，构建了1个rbtree：

   ```c
   /* CFS-related fields in a runqueue */
    struct cfs_rq {
        ...
        struct rb_root_cached    tasks_timeline; /* 维护任务的vruntime的rbtree */
        struct sched_entity      *curr;
        ...
    }
    /*
     * Leftmost-cached rbtrees.
     *
     * We do not cache the rightmost node based on footprint
     * size vs number of potential users that could benefit
     * from O(1) rb_last(). Just not worth it, users that want
     * this feature can always implement the logic explicitly.
     * Furthermore, users that want to cache both pointers may
     * find it a bit asymmetric, but that's ok.
     */
     struct rb_root_cached {
         struct rb_root rb_root;
         struct rb_node *rb_leftmost;
      };
   ```

   红黑树的更新逻辑这里暂时按下不提，我们先关注核心逻辑，如果此时运行中的任务curr被抢占，那么下一个执行的就是cfs_rq.tasks_timeline->rb_leftmost。
   在介绍调度器抢占逻辑时，我们会看到这部分的更多的源码细节。OK，理解cfs的核心数据结构大致就是这些，篇幅原因我们暂时移除了支持组调度相关的部分。

#### 调度粒度

前面核心数据结构部分，我们介绍了sched_entity，从这里可以引申出一个重要概念，调度粒度。

```c
struct sched_entity {
    /* For load-balancing: */
    struct load_weight        load;
    struct rb_node            run_node;
    struct list_head          group_node;
    unsigned int              on_rq;

    ...

    #ifdef CONFIG_FAIR_GROUP_SCHED
        int                     depth;
        struct sched_entity     *parent;

        /* rq on which this entity is (to be) queued: */
        struct cfs_rq           *cfs_rq;

        /* rq "owned" by this entity/group: */
        struct cfs_rq           *my_q;

        /* cached value of my_q->h_nr_running */
        unsigned long           runnable_weight;
    #endif
    ...
}
```

sched_entity，可以表示：

1) 具体的1个任务；
2) 任务组，此时sched_entity.cfs_rq表示当前任务组从属于哪个任务队列，并且sched_entity.my_q表示当前任务组包含的任务队列；
   现在你明白了：
   - 调度器cfs_rq中的某个任务可以是一个“任务组”，
   - 该任务组内包含了自己的任务队列，任务组内的任务也是按照CFS vruntime进行调度，
   - 同时该任务组的vruntime是由其my_q中的所有可调度实体的vruntime求和计算而来，该任务组与其所在的cfs_rq中的其他调度实体按照CFS vruntime进行调度。
3) 用户组是任务组的一种特殊应用形式，本质还是任务组这样的组调度；

关于组调度的实现源码，篇幅原因，本文中可能不涉及，但是看罢此文，我相信读者已经可以自己去阅读源码了。如果有时间我会再写一篇文章讲述组调度的细节。

#### 任务的优先级

在前面介绍的楼梯调度算法、旋转楼梯调度算法，提到了多优先级队列来实现“公平性”对于“任务优先级”的理解。看上去它确实也是种解决办法，但是它真的很难被建模、量化然后说它到底好还是不好？任务在active、expire队列中挪来挪去，或者从高优先级队列挪到低优先级队列，真的是最优雅的解决办法吗？首先，理解起来它就不是那么简单，尽管我在信息流图文、视频链路处理过程中也使用过类似的方法来解决业务中的资源调度问题，但是我确实不认为那就是最好的解决方案。

CFS调度器的设计，核心思想更简单易懂，且非常容易比建模、量化评估：
1）任务的优先级，包括了初始的静态优先级(nice，从-20到19)和动态优先级(priority，根据是否响应式任务动态调整)；
2）调度器执行调度时，会检查任务列表中的任务是否是响应式任务，并调整其对应的动态优先级（奖励 or 惩罚，-5到+5）；
3）任务的最终优先级 = 静态优先级 + 动态优先级；
4）任务的优先级会被映射为一种“权重”，表示它在总的CPU执行时间里的一种占比，显然优先级越高对应的权重也应该越大；

#### 虚拟运行时间

调度器执行调度时，很重要的一部操作就是迅速找到下一个被调度的可运行任务。Linux v0.01版本中找到下一个可运行任务的复杂度是O(n)，O(1)调度器是O(1)，CFS调度器是O(log(n))。
CFS调度器建立了一个红黑树（RBTree），树种每个节点表示一个任务，任务中包含了一个属性 `vruntime`。

`vruntime`是一个虚拟运行时间: `vruntime = 实际执行时间 / weight`

1) 实际执行时间，就是任务被调度到CPU上执行的总时间；
   2）处理器时钟中断定时触发，时钟中断服务程序此时会更新当前运行中的任务的实际执行时间，并更新vruntime；
   ```c
   时钟中断服务入口 scheduler_tick(preempt):
      \-> scheduler_tick()
            \-> task_tick(rq, cur, 0)
                  \-> task_tick_fair(rq, cur, 0)
                        \-> foreach se in cfs_rq: entity_tick(cfs_rq, se, queued)
                              \-> update_curr(cfs_rq)
                                    \-> curr->sum_exec_runtime += delta_exec;
                                    \-> curr->vruntime += calc_delta_fair(delta_exec, curr);

   /*
   * delta /= w
   */
   static inline u64 calc_delta_fair(u64 delta, struct sched_entity *se)
   {
      if (unlikely(se->load.weight != NICE_0_LOAD))
       delta = __calc_delta(delta, NICE_0_LOAD, &se->load);
      return delta;
   }   
   ```

3）weight则是由前面提到的任务优先级，通过查表映射而来得到的权重值；
   vruntime的实际计算式为：

```c
   virtual runtime = (real runtime) * (NICE_0_LOAD) / (weight of the process)
```

- 其中virtual runtime指的就是vruntime;
- real runtime指的是cpu上的实际执行时间;
- NICE_0_LOAD表示nice==0时的默认权重（1024）;
- 而weight of the process指的是由进程的实际优先级从映射表映射而来的权重;

  完整的映射表可以参考：

```c
   const int sched_prio_to_weight[40] = {
    /* -20 */     88761,     71755,     56483,     46273,     36291,
    /* -15 */     29154,     23254,     18705,     14949,     11916,
    /* -10 */      9548,      7620,      6100,      4904,      3906,
    /*  -5 */      3121,      2501,      1991,      1586,      1277,
    /*   0 */      1024,       820,       655,       526,       423,
    /*   5 */       335,       272,       215,       172,       137,
    /*  10 */       110,        87,        70,        56,        45,
    /*  15 */        36,        29,        23,        18,        15,
   };
```

当一个任务被调度执行时，时钟中断会定时触发，对应的时钟中断通过1）中代码序列会不断更新任务的实际执行时间和 `vruntime`，陷入阻塞状态的任务不会占用CPU，这里的时间也不会增加。

ps：sched_entity可以表示具体任务，也可以表示任务组、用户组（用户组是任务组的一种特殊应用方式），而vruntime是定义在sched_entity中的，对于组调度而言，计算vruntime的时候就是递归计算其包含的所有任务的vruntime，汇总起来。

#### 调度周期

sched_latency，直译过来应该是调度延迟，但是理解成调度周期更好理解一点，它表示什么呢？
1）任意一个可运行任务先后两次调度之间的时间差上限；
2）在这个时限内所有可运行任务都必须完成一次调度；

sched_latency，强调的是多久的时间窗口内所有运行任务可以都被调度一轮，它不等于任务执行时的时间片sched_slice。在传统调度器实现中，时间片是固定的，在CFS中不是的，时间片是动态计算的，后面会提到。

我们看下调度周期的相关计算逻辑：

```c
/*
 * Targeted preemption latency for CPU-bound tasks:
 *
 * NOTE: this latency value is not the same as the concept of
 * 'timeslice length' - timeslices in CFS are of variable length
 * and have no persistent notion like in traditional, time-slice
 * based scheduling concepts.
 *
 * (to see the precise effective timeslice length of your workload,
 *  run vmstat and monitor the context-switches (cs) field)
 *
 * (default: 6ms * (1 + ilog(ncpus)), units: nanoseconds)
 */
unsigned int sysctl_sched_latency			= 6000000ULL;

/*
 * Minimal preemption granularity for CPU-bound tasks:
 *
 * (default: 0.75 msec * (1 + ilog(ncpus)), units: nanoseconds)
 */
unsigned int sysctl_sched_min_granularity			= 750000ULL;

/*
 * This value is kept at sysctl_sched_latency/sysctl_sched_min_granularity
 */
static unsigned int sched_nr_latency = 8;

 * The idea is to set a period in which each task runs once.
 *
 * When there are too many tasks (sched_nr_latency) we have to stretch
 * this period because otherwise the slices get too small.
 *
 * p = (nr <= nl) ? l : l*nr/nl
 */
static u64 __sched_period(unsigned long nr_running)
{
	if (unlikely(nr_running > sched_nr_latency))
		return nr_running * sysctl_sched_min_granularity;
	else
		return sysctl_sched_latency;
}
```

不难看出:

1) 当可运行任务数<=8时，调度周期sched_latency=6ms；
2) 当>8时，调度周期sched_latency=可运行任务数*0.75ms，超过8个时就大于6ms。

这里的调度延迟和下面的动态时间片的计算有关系，注意看。

#### 时间片

调度器中包含“时间片”这个设计，主要有两个目的：
1）为了避免进程频繁切换，必须要让任务执行一段时间后再切换，否则每次系统调用返回、时钟中断服务检测到vruntime最小时都会立即触发触发，开销极大；
2）为了避免进程长时间霸占CPU，有些进程不进行IO或者其他可能阻塞性的处理，就不会主动让出CPU，时钟中断服务每隔一段时间触发调度器进行检查，如果任务运行时间片就要强制抢占；

不同调度器实现都肯定需要考虑“时间片”的设计，不同于传统的基于固定时间片大小的调度器实现，CFS中的任务时间片是动态计算的，详见 `sched_slice(...)`。

```c
/*
 * We calculate the wall-time slice from the period by taking a part
 * proportional to the weight.
 *
 * s = p*P[w/rw]
 */
static u64 sched_slice(struct cfs_rq *cfs_rq, struct sched_entity *se)
{
   // if nr_running<=8, slice=6ms; else slice=nr_running*0.75ms
	u64 slice = __sched_period(cfs_rq->nr_running + !se->on_rq);

	for_each_sched_entity(se) {
		struct load_weight *load;
		struct load_weight lw;

		cfs_rq = cfs_rq_of(se);
		load = &cfs_rq->load;

		if (unlikely(!se->on_rq)) {
         // total load on this cfs_rq, sum(load-per-task)
			lw = cfs_rq->load;

			update_load_add(&lw, se->load.weight);
			load = &lw;
		}
		// slice = delta_exec * weight / lw.weight
      // or
      // (delta_exec * (weight * lw->inv_weight)) >> WMULT_SHIFT
		slice = __calc_delta(slice, se->load.weight, load);
	}
	return slice;
}
```

首先根据可运行任务数量计算出一个调度周期，然后根据过去每个任务执行贡献的负载/总负载，按比例划分调度周期得到该任务的动态时间片。

> ps: 这里的概念“负载”，就是占据CPU的时间，不是top中的loadavg的负载概念。

能不能确定动态时间片的一个上下界呢？接着往下看你就知道了。

#### 调度节拍

检查任务是否需要切换，有这么几个时机:

1) 时钟中断服务程序触发scheduler_tick(void)，如果检查逻辑发现需要触发会设置对应的标记位TIF_NEED_RESCHED；
2) 任务执行到阻塞型系统调用时，任务需要阻塞执行、不可被调度，此时会主动让出CPU，如mutex, semaphore, waitqueue；
3) 任务执行系统调用返回时，一般也会做个检查 （在看linux v0.01源码时就是会检查的，合理，推测后续版本也是这样的）；

这里的调度节拍，强调的更多的是硬件时钟中断触发时钟中断服务程序，进入这里的scheduler_tick执行任务切换逻辑:

1) 更新任务执行时间、vruntime；
2) 抢占逻辑check_preempty_check里检查任务执行时间是否已经超过时间片，超过则寻找下一个待调度任务，设置标志位TIF_NEED_RESCHED返回；
3) 等待调度器__schedule(preempt)执行实际的任务切换逻辑。

```c
时钟中断服务入口 scheduler_tick(preempt):
   \-> scheduler_tick()
         \-> task_tick(rq, cur, 0)
               \-> task_tick_fair(rq, cur, 0)
                     \-> foreach se in cfs_rq: entity_tick(cfs_rq, se, queued)
                           \-> update_curr(cfs_rq)
                                 \-> curr->sum_exec_runtime += delta_exec;
                                 \-> curr->vruntime += calc_delta_fair(delta_exec, curr);
                           \-> check_preempt_tick(cfs_rq, curr)

// Preempt the current task with a newly woken task if needed:
static void
check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)
{ ... }
```

#### 任务抢占

当前正在执行的任务，在时钟中断到来时schedule_tick函数被执行，它里面会检查当前任务是否应该被抢占，如果需要被抢占，则会调用resched_cur
来标记任务的一些抢占标记为。检查当前任务是否运行足够久应该被抢占的函数，前面我们已经分析过了，就是check_preempt_tick函数。

```c
/*
 * Preempt the current task with a newly woken task if needed:
 * 1) 如果运行足够久了，超过了sched_slice返回的时间片（时间配额），则直接标记为抢占然后返回
 * 2) 如果运行任务时间很短，没有超过动态时间片，并且还不到最小的0.75ms，那么无需抢占、继续执行
 * 3) 如果运行时间不太短，虽然不到动态时间片大小，但是超过了0.75ms，可以检测下是否需要被抢占 
 *    则从当前cpu的cfs_rq（任务队列）中取出vruntime最小的一个se，进行比较。
 *    - 如果当前任务的vruntime更小，则不能被抢占，当前任务继续执行；
 *    - 如果当前任务的vruntime更大 (delta=curr.vruntime-se.vruntime，delta>0)
 *       - delta<=ideal_time，从全局来看有比我更应该优先调度的，但是也没等太久，让我再执行一会，一会就让出CPU；
         - delta>ideal_time，从全局来有比我更应该优先调度的，且已经等了比较久时间了；
 */
static void
check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)
{
	unsigned long ideal_runtime, delta_exec;
	struct sched_entity *se;
	s64 delta;

	ideal_runtime = sched_slice(cfs_rq, curr);
	delta_exec = curr->sum_exec_runtime - curr->prev_sum_exec_runtime;
	if (delta_exec > ideal_runtime) {
		resched_curr(rq_of(cfs_rq));
      ...
		return;
	}

	/*
	 * Ensure that a task that missed wakeup preemption by a
	 * narrow margin doesn't have to wait for a full slice.
	 * This also mitigates buddy induced latencies under load.
	 */
	if (delta_exec < sysctl_sched_min_granularity)
		return;

	se = __pick_first_entity(cfs_rq);
	delta = curr->vruntime - se->vruntime;

	if (delta < 0)
		return;

	if (delta > ideal_runtime)
		resched_curr(rq_of(cfs_rq));
}


/*
 * resched_curr - mark rq's current task 'to be rescheduled now'.
 *
 * On UP this means the setting of the need_resched flag, on SMP it
 * might also involve a cross-CPU call to trigger the scheduler on
 * the target CPU.
 */
void resched_curr(struct rq *rq)
{
   ...
	if (test_tsk_need_resched(curr))
		return;

	cpu = cpu_of(rq);
	if (cpu == smp_processor_id()) {
		set_tsk_need_resched(curr);
		set_preempt_need_resched();
		return;
	}

	if (set_nr_and_not_polling(curr))
		smp_send_reschedule(cpu);
	else
		trace_sched_wake_idle_without_ipi(cpu);
}
```

什么情况下会出现上述check_preempt_tick注释中 3) 这种情况呢？

- nr_running>8，并且任务优先级高贡献负载多，sched_slice>0.75ms，
- 恰巧任务执行期间scheduler_tick执行这里的检测，有可能会发现此时执行时间不到sched_slice，
- 但是超过了0.75ms，此时为什么要检测有没有vruntime更小的呢？

理想情况下，还是需要执行完sched_slice后再切换，才能体现公平是不是？确实。
那为什么现在就要执行检测呢？因为系统中随时可能会插入高优先级进程、考虑交互性程序的奖励、非交互性程序的处罚以及避免饿死问题。“公平”不仅要看过去、现在，也要看将来，不仅要看局部，也要看整体。So……此时检查下是否需要被抢占十分合理，更何况是一个已经“等”了我一会的任务呢？

> ps: 从这里可以看出，cfs并不是立即选一个vruntime更小的任务来立即执行，即使下一个任务的vruntime比当前任务小，当前任务也会尽量拖着再执行一会，要么等到执行完理想的时间片（这样最公平），要么拖到下一个任务再等我一会，这样我执行时间更接近理想时间片。

#### 任务切换

`schedule_tick(...)` 只是时钟中断服务触发检查“是否需要抢占当前任务“，如果需要就设置标记位并返回。
我们知道此时当前任务还是在执行中的，顶多被设置了个抢占标记位而已，那么调度器什么时候执行了真正的切换呢？在 `__schedule(preempt)`这个调度器逻辑中。

```c
/*
 * __schedule() is the main scheduler function.
 *
 * The main means of driving the scheduler and thus entering this function are:
 *
 *   1. Explicit blocking: mutex, semaphore, waitqueue, etc.
 *
 *   2. TIF_NEED_RESCHED flag is checked on interrupt and userspace return
 *      paths. For example, see arch/x86/entry_64.S.
 *
 *      To drive preemption between tasks, the scheduler sets the flag in timer
 *      interrupt handler scheduler_tick().
 *
 *   3. Wakeups don't really cause entry into schedule(). They add a
 *      task to the run-queue and that's it.
 *
 *      Now, if the new task added to the run-queue preempts the current
 *      task, then the wakeup sets TIF_NEED_RESCHED and schedule() gets
 *      called on the nearest possible occasion:
 */
static void __sched notrace __schedule(bool preempt)
{
	struct task_struct *prev, *next;
	unsigned long *switch_count;
	unsigned long prev_state;
	struct rq_flags rf;
	struct rq *rq;
	int cpu;

	cpu = smp_processor_id();
	rq = cpu_rq(cpu);
	prev = rq->curr;

   ...

   // 寻找下一个可执行任务
	next = pick_next_task(rq, prev, &rf);
   // 清理旧任务的抢占标记位
	clear_tsk_need_resched(prev);
	clear_preempt_need_resched();

   // 如果next!=prev，更新上下文切换计数器，并执行上下文切换
   // 如果next==prev，说明当前runq上没有其他任务，需要检查下负载均衡了
	if (likely(prev != next)) {
		rq->nr_switches++;

      // 执行上下文切换，从prev到next，切换完就开始执行next这个任务了
		rq = context_switch(rq, prev, next, &rf);
	} else {
		rq->clock_update_flags &= ~(RQCF_ACT_SKIP|RQCF_REQ_SKIP);

      // 负载均衡相关的操作，rq.lock dropped之后会执行balance_callbacks
		rq_unpin_lock(rq, &rf);
		__balance_callbacks(rq);
		raw_spin_unlock_irq(&rq->lock);
	}
}
```

`__schedule(preempt)` 函数非常长，我们删减了不是很相关的代码，只看下任务切换的核心逻辑：
1）这个函数什么时候会被执行到呢？注释提到了有几个时机，任务阻塞主动让出CPU、任务被抢占、任务被唤醒任务重新加入run-queue；
   我们刚才提到的任务抢占就会导致进入这个函数处理。
2）cfs调度器通过pick_next_task(...)从rq中找到下一个vruntime最小的任务；
3）清理之前设置的抢占标记位，更新抢占计数器；
4）执行上下文切换 context_switch，执行新任务逻辑；
5）再释放掉rq上的锁后，会执行负载均衡逻辑（work-sharing mode）；

这就是大致的任务抢占、任务切换、负载均衡的核心逻辑。

#### 负载均衡

see: `__balance_callbacks(rq)`，因为我们了解go workstealing相关的迁移负载的做法，对linux cfs调度器做到负载均衡的思路并不十分好奇，
我们这里只是简单总结下负载均衡的核心思路，细节直接跳过。

**1）这里笼统地说下cfs调度器负载均衡的时机，以及考虑因素。**

**负载均衡的时机**，负载均衡通常在以下几种情况下触发：

- 周期性负载均衡：调度器会定期检查各个CPU的负载，并在必要时进行任务迁移。
- 任务唤醒：当一个任务从睡眠状态被唤醒时，调度器会检查当前CPU的负载情况，并可能将任务分配到负载较轻的CPU。
- 任务创建：当一个新任务被创建时，调度器会选择一个负载较轻的CPU来运行该任务。

**任务迁移的考虑因素**，在决定是否迁移任务时，调度器会考虑多个因素，包括：

- CPU负载：调度器会比较各个CPU的负载，选择负载较轻的CPU进行任务迁移。
- 任务的vruntime：调度器会比较任务的vruntime，选择合适的任务进行迁移。
- 任务的亲和性：某些任务可能对特定的CPU有亲和性（例如，缓存亲和性），调度器会尽量避免迁移这些任务。

**2）CPU1上的P1的vruntime比CPU2上的P2的vruntime更小，CPU1负载高，会将P1迁迁移到CPU2上吗？**

假设有两个CPU（CPU1和CPU2），每个CPU有自己的调度队列和红黑树：

- CPU1上的任务P1的vruntime较大，暂时不被CPU1调度。
- CPU2上的任务P2的vruntime最小，但P1的vruntime比P2更小。

在这种情况下，是否会将P1迁移到CPU2取决于负载均衡机制的具体实现和当前系统的负载情况：

- 如果CPU1的负载较高，而CPU2的负载较低，负载均衡机制可能会将P1迁移到CPU2，以平衡负载。
- 如果CPU1和CPU2的负载相对均衡，调度器可能不会进行任务迁移，因为任务迁移本身也有一定的开销。

如果您对负载均衡的细节感兴趣，可以看下相关的代码。

#### 组调度

组调度，一个任务组是组，一个用户组是一个特殊的任务组的应用场景。前面介绍核心数据结构时，特别提了sched_entity中如何借助字段my_q来表示该任务组包含的任务队列，组内的任务也是按照CFS调度器算法进行调度。而这个任务组又作为一个调度实体从属于更上层的“组”，被CFS调度算法调度。

这里的“组调度”，在Linux的设计实现中：
1）需要有一个能力来灵活的定义组，然后灵活地在这个组中添加任务，灵活地建立一个sched_entity的树形结构。cgroups就是用来干这个事情的。
   在cgroups中增加配置项来影响调度，如cpu.shares表示这个调度组的CPU开销的配额。
2) 对应地cfs调度器需要读取cgroups这里的这些配置项，来感知到有哪些任务组，每个任务组的配置是啥样的，进而整合成sched_entity的树形结构，让树形结构中的每个调度实体（任务、组）被CFS调度器调度。

OK，篇幅原因本文不打算继续介绍组调度相关的内容，读到这里了解了CFS关键的处理过程后，大家可以自行查看组调度相关的设计实现了。或者等我有时间时再补一篇文章，专门介绍组调度。我们来回答下前面的几个疑问吧。

### Go运行时引发的思考

#### 一个线上问题

对CFS的深入思考，一个直接原因是因为go程序中GOMAXPROCS设置不合理，母机上有128个CPU核心，但是虚拟化技术下容器里分配的只有2个cpus。

此时go进程检测到GOMAXPROCS=128（go不会自动感知到实际上只分配了2个cpus），此时runtime会误认为最多可以创建128个P（GMP中的P，Processor），后果就是进程中最多会创建128个P。比如随着goroutines增多如果当前P处理不过来，就会激活更多的空闲P，对应的创建更多的线程M并轮询绑定的P上的的localrunq、全局的globalrunq以及定时器事件、网络IO事件就绪的goroutines并调度。这里的轮询操作就会导致较高的CPU开销，容易导致CPU throttling（节流）从而导致程序性能下降。

#### GMP调度是如何初始化的

go运行时是这样创建GMP的

1. 进程启动的时候会根据GOMAXPROCS先创建出对应数量的P，详见 `schedinit()->procresize()`，但是还是没有创建M个这么多线程的；
2. 上述创建出来的一堆P，除了当前g.m.p是在用状态，其他都是idle状态；M也不会预先创建出来，而是根据设计负载情况动态去创建、去激活P去执行的；
3. 具体来说就是当创建一堆goroutines后，这些goroutine会先往 `p.runq`放，放不下了就会考虑 `injectglist(...)`，这个其实就是放到全局队列 `sched.runq`，放的时候：
   - 如果当前M有关联一个P，就先放 `npidle`个G到 `sched.runq`，并且启动 `npdile`个M去激活 `npdile`个P，去尝试从goroutine抢G然后执行。然后剩下的放到 `p.runq`；
   - 如果当前M没有关联一个P，这种情况下怎么会发生呢（有多种情况可能会发生，比如GC、系统调用阻塞、初始化阶段等）？这种情况下会全部放到 `sched.runq`，然后启动最多npidle个（即 `min(goroutineQSize, npdile)`）个M去激活P并执行；

简单总结就是：“**如果短时间内创建大量goroutines，当前p.runq full（或者M解绑了P）就会往sched.runq放。然后会启动最多npidle个M去抢P激活，然后workstealing的方式从sched.runq抢goroutines执行。**”

如果这种情况一旦出现了，这些大量创建出来的M，后续无goroutines执行时，也会不断地执行一些轮询 p.runq、sched.runq、netpoller、stealing、timer事件，这个无谓的轮询过程中就容易推高CPU占用。而实际的 `--cpus` 配额很少，就更容易达到CPU配额限制，进而被虚拟化管理软件给节流（CPU throttling），进而导致程序性能出现整体性的下降 (程序正常逻辑还没怎么执行，全被这些多出来的M轮询消耗掉了)。

#### 一时负载高创建的M能退出吗

那有没有办法，让这些创建出来的大量M退出呢？创建出来的M退出只有一种办法，`runtime.LockOSThread()`，这种情况下，goroutine会和M绑定，goroutine执行完毕退出时，M也会被销毁。但是正常情况下是不会调用这个函数的（调试器tracer会调用该函数），所以多创建出来的M不会退出，进而就导致了这里的问题。

实际上，go程序中解决这个问题，很简单，读取下cgroups的cpu配额即可。可以直接 `import _ "github.com/uber-go/automaxprocs"` 来解决。

#### 更多任务会导致更频繁上下文切换吗

上面go运行时错误设置GOMAXPROCS导致过多P、M创建出来导致了轮询的CPU开销，这个点我们已经明确了，并且了解到了对应的解决方案。

我们还有一个顾虑：

1）同一个机器上，有多个进程，其中一个go进程因为上述原因创建了大量的线程，CFS调度器任务切换频率会不会也被推高？我们都知道上下文切换有开销。

2）同一个机器上，如果有多个进程，如果我想避免某个进程对其他进程的影响，或者某个用户下的所有进程对其他用户下的进程的影响？该如何做。

这几个问题，其实就是我深入研究CFS调度器的根本原因，因为我像搞明白混部的影响及问题边界，这对保证服务乃至系统的可用性至关重要。当然你可以不混部来绕过这些弯弯绕绕的细节。

让我来尝试会大下上面两个问题，其中2）我们已经知道了，CFS可以通过组调度来解决这类问题。我们只需要搞清楚1），1）如果CFS解决不了，意味着2）怎么着都还是无法彻底解决的。

如果任务数增多，上下文切换就更加频繁？看上去没问题，但是如果真这么做是个巨大的风险点。现代Linux系统不是早些年的时候由CS 13bits索引范围限制了GDT/LDT表长度了，2^13/2=4096个进程（每个进程占GDT表的2项），早期版本最多支持这么多个任务。但是后面Linux版本对此做了修改，解除了这里的限制。每个处理器核心只在GDT中记录它当前运行的任务的表项信息，而任务队列则交给每个处理器核心的cfs_rq，可以创建的任务数量不再受CS 13bits索引、GDT/LDT表长度限制了。Linux系统可以支持的任务数只受限于pid_max、内核配置项、系统资源了。

那意味着如果我可以创建非常多的任务出来，而如果随着任务数增多，上下文切换频率就变高，这个方案就不行，因为这样大量的CPU资源会被浪费在上下文切换上，白白浪费掉。所以调度器是绝对不会这样实现的，我们可以接受大量任务时任务调度的延迟变高，但是不能接受CPU资源被上下文切换浪费。OK，我们再根据CFS讲解来严谨地估算下上下文切换频率。

#### 谨慎评估下上下文切换频率

根据前面的介绍，任务切换 `__schedule(preempt)`的时机有3个，任务阻塞主动让出CPU、任务抢占、任务唤醒被重新加入run-queue。任务阻塞到被唤醒，让出CPU会比较久，对我们分析应该影响不大，我们将其排除在分析之外。我们只需要分析任务抢占这个路径即可，`scheduler_tick()->task_tick()->check_preempt_tick()`，这里面会检查当前任务是否应该被抢占，发生抢占才会发生上下文切换。

似乎不是那么好计算，因为没有固定的时间片，大的方向是：执行时间没有用完动态时间片的情况下，而且即使有vruntime更小的，也会让它先等，以让当前进程尽可能多执行一点，以让运行时间多接近时间片一点。那我们简化下这个量化模型，姑且认为所有任务都能执行时间片长度。

Ok，那时间片长度是如何计算的？sched_slice来计算动态时间片，大致计算方式是:

```
u64 slice = __sched_period(cfs_rq->nr_running + !se->on_rq);
slice = __calc_delta(slice, se->load.weight, load);
```

第1步__sched_period计算的是调度周期：1）nr_running<=8时，固定6ms；2）nr_running>8时，等于nr_running*0.75ms；

第2步 __calc_delta按当前任务贡献的全局权重来瓜分调度周期，作为该任务的时间片；

我们忽略nice值不同的情况，以及交互式程序、非交互式程序的奖励、处罚，我们将所有任务一视同仁，他们优先级都一样，那么他们的权重也一样，那么预期他们瓜分到的时间片也是一样的。那当任务数很多的时候，上下文切换频率 = nr_running*0.75ms / nr_running=0.75ms吗？

这里我们严谨一点：

1）随着任务数量增加，尤其是增加的那一瞬间内，上下文切换频率可能会“突增”，但是达到一定稳态后，上下文切换频率会下降下来并下降到一个更小的值；

2）如果继续增大任务数量，上下文切换频率可能会比之前还高；

3）继续增大任务数量，继续增大、增大、增大，上下文切换频率不会无限制增大，也就是我们说的，当很多任务要调度的时候，可能就是每隔0.75ms切换一下。

这样设计其实是对的，可以避免过多的上下文切换开销带来的CPU资源的浪费，反而保证了吞吐量，只是可能牺牲了点调度的及时性，引入了一点延迟，但是这对于稳定性来说是值得的。

#### 实际测试下

我们写个工具测试下，thread_test.c：

```c
#include <stdio.h>
#include <stdlib.h>
#include <pthread.h>
#include <unistd.h>

// Thread function
void *thread_func(void *arg) {
    long long i = 0;
    while (1) {
        i++;  // Simple increment operation
    }
    return NULL;
}

int main(int argc, char *argv[]) {
    if (argc != 2) {
        printf("Usage: %s -n <thread_count>\n", argv[0]);
        return 1;
    }

    int thread_count = atoi(argv[1] + 2);  // Skip "-n"
    if (thread_count <= 0) {
        printf("Invalid thread count: %d\n", thread_count);
        return 1;
    }

    pthread_t *threads = malloc(thread_count * sizeof(pthread_t));
    if (!threads) {
        perror("Failed to allocate memory for threads");
        return 1;
    }

    printf("Creating %d threads...\n", thread_count);

    // Create threads
    for (int i = 0; i < thread_count; i++) {
        if (pthread_create(&threads[i], NULL, thread_func, NULL) != 0) {
            perror("Failed to create thread");
            free(threads);
            return 1;
        }
    }

    printf("Threads created. Press Ctrl+C to exit...\n");

    // Wait indefinitely (or until Ctrl+C)
    while (1) {
        sleep(1);
    }

    // This code is unreachable but included for completeness
    free(threads);
    return 0;
}
```

编译构建：`gcc -o thread_test thread_test.c -lpthread。`

然后为了避免其他机器进程的影响，我们使用docker来隔离下环境，然后在docker容器里观察该进程下所有线程的上下文切换次数：

shell1:

```bash
# 先创建容器，分配一个cpu减少多核负载均衡影响
docker run --name linux101 --rm -it -v .:/workspace --cpus=1 --cap-add SYS_ADMIN hitzhangjie/linux101:latest /bin/bash

# 启动进程
cd /workspace
./thread_test -n1 #逐渐增大到2,3,4,5,8,16,32,64,128,256,512,1024,2048,4096等分别观察
```

shell2:

```bash
# 先进入容器
docker exec linux101 -it /bin/bash` 

# perf观察，每1s输出一次结果
perf stat -e context-switches -I 1000 -p `pidof thread_test`
```

逐渐增大thread_test -n<?>的参数值，观察这个增大的过程中，perf观察到的上下文切换的频率变化（每妙多少次）。理论上我推测单处理器核心CFS最多执行1333次切换，因为1000ms/0.75ms=1333.3，实际上我在测试的时候还是有点偏差。系统中还有其他服务存在，优先级不一样，另外上下文切换本身也有开销，可能会导致这里的测试有一定偏差。但是刻意肯定的是，从-n1024到-n2048并不会导致类似的倍数关系的上下文切换，单核心情况下基本就是维持在500次/s左右。

```c
     9.001905387                168      context-switches      <= 16 threads, 168 次/s
    10.099542009                184      context-switches
    11.099730077                164      context-switches
    12.099939851                173      context-switches
    13.100139972                174      context-switches   
     ...

     4.299515329                372      context-switches      <= 64 threads, 372 次/s
     5.399359483                387      context-switches
     6.499338791                380      context-switches
     7.599256072                397      context-switches
     8.599614313                355      context-switches   
     ...

     7.699145120                458      context-switches      <= 256 threads, 458 次/s
     8.798950683                418      context-switches
     9.899027530                447      context-switches
    10.998943248                434      context-switches
    12.198541640                449      context-switches
    13.199237596                440      context-switches   
    ...

   157.899086597                551      context-switches      <= 512 threads，598/(159-157) = 299 次/s
   159.000687239                598      context-switches
   160.100710621                507      context-switches
   161.200539649                504      context-switches
   162.300472054                516      context-switches
   ...

   56.603350232              6,854      context-switches       <= 2048 threads, 6991/(71-56)=466 次/s
   71.400023708              6,991      context-switches
   83.700729604              6,418      context-switches
   102.100561290              8,369      context-switches
   120.800407842              8,847      context-switches
   ...
```

达到上限500左右我好理解，但是线程数少的时候，上下文切换次数也少，比如16比64threads时少，64比256threads时少……，这个我没搞明白。我怀疑这里面有个地方还是影响到了动态时间片的计算，但是我没证据。如何通过bpf来拿到动态时间片大小并输出出来呢？后面注意到测试机器的内核参数是被运维管理员调整优化过的，可能也对这里的测试造成了一定影响。

```
kernel.sched_latency_ns = 24000000  // 不是默认的6ms
kernel.sched_min_granularity_ns = 3000000 // 不是默认的0.75ms
```

如果所有任务权重一样、任务数量不变，那么动态时间片也一样=3ms，那么一秒内上下文切换次数=1000/3=333.3次/s。但是如果实际执行中，确实涉及到优先级、贡献负载不同、任务新建退出，那么这里的值是可能会变的，动态时间片可能大也可能小，就不一定等于3ms，那么上下文切换次数也会在这个数值基础上上下浮动。

由于我用docker进行了隔离，实际上其他系统服务进程影响可以忽略不计，因为他们影响也没有那么大，反倒是我大量增加线程数时，看到了上下切换次数的明显上升。所以一定是算出来的动态时间片有减小的情况。但是调度周期=nr_running*3ms，nr_running几乎不变，而且这些线程的优先级相同，最后在系统中的权重占比也应该一样，那么他们瓜分得到的执行时间片也应该一样，就应该是3ms才对啊。还是感觉这个值应该在333左右，不应该出现明显的上涨。

继续考虑之前我们主动忽略掉的一个问题，任务抢占时，有可能没有完全用光时间片，就可能被切换，如果当前运行任务的 vruntime 显著大于队列中最小的 vruntime，就可能触发切换。如果线程数增多，理论上上述vruntime差异更容易产生，任务队列待选任务更多，可能导致实际执行时间少于理论时间，导致上下文切换频率上升，超过333次/s。

那么为什么线程数少的时候又小于333次/s呢？……

#### 使用bpf来跟踪下任务执行时间

写一个bpftrace脚本，sched_trace.bt：
```
#!/usr/bin/env bpftrace

BEGIN
{
    printf("Tracing CFS scheduler... Hit Ctrl-C to end.\n");
    @last_switch = nsecs;
}

// 跟踪进程切换事件
tracepoint:sched:sched_switch
{
    $prev_pid = args->prev_pid;
    $next_pid = args->next_pid;
    $prev_prio = args->prev_prio;
    $next_prio = args->next_prio;
    $prev_comm = args->prev_comm;
    $next_comm = args->next_comm;

    // 计算两次切换之间的时间间隔（实际运行时间）
    $delta = nsecs - @last_switch;
    @last_switch = nsecs;

    // 只关注 thread_test 相关的线程
    if (strncmp($prev_comm, "thread_test", 10) == 0 || strncmp($next_comm, "thread_test", 10) == 0) {
        // 记录运行时间分布（单位：微秒）
        @runtime_us = hist($delta / 1000);
        
        // 记录超过理论时间片(3ms)的次数
        if ($delta > 3000000) {
            @long_runtime++;
        }
        
        // 打印详细信息
        printf("switch: %s(%d) -> %s(%d), runtime: %d us\n", 
               $prev_comm, $prev_pid, $next_comm, $next_pid, $delta / 1000);
    }
}

// 跟踪唤醒事件
tracepoint:sched:sched_wakeup
{
    $pid = args->pid;
    $comm = args->comm;
    
    if (strncmp($comm, "thread_test", 10) == 0) {
        @wakeups[$comm]++;
    }
}

END
{
    clear(@last_switch);
    printf("\nRuntime distribution (microseconds):\n");
    print(@runtime_us);
    printf("\nLong runtime (>3ms) count: %d\n", @long_runtime);
    printf("\nWakeup counts per thread:\n");
    print(@wakeups);
}
```

然后在docker宿主机上执行 `bpftrace sched_trace.bt`，注意使用root权限。

128threads时：

```
Runtime distribution (microseconds):
@runtime_us:
[0]                  749 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[1]                  428 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                       |
[2, 4)               346 |@@@@@@@@@@@@@@@@@@@@@@@@                            |
[4, 8)               322 |@@@@@@@@@@@@@@@@@@@@@@                              |
[8, 16)              210 |@@@@@@@@@@@@@@                                      |
[16, 32)              40 |@@                                                  |
[32, 64)              19 |@                                                   |
[64, 128)             40 |@@                                                  |
[128, 256)            78 |@@@@@                                               |
[256, 512)            73 |@@@@@                                               |
[512, 1K)             34 |@@                                                  |
[1K, 2K)               0 |                                                    |
[2K, 4K)               0 |                                                    |
[4K, 8K)               0 |                                                    |
[8K, 16K)              0 |                                                    |
[16K, 32K)             0 |                                                    |
[32K, 64K)             0 |                                                    |
[64K, 128K)            0 |                                                    |
[128K, 256K)           0 |                                                    |
[256K, 512K)           0 |                                                    |
[512K, 1M)             0 |                                                    |
[1M, 2M)               0 |                                                    |
[2M, 4M)               0 |                                                    |
[4M, 8M)               0 |                                                    |
[8M, 16M)              0 |                                                    |
[16M, 32M)             0 |                                                    |
[32M, 64M)             0 |                                                    |
[64M, 128M)            0 |                                                    |
[128M, 256M)           0 |                                                    |
[256M, 512M)           0 |                                                    |
[512M, 1G)             0 |                                                    |
[1G, 2G)               0 |                                                    |
[2G, 4G)               1 |                                                    |
```

注意到大多数线程执行时间片都没有达到3ms，然后我们调整下bpf程序只让它跟踪threadtest->threadtest的切换。

128 threads时：

```
switch: thread_test(1888921) -> thread_test(1888874), runtime: 32 us
switch: thread_test(1888874) -> thread_test(1888921), runtime: 7 us
switch: thread_test(1888988) -> thread_test(1888939), runtime: 287 us
switch: thread_test(1888914) -> thread_test(1888892), runtime: 132 us
switch: thread_test(1888944) -> thread_test(1888940), runtime: 59 us
switch: thread_test(1888961) -> thread_test(1888895), runtime: 0 us
switch: thread_test(1888884) -> thread_test(1888932), runtime: 139 us
switch: thread_test(1888948) -> thread_test(1888998), runtime: 89 us
switch: thread_test(1888905) -> thread_test(1888926), runtime: 0 us
switch: thread_test(1888943) -> thread_test(1888981), runtime: 12 us
switch: thread_test(1888892) -> thread_test(1888910), runtime: 101 us
...

@runtime_us:
[0]                  281 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[1]                  128 |@@@@@@@@@@@@@@@@@@@@@@@                             |
[2, 4)                88 |@@@@@@@@@@@@@@@@                                    |
[4, 8)                33 |@@@@@@                                              |
[8, 16)               71 |@@@@@@@@@@@@@                                       |
[16, 32)              79 |@@@@@@@@@@@@@@                                      |
[32, 64)              80 |@@@@@@@@@@@@@@                                      |
[64, 128)            165 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                      |
[128, 256)           161 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@                       |
[256, 512)           121 |@@@@@@@@@@@@@@@@@@@@@@                              |
[512, 1K)             28 |@@@@@                                               |
```

1024 threads时：
```
@runtime_us:
[0]                  605 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[1]                  206 |@@@@@@@@@@@@@@@@@                                   |
[2, 4)                29 |@@                                                  |
[4, 8)                15 |@                                                   |
[8, 16)               15 |@                                                   |
[16, 32)              18 |@                                                   |
[32, 64)              29 |@@                                                  |
[64, 128)             29 |@@                                                  |
[128, 256)            26 |@@                                                  |
[256, 512)            43 |@@@                                                 |
[512, 1K)              6 |                                                    |
[1K, 2K)               0 |                                                    |
[2K, 4K)               0 |                                                    |
[4K, 8K)               0 |                                                    |
[8K, 16K)              0 |                                                    |
[16K, 32K)             0 |                                                    |
```

2048threads：
```
@runtime_us:
[0]                  591 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[1]                  216 |@@@@@@@@@@@@@@@@@@@                                 |
[2, 4)                37 |@@@                                                 |
[4, 8)                20 |@                                                   |
[8, 16)                8 |                                                    |
[16, 32)              12 |@                                                   |
[32, 64)              25 |@@                                                  |
[64, 128)             38 |@@@                                                 |
[128, 256)            15 |@                                                   |
[256, 512)            22 |@                                                   |
[512, 1K)              2 |                                                    |
```

4096threads：
```
[0]                  718 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[1]                  263 |@@@@@@@@@@@@@@@@@@@                                 |
[2, 4)                60 |@@@@                                                |
[4, 8)                17 |@                                                   |
[8, 16)               12 |                                                    |
[16, 32)              16 |@                                                   |
[32, 64)              43 |@@@                                                 |
[64, 128)             56 |@@@@                                                |
[128, 256)            16 |@                                                   |
[256, 512)            49 |@@@                                                 |
[512, 1K)              4 |                                                    |
[1K, 2K)               0 |                                                    |
```

So ... 实际上算出来的动态时间片，跟我们想象的完全不一样，它并没有尽可能逼近那个最小值3ms。表现上确实是随着线程数增加，每个线程的执行时间片变少了。很容易看出来随着线程数从128增加到1024时，每个线程的执行时间在直方图分布中显著地减少到了[0,2)微秒的桶范围内。但是当我从1024继续增大线程数到2048甚至4096时，变化就不那么明显了。

我们只是观察到了这个现象，并没有从源码层面确定为什么会这样。或者我们之前的另一个假设也是有问题的，我们创建出来的这些线程，尽管看上去他们优先级相同，我们就假定它贡献的负载相同，实际上可能也不同，最终导致这个动态时间片算出来也不同。

还需要继续调查下这里 …… 究竟是为什么。



