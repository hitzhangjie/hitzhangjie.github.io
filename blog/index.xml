<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>博客 on 介绍</title>
    <link>https://hitzhangjie.github.io/blog/</link>
    <description>Recent content in 博客 on 介绍</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sat, 19 May 2018 19:55:15 +0800</lastBuildDate>
    
	<atom:link href="https://hitzhangjie.github.io/blog/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>golang function-closure 实现机制</title>
      <link>https://hitzhangjie.github.io/blog/2018-05-19-golang-function-closure%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Sat, 19 May 2018 19:55:15 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2018-05-19-golang-function-closure%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/</guid>
      <description>golang里面函数时first-class citizen，可以作为值进行参数传递，不管是普通函数“func abc()”，还是成员方法“func (x X) xxx()”，还是一个闭包“func () { return func(){&amp;hellip;.}}”……看上去很方便，不禁要问，golang里面funciton和closure是如何实现的呢？扒拉了下源码，这里简单总结下。
1 golang中函数内部表示是什么样子的？ 看下golang cmd/compile/internal/types/type.go中对Func类型的定义：
// Func contains Type fields specific to func types. type Func struct { Receiver *Type // function receiver，接受者类型，每个函数定义都包括该字段，可以为nil或non-nil  Results *Type // function results，返回值类型  Params *Type // function params，参数列表类型  Nname *Node // function name，函数名  // Argwid is the total width of the function receiver, params, and results.  // It gets calculated via a temporary TFUNCARGS type.</description>
    </item>
    
    <item>
      <title>golang select-case 实现机制</title>
      <link>https://hitzhangjie.github.io/blog/2018-05-19-golang-select-case%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Sat, 19 May 2018 19:21:11 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2018-05-19-golang-select-case%E5%AE%9E%E7%8E%B0%E6%9C%BA%E5%88%B6/</guid>
      <description>1 chan操作规则 在介绍select-case实现机制之前，最好先了解下chan操作规则，明白goroutine何时阻塞，又在什么时机被唤醒，这对后续理解select-case实现有帮助。所以接下来先介绍chan操作规则，然后再介绍select-case的实现。
1.1 chan操作规则1 当一个goroutine要从一个non-nil &amp;amp; non-closed chan上接收数据时，goroutine首先会去获取chan上的锁，然后执行如下操作直到某个条件被满足：
1）如果chan上的value buffer不空，这也意味着chan上的recv goroutine queue也一定是空的，该接收goroutine将从value buffer中unshift出一个value。这个时候，如果send goroutine队列不空的情况下，因为刚才value buffer中空出了一个位置，有位置可写，所以这个时候会从send goroutine queue中unshift出一个发送goroutine并让其恢复执行，让其执行把数据写入chan的操作，实际上是恢复该发送该goroutine执行，并把该发送goroutine要发送的数据push到value buffer中。然后呢，该接收goroutine也拿到了数据了，就继续执行。这种情景，channel的接收操作称为non-blocking操作。
2）另一种情况，如果value buffer是空的，但是send goroutine queue不空，这种情况下，该chan一定是unbufferred chan，不然value buffer肯定有数据嘛，这个时候接收goroutine将从send goroutine queue中unshift出一个发送goroutine，并将该发送goroutine要发送的数据接收过来（两个goroutine一个有发送数据地址，一个有接收数据地址，拷贝过来就ok），然后这个取出的发送goroutine将恢复执行，这个接收goroutine也可以继续执行。这种情况下，chan接收操作也是non-blocking操作。
3）另一种情况，如果value buffer和send goroutine queue都是空的，没有数据可接收，将把该接收goroutine push到chan的recv goroutine queue，该接收goroutine将转入blocking状态，什么时候恢复期执行呢，要等到有一个goroutine尝试向chan发送数据的时候了。这种场景下，chan接收操作是blocking操作。
1.2 chan操作规则2 当一个goroutine常识向一个non-nil &amp;amp; non-closed chan发送数据的时候，该goroutine将先尝试获取chan上的锁，然后执行如下操作直到满足其中一种情况。
1）如果chan的recv goroutine queue不空，这种情况下，value buffer一定是空的。发送goroutine将从recv goroutine queue中unshift出一个recv goroutine，然后直接将自己要发送的数据拷贝到该recv goroutine的接收地址处，然后恢复该recv goroutine的运行，当前发送goroutine也继续执行。这种情况下，chan send操作是non-blocking操作。
2）如果chan的recv goroutine queue是空的，并且value buffer不满，这种情况下，send goroutine queue一定是空的，因为value buffer不满发送goroutine可以发送完成不可能会阻塞。该发送goroutine将要发送的数据push到value buffer中然后继续执行。这种情况下，chan send操作是non-blocking操作。
3）如果chan的recv goroutine queue是空的，并且value buffer是满的，发送goroutine将被push到send goroutine queue中进入阻塞状态。等到有其他goroutine尝试从chan接收数据的时候才能将其唤醒恢复执行。这种情况下，chan send操作是blocking操作。
1.3 chan操作规则3 当一个goroutine尝试close一个non-nil &amp;amp; non-closed chan的时候，close操作将依次执行如下操作。</description>
    </item>
    
    <item>
      <title>go风格协程库libmill之源码分析</title>
      <link>https://hitzhangjie.github.io/blog/2017-12-03-go%E9%A3%8E%E6%A0%BC%E5%8D%8F%E7%A8%8B%E5%BA%93libmill%E4%B9%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</link>
      <pubDate>Sun, 03 Dec 2017 16:49:09 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-12-03-go%E9%A3%8E%E6%A0%BC%E5%8D%8F%E7%A8%8B%E5%BA%93libmill%E4%B9%8B%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/</guid>
      <description>1 Preface libmill, 是Martin Sustrik发起的一个面向unix平台下c语言开发的协程库，实现了一种类似goroutine风格的协程，也支持channel，“通过通信共享数据，而非通过共享数据来完成通信”。
觉得挺有意思的，就抽周末时间看了下。大神的代码干净利索，也看到了不少令自己眼前一亮的tricks，举几个例子吧。
1 通用链表及迭代器实现
offsetof可以计算结构体中的成员的offset，如果我们知道一个struct的类型、其成员名、成员地址，我们就可以计算出struct的地址：
#define mill_cont(ptr, type, member) \ (ptr ? ((type*) (((char*) ptr) - offsetof(type, member))) : NULL) 基于此可以进一步实现一个通用链表，怎么搞呢？
struct list_item { struct list_item * next; }; struct my_struct { void * data; struct list_item * iter; }; 我们通过list_item来构建链表，并在自定义my_struct中增加一个list_item成员，将其用作迭代器。当我们希望构建一个my_struct类型的链表时实际上构建的是list_item的列表，当我们遍历my_struct类型的链表时遍历的也是list_item构成的链表。加入现在遍历到了链表中的某个list_item item，就可以结合前面提到的mill_cont(&amp;amp;item, struct list_item, iter)来获得包括成员的结构体地址，进而就可以访问结构体中的data了。
其实这里Martin Sustrik的实现方式与Linux下的通用链表相关的宏实现类似，只是使用起来感觉更加自然一些，也更容易被接受。
2 栈指针调整（分配协程栈）
栈的分配有两个时机，一个是编译时，一个是运行时。对于编译时可以确定占用空间大小的就在编译时生成对应的汇编指令来分配，如：sub 0x16, %rsp；对于运行时才可以确定占用空间大小的就要在运行时分配，如：int n = srand()%16; int buf[n];，这个如何分配呢？Linux下有个库函数alloca可以在当前栈帧上继续分配空间，但是呢？它不会检查是否出现越界的行为，注意了，因为内存分配后，栈顶会发生变化，寄存器%rsp会受到影响，也是基于这个side effect，就可以实现让指定的函数go(func)将新分配的内存空间当做自己的栈帧继续运行。这样每个协程都有自己的栈空间，再存储一下协程上下文就可以很方便地实现协程切换。
#define mill_go_(fn) \ do {\ void *mill_sp;\ mill_ctx ctx = mill_getctx_();\ if(!</description>
    </item>
    
    <item>
      <title>Assembly Language</title>
      <link>https://hitzhangjie.github.io/blog/2017-10-14-assembly-language/</link>
      <pubDate>Sat, 14 Oct 2017 20:13:35 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-10-14-assembly-language/</guid>
      <description>处理器是算逻运算、控制操作的执行部件，它只能识别机器指令并执行动作。机器指令是一系列的0、1字符串，本质上对应了总线上的高低电平信号，所以机器语言都是特定于硬件的。
由于0、1字符串很难记忆，用机器语言开发是一个老大难的问题，汇编语言因此被开发出来用于代替机器语言。汇编指令只是机器指令中操作码的助记符，因此汇编语言仍然是机器强相关的，不同的处理器其对应的汇编指令也不同。
学习汇编语言有助于理解：
 程序是如何与操作系统、处理器、bios进行交互的； 数据如何在内存中以及外设中表示的； 处理器如何访问、执行指令； 指令如何访问、处理数据； 程序如何访问外设；  其他使用汇编语言的优势：
 消耗更少的内存和处理器执行时间； 允许以更简单的方式来完成硬件特定的复杂作业； 适用于时间敏感的作业； 适用于编写中断服务程序和内存驻留程序；  1.1 PC硬件的基本特征 机器指令是0、1字符串，分别表示ON、OFF，对应数字信号的高低电平。机器中的最低存储单位是bit，通常8bit构成一个byte，为了对数据传输过程中传输数据的有效性进行检查，通常会在数据byte发送之后再追加一个奇偶校验bit。
 奇校验：保证8bit数据+1bit校验位中的1的个数为奇数； 偶校验：保证8bit数据+1bit校验位中的1的个数为偶数；  发送方、接收方遵循相同的奇偶校验规则，如果接收方收到数据后发现奇偶校验不正确，则表示可能硬件出错，或者出现了电平扰动。
处理器支持如下数据尺寸：
|:&amp;mdash;|:&amp;mdash;&amp;mdash;| |Word|2 bytes| |Doubleword|4 bytes| |Quadword|8 bytes| |Paragraph|16 bytes| |Kilobyte|2^10 bytes| |Megabyte|2^20 bytes|
二进制 &amp;amp; 十六进制系统：
二进制天然适用于计算机计算领域，0、1刚好代表数字电路中的高低电平；而十六进制是用于对比较长的二进制数值进行更加优雅地简写，使我们表示起来更加清晰、简单。
二进制、十六进制的相关运算，特别是涉及到原码、反码、补码、移码的运算，需要重点了解下，建议参考《计算机组成原理》相关章节。
访问内存中的数据：
处理器控制指令执行的过程可以简化为”取指令-指令移码-指令执行“的循环体，一个”取指令-指令译码-指令执行“周期称之为一个机器周期。
 取指周期：根据CS、IP从内存指定位置取指令，并存储到指令寄存器IR； 译码周期：根据IR中的指令，分析出操作码OP、操作数或操作数地址； 执行周期：根据分析出的OP、操作数或操作地址信息执行相应的动作；  Intel架构的处理器在内存中存储时是采用的小端字节序，意味着一个多字节数值的低字节部分将在低地址存储，高字节部分将在高地址存储，但是在处理器寄存器中存储时低字节部分就在低字节，高字节部分就在高字节，所以在处理器寄存器、内存之间存储、加载数据时需要做字节序方面的转换。
以处理器寄存器中数值0x1234为例，现在要将其存储到内存中，处理器先将0x34存储到内存低地址，然后再见0x12存储到内存高地址；假如内存中有数据0xabcd，现在要将其加载到处理器寄存器中，加载时也会做对应的处理，将0xab放在寄存器高位，将0xcd放在寄存器低位。
指令中的操作数地址，又有多种不同的寻址方式，立即数寻址、直接寻址、间接寻址、寄存器寻址等，这里后面会做相应的介绍。
1.2 开发环境配置 汇编指令特定于处理器的，因此不同的处理器系列、型号对应的汇编指令可能也会有差异，这里使用的是Intel-32架构的处理器，使用汇编器NASM进行汇编操作，其他可选的汇编器还有MASM、TASM、GAS等。
1.3 基本语法 汇编程序通常包括3个节，分别是data、bss、text节：
 data，用于声明初始化的变量和常量； bss，用于声明未初始化的变量，这部分不会出现在编译后的程序中； text，用于保存程序指令；  text节中必须包括&amp;rdquo;global ${entry}&amp;ldquo;声明，${entry}是程序入口，通常定义未_start，见文生义嘛。
汇编程序中的注释均以&amp;rdquo;;&amp;ldquo;开头，直到所在行结束。
汇编语言程序包括3种不同类型的语句：
 可执行汇编指令； 传递给汇编器的指令或伪操作； 宏；  汇编语言语句遵循如下结构：</description>
    </item>
    
    <item>
      <title>Protoc及其插件工作原理分析(精华版)</title>
      <link>https://hitzhangjie.github.io/blog/2017-05-23-protoc%E5%8F%8A%E6%8F%92%E4%BB%B6%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E7%B2%BE%E5%8D%8E%E7%89%88/</link>
      <pubDate>Tue, 23 May 2017 16:29:25 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-05-23-protoc%E5%8F%8A%E6%8F%92%E4%BB%B6%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%88%86%E6%9E%90%E7%B2%BE%E5%8D%8E%E7%89%88/</guid>
      <description>在进行protoc插件开发之前，首先要了解protoc的工作原理。protobuf具有诸多优点被广泛使用，由于protoc对proto文件的强大解析能力使我们可以更进一步来开发一些插件，通过插件快速生成特定于proto文件的工具类、配置文件等，从而提高开发效率。
本文首先会介绍一下protoc的整体工作原理，然后详细介绍一下protoc对proto文件的解析过程，最后给出编写protoc插件来扩展protoc功能的一个示例（这里以protoc-gen-go插件为例）。
1. protoc工作原理分析 1.0. protoc源代码准备 要想了解protoc的工作机制，查看其源代码了解其核心流程是最靠谱的方法。
获取程序源代码的方式如下：
git co https://github.com/google/protobuf 由于我们工程中常用的protoc版本是v2.5.0，所以这里检出对应版本的tag。
git ck v2.5.0 考虑到可能会进行测试、修改、注释等学习过程，这里最好创建一个新的分支来操作。
git branch -b ${new-branch-name} 现在源代码准备好了，下面可以阅读protoc的源码梳理一下其工作原理了。
上述git检出后的protobuf路径，记为${protobuf}，后面如果出现${protobuf}请知晓其含义。如果在描述源代码时没有提及代码起始路径${protobuf}，那么起始路径均为${protobuf}。
1.1. protoc执行流程说明 protoc执行流程的相关源码，主要包括如下两个部分。
1.1.1. protoc程序入口 protoc程序入口为以下源文件main函数，该入口函数中完成protoc命令行接口初始化、编程语言及代码生成器注册后，调用cli.Run(argc,argv)解析proto文件并生成特定语言的源代码。
file: src/google/protobuf/compiler/main.cc
// Author: kenton@google.com (Kenton Varda)  // 这个头文件定义了protoc的命令行接口 #include &amp;lt;google/protobuf/compiler/command_line_interface.h&amp;gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include &amp;lt;google/protobuf/compiler/cpp/cpp_generator.h&amp;gt;#include &amp;lt;google/protobuf/compiler/python/python_generator.h&amp;gt;#include &amp;lt;google/protobuf/compiler/java/java_generator.h&amp;gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件 	// - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头 	// - 假定protoc --foo_out，那么实际调用的插件是protoc-foo 	google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(&amp;#34;protoc-&amp;#34;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator) 	google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.</description>
    </item>
    
    <item>
      <title>Protoc工作原理分析</title>
      <link>https://hitzhangjie.github.io/blog/2017-05-16-protoc%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</link>
      <pubDate>Fri, 19 May 2017 14:29:25 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-05-16-protoc%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86/</guid>
      <description>在进行protoc插件开发之前，首先要了解protoc的工作原理。在protobuf的使用过程中，protoc作为proto文件的编译器，很多开发人员只会用但是不了解其工作原理，更不了解如何扩展其功能。protobuf作为目前常用的数据交换格式在协议开发中被广泛采用，此外，protoc对proto文件的强大解析能力使我们可以开发一些插件，通过插件快速生成特定于proto文件的工具类、配置文件等，从而提高开发效率。
本文首先会介绍一下protoc的整体工作机制，然后解释一下protoc对proto文件的解析过程，最后给出编写protoc插件扩展protoc功能的一个示例教程。
1. protoc源代码准备 要想了解protoc的工作机制，查看其源代码了解其核心流程是最靠谱的方法。
获取程序源代码的方式如下：
git co https://github.com/google/protobuf 由于我们工程中常用的protoc版本是v2.5.0，所以这里检出对应版本的tag。
git ck v2.5.0 考虑到可能会进行测试、修改、注释等学习过程，这里最好创建一个新的分支来操作。
git branch ${new-branch-name} git ck ${new-branch-name} 现在源代码准备好了，我比较喜欢使用vim、ctags、cscope来阅读源码，根据个人习惯吧，下面可以阅读protoc的源码梳理以下工作机制。
2. protoc源码分析 上述git检出后的protobuf路径，记为${protobuf}，后面如果出现${protobuf}请知晓其含义。如果在描述源代码时没有提及起始路径${protobuf}，那么起始路径均为${protobuf}。
2.1. protoc程序入口 src/google/protobuf/compiler/main.cc中的main函数，为protoc的入口函数。
file: src/google/protobuf/compiler/main.cc
// Author: kenton@google.com (Kenton Varda)  // 这个头文件定义了protoc的命令行接口 #include &amp;lt;google/protobuf/compiler/command_line_interface.h&amp;gt; // protoc中内置了对cpp、python、java语言的支持，对其他语言的支持需要以plugin的方式来支持 #include &amp;lt;google/protobuf/compiler/cpp/cpp_generator.h&amp;gt;#include &amp;lt;google/protobuf/compiler/python/python_generator.h&amp;gt;#include &amp;lt;google/protobuf/compiler/java/java_generator.h&amp;gt; int main(int argc, char* argv[]) { // 初始化protoc命令行接口并开启插件  // - 插件只是普通的可执行程序，其文件名以AllowPlugins参数protoc-开头  // - 假定protoc --foo_out，那么实际调用的插件是protoc-foo  google::protobuf::compiler::CommandLineInterface cli; cli.AllowPlugins(&amp;#34;protoc-&amp;#34;); // Proto2 C++ (指定了--cpp_out将调用cpp::Generator)  google::protobuf::compiler::cpp::CppGenerator cpp_generator; cli.</description>
    </item>
    
    <item>
      <title>Linux常见IO模型</title>
      <link>https://hitzhangjie.github.io/blog/2017-05-02-linux-common-io-model/</link>
      <pubDate>Tue, 02 May 2017 21:42:13 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-05-02-linux-common-io-model/</guid>
      <description>目前Linux下可用的IO模型有5种，分别为阻塞IO、非阻塞IO、IO多路复用、信号驱动IO、异步IO，其中较为成熟且高效、稳定的是IO多路复用模型，因此当前众多网络服务程序几乎都是采用这种IO操作策略。
当一个应用程序读写（以读为例）某端口数据时，选择不同IO模型的应用程序，其执行流程也将不同。下面将对选择这5种不同IO模型时的程序的执行情形进行分析，以便了解使用IO复用模型的运行情况和性能优势。
一个完整经典的应用程序的数据读取操作可以看做两步：
 等待数据准备好； 将数据从内核复制到应用程序进程；  1. 阻塞IO模型 最流行的IO模型是阻塞IO（Blocking IO）模型，几乎所有刚开始学习IO操作的人员都是使用这个模型，虽然它存在一定的性能缺陷，但是它的确很简单。
如下图所示，是利用该模型读取IO端口数据的典型流程。在有些情况下，当系统调用发现用户请求的IO操作不能立刻完成时（比如对IO写操作，缓冲区没有空闲空间或者空闲空间少于待写的数据量；而对于读操作，缓冲区中没有数据可读或者可读数据少于用户请求的数据量），则当前的进程会进入睡眠，也就是进程被IO读写阻塞。但是当数据可以写出或者有数据可供读入时（其他进程或线程从缓冲区中读走了数据后或者向缓冲区写入了数据），系统将会产生中断，唤醒在缓冲区上等待相应事件的进程继续执行。
 备注：
有必要在这里进一步解释一下“阻塞IO”的含义。通过阻塞IO系统调用进行IO操作时，以read为例，在内核将数据拷贝到用户程序完成之前，Linux内核会对当前read请求操作的缓冲区（内存中的特殊区域）进行加锁，并且会将调用read的进程的状态设置为 “uninterruptible wait”状态（不可中断等待状态），处于该状态的进程将无法参与进程调度。能够参与进程调度的进程的状态必须是处于running状态的进程或者有信号到达的处于interruptible wait状态（可中断等待状态）的进程。当read操作完成时，内核会将对应的缓冲块解锁，然后发出中断请求，内核中的中断服务程序会将阻塞在该缓冲块上的进程的状态修改为running状态以使其重新具备参与进程调度的能力。
 2. 非阻塞IO模型 在有些时候并不希望进程在IO操作未完成时睡眠，而是希望系统调用能够立刻返回一个错误，以报告这一情况，然后进程可以根据需要在适当的时候再重新执行这个IO操作。这就是所谓的非阻塞IO模型。
如下图所示，应用程序前几次read系统调用时都没有数据可供返回，此时内核立即返回一个EAGAIN错误代码，程序并不睡眠而是继续调用read，当第四次调用read时数据准备好了，于是执行数据从内核到用户空间的复制操作并成功返回，应用程序接着处理数据。这种对一个非阻塞IO端口反复调用read进行数据读取的动作称为轮询，即应用程序持续轮询内核数据是否准备好。这里的持续轮询操作将导致耗费大量的CPU时间，因此该模型并不推荐使用。
3. IO多路复用模型 前面介绍了非阻塞IO模型的问题在于，尽管应用程序可以在当前IO操作不能完成的时候迫使系统调用立刻返回而不至于睡眠，但是却无法知道什么时候再次请求IO操作可以顺利完成，只能周期性地做很多无谓的轮询，每隔一段时间就要重新请求一次系统调用，这种轮询策略极大浪费了CPU时间。
IO多路复用模型就是在此之上的改进，它的好处在于使得应用程序可以同时对多个IO端口进行监控以判断其上的操作是否可以顺利（无阻塞地）完成，达到时间复用的目的。进程阻塞在类似于select、poll或epoll这样的系统调用上，而不是阻塞在真正的IO系统调用上，意思也就是说在这些select、poll或者epoll函数内部会代替我们做非阻塞地轮询，那么它的轮询策略是怎样地呢？稍后会进行介绍。
select、poll或epoll使得进程可以在多个IO端口上等待IO事件（可读、可写、网络连接请求等）的发生，当有事件发生时再根据发生事件的类型进行适当的IO处理。不过进程在等待IO事件发生时仍然在代码执行序上处于“阻塞”状态，应用程序“阻塞”在这里照样还是无法做其他的工作（尽管可以指定轮询时等待时间的长短）。因此如果希望进程在没有IO事件要处理时还能做其他的工作，这种模型是不可行的。
下图是IO多路复用模型的示例。
IO多路复用模型主要有3种实现形式，select、poll、epoll。
3.1. select #include &amp;lt;sys/select.h&amp;gt; //返回值：readfds、writefds、exceptfds中事件就绪的fd的数量 int select(int nfds, // 最大文件描述符fd+1  fd_set *restrict readfds, // 等待读取的fds  fd_set *restrict writefds, // 等待写入的fds  fd_set *restrict exceptfds, // 异常fds  struct timeval *restrict timeout); // 超时时间  //返回值：readfds、writefds、exceptfds中事件就绪的fd的数量 int pselect(int nfds, // 最大文件描述符fd+1  fd_set *restrict readfds, // 等待读取的fds  fd_set *restrict writefds, // 等待写入的fds  fd_set *restrict exceptfds, // 异常fds  const struct timespec *restrict timeout, // 超时时间  const sigset_t *restrict sigmask); // 信号掩码  备注：</description>
    </item>
    
    <item>
      <title>协程的历史、现在和未来!</title>
      <link>https://hitzhangjie.github.io/blog/2017-09-23-%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%8E%86%E5%8F%B2%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/</link>
      <pubDate>Thu, 27 Apr 2017 02:25:36 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-09-23-%E5%8D%8F%E7%A8%8B%E7%9A%84%E5%8E%86%E5%8F%B2%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/</guid>
      <description>计算机科学是一门应用科学，几乎所有概念都是为了理解或解决实际问题而生的。协程 (Coroutine) 的出现也不例外。协程的概念，最早可以追溯到写作 COBOL 语言编译器中的技术难题。
1.从磁带到协程 COBOL 是最早的高级语言之一。编译器则是高级语言必不可少的一部分。现如今，我们对编译器了解，已经到了可以把核心内容浓缩成一本教科书的程度。然而在六十年代，如何写作高效的语言编译器是那个时代绕不过的现实问题。比如，1960 年夏天，D. E. Knuth 就是利用开车横穿美国去加州理工读研究生的时间，对着 Burroughs 205 机器指令集手写 COBOL 编译器。最早提出“协程”概念的 Melvin Conway 的出发点，也是如何写一个只扫描一遍程序 (one-pass) 的 COBOL 编译器。众多的“高手”纷纷投入编译器书写，可见一门新科学发展之初也是筚路蓝缕
以现代眼光来看，高级语言编译器实际上是多个步骤组合而成：词法解析，语法解析，语法树构建，以及优化和目标代码生成等等。编译实质上就是从源程序出发，依次将这些步骤的输出作为下一步的输入，最终输出目标代码。在现代计算机上实现这种管道式的架构毫无困难：只需要依次运行，中间结果存为中间文件或放入内存即可。GCC 和 Clang 编译器，以及 ANTLR 构建的编译器，都遵循这样的设计。
在 Conway 的设计里，词法和语法解析不再是两个独立运行的步骤，而是交织在一起。编译器的控制流在词法和语法解析之间来回切换：当词法模块读入足够多的 token 时，控制流交给语法分析；当语法分析消化完所有 token 后，控制流交给词法分析。词法和语法分别独立维护自身的运行状态。Conway 构建的这种协同工作机制，需要参与者“让出 (yield)”控制流时，记住自身状态，以便在控制流返回时能够从上次让出的位置恢复(resume)执行。简言之，协程的全部精神就在于控制流的主动让出和恢复。我们熟悉的子过程调用可以看作在返回时让出控制流的一种特殊的协程，其内部状态在返回时被丢弃了，因此不存在“恢复”这个操作。
以现在眼光来看，编译器的实现并不必然需要协程。然而，Conway 用协程实现 COBOL 编译器在当时绝不是舍近求远。
2.自顶向下，无需协同 虽然协程是伴随着高级语言诞生的，它却没有能像子过程一样成为通用编程语言的基本元素。
从 1963 年首次提出到上个世纪九十年代，我们在 ALOGL, Pascal, C, FORTRAN 等主流的命令式编程语言中都没有看到原生的协程支持。协程只稀疏地出现在 Simula，Modular-2 (Pascal 升级版) 和 Smalltalk 等相对小众的语言中。协程作为一个比子进程更加通用的概念，在实际编程却没有取代子进程，这一点不得不说是出乎意外的。如果我们结合当时的程序设计思想看，这一点又是意料之中的：协程是不符合那个时代所崇尚的“自顶向下”的程序设计思想的，自然也就不会成为当时主流的命令式编程语言 (imperative programming) 的一部分。
正如面向对象的语言是围绕面向对象的开发理念设计一样，命令式编程语言是围绕自顶向下(top-down)的开发理念设计的。在自顶向下的理念指导下，程序被切分为一个主程序和大大小小的子模块，每一个子模块又可能调用更多子模块等等。C 家族语言的 main() 函数就是这种自顶而下思想的体现。在这种理念指导下，各模块形成层次调用关系，而程序设计就是制作这些子过程。在“自顶向下”这种层次化的理念下，具有鲜明层次的子过程调用成为软件系统最自然的组织方式，也是理所当然。相较之下，具有执行中让出和恢复功能的协程在这种架构下无用武之地。可以说，自上而下的设计思想从一开始就排除了对协程的需求。其后的结构化编程(Structural Programming) 思想，更是进一步强化了“子过程调用作为唯一控制结构”的基本假设。在这样的指导思想下，协程一直没有成为当时编程语言的一等公民。
尽管从提出到上世纪 90 年代，协程在编程语言中没有普遍成为一等公民，但作为一种易于理解的控制结构，协程的概念渗入到了软件设计的许多方面。在结构化编程思想一统天下之时， D.</description>
    </item>
    
    <item>
      <title>Coroutine-Switching</title>
      <link>https://hitzhangjie.github.io/blog/2017-04-26-coroutine-switching/</link>
      <pubDate>Wed, 26 Apr 2017 16:23:49 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-04-26-coroutine-switching/</guid>
      <description>1. 协程Coroutine 1.1. 协程coroutine声明 file: coroutine.h
#include &amp;lt;stdint.h&amp;gt; typedef int64_t (*EntryCallback)(void*); //硬件上下文信息 struct stRegister { uint64_t rax; uint64_t rbx; uint64_t rcx; uint64_t rdx; uint64_t rsi; uint64_t rdi; uint64_t r8; uint64_t r9; uint64_t r10; uint64_t r11; uint64_t r12; uint64_t r13; uint64_t r14; uint64_t r15; uint64_t rbp; uint64_t rsp; uint64_t rip; }; //协程上下文 struct stContext { struct stRegister cpu_register; void *arg; uint8_t *stack; }; typedef struct stContext Coroutine; //创建协程 Coroutine* CreateCoroutine(EntryCallback entry, void *arg); //删除协程 void DeleteCoroutine(Coroutine *ptr); //设置协程栈尺寸 void SetStackSize(uint32_t size); //协程切换 void __SwitchCoroutine__(Coroutine *cur, const Coroutine *next); 1.</description>
    </item>
    
    <item>
      <title>Java NIO Tutorials</title>
      <link>https://hitzhangjie.github.io/blog/2017-04-20-%E5%AD%A6%E4%B9%A0java-nio/</link>
      <pubDate>Wed, 05 Apr 2017 14:56:32 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-04-20-%E5%AD%A6%E4%B9%A0java-nio/</guid>
      <description>1 前言 Java NIO，意为Java New IO，是一种相对于Java标准IO、网络API的替代方案。从JDK 1.4开始NIO就被引入了进来，它提供了另一种IO处理的方式，这使得Java在IO处理方面向前迈进了一大步。
NIO Channel &amp;amp; Buffer 在Java标准IO里面，IO处理的对象是字节流或字符流，在NIO里面我们处理的对象是channel和buffer，数据读总是从channel中读入到buffer，输入写总是从buffer写入到channel。
NIO Non-Blocking IO Java NIO使得我们可以通过非阻塞的方式执行IO处理，例如一个线程请求从channel中读取数据到buffer的时候，在channel执行数据读取操作到buffer的过程中，线程仍然可以执行其他的处理工作，当数据被读取到buffer中之后，线程再去对数据进行处理。数据写的过程也是与此类似。
 备注：
其实参考glibc中的pthread用户级线程库实现，可以大致想到这种channel、buffer工作模式的一种大致实现，大不了我多开一个用户线程让其执行channel和buffer之间的数据传输工作，处理完之后给原本请求channel读写数据的用户线程发个信号让其进行数据处理。Linux中的AIO就是这么搞的，可以参考《Linux设备驱动开发》。
大家所描述的没有底层硬件支持的异步，很多都是指的软件代码执行序上的异步，本质上代码还是在以同步的方式执行，只不过在这些同步技术之上结合一些小佐料起到了类似的异步执行的效果。
 NIO Selector Java NIO中有Selector（选择器）的概念，一个selector可以对多个channel上的事件进行监听，例如对多个channel上的连接打开、数据到达事件进行监听，因此一个selector可以用于对多个channel上的连接打开、关闭以及读写事件进行监听、处理。
 备注：
Linux中的selector本质上是基于epoll实现的，因此可以结合epoll来理解selector。
channel不过是对网络套接字的封装，buffer不过是对接收缓冲、发送缓冲的封装，selector不过是对epollfd的封装，selector对多个channel的监听，不过是epoll在epollfd上EPOLL_CTL_ADD了多个channel对应的fd，并对其上的事件进行必要的监听。selector轮询事件是否发生，本质上也就是epoll_wait轮询注册的多个fd上是否有事件发生。
 下面将展开介绍Java NIO是如何工作的。
2 概要 Java NIO包括3个核心组件，即channel、buffer、selector。Java NIO里面包括的类不止这几个，但是我个人认为Java NIO API的核心类就这几个，其他的例如Pipe、FileLock子类的都是配合这3个核心组件使用的工具类，所以这里先重点介绍channel、buffer、selector，后面会在独立章节中对其他类进行介绍。
NIO Channel &amp;amp; Buffer Java NIO中的所有IO操作几乎都是从一个channel开始的，channel可以看做是对一对套接字的封装，例如一个tcp连接。可以从channel中读取数据到buffer，同样也可以将buffer中的数据写入到channel中，下图展示了channel和buffer的这一关系。
Channel大致有如下几种实现：
 FileChannel DatagramChannel SocketChannel ServerSocketChannel  其中FileChannel主要用于文件io，DatagramChannel主要用于udp网络通信，SocketChannel用于tcp网络通信，而ServerSocketChannel用于建立tcp连接。
Buffer大致有如下几种实现：
 ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer  上述多种Buffer的不同之处在于其中存储的数据类型的差异，例如ByteBuffer就是按照直接进行读写，CharBuffer就是按照字符进行读写。
Java NIO中海油一种Buffer实现MappedByteBuffer，这种Buffer需要与内存映射文件来配合使用，我们这里暂时先不予介绍。
NIO Selector 一个selector允许一个单一线程对多个channel上的事件进行处理（Linux平台下的selector实现就是基于epoll），一个单一线程也可以对多个channel进行高效的io处理，例如一个可能会创建很多tcp连接每个tcp连接流量不大的情况下，比如构建一个聊天服务。</description>
    </item>
    
    <item>
      <title>学习Apache Ant</title>
      <link>https://hitzhangjie.github.io/blog/2017-04-01-%E5%AD%A6%E4%B9%A0apache-ant/</link>
      <pubDate>Sat, 01 Apr 2017 17:45:40 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-04-01-%E5%AD%A6%E4%B9%A0apache-ant/</guid>
      <description>Apache Ant是由Apache开发的基于Java的构建工具，本文对tutorialspoint上面的Apache Ant教程进行简要总结。
1 为什么需要这样一个构建工具？ Ant是Another Neat Tool的缩写形式，为什么需要这样一个工具呢？跟它的名字一样，就是希望我们开发人员的工作能够更加neat！
开发人员有些琐碎的、重复性的工作，包括：编译代码、打包可执行程序、部署程序到测试服务器、测试改变、拷贝代码到不同的地方。Ant可以帮助我们自动化上面列举的这几个步骤，简化我们的工作。
Ant是tomcat的作者开发出来的，最初适用于构建tomcat的，并且作为tomcat的一部分，之所以开发它是为了弥补当初Apache Make工具（没有在apache项目列表中搜索到该项目）的不足之处，2000年的时候Ant从tomcat项目中独立出来作为一个独立的项目开发。
至于Apache Ant的优势具体在哪，这个我们最后在给出来，目的是让大家结合自身工作经历，根据Apache Ant的功能自己主动去发现它的优势。
2 Ant build.xml Ant的构建脚本默认是build.xml，也可以用其他的文件名。build.xml里面通常包括tag ，这里name指定了工程的名字，default是默认名字，basedir指定了工程的根目录。另外还包括多个tag ，其中name指定了目标动作的名字，例如compile、package、clean等等，它们之间存在某种依赖关系，可以通过depends指定。例如package依赖clean、compile，就可以指定depends=&amp;quot;clean,package&amp;rdquo;，注意依赖先后顺序，不要写成depends=&amp;quot;package,clean&amp;rdquo;。
示例1：
&amp;lt;?xml version=&amp;#34;1.0&amp;#34;?&amp;gt; &amp;lt;project name=&amp;#34;Hello World Project&amp;#34; default=&amp;#34;info&amp;#34;&amp;gt; &amp;lt;target name=&amp;#34;info&amp;#34;&amp;gt; &amp;lt;echo&amp;gt;Hello World - Welcome to Apache Ant!&amp;lt;/echo&amp;gt; &amp;lt;/target&amp;gt; &amp;lt;/project&amp;gt; 示例2：
&amp;lt;target name=&amp;#34;deploy&amp;#34; depends=&amp;#34;package&amp;#34;&amp;gt; .... &amp;lt;/target&amp;gt; &amp;lt;target name=&amp;#34;package&amp;#34; depends=&amp;#34;clean,compile&amp;#34;&amp;gt; .... &amp;lt;/target&amp;gt; &amp;lt;target name=&amp;#34;clean&amp;#34; &amp;gt; .... &amp;lt;/target&amp;gt; &amp;lt;target name=&amp;#34;compile&amp;#34; &amp;gt; .... &amp;lt;/target&amp;gt; build.xml里面可以使用ant预先定义的一些变量，例如：
   property desc     ant.</description>
    </item>
    
    <item>
      <title>我的兴趣列表</title>
      <link>https://hitzhangjie.github.io/blog/2017-02-25-%E6%88%91%E7%9A%84%E5%85%B4%E8%B6%A3%E5%88%97%E8%A1%A8/</link>
      <pubDate>Sat, 25 Feb 2017 21:07:54 +0800</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-02-25-%E6%88%91%E7%9A%84%E5%85%B4%E8%B6%A3%E5%88%97%E8%A1%A8/</guid>
      <description>hitzhangjie&amp;rsquo;s blog 2016-07-04 11:12:22 AM ==============================================================================
With the help of github.io,I start my personal blog - hitzhangjie&amp;rsquo;s blog. I will share my ideas, experience, lessons taught during my study and work, which includes but not limited to:
1. Computer Engineering Techniques  Programming Languages  C C++ Java Shell JavaScript Python Perl Go   Unix/Linux System Administration  Start to Shutdown internals Important Scripts Systemd vs. Initd Services Control Job Control Process Control Web Server Setup  Httpd (Apache Web Server) Nginx Tomcat   Database Server Setup  MySQL MarialDB Oracle PostgreSQL SQLite etc   Distributed Cache Server  Memcached etc   Email Server Git Server Bugzilla TheBugGennie   Linux Kernel Internals  C Prerequisitives Virtual Memory Manangement Process Schedule Network Interrupt, Exception and Signal FileSystems etc.</description>
    </item>
    
    <item>
      <title>golang method receiver-type的梗</title>
      <link>https://hitzhangjie.github.io/blog/2018-05-21-golang-method-receiver-type%E7%9A%84%E6%A2%97/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2018-05-21-golang-method-receiver-type%E7%9A%84%E6%A2%97/</guid>
      <description>这里来聊聊method receiver type为什么不能是pointer和interface类型。
1 receiver-type必须满足的条件 golang里面提供了一定的面向对象支持，比如我们可以为类型T或者*T定义成员方法（类型T称为成员方法的receiver-type），但是这里的类型T必须满足如下几个条件：
 T必须是已经定义过的类型； T与当前方法定义必须在同一个package下面； T不能是指针； T不能是接口类型；  前面两点都比较容易理解，下面两点是什么梗？为什么就不能在指针类型上添加方法？为什么就不能在interface上添加方法？当然可以一句话待过，golang不支持，但是我想问下为什么？
2 receiver-type为什么不能是指针类型？ golang允许为 类型指针*T 添加方法，但是不允许为 指针类型本身 添加方法。按现有golang的实现方式，为指针类型添加方法会导致方法调用时的歧义。
看下面这个示例程序。
type T int func (t *T) Get() T { return *t + 1 } type P *T func (p P) Get() T { return *p + 2 } func F() { var v1 T var v2 = &amp;amp;v1 var v3 P = &amp;amp;v1 fmt.Println(v1.Get(), v2.Get(), v3.Get()) } 示例程序中 v3.Get() 存在调用歧义，编译器不知道该调用哪个方法了。如果要支持在指针这种receiver-type上定义方法，golang编译器势必要实现地更复杂才能支持到，指针本来就比较容易破坏可读性，还要在一种指针类型上定义方法，对使用者、编译器开发者而言可能都是件费力不讨好的事情。</description>
    </item>
    
    <item>
      <title>Nothing, Just Linux!</title>
      <link>https://hitzhangjie.github.io/blog/2017-03-13-nothing-just-linux/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://hitzhangjie.github.io/blog/2017-03-13-nothing-just-linux/</guid>
      <description>1 邂逅Linux 初次接触Linux操作系统是在什么时候？想想～～
高三毕业后买了第一台电脑，一台清华同方的台式机，随机赠送的光盘里面有一张操作系 统光盘“家电下乡Linux适农版”……那是我第一次接触并运行Linux，但那时的我并没有意识 到，放在我面前的是一个即将深深地吸引我并要在多年的职业生涯中去不断锤炼的存在。
大一、大二这两年，我或多或少地接触到了Linux，但是并没有产生多大兴趣，直到有一 天我激怒了一个同学。当时他正在摆弄Ubuntu，错误地GRUB配置导致系统引导失败，着急 的他在QQ空间发了一条状态，意思就是大神求救之类的。当时我回了一个字“水”。他看后 很生气，系统都启动不了了能不着急吗？于是呢，就言辞激烈地“回敬”了我几句……
事后我想，Linux有这么复杂吗？于是我开始试图取了解Linux，当然这只是个引子，后面 陆陆续续看到有不少同学都在使用各种Linux的发行版，我才决定认真去了解、学习一下 Linux，没想到这竟是一条不归路……
 LiveCD &amp;amp; RemasterSys &amp;amp; dump &amp;amp; restore GRUB 2 &amp;amp; Customize Boot Menu to bootstrap Multiple OS Plymouth Tweak KDE/GNOME/Unity Appearance (Colors &amp;amp; Themes) Linux Commandline Techs &amp;amp; Administration Unix/Linux Programming Linux Kernel 0.11 Linux Kernel 2.4 Keep going along the roadmap to Linux World!  上面大体上是我初识、折腾、学习、应用、研究Linux的过程，而且这个过程在相当长一 段事时间内还将一直向前延伸下去。与其说对Linux感兴趣，不如说是好奇心驱使，还有 很多疑问没有揭开，这里当然不只是Linux操作系统内核本身。
我这个博客所要描述的东西可能就比较杂了，这里面我会穿插着记录很多东西～与其说是 博客，不如说是我自己的一个学习笔记了，但是我这个人比较喜欢分享，但有不想那么刻 意，所以我就把它丢在这，谁看见就看，看不见就当作我个人的笔记了。
2 LiveCD &amp;amp; RemasterSys &amp;amp; dump &amp;amp; restore 3 GRUB 2 &amp;amp; Customize Boot Menu to bootstrap Multiple OS 4 Plymouth 5 Tweak KDE/GNOME/Unity Appearance (Colors &amp;amp; Themes) 6 Linux Commandline Techs &amp;amp; Administration 7 Unix/Linux Programming 8 Linux Kernel 0.</description>
    </item>
    
  </channel>
</rss>