<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>gmp on</title><link>/tags/gmp/</link><description>Recent content in gmp on</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><lastBuildDate>Thu, 27 Jun 2024 12:36:00 +0800</lastBuildDate><atom:link href="/tags/gmp/index.xml" rel="self" type="application/rss+xml"/><item><title>Linux任务调度(7): CFS调度器源码分析1</title><link>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A67v2/</link><pubDate>Thu, 27 Jun 2024 12:36:00 +0800</pubDate><guid>/blog/%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A67v2/</guid><description>Linux任务调度(7): CFS调度器源码分析 # 前面几篇文章介绍了Linux下调度器的演进过程，也对CFS调度器的大致工作原理进行了介绍，本文在CFS源码层面进行深入分析，帮助大家更深刻地理解CFS调度器的实现细节。Linux从开始引入CFS调度器到现在，已经发展了近20年的时间。在这一段时间里，CFS调度器经历了多次演进，我们选择相对比较新的版本 v5.12 版本内核为例进行说明。现在主流云厂商提供的Linux发行版内核都还有这个版本，我们的分析仍然具有一定的时效性方面的价值。OK，我们开始。
核心概念及源码分析 # 对“公平”的理解 # CFS的目标是为所有任务提供公平的CPU时间分配，这里要先好好理解下 “公平” 的含义：
1）如果多个任务具有相同的优先级，那么它们理应获得相同的调度机会； 2）如果多个任务优先级有高低之分，那么它们在调度上要有对应的体现，优先级高的要获得更多的调度机会； 3）要防止高优先级任务始终霸占CPU，导致低优先级任务饿死（starvation）； 4）对于响应式任务、非响应式任务，要有必要的奖励和惩罚机制，以改善用户体验； 5）要有能力在用户层级、任务组层级、具体任务层级，建立这种“公平性”； 6）这种公平性在多CPU核心上，除了100%保证单CPU核心上的公平，也需要考虑负载均衡和任务迁移，尽力去做到多CPU核心上的整体调度的相对公平；
这是我对CFS中“公平性”的理解，接下来我们将结合CFS的源码来分析是如何做到的，让大家知其然知其所以然。
核心数据结构 # 被调度的具体任务，或者用户组、任务组，它们都用可调度实体来抽象表示，即 sched_entity； struct sched_entity { /* For load-balancing: */ struct load_weight load; struct rb_node run_node; struct list_head group_node; unsigned int on_rq; u64 exec_start; u64 sum_exec_runtime; u64 vruntime; u64 prev_sum_exec_runtime; u64 nr_migrations; struct sched_statistics exec_statistics; #ifdef CONFIG_FAIR_GROUP_SCHED int depth; struct sched_entity *parent; /* rq on which this entity is (to be) queued: */ struct cfs_rq *cfs_rq; /* rq &amp;quot;owned&amp;quot; by this entity/group: */ struct cfs_rq *my_q; /* cached value of my_q-&amp;gt;h_nr_running */ unsigned long runnable_weight; #endif #ifdef CONFIG_SMP /* * Per entity load average tracking.</description></item></channel></rss>